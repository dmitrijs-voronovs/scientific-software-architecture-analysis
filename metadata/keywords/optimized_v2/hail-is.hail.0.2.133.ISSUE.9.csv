quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Energy Efficiency,"li>; <p>Add <code>py.typed</code> macro <a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/89"">#89</a></p>; </li>; <li>; <p>Drop python 3.4 support and fix minimal version python3.5.3 <a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/88"">#88</a></p>; </li>; <li>; <p>Add property with that indicates if queue is closed <a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/86"">#86</a></p>; </li>; </ul>; <h2>0.3.2 (2018-07-06)</h2>; <ul>; <li>Fixed python 3.7 support <a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/97"">#97</a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/janus/commit/0783f9b7a9bb7e1c095e93ebb4aad4f1e219f512""><code>0783f9b</code></a> Fix coverage upload</li>; <li><a href=""https://github.com/aio-libs/janus/commit/41c49bafb1b192d2ee25b7394cead2386e452dc2""><code>41c49ba</code></a> Make deployment only if checks are green</li>; <li><a href=""https://github.com/aio-libs/janus/commit/ec94b35b2ae095dcb97827f1369c0cd31b7e8e5e""><code>ec94b35</code></a> Fix CI again</li>; <li><a href=""https://github.com/aio-libs/janus/commit/2303208c2f972e38445e7ecec54fda0f3203f566""><code>2303208</code></a> Fix CI</li>; <li><a href=""https://github.com/aio-libs/janus/commit/dff507895bf8d77efea2c4cc1d8b04a8a2986a0b""><code>dff5078</code></a> Bump to 1.0.0</li>; <li><a href=""https://github.com/aio-libs/janus/commit/3421545f3954b7ef6d90e02b7653a7ab685f3e78""><code>3421545</code></a> Bump mypy from 0.910 to 0.920 (<a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/384"">#384</a>)</li>; <li><a href=""https://github.com/aio-libs/janus/commit/56b2d1d8dbd10cce28302a4e1c4224ce219c6246""><code>56b2d1d</code></a> Bump black from 21.11b1 to 21.12b0 (<a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/383"">#383</a>)</li>; <li><a href=""https://github.com/aio-li",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11466:3002,green,green,3002,https://hail.is,https://github.com/hail-is/hail/pull/11466,1,['green'],['green']
Energy Efficiency,"li>Remove kubescheduler.config.k8s.io/v1alpha1 (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89298"">kubernetes/kubernetes#89298</a>, <a href=""https://github.com/gavinfish""><code>@​gavinfish</code></a>) [SIG Scheduling]</li>; <li>Reserve plugins that fail to reserve will trigger the unreserve extension point (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92391"">kubernetes/kubernetes#92391</a>, <a href=""https://github.com/adtac""><code>@​adtac</code></a>) [SIG Scheduling and Testing]</li>; <li>Resolve regression in <code>metadata.managedFields</code> handling in update/patch requests submitted by older API clients (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91748"">kubernetes/kubernetes#91748</a>, <a href=""https://github.com/apelisse""><code>@​apelisse</code></a>)</li>; <li>Scheduler: optionally check for available storage capacity before scheduling pods which have unbound volumes (alpha feature with the new <code>CSIStorageCapacity</code> feature gate, only works for CSI drivers and depends on support for the feature in a CSI driver deployment) (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92387"">kubernetes/kubernetes#92387</a>, <a href=""https://github.com/pohly""><code>@​pohly</code></a>) [SIG API Machinery, Apps, Auth, Scheduling, Storage and Testing]</li>; <li>Seccomp support has graduated to GA. A new <code>seccompProfile</code> field is added to pod and container securityContext objects. Support for <code>seccomp.security.alpha.kubernetes.io/pod</code> and <code>container.seccomp.security.alpha.kubernetes.io/...</code> annotations is deprecated, and will be removed in v1.22. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91381"">kubernetes/kubernetes#91381</a>, <a href=""https://github.com/pjbgf""><code>@​pjbgf</code></a>) [SIG Apps, Auth, Node, Release, Scheduling and Testing]</li>; <li>ServiceAppProtocol feature gate is",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:12744,Schedul,Scheduler,12744,https://hail.is,https://github.com/hail-is/hail/pull/11462,2,"['Schedul', 'schedul']","['Scheduler', 'scheduling']"
Energy Efficiency,"libs/aioredis-py/issues/1101"">#1101</a>)</li>; <li>Synchronized reading the responses from a connection (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1106"">#1106</a>)</li>; </ul>; <h2>Fixes</h2>; <ul>; <li>Remove del from Redis (Fixes <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1115"">#1115</a>) (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1227"">#1227</a>)</li>; <li>fix socket.error raises (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1129"">#1129</a>)</li>; <li>Fix buffer is closed error when using PythonParser class (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1213"">#1213</a>)</li>; </ul>; <h2>Version v2.0.0</h2>; <p>Version 2.0 is a complete rewrite of aioredis. Starting with this version, aioredis now follows the API of <a href=""https://github.com/andymccurdy/redis-py"">redis-py</a>, so you can easily adapt synchronous code that uses redis-py for async applications with aioredis-py.</p>; <p><strong>NOTE:</strong> This version is <em>not</em> compatible with earlier versions of aioredis. If you upgrade, you will need to make code changes.</p>; <p>For more details, read our <a href=""https://aioredis.readthedocs.io/en/latest/migration/"">documentation on migrating to version 2.0</a>.</p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aioredis-py/blob/master/CHANGELOG.md"">aioredis's changelog</a>.</em></p>; <blockquote>; <h2>2.0.1 - (2021-12-20)</h2>; <h3>Features</h3>; <ul>; <li>Added Python 3.10 to CI &amp; Updated the Docs; (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1160"">#1160</a>)</li>; <li>Enable mypy in CI (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1101"">#1101</a>)</li>; <li>Synchronized reading the responses from a connection; (see <a href",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11569:1540,adapt,adapt,1540,https://hail.is,https://github.com/hail-is/hail/pull/11569,1,['adapt'],['adapt']
Energy Efficiency,"lization stack:; 	- object not serializable (class: is.hail.io.bgen.BgenRecordV11$$anon$1, value: BgenRecordV11(0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=0.99798583984375,0.00201416015625,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0,. goes on for a while. field (class: scala.Tuple2, name: _2, type: class java.lang.Object); 	- object (class scala.Tuple2, ([rs149841286:10000179:AAAAAAAC:A,---],BgenRecordV11(0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0,. keeps on going like above until remaining stack trace:. at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2527:1587,schedul,scheduler,1587,https://hail.is,https://github.com/hail-is/hail/issues/2527,1,['schedul'],['scheduler']
Energy Efficiency,"llect_distributed_array_table_native_writer.__m9658split_Let(Unknown Source)__C9622collect_distributed_array_table_native_writer.apply(Unknown Source)__C9622collect_distributed_array_table_native_writer.apply(Unknown Source); app//is.hail.backend.BackendUtils.$anonfun$collectDArray$6(BackendUtils.scala:52); app//is.hail.backend.BackendUtils$Lambda$783/0x000000080080c040.apply(Unknown Source); app//is.hail.utils.package$.using(package.scala:635); app//is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); app//is.hail.backend.BackendUtils.$anonfun$collectDArray$5(BackendUtils.scala:51); app//is.hail.backend.BackendUtils$Lambda$757/0x00000008007bcc40.apply(Unknown Source); app//is.hail.backend.spark.SparkBackendComputeRDD.compute(SparkBackend.scala:751); app//org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365); app//org.apache.spark.rdd.RDD.iterator(RDD.scala:329); app//org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); app//org.apache.spark.scheduler.Task.run(Task.scala:136); app//org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); app//org.apache.spark.executor.Executor$TaskRunner$Lambda$608/0x0000000800652c40.apply(Unknown Source); app//org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); app//org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); java.base@11.0.17/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); java.base@11.0.17/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); java.base@11.0.17/java.lang.Thread.run(Thread.java:829); ```. A few things:; 1. Verify that this case statement is evaluated intelligently. In particular, we really want to evaluate each predicate once, and only if necessary.; 2. We *should not allocate* just to evaluate these reference genome predicates, but that is [exactly what we do](https://github.com/hail-is/hail/blob/main/hail/src/main/scala/is/hail/expr/ir/functions/Locu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13862:3179,schedul,scheduler,3179,https://hail.is,https://github.com/hail-is/hail/issues/13862,1,['schedul'],['scheduler']
Energy Efficiency,llection.AbstractIterator.aggregate(Iterator.scala:1336); 	at is.hail.sparkextras.ContextRDD$$anonfun$6$$anonfun$apply$11.apply(ContextRDD.scala:237); 	at is.hail.sparkextras.ContextRDD$$anonfun$6$$anonfun$apply$11.apply(ContextRDD.scala:235); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.sparkextras.ContextRDD$$anonfun$6.apply(ContextRDD.scala:235); 	at is.hail.sparkextras.ContextRDD$$anonfun$6.apply(ContextRDD.scala:234); 	at scala.Function1$$anonfun$andThen$1.apply(Function1.scala:52); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; ```. _All_ of my workers had this error:; ```; java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:815); 	at is.hail.expr.MatrixM,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:6217,schedul,scheduler,6217,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681,1,['schedul'],['scheduler']
Energy Efficiency,llection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer$$anonfun$writeRows$1.apply$mcV$sp(WriterContainer.scala:253); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer$$anonfun$writeRows$1.apply(WriterContainer.scala:252); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer$$anonfun$writeRows$1.apply(WriterContainer.scala:252); 	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1348); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer.writeRows(WriterContainer.scala:258); 	... 8 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1822:5931,schedul,scheduler,5931,https://hail.is,https://github.com/hail-is/hail/issues/1822,1,['schedul'],['scheduler']
Energy Efficiency,"llib3.exceptions.ReadTimeoutError: HTTPConnectionPool(host='127.0.0.1', port=5000): Read timed out. (read timeout=120). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/batch/server.py"", line 417, in run_forever; target(*args, **kwargs); File ""/batch/server.py"", line 441, in kube_event_loop; requests.post('http://127.0.0.1:5000/pod_changed', json={'pod_name': name}, timeout=120); File ""/usr/lib/python3.6/site-packages/requests/api.py"", line 116, in post; return request('post', url, data=data, json=json, **kwargs); File ""/usr/lib/python3.6/site-packages/requests/api.py"", line 60, in request; return session.request(method=method, url=url, **kwargs); File ""/usr/lib/python3.6/site-packages/requests/sessions.py"", line 524, in request; resp = self.send(prep, **send_kwargs); File ""/usr/lib/python3.6/site-packages/requests/sessions.py"", line 637, in send; r = adapter.send(request, **kwargs); File ""/usr/lib/python3.6/site-packages/requests/adapters.py"", line 529, in send; raise ReadTimeout(e, request=request); requests.exceptions.ReadTimeout: HTTPConnectionPool(host='127.0.0.1', port=5000): Read timed out. (read timeout=120); INFO | 2018-10-23 03:58:08,124 | server.py | run_forever:416 | run_forever: run target kube_event_loop; INFO | 2018-10-23 03:59:30,729 | server.py | mark_complete:175 | wrote log for job 153 to logs/job-153.log; INFO | 2018-10-23 03:59:30,730 | server.py | set_state:141 | job 153 changed state: Created -> Complete; INFO | 2018-10-23 03:59:30,730 | server.py | mark_complete:184 | job 153 complete, exit_code 2; INFO | 2018-10-23 03:59:30,737 | _internal.py | _log:88 | 127.0.0.1 - - [23/Oct/2018 03:59:30] ""POST /pod_changed HTTP/1.1"" 204 -; INFO | 2018-10-23 03:59:30,806 | _internal.py | _log:88 | 10.56.142.33 - - [23/Oct/2018 03:59:30] ""GET /jobs HTTP/1.1"" 200 -; INFO | 2018-10-23 03:59:30,815 | _internal.py | _log:88 | 127.0.0.1 - - [23/Oct/2018 03:59:30] ""POST /pod_changed HTTP/1.1"" 204 -; I",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4608#issuecomment-432083038:1798,adapt,adapters,1798,https://hail.is,https://github.com/hail-is/hail/issues/4608#issuecomment-432083038,1,['adapt'],['adapters']
Energy Efficiency,lock(TorrentBroadcast.scala:206); at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); at is.hail.io.RichRDDRegionValue$$anonfun$5.apply(RowStore.scala:757); at is.hail.io.RichRDDRegionValue$$anonfun$5.apply(RowStore.scala:756); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:65); at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); at org.apache.spark.serializer.KryoDeserializationStream.readObject(KryoSerializer.scala:246); at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$8.apply(TorrentBroadcast.scala:293); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); at org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject(TorrentBroadcast.scala:294); at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(Torrent,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3342:3697,schedul,scheduler,3697,https://hail.is,https://github.com/hail-is/hail/issues/3342,1,['schedul'],['scheduler']
Energy Efficiency,lock(TorrentBroadcast.scala:206); at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); at is.hail.io.RichRDDRegionValue$$anonfun$5.apply(RowStore.scala:757); at is.hail.io.RichRDDRegionValue$$anonfun$5.apply(RowStore.scala:756); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745)com.esotericsoftware.kryo.KryoException: Error during Java deserialization.; at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:65); at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); at org.apache.spark.serializer.KryoDeserializationStream.readObject(KryoSerializer.scala:246); at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$8.apply(TorrentBroadcast.scala:293); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); at org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject(TorrentBroadcast.scala:294); at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.sca,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3342:9855,schedul,scheduler,9855,https://hail.is,https://github.com/hail-is/hail/issues/3342,1,['schedul'],['scheduler']
Energy Efficiency,lock(TorrentBroadcast.scala:206); at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); at is.hail.io.RichRDDRegionValue$$anonfun$5.apply(RowStore.scala:757); at is.hail.io.RichRDDRegionValue$$anonfun$5.apply(RowStore.scala:756); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745)java.lang.ClassNotFoundException: is.hail.utils.SerializableHadoopConfiguration; at java.net.URLClassLoader.findClass(URLClassLoader.java:381); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at java.lang.Class.forName0(Native Method); at java.lang.Class.forName(Class.java:348); at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:677); at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1819); at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713); at java.io.ObjectInputStream.readOrdinaryObject(Objec,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3342:11993,schedul,scheduler,11993,https://hail.is,https://github.com/hail-is/hail/issues/3342,1,['schedul'],['scheduler']
Energy Efficiency,"loudDriverAPI`. Feel free to suggest a better name. The GCPResourceManager is a skeleton right now, but we'll have to flesh it out in the new year when GCP moves to spot billing with varying prices. For the `AzureResourceManager`, I use a new pricing client to grab the latest vm and disk prices. I support all possible disk prices, but for now, I limited the VM query to just get the machine types we support right now. In the future, we could get all VM prices, but the query is around 40 seconds for that compared to 2 seconds now. I was worried if we had such a slow query that blocked driver startup, that would be bad and this is fine for now. There are two classes I added: a `Resource` and a `Price`. The Price is only implemented for Azure and is used to store cost results from the pricing API. The resource has a couple of different mixin classes with an abstract method to generate the quantified resource depending on the type (ex: ComputeResourceMixin). Then there's `AzureDiskResource`, `AzureVMResource`, etc. I had to add a Resource specifically for external disks which made things a little more complicated because you don't know the size of the disk ahead of time. The reason for storing the resources in the InstanceConfig now is because we can change the implementation or add new products without breaking the billing for existing instances. I think this is a positive change and will give us more flexibility. I also worked hard to make sure the definition of a resource prefix was only defined in a consistent place for each resource type. The `AzureExternalDiskResource` is complicated because we have to store all possible disk resource names that are current at the time of Instance creation for that disk family. This is because Azure charges different rates per disk type (ex: P20) and the cost per GiB is not consistent across products. Therefore, one job could use a P4 while another job uses a P50, so we have to store all disk types with their latest resource names.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11092:2743,charge,charges,2743,https://hail.is,https://github.com/hail-is/hail/pull/11092,1,['charge'],['charges']
Energy Efficiency,lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:78); at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:21); at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:19); at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:19); at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:45); at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:600); at is.hail.backend.spark.SparkBackend.$anonfun$execute$4(SparkBackend.scala:636); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); at is.hail.backend.spark.SparkBackend.$anonfun$execute$3(SparkBackend.scala:631); at is.hail.backend.spark.SparkBackend.$anonfun$execute$3$adapted(SparkBackend.scala:630); at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); at is.hail.utils.package$.using(package.scala:664); at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); at is.hail.utils.package$.using(package.scala:664); at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); at is.hail.backend.spark.SparkBackend.$anonfun$withExecuteContext$2(SparkBackend.scala:407); at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:393); at is.hail.backend.spark.SparkBackend.execute(SparkBackend.scala:630); at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); at com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:79); at sun.net.httpserver.AuthFilter.doFilter(AuthFilter.java:83);,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14249:5886,adapt,adapted,5886,https://hail.is,https://github.com/hail-is/hail/issues/14249,1,['adapt'],['adapted']
Energy Efficiency,lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:78); at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:21); at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:19); at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:19); at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:45); at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:601); at is.hail.backend.spark.SparkBackend.$anonfun$execute$4(SparkBackend.scala:637); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); at is.hail.backend.spark.SparkBackend.$anonfun$execute$3(SparkBackend.scala:632); at is.hail.backend.spark.SparkBackend.$anonfun$execute$3$adapted(SparkBackend.scala:631); at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:77); at is.hail.utils.package$.using(package.scala:665); at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:77); at is.hail.utils.package$.using(package.scala:665); at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:64); at is.hail.backend.spark.SparkBackend.$anonfun$withExecuteContext$2(SparkBackend.scala:407); at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:393); at is.hail.backend.spark.SparkBackend.execute(SparkBackend.scala:631); at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:89); at com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:79); at sun.net.httpserver.AuthFilter.doFilter(AuthFilter.java:83);,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14168:7148,adapt,adapted,7148,https://hail.is,https://github.com/hail-is/hail/issues/14168,3,['adapt'],['adapted']
Energy Efficiency,ls.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:198); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apa,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:2242,schedul,scheduler,2242,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437,1,['schedul'],['scheduler']
Energy Efficiency,"lt: is.hail.io.bgen.Bgen12GenotypeIterator; Serialization stack:; 	- object not serializable (class: is.hail.io.bgen.Bgen12GenotypeIterator, value: Bgen12GenotypeIterator(0/0:.:.:.:GP=0.99798583984375,0.00201416015625,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:; ```; ```; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1906); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1219); 	at org.apache.spark.rdd.PairRDDFun",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:1269,schedul,scheduler,1269,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783,1,['schedul'],['scheduler']
Energy Efficiency,ltTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(Spar,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3901:7507,schedul,scheduler,7507,https://hail.is,https://github.com/hail-is/hail/issues/3901,2,['schedul'],['scheduler']
Energy Efficiency,ltTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(Spar,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3040:7349,schedul,scheduler,7349,https://hail.is,https://github.com/hail-is/hail/issues/3040,2,['schedul'],['scheduler']
Energy Efficiency,ltTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at is.hail.sparkextras.ContextRDD.runJob(Con,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4055:6200,schedul,scheduler,6200,https://hail.is,https://github.com/hail-is/hail/issues/4055,2,['schedul'],['scheduler']
Energy Efficiency,ltTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at is.hail.sparkextras.ContextRDD.runJob(Con,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3516:4045,schedul,scheduler,4045,https://hail.is,https://github.com/hail-is/hail/issues/3516,1,['schedul'],['scheduler']
Energy Efficiency,ltTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at is.hail.sparkextras.ContextRDD.runJob(Con,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3790:6942,schedul,scheduler,6942,https://hail.is,https://github.com/hail-is/hail/issues/3790,1,['schedul'],['scheduler']
Energy Efficiency,ltTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.SparkContext.runJob(Spar,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3465:9133,schedul,scheduler,9133,https://hail.is,https://github.com/hail-is/hail/issues/3465,5,['schedul'],['scheduler']
Energy Efficiency,ltTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.SparkContext.runJob(Spar,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:3530,schedul,scheduler,3530,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627,3,['schedul'],['scheduler']
Energy Efficiency,ltTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:344); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1575); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1563); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1562); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1562); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1790); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1745); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1734); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:619); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126); 	at is.hail.rvd.RVD.aggregateWithPartitionOp(RVD.scala:558); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scal,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5846:6737,schedul,scheduler,6737,https://hail.is,https://github.com/hail-is/hail/issues/5846,1,['schedul'],['scheduler']
Energy Efficiency,"lv.conf; /dev/sda1 94.3G 46.4G 47.9G 49% /etc/hostname; /dev/sda1 94.3G 46.4G 47.9G 49% /etc/hosts; shm 64.0M 0 64.0M 0% /dev/shm; tmpfs 14.7G 12.0K 14.7G 0% /var/run/secrets/kubernetes.io/serviceaccount; tmpfs 14.7G 0 14.7G 0% /proc/acpi; tmpfs 64.0M 0 64.0M 0% /proc/kcore; tmpfs 64.0M 0 64.0M 0% /proc/keys; tmpfs 64.0M 0 64.0M 0% /proc/timer_list; tmpfs 14.7G 0 14.7G 0% /proc/scsi; tmpfs 14.7G 0 14.7G 0% /sys/firmware; ```. Which isn't much larger than it was before the scaling tests. It appears to slowly increase the amount of memory it needs:; ```; 1 0 nobody S 30.9g103.7 1 11.5 /bin/prometheus --config.file=/etc/prometheus/prometheus.yml --storage.tsdb.path=/prometheus --web.console.libraries=/usr/share/prometheus/console_libraries --web.console.templates=/usr/share/prometheus/consoles --web.external; ```. caping out at 31.5 GB (the disk is 31.2 GB). Now, it is presumably trying to recover. It's been up for about 7 minutes. Still unavailable:; ```; /prometheus $ wget localhost:9090/monitoring/prometheus; Connecting to localhost:9090 (127.0.0.1:9090); wget: server returned error: HTTP/1.1 503 Service Unavailable; /prometheus $ ; ```. https://github.com/prometheus/prometheus/issues/5727#issuecomment-510818825; https://github.com/prometheus/prometheus/issues/4324#issuecomment-460243182. ```; # k logs -n monitoring prometheus-0 ; level=info ts=2019-07-31T15:45:51.990Z caller=main.go:286 msg=""no time or size retention was set so using the default time retention"" duration=15d; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:322 msg=""Starting Prometheus"" version=""(version=2.10.0, branch=HEAD, revision=d20e84d0fb64aff2f62a977adc8cfb656da4e286)""; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:323 build_context=""(go=go1.12.5, user=root@a49185acd9b0, date=20190525-12:28:13)""; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:324 host_details=""(Linux 4.14.127+ #1 SMP Tue Jun 18 18:32:10 PDT 2019 x86_64 prometheus-0 (none))""; level=info ts=2019-07-31T15:45:5",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6773:1970,monitor,monitoring,1970,https://hail.is,https://github.com/hail-is/hail/issues/6773,1,['monitor'],['monitoring']
Energy Efficiency,ly$20.apply(ContextRDD.scala:280); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-76c42fe; Error summary: ClassCastException: is.hail.codegen.generated.C29 cannot be cast to is.hail.asm4s.AsmFunction5; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:9136,schedul,scheduler,9136,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410,2,['schedul'],['scheduler']
Energy Efficiency,ly(AnnotateVariantsExpr.scala:70); at scala.collection.IndexedSeqOptimized$class.foldl(IndexedSeqOptimized.scala:51); at scala.collection.IndexedSeqOptimized$class.foldLeft(IndexedSeqOptimized.scala:60); at scala.collection.mutable.ArrayOps$ofRef.foldLeft(ArrayOps.scala:108); at org.broadinstitute.hail.driver.AnnotateVariantsExpr$$anonfun$2.apply(AnnotateVariantsExpr.scala:70); at org.broadinstitute.hail.driver.AnnotateVariantsExpr$$anonfun$2.apply(AnnotateVariantsExpr.scala:64); at org.broadinstitute.hail.variant.VariantSampleMatrix$$anonfun$mapAnnotations$1.apply(VariantSampleMatrix.scala:399); at org.broadinstitute.hail.variant.VariantSampleMatrix$$anonfun$mapAnnotations$1.apply(VariantSampleMatrix.scala:399); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:285); at org.apache.spark.CacheManager.putInBlockManager(CacheManager.scala:171); at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:78); at org.apache.spark.rdd.RDD.iterator(RDD.scala:268); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); at org.apache.spark.scheduler.Task.run(Task.scala:89); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/660#issuecomment-241800222:2376,schedul,scheduler,2376,https://hail.is,https://github.com/hail-is/hail/issues/660#issuecomment-241800222,2,['schedul'],['scheduler']
Energy Efficiency,"lygenic risk score with code from the [Polygenic Score Calculation](https://hail.is/docs/0.2/guides/genetics.html#polygenic-score-calculation), getting error with stacktrace:. `2022-05-14 12:09:07 Hail: INFO: Running Hail version 0.2.94-f0b38d6c436f; 2022-05-14 12:09:08 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.; 2022-05-14 12:09:08 root: INFO: RegionPool: initialized for thread 30: Thread-4; 2022-05-14 12:09:09 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 34.3 KiB, free 434.4 MiB); 2022-05-14 12:09:09 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 434.4 MiB); 2022-05-14 12:09:09 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on 10.40.3.21:33951 (size: 3.2 KiB, free: 434.4 MiB); 2022-05-14 12:09:09 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:311; 2022-05-14 12:09:11 root: INFO: RegionPool: FREE: 64.0K allocated (64.0K blocks / 0 chunks), regions.size = 1, 0 current java objects, thread 30: Thread-4; 2022-05-14 12:09:11 root: ERROR: HailException: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; From is.hail.utils.HailException: /data/public/prs/ex_antonk.bim:1013423: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; offending line: 11	.	0	135009883	CT	C; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:30); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:28); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.utils.Context.wrapException(Context.scala:21); 	at is.hail.utils.WithContext.foreach(Context.scala:51); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2(LoadPlink.scala:37); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2$adapted(LoadPlink.scala:36); 	at scala.collection.Iterator.foreach(Iter",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11836:1022,allocate,allocated,1022,https://hail.is,https://github.com/hail-is/hail/issues/11836,1,['allocate'],['allocated']
Energy Efficiency,mand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). java.lang.NoClassDefFoundError: Could not initialize class __C147RGContainer_GRCh38; 	at __C144Compiled.applyregion0_8(Emit.scala); 	at __C144Compiled.apply(Emit.scala); 	at is.hail.expr.ir.TableMapRows.$anonfun$execute$43(TableIR.scala:1938); 	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23); 	at scala.collection.Iterator$$anon$10.next(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:496); 	at is.hail.utils.richUtils.RichContextRDD$$anon$1.next(RichContextRDD.scala:79); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:496); 	at is.hail.utils.package$.getIteratorSizeWithMaxN(package.scala:415); 	at is.hail.rvd.RVD.$anonfun$head$2(RVD.scala:526); 	at is.hail.rvd.RVD.$anonfun$head$2$adapted(RVD.scala:526); 	at is.hail.sparkextras.ContextRDD.$anonfun$runJob$2(ContextRDD.scala:366); 	at is.hail.sparkextras.ContextRDD.sparkManagedContext(ContextRDD.scala:164); 	at is.hail.sparkextras.ContextRDD.$anonfun$runJob$1(ContextRDD.scala:365); 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:131); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.71-f3a54b530979; Error summary: NoClassDefFoundError: Could not initialize class __C147RGContainer_GRCh38; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:15072,schedul,scheduler,15072,https://hail.is,https://github.com/hail-is/hail/issues/10682,2,['schedul'],['scheduler']
Energy Efficiency,"mb: MethodBuilder, addr: Code[Long], region: Code[Region], srcPType: PType, srcAddress: Code[Long], forceDeep: Boolean): Code[Unit]; def constructAtAddress(addr: Long, region: Region, srcPType: PType, srcAddress: Long, forceDeep: Boolean): Unit; ```. - Constructs a new value at `addr`, from `srcAddrss`; - Performs a deep copy when `srcPType != this`, or when `forceDeep == true`. ```scala; def copyFromType(mb: MethodBuilder, region: Code[Region], srcPType: PType, srcAddress: Code[Long], forceDeep: Boolean): Code[Long] = ...; def copyFromType(region: Region, srcPType: PType, srcAddress: Long, forceDeep: Boolean): Long = ...; ```. - Allocates a new address and calls constructAtAddress; - For operations that can be shallow, returns srcAddress, skipping construction. # <a name=""parray""></a> PArray. An abstract class for immutable ordered collections where all elements are of a single type. Does not contain the value constructor (e.g allocate). ## Core Methods. ```scala; def allocate(region: Region, length: Int): Long = ...; def allocate(region: Code[Region], length: Code[Int]): Code[Long] = ...; ```. - Allocate the memory needed for an array of `length` length. Cannot exceed 2^31 entries. ```scala; def initialize(aoff: Long, length: Int, setMissing: Boolean = false) = ...; def stagedInitialize(aoff: Code[Long], length: Code[Int], setMissing: Boolean = false): Code[Unit] = ...; ```. - Initialize an allocated array by setting its elements to present or missing. ```scala; def isElementMissing(arrayAddress: Long, elementIndex: Int): Boolean= ...; def isElementMissing(arrayAddress: Long, elementIndex: Code[Int]): Code[Boolean] = ...; ```. - Does the element at the given index exist. ```scala; def loadLength(arrayAddress: Long): Int = ...; def loadLength(arrayAddress: Code[Long]): Code[Int] = ...; ```. - Gets the array length, will not exceed 2^31. ```scala; def loadElement(arrayAddress: Long, elementIndex: Int): Long = ...; def loadElement(arrayAddress: Code[Long], elementInd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7988:4073,allocate,allocate,4073,https://hail.is,https://github.com/hail-is/hail/issues/7988,1,['allocate'],['allocate']
Energy Efficiency,"mendelerrors and linreg has the longest help lines, so I reduced them to 80 characters, while preserving the content. Hopefully the top level help descriptions will be used as reminders of functionality rather than reference documentation, curious for your opinion.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/272:57,reduce,reduced,57,https://hail.is,https://github.com/hail-is/hail/pull/272,1,['reduce'],['reduced']
Energy Efficiency,"mes (alpha feature with the new <code>CSIStorageCapacity</code> feature gate, only works for CSI drivers and depends on support for the feature in a CSI driver deployment) (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92387"">kubernetes/kubernetes#92387</a>, <a href=""https://github.com/pohly""><code>@​pohly</code></a>) [SIG API Machinery, Apps, Auth, Scheduling, Storage and Testing]</li>; <li>Seccomp support has graduated to GA. A new <code>seccompProfile</code> field is added to pod and container securityContext objects. Support for <code>seccomp.security.alpha.kubernetes.io/pod</code> and <code>container.seccomp.security.alpha.kubernetes.io/...</code> annotations is deprecated, and will be removed in v1.22. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91381"">kubernetes/kubernetes#91381</a>, <a href=""https://github.com/pjbgf""><code>@​pjbgf</code></a>) [SIG Apps, Auth, Node, Release, Scheduling and Testing]</li>; <li>ServiceAppProtocol feature gate is now beta and enabled by default, adding new AppProtocol field to Services and Endpoints. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/90023"">kubernetes/kubernetes#90023</a>, <a href=""https://github.com/robscott""><code>@​robscott</code></a>) [SIG Apps and Network]</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/bcfd4ed2ec3b2f503adc4f2e681f9404216d302c""><code>bcfd4ed</code></a> chore: update version</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/37f5d63425976b463bb83348d592859a82f2b5af""><code>37f5d63</code></a> chore: update changelog</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/ef2fe15d3473a38f1c13558acf05631d909560ce""><code>ef2fe15</code></a> fix: watch returns raw_object if detection of returned objects fail (<a href=""https://g",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:13805,Schedul,Scheduling,13805,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['Schedul'],['Scheduling']
Energy Efficiency,monitor time-to-running for pods by tolerations,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6680:0,monitor,monitor,0,https://hail.is,https://github.com/hail-is/hail/issues/6680,1,['monitor'],['monitor']
Energy Efficiency,more efficient ld prune example,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3929:5,efficient,efficient,5,https://hail.is,https://github.com/hail-is/hail/pull/3929,1,['efficient'],['efficient']
Energy Efficiency,moved to asana to be scheduled.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7574#issuecomment-613493348:21,schedul,scheduled,21,https://hail.is,https://github.com/hail-is/hail/issues/7574#issuecomment-613493348,2,['schedul'],['scheduled']
Energy Efficiency,mplatedBulk.doWriteObject(TemplatedBulk.java:71); 	at org.elasticsearch.hadoop.serialization.bulk.TemplatedBulk.write(TemplatedBulk.java:58); 	at org.elasticsearch.hadoop.rest.RestRepository.writeToIndex(RestRepository.java:168); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:5609,schedul,scheduler,5609,https://hail.is,https://github.com/hail-is/hail/issues/4250,1,['schedul'],['scheduler']
Energy Efficiency,"mps [com.azure:azure-core-http-netty](https://github.com/Azure/azure-sdk-for-java) from 1.13.3 to 1.13.7.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/Azure/azure-sdk-for-java/releases"">com.azure:azure-core-http-netty's releases</a>.</em></p>; <blockquote>; <h2>azure-core-http-netty_1.13.7</h2>; <h2>1.13.7 (2023-09-07)</h2>; <h3>Other Changes</h3>; <h4>Dependency Updates</h4>; <ul>; <li>Upgraded <code>azure-core</code> from <code>1.42.0</code> to <code>1.43.0</code>.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/c775e1c94f17319d3d3a96fc1f5e1044c5a7bfee""><code>c775e1c</code></a> Prepare Core Libraries for September 2023 Release (<a href=""https://redirect.github.com/Azure/azure-sdk-for-java/issues/36667"">#36667</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/8b00302c83c125de0ba095d3269bc05a680c65b1""><code>8b00302</code></a> [Monitor Query] Add samples/docs for running big queries and overcoming API l...</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/f84db5ba8d7c101ad8312f89ca3bfab9b648c5d1""><code>f84db5b</code></a> Set skipPublishDocMs to true for packages which do not build docs (<a href=""https://redirect.github.com/Azure/azure-sdk-for-java/issues/36385"">#36385</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/db5547e5add394b2639a3a2103b826fd4e9bbe02""><code>db5547e</code></a> mgmt, fix <code>VirtualMachineCustomImage</code> hyperv (<a href=""https://redirect.github.com/Azure/azure-sdk-for-java/issues/36659"">#36659</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/8d1552bd407977ec4083c42695e11488fd540bba""><code>8d1552b</code></a> Run MHSM tests weekly, disable attestation in Canary (<a href=""https://redirect.github.com/Azure/azure-sdk-for-java/issues/36651"">#36651</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13597:1016,Monitor,Monitor,1016,https://hail.is,https://github.com/hail-is/hail/pull/13597,1,['Monitor'],['Monitor']
Energy Efficiency,"n ""aggregation interval"", packets are aggregated into ""records"" which are keyed (my term); by source & destination. There are currently six choices for aggregation interval: 5s, 30s, 1m,; 5m, 10m, and 15m. 3. Records are sampled. The sampling rate is a user configured floating point number (precision; unclear) between 0 and 1. 4. Metadata is optionally added to the records. The metadata captures information about the source; and destination VM such as project id, VM name, zone, region, GKE pod, GKE service, and geographic; information of external parties. The user may elect to receive all metadata, no metadata, or a; specific set of metadata fields. 5. The records are written to Google Cloud Logging. The pricing of VPC Flow Logs is described at the [network pricing page](https://cloud.google.com/vpc/network-pricing#network-telemetry). Notice that, if logs are only sent to Cloud Logging (not to BigQuery, Pub/Sub, or Cloud Storage):. > If you store your logs in Cloud Logging, logs generation charges are waived, and only Logging charges apply. I believe in this phrase ""logs generation charges"" refers to *VPC Flow logs* generation charges. The Google Cloud Logging [pricing page](https://cloud.google.com/stackdriver/pricing#google-clouds-operations-suite-pricing) indicates that, after 50 GiB of free logs, the user is charged 0.50 USD per GiB of logs. Storage is free for thirty days and 0.01 USD per GiB for each additional day. We can calculate the cost of our logs as follows. Refer to the [definition of the record format](https://cloud.google.com/vpc/docs/flow-logs#record_format) for details. ```python3; ip_string = len(""123.123.123.123""); ip_connection = 4 + ip_string + ip_string + 4 + 4; date_time = len(""1937-01-01T12:00:27.87+00:20""); record_bytes = sum((; ip_connection,; max(len('SRC'), len('DEST')),; 8,; 8,; 8,; date_time,; date_time,; )); assert record_bytes == 126. hours_per_month = 24 * 60; seconds_per_hour = 60 * 60. seconds_per_interval = 15 * 60; vms = 10000; s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12883:1813,charge,charges,1813,https://hail.is,https://github.com/hail-is/hail/pull/12883,2,['charge'],['charges']
Energy Efficiency,n$5.apply(VariantSampleMatrix.scala:151); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:415); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:369); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1626); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1099); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1099); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1767); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1767); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:63); at org.apache.spark.scheduler.Task.run(Task.scala:70); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1273); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1264); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1263); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1263); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:730); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1457); at org.apache.spark.sch,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/120:4305,schedul,scheduler,4305,https://hail.is,https://github.com/hail-is/hail/issues/120,1,['schedul'],['scheduler']
Energy Efficiency,n$apply$1.apply(TaskSchedulerImpl.scala:242); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply(TaskSchedulerImpl.scala:242); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3.apply(TaskSchedulerImpl.scala:242); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3.apply(TaskSchedulerImpl.scala:235); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:235); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:234); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.TaskSchedulerImpl.cancelTasks(TaskSchedulerImpl.scala:234); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply$mcVI$sp(DAGScheduler.scala:1543); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:200701,schedul,scheduler,200701,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['schedul'],['scheduler']
Energy Efficiency,n$apply$1.apply(TaskSchedulerImpl.scala:242); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply(TaskSchedulerImpl.scala:242); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3.apply(TaskSchedulerImpl.scala:242); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3.apply(TaskSchedulerImpl.scala:235); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:235); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:234); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.TaskSchedulerImpl.cancelTasks(TaskSchedulerImpl.scala:234); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply$mcVI$sp(DAGScheduler.scala:1543); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1457); at org.apache.spark.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:204348,schedul,scheduler,204348,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['schedul'],['scheduler']
Energy Efficiency,"n$apply$2$$anonfun$apply$3.apply(RowStore.scala:767); at is.hail.io.RichRDDRegionValue$$anonfun$5$$anonfun$apply$1$$anonfun$apply$2$$anonfun$apply$3.apply(RowStore.scala:766); at is.hail.utils.package$.using(package.scala:576); at is.hail.utils.richUtils.RichHadoopConfiguration$.writeFile$extension(RichHadoopConfiguration.scala:265); at is.hail.io.RichRDDRegionValue$$anonfun$5$$anonfun$apply$1$$anonfun$apply$2.apply(RowStore.scala:766); at is.hail.io.RichRDDRegionValue$$anonfun$5$$anonfun$apply$1$$anonfun$apply$2.apply(RowStore.scala:763); at is.hail.utils.package$.using(package.scala:576); at is.hail.io.RichRDDRegionValue$$anonfun$5$$anonfun$apply$1.apply(RowStore.scala:763); at is.hail.io.RichRDDRegionValue$$anonfun$5$$anonfun$apply$1.apply(RowStore.scala:762); at is.hail.utils.package$.using(package.scala:576); at is.hail.utils.richUtils.RichHadoopConfiguration$.writeFile$extension(RichHadoopConfiguration.scala:265); at is.hail.io.RichRDDRegionValue$$anonfun$5.apply(RowStore.scala:762); at is.hail.io.RichRDDRegionValue$$anonfun$5.apply(RowStore.scala:756); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Hail version: devel-abac611; Error summary: NumberFormatException: For input string: ""-66.2667,0,-25.4754""; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3361:15817,schedul,scheduler,15817,https://hail.is,https://github.com/hail-is/hail/issues/3361,2,['schedul'],['scheduler']
Energy Efficiency,n$apply$22$$anonfun$apply$23.apply(ContextRDD.scala:310); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.hasNext(OrderedRVD.scala:1015); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.utils.package$.getIteratorSizeWithMaxN(package.scala:357); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:444); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:444); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:471); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:469); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGSched,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4055:5263,schedul,scheduler,5263,https://hail.is,https://github.com/hail-is/hail/issues/4055,1,['schedul'],['scheduler']
Energy Efficiency,n$apply$9$$anonfun$apply$10.apply(RVD.scala:221); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:221); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:220); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:220); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:218); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1795); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.sp,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:2521,schedul,scheduler,2521,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627,1,['schedul'],['scheduler']
Energy Efficiency,"n$apply$9$$anonfun$apply$10.apply(RVD.scala:221); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:221); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8$$anonfun$apply$9.apply(RVD.scala:220); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:220); 	at is.hail.rvd.RVD$$anonfun$7$$anonfun$apply$8.apply(RVD.scala:218); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1795); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-e6de08e; Error summary: ClassCastException: is.hail.codegen.generated.C14 cannot be cast to is.hail.asm4s.AsmFunction2; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [3c5f402fed564ccd85257c0919d4bffb] entered state [ERROR] while waiting for [DONE].; Traceback (most recent call last):; File ""pyhail.py"", line 128, in <module>; main(args, pass_through_args); File ""pyhail.py"", line 109, in main; subprocess.check_output(job); File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py"", line 573, in check_output; raise CalledProcessError(retcode, cmd, ou",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:7040,schedul,scheduler,7040,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627,1,['schedul'],['scheduler']
Energy Efficiency,n(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Caused by: java.net.SocketException: Too many open files; at sun.nio.ch.Net.socket0(Native Method); at sun.nio.ch.Net.socket(Net.java:411); at sun.nio.ch.Net.socket(Net.java:404); at sun.nio.ch.SocketChannelImpl.<init>(SocketChannelImpl.java:105); at sun.nio.ch.SelectorProviderImpl.openSocketChannel(SelectorProviderImpl.java:60); at java.nio.channels.SocketChannel.open(SocketChannel.java:145); at org.apache.hadoop.net.StandardSocketFactory.createSocket(StandardSocketFactory.java:62); at org.apache.hadoop.hdfs.DFSOutputStream.createSocketForPipeline(DFSOutputStream.java:1531); at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.createBlockOutputStream(DFSOutputStream.java:1309); at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1262); at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:448). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293:9105,schedul,scheduler,9105,https://hail.is,https://github.com/hail-is/hail/issues/9293,1,['schedul'],['scheduler']
Energy Efficiency,"n, payload); 208 path = action_routes[action]; 209 port = self._backend_server_port; --> 210 resp = self._requests_session.post(f'http://localhost:{port}{path}', data=data); 211 if resp.status_code >= 400:; 212 error_json = orjson.loads(resp.content). File /opt/conda/lib/python3.10/site-packages/requests/sessions.py:635, in Session.post(self, url, data, json, **kwargs); 624 def post(self, url, data=None, json=None, **kwargs):; 625 r""""""Sends a POST request. Returns :class:`Response` object.; 626 ; 627 :param url: URL for the new :class:`Request` object.; (...); 632 :rtype: requests.Response; 633 """"""; --> 635 return self.request(""POST"", url, data=data, json=json, **kwargs). File /opt/conda/lib/python3.10/site-packages/requests/sessions.py:587, in Session.request(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json); 582 send_kwargs = {; 583 ""timeout"": timeout,; 584 ""allow_redirects"": allow_redirects,; 585 }; 586 send_kwargs.update(settings); --> 587 resp = self.send(prep, **send_kwargs); 589 return resp. File /opt/conda/lib/python3.10/site-packages/requests/sessions.py:701, in Session.send(self, request, **kwargs); 698 start = preferred_clock(); 700 # Send the request; --> 701 r = adapter.send(request, **kwargs); 703 # Total elapsed time of the request (approximately); 704 elapsed = preferred_clock() - start. File /opt/conda/lib/python3.10/site-packages/requests/adapters.py:502, in HTTPAdapter.send(self, request, stream, timeout, verify, cert, proxies); 487 resp = conn.urlopen(; 488 method=request.method,; 489 url=url,; (...); 498 chunked=chunked,; 499 ); 501 except (ProtocolError, OSError) as err:; --> 502 raise ConnectionError(err, request=request); 504 except MaxRetryError as e:; 505 if isinstance(e.reason, ConnectTimeoutError):; 506 # TODO: Remove this in 3.0.0: see #2811. ConnectionError: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960:12774,adapt,adapter,12774,https://hail.is,https://github.com/hail-is/hail/issues/13960,2,['adapt'],"['adapter', 'adapters']"
Energy Efficiency,"n.Iterator$$anon$12.nextCur(Iterator.scala:434); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Hail version: devel-544bf8f; Error summary: HailException: gcad.sv.delly.5k.vcf.bgz:column 80816: invalid character '-' in integer literal; ... 2:0:0:0:6 ./.:0,0,0:0:LowQual:0:0:0:-1:0:0:0:0 ./.:0,0,0:0:LowQual:0:0:0 ...; ^; offending line: chr1 152267996 DEL00028254 AATATATATACTTTACGTAAAGT A . PASS ...; see the Hail log for the full offending line; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3379:15747,schedul,scheduler,15747,https://hail.is,https://github.com/hail-is/hail/issues/3379,2,['schedul'],['scheduler']
Energy Efficiency,"n/pyspark/sql/utils.py"", line 36, in deco; return f(*a, **kw); File ""/opt/spark/spark-1.5.2/python/lib/py4j-0.8.2.1-src.zip/py4j/protocol.py"", line 300, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling o417.run.; : org.apache.spark.SparkDriverExecutionException: Execution error; at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1024); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1493); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1458); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1447); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:567); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1824); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1944); at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1007); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108); at org.apache.spark.rdd.RDD.withScope(RDD.scala:310); at org.apache.spark.rdd.RDD.reduce(RDD.scala:989); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1.apply(RDD.scala:1118); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108); at org.apache.spark.rdd.RDD.withScope(RDD.scala:310); at org.apache.spark.rdd.RDD.treeAggregate(RDD.scala:1095); at org.broadinstitute.hail.methods.Aggregators$.buildSampleAggregations(Aggregators.scala:66); at org.broadinstitute.hail.driver.AnnotateSamplesExpr$.run(AnnotateSamplesExpr.scala:63); at org.broadinstitute.hail.driver.AnnotateSamplesExpr$.run(AnnotateSamplesExpr.scala:11); at org.broadinstitute.hail.driver.Command.runCommand(Command.scal",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1107:1461,reduce,reduce,1461,https://hail.is,https://github.com/hail-is/hail/issues/1107,1,['reduce'],['reduce']
Energy Efficiency,nCompilable.scala:27); at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:59); at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:64); at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:83); at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:32); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:32); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:30); at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:29); at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:78); at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:21); at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:19); at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:19); at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:45); at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:600); at is.hail.backend.spark.SparkBackend.$anonfun$execute$4(SparkBackend.scala:636); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); at is.hail.backend.spark.SparkBackend.$anonfun$execute$3(SparkBackend.scala:631); at is.hail.backend.spark.SparkBackend.$anonfun$execute$3$adapted(SparkBackend.scala:630); at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); at is.hail.utils.package$.using(package.scala:664); at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14249:5113,adapt,adapted,5113,https://hail.is,https://github.com/hail-is/hail/issues/14249,1,['adapt'],['adapted']
Energy Efficiency,nCompilable.scala:27); at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:59); at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:64); at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:83); at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:32); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:32); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:30); at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:29); at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:78); at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:21); at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:19); at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:19); at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:45); at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:601); at is.hail.backend.spark.SparkBackend.$anonfun$execute$4(SparkBackend.scala:637); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); at is.hail.backend.spark.SparkBackend.$anonfun$execute$3(SparkBackend.scala:632); at is.hail.backend.spark.SparkBackend.$anonfun$execute$3$adapted(SparkBackend.scala:631); at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:77); at is.hail.utils.package$.using(package.scala:665); at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14168:6375,adapt,adapted,6375,https://hail.is,https://github.com/hail-is/hail/issues/14168,3,['adapt'],['adapted']
Energy Efficiency,nCompilable.scala:67); at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:53); at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:72); at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:69); at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:64); at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:15); at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:13); at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:13); at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:47); at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:416); at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:452); at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:70); at is.hail.utils.package$.using(package.scala:646); at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:70); at is.hail.utils.package$.using(package.scala:646); at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:59); at is.hail.backend.spark.Sp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12280:4207,adapt,adapted,4207,https://hail.is,https://github.com/hail-is/hail/issues/12280,1,['adapt'],['adapted']
Energy Efficiency,nagedContext(ContextRDD.scala:164); 	at is.hail.sparkextras.ContextRDD.$anonfun$runJob$1(ContextRDD.scala:365); 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:131); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2254); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2203); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2202); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2202); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2441); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2383); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSched,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:8056,schedul,scheduler,8056,https://hail.is,https://github.com/hail-is/hail/issues/10682,1,['schedul'],['scheduler']
Energy Efficiency,nagerMaster: INFO: Removal of executor 12 requested; 2019-01-22 13:12:06 BlockManagerMasterEndpoint: INFO: Trying to remove executor 12 from BlockManagerMaster.; 2019-01-22 13:12:06 YarnSchedulerBackend$YarnDriverEndpoint: INFO: Asked to remove non-existent executor 12; 2019-01-22 13:12:06 YarnScheduler: INFO: Cancelling stage 0; 2019-01-22 13:12:06 DAGSchedulerEventProcessLoop: ERROR: DAGSchedulerEventProcessLoop failed; shutting down SparkContext; java.util.NoSuchElementException: key not found: 70; at scala.collection.MapLike$class.default(MapLike.scala:228); at scala.collection.AbstractMap.default(Map.scala:59); at scala.collection.mutable.HashMap.apply(HashMap.scala:65); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply$mcVJ$sp(TaskSchedulerImpl.scala:243); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply(TaskSchedulerImpl.scala:242); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply(TaskSchedulerImpl.scala:242); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3.apply(TaskSchedulerImpl.scala:242); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3.apply(TaskSchedulerImpl.scala:235); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:235); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.s,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:199772,schedul,scheduler,199772,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['schedul'],['scheduler']
Energy Efficiency,"nb, from [Authorization Overview](https://kubernetes.io/docs/reference/access-authn-authz/authorization/):. > Caution: System administrators, use care when granting access to pod creation. A user granted permission to create pods (or controllers that create pods) in the namespace can: read all secrets in the namespace; read all config maps in the namespace; and impersonate any service account in the namespace and take any action the account could take. This applies regardless of authorization mode. Permission to create a pod gives you permission to mount any secrets in said namespace. Pod creation is a dangerous and powerful permission. See this [recently closed ticket on k8s](https://github.com/kubernetes/kubernetes/issues/4957). [An issue from June 2018](https://github.com/kubernetes/community/pull/1604) notes this is an issue for multi-tenant clusters. The k8s maintainers don't have bandwidth to iterate on a solution right now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5753#issuecomment-479640539:624,power,powerful,624,https://hail.is,https://github.com/hail-is/hail/pull/5753#issuecomment-479640539,1,['power'],['powerful']
Energy Efficiency,nce.toArray$(TraversableOnce.scala:339); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1431); 	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1021); 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2276); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2673); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2609); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2608); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2608); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2861); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12936:5129,schedul,scheduler,5129,https://hail.is,https://github.com/hail-is/hail/issues/12936,1,['schedul'],['scheduler']
Energy Efficiency,nceBuilder.instantiate(Extraction.scala:546); 	at org.json4s.Extraction$ClassInstanceBuilder.result(Extraction.scala:597); 	at org.json4s.Extraction$$anonfun$extract$6.apply(Extraction.scala:400); 	at org.json4s.Extraction$$anonfun$extract$6.apply(Extraction.scala:392); 	at org.json4s.Extraction$.customOrElse(Extraction.scala:606); 	at org.json4s.Extraction$.extract(Extraction.scala:392); 	at org.json4s.Extraction$.extract(Extraction.scala:39); 	... 38 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2039); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2027); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2026); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2026); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:966); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:966); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:966); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2260); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2209); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2198); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:777); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkConte,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:12333,schedul,scheduler,12333,https://hail.is,https://github.com/hail-is/hail/issues/7044,2,['schedul'],['scheduler']
Energy Efficiency,nd(WriterAppender.java:310); at org.apache.log4j.WriterAppender.append(WriterAppender.java:162); at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251); at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66); at org.apache.log4j.Category.callAppenders(Category.java:206); at org.apache.log4j.Category.forcedLog(Category.java:391); at org.apache.log4j.Category.log(Category.java:856); at org.slf4j.impl.Log4jLoggerAdapter.warn(Log4jLoggerAdapter.java:400); at org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66); at org.apache.spark.scheduler.TaskSetManager.logWarning(TaskSetManager.scala:52); at org.apache.spark.scheduler.TaskSetManager.handleFailedTask(TaskSetManager.scala:693); at org.apache.spark.scheduler.TaskSchedulerImpl.handleFailedTask(TaskSchedulerImpl.scala:421); at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply$mcV$sp(TaskResultGetter.scala:139); at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply(TaskResultGetter.scala:124); at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply(TaskResultGetter.scala:124); at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1953); at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:124); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ```; `pyhail-submit`:; ```bash; #!/bin/bash. if [ $# -ne 2 ]; then; echo 'usage: gcp-pyhail-submit <cluster> <py-file>'; exit 1; fi. cluster=$1; script=$2. echo cluster = $cluster; echo script = $script. HASH=`gsutil cat gs://hail-common/latest-hash.txt`. JAR_FILE=hail-hail-is-master-all-spark2.0.2-$HASH.jar; JAR=gs://hail-common/$JAR_FILE. PYHAIL_ZIP=gs://hail-common/pyhail-hail-is-master-$HASH.zip. gcloud dataproc jobs submit pyspark \; $,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1186#issuecomment-267416027:1887,schedul,scheduler,1887,https://hail.is,https://github.com/hail-is/hail/issues/1186#issuecomment-267416027,2,['schedul'],['scheduler']
Energy Efficiency,"ne: 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:20) 	at is.hail.utils.package$.fatal(package.scala:26) 	at is.hail.utils.Context.wrapException(Context.scala:19) 	at is.hail.utils.WithContext.foreach(Context.scala:51) 	at is.hail.utils.TextTableReader$$anonfun$5$$anonfun$apply$2.apply(TextTableReader.scala:126) 	at is.hail.utils.TextTableReader$$anonfun$5$$anonfun$apply$2.apply(TextTableReader.scala:126) 	at scala.collection.Iterator$class.foreach(Iterator.scala:893) 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336) 	at is.hail.utils.TextTableReader$$anonfun$5.apply(TextTableReader.scala:126) 	at is.hail.utils.TextTableReader$$anonfun$5.apply(TextTableReader.scala:122) 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797) 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87) 	at org.apache.spark.scheduler.Task.run(Task.scala:108) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338) 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) 	at java.lang.Thread.run(Thread.java:748) Caused by: is.hail.utils.HailException: expected 13 fields, but found 1 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9) 	at is.hail.utils.package$.fatal(package.scala:26) 	at is.hail.utils.TextTableReader$$anonfun$5$$anonfun$apply$2$$anonfun$apply$3.apply(TextTableReader.scala:129) 	at is.hail.utils.TextTableReader$$anonfun$5$$anonfun$apply$2$$anonfun$apply$3.apply(TextTableReader.scala:126) 	at is.hail.utils.WithContext.foreach(Context.scala:49) 	... 17 more; --. ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4100:1589,schedul,scheduler,1589,https://hail.is,https://github.com/hail-is/hail/issues/4100,2,['schedul'],['scheduler']
Energy Efficiency,nelImpl.map(FileChannelImpl.java:869); 	at org.apache.spark.storage.DiskStore$$anonfun$getBytes$2.apply(DiskStore.scala:103); 	at org.apache.spark.storage.DiskStore$$anonfun$getBytes$2.apply(DiskStore.scala:91); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1310); 	at org.apache.spark.storage.DiskStore.getBytes(DiskStore.scala:105); 	at org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:438); 	at org.apache.spark.storage.BlockManager.get(BlockManager.scala:606); 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:663); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:281); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGSchedu,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1806:2289,schedul,scheduler,2289,https://hail.is,https://github.com/hail-is/hail/issues/1806,1,['schedul'],['scheduler']
Energy Efficiency,netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) at io.netty.util.concurrent.Default; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1493); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2107); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114); at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:78); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1096); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8106:24755,schedul,scheduler,24755,https://hail.is,https://github.com/hail-is/hail/issues/8106,1,['schedul'],['scheduler']
Energy Efficiency,nextBlockOutputStream(DFSOutputStream.java:1262); at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:448). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.a,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293:9924,schedul,scheduler,9924,https://hail.is,https://github.com/hail-is/hail/issues/9293,1,['schedul'],['scheduler']
Energy Efficiency,"nformation. Nit: the doc doesn't say the instance monitor monitors instances, it just monitors and handles *events*. Let me be explicit: I think the doc is wrong about the monitor doing health checking because that requires it to track the instances, which I just said should be owned by the pools and the JPIM. That didn't occur to me when we were writing the doc, my apologies. I still think the monitor should:; - route events to the right pool or to the JPIM, and; - aggregate summaries up for the web UI. ---. Let me try to be more specific in my critique:. I think of the system as three layers: the top most is the driver, the middle layer is the monitor, and the bottom layer is the pool or JobPrivateInstanceManager (JPIM). I don't want control flow to go down, up, and back down again. If that happens, then we can't reason about our system as separate layers, we necessarily have to think about the middle and bottom layer together. Very specifically, this flow worries me: (instance pool) create_instance -> (instance monitor) add_instance -> adjust_for_add_instance -> (instance pool) adjust_for_add_instance. We move from low to mid *back to low*. I want information to flow in one direction: either its downward information or its upward information. ---. I'm guessing you're also concerned about code organization / code duplication. I'm not that worried about this. The JPIM and the Pool are similar things and we might inevitably produce some duplication. That's OK with me. To be honest, I think a few stand-alone functions that both of them use will eliminate any code duplication. Both pools and the JPIM will have a `name_instances` and `instance_by_last_updated`. If the duplication gets hard to manage, we might pack that up into another class like InstanceCollection. I realize this means we have several monitoring loops. I'm not very worried about that. I think it's fine and it helps simplify the architecture. It avoids entangling the monitor with the pools and the JPIM.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9772#issuecomment-738515358:1169,monitor,monitor,1169,https://hail.is,https://github.com/hail-is/hail/pull/9772#issuecomment-738515358,6,['monitor'],"['monitor', 'monitoring']"
Energy Efficiency,nfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101); at org.apache.spark.SparkContext.runJob(SparkContext.sca,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403:12721,schedul,scheduler,12721,https://hail.is,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403,1,['schedul'],['scheduler']
Energy Efficiency,nfun$apply$2(Optimize.scala:22); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.Optimize$.apply(Optimize.scala:18); E 	at is.hail.expr.ir.lowering.OptimizePass.transform(LoweringPass.scala:40); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.OptimizePass.apply(LoweringPass.scala:36); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); E 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); E 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); E 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); E 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); E 	at is.hail.expr.ir.Compile$.$anonfun$apply$4(Compile.scala:45); E 	at is.hail.backend.BackendWithCodeCache.lookupOrCompileCachedFunction(Backend.scala:126); E 	at is.hail.backend.BackendWithCodeCache.lookupOrCompileCachedFunction$(Backend.scala:122); E 	at is.hail.backend.local.LocalBackend.lookupOrCompileCachedFunction(LocalBackend.scala:73); E 	at is.hail.expr.ir.Compile$.apply(Compile.scala:39); E 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$_apply$5(CompileAndEvaluate.scala:66); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:66); E 	at,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:8341,adapt,adapted,8341,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198,1,['adapt'],['adapted']
Energy Efficiency,nfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:694); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:694); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.foreach(OrderedRVD.scala:691); 	at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:170); 	at is.hail.methods.SampleQC$$anonfun$results$1.apply(SampleQC.scala:166); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:785); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:79); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:47); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2803:2771,schedul,scheduler,2771,https://hail.is,https://github.com/hail-is/hail/issues/2803,3,['schedul'],['scheduler']
Energy Efficiency,nfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply$mcVI$sp(DAGScheduler.scala:1543); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 2019-01-22 13:12:06 YarnScheduler: INFO: Cancelling stage 0; 2019-01-22 13:12:06 DAGSchedulerEventProcessLoop: ERROR: DAGScheduler failed to cancel all jobs.; java.util.NoSuchElementException: key not found: 70; at scala.collection.MapLike$class.def,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:201963,schedul,scheduler,201963,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['schedul'],['scheduler']
Energy Efficiency,nfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkConte,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3901:7426,schedul,scheduler,7426,https://hail.is,https://github.com/hail-is/hail/issues/3901,2,['schedul'],['scheduler']
Energy Efficiency,nfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkConte,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4055:6119,schedul,scheduler,6119,https://hail.is,https://github.com/hail-is/hail/issues/4055,2,['schedul'],['scheduler']
Energy Efficiency,nfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkConte,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3516:3964,schedul,scheduler,3964,https://hail.is,https://github.com/hail-is/hail/issues/3516,1,['schedul'],['scheduler']
Energy Efficiency,nfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkConte,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3465:9052,schedul,scheduler,9052,https://hail.is,https://github.com/hail-is/hail/issues/3465,6,['schedul'],['scheduler']
Energy Efficiency,nfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkConte,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:3449,schedul,scheduler,3449,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627,3,['schedul'],['scheduler']
Energy Efficiency,ng.LowerAndExecuteShufflesPass.apply(LoweringPass.scala:161); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:50); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:517); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$4(SparkBackend.scala:546); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$3(SparkBackend.scala:542); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$3$adapted(SparkBackend.scala:541); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:76); 	at is.hail.utils.package$.using(package.scala:657); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:76); 	at is.hail.utils.package$.using(package.scala:657); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:62); 	at is.hail.backend.spark.SparkBackend.$anonfun$withExecuteContext$3(SparkBackend.scala:368); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59); 	at is.hail.backend.spark.SparkBackend.$anonfun$withExecuteContext$2(SparkBackend.scala:364); 	at is.hail.backend.spark.SparkBackend.execute(SparkBackend.scala:541); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:81); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:14006,adapt,adapted,14006,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['adapt'],['adapted']
Energy Efficiency,ng.Thread.run(Thread.java:750). java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.SSLSocketInputRecord.read(SSLSocketInputRecord.java:464); 	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:237); 	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:109); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:226); 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:104); 	at is.hail.relocated.com.google.cloud.storage.UnbufferedReadableByteChannelSession$UnbufferedReadableByteChannel.read(UnbufferedReadableByteChannelSession.java:31); 	at is.hail.relocated.com.google.cloud.storage.DefaultBufferedReadableByteChannel.read(DefaultBufferedReadableByteChannel.java:81); 	at is.hail.relocated.com.google.cloud.storage.StorageByteCh,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12982:15244,Meter,MeteredStream,15244,https://hail.is,https://github.com/hail-is/hail/issues/12982,1,['Meter'],['MeteredStream']
Energy Efficiency,ng.Thread.run(Thread.java:750). java.net.SocketException: Connection reset; 	at java.net.SocketInputStream.read(SocketInputStream.java:210); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.SSLSocketInputRecord.read(SSLSocketInputRecord.java:464); 	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:237); 	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:109); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:226); 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:104); 	at is.hail.relocated.com.google.cloud.storage.UnbufferedReadableByteChannelSession$UnbufferedReadableByteChannel.read(UnbufferedReadableByteChannelSession.java:36); 	at is.hail.relocated.com.google.cloud.storage.DefaultBufferedReadableByteChannel.read(DefaultBufferedReadableByteChannel.java:106); 	at is.hail.relocated.com.google.cloud.storage.StorageByteC,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:13706,Meter,MeteredStream,13706,https://hail.is,https://github.com/hail-is/hail/issues/12983,2,['Meter'],['MeteredStream']
Energy Efficiency,"ng; the latest changes weekly.; Read in PASS SNVs; Filtering Common Variants; [Stage 0:==================================================>(96600 + 1) / 96601]2018-04-27 20:54:43 Hail: INFO: wrote 11341822 items in 96601 partitions; Pruning LD Variants; [Stage 1:==================================================>(96598 + 3) / 96601]2018-04-27 21:19:04 Hail: INFO: Running LD prune with nSamples=4795, nVariants=11341822, nPartitions=96601, and maxQueueSize=429841.; [Stage 2:=========================================> (79823 + 18) / 96601]java.lang.OutOfMemoryError: Java heap spaceop""; at java.util.Arrays.copyOf(Arrays.java:3181); at java.util.ArrayList.toArray(ArrayList.java:376); at java.util.Collections$SynchronizedCollection.toArray(Collections.java:2024); at java.util.ArrayList.<init>(ArrayList.java:177); at org.apache.spark.util.CollectionAccumulator.value(AccumulatorV2.scala:470); at org.apache.spark.util.CollectionAccumulator.value(AccumulatorV2.scala:444); at org.apache.spark.scheduler.DAGScheduler$$anonfun$updateAccumulators$1.apply(DAGScheduler.scala:1103); at org.apache.spark.scheduler.DAGScheduler$$anonfun$updateAccumulators$1.apply(DAGScheduler.scala:1092); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.updateAccumulators(DAGScheduler.scala:1092); at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1168); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1711); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); [Stage 2:=========================================> (79823 + 18) / 96601]. Used yarn application -kill to kill but driver still ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3463:3451,schedul,scheduler,3451,https://hail.is,https://github.com/hail-is/hail/issues/3463,1,['schedul'],['scheduler']
Energy Efficiency,nnelRead(DefaultChannelPipeline.java:935) at io.nettyectedKey(NioEventLoop.java:645) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580) at io.netty at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) at io.netty.util.concurrent.Default; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1493); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2107); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2114); at org.apache.spark.internal.io.SparkHadoopWriter$.write(SparkHadoopWriter.scala:78); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp(PairRDDFunctions.scala:1096); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFunctions.scala:1094); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply(PairRDDFun,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8106:24563,schedul,scheduler,24563,https://hail.is,https://github.com/hail-is/hail/issues/8106,1,['schedul'],['scheduler']
Energy Efficiency,nnotateVariantsExpr$$anonfun$2$$anonfun$apply$2.apply(AnnotateVariantsExpr.scala:70); at scala.collection.IndexedSeqOptimized$class.foldl(IndexedSeqOptimized.scala:51); at scala.collection.IndexedSeqOptimized$class.foldLeft(IndexedSeqOptimized.scala:60); at scala.collection.mutable.ArrayOps$ofRef.foldLeft(ArrayOps.scala:108); at org.broadinstitute.hail.driver.AnnotateVariantsExpr$$anonfun$2.apply(AnnotateVariantsExpr.scala:70); at org.broadinstitute.hail.driver.AnnotateVariantsExpr$$anonfun$2.apply(AnnotateVariantsExpr.scala:64); at org.broadinstitute.hail.variant.VariantSampleMatrix$$anonfun$25.apply(VariantSampleMatrix.scala:423); at org.broadinstitute.hail.variant.VariantSampleMatrix$$anonfun$25.apply(VariantSampleMatrix.scala:423); at org.broadinstitute.hail.RichPairRDD$$anonfun$mapValuesWithKey$extension$1$$anonfun$apply$5.apply(Utils.scala:459); at org.broadinstitute.hail.RichPairRDD$$anonfun$mapValuesWithKey$extension$1$$anonfun$apply$5.apply(Utils.scala:459); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1555); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1125); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1125); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1850); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1850); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); at org.apache.spark.scheduler.Task.run(Task.scala:88); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); I0824 16:44:07.061986 9121 sched.cpp:1771] Asked to stop the driver; I0824 16:44:07.062144 8743 sched.cpp:1040] Stopping framework '0233fcf9-88ce-407f-8ed5-b015adf9b59c-1932'`,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/660#issuecomment-242218633:11371,schedul,scheduler,11371,https://hail.is,https://github.com/hail-is/hail/issues/660#issuecomment-242218633,2,['schedul'],['scheduler']
Energy Efficiency,non$2.hasNext(OrderedRDD.scala:210); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1763); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1134); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1134); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882:3839,schedul,scheduler,3839,https://hail.is,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882,1,['schedul'],['scheduler']
Energy Efficiency,nonfun$apply$11.apply(TableIR.scala:627); at is.hail.expr.ir.TableMapRows$$anonfun$21$$anonfun$apply$11.apply(TableIR.scala:626); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); at is.hail.rvd.RVD$$anonfun$apply$25$$anon$3.next(RVD.scala:1264); at is.hail.rvd.RVD$$anonfun$apply$25$$anon$3.next(RVD.scala:1258); at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); at scala.collection.Iterator$JoinIterator.next(Iterator.scala:232); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$12$$anonfun$apply$4.apply$mcV$sp(PairRDDFunctions.scala:1138); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$12$$anonfun$apply$4.apply(PairRDDFunctions.scala:1137); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$12$$anonfun$apply$4.apply(PairRDDFunctions.scala:1137); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1371); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$12.apply(PairRDDFunctions.scala:1145); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$12.apply(PairRDDFunctions.scala:1125); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5174:2487,schedul,scheduler,2487,https://hail.is,https://github.com/hail-is/hail/issues/5174,2,['schedul'],['scheduler']
Energy Efficiency,nonfun$cmapPartitionsWithIndex$1$$anonfun$apply$22$$anonfun$apply$23.apply(ContextRDD.scala:310); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$22$$anonfun$apply$23.apply(ContextRDD.scala:310); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.hasNext(OrderedRVD.scala:1014); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.RVD$$anonfun$4$$anon$1.hasNext(RVD.scala:226); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.hasNext(OrderedRVD.scala:1014); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.utils.package$.getIteratorSizeWithMaxN(package.scala:357); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:444); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:444); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:471); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:469); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-f2b0dca9f506; Error summary: AssertionError: assertion failed; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4114:8774,schedul,scheduler,8774,https://hail.is,https://github.com/hail-is/hail/issues/4114,2,['schedul'],['scheduler']
Energy Efficiency,nonfun$collectDArray$5(BackendUtils.scala:86); 	at is.hail.backend.spark.SparkBackendComputeRDD.compute(SparkBackend.scala:910); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2717); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2653); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2652); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2652); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1189); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1189); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1189); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2913); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:8305,schedul,scheduler,8305,https://hail.is,https://github.com/hail-is/hail/issues/14513,1,['schedul'],['scheduler']
Energy Efficiency,"not moved to table there. Same needs to be done for VDS, this isn't too hard); - Add the non-core methods to `hail.methods` / `hail.genetics.methods`; - some stuff here is much harder than the rest, like `filter_alleles`; - This is mostly just labor, but some require more thought than others, like moving TDT to use hail2 expr; - Support intervals in the `index_*` methods. It's possible now to join by locus, but not using the `annotateLociTable` fast path.; - Move to Python 3 so argument order is preserved; - Test the hail2 api much more rigorously than we do now (at the very least, call each parameter branch for each method!; - Typecheck the expression language. This isn't super trivial, and making a nice system to integrate our `typecheck` module and expressions will require some thoughtful design work.; - Some more organization around the package: monkey patching with `import hail.genetics` is an idea I like, but want to think about the edge cases first. ## Documentation; - Document the `index_*` methods / joins; - Translate the _Hail Overview_ tutorial; - Make new tutorials to replace the 2 expr ones we have; - Fill in docs on api2 methods (they're not all there yet); - Fill in docs on expression language (things like __mul__ on NumericExpression haven't been documented); - Write ""integrative docs"" that provide how-tos for common types of workflows. Show the power of annotate / select / group_by/aggregate, etc. ## Longer term QoL:; - Move over tests to Python as much as possible. I looked at the linear regression suite and it can be moved entirely into Python without many problems.; - Write a type parser in Python. The nested calls into the JVM for Type._from_java make the library feel extremely sluggish on teensy data.; - Integrate RV with C/C++, so we can transmit data much more efficiently between Python and Java.; - Rethink the expr language function registry, because many functions there can be implemented in terms of others in Python.; - add back in de novo",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2588#issuecomment-352190554:1650,power,power,1650,https://hail.is,https://github.com/hail-is/hail/pull/2588#issuecomment-352190554,4,"['efficient', 'power']","['efficiently', 'power']"
Energy Efficiency,"notate_cols(prs=hl.agg.sum(mt.beta * mt.dosage)). # write out table with sample IDs and PRS scores; mt.cols().export('gs://ukbb_prs/prs/UKB_'+pheno+'_PRS_22.txt'). parser = argparse.ArgumentParser(); parser.add_argument(""--phenotype"", help=""name of the sumstat phenotype""); args = parser.parse_args(). try:; start = time.time(); main(args.phenotype); end = time.time(); message = ""Success! Job was completed in %s"" % time.strftime(""%H:%M:%S"", time.gmtime(end - start)); send_message(message); except Exception as e:; send_message(""Fail.""); ```. ""Failure Reason"":; ```; Job aborted due to stage failure: Task 98 in stage 13.0 failed 20 times, most recent failure: Lost task 98.19 in stage 13.0 (TID 22699, ccarey-sw-xt4j.c.ukbb-robinson.internal, executor 68): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:815); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:804); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:914); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:908); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scal",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:3245,allocate,allocate,3245,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681,1,['allocate'],['allocate']
Energy Efficiency,"nt call first):; File ""/usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py"", line 217 in _rpc; File ""/usr/local/lib/python3.9/dist-packages/hail/backend/backend.py"", line 212 in table_type; ...; ```. Line 217 only does one thing: call `orjson.dumps`. https://github.com/hail-is/hail/blob/b3df76360f931f54688bb03bf5774643c0b8205e/hail/python/hail/backend/py4j_backend.py#L216-L218. Indeed, `orjson` has had [this issue since 3.9.12](https://github.com/ijl/orjson/issues/452) and we just recently updated orjson from 3.9.10 to 3.9.12:. ```; commit d2615543476bde5d01061499c92f26124b85caf3; Author: Dan King <daniel.zidan.king@gmail.com>; Date: Fri Feb 2 14:21:47 2024 -0500. [dependencies] mass update (#14233). ```; The [relevant part of the diff](https://github.com/hail-is/hail/commit/d2615543476bde5d01061499c92f26124b85caf3#diff-332ea445eb23998f4f4e34a9bb687fa533a063641eb05f791c105a187bf0c19bL101-R101; ):; ```diff; -orjson==3.9.10; +orjson==3.9.12; ```. orjson [reduced the frequency of this segfault in 3.9.13](https://github.com/ijl/orjson/commit/58a8bd3e31aa3b5fd3d962fb5b03479fa0014ee9) by eliding some of the code that caused buffer overheads; however, [the problem persists](https://github.com/ijl/orjson/issues/452#issuecomment-1943053799). I complete fix is currently awaiting [pull request review](https://github.com/ijl/orjson/pull/457). Reports:; - https://hail.zulipchat.com/#narrow/stream/127527-team/topic/seg.20faults.20in.20tests; - https://hail.zulipchat.com/#narrow/stream/123011-Hail-Query-Dev/topic/segfault.20in.20ci.20tests. Batches:; - https://batch.hail.is/batches/8123269/jobs/86; - https://batch.hail.is/batches/8127894/jobs/53. ### Version. 0.2.127. ### Relevant log output. ```shell; [2024-02-08 22:36:47] test/hail/matrixtable/test_file_formats.py::test_backward_compatability_ht[/io/resources/backward_compatability/1.6.0/table/6.ht/] Fatal Python error: Segmentation fault. Thread 0x00007fa51d817640 (most recent call first):; File ""/usr/lib/python3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14299:2272,reduce,reduced,2272,https://hail.is,https://github.com/hail-is/hail/issues/14299,1,['reduce'],['reduced']
Energy Efficiency,"nt.py\"", line 1285, in _send_request\n self.endheaders(body, encode_chunked=encode_chunked)\n File \""/usr/lib/python3.6/http/client.py\"", line 1234, in endheaders\n self._send_output(message_body, encode_chunked=encode_chunked)\n File \""/usr/lib/python3.6/http/client.py\"", line 1026, in _send_output\n self.send(msg)\n File \""/usr/lib/python3.6/http/client.py\"", line 964, in send\n self.connect()\n File \""/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\"", line 181, in connect\n conn = self._new_conn()\n File \""/usr/local/lib/python3.6/dist-packages/urllib3/connection.py\"", line 168, in _new_conn\n self, \""Failed to establish a new connection: %s\"" % e)\nurllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7ff2413b8470>: Failed to establish a new connection: [Errno 113] No route to host\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/requests/adapters.py\"", line 449, in send\n timeout=timeout\n File \""/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py\"", line 638, in urlopen\n _stacktrace=sys.exc_info()[2])\n File \""/usr/local/lib/python3.6/dist-packages/urllib3/util/retry.py\"", line 399, in increment\n raise MaxRetryError(_pool, url, error or ResponseError(cause))\nurllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='10.32.16.16', port=5001): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ff2413b8470>: Failed to establish a new connection: [Errno 113] No route to host',))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1341, in polling_event_loop\n await refresh_k8s_state()\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1332, in refresh_k8s_state\n await refresh_k8s_pods()\n Fil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6754:2488,adapt,adapters,2488,https://hail.is,https://github.com/hail-is/hail/issues/6754,1,['adapt'],['adapters']
Energy Efficiency,ntext$$anonfun$runJob$5.apply(SparkContext.scala:2101); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:121); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:403); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:409); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8545:9531,schedul,scheduler,9531,https://hail.is,https://github.com/hail-is/hail/issues/8545,1,['schedul'],['scheduler']
Energy Efficiency,ntext$$anonfun$runJob$5.apply(SparkContext.scala:2101); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:123); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1892); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1880); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2113); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2062); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2051); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:82358,schedul,scheduler,82358,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['schedul'],['scheduler']
Energy Efficiency,ntextRDD.$anonfun$runJob$2(ContextRDD.scala:366); 	at is.hail.sparkextras.ContextRDD.sparkManagedContext(ContextRDD.scala:164); 	at is.hail.sparkextras.ContextRDD.$anonfun$runJob$1(ContextRDD.scala:365); 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:131); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2254); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2203); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2202); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2202); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2441); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:7964,schedul,scheduler,7964,https://hail.is,https://github.com/hail-is/hail/issues/10682,1,['schedul'],['scheduler']
Energy Efficiency,o.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:742); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.hasNext(OrderedRVD.scala:733); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$11.apply(OrderedRVD.scala:491); 	at is.hail.rvd.OrderedRVD$$anonfun$11.apply(OrderedRVD.scala:490); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	... 1 more; Caused by: htsjdk.tribble.TribbleException: The provided VCF file is malformed at approximately line number 458249: unparsable vcf record with allele M; 	at htsjdk.variant.vcf.AbstractVCFCodec.generateException(AbstractVCFCodec.java:783); 	at htsjdk.variant.vcf.AbstractVCFCodec.checkAllele(AbstractVCFCodec.java:569); 	at htsjdk.variant.vcf.AbstractVCFCodec.parseAlleles(AbstractVCFCodec.java:531); 	at htsjdk.variant.vcf.AbstractVCFCodec.parseVCFLine(AbstractVCFCodec.java:336); 	at htsjdk.variant.vcf.AbstractVCFCodec.decodeLine(AbstractVCFCodec.java:279); 	at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:257); 	at is.hail.io.vcf.LoadVCF$$anonfun$13.apply(LoadVCF.scala:850); 	at is.hail,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3015:7127,schedul,scheduler,7127,https://hail.is,https://github.com/hail-is/hail/issues/3015,1,['schedul'],['scheduler']
Energy Efficiency,o.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:742); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.hasNext(OrderedRVD.scala:733); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$11.apply(OrderedRVD.scala:491); 	at is.hail.rvd.OrderedRVD$$anonfun$11.apply(OrderedRVD.scala:490); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748); Caused by: htsjdk.tribble.TribbleException: The provided VCF file is malformed at approximately line number 458249: unparsable vcf record with allele M; 	at htsjdk.variant.vcf.AbstractVCFCodec.generateException(AbstractVCFCodec.java:783); 	at htsjdk.variant.vcf.AbstractVCFCodec.checkAllele(AbstractVCFCodec.java:569); 	at htsjdk.variant.vcf.AbstractVCFCodec.parseAlleles(AbstractVCFCodec.java:531); 	at htsjdk.variant.vcf.AbstractVCFCodec.parseVCFLine(AbstractVCFCodec.java:336); 	at htsjdk.variant.vcf.AbstractVCFCodec.decodeLine(AbstractVCFCodec.java:279); 	at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:257); 	at is.hail.io.vcf.LoadVCF$$anonfun$13.apply(L,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3015:1448,schedul,scheduler,1448,https://hail.is,https://github.com/hail-is/hail/issues/3015,1,['schedul'],['scheduler']
Energy Efficiency,o.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1921); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7$adapted(LoadVCF.scala:1909); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:515); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at __C678stream_Let.apply(Emit.scala); 	at is.hail.expr.ir.CompileIterator$$anon$2.step(Compile.scala:302); 	at is.hail.expr.ir.CompileIterator$LongIteratorWrapper.hasNext(Compile.scala:155); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2(RVD.scala:1030); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1029); 	at is.hail.sparkextras.ContextRDD.$anonfun$crunJobWithIndex$1(ContextRDD.scala:242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). is.hail.utils.HailException: cannot set missing field for required type +PFloat64; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:18); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:18); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.annotations.RegionValueBuilder.setMissing(RegionValueBuilder.scala:207); 	at is.hail.io.vcf.VCFLine.parseAddInfoArrayDouble(LoadVCF.scala:1034); 	at,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:17987,schedul,scheduler,17987,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['schedul'],['scheduler']
Energy Efficiency,o.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1921); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7$adapted(LoadVCF.scala:1909); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:515); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at __C678stream_Let.apply(Emit.scala); 	at is.hail.expr.ir.CompileIterator$$anon$2.step(Compile.scala:302); 	at is.hail.expr.ir.CompileIterator$LongIteratorWrapper.hasNext(Compile.scala:155); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2(RVD.scala:1030); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1029); 	at is.hail.sparkextras.ContextRDD.$anonfun$crunJobWithIndex$1(ContextRDD.scala:242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829); Caused by: is.hail.utils.HailException: cannot set missing field for required type +PFloat64; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:18); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:18); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.annotations.RegionValueBuilder.setMissing(RegionValueBuilder.scala:207); 	at is.hail.io.vcf.VCFLine.parseAddInfoArrayDouble(LoadVCF.scala,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:8433,schedul,scheduler,8433,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['schedul'],['scheduler']
Energy Efficiency,o.writeObject(Kryo.java:552); 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); 	... 10 more; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126); 	at is.hail.sparkextras.ContextRDD.aggregate(ContextRDD.scala:193); 	at is.hail.sparkextras.ContextRDD.aggregate(ContextRDD.scala:177); 	at is.hail.sparkextras.ContextRDD.fold(ContextRDD.scala:170); 	at is.hail.rvd.RVD$class.aggregateWithPartitionOp(RVD.scala:359); 	at is.hail.rvd.OrderedRVD.aggregateWithPartitionOp(OrderedRVD.scala:31); 	at is.hail.expr.ir.Interpre,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4215:3323,schedul,scheduler,3323,https://hail.is,https://github.com/hail-is/hail/issues/4215,1,['schedul'],['scheduler']
Energy Efficiency,"o/en/stable/the_black_code_style/index.html#stability-policy"">stability policy</a>.</p>; <h3>Highlights</h3>; <ul>; <li><strong>Remove Python 2 support</strong> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2740"">#2740</a>)</li>; <li>Introduce the <code>--preview</code> flag (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2752"">#2752</a>)</li>; </ul>; <h3>Style</h3>; <ul>; <li>Deprecate <code>--experimental-string-processing</code> and move the functionality under; <code>--preview</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2789"">#2789</a>)</li>; <li>For stubs, one blank line between class attributes and methods is now kept if there's; at least one pre-existing blank line (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2736"">#2736</a>)</li>; <li>Black now normalizes string prefix order (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2297"">#2297</a>)</li>; <li>Remove spaces around power operators if both operands are simple (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2726"">#2726</a>)</li>; <li>Work around bug that causes unstable formatting in some cases in the presence of the; magic trailing comma (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2807"">#2807</a>)</li>; <li>Use parentheses for attribute access on decimal float and int literals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2799"">#2799</a>)</li>; <li>Don't add whitespace for attribute access on hexadecimal, binary, octal, and complex; literals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2799"">#2799</a>)</li>; <li>Treat blank lines in stubs the same inside top-level <code>if</code> statements (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2820"">#2820</a>)</li>; <li>Fix unstable formatting with semicolons and arithmetic expressions (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2817"">#281",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11468:8386,power,power,8386,https://hail.is,https://github.com/hail-is/hail/pull/11468,1,['power'],['power']
Energy Efficiency,oMessageDecoder.java:102) at io.netty.channel.AbstractChannelHandlerContext.invokeChalerContext.java:348) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) at org.apacxt.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelt io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359) at io.netty.channel.AbstractChannelHandlerCtractChannelHandlerContext.java:348) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935) at io.nettyectedKey(NioEventLoop.java:645) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580) at io.netty at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) at io.netty.util.concurrent.Default; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1493); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2107); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8106:23947,schedul,scheduler,23947,https://hail.is,https://github.com/hail-is/hail/issues/8106,1,['schedul'],['scheduler']
Energy Efficiency,oOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 2019-01-22 13:12:06 YarnScheduler: INFO: Cancelling stage 0; 2019-01-22 13:12:06 DAGSchedulerEventProcessLoop: ERROR: DAGScheduler failed to cancel all jobs.; java.util.NoSuchElementException: key not found: 70; at scala.collection.MapLike$class.default(MapLike.scala:228); at scala.collection.AbstractMap.default(Map.scala:59); at scala.collection.mutable.HashMap.apply(HashMap.scala:65); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply$mcVJ$sp(TaskSchedulerImpl.scala:243); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply(TaskSchedulerImpl.scala:242); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply(TaskSchedulerImpl.scala:242); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3.apply(TaskSchedulerImpl.scala:242); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3.apply(TaskSchedulerImpl.scala:235); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:235); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.s,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:203419,schedul,scheduler,203419,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['schedul'],['scheduler']
Energy Efficiency,oSerializableSerializer.write(DefaultSerializers.java:503); 	at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:628); 	at com.esotericsoftware.kryo.serializers.MapSerializer.write(MapSerializer.java:106); 	at com.esotericsoftware.kryo.serializers.MapSerializer.write(MapSerializer.java:39); 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552); 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); 	... 10 more; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126); 	at is.hail.sparkextras.Context,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4215:2986,schedul,scheduler,2986,https://hail.is,https://github.com/hail-is/hail/issues/4215,1,['schedul'],['scheduler']
Energy Efficiency,ob$1$$anonfun$apply$34.apply(ContextRDD.scala:458); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1$$anonfun$apply$34.apply(ContextRDD.scala:458); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:458); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:458); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apa,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3516:3473,schedul,scheduler,3473,https://hail.is,https://github.com/hail-is/hail/issues/3516,1,['schedul'],['scheduler']
Energy Efficiency,"objects, thread 10: pool-2-thread-2; 2023-09-24 01:58:19.984 : INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.0M blocks / 1010.0K chunks), regions.size = 19, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-24 01:58:24.240 : INFO: RegionPool: REPORT_THRESHOLD: 4.3M allocated (2.2M blocks / 2.1M chunks), regions.size = 19, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-24 01:58:24.240 GoogleStorageFS$: INFO: createNoCompression: gs://aou_tmp/tmp/hail/icullIwHC8dQXtq8JU2uDW/aggregate_intermediates/-ntpjdAQ9sKaR8lK26cV0p5790a4d87-9035-41ae-afc6-326f710d9a89; 2023-09-24 01:58:24.305 GoogleStorageFS$: INFO: close: gs://aou_tmp/tmp/hail/icullIwHC8dQXtq8JU2uDW/aggregate_intermediates/-ntpjdAQ9sKaR8lK26cV0p5790a4d87-9035-41ae-afc6-326f710d9a89; 2023-09-24 01:58:51.513 : INFO: TaskReport: stage=0, partition=9571, attempt=0, peakBytes=4507648, peakBytesReadable=4.30 MiB, chunks requested=51, cache hits=0; 2023-09-24 01:58:51.513 : INFO: RegionPool: FREE: 4.3M allocated (2.2M blocks / 2.1M chunks), regions.size = 19, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-24 01:58:51.515 JVMEntryway: ERROR: QoB Job threw an exception.; java.lang.reflect.InvocationTargetException: null; 	at sun.reflect.GeneratedMethodAccessor42.invoke(Unknown Source) ~[?:?]; 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_382]; 	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_382]; 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119) ~[jvm-entryway.jar:?]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[?:1.8.0_382]; 	at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[?:1.8.0_382]; 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) ~[?:1.8.0_382]; 	at java.u",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13721:3651,allocate,allocated,3651,https://hail.is,https://github.com/hail-is/hail/issues/13721,1,['allocate'],['allocated']
Energy Efficiency,"ocated (192.0K blocks / 3.4G chunks), regions.size = 3, 0 current java objects, thread 9: pool-1-thread-2; is.hail.utils.HailException: Hail off-heap memory exceeded maximum threshold: limit 2.25 GiB, allocated 3.35 GiB; Report: 3.4G allocated (192.0K blocks / 3.4G chunks), regions.size = 3, 0 current java objects, thread 9: pool-1-thread-2; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:17); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:17); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.annotations.RegionPool.closeAndThrow(RegionPool.scala:58); 	at is.hail.annotations.RegionPool.incrementAllocatedBytes(RegionPool.scala:73); 	at is.hail.annotations.ChunkCache.newChunk(ChunkCache.scala:75); 	at is.hail.annotations.ChunkCache.getChunk(ChunkCache.scala:130); 	at is.hail.annotations.RegionPool.getChunk(RegionPool.scala:96); 	at is.hail.annotations.RegionMemory.allocateBigChunk(RegionMemory.scala:62); 	at is.hail.annotations.RegionMemory.allocate(RegionMemory.scala:96); 	at is.hail.annotations.Region.allocate(Region.scala:332); 	at __C35collect_distributed_array.__m61split_ToArray(Unknown Source); 	at __C35collect_distributed_array.__m54split_StreamFor(Unknown Source); 	at __C35collect_distributed_array.__m49begin_group_0(Unknown Source); 	at __C35collect_distributed_array.apply(Unknown Source); 	at __C35collect_distributed_array.apply(Unknown Source); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$2(BackendUtils.scala:31); 	at is.hail.utils.package$.using(package.scala:638); 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$1(BackendUtils.scala:30); 	at is.hail.backend.service.Worker$.$anonfun$main$13(Worker.scala:142); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:77); 	at is.hail.backend.service.Worker$.main(Worker.scala:142); 	at is.hail.backend.se",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11777#issuecomment-1110147573:1206,allocate,allocate,1206,https://hail.is,https://github.com/hail-is/hail/pull/11777#issuecomment-1110147573,1,['allocate'],['allocate']
Energy Efficiency,"oci`. ```; 2023-09-11 16:22:59.815 : INFO: RegionPool: REPORT_THRESHOLD: 1.0G allocated (662.3M blocks / 363.4M chunks), regions.size = 3, 0 current java objects, thread 24: Thread-3; 2023-09-11 16:23:01.488 : INFO: executing D-Array [table_scan_prefix_sums_singlestage] with 1 tasks, contexts size = 430.00 B, globals size = 2.52 MiB; 2023-09-11 16:23:01.540 : INFO: RegionPool: initialized for thread 115: Executor task launch worker for task 0.0 in stage 37.0 (TID 442); 2023-09-11 16:23:01.567 : INFO: RegionPool: REPORT_THRESHOLD: 2.2M allocated (64.0K blocks / 2.1M chunks), regions.size = 1, 0 current java objects, thread 115: Executor task launch worker for task 0.0 in stage 37.0 (TID 442); 2023-09-11 16:23:01.572 : INFO: RegionPool: REPORT_THRESHOLD: 4.2M allocated (64.0K blocks / 4.1M chunks), regions.size = 1, 0 current java objects, thread 115: Executor task launch worker for task 0.0 in stage 37.0 (TID 442); 2023-09-11 16:23:01.573 : INFO: RegionPool: REPORT_THRESHOLD: 4.3M allocated (64.0K blocks / 4.2M chunks), regions.size = 1, 0 current java objects, thread 115: Executor task launch worker for task 0.0 in stage 37.0 (TID 442); 2023-09-11 16:23:01.573 : INFO: RegionPool: REPORT_THRESHOLD: 4.3M allocated (128.0K blocks / 4.2M chunks), regions.size = 2, 0 current java objects, thread 115: Executor task launch worker for task 0.0 in stage 37.0 (TID 442); 2023-09-11 16:23:01.573 : INFO: RegionPool: REPORT_THRESHOLD: 12.3M allocated (192.0K blocks / 12.1M chunks), regions.size = 3, 0 current java objects, thread 115: Executor task launch worker for task 0.0 in stage 37.0 (TID 442); 2023-09-11 16:23:01.579 : INFO: RegionPool: REPORT_THRESHOLD: 12.4M allocated (192.0K blocks / 12.2M chunks), regions.size = 3, 0 current java objects, thread 115: Executor task launch worker for task 0.0 in stage 37.0 (TID 442); 2023-09-11 16:23:01.582 : INFO: RegionPool: REPORT_THRESHOLD: 35.3M allocated (768.0K blocks / 34.5M chunks), regions.size = 12, 0 current java objects, threa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13606:1176,allocate,allocated,1176,https://hail.is,https://github.com/hail-is/hail/issues/13606,1,['allocate'],['allocated']
Energy Efficiency,"ode>] Adding support for ImageProperties feature to detect dominant colors and image brightness, sharpness, and contrast, inclusion and exclusion filters for labels and label categories, new fields to the API response, &quot;aliases&quot; and &quot;categories&quot;</li>; <li>api-change:<code>securityhub</code>: [<code>botocore</code>] Documentation updates for Security Hub</li>; <li>api-change:<code>ssm-incidents</code>: [<code>botocore</code>] RelatedItems now have an ID field which can be used for referencing them else where. Introducing event references in TimelineEvent API and increasing maximum length of &quot;eventData&quot; to 12K characters.</li>; </ul>; <h1>1.26.7</h1>; <ul>; <li>api-change:<code>autoscaling</code>: [<code>botocore</code>] This release adds a new price capacity optimized allocation strategy for Spot Instances to help customers optimize provisioning of Spot Instances via EC2 Auto Scaling, EC2 Fleet, and Spot Fleet. It allocates Spot Instances based on both spare capacity availability and Spot Instance price.</li>; <li>api-change:<code>ec2</code>: [<code>botocore</code>] This release adds a new price capacity optimized allocation strategy for Spot Instances to help customers optimize provisioning of Spot Instances via EC2 Auto Scaling, EC2 Fleet, and Spot Fleet. It allocates Spot Instances based on both spare capacity availability and Spot Instance price.</li>; <li>api-change:<code>ecs</code>: [<code>botocore</code>] This release adds support for task scale-in protection with updateTaskProtection and getTaskProtection APIs. UpdateTaskProtection API can be used to protect a service managed task from being terminated by scale-in events and getTaskProtection API to get the scale-in protection status of a task.</li>; <li>api-change:<code>es</code>: [<code>botocore</code>] Amazon OpenSearch Service now offers managed VPC endpoints to connect to your Amazon OpenSearch Service VPC-enabled domain in a Virtual Private Cloud (VPC). This feature allows y",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12458:2148,allocate,allocates,2148,https://hail.is,https://github.com/hail-is/hail/pull/12458,2,['allocate'],['allocates']
Energy Efficiency,"of control). For example:. ```; sema = asyncio.Semaphore(50); async with sema:; await copy(sema, ...); ```. Then, to run a set of operations in parallel, subject to the global parallelism bound, use bounded_gather2:. ```; await bounded_gather2(sema, *aws); ```. The naive implementation of bounded_gather2 doesn't work: bounded_gather2 cannot spawn a task for each awaitable and have it try to acquiare the semaphore, because this can lead to deadlock: if 50 tasks launch and wait for children, but none of those children can run because the parents have all the threads of control, the algorithm will deadlock. The key is to make sure at least one child can always be running in a bounded_gather2. But the caller of bounded_gather2 had a reserved thread of execution and it is blocking, so that thread of execution should be transferred to the children while the bounded_gather2 is blocked. This is what bounded_gather2 does. There is also an ""online"" version of bounded_gather2 which lets you schedule an unbounded number of children (potentially generated asynchronously). OnlineBoundedGather2 is used in parallelizing file transfers generated by directory listings, for example, which are enumerated via an async generator, and are potentially very large. I will try to replace bounded_gather and the async worker pool with this mechanism in a future PR. The parameters will likely need additional tuning. I have done some rough timing, and already this is beating gsutil:. - Transfer 10GB spread over 40K files (times in ms):. {'upload': 95803,; 'download': 55240,; 'compare': 54117,; 'clean file': 632,; 'clean gs': 117263,; 'total': 323061}. vs the gsutil transfer:. real	11m14.153s; user	14m28.789s; sys	1m29.090s. and gsutil cleanup (removing 40K files in gs://):. real	10m12.236s; user	3m33.382s; sys	0m55.450s. - Transfer 10GB in one file takes ~20s (up) and ~30s (down) for copy vs ~1m for gsutil. I'm still working on the benchmark harness and will post more complete comparisons in a fut",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9934:2385,schedul,schedule,2385,https://hail.is,https://github.com/hail-is/hail/pull/9934,1,['schedul'],['schedule']
Energy Efficiency,"ogle Monitoring set up to retrieve process-level memory statistics from the driver node that should also work. Just to be clear, I don't anticipate any changes to Hail in the next week that would change the memory use of this pipeline. There could be a memory leak, but I have no clews that lead to it. I realize this is an unsatisfying answer. I'm pretty perplexed as to what could be the issue here. #### technical details. We'll call the second to most recent run Run A and the most recent run Run B. Run A (like all runs before it) only manages two sample groups before failing. Run B made it through 50 groups before failing on 51. Why did they fail? The syslog for Run A is clear: the oomkiller killed Run A. We lack syslogs for Run B, so we cannot be certain but the lack of a JVM stack trace suggests to me that (a) the driver failed and (b) the driver was killed by the system.; Let's focus on the driver machines. In Run A, we used an n1-highmem-8 which is advertised to have 52GiB (53248 MiB). In Run B, we used an n1-highmem-16 which is advertised to have 104GiB (106,496 MiB). hailctl sets the JVM max heap size to 80% of the advertised RAM, so 42598 MiB (see hailctl's --master-memory-fraction). In Run A (the only run for which we have syslogs), based on the driver's syslog, before Spark starts, the system has already allocated 8500 MiB to Linux/Google/Dataproc daemons. Moreover, the actual RAM of the system (as reported by the earlyoom daemon) is 52223 MiB (51 GiB, 1GiB less than Google advertises for n1-highmem-8). Assuming these daemons never release their memory, all our user code must fit in 43723 MiB. Since the JVM's max heap is 42598 MiB, Python (and indeed, anything else on the system) is limited to allocating 1125 MiB. I assume that an n1-highmem-16 uses the same amount of memory for system daemons, so I'd expect just over ten GiB that is used neither by system daemons nor the JVM. Assuming that's right, I can't explain why the oomkiller killed the JVM in Run B.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449:2477,allocate,allocated,2477,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832666449,2,['allocate'],['allocated']
Energy Efficiency,"oint number (precision; unclear) between 0 and 1. 4. Metadata is optionally added to the records. The metadata captures information about the source; and destination VM such as project id, VM name, zone, region, GKE pod, GKE service, and geographic; information of external parties. The user may elect to receive all metadata, no metadata, or a; specific set of metadata fields. 5. The records are written to Google Cloud Logging. The pricing of VPC Flow Logs is described at the [network pricing page](https://cloud.google.com/vpc/network-pricing#network-telemetry). Notice that, if logs are only sent to Cloud Logging (not to BigQuery, Pub/Sub, or Cloud Storage):. > If you store your logs in Cloud Logging, logs generation charges are waived, and only Logging charges apply. I believe in this phrase ""logs generation charges"" refers to *VPC Flow logs* generation charges. The Google Cloud Logging [pricing page](https://cloud.google.com/stackdriver/pricing#google-clouds-operations-suite-pricing) indicates that, after 50 GiB of free logs, the user is charged 0.50 USD per GiB of logs. Storage is free for thirty days and 0.01 USD per GiB for each additional day. We can calculate the cost of our logs as follows. Refer to the [definition of the record format](https://cloud.google.com/vpc/docs/flow-logs#record_format) for details. ```python3; ip_string = len(""123.123.123.123""); ip_connection = 4 + ip_string + ip_string + 4 + 4; date_time = len(""1937-01-01T12:00:27.87+00:20""); record_bytes = sum((; ip_connection,; max(len('SRC'), len('DEST')),; 8,; 8,; 8,; date_time,; date_time,; )); assert record_bytes == 126. hours_per_month = 24 * 60; seconds_per_hour = 60 * 60. seconds_per_interval = 15 * 60; vms = 10000; sampling_rate = 0.5; connections_per_vm_per_aggregation_interval = 100. intervals_per_hour = seconds_per_hour / seconds_per_interval; records_per_hour = intervals_per_hour * vms * connections_per_vm_per_aggregation_interval * sampling_rate; bytes_per_hour = records_per_hour * rec",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12883:2142,charge,charged,2142,https://hail.is,https://github.com/hail-is/hail/pull/12883,1,['charge'],['charged']
Energy Efficiency,oke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:926); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:908); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.utils.package$.getIteratorSizeWithMaxN(package.scala:349); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:433); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:433); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1$$anonfun$apply$34.apply(ContextRDD.scala:458); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1$$anonfun$apply$34.apply(ContextRDD.scala:458); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:458); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:458); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Hail version: devel-9a5678f; Error summary: AssertionError: assertion failed; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3516:7412,schedul,scheduler,7412,https://hail.is,https://github.com/hail-is/hail/issues/3516,2,['schedul'],['scheduler']
Energy Efficiency,okeChalerContext.java:348) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) at org.apacxt.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelt io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359) at io.netty.channel.AbstractChannelHandlerCtractChannelHandlerContext.java:348) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935) at io.nettyectedKey(NioEventLoop.java:645) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580) at io.netty at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) at io.netty.util.concurrent.Default; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1493); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2107); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); at org.apac,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8106:24045,schedul,scheduler,24045,https://hail.is,https://github.com/hail-is/hail/issues/8106,1,['schedul'],['scheduler']
Energy Efficiency,"ol one except the resource being allocated is n_ready_jobs compared to total_jobs rather than ready_cores_mcpu. ; - The instance creation loop needs to extract the machine_type, storage_gib, and preemptible from the spec without hitting GCS. Therefore, it is stored in the ""spec"" field in the database which required changing the batch format version a bit.; - We avoid double scheduling by requiring that there are no live instances assigned to attempts for that job before creating an instance.; - We mark a job as creating after creating the instance for the new attempt; - The number of instances that can be created is similar to the pool control loop. The total number of instances we can create is fed to the fair share allocator.; - I added an asyncio.wait(15) at the end of the instance creation loop body to make sure we didn't run past our GCE limits.; - The scheduling loop iterates over all attempts with active instances in order of time of activation (no user fair share here -- FIFO); - There is no possibility of double scheduling because there must only be one active instance per job based on the create instances loop. **Canceller:**; - There's a new canceller loop that looks for jobs that need to be cancelled in the creating state. It marks these jobs as complete ""cancelled"" in the database and then calls GCE to delete the instance. **Mark Job Complete:**; - I modified this function to kill a job private instance if the job is marked as complete and the instance is active. **Worker:**; - I added a kill function; - Note: I did not change how storage is computed. For job private instances, it's possible to be billed for 10Gi but only get 5 Gi if you requested 5 Gi in the XFS quotas. I decided that thinking through the storage here can be delayed until the storage PR since no one is going to be using this functionality yet. **Testing:**; - I added three new job private instance tests: preemptible, non preemptible, preemptible with cancellation in the creating state;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9972:3306,schedul,scheduling,3306,https://hail.is,https://github.com/hail-is/hail/pull/9972,2,['schedul'],['scheduling']
Energy Efficiency,ollection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apa,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3901:6935,schedul,scheduler,6935,https://hail.is,https://github.com/hail-is/hail/issues/3901,2,['schedul'],['scheduler']
Energy Efficiency,ollection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apa,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3465:8561,schedul,scheduler,8561,https://hail.is,https://github.com/hail-is/hail/issues/3465,5,['schedul'],['scheduler']
Energy Efficiency,ollection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apa,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:4042,schedul,scheduler,4042,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410,2,['schedul'],['scheduler']
Energy Efficiency,"om the exception chain in; 447 # Python 3 (including for exceptions like SystemExit).; 448 # Otherwise it looks like a bug in the code. File /opt/conda/lib/python3.10/http/client.py:1375, in HTTPConnection.getresponse(self); 1374 try:; -> 1375 response.begin(); 1376 except ConnectionError:. File /opt/conda/lib/python3.10/http/client.py:318, in HTTPResponse.begin(self); 317 while True:; --> 318 version, status, reason = self._read_status(); 319 if status != CONTINUE:. File /opt/conda/lib/python3.10/http/client.py:287, in HTTPResponse._read_status(self); 284 if not line:; 285 # Presumably, the server closed the connection before; 286 # sending a valid response.; --> 287 raise RemoteDisconnected(""Remote end closed connection without""; 288 "" response""); 289 try:. RemoteDisconnected: Remote end closed connection without response. During handling of the above exception, another exception occurred:. ProtocolError Traceback (most recent call last); File /opt/conda/lib/python3.10/site-packages/requests/adapters.py:487, in HTTPAdapter.send(self, request, stream, timeout, verify, cert, proxies); 486 try:; --> 487 resp = conn.urlopen(; 488 method=request.method,; 489 url=url,; 490 body=request.body,; 491 headers=request.headers,; 492 redirect=False,; 493 assert_same_host=False,; 494 preload_content=False,; 495 decode_content=False,; 496 retries=self.max_retries,; 497 timeout=timeout,; 498 chunked=chunked,; 499 ); 501 except (ProtocolError, OSError) as err:. File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:787, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw); 785 e = ProtocolError(""Connection aborted."", e); --> 787 retries = retries.increment(; 788 method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]; 789 ); 790 retries.sleep(). File /opt/conda/lib/python3.10/site-packages/urllib3/util/retry.py:550, in Retry.increment(self, m",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960:6273,adapt,adapters,6273,https://hail.is,https://github.com/hail-is/hail/issues/13960,1,['adapt'],['adapters']
Energy Efficiency,"om/danielduhh""><code>@​danielduhh</code></a>) (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/133"">#133</a> <a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/134"">#134</a>)</li>; </ul>; <p>Version 0.8.0 (released 2019-03-17)</p>; <ul>; <li>Respect <code>dot_notation</code> flag in ignore argument (<a href=""https://github.com/yoyonel""><code>@​yoyonel</code></a>) (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/107"">#107</a>)</li>; <li>Adds argument for toggling dot notation in diff. (<a href=""https://github.com/robinchew""><code>@​robinchew</code></a>)</li>; </ul>; <p>Version 0.7.2 (released 2019-02-22)</p>; <ul>; <li>Two NaN values are considered the same, hence they are not shown in <code>diff</code>; output. (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/114"">#114</a>) (<a href=""https://github.com/t-b""><code>@​t-b</code></a>)</li>; <li>Refactors <code>diff</code> method to reduce recursive call stack size. (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/112"">#112</a>); (<a href=""https://github.com/yoyonel""><code>@​yoyonel</code></a>)</li>; <li>Python porting best practice use feature detection instead; of version detection to save an import and pass both PyLint; and Flake8 tests with neither 'pragma' nor 'noqa'. (<a href=""https://github.com/cclauss""><code>@​cclauss</code></a>)</li>; </ul>; <p>Version 0.7.1 (released 2018-05-04)</p>; <ul>; <li>Resolves issue with keys containing dots. (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/101"">#101</a>)</li>; </ul>; <p>Version 0.7.0 (released 2017-10-16)</p>; <ul>; <li>Fixes problem with diff results that reference the original structure by; introduction of <code>deepcopy</code> for all possibly unhashable items. Thus the diff; does not change later when the diffed structures change.</li>; <li>Adds new option for patchi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11485:3967,reduce,reduce,3967,https://hail.is,https://github.com/hail-is/hail/pull/11485,1,['reduce'],['reduce']
Energy Efficiency,ommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.base/java.lang.Thread.run(Thread.java:834). is.hail.utils.HailException: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:17); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:17); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.variant.ReferenceGenome.checkLocus(ReferenceGenome.scala:210); 	at is.hail.variant.Locus$.apply(Locus.scala:18); 	at is.hail.variant.Locus$.annotation(Locus.scala:24); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$3(LoadPlink.scala:43); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$3$adapted(LoadPlink.scala:37); 	at is.hail.utils.WithContext.foreach(Context.scala:49); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2(LoadPlink.scala:37); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2$adapted(LoadPlink.scala:36); 	at scala.collection.Iterator.foreach(Iterator.scala:941); 	at scala.collection.Iterator.foreach$(Iterator.scala:941); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1(LoadPlink.scala:36); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1$adapted(LoadPlink.scala:35); 	at is.hail.io.fs.FS.$anonfun$readLines$1(FS.scala:222); 	at is.hail.utils.package$.using(package.scala:640); 	at is.hail.io.fs.FS.readLines(FS.scala:213); 	at is.hail.io.fs.FS.readLines$(FS.scala:211); 	at is.hail.io.fs.HadoopFS.readLines(HadoopFS.scala:72); 	at is.hail.io.plink.LoadPlink$.parseBim(LoadPlink.scala:35); 	at is.hail.io.plink.MatrixPLINKReader$.fromJValue(LoadPlink.scala:179); 	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:88); 	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1720); 	at is.hail.expr.ir.IRParser$.$anonfun$matrix_ir$1(Parser.scala:1646); 	at is.hail.utils.StackSafe$More.advan,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11836:5814,adapt,adapted,5814,https://hail.is,https://github.com/hail-is/hail/issues/11836,1,['adapt'],['adapted']
Energy Efficiency,ompute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:332); 	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:330); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:935); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:926); 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:866); 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:926); 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:670); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:281); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spa,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:8083,schedul,scheduler,8083,https://hail.is,https://github.com/hail-is/hail/issues/3760,1,['schedul'],['scheduler']
Energy Efficiency,on pod not container. Scheduling will be a bit messed up until this goes in (I had deployed to hopefully speed up the testing).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7326:22,Schedul,Scheduling,22,https://hail.is,https://github.com/hail-is/hail/pull/7326,1,['Schedul'],['Scheduling']
Energy Efficiency,on.Iterator$$anon$13.hasNext(Iterator.scala:415); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:369); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1626); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1099); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1099); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1767); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1767); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:63); at org.apache.spark.scheduler.Task.run(Task.scala:70); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1273); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1264); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1263); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1263); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:730); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:730); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1457); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/120:4345,schedul,scheduler,4345,https://hail.is,https://github.com/hail-is/hail/issues/120,1,['schedul'],['scheduler']
Energy Efficiency,"onda3/lib/python3.10/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 63 tpl = Env.jutils().handleForPython(e.java_exception); 64 deepest, full, error_id = tpl._1(), tpl._2(), tpl._3(); ---> 65 raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; 66 except pyspark.sql.utils.CapturedException as e:; 67 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: HailException: Chain file 'grch37_to_grch38.over.chain.gz' does not exist. Java stack trace:; is.hail.utils.HailException: Chain file 'grch37_to_grch38.over.chain.gz' does not exist.; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:18); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:18); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.variant.ReferenceGenome.addLiftover(ReferenceGenome.scala:407); 	at is.hail.backend.spark.SparkBackend.$anonfun$pyAddLiftover$2(SparkBackend.scala:613); 	at is.hail.backend.spark.SparkBackend.$anonfun$pyAddLiftover$2$adapted(SparkBackend.scala:612); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:76); 	at is.hail.utils.package$.using(package.scala:657); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:76); 	at is.hail.utils.package$.using(package.scala:657); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:62); 	at is.hail.backend.spark.SparkBackend.$anonfun$withExecuteContext$1(SparkBackend.scala:347); 	at is.hail.backend.spark.SparkBackend.$anonfun$pyAddLiftover$1(SparkBackend.scala:612); 	at is.hail.backend.spark.SparkBackend.$anonfun$pyAddLiftover$1$adapted(SparkBackend.scala:611); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59); 	at is.hail.backend.spark.SparkBackend.pyAddLiftover(SparkBackend.scala:611); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13993:3808,adapt,adapted,3808,https://hail.is,https://github.com/hail-is/hail/issues/13993,1,['adapt'],['adapted']
Energy Efficiency,onfun$cmapPartitionsWithIndex$1$$anonfun$apply$27.apply(ContextRDD.scala:355); at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$27.apply(ContextRDD.scala:355); at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5.apply(ContextRDD.scala:135); at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5.apply(ContextRDD.scala:135); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.s,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4755#issuecomment-438447635:5023,schedul,scheduler,5023,https://hail.is,https://github.com/hail-is/hail/issues/4755#issuecomment-438447635,1,['schedul'],['scheduler']
Energy Efficiency,onfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3901:7172,schedul,scheduler,7172,https://hail.is,https://github.com/hail-is/hail/issues/3901,2,['schedul'],['scheduler']
Energy Efficiency,onfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3465:8798,schedul,scheduler,8798,https://hail.is,https://github.com/hail-is/hail/issues/3465,5,['schedul'],['scheduler']
Energy Efficiency,onfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:4279,schedul,scheduler,4279,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410,2,['schedul'],['scheduler']
Energy Efficiency,onfun$getKeyInfo$2(RVD.scala:1234); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1233); 	at is.hail.sparkextras.ContextRDD.$anonfun$crunJobWithIndex$1(ContextRDD.scala:242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:131); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:498); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:501); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1124); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2491); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2433); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSched,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12532:5924,schedul,scheduler,5924,https://hail.is,https://github.com/hail-is/hail/issues/12532,1,['schedul'],['scheduler']
Energy Efficiency,onfun$runJob$5.apply(SparkContext.scala:1899); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkConte,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882:4290,schedul,scheduler,4290,https://hail.is,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882,1,['schedul'],['scheduler']
Energy Efficiency,ontainerregistry/client/__pycache__/docker_creds_.cpython-39.pyc; /usr/lib/google-cloud-sdk/lib/third_party/containerregistry/client/__pycache__/docker_name_.cpython-39.pyc; /usr/lib/google-cloud-sdk/lib/third_party/containerregistry/tools/docker_puller_.py; /usr/lib/google-cloud-sdk/lib/third_party/containerregistry/tools/docker_pusher_.py; /usr/lib/google-cloud-sdk/lib/third_party/containerregistry/tools/docker_appender_.py; /usr/lib/google-cloud-sdk/lib/third_party/containerregistry/tools/__pycache__/docker_appender_.cpython-39.pyc; /usr/lib/google-cloud-sdk/lib/third_party/containerregistry/tools/__pycache__/docker_puller_.cpython-39.pyc; /usr/lib/google-cloud-sdk/lib/third_party/containerregistry/tools/__pycache__/docker_pusher_.cpython-39.pyc; /usr/local/share/google/dataproc/npd-config/docker-monitor-counter.json; /usr/local/share/google/dataproc/npd-config/docker-monitor.json; /usr/local/share/google/dataproc/npd-config/health-checker-docker.json; /usr/local/share/google/dataproc/npd-config/docker-monitor-filelog.json; /usr/local/share/google/dataproc/bdutil/fluentd/container_logging/plugin/test/Dockerfile; /usr/local/share/google/dataproc/bdutil/components/initialize/docker-ce.sh; /usr/local/share/google/dataproc/bdutil/components/install/docker-ce.sh; /usr/local/share/google/dataproc/bdutil/components/uninstall/docker-ce.sh; /usr/local/share/google/dataproc/bdutil/components/post-install/docker-ce.sh; /usr/local/share/google/dataproc/bdutil/components/activate/docker-ce.sh; /usr/local/share/google/dataproc/bdutil/components/shared/docker.sh; /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/docker-ce.sh; /usr/local/share/google/dataproc/bdutil/configure_docker.sh; /run/docker.sock; /tmp/dataproc/uninstall/docker-ce; /tmp/dataproc/components/uninstall/docker-ce.running; /tmp/dataproc/components/uninstall/docker-ce.done; /tmp/dataproc/components/pre-uninstall/docker-ce.running; /tmp/dataproc/components/pre-uninstall/docker-ce.done; /etc/apt/pre,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12936#issuecomment-1709120751:11867,monitor,monitor-filelog,11867,https://hail.is,https://github.com/hail-is/hail/issues/12936#issuecomment-1709120751,1,['monitor'],['monitor-filelog']
Energy Efficiency,"ook so we can avoid a rename. > The landing page should be password protected. We should think about whether; > we want to collect additional information there (e.g. email), although for now; > I don't think we need to, as everyone who signed up for the next tutorial; > filled out a questionnaire. For the tutorial, I'll just put a password. I think for Stanley Center stuff we; should use GCP auth. > I'm getting proxy timeouts. We need an ready endpoint and something on the; > client side to poll and redirect. Actually, awesome if it doesn't poll but; > uses, say, websockets, and the server watches the pod for a notification for; > k8s (or does this and also polls, which seems to be our standard pattern). The proxy timeouts might be because I shut the whole thing down? But yeah, I; also saw timeouts if a pod can't be scheduled right away. > Should we have an auto-scaling non-preemptible pool and schedule these there?. We already have such a pool, and these pods do not tolerate the preemptible; taint, so they are forced to get scheduled on non-preemptibles. > If we do that, to optimize startup time, we should have imagePullPolicy: Never; > and then pull the image on startup and push it on update. I think `imagePullPolicy: Never` is a bad idea. If there's a bug where the image; is not present, then we get stuck. I think we should rely on k8s to pull the 5GB; jupyter image in a reasonable time period. If we cannot rely on that, we just; start up N nodes before the tutorial, ssh to each and pull the image. If; somehow the image disappears, `imagePullPolicy: IfNotPresent` ensures we just; experience a delay rather than complete interruption. > When do you reap jupyter pods? jupyterhub has a simple management console that; > lets you shut down notebooks. I just run `make clean-jobs`, but we could add a delete endpoint and a little; web page. > I don't think you can do this dynamically using headers. Blueprints seem to be; > the answer in Flask:; > https://stackoverflow.com/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4576#issuecomment-431185878:1504,schedul,scheduled,1504,https://hail.is,https://github.com/hail-is/hail/pull/4576#issuecomment-431185878,2,['schedul'],['scheduled']
Energy Efficiency,oolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745)java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.methods.VEP$$anonfun$16$$anon$1.hasNext(VEP.scala:398); 	at is.hail.sparkextras.OrderedRDD$$anonfun$apply$7$$anon$2.hasNext(OrderedRDD.scala:211); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer$$anonfun$writeRows$1.apply$mcV$sp(WriterContainer.scala:253); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer$$anonfun$writeRows$1.apply(WriterContainer.scala:252); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer$$anonfun$writeRows$1.apply(WriterContainer.scala:252); 	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1348); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer.writeRows(WriterContainer.scala:258); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Hail version: 0.1-1908254; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1822:12412,schedul,scheduler,12412,https://hail.is,https://github.com/hail-is/hail/issues/1822,2,['schedul'],['scheduler']
Energy Efficiency,or$$anon$11.next(Iterator.scala:328); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1555); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1125); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1125); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1850); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1850); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); at org.apache.spark.scheduler.Task.run(Task.scala:88); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1283); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1270); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1270); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:697); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:697); at scala.Option.foreach(Option.scala:236); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:697); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1496); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1458); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/660#issuecomment-242218633:6055,schedul,scheduler,6055,https://hail.is,https://github.com/hail-is/hail/issues/660#issuecomment-242218633,1,['schedul'],['scheduler']
Energy Efficiency,"or: INFO: Stopped Spark@1433e9ec{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2019-01-22 13:12:06 SparkUI: INFO: Stopped Spark web UI at http://10.48.225.55:4040; 2019-01-22 13:12:06 DAGScheduler: INFO: Job 0 failed: fold at RVD.scala:603, took 14.445174 s; 2019-01-22 13:12:06 DAGScheduler: INFO: ResultStage 0 (fold at RVD.scala:603) failed in 14.237 s due to Stage cancelled because SparkContext was shut down; 2019-01-22 13:12:06 root: ERROR: SparkException: Job 0 cancelled because SparkContext was shut down; From org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down; at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:820); at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:818); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:818); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:1750); at org.apache.spark.util.EventLoop.stop(EventLoop.scala:83); at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:1669); at org.apache.spark.SparkContext$$anonfun$stop$8.apply$mcV$sp(SparkContext.scala:1928); at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317); at org.apache.spark.SparkContext.stop(SparkContext.scala:1927); at org.apache.spark.SparkContext$$anon$3.run(SparkContext.scala:1872); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126); at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1089); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); at org.apa",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:206982,schedul,scheduler,206982,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['schedul'],['scheduler']
Energy Efficiency,"orAddress: Code[Long], targetAddress: Code[Long], nRows: Code[Long], nCols: Code[Long], mb: MethodBuilder): Code[Unit]; ```. - Interconvert between column and row major. ```scala; def construct(flags: Code[Int], offset: Code[Int], shapeBuilder: (StagedRegionValueBuilder => Code[Unit]),; stridesBuilder: (StagedRegionValueBuilder => Code[Unit]), data: Code[Long], mb: MethodBuilder): Code[Long]; }; ```. - Construct the NDArray off-heap. ```scala; def arrayFundamentalType: PArray; ```. - The underlying array representation. ## <a name=""parray""></a> PCanonicalNDArray. A PCanonicalArray-backed NDArray. # <a name=""ptuple"">PTuple</a>. An immutible, collection of ordered values, whose elements may be of different types. ## Core methods. ```scala; val _types: IndexedSeq[PTupleField]; ```. - The ordered representation of physical types that represent this collection. ```scala; def allocate(region: Region): Long; def allocate(region: Code[Region]): Code[Long]; ```. - Allocate enough memory off-heap to store the requested elements. ```scala; def initialize(address: Long, setMissing: Boolean = false): Unit; def stagedInitialize(address: Code[Long], setMissing: Boolean = false): Code[Unit]; ```; - Set element missingness and store element length. ```scala; def isFieldDefined(address: Long, fieldIdx: Int): Boolean; def isFieldDefined(address: Code[Long], fieldIdx: Code[Int]): Boolean; ```. ```scala; def setFieldMissing(address: Long, fieldIdx: Int): Unit; def setFieldMissing(address: Code[Long], fieldIdx: Int): Code[Unit]. def setFieldPresent(address: Long, fieldIdx: Int): Unit; def setFieldPresent(address: Code[Long], fieldIdx: Int): Code[Unit]; }; ```; - Set field present of missing at a given memory address. ```scala; def loadField(address: Long, fieldIdx: Int): Long; def loadField(address: Code[Long], fieldIdx: Int): Code[Long]; ```; - Load field at a given memory address. ```scala; def storeField(address: Long, fieldIdx: Int): Long; def storeField(address: Code[Long], fieldIdx:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7988:8542,Allocate,Allocate,8542,https://hail.is,https://github.com/hail-is/hail/issues/7988,1,['Allocate'],['Allocate']
Energy Efficiency,"ord. I think for Stanley Center stuff we should use GCP auth. Yes. I'm imagining we'll have a tutorial service for intermittent tutorials and a jupyter/Hail service, both, although maybe eventually the latter can be used for both?. > But yeah, I also saw timeouts if a pod can't be scheduled right away. I definitely saw this case (e.g. I refreshed and then got the notebook). > I think imagePullPolicy: Never is a bad idea. Agreed, too aggressive. > I think we should rely on k8s to pull the 5GB jupyter image in a reasonable time period. No. I'm going to be demanding about making our tools responsive with good feedback (not responsive in the sense of responsive web design, but responsive in the sense of fast). It has to be fast, and when can't be, it has to give clear feedback about what it's doing and how long it will take. We routinely see pulling a 5GB image take 1-2m. That's spin up a VM level nonsense. Kubernetes 1.6 had an SLO to schedule 99% of pre-pulled containers within 5s on a 5K node cluster (from the plots it looks like they were closer to 2s):. > Pod startup time: 99% of pods and their containers (with pre-pulled images) start within 5s. from http://webcache.googleusercontent.com/search?q=cache:Soglxt0kAI0J:blog.kubernetes.io/2017/03/scalability-updates-in-kubernetes-1.6.html+&cd=1&hl=en&ct=clnk&gl=us. When we have to pull an image, I want spinner and the estimated spin time. If we have to spin up a node, same. (I know this is a first cut. I'm just saying where I'd like to see us head.). > I just run make clean-jobs, but we could add a delete endpoint and a little web page. OK, here's my picture:; - first time, prompt for password,; - if no notebook is running launch one and go straight there,; - if notebook is running, get a page with a link to the notebook and a link to kill it. That might be considered strange web design (skip the console depending on the state), in which case I'd vote for the console always. (What Jupyter hub does.). > I thought it wou",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4576#issuecomment-431248659:987,schedul,schedule,987,https://hail.is,https://github.com/hail-is/hail/pull/4576#issuecomment-431248659,2,['schedul'],['schedule']
Energy Efficiency,"ored failure: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@115b6ba4 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@3f21bf73[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]; 2019-01-22 13:12:06 YarnSchedulerBackend$YarnSchedulerEndpoint: ERROR: Error requesting driver to remove executor 14 after disconnection.; org.apache.spark.rpc.RpcEnvStoppedException: RpcEnv already stopped.; at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:155); at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:132); at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:228); at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:515); at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:63); at org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint$$anonfun$org$apache$spark$scheduler$cluster$YarnSchedulerBackend$$handleExecutorDisconnectedFromDriver$2.apply(YarnSchedulerBackend.scala:253); at org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint$$anonfun$org$apache$spark$scheduler$cluster$YarnSchedulerBackend$$handleExecutorDisconnectedFromDriver$2.apply(YarnSchedulerBackend.scala:252); at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:253); at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293); at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136); at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40); at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248); at scala.concurrent.Promise$class.complete(Promise.scala:55); at scala.concurrent.impl",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:214872,schedul,scheduler,214872,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['schedul'],['scheduler']
Energy Efficiency,org.apache.hadoop.hdfs.DFSOutputStream.createSocketForPipeline(DFSOutputStream.java:1531); at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.createBlockOutputStream(DFSOutputStream.java:1309); at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1262); at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:448). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101); at org.apache.spark.SparkContext.runJob(SparkContext.sca,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293:9671,schedul,scheduler,9671,https://hail.is,https://github.com/hail-is/hail/issues/9293,1,['schedul'],['scheduler']
Energy Efficiency,org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3235:5806,schedul,scheduler,5806,https://hail.is,https://github.com/hail-is/hail/issues/3235,1,['schedul'],['scheduler']
Energy Efficiency,org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3413:3502,schedul,scheduler,3502,https://hail.is,https://github.com/hail-is/hail/issues/3413,1,['schedul'],['scheduler']
Energy Efficiency,org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3040:7014,schedul,scheduler,7014,https://hail.is,https://github.com/hail-is/hail/issues/3040,1,['schedul'],['scheduler']
Energy Efficiency,org.broadinstitute.hail.methods.FilterVariantCondition.apply(Filter.scala:613); at org.broadinstitute.hail.driver.FilterVariants$$anonfun$2.apply(FilterVariants.scala:45); at org.broadinstitute.hail.driver.FilterVariants$$anonfun$2.apply(FilterVariants.scala:45); at org.broadinstitute.hail.variant.VariantSampleMatrix$$anonfun$5.apply(VariantSampleMatrix.scala:151); at org.broadinstitute.hail.variant.VariantSampleMatrix$$anonfun$5.apply(VariantSampleMatrix.scala:151); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:415); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:369); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1626); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1099); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1099); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1767); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1767); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:63); at org.apache.spark.scheduler.Task.run(Task.scala:70); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1273); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1264); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1263); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1263); at org.apache.spark.scheduler,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/120:3875,schedul,scheduler,3875,https://hail.is,https://github.com/hail-is/hail/issues/120,1,['schedul'],['scheduler']
Energy Efficiency,org.elasticsearch.hadoop.util.EsMajorVersion.parse(EsMajorVersion.java:79); 	at org.elasticsearch.hadoop.rest.RestClient.remoteEsVersion(RestClient.java:613); 	at org.elasticsearch.hadoop.rest.InitializationUtils.discoverEsVersion(InitializationUtils.java:240); 	... 10 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1906); 	at org.elasticsearch.spark.rdd.EsSpark$.doSaveToEs(EsSpark.scala:102); 	at org.elasticsearch.spark.rdd.EsSpark$.saveToEs(EsSpark.scala:76); 	at org.el,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4138:3811,schedul,scheduler,3811,https://hail.is,https://github.com/hail-is/hail/issues/4138,1,['schedul'],['scheduler']
Energy Efficiency,"orker image (with one retry) before trying to run it.; - Batch and Job are gone. database.py is effectively gone. Almost everywhere interacts directly with the database using the simple gear.Database interface, and drops down to aiomysql directly when that is insufficient (e.g. transaction with multiple executemany for /jobs/create). When we pass around data representing a job or batch, it's normally a data record (a dict).; - Added the running log test from your PR.; - The job status is no longer written to a file, just in the database jobs.status.; - I moved the INSTANCE_ID to the database. There is now a table called tokens. It has the instance id and a token for securing communication between the front end and the driver (currently unused).; - Operations that need to be atomic in the database are now implemented as stored procedures which can be called with the check_call_procedure helper in database.py. They return a row with a field rc (return code) that is 0 on success and non-zero on failure.; - Renamed Driver => Scheduler. Scheduler has two threads, one that schedules jobs that are in the Ready state, and one that cancels cancelled jobs in the Running state. There is a new job state Ready. A job is Ready if its parents are complete and it is not scheduled (instance_id is null). A job is Running if it is scheduled (instance_id is not null).; - The full set of instances are mirrored in memory as Instance objects.; - Added a ready_cores table with a single row that has the total core count of the ready jobs. It is updated by the stored procedures as jobs are scheduled/unscheduled/marked complete. It is used by the instance pool control loop. This is great, and something we couldn't easily see before. Things that got removed that I will add back in the next PRs:; - Database retries; - Instance pool heal loop; - Instance health; - attempt tokens (from the Google backend). These are all pretty easy. Then back to scale tests. Let me know if you have any questions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7420:1628,Schedul,Scheduler,1628,https://hail.is,https://github.com/hail-is/hail/pull/7420,6,"['Schedul', 'schedul']","['Scheduler', 'scheduled', 'schedules']"
Energy Efficiency,"orker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,598	job.py	schedule_job:443	schedule job (97, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,656	job.py	schedule_job:443	schedule job (99, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,662	job.py	schedule_job:443	schedule job (100, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,663	job.py	schedule_job:443	schedule job (98, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:32,455	job.py	schedule_job:443	schedule job (101, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:32,455	job.py	schedule_job:443	schedule job (102, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:33,456	hail_logging.py	log:40	https POST /pr-11438-default-g6cibyji6520/batch-driver/api/v1alpha/instances/activate done in 3.2369999999998527s: 200; ERROR	2022-03-02 19:06:33,492	job.py	schedule_job:473	error while scheduling job (95, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n time",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:2639,schedul,schedule,2639,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['schedul'],['schedule']
Energy Efficiency,"ormation: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjMjFkYTE5Ny1lMDgzLTRiNzEtODc1Yi0xZmY0MjNhZWZmOWEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImMyMWRhMTk3LWUwODMtNGI3MS04NzViLTFmZjQyM2FlZmY5YSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""c21da197-e083-4b71-875b-1ff423aeff9a"",""prPublicId"":""c21da197-e083-4b71-875b-1ff423aeff9a"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.7"",""to"":""42.0.2""}],""packageManager"":""pip"",""projectPublicId"":""701495b8-b53d-48af-82fe-1a6c57aa56cb"",""projectUrl"":""https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-6149518"",""SNYK-PYTHON-CRYPTOGRAPHY-6157248"",""SNYK-PYTHON-CRYPTOGRAPHY-6210214""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[509,581,451],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Use of a Broken or Risky Cryptographic Algorithm](https://learn.snyk.io/lesson/insecure-hash/?loc&#x3D;fix-pr); 🦉 [Uncontrolled Resource Consumption (&#x27;Resource Exhaustion&#x27;)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr); 🦉 [NULL Pointer Dereference](https://learn.snyk.io/lesson/null-dereference/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14236:4262,Consumption,Consumption,4262,https://hail.is,https://github.com/hail-is/hail/pull/14236,1,['Consumption'],['Consumption']
Energy Efficiency,"oud -q auth activate-service-account; --key-file=/gsa-key/privateKeyData || (sleep $(( 5 + (RANDOM % 5) )); gcloud; -q auth activate-service-account --key-file=/gsa-key/privateKeyData)) && mkdir; -p /io/pipeline/pipeline-1cac3dd4e66d/__TASK__0; gsutil -m cp -R gs://hail-wang-ukps2/pipeline/pipeline-1cac3dd4e66d/__TASK__0/0731f9a3; /io/pipeline/pipeline-1cac3dd4e66d/__TASK__0/0731f9a3\n ""; image: google/cloud-sdk:237.0.0-alpine; imagePullPolicy: IfNotPresent; name: setup; resources:; requests:; cpu: 500m; terminationMessagePath: /dev/termination-log; terminationMessagePolicy: File; volumeMounts:; - mountPath: /batch-gsa-key; name: batch-gsa-key; - mountPath: /gsa-key; name: gsa-key; - mountPath: /io; name: batch-12728-job-287-742170; - mountPath: /var/run/secrets/kubernetes.io/serviceaccount; name: batch-output-pod-token-8pkmz; readOnly: true; nodeName: gke-vdc-non-preemptible-pool-0106a51b-qz7f; priority: 500000; priorityClassName: user; restartPolicy: Never; schedulerName: default-scheduler; securityContext: {}; serviceAccount: batch-output-pod; serviceAccountName: batch-output-pod; terminationGracePeriodSeconds: 30; tolerations:; - key: preemptible; value: ""true""; - effect: NoExecute; key: node.kubernetes.io/not-ready; operator: Exists; tolerationSeconds: 300; - effect: NoExecute; key: node.kubernetes.io/unreachable; operator: Exists; tolerationSeconds: 300; volumes:; - name: gsa-key; secret:; defaultMode: 420; secretName: wang-gsa-key; - name: batch-gsa-key; secret:; defaultMode: 420; secretName: batch-gsa-key; - name: batch-12728-job-287-742170; persistentVolumeClaim:; claimName: batch-12728-job-287-742170; - name: batch-output-pod-token-8pkmz; secret:; defaultMode: 420; secretName: batch-output-pod-token-8pkmz; status:; conditions:; - lastProbeTime: null; lastTransitionTime: 2019-09-05T19:15:42Z; message: 'containers with incomplete status: [setup]'; reason: ContainersNotInitialized; status: ""False""; type: Initialized; - lastProbeTime: null; lastTransitionTime:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7016:9471,schedul,schedulerName,9471,https://hail.is,https://github.com/hail-is/hail/issues/7016,2,['schedul'],"['scheduler', 'schedulerName']"
Energy Efficiency,"ow added to all test namespaces using the `add_users` build.yaml step and removed at the end of the PR run through the `delete_users` step. These use the normal create and delete API instead of copying the user's gsa from the production namespace. This relies on / tests that the delete user endpoint is properly deleting cloud identities when the users are deleted (previously broken in GCP but fixed in this PR.; - The developer role no longer implicitly deletes and recreates a corresponding namespace. I wanted adding developers to test namespaces not to have side-effects that leaked out of the namespace. A follow-up PR will incorporate the ability for a developer to request an on-demand dev namespace, which should be made a lot easier after these changes. I think this also means that we can remove some permissions from the auth K8s ServiceAccount since it no longer needs the ability to create and delete namespaces.; - A fixed-but-sufficient number of oauth2 callbacks are hard-coded into the oauth2 secret from GCP/azure and then allocated to a given namespace. This is fairly self-contained, all that needs to happen is to tell `auth` what callback to use and rewrite those callback urls in gateway to route back to the appropriate auth. This is done only for test namespaces, production still just uses `auth.hail.is/oauth2callback`. This gets around a long-standing limitation of Google oauth2 clients where there is no programmatic way to change the oauth2 callbacks. ### What has stayed the same; - The lifecycle of dev and test namespaces has not changed (future PR).; - The semantics of a dev deploy has not changed (other than a different oauth2 callback which the user will not notice). ### Testing; I've tested this branch in my own google project both by deploying main and updating to this branch and by deploying this branch from the beginning. The CI in my project ran both some dev deploys and a test batch because I PR'd this branch against my fork. Tested that I could ac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12751:1742,allocate,allocated,1742,https://hail.is,https://github.com/hail-is/hail/pull/12751,1,['allocate'],['allocated']
Energy Efficiency,"ow.get(UnsafeRow.scala:254); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:871); 	at is.hail.variant.MatrixTable$$anonfun$59$$anonfun$apply$42.apply(MatrixTable.scala:860); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:637); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.next(OrderedRVD.scala:631); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.foreach(OrderedRVD.scala:631); 	at is.hail.io.RichRDDRegionValue$.writeRowsPartition(RowStore.scala:510); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.io.RichRDDRegionValue$$anonfun$writeRows$extension$1.apply(RowStore.scala:526); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:207); 	at is.hail.utils.richUtils.RichRDD$$anonfun$5.apply(RichRDD.scala:198); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-df17cef; Error summary: IndexOutOfBoundsException: 3; ```; (NB: a custom VEP/LOFTEE, but that shouldn't matter - ran same thing on `devel-cd48e11` and it worked fine)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:6673,schedul,scheduler,6673,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437,2,['schedul'],['scheduler']
Energy Efficiency,owering.EvalRelationalLetsPass.apply(LoweringPass.scala:162); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:21); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:19); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:19); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:45); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:600); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$4(SparkBackend.scala:636); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$3(SparkBackend.scala:631); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$3$adapted(SparkBackend.scala:630); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); 	at is.hail.backend.spark.SparkBackend.$anonfun$withExecuteContext$2(SparkBackend.scala:407); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); 	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:393); 	at is.hail.backend.spark.SparkBackend.execute(SparkBackend.scala:630); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); 	at com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:79); 	at sun.net.httpserver.AuthFilter.doFilter(AuthFi,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14529:11232,adapt,adapted,11232,https://hail.is,https://github.com/hail-is/hail/issues/14529,1,['adapt'],['adapted']
Energy Efficiency,owering.EvalRelationalLetsPass.apply(LoweringPass.scala:164); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:21); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:19); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:19); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:45); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:601); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$4(SparkBackend.scala:637); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$3(SparkBackend.scala:632); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$3$adapted(SparkBackend.scala:631); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:77); 	at is.hail.utils.package$.using(package.scala:665); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:77); 	at is.hail.utils.package$.using(package.scala:665); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:64); 	at is.hail.backend.spark.SparkBackend.$anonfun$withExecuteContext$2(SparkBackend.scala:407); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); 	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:393); 	at is.hail.backend.spark.SparkBackend.execute(SparkBackend.scala:631); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:89); 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); 	at jdk.httpserver/sun.net.httpser,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14362:17994,adapt,adapted,17994,https://hail.is,https://github.com/hail-is/hail/issues/14362,1,['adapt'],['adapted']
Energy Efficiency,"owever, I am; pretty certain I understand the bug. I have seen this happen in GCP; and in Azure. Take a look at an interval of driver logs:; ```; INFO	2022-03-02 19:06:30,198	main.py	get_credentials_1:226	returning azure credentials to activating instance instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q; INFO	2022-03-02 19:06:30,199	hail_logging.py	log:40	https GET /pr-11438-default-g6cibyji6520/batch-driver/api/v1alpha/instances/credentials done in 0.005999999999858119s: 200; INFO	2022-03-02 19:06:30,226	main.py	activate_instance_1:237	activating instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q; INFO	2022-03-02 19:06:30,991	base.py	check:335	checking on instance batch-worker-pr-11438-default-g6cibyji6520-highcpu-z0idl, last updated 60.151s ago; INFO	2022-03-02 19:06:31,526	pool.py	schedule_loop_body:371	schedule pool standard: starting; INFO	2022-03-02 19:06:31,583	job.py	schedule_job:443	schedule job (94, 2) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,584	job.py	schedule_job:443	schedule job (95, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,585	job.py	schedule_job:443	schedule job (93, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,586	job.py	schedule_job:443	schedule job (90, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,586	job.py	schedule_job:443	schedule job (94, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,598	job.py	schedule_job:443	schedule job (97, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,656	job.py	schedule_job:443	schedule job (99, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:1017,schedul,schedule,1017,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['schedul'],['schedule']
Energy Efficiency,pPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) at org.apache.spark.scheduler.Task.run(Task.scala:123) at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408) at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748); 			at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 			at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 			at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 			at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 			at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 			at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); 			at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1495); 			at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2109); 			at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); 			at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); 			at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 			at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); 			at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 			at org.apache.spark.SparkContext.runJob(SparkContext.scala:2158); 			at is.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944:11059,schedul,scheduler,11059,https://hail.is,https://github.com/hail-is/hail/issues/8944,1,['schedul'],['scheduler']
Energy Efficiency,pache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:222); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	... 11 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1089); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperation,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:3716,schedul,scheduler,3716,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807,1,['schedul'],['scheduler']
Energy Efficiency,"pache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251); at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66); at org.apache.log4j.Category.callAppenders(Category.java:206); at org.apache.log4j.Category.forcedLog(Category.java:391); at org.apache.log4j.Category.log(Category.java:856); at org.slf4j.impl.Log4jLoggerAdapter.warn(Log4jLoggerAdapter.java:400); at org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66); at org.apache.spark.scheduler.TaskSetManager.logWarning(TaskSetManager.scala:52); at org.apache.spark.scheduler.TaskSetManager.handleFailedTask(TaskSetManager.scala:693); at org.apache.spark.scheduler.TaskSchedulerImpl.handleFailedTask(TaskSchedulerImpl.scala:421); at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply$mcV$sp(TaskResultGetter.scala:139); at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply(TaskResultGetter.scala:124); at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply(TaskResultGetter.scala:124); at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1953); at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:124); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ```; `pyhail-submit`:; ```bash; #!/bin/bash. if [ $# -ne 2 ]; then; echo 'usage: gcp-pyhail-submit <cluster> <py-file>'; exit 1; fi. cluster=$1; script=$2. echo cluster = $cluster; echo script = $script. HASH=`gsutil cat gs://hail-common/latest-hash.txt`. JAR_FILE=hail-hail-is-master-all-spark2.0.2-$HASH.jar; JAR=gs://hail-common/$JAR_FILE. PYHAIL_ZIP=gs://hail-common/pyhail-hail-is-master-$HASH.zip. gcloud dataproc jobs submit pyspark \; $script \; --cluster $cluster \; --files=$JAR \; --py-files=$PYHAIL_ZIP \; --properties=""spark.driver.extr",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1186#issuecomment-267416027:1992,schedul,scheduler,1992,https://hail.is,https://github.com/hail-is/hail/issues/1186#issuecomment-267416027,2,['schedul'],['scheduler']
Energy Efficiency,pache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37); at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:199); at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:103); at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:9912,schedul,scheduler,9912,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['schedul'],['scheduler']
Energy Efficiency,"pache.spark.SparkException: Job aborted due to stage failure: Task 582 in stage 10.0 failed 20 times, most recent failure: Lost task 582.19 in stage 10.0 (TID 461381) (cluster-w-144.c.gbsc-project.internal executor 3568): ExecutorLostFailure (executor 3568 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 128936 ms; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1124); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2491); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2433); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2422); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:902); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2204); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2225); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2244); 	at org.apache.spark.SparkContext.runJob(Spark",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12290:2738,schedul,scheduler,2738,https://hail.is,https://github.com/hail-is/hail/issues/12290,1,['schedul'],['scheduler']
Energy Efficiency,pache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3040:6916,schedul,scheduler,6916,https://hail.is,https://github.com/hail-is/hail/issues/3040,1,['schedul'],['scheduler']
Energy Efficiency,package$.getIteratorSizeWithMaxN(package.scala:347); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:442); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:442); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:469); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:467); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apa,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3790:6370,schedul,scheduler,6370,https://hail.is,https://github.com/hail-is/hail/issues/3790,1,['schedul'],['scheduler']
Energy Efficiency,package$.getIteratorSizeWithMaxN(package.scala:357); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:444); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:444); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:471); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:469); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apa,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4055:5628,schedul,scheduler,5628,https://hail.is,https://github.com/hail-is/hail/issues/4055,2,['schedul'],['scheduler']
Energy Efficiency,parseAddInfo(LoadVCF.scala:1112); 	at is.hail.io.vcf.LoadVCF$.parseLineInner(LoadVCF.scala:1541); 	at is.hail.io.vcf.LoadVCF$.parseLine(LoadVCF.scala:1409); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1916); 	... 21 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2673); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2609); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2608); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2608); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2861); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2792); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2257); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2289); 	at is.hail.sparkextras.ContextRDD.crunJobWithIndex(ContextRDD.scala:238); 	at is.hail.rvd.RVD$.getKeyInfo(RVD.scala:1029); 	at is.hail.rvd.RVD$.ma,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:10595,schedul,scheduler,10595,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['schedul'],['scheduler']
Energy Efficiency,pl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745)java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE; 	at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:869); 	at org.apache.spark.storage.DiskStore$$anonfun$getBytes$2.apply(DiskStore.scala:103); 	at org.apache.spark.storage.DiskStore$$anonfun$getBytes$2.apply(DiskStore.scala:91); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1310); 	at org.apache.spark.storage.DiskStore.getBytes(DiskStore.scala:105); 	at org.apache.spark.storage.BlockManager.getLocalValues(BlockManager.scala:438); 	at org.apache.spark.storage.BlockManager.get(BlockManager.scala:606); 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:663); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:281); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Hail version: devel-ebabd77; Error summary: IllegalArgumentException: Size exceeds Integer.MAX_VALUE. ​; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1806:6442,schedul,scheduler,6442,https://hail.is,https://github.com/hail-is/hail/issues/1806,2,['schedul'],['scheduler']
Energy Efficiency,ply$27.apply(ContextRDD.scala:359); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5.apply(ContextRDD.scala:139); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5.apply(ContextRDD.scala:139); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-15f58831fe57; Error summary: AssertionError: assertion failed; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4263:11884,schedul,scheduler,11884,https://hail.is,https://github.com/hail-is/hail/issues/4263,2,['schedul'],['scheduler']
Energy Efficiency,ply$27.apply(ContextRDD.scala:359); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5.apply(ContextRDD.scala:139); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5.apply(ContextRDD.scala:139); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-f80a6f10bc84; Error summary: AssertionError: assertion failed; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4128#issuecomment-412764719:11890,schedul,scheduler,11890,https://hail.is,https://github.com/hail-is/hail/pull/4128#issuecomment-412764719,2,['schedul'],['scheduler']
Energy Efficiency,ply$4.apply(LinearRegression.scala:130); at org.broadinstitute.hail.methods.LinearRegression$$anonfun$apply$4.apply(LinearRegression.scala:129); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$41$$anonfun$apply$42.apply(PairRDDFunctions.scala:700); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$41$$anonfun$apply$42.apply(PairRDDFunctions.scala:700); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$20.next(Iterator.scala:635); at scala.collection.Iterator$$anon$20.next(Iterator.scala:633); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$6.apply$mcV$sp(PairRDDFunctions.scala:1109); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$6.apply(PairRDDFunctions.scala:1108); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$6.apply(PairRDDFunctions.scala:1108); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1206); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1116); at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1095); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); at org.apache.spark.scheduler.Task.run(Task.scala:88); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/336:2812,schedul,scheduler,2812,https://hail.is,https://github.com/hail-is/hail/issues/336,2,['schedul'],['scheduler']
Energy Efficiency,ply(ContextRDD.scala:192); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); 	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.fold(TraversableOnce.scala:212); 	at scala.collection.AbstractIterator.fold(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1$$anonfun$20.apply(RDD.scala:1095); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1$$anonfun$20.apply(RDD.scala:1095); 	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2125); 	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2125); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:344); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). is.hail.utils.HailException: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.io.LoadMatrixParser.parseLine(LoadMatrix.scala:33); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:383); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:377); 	at is.hail.utils.WithContext.wrap(Context.scala:41); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:377); 	at is.hai,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:12334,schedul,scheduler,12334,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['schedul'],['scheduler']
Energy Efficiency,ply(ContextRDD.scala:192); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); 	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.fold(TraversableOnce.scala:212); 	at scala.collection.AbstractIterator.fold(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1$$anonfun$20.apply(RDD.scala:1095); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1$$anonfun$20.apply(RDD.scala:1095); 	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2125); 	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2125); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:344); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: is.hail.utils.HailException: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.io.LoadMatrixParser.parseLine(LoadMatrix.scala:33); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:383); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:377); 	at is.hail.utils.WithContext.wrap(Context.scala:41); 	... 30 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$a,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:5001,schedul,scheduler,5001,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['schedul'],['scheduler']
Energy Efficiency,point(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3235:5707,schedul,scheduler,5707,https://hail.is,https://github.com/hail-is/hail/issues/3235,1,['schedul'],['scheduler']
Energy Efficiency,pply(ContextRDD.scala:373); at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$30.apply(ContextRDD.scala:373); at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$8.apply(ContextRDD.scala:153); at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$8.apply(ContextRDD.scala:153); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5371:8091,schedul,scheduler,8091,https://hail.is,https://github.com/hail-is/hail/issues/5371,2,['schedul'],['scheduler']
Energy Efficiency,pply(Partitioner.scala:66); 	at org.apache.spark.Partitioner$$anonfun$defaultPartitioner$2.apply(Partitioner.scala:66); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.immutable.List.map(List.scala:285); 	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:66); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:329); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:329); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:328); 	at is.hail.methods.MendelErrors.nErrorPerNuclearFamily(MendelErrors.scala:145); 	at is.hail.methods.MendelErrors.fMendelKT(MendelErrors.scala:184); 	at is.hail.variant.MatrixTable.mendelErrors(MatrixTable.scala:1913); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3074#issuecomment-370494908:9306,reduce,reduceByKey,9306,https://hail.is,https://github.com/hail-is/hail/issues/3074#issuecomment-370494908,1,['reduce'],['reduceByKey']
Energy Efficiency,"ps and Storage]</li>; <li>In kubelet, log verbosity and flush frequency can also be configured via the configuration file and not just via command line flags. In other commands (kube-apiserver, kube-controller-manager), the flags are listed in the &quot;Logs flags&quot; group and not under &quot;Global&quot; or &quot;Misc&quot;. The type for <code>-vmodule</code> was made a bit more descriptive (<code>pattern=N,...</code> instead of <code>moduleSpec</code>). (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/106090"">kubernetes/kubernetes#106090</a>, <a href=""https://github.com/pohly""><code>@​pohly</code></a>) [SIG API Machinery, Architecture, CLI, Cluster Lifecycle, Instrumentation, Node and Scheduling]</li>; <li>Introduce <code>OS</code> field in the PodSpec (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104693"">kubernetes/kubernetes#104693</a>, <a href=""https://github.com/ravisantoshgudimetla""><code>@​ravisantoshgudimetla</code></a>)</li>; <li>Introduce <code>v1beta3</code> API for scheduler. This version; <ul>; <li>; <p>increases the weight of user specifiable priorities.; The weights of following priority plugins are increased</p>; <ul>; <li><code>TaintTolerations</code> to 3 - as leveraging node tainting to group nodes in the cluster is becoming a widely-adopted practice</li>; <li><code>NodeAffinity</code> to 2</li>; <li><code>InterPodAffinity</code> to 2</li>; </ul>; </li>; <li>; <p>Won't have <code>HealthzBindAddress</code>, <code>MetricsBindAddress</code> fields (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104251"">kubernetes/kubernetes#104251</a>, <a href=""https://github.com/ravisantoshgudimetla""><code>@​ravisantoshgudimetla</code></a>)</p>; </li>; </ul>; </li>; <li>Introduce v1beta2 for Priority and Fairness with no changes in API spec. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104399"">kubernetes/kubernetes#104399</a>, <a href=""https://gith",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:5881,schedul,scheduler,5881,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['schedul'],['scheduler']
Energy Efficiency,"pull/89594"">kubernetes/kubernetes#89594</a>, <a href=""https://github.com/wojtek-t""><code>@​wojtek-t</code></a>) [SIG Apps and Testing]</li>; <li>Remove <code>BindTimeoutSeconds</code> from schedule configuration <code>KubeSchedulerConfiguration</code> (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91580"">kubernetes/kubernetes#91580</a>, <a href=""https://github.com/cofyc""><code>@​cofyc</code></a>) [SIG Scheduling and Testing]</li>; <li>Remove kubescheduler.config.k8s.io/v1alpha1 (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89298"">kubernetes/kubernetes#89298</a>, <a href=""https://github.com/gavinfish""><code>@​gavinfish</code></a>) [SIG Scheduling]</li>; <li>Reserve plugins that fail to reserve will trigger the unreserve extension point (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92391"">kubernetes/kubernetes#92391</a>, <a href=""https://github.com/adtac""><code>@​adtac</code></a>) [SIG Scheduling and Testing]</li>; <li>Resolve regression in <code>metadata.managedFields</code> handling in update/patch requests submitted by older API clients (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91748"">kubernetes/kubernetes#91748</a>, <a href=""https://github.com/apelisse""><code>@​apelisse</code></a>)</li>; <li>Scheduler: optionally check for available storage capacity before scheduling pods which have unbound volumes (alpha feature with the new <code>CSIStorageCapacity</code> feature gate, only works for CSI drivers and depends on support for the feature in a CSI driver deployment) (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92387"">kubernetes/kubernetes#92387</a>, <a href=""https://github.com/pohly""><code>@​pohly</code></a>) [SIG API Machinery, Apps, Auth, Scheduling, Storage and Testing]</li>; <li>Seccomp support has graduated to GA. A new <code>seccompProfile</code> field is added to pod and container securityContext objects. Supp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:12394,Schedul,Scheduling,12394,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['Schedul'],['Scheduling']
Energy Efficiency,pute(BlockMatrix.scala:1829); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403:12390,schedul,scheduler,12390,https://hail.is,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403,1,['schedul'],['scheduler']
Energy Efficiency,"py"", line 380, in _make_request; httplib_response = conn.getresponse(); File ""/usr/local/lib/python3.6/http/client.py"", line 1354, in getresponse; response.begin(); File ""/usr/local/lib/python3.6/http/client.py"", line 307, in begin; version, status, reason = self._read_status(); File ""/usr/local/lib/python3.6/http/client.py"", line 268, in _read_status; line = str(self.fp.readline(_MAXLINE + 1), ""iso-8859-1""); File ""/usr/local/lib/python3.6/socket.py"", line 586, in readinto; return self._sock.recv_into(b); File ""/usr/local/lib/python3.6/ssl.py"", line 1012, in recv_into; return self.read(nbytes, buffer); File ""/usr/local/lib/python3.6/ssl.py"", line 874, in read; return self._sslobj.read(len, buffer); File ""/usr/local/lib/python3.6/ssl.py"", line 631, in read; v = self._sslobj.read(len, buffer); socket.timeout: The read operation timed out. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.6/site-packages/requests/adapters.py"", line 449, in send; timeout=timeout; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 638, in urlopen; _stacktrace=sys.exc_info()[2]); File ""/usr/local/lib/python3.6/site-packages/urllib3/util/retry.py"", line 368, in increment; raise six.reraise(type(error), error, _stacktrace); File ""/usr/local/lib/python3.6/site-packages/urllib3/packages/six.py"", line 686, in reraise; raise value; File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 600, in urlopen; chunked=chunked); File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 386, in _make_request; self._raise_timeout(err=e, url=url, timeout_value=read_timeout); File ""/usr/local/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 306, in _raise_timeout; raise ReadTimeoutError(self, url, ""Read timed out. (read timeout=%s)"" % timeout_value); urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.googleapis.com', port=443): ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8053:1293,adapt,adapters,1293,https://hail.is,https://github.com/hail-is/hail/issues/8053,3,['adapt'],['adapters']
Energy Efficiency,"py4j-0.10.9.5-src.zip/py4j/java_gateway.py"", line 1321, in __call__; File ""/opt/conda/default/lib/python3.10/site-packages/hail/backend/py4j_backend.py"", line 35, in deco; raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; hail.utils.java.FatalError: HailException: zip: length mismatch: 62164, 104. Java stack trace:; is.hail.utils.HailException: zip: length mismatch: 62164, 104; 	at __C8160Compiled.__m8201split_ToArray(Emit.scala); 	at __C8160Compiled.__m8169split_CollectDistributedArray(Emit.scala); 	at __C8160Compiled.__m8164split_Let(Emit.scala); 	at __C8160Compiled.apply(Emit.scala); 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$_apply$4(CompileAndEvaluate.scala:61); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$_apply$2(CompileAndEvaluate.scala:61); 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$_apply$2$adapted(CompileAndEvaluate.scala:59); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:140); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:140); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:59); 	at is.hail.expr.ir.CompileAndEvaluate$.evalToIR(CompileAndEvaluate.scala:33); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.evaluate$1(LowerOrInterpretNonCompilable.scala:30); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:58); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:63); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:67); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13486:3104,adapt,adapted,3104,https://hail.is,https://github.com/hail-is/hail/issues/13486,1,['adapt'],['adapted']
Energy Efficiency,ql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:247); at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1275:3676,schedul,scheduler,3676,https://hail.is,https://github.com/hail-is/hail/issues/1275,1,['schedul'],['scheduler']
Energy Efficiency,"r node syslogs as well as the Hail log file. For some reason all logs other than the Hail logs are missing from this file. We separately need to determine why all the Spark logs etc. are missing. Based on the syslog, after system start up and just before the Jupyter notebook starts, the system is already using ~8,500MiB:; ```; Nov 22 14:29:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43808 of 52223 MiB (83.89%), swap free: 0 of 0 MiB ( 0.00%); ```; So, the effective maximum memory that Hail could possibly use is around 43808MiB. After the Notebook and Spark initialize we're down to 42,700 MiB (about ~1000MiB more in use).; ```; Nov 22 14:30:06 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 42760 of 52223 MiB (81.88%), swap free: 0 of 0 MiB ( 0.00%); ```. `hailctl` sets the VM RAM limit to 80% of the instance type's memory, so 80% * 52GiB = 42598MiB. This means the JVM is permitted to effectively use all the remaining memory. At time of sigkill the total memory allocated by the JVM was about 2000MiB below the max heap size. Note that the heap is contained within all memory allocated by the JVM.; ```; Nov 22 15:31:05 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 43 of 52223 MiB ( 0.08%), swap free: 0 of 0 MiB ( 0.00%); Nov 22 15:31:09 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: low memory! at or below SIGTERM limits: mem 0.12%, swap 1.00%; Nov 22 15:31:09 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM to process 8421 uid 0 ""java"": badness 1852, VmRSS 40578 MiB; ```. Indeed, the VmRSS is the memory in use from the kernel's perspective so it includes any off-heap memory created by Hail. The Hail log indicates the region pools are tiny, ~10s of MiB. Not a concern. After the JVM is killed, memory jumps back up to 40683MiB (which checks out, that's roughly what the killed process was using).; ```; Nov 22 15:31:10 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem avail: 40683 of 52223 MiB (77.90%), swap free: 0 of 0 MiB ( 0.00%); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419:1795,allocate,allocated,1795,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1832531419,2,['allocate'],['allocated']
Energy Efficiency,"r. I think this is currently impossible due to lack of permissions, but we should either explicitly prohibit this or ensure our solution encompasses it. In particular, I am concerned OpenID could be used to grant permission for a GCP identity to write to S3 or ABS. . Pulling an image shouldn’t trigger substantial egress. In the first case, there are three kinds of possible egress:; 1. Egress to the Public Internet.; 2. Egress to a VM in a different Google region.; 3. Egress to a Google Service in a different Google region (e.g. uploading to a bucket in a different region). I believe (2) and (3) are charged equivalently. (1) is simply Internet egress pricing. In (3), I’m not sure who pays the egress from a VM to a bucket in a different region. I assume the VM owner. In all three cases, the destination’s location matters. For public Internet egress, we can use GeoIP to determine the region of the planet. I’m not sure if we can determine the region of (2) and (3). If we can’t, we should either prevent such traffic or we should charge the maximum egress. A final caveat is that we use Premium Networking. As a result, our traffic can use Google’s internal backbone. It’s not clear to me if this means that a packet from us-central to a public IP in Australia incurs just Internet egress or that *and* a region-to-region egress to pay for the use of GCP’s internal global backbone. The priority of various considerations:; 1. Top priority within this issue is to track and recover costs. Even if this means charging a flat fee across all possible kinds of egress. Even if that fee is substantially higher than the real cost to us.; 2. Second priority is to surface this information to the user. Simply providing, in the job page, the usage and cost of each resource for this job.; 3. Fine grained egress so that users can actually intentionally use it at cost or near cost to, for example, move data between clouds or regions. . ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13428:1463,charge,charge,1463,https://hail.is,https://github.com/hail-is/hail/issues/13428,1,['charge'],['charge']
Energy Efficiency,r.TableMapRows.$anonfun$execute$43(TableIR.scala:1938); 	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23); 	at scala.collection.Iterator$$anon$10.next(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:496); 	at is.hail.utils.richUtils.RichContextRDD$$anon$1.next(RichContextRDD.scala:79); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:496); 	at is.hail.utils.package$.getIteratorSizeWithMaxN(package.scala:415); 	at is.hail.rvd.RVD.$anonfun$head$2(RVD.scala:526); 	at is.hail.rvd.RVD.$anonfun$head$2$adapted(RVD.scala:526); 	at is.hail.sparkextras.ContextRDD.$anonfun$runJob$2(ContextRDD.scala:366); 	at is.hail.sparkextras.ContextRDD.sparkManagedContext(ContextRDD.scala:164); 	at is.hail.sparkextras.ContextRDD.$anonfun$runJob$1(ContextRDD.scala:365); 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:131); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2254); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2203); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2202); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuf,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:7344,schedul,scheduler,7344,https://hail.is,https://github.com/hail-is/hail/issues/10682,1,['schedul'],['scheduler']
Energy Efficiency,r.ir.EmitClassBuilder$$anon$1.apply(EmitClassBuilder.scala:708); 	at is.hail.expr.ir.CompileIterator$.$anonfun$forTableStageToRVD$1(Compile.scala:311); 	at is.hail.expr.ir.CompileIterator$.$anonfun$forTableStageToRVD$1$adapted(Compile.scala:310); 	at is.hail.expr.ir.lowering.TableStageToRVD$.$anonfun$apply$9(RVDToTableStage.scala:106); 	at is.hail.sparkextras.ContextRDD.$anonfun$cflatMap$2(ContextRDD.scala:211); 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2(RVD.scala:1234); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1233); 	at is.hail.sparkextras.ContextRDD.$anonfun$crunJobWithIndex$1(ContextRDD.scala:242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:131); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:498); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:501); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuf,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12532:5212,schedul,scheduler,5212,https://hail.is,https://github.com/hail-is/hail/issues/12532,1,['schedul'],['scheduler']
Energy Efficiency,"r.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.hasNext(OrderedRVD.scala:911); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.utils.package$.getIteratorSizeWithMaxN(package.scala:347); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:433); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:433); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1$$anonfun$apply$34.apply(ContextRDD.scala:458); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1$$anonfun$apply$34.apply(ContextRDD.scala:458); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:458); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:458); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); ```. Under ""Failed Stages"", these were the details for what I was running:; ```; org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); is.hail.sparkextras.ContextRDD.runJob(ContextRDD.scala:456); is.hail.sparkextras.ContextRDD.head(ContextRDD.scala:433); is.hail.rvd.OrderedRVD.head(OrderedRVD.scala:285); is.hail.rvd.OrderedRVD.head(OrderedRVD.scala:21); is.hail.rvd.RVD$class.takeAsBytes(RVD.scala:243); is.hail.rvd.OrderedRVD.takeAsBytes(OrderedRVD.scala:21); is.hail.rvd.RVD$class.take(RVD.scala:247); is.hail.rvd.OrderedRVD.take(OrderedRVD.scala:21); is.hail.table.Table.take(Table.scala:990); i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3508:5846,schedul,scheduler,5846,https://hail.is,https://github.com/hail-is/hail/issues/3508,1,['schedul'],['scheduler']
Energy Efficiency,rLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container from a bad node: container_1691092255852_0001_01_000005 on host: all-of-us-56-w-0.c.terra-vpc-sc-8f5cdfd2.internal. Exit status: 137. Diagnostics: [2023-08-03 20:14:25.441]Container killed on request. Exit code is 137; [2023-08-03 20:14:25.442]Container exited with a non-zero exit code 137. ; [2023-08-03 20:14:25.442]Killed by external signal; .; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1124); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2491); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2433); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2422); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:902); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2204); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2225); 	at org.apache.spark.SparkContex,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287#issuecomment-1664593619:5621,schedul,scheduler,5621,https://hail.is,https://github.com/hail-is/hail/issues/13287#issuecomment-1664593619,1,['schedul'],['scheduler']
Energy Efficiency,rReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:332); 	at org.apache.spark.rdd.RDD$$anonfun$8.apply(RDD.scala:330); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:935); 	at org.apache.spark.storage.BlockManager$$anonfun$doPutIterator$1.apply(BlockManager.scala:926); 	at org.apache.spark.storage.BlockManager.doPut(BlockManager.scala:866); 	at org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:926); 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:670); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:281); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGSchedu,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:8155,schedul,scheduler,8155,https://hail.is,https://github.com/hail-is/hail/issues/3760,1,['schedul'],['scheduler']
Energy Efficiency,rVariants$$anonfun$10.apply(Relational.scala:503); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:500); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.sparkextras.OrderedRDD$$anonfun$apply$5$$anon$2.hasNext(OrderedRDD.scala:194); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.sparkextras.PartitionKeyInfo$.apply(PartitionKeyInfo.scala:30); 	at is.hail.sparkextras.OrderedRDD$$anonfun$4.apply(OrderedRDD.scala:72); 	at is.hail.sparkextras.OrderedRDD$$anonfun$4.apply(OrderedRDD.scala:70); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-08a1543; Error summary: AssertionError: assertion failed; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:9865,schedul,scheduler,9865,https://hail.is,https://github.com/hail-is/hail/issues/2743,2,['schedul'],['scheduler']
Energy Efficiency,"rack bytes and charge some, possibly very high, rate. 2. How can we allow public Internet egress at or near the real cost to us?. The second question is complex because Google's egress pricing is complex. To directly respond to your comment: I don't think we need to disaggregate by destination IP address, but we do need to disaggregate by destination ""type & location"". GeoIP _might_ allow us to do this in iptables, we should figure out what is and isn't possible and how hard it would be. ---. The following is distilled from [Network Pricing](https://cloud.google.com/vpc/network-pricing). There are six types of egress:; 1. VM-to-Internet; 2. VM-to-VM or VM-to-Google-Service (which are charged equally); 3. Spanner-to-VM; 4. VM-to-Spanner; 5. GCS-to-VM; 6. VM-to-GCS. Egress types (3) and (5) do not apply to us because hail-vdc does not have Spanner and user jobs cannot read from hail-vdc buckets. Egress types (4) and (6) are slightly ambiguous. We should create a support ticket to verify, but I believe they're charged just like (2). This means we are concerned with just two types of egress:. 1. VM-to-Internet; 2. VM-to-VM / VM-to-Google-Service. Each type has a different cost table based on the _destination location_. In these tables, the cheapest price applies, so, for example, for traffic form us-central1-a to us-central1-a the within-zone price applies, not the within-region price. 1. VM-to-Internet. Prices decrease with more usage.; 1. Standard Tier Networking. For the first 10 TiB: 0.085 USD per GiB.; 2. Premium Tier Networking (we are using this currently). For the first 1 TiB:. | Destination | Cost (USD per GiB) |; | --- | --- |; | Anywhere except China, except Australia, but including Hong Kong | 0.12 |; | China except Hong Kong | 0.23 |; | Australia | 0.19 |; 5. VM-to-VM or VM-to-Google-Service. | Location Type | Cost (USD per GiB) |; | --- | --- |; |Within-Zone|0.00|; |Within-Region (but different Zones)|0.01|; |Within-US/Canada|0.01|; |Within-Europe|0.02|; |",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13428#issuecomment-1692168526:1521,charge,charged,1521,https://hail.is,https://github.com/hail-is/hail/issues/13428#issuecomment-1692168526,1,['charge'],['charged']
Energy Efficiency,ractChannelHandlerContext.java:340) at org.apacxt.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelt io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359) at io.netty.channel.AbstractChannelHandlerCtractChannelHandlerContext.java:348) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935) at io.nettyectedKey(NioEventLoop.java:645) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580) at io.netty at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) at io.netty.util.concurrent.Default; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1493); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2107); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); at org.apache.spark.SparkContext.runJob(Sp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8106:24142,schedul,scheduler,24142,https://hail.is,https://github.com/hail-is/hail/issues/8106,1,['schedul'],['scheduler']
Energy Efficiency,rap(Context.scala:41); 	... 30 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1575); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1563); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1562); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1562); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1790); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1745); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1734); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:619); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1097); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.fold(RDD.scala:1091); 	at is.hail.rvd.RVD.count(RVD.scala:580); 	at is.hail.expr.ir.Interpret$$anonfun$apply$1.apply$mcJ$sp(Interpret.sca,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:6895,schedul,scheduler,6895,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['schedul'],['scheduler']
Energy Efficiency,rator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.sparkextras.OrderedRDD$$anonfun$apply$5$$anon$2.hasNext(OrderedRDD.scala:194); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.sparkextras.PartitionKeyInfo$.apply(PartitionKeyInfo.scala:30); 	at is.hail.sparkextras.OrderedRDD$$anonfun$4.apply(OrderedRDD.scala:72); 	at is.hail.sparkextras.OrderedRDD$$anonfun$4.apply(OrderedRDD.scala:70); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGSchedu,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:4250,schedul,scheduler,4250,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['schedul'],['scheduler']
Energy Efficiency,rator.scala:1334); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:655); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:653); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$28.apply(ContextRDD.scala:405); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$28.apply(ContextRDD.scala:405); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$8.apply(ContextRDD.scala:192); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$8.apply(ContextRDD.scala:192); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); 	at scala.collection.Iterator$class.foreach(Iterator.scala:891); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); 	at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); 	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334); 	at scala.collection.TraversableOnce$class.fold(TraversableOnce.scala:212); 	at scala.collection.AbstractIterator.fold(Iterator.scala:1334); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1$$anonfun$20.apply(RDD.scala:1096); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1$$anonfun$20.apply(RDD.scala:1096); 	at org.apache.spark.SparkContext$$anonfun$36.apply(SparkContext.scala:2157); 	at org.apache.spark.SparkContext$$anonfun$36.apply(SparkContext.scala:2157); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:121); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:403); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:409); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6345#issuecomment-503757307:6939,schedul,scheduler,6939,https://hail.is,https://github.com/hail-is/hail/pull/6345#issuecomment-503757307,2,['schedul'],['scheduler']
Energy Efficiency,rator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:247); at org.apache.spark.sql.execution.SparkPlan$$anonfun$4.apply(SparkPlan.scala:240); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:803); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); at org.apache.spark.scheduler.Task.run(Task.scala:86); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:8,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1275:3317,schedul,scheduler,3317,https://hail.is,https://github.com/hail-is/hail/issues/1275,1,['schedul'],['scheduler']
Energy Efficiency,rator.scala:490); 	at is.hail.utils.richUtils.RichContextRDD$$anon$1.hasNext(RichContextRDD.scala:69); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator.foreach(Iterator.scala:943); 	at scala.collection.Iterator.foreach$(Iterator.scala:943); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431); 	at is.hail.io.RichContextRDDRegionValue$.writeRowsPartition(RichContextRDDRegionValue.scala:37); 	at is.hail.io.RichContextRDDLong$.$anonfun$writeRows$2(RichContextRDDRegionValue.scala:234); 	at is.hail.utils.richUtils.RichContextRDD$.writeParts(RichContextRDD.scala:42); 	at is.hail.utils.richUtils.RichContextRDD.$anonfun$writePartitions$1(RichContextRDD.scala:107); 	at is.hail.utils.richUtils.RichContextRDD.$anonfun$writePartitions$1$adapted(RichContextRDD.scala:105); 	at is.hail.sparkextras.ContextRDD.$anonfun$cmapPartitionsWithIndex$2(ContextRDD.scala:259); 	at is.hail.utils.richUtils.RichContextRDD.$anonfun$cleanupRegions$2(RichContextRDD.scala:60); 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492); 	at is.hail.utils.richUtils.RichContextRDD$$anon$1.hasNext(RichContextRDD.scala:69); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator.foreach(Iterator.scala:943); 	at scala.collection.Iterator.foreach$(Iterator.scala:943); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431); 	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62); 	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12936:2609,adapt,adapted,2609,https://hail.is,https://github.com/hail-is/hail/issues/12936,1,['adapt'],['adapted']
Energy Efficiency,rayBuffer.$plus$plus$eq(ArrayBuffer.scala:105); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49); 	at scala.collection.TraversableOnce.to(TraversableOnce.scala:366); 	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:364); 	at scala.collection.AbstractIterator.to(Iterator.scala:1431); 	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358); 	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1431); 	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345); 	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1431); 	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1021); 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2276); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2673); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2609); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2608); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutabl,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12936:4479,schedul,scheduler,4479,https://hail.is,https://github.com/hail-is/hail/issues/12936,1,['schedul'],['scheduler']
Energy Efficiency,"rce (or it may not exist)."",; E ""reason"": ""forbidden""; E }; E ],; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist).""; E }; E ; E Java stack trace:; E java.io.IOException: Error accessing gs://hail-test-requester-pays-fds32/zero-to-nine; E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:1986); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:1882); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystemImpl.getFileInfoInternal(GoogleCloudStorageFileSystemImpl.java:861); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageFileSystemImpl.getFileInfo(GoogleCloudStorageFileSystemImpl.java:833); E 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.getFileStatus(GoogleHadoopFileSystem.java:724); E 	at org.apache.hadoop.fs.Globber.getFileStatus(Globber.java:115); E 	at org.apache.hadoop.fs.Globber.doGlob(Globber.java:349); E 	at org.apache.hadoop.fs.Globber.glob(Globber.java:202); E 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:2142); E 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.globStatus(GoogleHadoopFileSystem.java:759); E 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem.globStatus(GoogleHadoopFileSystem.java:1277); E 	at is.hail.io.fs.HadoopFS.glob(HadoopFS.scala:162); E 	at is.hail.io.fs.HadoopFS.glob(HadoopFS.scala:85); E 	at is.hail.io.fs.FS.glob(FS.scala:402); E 	at is.hail.io.fs.FS.glob$(FS.scala:402); E 	at is.hail.io.fs.HadoopFS.glob(HadoopFS.scala:85); E 	at is.hail.io.fs.HadoopFS.$anonfun$globAll$1(HadoopFS.scala:154); E 	at is.hail.io.fs.HadoopFS.$anonfun$globAll$1$adapted(HadoopFS.scala:153). ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236:3197,adapt,adapted,3197,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236,1,['adapt'],['adapted']
Energy Efficiency,"re: memory allocation --- passing NDArrays around on the stack seems adequate for now given that the data array will still be region-allocated and I don't think we expect the rest of it to ever get large, but we should probably set up a time to talk about a fuller plan for allocation/memory management sooner rather than later.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5627#issuecomment-474470091:133,allocate,allocated,133,https://hail.is,https://github.com/hail-is/hail/pull/5627#issuecomment-474470091,1,['allocate'],['allocated']
Energy Efficiency,"redRVD.scala:736); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1336); at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214); at scala.collection.AbstractIterator.aggregate(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$22.apply(RDD.scala:1113); at org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$22.apply(RDD.scala:1113); at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2118); at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2118); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); ... 1 more. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/tmp/b09ec92a-49f4-4d16-ad6d-efc5a5805e92/05_variant_qc.py"", line 201, in <module>; cumcounts = {'step0': rt.aggregate(hl.agg.sum(hl.cond(rt.qccum.step0, 1, 0))),; File ""<decorator-gen-519>"", line 2, in aggregate; File ""/home/hail/hail.zip/hail/utils/java.py"", line 191, in handle_py4j; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 6.0 failed 20 times, most recent failure: Lost task 7.19 in stage 6.0 (TID 179, ro",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3063:10954,schedul,scheduler,10954,https://hail.is,https://github.com/hail-is/hail/issues/3063,1,['schedul'],['scheduler']
Energy Efficiency,redRVD.scala:736); at is.hail.rvd.OrderedRVD$$anonfun$apply$6$$anon$5.next(OrderedRVD.scala:730); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1336); at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214); at scala.collection.AbstractIterator.aggregate(Iterator.scala:1336); at org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$22.apply(RDD.scala:1113); at org.apache.spark.rdd.RDD$$anonfun$aggregate$1$$anonfun$22.apply(RDD.scala:1113); at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2118); at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2118); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.schedule,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3063:4690,schedul,scheduler,4690,https://hail.is,https://github.com/hail-is/hail/issues/3063,2,['schedul'],['scheduler']
Energy Efficiency,reduce cpu and memory minimums,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4966:0,reduce,reduce,0,https://hail.is,https://github.com/hail-is/hail/pull/4966,1,['reduce'],['reduce']
Energy Efficiency,reduce num of takeby cases,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3844:0,reduce,reduce,0,https://hail.is,https://github.com/hail-is/hail/pull/3844,1,['reduce'],['reduce']
Energy Efficiency,reduce pc relate test time,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2275:0,reduce,reduce,0,https://hail.is,https://github.com/hail-is/hail/pull/2275,1,['reduce'],['reduce']
Energy Efficiency,reduced SVD on BlockMatrix via local gramian,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3977:0,reduce,reduced,0,https://hail.is,https://github.com/hail-is/hail/pull/3977,1,['reduce'],['reduced']
Energy Efficiency,"ref=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105687"">kubernetes/kubernetes#105687</a>, <a href=""https://github.com/alculquicondor""><code>@​alculquicondor</code></a>)</li>; <li>Kube-apiserver: Fixes handling of CRD schemas containing literal null values in enums. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104969"">kubernetes/kubernetes#104969</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>)</li>; <li>Kube-apiserver: The <code>rbac.authorization.k8s.io/v1alpha1</code> API version is removed; use the <code>rbac.authorization.k8s.io/v1</code> API, available since v1.8. The <code>scheduling.k8s.io/v1alpha1</code> API version is removed; use the <code>scheduling.k8s.io/v1</code> API, available since v1.14. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104248"">kubernetes/kubernetes#104248</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>)</li>; <li>Kube-scheduler: support for configuration file version <code>v1beta1</code> is removed. Update configuration files to v1beta2(xref: <a href=""https://github-redirect.dependabot.com/kubernetes/enhancements/issues/2901"">kubernetes/enhancements#2901</a>) or v1beta3 before upgrading to 1.23. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104782"">kubernetes/kubernetes#104782</a>, <a href=""https://github.com/kerthcet""><code>@​kerthcet</code></a>)</li>; <li>KubeSchedulerConfiguration provides a new field <code>MultiPoint</code> which will register a plugin for all valid extension points (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105611"">kubernetes/kubernetes#105611</a>, <a href=""https://github.com/damemi""><code>@​damemi</code></a>) [SIG Scheduling and Testing]</li>; <li>Kubelet should reject pods whose OS doesn't match the node's OS label. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105292"">kubernetes/kubernetes#105292",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:8360,schedul,scheduler,8360,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['schedul'],['scheduler']
Energy Efficiency,refactor backend stuff in preparation for scheduler's backend,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6301:42,schedul,scheduler,42,https://hail.is,https://github.com/hail-is/hail/pull/6301,1,['schedul'],['scheduler']
Energy Efficiency,registerKryoClasses to reduce classname serialization overhead and catch unintended serialization,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1022:23,reduce,reduce,23,https://hail.is,https://github.com/hail-is/hail/issues/1022,1,['reduce'],['reduce']
Energy Efficiency,remove monitoring/,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8703:7,monitor,monitoring,7,https://hail.is,https://github.com/hail-is/hail/pull/8703,1,['monitor'],['monitoring']
Energy Efficiency,remove scheduler,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8128:7,schedul,scheduler,7,https://hail.is,https://github.com/hail-is/hail/pull/8128,1,['schedul'],['scheduler']
Energy Efficiency,"rent java objects, thread 9: pool-1-thread-2; is.hail.utils.HailException: Hail off-heap memory exceeded maximum threshold: limit 2.25 GiB, allocated 3.35 GiB; Report: 3.4G allocated (192.0K blocks / 3.4G chunks), regions.size = 3, 0 current java objects, thread 9: pool-1-thread-2; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:17); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:17); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.annotations.RegionPool.closeAndThrow(RegionPool.scala:58); 	at is.hail.annotations.RegionPool.incrementAllocatedBytes(RegionPool.scala:73); 	at is.hail.annotations.ChunkCache.newChunk(ChunkCache.scala:75); 	at is.hail.annotations.ChunkCache.getChunk(ChunkCache.scala:130); 	at is.hail.annotations.RegionPool.getChunk(RegionPool.scala:96); 	at is.hail.annotations.RegionMemory.allocateBigChunk(RegionMemory.scala:62); 	at is.hail.annotations.RegionMemory.allocate(RegionMemory.scala:96); 	at is.hail.annotations.Region.allocate(Region.scala:332); 	at __C35collect_distributed_array.__m61split_ToArray(Unknown Source); 	at __C35collect_distributed_array.__m54split_StreamFor(Unknown Source); 	at __C35collect_distributed_array.__m49begin_group_0(Unknown Source); 	at __C35collect_distributed_array.apply(Unknown Source); 	at __C35collect_distributed_array.apply(Unknown Source); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$2(BackendUtils.scala:31); 	at is.hail.utils.package$.using(package.scala:638); 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$1(BackendUtils.scala:30); 	at is.hail.backend.service.Worker$.$anonfun$main$13(Worker.scala:142); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:77); 	at is.hail.backend.service.Worker$.main(Worker.scala:142); 	at is.hail.backend.service.Main$.main(Main.scala:32); 	at is.hail.backend.service.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11777#issuecomment-1110147573:1270,allocate,allocate,1270,https://hail.is,https://github.com/hail-is/hail/pull/11777#issuecomment-1110147573,1,['allocate'],['allocate']
Energy Efficiency,"rets/ConfigMaps feature to Beta and enable the feature by default.; This allows to set <code>Immutable</code> field in Secrets or ConfigMap object to mark their contents as immutable. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89594"">kubernetes/kubernetes#89594</a>, <a href=""https://github.com/wojtek-t""><code>@​wojtek-t</code></a>) [SIG Apps and Testing]</li>; <li>Remove <code>BindTimeoutSeconds</code> from schedule configuration <code>KubeSchedulerConfiguration</code> (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91580"">kubernetes/kubernetes#91580</a>, <a href=""https://github.com/cofyc""><code>@​cofyc</code></a>) [SIG Scheduling and Testing]</li>; <li>Remove kubescheduler.config.k8s.io/v1alpha1 (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89298"">kubernetes/kubernetes#89298</a>, <a href=""https://github.com/gavinfish""><code>@​gavinfish</code></a>) [SIG Scheduling]</li>; <li>Reserve plugins that fail to reserve will trigger the unreserve extension point (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92391"">kubernetes/kubernetes#92391</a>, <a href=""https://github.com/adtac""><code>@​adtac</code></a>) [SIG Scheduling and Testing]</li>; <li>Resolve regression in <code>metadata.managedFields</code> handling in update/patch requests submitted by older API clients (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91748"">kubernetes/kubernetes#91748</a>, <a href=""https://github.com/apelisse""><code>@​apelisse</code></a>)</li>; <li>Scheduler: optionally check for available storage capacity before scheduling pods which have unbound volumes (alpha feature with the new <code>CSIStorageCapacity</code> feature gate, only works for CSI drivers and depends on support for the feature in a CSI driver deployment) (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92387"">kubernetes/kubernetes#92387</a>, <a href=""https:/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:12110,Schedul,Scheduling,12110,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['Schedul'],['Scheduling']
Energy Efficiency,rettyPrint.Doc.render(PrettyPrintWriter.scala:167); at is.hail.expr.ir.Pretty.sexprStyle(Pretty.scala:466); at is.hail.expr.ir.Pretty.apply(Pretty.scala:429); at is.hail.expr.ir.Pretty$.apply(Pretty.scala:22); at is.hail.expr.ir.Optimize$.apply(Optimize.scala:45); at is.hail.expr.ir.lowering.OptimizePass.transform(LoweringPass.scala:30); at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); at is.hail.expr.ir.lowering.OptimizePass.apply(LoweringPass.scala:26); at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:15); at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:13); at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:13); at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:47); at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:450); at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:486); at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:70); at is.hail.utils.package$.using(package.scala:635); at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:70); at is.hail.utils.package$.using(package.scala:635); at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:59); at is.hail.backend.spark.Sp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13046:3520,adapt,adapted,3520,https://hail.is,https://github.com/hail-is/hail/issues/13046,1,['adapt'],['adapted']
Energy Efficiency,"returned objects fail (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/pull/177"">#177</a>, <a href=""https://github.com/tomplus""><code>@​tomplus</code></a>)</li>; </ul>; <h1>v19.15.0</h1>; <ul>; <li>feat: Kubernetes API Version: v1.19.15</li>; </ul>; <h3>API Change</h3>; <ul>; <li>We have added a new Priority &amp; Fairness rule that exempts all probes (/readyz, /healthz, /livez) to prevent; restarting of &quot;healthy&quot; kube-apiserver instance(s) by kubelet. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/101113"">kubernetes/kubernetes#101113</a>, <a href=""https://github.com/tkashem""><code>@​tkashem</code></a>) [SIG API Machinery]</li>; <li>Fixes using server-side apply with APIService resources (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/100713"">kubernetes/kubernetes#100713</a>, <a href=""https://github.com/kevindelgado""><code>@​kevindelgado</code></a>) [SIG API Machinery, Apps, Scheduling and Testing]</li>; <li>Regenerate protobuf code to fix CVE-2021-3121 (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/100515"">kubernetes/kubernetes#100515</a>, <a href=""https://github.com/joelsmith""><code>@​joelsmith</code></a>) [SIG API Machinery, Auth, CLI, Cloud Provider, Cluster Lifecycle, Instrumentation, Node and Storage]</li>; <li>Kubernetes is now built using go1.15.8 (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/99093"">kubernetes/kubernetes#99093</a>, <a href=""https://github.com/cpanato""><code>@​cpanato</code></a>) [SIG Cloud Provider, Instrumentation, Release and Testing]</li>; <li>Fix conversions for custom metrics. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/94654"">kubernetes/kubernetes#94654</a>, <a href=""https://github.com/wojtek-t""><code>@​wojtek-t</code></a>) [SIG Instrumentation]</li>; <li>A new alpha-level field, <code>SupportsFsGroup</code>, has been introduced for CSIDrivers to allow th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:1370,Schedul,Scheduling,1370,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['Schedul'],['Scheduling']
Energy Efficiency,rg.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:344); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: is.hail.utils.HailException: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.io.LoadMatrixParser.parseLine(LoadMatrix.scala:33); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:383); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:377); 	at is.hail.utils.WithContext.wrap(Context.scala:41); 	... 30 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1575); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1563); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1562); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1562); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1790); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:6018,schedul,scheduler,6018,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['schedul'],['scheduler']
Energy Efficiency,rg.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1134); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1134); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1899); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882:4036,schedul,scheduler,4036,https://hail.is,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882,1,['schedul'],['scheduler']
Energy Efficiency,rg.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2254); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2203); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2202); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2202); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2441); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2383); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2372); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2202); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2223); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2242); 	at is.hail.sparkextras.ContextRDD.runJob(Cont,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:8466,schedul,scheduler,8466,https://hail.is,https://github.com/hail-is/hail/issues/10682,1,['schedul'],['scheduler']
Energy Efficiency,rg.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:501); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1124); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2491); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2433); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2422); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:902); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2204); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2225); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2257); 	at is.hail.sparkextras.ContextRDD.crunJobWith,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12532:6334,schedul,scheduler,6334,https://hail.is,https://github.com/hail-is/hail/issues/12532,1,['schedul'],['scheduler']
Energy Efficiency,rixTable.selectRows(MatrixTable.scala:1168); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)java.lang.NegativeArraySizeException: null; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:140); 	at is.hail.annotations.Region.allocate(Region.scala:153); 	at is.hail.annotations.Region.allocate(Region.scala:160); 	at is.hail.codegen.generated.C11.apply(Unknown Source); 	at is.hail.codegen.generated.C11.apply(Unknown Source); 	at is.hail.io.CompiledPackDecoder.readRegionValue(RowStore.scala:650); 	at is.hail.HailContext$$anon$2.next(HailContext.scala:245); 	at is.hail.HailContext$$anon$2.next(HailContext.scala:218); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.sparkextras.ContextRDD$$anonfun$czip$1$$anon$1.next(ContextRDD.scala:333); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:915); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:909); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.hasNext(OrderedRVD.scala:912); 	at scal,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3583:11568,allocate,allocate,11568,https://hail.is,https://github.com/hail-is/hail/issues/3583,1,['allocate'],['allocate']
Energy Efficiency,"rk releases</li>; <li><a href=""https://github.com/apache/spark/commit/001d8b0cddcec46a44e7c6e31612dc2baada05d5""><code>001d8b0</code></a> [SPARK-37554][BUILD] Add PyArrow, pandas and plotly to release Docker image d...</li>; <li><a href=""https://github.com/apache/spark/commit/9dd4c07475c82f922c29d67a4db4bb42676c5c07""><code>9dd4c07</code></a> [SPARK-37730][PYTHON][FOLLOWUP] Split comments to comply pycodestyle check</li>; <li><a href=""https://github.com/apache/spark/commit/bc54a3f0c2e08893702c3929bfe7a9d543a08cdb""><code>bc54a3f</code></a> [SPARK-37730][PYTHON] Replace use of MPLPlot._add_legend_handle with MPLPlot....</li>; <li><a href=""https://github.com/apache/spark/commit/c5983c1691f20590abf80b17bdc029b584b89521""><code>c5983c1</code></a> [SPARK-38018][SQL][3.2] Fix ColumnVectorUtils.populate to handle CalendarInte...</li>; <li><a href=""https://github.com/apache/spark/commit/32aff86477ac001b0ee047db08591d89e90c6eb8""><code>32aff86</code></a> [SPARK-39447][SQL][3.2] Avoid AssertionError in AdaptiveSparkPlanExec.doExecu...</li>; <li><a href=""https://github.com/apache/spark/commit/be891ad99083564a7bf7f421e00b2cc4759a679f""><code>be891ad</code></a> [SPARK-39551][SQL][3.2] Add AQE invalid plan check</li>; <li><a href=""https://github.com/apache/spark/commit/1c0bd4c15a28d7c6a2dca846a5b8d0eb1d152aae""><code>1c0bd4c</code></a> [SPARK-39656][SQL][3.2] Fix wrong namespace in DescribeNamespaceExec</li>; <li><a href=""https://github.com/apache/spark/commit/3d084fe3217bea9af4c544f10ead8a2e5b97dad4""><code>3d084fe</code></a> [SPARK-39677][SQL][DOCS][3.2] Fix args formatting of the regexp and like func...</li>; <li>Additional commits viewable in <a href=""https://github.com/apache/spark/compare/v3.1.3...v3.2.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyspark&package-manager=pip&previous-version=3.1.3&new-version=3.2.2)](https://docs.github.com/en/github/managing-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12452:1466,Adapt,AdaptiveSparkPlanExec,1466,https://hail.is,https://github.com/hail-is/hail/pull/12452,1,['Adapt'],['AdaptiveSparkPlanExec']
Energy Efficiency,rk$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Unsupported/Unknown Elasticsearch version 6.0.0; 	at org.elasticsearch.hadoop.util.EsMajorVersion.parse(EsMajorVersion.java:79); 	at org.elasticsearch.hadoop.rest.RestClient.remoteEsVersion(RestClient.java:613); 	at org.elasticsearch.hadoop.rest.InitializationUtils.discoverEsVersion(InitializationUtils.java:240); 	... 10 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apa,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4138:3133,schedul,scheduler,3133,https://hail.is,https://github.com/hail-is/hail/issues/4138,1,['schedul'],['scheduler']
Energy Efficiency,rk.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:250); 	at org.apache.spark.Partitioner$$anonfun$defaultPartitioner$2.apply(Partitioner.scala:66); 	at org.apache.spark.Partitioner$$anonfun$defaultPartitioner$2.apply(Partitioner.scala:66); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.immutable.List.map(List.scala:285); 	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:66); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:329); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:329); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:328); 	at is.hail.methods.MendelErrors.nErrorPerNuclearFamily(MendelErrors.scala:144); 	at is.hail.methods.MendelErrors.fMendelKT(MendelErrors.scala:183); 	at is.hail.variant.MatrixTable.mendelErrors(MatrixTable.scala:1915); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3039:10307,reduce,reduceByKey,10307,https://hail.is,https://github.com/hail-is/hail/issues/3039,1,['reduce'],['reduceByKey']
Energy Efficiency,rk.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:250); 	at org.apache.spark.Partitioner$$anonfun$defaultPartitioner$2.apply(Partitioner.scala:66); 	at org.apache.spark.Partitioner$$anonfun$defaultPartitioner$2.apply(Partitioner.scala:66); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.immutable.List.map(List.scala:285); 	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:66); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:329); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:329); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:328); 	at is.hail.methods.MendelErrors.nErrorPerNuclearFamily(MendelErrors.scala:145); 	at is.hail.methods.MendelErrors.fMendelKT(MendelErrors.scala:184); 	at is.hail.variant.MatrixTable.mendelErrors(MatrixTable.scala:1913); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3074#issuecomment-370494908:8992,reduce,reduceByKey,8992,https://hail.is,https://github.com/hail-is/hail/issues/3074#issuecomment-370494908,1,['reduce'],['reduceByKey']
Energy Efficiency,roadinstitute.hail.driver.AnnotateVariantsExpr$$anonfun$2.apply(AnnotateVariantsExpr.scala:64); at org.broadinstitute.hail.variant.VariantSampleMatrix$$anonfun$25.apply(VariantSampleMatrix.scala:423); at org.broadinstitute.hail.variant.VariantSampleMatrix$$anonfun$25.apply(VariantSampleMatrix.scala:423); at org.broadinstitute.hail.RichPairRDD$$anonfun$mapValuesWithKey$extension$1$$anonfun$apply$5.apply(Utils.scala:459); at org.broadinstitute.hail.RichPairRDD$$anonfun$mapValuesWithKey$extension$1$$anonfun$apply$5.apply(Utils.scala:459); at scala.collection.Iterator$$anon$11.next(Iterator.scala:328); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1555); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1125); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1125); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1850); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:1850); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); at org.apache.spark.scheduler.Task.run(Task.scala:88); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1283); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1270); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1270); at org.apache.spark.scheduler,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/660#issuecomment-242218633:5487,schedul,scheduler,5487,https://hail.is,https://github.com/hail-is/hail/issues/660#issuecomment-242218633,1,['schedul'],['scheduler']
Energy Efficiency,rom a bad node: container_e01_1690206305672_0001_01_000007 on host: all-of-us-1774-w-0.c.terra-vpc-sc-23dfb1a3.internal. Exit status: 137. Diagnostics: [2023-07-24 13:52:49.515]Container killed on request. Exit code is 137; [2023-07-24 13:52:49.517]Container exited with a non-zero exit code 137. ; [2023-07-24 13:52:49.518]Killed by external signal; .; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1124); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2491); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2433); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2422); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:902); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2204); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2225); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2244); 	at org.apache.spark.SparkContext.runJob(Spark,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287:6997,schedul,scheduler,6997,https://hail.is,https://github.com/hail-is/hail/issues/13287,1,['schedul'],['scheduler']
Energy Efficiency,"rotating log: https://stackoverflow.com/questions/40636021/how-to-list-kubernetes-recently-deleted-pods . For users, and for investors, we want to have a permanent record of all user interactions. * Some kinds of data may be awkward to store and query within pod labels. For instance, how much user state do we want to store in labels? How do we store operation graphs / history?; ; * aggregation operations across users or resources; * a given, or all users' history: so the user can manage, see, so we can track (some, gross) metrics for billing; * various sorting operations (by date/time, etc); * full log of state for a given set of related resources (I think k8 stores last 5 events, this is probably configurable) ; ability to retry in a user-controlled way, even if pod is deleted from etcd. * Operations across N k8 resources seems like it may take up to N queries (i.e k8s.list_namespaced_service, k8s.list_namespaced_pod). There may be more efficient ways of handling this (there either is, or should be a way of querying one selector across all resources). . * Performance, even for very basic queries. An initial assumption, may prove to be incorrect, but I think we will find a fast db to be much faster than K8, even if we could directly query etcd. This is based on my experience with Amazon data stores, and general impression/experience with google cs products.; * Open issue on this: even directly accessed, etcd is slow, doesn't index selectors https://github.com/kubernetes/kubernetes/issues/4817. * We may want to differentiate between k8 outages and lack of user requests. I also want to be able to quickly present a potential investor aggregate data, for notebook and all other manner of hail services: for notebook case: # notebooks created, length a notebook was used, how many notebooks were shared with others (I think this could be a useful feature, even if ""sharing"" meant taking a user-opt-in text dump that could be used to re-create a notebook, rather than connecting ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5215#issuecomment-459054290:1958,efficient,efficient,1958,https://hail.is,https://github.com/hail-is/hail/pull/5215#issuecomment-459054290,1,['efficient'],['efficient']
Energy Efficiency,rovided VCF file is malformed at approximately line number 458249: unparsable vcf record with allele M; 	at htsjdk.variant.vcf.AbstractVCFCodec.generateException(AbstractVCFCodec.java:783); 	at htsjdk.variant.vcf.AbstractVCFCodec.checkAllele(AbstractVCFCodec.java:569); 	at htsjdk.variant.vcf.AbstractVCFCodec.parseAlleles(AbstractVCFCodec.java:531); 	at htsjdk.variant.vcf.AbstractVCFCodec.parseVCFLine(AbstractVCFCodec.java:336); 	at htsjdk.variant.vcf.AbstractVCFCodec.decodeLine(AbstractVCFCodec.java:279); 	at htsjdk.variant.vcf.AbstractVCFCodec.decode(AbstractVCFCodec.java:257); 	at is.hail.io.vcf.LoadVCF$$anonfun$13.apply(LoadVCF.scala:850); 	at is.hail.io.vcf.LoadVCF$$anonfun$13.apply(LoadVCF.scala:849); 	at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:718); 	... 17 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3015:2816,schedul,scheduler,2816,https://hail.is,https://github.com/hail-is/hail/issues/3015,1,['schedul'],['scheduler']
Energy Efficiency,rray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2202); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2441); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2383); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2372); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2202); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2223); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2242); 	at is.hail.sparkextras.ContextRDD.runJob(ContextRDD.scala:362); 	at is.hail.rvd.RVD.$anonfun$head$1(RVD.scala:526); 	at is.hail.utils.PartitionCounts$.incrementalPCSubsetOffset(PartitionCounts.scala:73); 	at is.hail.rvd.RVD.head(RVD.scala:526); 	at is.hail.expr.ir.TableSubset.execute(TableIR.scala:1380); 	at is.hail.expr.ir.TableSubset.execute$(TableIR.scala:1377); 	at is.hail.expr.ir.TableHead.execute(TableIR.scala:1386); 	at is.hail.expr.ir.TableMapRows.execute(TableIR.scala:1905); 	at is.hail.expr.ir.Interpret$.run(Interpret.scala:784); 	at is.hail.expr.ir.Interpret$.alreadyLowered(Interpret.scala:56); 	at is.hail.expr.ir.InterpretNonCompilable$.interpretAndCoerce$1(InterpretNonCompilable.scala:16); 	at is.hail.expr.ir.InterpretNonComp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:9169,schedul,scheduler,9169,https://hail.is,https://github.com/hail-is/hail/issues/10682,1,['schedul'],['scheduler']
Energy Efficiency,rray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1124); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2491); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2433); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2422); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:902); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2204); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2225); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2244); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2269); 	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029); 	at is.hail.backend.spark.SparkBackend.parallelizeAndComputeWithIndex(SparkBackend.scala:355); 	at is.hail.backend.BackendUtils.collectDArray(BackendUtils.scala:43); 	at __C16570Compiled.__m16792split_CollectDistributedArray(Emit.scala); 	at __C16570Compiled.__m16791begin_group_0(Emit.scala); 	at __C16570Compiled.apply(Emit.scala); 	at is,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287#issuecomment-1664593619:6405,schedul,scheduler,6405,https://hail.is,https://github.com/hail-is/hail/issues/13287#issuecomment-1664593619,1,['schedul'],['scheduler']
Energy Efficiency,rray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1124); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2491); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2433); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2422); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:902); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2204); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2225); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2244); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2269); 	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029); 	at is.hail.backend.spark.SparkBackend.parallelizeAndComputeWithIndex(SparkBackend.scala:355); 	at is.hail.backend.BackendUtils.collectDArray(BackendUtils.scala:43); 	at __C793Compiled.__m916begin_group_0(Emit.scala); 	at __C793Compiled.__m794split_Let(Emit.scala); 	at __C793Compiled.apply(Emit.scala); 	at is.hail.expr.ir.CompileAndEvalua,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287:7700,schedul,scheduler,7700,https://hail.is,https://github.com/hail-is/hail/issues/13287,1,['schedul'],['scheduler']
Energy Efficiency,rray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1124); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2491); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2433); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2422); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:902); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2204); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2225); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2244); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2269); 	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029); 	at is.hail.sparkextras.ContextRDD.collect(ContextRDD.scala:176); 	at is.hail.utils.richUtils.RichContextRDD.writePartitions(RichContextRDD.scala:105); 	at is.hail.utils.richUtils.RichRDD$.writePartitions$extension(RichRDD.scala:209); 	at is.hail.linalg.BlockMatrix.write(BlockMatrix.scala:871); 	at is.hail.expr.ir.BlockMatrixNativeWriter.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12290:3441,schedul,scheduler,3441,https://hail.is,https://github.com/hail-is/hail/issues/12290,1,['schedul'],['scheduler']
Energy Efficiency,rray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1124); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2491); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2433); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2422); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:902); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2204); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2225); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2257); 	at is.hail.sparkextras.ContextRDD.crunJobWithIndex(ContextRDD.scala:238); 	at is.hail.rvd.RVD$.getKeyInfo(RVD.scala:1233); 	at is.hail.rvd.RVD$.makeCoercer(RVD.scala:1308); 	at is.hail.rvd.RVD$.coerce(RVD.scala:1264); 	at is.hail.rvd.RVD.changeKey(RVD.scala:144); 	at is.hail.rvd.RVD.changeKey(RVD.scala:137); 	at is.hail.backend.spark.SparkBackend.lowerDistributedSort(SparkBackend.scala:722); 	at is.hail.expr.ir.lowering.LowerTableIR$.applyTable(LowerTableIR.scala:875); 	at is.hail.expr.ir.lowering.LowerTableIR$.lower$2(LowerTableIR.scala:731); 	at is.hail.expr.ir.lowering.LowerTableIR$.applyTable(LowerTableIR.scala:1216); 	at is.hail.expr.ir.lowering.LowerTableIR$.lower$1(LowerTableIR.scala:493); 	at is.hail.expr.ir.lowering.LowerTableIR$,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12532:7037,schedul,scheduler,7037,https://hail.is,https://github.com/hail-is/hail/issues/12532,1,['schedul'],['scheduler']
Energy Efficiency,rray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2608); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2861); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2792); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2257); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2276); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2301); 	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1021); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:1020); 	at is.hail.sparkextras.ContextRDD.collect(ContextRDD.scala:176); 	at is.hail.utils.richUtils.RichContextRDD.writePartitions(RichContextRDD.scala:105); 	at is.hail.io.RichContextRDDLong$.writeRows$extension(RichContextRDDRegionValue.scala:234); 	at is.hail.rvd.RVD.write(RVD.scala:779); 	at is.hail.expr.ir.TableNativeWriter.apply(TableWrit,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12936:6334,schedul,scheduler,6334,https://hail.is,https://github.com/hail-is/hail/issues/12936,1,['schedul'],['scheduler']
Energy Efficiency,rray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2608); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2861); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2792); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2257); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2289); 	at is.hail.sparkextras.ContextRDD.crunJobWithIndex(ContextRDD.scala:238); 	at is.hail.rvd.RVD$.getKeyInfo(RVD.scala:1029); 	at is.hail.rvd.RVD$.makeCoercer(RVD.scala:1104); 	at is.hail.rvd.RVD$.coerce(RVD.scala:1060); 	at is.hail.rvd.RVD.changeKey(RVD.scala:142); 	at is.hail.rvd.RVD.changeKey(RVD.scala:135); 	at is.hail.backend.spark.SparkBackend.lowerDistributedSort(SparkBackend.scala:716); 	at is.hail.backend.Backend.lowerDistributedSort(Backend.scala:143); 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.$anonfun$apply$1(LowerAndExecuteShuffles.scala:17); 	at is.hail.expr.ir.RewriteBottomUp$.$anonfun$apply$2(RewriteBottomUp.scala:11); 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:60); 	at is.hail.utils.StackSafe$.run(St,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:11197,schedul,scheduler,11197,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['schedul'],['scheduler']
Energy Efficiency,rray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2652); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1189); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1189); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1189); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2913); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2855); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2844); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:959); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2282); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2301); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2326); 	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1021); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:1020); 	at is.hail.backend.spark.SparkBackend.parallelizeAndComputeWithIndex(SparkBackend.scala:429); 	at is.hail.backend.BackendUtils.collectDArray(BackendUtils.scala:82); 	at __C1286Compiled.__m1290split_Block_region18_70(Emit.scala); 	at __C1286Compiled.__m1290split_Block(Emit.scala); 	at __C1286Compiled.apply(Emit.scala); 	at is.hail.expr.ir,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:9510,schedul,scheduler,9510,https://hail.is,https://github.com/hail-is/hail/issues/14513,1,['schedul'],['scheduler']
Energy Efficiency,"rrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750); ```. The driver will have log output like this:; ```; 2023-09-22 19:11:13.051 Requester: INFO: request GET http://batch.hail/api/v1alpha/batches/8042383 response 200; 2023-09-22 19:11:13.052 ServiceBackend$: INFO: parallelizeAndComputeWithIndex: O3mcL5QoyfBBMz0eSi7uIjGQkV3FuD5vCON_8i4r0ss=: reading results; 2023-09-22 19:11:13.125 ServiceBackend$: INFO: all results read. 0.072746861 s. 0.0 result/s. 0.0 MiB/s.; 2023-09-22 19:11:13.125 : INFO: [collectDArray|table_native_writer]: executed 5 tasks in 1.822s; 2023-09-22 19:11:13.126 : INFO: RegionPool: initialized for thread 10: pool-2-thread-2; 2023-09-22 19:11:13.126 : INFO: TaskReport: stage=0, partition=0, attempt=0, peakBytes=0, peakBytesReadable=0.00 B, chunks requested=0, cache hits=0; 2023-09-22 19:11:13.126 : INFO: RegionPool: FREE: 0 allocated (0 blocks / 0 chunks), regions.size = 0, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-22 19:11:13.127 : INFO: RegionPool: initialized for thread 10: pool-2-thread-2; 2023-09-22 19:11:13.127 : INFO: TaskReport: stage=0, partition=0, attempt=0, peakBytes=0, peakBytesReadable=0.00 B, chunks requested=0, cache hits=0; 2023-09-22 19:11:13.127 : INFO: RegionPool: FREE: 0 allocated (0 blocks / 0 chunks), regions.size = 0, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-22 19:11:13.127 : INFO: RegionPool: FREE: 128.0K allocated (128.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-22 19:11:13.138 : ERROR: GoogleJsonResponseException: 404 Not Found; GET https://storage.googleapis.com/download/storage/v1/b/1-day/o/parallelizeAndComputeWithIndex%2FO3mcL5QoyfBBMz0eSi7uIjGQkV3FuD5vCON_8i4r0ss=%2Fresult.0?alt=media; No such object: 1-day/parallelizeAndComputeWithIndex/O3mcL5QoyfBBMz0eSi7uIjGQkV3FuD5vCON_8i4r0ss=/resu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:3260,allocate,allocated,3260,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['allocate'],['allocated']
Energy Efficiency,rrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:178); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:222); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	... 11 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:3177,schedul,scheduler,3177,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807,1,['schedul'],['scheduler']
Energy Efficiency,rrentBroadcast.scala:178); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:222); 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); 	... 11 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:3275,schedul,scheduler,3275,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807,1,['schedul'],['scheduler']
Energy Efficiency,rsableOnce$class.to(TraversableOnce.scala:310). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); at org.apache.spark.rdd.RDD.collect(RDD.sc,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4755#issuecomment-438447635:5930,schedul,scheduler,5930,https://hail.is,https://github.com/hail-is/hail/issues/4755#issuecomment-438447635,1,['schedul'],['scheduler']
Energy Efficiency,rtitionsRDD.compute(MapPartitionsRDD.scala:38). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094); at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:926); at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:924); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.ap,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:10584,schedul,scheduler,10584,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['schedul'],['scheduler']
Energy Efficiency,"run_result = self._backend._run(self, dry_run, verbose, delete_scratch_on_exit, **backend_kwargs) # pylint: disable=assignment-from-no-return; batch/backend.py:475: in _run; self._async_run(batch, dry_run, verbose, delete_scratch_on_exit, wait, open, disable_progress_bar, callback, token, **backend_kwargs)); utils/utils.py:127: in async_to_blocking; return asyncio.get_event_loop().run_until_complete(coro); /usr/local/lib/python3.7/dist-packages/nest_asyncio.py:63: in run_until_complete; return self._run_until_complete_orig(future); /usr/lib/python3.7/asyncio/base_events.py:574: in run_until_complete; self.run_forever(); /usr/lib/python3.7/asyncio/base_events.py:541: in run_forever; self._run_once(); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <_UnixSelectorEventLoop running=False closed=False debug=False>. def _run_once(self):; """"""Run one full iteration of the event loop.; ; This calls all currently ready callbacks, polls for I/O,; schedules the resulting callbacks, and finally schedules; 'call_later' callbacks.; """"""; ; sched_count = len(self._scheduled); if (sched_count > _MIN_SCHEDULED_TIMER_HANDLES and; self._timer_cancelled_count / sched_count >; _MIN_CANCELLED_TIMER_HANDLES_FRACTION):; # Remove delayed calls that were cancelled if their number; # is too high; new_scheduled = []; for handle in self._scheduled:; if handle._cancelled:; handle._scheduled = False; else:; new_scheduled.append(handle); ; heapq.heapify(new_scheduled); self._scheduled = new_scheduled; self._timer_cancelled_count = 0; else:; # Remove delayed calls that were cancelled from head of queue.; while self._scheduled and self._scheduled[0]._cancelled:; self._timer_cancelled_count -= 1; handle = heapq.heappop(self._scheduled); handle._scheduled = False; ; timeout = None; if self._ready or self._stopping:; timeout = 0; elif self._scheduled:; # Compute the desired timeout.; when = self._scheduled[0]._when; timeout = min(max(0, when - self.time()), MAXIMUM",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10705:1605,schedul,schedules,1605,https://hail.is,https://github.com/hail-is/hail/pull/10705,2,['schedul'],['schedules']
Energy Efficiency,rvd.RVD$$anonfun$aggregateWithPartitionOp$1.apply(RVD.scala:558); 	at is.hail.rvd.RVD$$anonfun$aggregateWithPartitionOp$1.apply(RVD.scala:558); 	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2125); 	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2125); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:344); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1575); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1563); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1562); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1562); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1790); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1745); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1734); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5846:6402,schedul,scheduler,6402,https://hail.is,https://github.com/hail-is/hail/issues/5846,1,['schedul'],['scheduler']
Energy Efficiency,"ry': '500M'}},\n 'security_context': None,\n 'stdin': None,\n 'stdin_once': None,\n 'termination_message_path': '/dev/termination-log',\n 'termination_message_policy': 'File',\n 'tty': None,\n 'volume_devices': None,\n 'volume_mounts': [{'mount_path': '/gsa-key',\n 'mount_propagation': None,\n 'name': 'gsa-key',\n 'read_only': None,\n 'sub_path': None},\n {'mount_path': '/var/run/secrets/kubernetes.io/serviceaccount',\n 'mount_propagation': None,\n 'name': 'default-token-brr2f',\n 'read_only': True,\n 'sub_path': None}],\n 'working_dir': None}],\n 'dns_config': None,\n 'dns_policy': 'ClusterFirst',\n 'enable_service_links': True,\n 'host_aliases': None,\n 'host_ipc': None,\n 'host_network': None,\n 'host_pid': None,\n 'hostname': None,\n 'image_pull_secrets': None,\n 'init_containers': None,\n 'node_name': 'gke-vdc-preemptible-pool-9c7148b2-8hq5',\n 'node_selector': None,\n 'priority': 500000,\n 'priority_class_name': 'user',\n 'readiness_gates': None,\n 'restart_policy': 'Never',\n 'runtime_class_name': None,\n 'scheduler_name': 'default-scheduler',\n 'security_context': {'fs_group': None,\n 'run_as_group': None,\n 'run_as_non_root': None,\n 'run_as_user': None,\n 'se_linux_options': None,\n 'supplemental_groups': None,\n 'sysctls': None},\n 'service_account': 'default',\n 'service_account_name': 'default',\n 'share_process_namespace': None,\n 'subdomain': None,\n 'termination_grace_period_seconds': 30,\n 'tolerations': [{'effect': None,\n 'key': 'preemptible',\n 'operator': None,\n 'toleration_seconds': None,\n 'value': 'true'},\n {'effect': 'NoExecute',\n 'key': 'node.kubernetes.io/not-ready',\n 'operator': 'Exists',\n 'toleration_seconds': 300,\n 'value': None},\n {'effect': 'NoExecute',\n 'key': 'node.kubernetes.io/unreachable',\n 'operator': 'Exists',\n 'toleration_seconds': 300,\n 'value': None}],\n 'volumes': [{'aws_elastic_block_store': None,\n 'azure_disk': None,\n 'azure_file': None,\n 'cephfs': None,\n 'cinder': None,\n 'config_map': None,\n 'downward_ap",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6616:3853,schedul,scheduler,3853,https://hail.is,https://github.com/hail-is/hail/issues/6616,2,['schedul'],['scheduler']
Energy Efficiency,ry/client/v1/__pycache__/docker_image_.cpython-39.pyc; /usr/lib/google-cloud-sdk/lib/third_party/containerregistry/client/v1/__pycache__/docker_http_.cpython-39.pyc; /usr/lib/google-cloud-sdk/lib/third_party/containerregistry/client/__pycache__/docker_creds_.cpython-39.pyc; /usr/lib/google-cloud-sdk/lib/third_party/containerregistry/client/__pycache__/docker_name_.cpython-39.pyc; /usr/lib/google-cloud-sdk/lib/third_party/containerregistry/tools/docker_puller_.py; /usr/lib/google-cloud-sdk/lib/third_party/containerregistry/tools/docker_pusher_.py; /usr/lib/google-cloud-sdk/lib/third_party/containerregistry/tools/docker_appender_.py; /usr/lib/google-cloud-sdk/lib/third_party/containerregistry/tools/__pycache__/docker_appender_.cpython-39.pyc; /usr/lib/google-cloud-sdk/lib/third_party/containerregistry/tools/__pycache__/docker_puller_.cpython-39.pyc; /usr/lib/google-cloud-sdk/lib/third_party/containerregistry/tools/__pycache__/docker_pusher_.cpython-39.pyc; /usr/local/share/google/dataproc/npd-config/docker-monitor-counter.json; /usr/local/share/google/dataproc/npd-config/docker-monitor.json; /usr/local/share/google/dataproc/npd-config/health-checker-docker.json; /usr/local/share/google/dataproc/npd-config/docker-monitor-filelog.json; /usr/local/share/google/dataproc/bdutil/fluentd/container_logging/plugin/test/Dockerfile; /usr/local/share/google/dataproc/bdutil/components/initialize/docker-ce.sh; /usr/local/share/google/dataproc/bdutil/components/install/docker-ce.sh; /usr/local/share/google/dataproc/bdutil/components/uninstall/docker-ce.sh; /usr/local/share/google/dataproc/bdutil/components/post-install/docker-ce.sh; /usr/local/share/google/dataproc/bdutil/components/activate/docker-ce.sh; /usr/local/share/google/dataproc/bdutil/components/shared/docker.sh; /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/docker-ce.sh; /usr/local/share/google/dataproc/bdutil/configure_docker.sh; /run/docker.sock; /tmp/dataproc/uninstall/docker-ce; /tmp/dataproc/compon,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12936#issuecomment-1709120751:11657,monitor,monitor-counter,11657,https://hail.is,https://github.com/hail-is/hail/issues/12936#issuecomment-1709120751,1,['monitor'],['monitor-counter']
Energy Efficiency,"s a reduced SVD of `A`. This is implemented in `KrylovFactorization.reduced_svd`. # Spectral moments; We can also easily compute estimates of spectral moments, i.e. moments of the set of all eigenvalues of `A'A`. The estimator exploits the following key facts:; * If `v` is a random vector of independent entries with mean 0, std. dev. 1 (equivalently `E(v) = 0`, `E(vv') = I`), then `E(v'Xv) = tr(X)`; * `tr(X)` equals the sum of the eigenvalues of `X`, `∑_i 𝜆_i`. More generally, if `f` is any matrix function, `tr(f(X)) = ∑_i f(𝜆_i)`.; * If `w` is a unit-norm vector, and `UR = AV` is the factorization `_krylov_factorization(A, w, p)`, then `w' f(A'A) w` is well-approximated by `w' f(VV'A'AVV') w = w'V f(R'U'UR) V'w = w'V f(R'R) V'w`, and is exact if `f` is a degree `2p+1` polynomial. Moreover, since `w` is the first column of `V`, i.e. `w = Ve_1`, the above further simplifies `w'V f(R'R) V'w = e'_1 f(R'R) e_1`. Finally, if `R = U_1 S V'_1` is an SVD, this reduces to `e'_1 f(R'R) e_1 = e'_1 f(V_1 S^2 V'_1) e_1 = e'_1 V_1 f(S^2) V'_1 e_1 = V_1[0, :] f(S^2) V_1[0, :]'`.; * The previous bullet has a block generalization. If `W` is an orthonormal matrix with `k` columns, and `UR = AV` is the factorization `_krylov_factorization(A, W, p)`, and `R = U_1 S V'_1` is an SVD, then `W' f(A'A) W` is well-approximated by `V_1[:k, :] f(S^2) V_1[:k, :]'`, and this is exact if `f` is a degree-p polynomial. We can combine the above into an estimator for the p-th spectral moment, `𝜇_p = ∑_i 𝜆_i^p`. We get an unbiased estimator by generating a random vector `v`, and using `E(v' (A'A)^p v) = tr((A'A)^p) = 𝜇_p`. The estimator can be computed exactly using the Krylov factorization as above, i.e. `v' (A'A)^p v = V_1[0, :] S^{2p} V_1[0, :]'`. But this estimator has large variance, so we can just average over many independent estimators. We combine `k` random vectors into a random matrix `V_0`, compute `_krylov_factorization(A, V_0, p)`, and then `V'_0 (A'A)^p V_0 = V_1[:k, :] f(S^2) V_1[:k, :]'",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11045:1994,reduce,reduces,1994,https://hail.is,https://github.com/hail-is/hail/pull/11045,1,['reduce'],['reduces']
Energy Efficiency,"s the problem):. `ukbb_in_tgp = ukbb.filter_rows(hl.is_defined(tgp[ukbb.row_key, :]))`. ```; FatalError: ClassCastException: null. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 40.0 failed 20 times, most recent failure: Lost task 0.19 in stage 40.0 (TID 2222, pca-w-8.c.daly-ibd.internal, executor 25): java.lang.ClassCastException. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); at org.apache.spark.SparkContext.runJob(SparkContext.sca",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3447:1150,schedul,scheduler,1150,https://hail.is,https://github.com/hail-is/hail/issues/3447,1,['schedul'],['scheduler']
Energy Efficiency,s.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$22$$anonfun$apply$23.apply(ContextRDD.scala:310); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.hasNext(OrderedRVD.scala:1015); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.utils.package$.getIteratorSizeWithMaxN(package.scala:357); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:444); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:444); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:471); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:469); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.sp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4055:5191,schedul,scheduler,5191,https://hail.is,https://github.com/hail-is/hail/issues/4055,1,['schedul'],['scheduler']
Energy Efficiency,s.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5$$anonfun$apply$6.apply(ContextRDD.scala:129); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5$$anonfun$apply$6.apply(ContextRDD.scala:129); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-c37301a; Error summary: IllegalArgumentException: requirement failed; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3465:18085,schedul,scheduler,18085,https://hail.is,https://github.com/hail-is/hail/issues/3465,2,['schedul'],['scheduler']
Energy Efficiency,s.map(TraversableLike.scala:234); 	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); 	at is.hail.io.vcf.FormatParser$.apply(LoadVCF.scala:470); 	at is.hail.io.vcf.ParseLineContext.getFormatParser(LoadVCF.scala:551); 	at is.hail.io.vcf.LoadVCF$$anonfun$14.apply(LoadVCF.scala:886); 	at is.hail.io.vcf.LoadVCF$$anonfun$14.apply(LoadVCF.scala:869); 	at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:737); 	... 34 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkConte,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3467:5204,schedul,scheduler,5204,https://hail.is,https://github.com/hail-is/hail/issues/3467,1,['schedul'],['scheduler']
Energy Efficiency,s.scala:1360) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748); 			at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1891); 			at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 			at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1878); 			at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 			at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 			at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1878); 			at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1495); 			at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2109); 			at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); 			at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); 			at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 			at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); 			at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 			at org.apache.spark.SparkContext.runJob(SparkContext.scala:2158); 			at is.hail.rvd.RVD.combine(RVD.scala:688); 			at is.hail.expr.ir.Interpret$.run(Interpret.scala:804); 			at is.hail.expr.ir.Interpret$.alreadyLowered(Interpret.scala:53); 			at is.hail.expr.ir.InterpretNonCompilable$.interpretAndCoerce$1(InterpretNonCompilable.scala:16); 			at is.hail.expr.ir.InterpretNonCompilable$.is$hail$expr$ir$InterpretNonCompilable$$rewrite$1(InterpretNonCompilable.scala:53); 			at is.hail.expr.ir.InterpretNonCompil,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944:11495,schedul,scheduler,11495,https://hail.is,https://github.com/hail-is/hail/issues/8944,1,['schedul'],['scheduler']
Energy Efficiency,"s: Code[Long], mb: MethodBuilder): Code[Unit]. def copyColumnMajorToRowMajor(colMajorAddress: Code[Long], targetAddress: Code[Long], nRows: Code[Long], nCols: Code[Long], mb: MethodBuilder): Code[Unit]; ```. - Interconvert between column and row major. ```scala; def construct(flags: Code[Int], offset: Code[Int], shapeBuilder: (StagedRegionValueBuilder => Code[Unit]),; stridesBuilder: (StagedRegionValueBuilder => Code[Unit]), data: Code[Long], mb: MethodBuilder): Code[Long]; }; ```. - Construct the NDArray off-heap. ```scala; def arrayFundamentalType: PArray; ```. - The underlying array representation. ## <a name=""parray""></a> PCanonicalNDArray. A PCanonicalArray-backed NDArray. # <a name=""ptuple"">PTuple</a>. An immutible, collection of ordered values, whose elements may be of different types. ## Core methods. ```scala; val _types: IndexedSeq[PTupleField]; ```. - The ordered representation of physical types that represent this collection. ```scala; def allocate(region: Region): Long; def allocate(region: Code[Region]): Code[Long]; ```. - Allocate enough memory off-heap to store the requested elements. ```scala; def initialize(address: Long, setMissing: Boolean = false): Unit; def stagedInitialize(address: Code[Long], setMissing: Boolean = false): Code[Unit]; ```; - Set element missingness and store element length. ```scala; def isFieldDefined(address: Long, fieldIdx: Int): Boolean; def isFieldDefined(address: Code[Long], fieldIdx: Code[Int]): Boolean; ```. ```scala; def setFieldMissing(address: Long, fieldIdx: Int): Unit; def setFieldMissing(address: Code[Long], fieldIdx: Int): Code[Unit]. def setFieldPresent(address: Long, fieldIdx: Int): Unit; def setFieldPresent(address: Code[Long], fieldIdx: Int): Code[Unit]; }; ```; - Set field present of missing at a given memory address. ```scala; def loadField(address: Long, fieldIdx: Int): Long; def loadField(address: Code[Long], fieldIdx: Int): Code[Long]; ```; - Load field at a given memory address. ```scala; def storeField",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7988:8455,allocate,allocate,8455,https://hail.is,https://github.com/hail-is/hail/issues/7988,2,['allocate'],['allocate']
Energy Efficiency,"s=""analysis_type=SelectVariants input_file=[] read_buffer_size=null phone_home=STANDARD gatk_key=null tag=NA read_filter=[] intervals=[/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.padded.interval_list] excludeIntervals=null interval_set_rule=UNION interval_merging=ALL interval_padding=0 reference_sequence=/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.fasta nonDeterministicRandomSeed=false disableRandomization=false maxRuntime=-1 maxRuntimeUnits=MINUTES downsampling_type=BY_SAMPLE downsample_to_fraction=null downsample_to_coverage=1000 use_legacy_downsampler=false baq=OFF baqGapOpenPenalty=40.0 fix_misencoded_quality_scores=false allow_potentially_misencoded_quality_scores=false performanceLog=null useOriginalQualities=false BQSR=null quantize_quals=0 disable_indel_quals=false emit_original_quals=false preserve_qscores_less_than=6 defaultBaseQualities=-1 validation_strictness=SILENT remove_program_records=false keep_program_records=false unsafe=null num_threads=1 num_cpu_threads_per_data_thread=1 num_io_threads=0 monitorThreadEfficiency=false num_bam_file_handles=null read_group_black_list=null pedigree=[] pedigreeString=[] pedigreeValidationType=STRICT allow_intervals_with_unindexed_bam=false generateShadowBCF=false logging_level=INFO log_to_file=null help=false variant=(RodBinding name=variant source=/seq/dax/all_1kg_exomes/v1/all_1kg_exomes.unfiltered.vcf) discordance=(RodBinding name= source=UNBOUND) concordance=(RodBinding name= source=UNBOUND) out=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub no_cmdline_in_header=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sites_only=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub bcf=org.broadinstitute.sting.gatk.io.stubs.VariantContextWriterStub sample_name=[] sample_expressions=null sample_file=null exclude_sample_name=[] exclude_sample_file=[] select_expressions=[] excludeNonVariants=false excludeFiltered=false regenotype=false restrictAllelesTo=ALL kee",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658:12316,monitor,monitorThreadEfficiency,12316,https://hail.is,https://github.com/hail-is/hail/issues/1822#issuecomment-301916658,1,['monitor'],['monitorThreadEfficiency']
Energy Efficiency,"s[1] == variants.ss.nt1)) | ; ((flip_text(variants.alleles[0]) == variants.ss.nt2) & ; (flip_text(variants.alleles[1]) == variants.ss.nt1)),; variants.ss.ldpred_inf_beta); .or_missing()). variants = variants.filter_rows(hl.is_defined(variants.beta)); variants.beta.show(); ```. ### What went wrong (all error messages here, including the full java stack trace): When I went to try to show the beta column, Scala ""crashed"" such that I had to type in ""localhost:4040"" to reconnect and go into my application history to see what happened. I didn't get any errors in the Notebook I was using--it just stopped doing any work. . In the Scala tasks console, all of my workers had the following error:; ```; java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TBinary$.allocate(TBinary.scala:101); 	at is.hail.annotations.RegionValueBuilder.fixupBinary(RegionValueBuilder.scala:263); 	at is.hail.annotations.RegionValueBuilder.fixupStruct(RegionValueBuilder.scala:319); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:288); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$31$$anonfun$apply$21.apply(Relational.scala:975); 	at is.hail.expr.MatrixMapRows$$anonfun$31$$anonfun$apply$21.apply(Relational.scala:964); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:914); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:908); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3508:3241,allocate,allocate,3241,https://hail.is,https://github.com/hail-is/hail/issues/3508,1,['allocate'],['allocate']
Energy Efficiency,scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at org.apache.spark.sql.execution.datasources.FileFormatWriter$SingleDirectoryWriteTask.execute(FileFormatWriter.scala:244); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:190); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:188); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1341); at org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:193); ... 8 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2407:7281,schedul,scheduler,7281,https://hail.is,https://github.com/hail-is/hail/issues/2407,1,['schedul'],['scheduler']
Energy Efficiency,scala:1055); 	at is.hail.io.vcf.VCFLine.addInfoField(LoadVCF.scala:1075); 	at is.hail.io.vcf.VCFLine.parseAddInfo(LoadVCF.scala:1112); 	at is.hail.io.vcf.LoadVCF$.parseLineInner(LoadVCF.scala:1541); 	at is.hail.io.vcf.LoadVCF$.parseLine(LoadVCF.scala:1409); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1916); 	... 21 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2673); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2609); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2608); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2608); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2861); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2792); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2257); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2289); 	at is.hail.sparkextras.ContextRDD.crunJobWith,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:10494,schedul,scheduler,10494,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['schedul'],['scheduler']
Energy Efficiency,scala:20); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:58); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:63); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:67); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:62); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:50); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:462); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:498); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:75); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:75); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:63); 	at is.hail.backend.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:9486,adapt,adapted,9486,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124,1,['adapt'],['adapted']
Energy Efficiency,scala:20); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:59); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:64); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:83); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:32); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:32); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:30); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:29); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:78); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:21); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:19); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:19); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:45); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:600); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$4(SparkBackend.scala:636); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$3(SparkBackend.scala:631); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$3$adapted(SparkBackend.scala:630); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(E,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:12705,adapt,adapted,12705,https://hail.is,https://github.com/hail-is/hail/issues/14513,1,['adapt'],['adapted']
Energy Efficiency,scala:20); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:67); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:72); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:67); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:62); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:50); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:463); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:499); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:75); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:75); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:63); 	at is.hail.backend.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12936:8566,adapt,adapted,8566,https://hail.is,https://github.com/hail-is/hail/issues/12936,1,['adapt'],['adapted']
Energy Efficiency,scala:20); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:67); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:72); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:69); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:64); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:15); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:13); 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:13); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:47); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:416); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:452); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:70); 	at is.hail.utils.package$.using(package.scala:646); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:70); 	at is.hail.utils.package$.using(package.scala:646); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:59); 	at is.hail.ba,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12290:5772,adapt,adapted,5772,https://hail.is,https://github.com/hail-is/hail/issues/12290,1,['adapt'],['adapted']
Energy Efficiency,scala:243); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply(TaskSchedulerImpl.scala:242); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3$$anonfun$apply$1.apply(TaskSchedulerImpl.scala:242); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3.apply(TaskSchedulerImpl.scala:242); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2$$anonfun$apply$3.apply(TaskSchedulerImpl.scala:235); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:99); at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:230); at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); at scala.collection.mutable.HashMap.foreach(HashMap.scala:99); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:235); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:234); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.TaskSchedulerImpl.cancelTasks(TaskSchedulerImpl.scala:234); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply$mcVI$sp(DAGScheduler.scala:1543); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1529); at o,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:200594,schedul,scheduler,200594,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,4,['schedul'],['scheduler']
Energy Efficiency,scala:27); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:59); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:64); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:83); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:32); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:32); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:30); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:29); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:78); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:21); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:19); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:19); 	at is.hail.expr.ir.lowering.EvalRelationalLets$.execute$1(EvalRelationalLets.scala:13); 	at is.hail.expr.ir.lowering.EvalRelationalLets$.lower$1(EvalRelationalLets.scala:21); 	at is.hail.expr.ir.lowering.EvalRelationalLets$.apply(EvalRelationalLets.scala:35); 	at is.hail.expr.ir.lowering.EvalRelationalLetsPass.transform(LoweringPass.scala:168); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:32); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:32); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.expr.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14529:9080,adapt,adapted,9080,https://hail.is,https://github.com/hail-is/hail/issues/14529,1,['adapt'],['adapted']
Energy Efficiency,scala:27); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:67); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:72); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:69); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:64); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:15); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:13); 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:13); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:47); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:450); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:486); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:70); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:70); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:59); 	at is.hail.ba,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12532:9391,adapt,adapted,9391,https://hail.is,https://github.com/hail-is/hail/issues/12532,1,['adapt'],['adapted']
Energy Efficiency,scala:30); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:58); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:63); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:67); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:62); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:50); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:462); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:498); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:75); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:75); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:63); 	at is.hail.backend.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13486:4606,adapt,adapted,4606,https://hail.is,https://github.com/hail-is/hail/issues/13486,1,['adapt'],['adapted']
Energy Efficiency,scala:30); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:59); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:64); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:83); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:32); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:32); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:30); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:29); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:78); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:21); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:19); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:19); 	at is.hail.expr.ir.lowering.EvalRelationalLets$.execute$1(EvalRelationalLets.scala:13); 	at is.hail.expr.ir.lowering.EvalRelationalLets$.lower$1(EvalRelationalLets.scala:21); 	at is.hail.expr.ir.lowering.EvalRelationalLets$.apply(EvalRelationalLets.scala:35); 	at is.hail.expr.ir.lowering.EvalRelationalLetsPass.transform(LoweringPass.scala:170); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:32); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:32); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.expr.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14362:15842,adapt,adapted,15842,https://hail.is,https://github.com/hail-is/hail/issues/14362,1,['adapt'],['adapted']
Energy Efficiency,scala:30); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:67); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:72); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:69); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:64); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:15); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:13); 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:13); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:47); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:381); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:417); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:47); 	at is.hail.utils.package$.using(package.scala:638); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:47); 	at is.hail.utils.package$.using(package.scala:638); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:46); 	at is.hail.ba,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12533:22268,adapt,adapted,22268,https://hail.is,https://github.com/hail-is/hail/issues/12533,1,['adapt'],['adapted']
Energy Efficiency,scala:30); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:67); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:72); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:69); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:64); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:15); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:13); 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:13); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:47); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:450); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:486); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:70); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:70); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:59); 	at is.hail.ba,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12531:9083,adapt,adapted,9083,https://hail.is,https://github.com/hail-is/hail/issues/12531,3,['adapt'],['adapted']
Energy Efficiency,scala:30); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:67); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:72); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:69); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:64); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:15); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:13); 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:13); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:47); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:450); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:486); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:70); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:70); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:59); 	at is.hail.ba,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287#issuecomment-1664593619:8876,adapt,adapted,8876,https://hail.is,https://github.com/hail-is/hail/issues/13287#issuecomment-1664593619,1,['adapt'],['adapted']
Energy Efficiency,scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); at org.apache.spark.sql.execution.datasources.FileFormatWriter$SingleDirectoryWriteTask.execute(FileFormatWriter.scala:244); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:190); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:188); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1341); at org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:193); ... 8 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2407:7183,schedul,scheduler,7183,https://hail.is,https://github.com/hail-is/hail/issues/2407,1,['schedul'],['scheduler']
Energy Efficiency,scala:438); 	at org.apache.spark.storage.BlockManager.get(BlockManager.scala:606); 	at org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:663); 	at org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:330); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:281); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1806:2693,schedul,scheduler,2693,https://hail.is,https://github.com/hail-is/hail/issues/1806,1,['schedul'],['scheduler']
Energy Efficiency,scala:526); 	at is.hail.rvd.RVD.$anonfun$head$2$adapted(RVD.scala:526); 	at is.hail.sparkextras.ContextRDD.$anonfun$runJob$2(ContextRDD.scala:366); 	at is.hail.sparkextras.ContextRDD.sparkManagedContext(ContextRDD.scala:164); 	at is.hail.sparkextras.ContextRDD.$anonfun$runJob$1(ContextRDD.scala:365); 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:131); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2254); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2203); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2202); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2202); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGSchedul,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:7866,schedul,scheduler,7866,https://hail.is,https://github.com/hail-is/hail/issues/10682,1,['schedul'],['scheduler']
Energy Efficiency,scala:73); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32); at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37); at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:199); at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:103); at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:9677,schedul,scheduler,9677,https://hail.is,https://github.com/hail-is/hail/issues/4780,1,['schedul'],['scheduler']
Energy Efficiency,scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 2019-01-22 13:12:06 YarnScheduler: INFO: Cancelling stage 0; 2019-01-22 13:12:06 DAGSchedulerEventProcessLoop: ERROR: DAGScheduler failed to cancel all jobs.; java.util.NoSuchElementException: key not found: 70; at scala.collection.MapLike$class.default(MapLike.scala:228); at scala.collection.AbstractMap.default(Map.scala:59); at scala.collection.mutable.HashMap.apply(HashMap.scala:65); at org.apache.spark.scheduler.TaskSchedulerI,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:202148,schedul,scheduler,202148,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['schedul'],['scheduler']
Energy Efficiency,"se); r2_adj = r2_adj.sparsify_triangle(); r2_adj = r2_adj.checkpoint(f'{tmp}/adj', overwrite=args.overwrite). if __name__ == '__main__':; main(); ```. ### Version. 0.2.128. ### Relevant log output. ```shell; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.128-17247d8990c6; LOGGING: writing to /home/edmund/.local/src/hail/hail-20240508-1553-0.2.128-17247d8990c6.log; Traceback (most recent call last):; File ""/home/edmund/.local/share/pyenv/versions/3.9.18/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.local/share/pyenv/versions/3.9.18/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/__main__.py"", line 39, in <module>; cli.main(); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py"", line 430, in main; run(); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py"", line 284, in run_file; runpy.run_path(target, run_name=""__main__""); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 321, in run_path; return _run_module_code(code, init_globals, run_name,; File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 135, in _run_module_code; _run_code(code, mod_globals, init_globals,; File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 124, in _run_code; exec(code, run_globals); File ""/home/ed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14537:2123,adapt,adapter,2123,https://hail.is,https://github.com/hail-is/hail/issues/14537,1,['adapt'],['adapter']
Energy Efficiency,see `org.apache.spark.scheduler.JobWaiter`. I think this will be fine.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4526#issuecomment-431683150:22,schedul,scheduler,22,https://hail.is,https://github.com/hail-is/hail/issues/4526#issuecomment-431683150,1,['schedul'],['scheduler']
Energy Efficiency,selectRows(MatrixTable.scala:1229); 	at is.hail.variant.MatrixTable.selectRows(MatrixTable.scala:1168); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)java.lang.NegativeArraySizeException: null; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:140); 	at is.hail.annotations.Region.allocate(Region.scala:153); 	at is.hail.annotations.Region.allocate(Region.scala:160); 	at is.hail.codegen.generated.C11.apply(Unknown Source); 	at is.hail.codegen.generated.C11.apply(Unknown Source); 	at is.hail.io.CompiledPackDecoder.readRegionValue(RowStore.scala:650); 	at is.hail.HailContext$$anon$2.next(HailContext.scala:245); 	at is.hail.HailContext$$anon$2.next(HailContext.scala:218); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.sparkextras.ContextRDD$$anonfun$czip$1$$anon$1.next(ContextRDD.scala:333); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:915); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:909); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonf,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3583:11509,allocate,allocate,11509,https://hail.is,https://github.com/hail-is/hail/issues/3583,1,['allocate'],['allocate']
Energy Efficiency,"ser ; - [x] Test in cluster; - [x] Make sure Notebook v1 still works; - [ ] Stretch, and only in v3 so Feb 5 entropy minimized: asynchttp + uvloop; - [ ] Stretch ?: route by pod ip instead of svc name: DNS propagation latency significantly longer than pod instantiation time, which sucks for users, both because notebook instances will look broken when they're not, and because if we mask that the apparent latency to first useful operation is multiples of that needed. new: ; Cotton is right, mysql is adding too much complexity for the minimal use case, esp. with gevent conflicting with PyMySQL, necessitating per route handler connection. old:; Not ready to be merged, would like to improve SQL connection handling. 6a4599df5dfe0affdb5e367dd9cdc70cca59fd17 onward dependent on this. MySQL use is unoptimized because PyMySQL doesn't play well with gevent in the following way: initial impression from reading was that monkey.patch_all() before creation of global connection should result in connection spawned for each new request, or to at least private to a greenlet. Doesn't appear to be the case, plenty of connection errors. So establishing connection within each request, which is slow. . Python C library also out, because it does not play well with Python threading/greenlet/monkey patch implementations. MySQL Connector is an option, provides thread pools, but is also slowest option, by up to 10x, for small requests, like our are likely to be. However, that will be next implementation, for velocity/documentation reasons. . A better, third, more unwieldy solution is to use the C library (MySQLDb) establish a connection pool, N threads, and use deqeue. No implementation for waiting state, but will be the same; effectively, browser will connect to notebook socket server, notebook will issue periodic updates. Same thing, just . Need help/ok to update gateway to test this in production environment. Preferably, as I mentioned to Dan, we would have a staging gateway, which *.dev.hai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5215:1608,green,greenlet,1608,https://hail.is,https://github.com/hail-is/hail/pull/5215,1,['green'],['greenlet']
Energy Efficiency,"sh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDKC9kZBCsWb78yJ1zcdhmrYEmjNEOaJN5RGuMBuoszUXGGOCJMFi6jMTgSVjTql90NchA0tWXAuooVLV++f8WIOwpP7TY1YzN1XCREyk8jKOMrIdCc22ueJlNvxmFfJhdDKBCy0eThWN2qFxQJ4p9SvzGlMd2r3nBy95v9f8WgkN8M/HTDwTsFafNT0arvHnmUY6rFHxQE9TgTRlH1/sZ7mMxzmVZ8NKI/wIXTkv53TbylBYbvkEXyVFl3OBj1MUvo17v99LGdQNFcAiWR/pRsDvXY415FzootwShgQpmvuPLP7buTqVcrRnwRr2hZcpaydOyEaErYsuEPiot0RPrvsIXSkSI4NlIbqO2i4gjfF8FwpDzyY0WtAvUbsY8dKxWXzcIWtQzUyYeqJq1R0Yh8p3ijmLgrkpAJTI/Lz8WT2foUFg7gYQwc9xbFN6aQzQwUQ0Y8s0DDvQqnbby12IXXHI+rjuh1TH8lIRPw/UsFInJn3WS1MBp4FRiXwRs9EwVhfeb+b8Z5rnaQ3RrmM8SY0kjg0i05rkMkygEnPuSec6qKYREHW8n4wbYQNhJvDW9RhUIGnzn3IQRJB57bOZ8xwPkZ97PM0WGsCMWwupSOuEk/NsFe69cZwbElYZJeqeA/bKKsmRsJ/tjzyYMLUlj4L++4GQIwPHgtjmQ9kUEeaw== dgoldste@wmce3-cb7\n"",; ""path"": ""/home/batch-worker/.ssh/authorized_keys""; }; ]; }; },; ""requireGuestProvisionSignal"": true,; ""secrets"": [],; ""windowsConfiguration"": null; },; ""plan"": null,; ""platformFaultDomain"": null,; ""priority"": ""Spot"",; ""provisioningState"": ""Succeeded"",; ""proximityPlacementGroup"": null,; ""resourceGroup"": ""dgoldste"",; ""resources"": null,; ""scheduledEventsProfile"": null,; ""securityProfile"": null,; ""storageProfile"": {; ""dataDisks"": [],; ""imageReference"": {; ""exactVersion"": ""0.0.12"",; ""id"": ""/subscriptions/22cd45fe-f996-4c51-af67-ef329d977519/resourceGroups/dgoldste/providers/Microsoft.Compute/galleries/dgoldste_batch/images/batch-worker/versions/0.0.12"",; ""offer"": null,; ""publisher"": null,; ""resourceGroup"": ""dgoldste"",; ""sharedGalleryImageId"": null,; ""sku"": null,; ""version"": null; },; ""osDisk"": {; ""caching"": ""ReadOnly"",; ""createOption"": ""FromImage"",; ""deleteOption"": ""Delete"",; ""diffDiskSettings"": null,; ""diskSizeGb"": 30,; ""encryptionSettings"": null,; ""image"": null,; ""managedDisk"": {; ""diskEncryptionSet"": null,; ""id"": ""/subscriptions/22cd45fe-f996-4c51-af67-ef329d977519/resourceGroups/dgoldste/providers/Microsoft.Compute/disks/batch-worker-pr-11144-default-nbthv8fduvd6-highmem-13t6m-os"",; ""resourceGroup"": ""dgoldste"",; ""storageAccountType"":",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11144#issuecomment-990039686:8524,schedul,scheduledEventsProfile,8524,https://hail.is,https://github.com/hail-is/hail/pull/11144#issuecomment-990039686,1,['schedul'],['scheduledEventsProfile']
Energy Efficiency,"sh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDKC9kZBCsWb78yJ1zcdhmrYEmjNEOaJN5RGuMBuoszUXGGOCJMFi6jMTgSVjTql90NchA0tWXAuooVLV++f8WIOwpP7TY1YzN1XCREyk8jKOMrIdCc22ueJlNvxmFfJhdDKBCy0eThWN2qFxQJ4p9SvzGlMd2r3nBy95v9f8WgkN8M/HTDwTsFafNT0arvHnmUY6rFHxQE9TgTRlH1/sZ7mMxzmVZ8NKI/wIXTkv53TbylBYbvkEXyVFl3OBj1MUvo17v99LGdQNFcAiWR/pRsDvXY415FzootwShgQpmvuPLP7buTqVcrRnwRr2hZcpaydOyEaErYsuEPiot0RPrvsIXSkSI4NlIbqO2i4gjfF8FwpDzyY0WtAvUbsY8dKxWXzcIWtQzUyYeqJq1R0Yh8p3ijmLgrkpAJTI/Lz8WT2foUFg7gYQwc9xbFN6aQzQwUQ0Y8s0DDvQqnbby12IXXHI+rjuh1TH8lIRPw/UsFInJn3WS1MBp4FRiXwRs9EwVhfeb+b8Z5rnaQ3RrmM8SY0kjg0i05rkMkygEnPuSec6qKYREHW8n4wbYQNhJvDW9RhUIGnzn3IQRJB57bOZ8xwPkZ97PM0WGsCMWwupSOuEk/NsFe69cZwbElYZJeqeA/bKKsmRsJ/tjzyYMLUlj4L++4GQIwPHgtjmQ9kUEeaw== dgoldste@wmce3-cb7\n"",; ""path"": ""/home/batch-worker/.ssh/authorized_keys""; }; ]; }; },; ""requireGuestProvisionSignal"": true,; ""secrets"": [],; ""windowsConfiguration"": null; },; ""plan"": null,; ""platformFaultDomain"": null,; ""priority"": ""Spot"",; ""provisioningState"": ""Succeeded"",; ""proximityPlacementGroup"": null,; ""resourceGroup"": ""dgoldste"",; ""resources"": null,; ""scheduledEventsProfile"": null,; ""securityProfile"": null,; ""storageProfile"": {; ""dataDisks"": [],; ""imageReference"": {; ""exactVersion"": ""0.0.12"",; ""id"": ""/subscriptions/22cd45fe-f996-4c51-af67-ef329d977519/resourceGroups/dgoldste/providers/Microsoft.Compute/galleries/dgoldste_batch/images/batch-worker/versions/0.0.12"",; ""offer"": null,; ""publisher"": null,; ""resourceGroup"": ""dgoldste"",; ""sharedGalleryImageId"": null,; ""sku"": null,; ""version"": null; },; ""osDisk"": {; ""caching"": ""ReadOnly"",; ""createOption"": ""FromImage"",; ""deleteOption"": ""Delete"",; ""diffDiskSettings"": null,; ""diskSizeGb"": 30,; ""encryptionSettings"": null,; ""image"": null,; ""managedDisk"": {; ""diskEncryptionSet"": null,; ""id"": ""/subscriptions/22cd45fe-f996-4c51-af67-ef329d977519/resourceGroups/dgoldste/providers/Microsoft.Compute/disks/batch-worker-pr-11144-default-nbthv8fduvd6-standard-i4sun-os"",; ""resourceGroup"": ""dgoldste"",; ""storageAccountType""",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11144#issuecomment-990039686:12872,schedul,scheduledEventsProfile,12872,https://hail.is,https://github.com/hail-is/hail/pull/11144#issuecomment-990039686,1,['schedul'],['scheduledEventsProfile']
Energy Efficiency,shMap.foreach(HashMap.scala:99); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:235); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:234); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.TaskSchedulerImpl.cancelTasks(TaskSchedulerImpl.scala:234); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply$mcVI$sp(DAGScheduler.scala:1543); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:201517,schedul,scheduler,201517,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['schedul'],['scheduler']
Energy Efficiency,"shMap.foreach(HashMap.scala:99); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:235); at org.apache.spark.scheduler.TaskSchedulerImpl$$anonfun$cancelTasks$2.apply(TaskSchedulerImpl.scala:234); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.TaskSchedulerImpl.cancelTasks(TaskSchedulerImpl.scala:234); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply$mcVI$sp(DAGScheduler.scala:1543); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1457); at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply$mcVI$sp(DAGScheduler.scala:723); at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:723); at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:723); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.doCancelAllJobs(DAGScheduler.scala:723); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onError(DAGScheduler.scala:1741); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:52); 2019-01-22 13:12:06 AbstractConnector: INFO: Stopped Spark@1433e9ec{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2019-01-22 13:12:06 SparkUI: INFO: Stopped Spark web UI at http://10.48.225.55:4040; 2019-01-22 13:12:06 DAGScheduler: INFO: Job 0 f",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:205164,schedul,scheduler,205164,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['schedul'],['scheduler']
Energy Efficiency,sk.scala:121); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:403); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:409); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkConte,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8545:9785,schedul,scheduler,9785,https://hail.is,https://github.com/hail-is/hail/issues/8545,1,['schedul'],['scheduler']
Energy Efficiency,sk.scala:123); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1892); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1880); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2113); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2062); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2051); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkConte,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:82612,schedul,scheduler,82612,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['schedul'],['scheduler']
Energy Efficiency,spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.ArrayIndexOutOfBoundsException. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1906); 	at org.apache.spark.sql.execution.datasource,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1202:5649,schedul,scheduler,5649,https://hail.is,https://github.com/hail-is/hail/issues/1202,1,['schedul'],['scheduler']
Energy Efficiency,"splitting in the Hail Query compiler. The first is a heuristic and greedy IR-level method splitter that generates new methods every X IR nodes, simply based on node count. However, the size of code generated by each IR can vary widely (`I32` vs `LowerBoundOnOrderedCollection` for instance), and so we have two other kinds of splitting that operate on the LIR level. The first is region splitting, which is used to split large blocks of LIR. In order to insert a split, any variables on the stack are stored in local variables before the split and loaded from those locals after the split. The second is method splitting, which is used to split large single methods. A single-exit group of blocks can be split into a separate method, and we have some machinery for replacing control flow instructions (which I will not go into here, for they are not relevant now), as well as handling local variables that are used across a method split. These shared Local variables are replaced by fields on a ""spills"" class which is allocated any time a split method is called. Spilled local `store`s are rewritten as field `store`s, and `load`s are rewritten as field `load`s. # What was the problem here?. A region split was inserted *directly between* the `I2B` instruction and the call to `OutputBuffer.write`. This meant that the result of `I2B` was stored in a local variable and read in the subsequent block. **The incorrect TypeInfo of Boolean was used for that local variable**, but this seems not to pose a problem -- both Boolean and Byte use a single slot, and so the code still works even with the wrong variable type. However, the method splitter then **generated a method split at the same point where the region was split**. This means that the local variable resulting from I2B is spilled to a class field on the spills class. Our incorrectly-Boolean local becomes an incorrectly-Boolean **field**, and this is where things go wrong -- it seems as though Boolean class fields (appropriately) trunc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11328:2635,allocate,allocated,2635,https://hail.is,https://github.com/hail-is/hail/pull/11328,1,['allocate'],['allocated']
Energy Efficiency,"st be initialized to dummy values in `setup0`, and initialized to correct initial values in `setup`. The former is needed to satisfy the bytecode verifier (otherwise it can't prove that the local always has a value in the basic blocks in which it's read).; * Any resources created in `setup0` must be freed in `close0`, and similarly for `setup`/`close`. The former will be run exactly once in a stream pipeline, while the latter will be run once per usage of the stream, which can be many times if the stream is used inside a flatMap.; * Both `firstPull` and `pull` must ultimately give control to either `eos` or `push`.; * On any control path leading to `eos`, `close` must have been run. The consumer of a `Stream` must satisfy the invariants:; * All pieces of code besides `setup0` and `setup` must be emitted at most once. This can always be arranged by emitting the code in a `JoinPoint` (label), then jumping to the label at each call site.; * If `firstPull` is defined, it must always be executed before `pull` on any consumption of the stream. (This is primarily used for flatMap, where `firstPull` pulls from the outer stream, and `pull` pulls from the inner stream.); * `push` must ultimately either give control back to `pull`, or run `close`.; * `setup0` must dominate all other code provided by the `Stream`. I.e., all possible control flow paths leading to any code in `Source` must go through `setup0`. (In particular, in flatMap, the `setup0` of the inner stream must be run before the outer stream is started.). The ""tests"" only print out streams along with ""setup"" and ""close"" messages to visually ensure they are being triggered properly; obviously those will have to change before this is merged. My plan is to write an instrumented range that sets flags in its setup and close code, so those flags can be inspected in asserts. But if speed is more important, I can put off those tests. The informal tests give me high confidence there are currently no bugs at the level of the s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8129:2815,consumption,consumption,2815,https://hail.is,https://github.com/hail-is/hail/pull/8129,1,['consumption'],['consumption']
Energy Efficiency,"st-6boype3d'...; Traceback (most recent call last):; File ""/home/hail/.conda/envs/hail/bin/cluster"", line 10, in <module>; sys.exit(main()); File ""/home/hail/.conda/envs/hail/lib/python3.6/site-packages/cloudtools/__main__.py"", line 85, in main; start.main(args); File ""/home/hail/.conda/envs/hail/lib/python3.6/site-packages/cloudtools/start.py"", line 210, in main; check_call(cmd); File ""/home/hail/.conda/envs/hail/lib/python3.6/subprocess.py"", line 291, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['gcloud', 'beta', 'dataproc', 'clusters', 'create', 'ci-test-6boype3d', '--image-version=1.2-deb9', '--metadata=MINICONDA_VERSION=4.4.10,JAR=gs://hail-ci-0-1/temp/25aa42b2d6d442615931b2eb65c5f8e012de52a0/96d6daa14989dd0cff08b30ac1f1d53288171a54/hail.jar,ZIP=gs://hail-ci-0-1/temp/25aa42b2d6d442615931b2eb65c5f8e012de52a0/96d6daa14989dd0cff08b30ac1f1d53288171a54/hail.zip', '--properties=spark:spark.driver.memory=3g,spark:spark.driver.maxResultSize=0,spark:spark.task.maxFailures=20,spark:spark.kryoserializer.buffer.max=1g,spark:spark.driver.extraJavaOptions=-Xss4M,spark:spark.executor.extraJavaOptions=-Xss4M,hdfs:dfs.replication=1,dataproc:dataproc.logging.stackdriver.enable=false,dataproc:dataproc.monitoring.stackdriver.enable=false', '--initialization-actions=gs://dataproc-initialization-actions/conda/bootstrap-conda.sh,gs://hail-common/cloudtools/init_notebook1.py,gs://hail-common/vep/vep/vep85-loftee-1.0-GRCh37-init-docker.sh', '--master-machine-type=n1-standard-1', '--master-boot-disk-size=40GB', '--num-master-local-ssds=0', '--num-preemptible-workers=0', '--num-worker-local-ssds=0', '--num-workers=2', '--preemptible-worker-boot-disk-size=40GB', '--worker-boot-disk-size=40', '--worker-machine-type=n1-standard-1', '--zone=us-central1-b', '--initialization-action-timeout=20m', '--bucket=hail-ci-0-1-dataproc-staging-bucket', '--max-idle=10m']' returned non-zero exit status 1. real	20m34.381s; user	0m6.329s; sys	0m1.522s; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4530#issuecomment-475782518:10766,monitor,monitoring,10766,https://hail.is,https://github.com/hail-is/hail/issues/4530#issuecomment-475782518,2,['monitor'],['monitoring']
Energy Efficiency,"st; tmpfs 14.7G 0 14.7G 0% /proc/scsi; tmpfs 14.7G 0 14.7G 0% /sys/firmware; ```. Which isn't much larger than it was before the scaling tests. It appears to slowly increase the amount of memory it needs:; ```; 1 0 nobody S 30.9g103.7 1 11.5 /bin/prometheus --config.file=/etc/prometheus/prometheus.yml --storage.tsdb.path=/prometheus --web.console.libraries=/usr/share/prometheus/console_libraries --web.console.templates=/usr/share/prometheus/consoles --web.external; ```. caping out at 31.5 GB (the disk is 31.2 GB). Now, it is presumably trying to recover. It's been up for about 7 minutes. Still unavailable:; ```; /prometheus $ wget localhost:9090/monitoring/prometheus; Connecting to localhost:9090 (127.0.0.1:9090); wget: server returned error: HTTP/1.1 503 Service Unavailable; /prometheus $ ; ```. https://github.com/prometheus/prometheus/issues/5727#issuecomment-510818825; https://github.com/prometheus/prometheus/issues/4324#issuecomment-460243182. ```; # k logs -n monitoring prometheus-0 ; level=info ts=2019-07-31T15:45:51.990Z caller=main.go:286 msg=""no time or size retention was set so using the default time retention"" duration=15d; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:322 msg=""Starting Prometheus"" version=""(version=2.10.0, branch=HEAD, revision=d20e84d0fb64aff2f62a977adc8cfb656da4e286)""; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:323 build_context=""(go=go1.12.5, user=root@a49185acd9b0, date=20190525-12:28:13)""; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:324 host_details=""(Linux 4.14.127+ #1 SMP Tue Jun 18 18:32:10 PDT 2019 x86_64 prometheus-0 (none))""; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:325 fd_limits=""(soft=1048576, hard=1048576)""; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:326 vm_limits=""(soft=unlimited, hard=unlimited)""; level=info ts=2019-07-31T15:45:51.993Z caller=main.go:645 msg=""Starting TSDB ...""; level=info ts=2019-07-31T15:45:51.994Z caller=web.go:417 component=web msg=""Start listening ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6773:2295,monitor,monitoring,2295,https://hail.is,https://github.com/hail-is/hail/issues/6773,1,['monitor'],['monitoring']
Energy Efficiency,stRepository.writeToIndex(RestRepository.java:168); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:67); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:107); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:5806,schedul,scheduler,5806,https://hail.is,https://github.com/hail-is/hail/issues/4250,1,['schedul'],['scheduler']
Energy Efficiency,stics: [2023-07-24 13:52:49.515]Container killed on request. Exit code is 137; [2023-07-24 13:52:49.517]Container exited with a non-zero exit code 137. ; [2023-07-24 13:52:49.518]Killed by external signal; .; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1124); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2491); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2433); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2422); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:902); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2204); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2225); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2244); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2269); 	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287:7152,adapt,adapted,7152,https://hail.is,https://github.com/hail-is/hail/issues/13287,1,['adapt'],['adapted']
Energy Efficiency,stics: [2023-08-03 20:14:25.441]Container killed on request. Exit code is 137; [2023-08-03 20:14:25.442]Container exited with a non-zero exit code 137. ; [2023-08-03 20:14:25.442]Killed by external signal; .; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1124); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2491); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2433); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2422); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:902); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2204); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2225); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2244); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2269); 	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOp,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287#issuecomment-1664593619:5857,adapt,adapted,5857,https://hail.is,https://github.com/hail-is/hail/issues/13287#issuecomment-1664593619,1,['adapt'],['adapted']
Energy Efficiency,"stomers and partners can automate and simplify their SAP system administration tasks such as backup/restore of SAP HANA.</li>; <li>api-change:<code>stepfunctions</code>: [<code>botocore</code>] Update stepfunctions client to latest version</li>; <li>api-change:<code>transfer</code>: [<code>botocore</code>] Adds a NONE encryption algorithm type to AS2 connectors, providing support for skipping encryption of the AS2 message body when a HTTPS URL is also specified.</li>; </ul>; <h1>1.26.12</h1>; <ul>; <li>api-change:<code>amplify</code>: [<code>botocore</code>] Adds a new value (WEB_COMPUTE) to the Platform enum that allows customers to create Amplify Apps with Server-Side Rendering support.</li>; <li>api-change:<code>appflow</code>: [<code>botocore</code>] AppFlow simplifies the preparation and cataloging of SaaS data into the AWS Glue Data Catalog where your data can be discovered and accessed by AWS analytics and ML services. AppFlow now also supports data field partitioning and file size optimization to improve query performance and reduce cost.</li>; <li>api-change:<code>appsync</code>: [<code>botocore</code>] This release introduces the APPSYNC_JS runtime, and adds support for JavaScript in AppSync functions and AppSync pipeline resolvers.</li>; <li>api-change:<code>dms</code>: [<code>botocore</code>] Adds support for Internet Protocol Version 6 (IPv6) on DMS Replication Instances</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/boto/boto3/commit/f38ce50a317baf6715870b2706100d43b80b0c73""><code>f38ce50</code></a> Merge branch 'release-1.26.16'</li>; <li><a href=""https://github.com/boto/boto3/commit/33d7d6f020510890b93edf49de3f81c0ba208cb3""><code>33d7d6f</code></a> Bumping version to 1.26.16</li>; <li><a href=""https://github.com/boto/boto3/commit/fb642196bd5dda0f48636e3eeae5f983835fcef5""><code>fb64219</code></a> Add changelog entries from botocore</",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12502:6217,reduce,reduce,6217,https://hail.is,https://github.com/hail-is/hail/pull/12502,1,['reduce'],['reduce']
Energy Efficiency,"stomers and partners can automate and simplify their SAP system administration tasks such as backup/restore of SAP HANA.</li>; <li>api-change:<code>stepfunctions</code>: [<code>botocore</code>] Update stepfunctions client to latest version</li>; <li>api-change:<code>transfer</code>: [<code>botocore</code>] Adds a NONE encryption algorithm type to AS2 connectors, providing support for skipping encryption of the AS2 message body when a HTTPS URL is also specified.</li>; </ul>; <h1>1.26.12</h1>; <ul>; <li>api-change:<code>amplify</code>: [<code>botocore</code>] Adds a new value (WEB_COMPUTE) to the Platform enum that allows customers to create Amplify Apps with Server-Side Rendering support.</li>; <li>api-change:<code>appflow</code>: [<code>botocore</code>] AppFlow simplifies the preparation and cataloging of SaaS data into the AWS Glue Data Catalog where your data can be discovered and accessed by AWS analytics and ML services. AppFlow now also supports data field partitioning and file size optimization to improve query performance and reduce cost.</li>; <li>api-change:<code>appsync</code>: [<code>botocore</code>] This release introduces the APPSYNC_JS runtime, and adds support for JavaScript in AppSync functions and AppSync pipeline resolvers.</li>; <li>api-change:<code>dms</code>: [<code>botocore</code>] Adds support for Internet Protocol Version 6 (IPv6) on DMS Replication Instances</li>; <li>api-change:<code>ec2</code>: [<code>botocore</code>] This release adds a new optional parameter &quot;privateIpAddress&quot; for the CreateNatGateway API. PrivateIPAddress will allow customers to select a custom Private IPv4 address instead of having it be auto-assigned.</li>; <li>api-change:<code>elbv2</code>: [<code>botocore</code>] Update elbv2 client to latest version</li>; <li>api-change:<code>emr-serverless</code>: [<code>botocore</code>] Adds support for AWS Graviton2 based applications. You can now select CPU architecture when creating new applications or updating exist",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12498:5746,reduce,reduce,5746,https://hail.is,https://github.com/hail-is/hail/pull/12498,1,['reduce'],['reduce']
Energy Efficiency,"storage client from service account key; 2023-09-24 01:58:17.061 WorkerTimer$: INFO: readInputs took 338.458743 ms.; 2023-09-24 01:58:17.061 : INFO: RegionPool: initialized for thread 10: pool-2-thread-2; 2023-09-24 01:58:17.096 : INFO: RegionPool: REPORT_THRESHOLD: 265.0K allocated (201.0K blocks / 64.0K chunks), regions.size = 5, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-24 01:58:17.707 : INFO: RegionPool: REPORT_THRESHOLD: 521.0K allocated (457.0K blocks / 64.0K chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-24 01:58:18.609 : INFO: RegionPool: REPORT_THRESHOLD: 1.1M allocated (698.0K blocks / 410.0K chunks), regions.size = 19, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-24 01:58:19.984 : INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.0M blocks / 1010.0K chunks), regions.size = 19, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-24 01:58:24.240 : INFO: RegionPool: REPORT_THRESHOLD: 4.3M allocated (2.2M blocks / 2.1M chunks), regions.size = 19, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-24 01:58:24.240 GoogleStorageFS$: INFO: createNoCompression: gs://aou_tmp/tmp/hail/icullIwHC8dQXtq8JU2uDW/aggregate_intermediates/-ntpjdAQ9sKaR8lK26cV0p5790a4d87-9035-41ae-afc6-326f710d9a89; 2023-09-24 01:58:24.305 GoogleStorageFS$: INFO: close: gs://aou_tmp/tmp/hail/icullIwHC8dQXtq8JU2uDW/aggregate_intermediates/-ntpjdAQ9sKaR8lK26cV0p5790a4d87-9035-41ae-afc6-326f710d9a89; 2023-09-24 01:58:51.513 : INFO: TaskReport: stage=0, partition=9571, attempt=0, peakBytes=4507648, peakBytesReadable=4.30 MiB, chunks requested=51, cache hits=0; 2023-09-24 01:58:51.513 : INFO: RegionPool: FREE: 4.3M allocated (2.2M blocks / 2.1M chunks), regions.size = 19, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-24 01:58:51.515 JVMEntryway: ERROR: QoB Job threw an exception.; java.lang.reflect.InvocationTargetException: null; 	at sun.reflect.GeneratedMethodAccessor42.invoke(Unknown Sou",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13721:2940,allocate,allocated,2940,https://hail.is,https://github.com/hail-is/hail/issues/13721,1,['allocate'],['allocated']
Energy Efficiency,stractIterator.toArray(Iterator.scala:1334); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:121); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:403); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:409); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); 	at org.apa,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8545:9294,schedul,scheduler,9294,https://hail.is,https://github.com/hail-is/hail/issues/8545,1,['schedul'],['scheduler']
Energy Efficiency,stractIterator.toArray(Iterator.scala:1334); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(RDD.scala:990); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:123); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1892); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1880); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2113); 	at org.apa,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:82121,schedul,scheduler,82121,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['schedul'],['scheduler']
Energy Efficiency,"svd symEigD symEig symEigR; 500 .092 .051 .234 .038; 500 .088 .050 .217 .046; 500 .093 .047 .229 .041; 1000 .458 .193 1.659 .191; 1000 .430 .184 1.469 .195; 1000 .441 .207 1.464 .183; 1500 1.399 .7245 4.810 .595; 1500 1.407 .5990 4.777 .601; 1500 1.421 .5835 5.236 .627; 2000 3.272 1.479 10.942 1.386; 2000 3.205 1.337 11.006 1.381; 2000 3.473 1.354 10.933 1.366; 2500 6.180 2.519 21.639 2.750; 2500 6.217 2.718 21.772 2.758; 2500 6.580 2.590 21.176 2.661; 3000 10.169 4.117 51.154 4.716; 3000 10.414 4.131 51.602 4.834; 3000 10.709 4.219 46.711 4.794; 3500 15.451 6.549 72.2 7.365; 3500 15.353 7.058 75.9 7.194; 3500 15.350 6.516 70.9 7.210; 4000 20.584 9.111 112.6 10.725; 4000 22.085 9.476 110.3 10.594; 4000 21.920 9.461 108.2 11.062; 4500 29.075 13.488 143.8 15.440; 4500 30.305 13.402 140.2 15.338; 4500 31.339 13.562 134.3 15.294; 5000 43.908 17.818 196.0 21.286; 5000 40.874 17.821 197.7 21.231; 5000 41.582 18.088 198.9 21.357; 5500 58.772 24.747 271.1 28.879; 5500 60.6 23.844 269.8 28.130; 5500 60.9 24.197 275.3 28.356; ```. Here's the R code for the plot for reference. I gave up on making a proper legend. ```; library(ggplot2); df <- read.table(""/Users/Jon/Desktop/svdEigen.tsv"",header=TRUE); ggplot(df, aes(dim)) + ; geom_point(aes(y = svd), color=""black"") + ; geom_smooth(aes(y = svd), method=lm, formula = y ~ poly(x, 3), color=""orange"", fullrange=TRUE) +; geom_point(aes(y = symEigD), color=""black"") + ; geom_smooth(aes(y = symEigD), method=lm, formula = y ~ poly(x, 3), color=""blue"", fullrange=TRUE) +; geom_point(aes(y = symEig), color=""black"") + ; geom_smooth(aes(y = symEig), method=lm, formula = y ~ poly(x, 3), color=""red"", fullrange=TRUE) +; geom_point(aes(y = symEigR), color=""black"") + ; geom_smooth(aes(y = symEigR), method=lm, formula = y ~ poly(x, 3), color=""green"", fullrange=TRUE) +; xlim(0, 360) +; ylim(0, 6000) +; ggtitle(""symEig (red), svd (orange), symEigR (green), symEigD (blue)\nstandard Wishart matrix, cubic spline"") +; labs(x=""dimension"", y=""seconds""); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/906#issuecomment-251835211:3189,green,green,3189,https://hail.is,https://github.com/hail-is/hail/pull/906#issuecomment-251835211,2,['green'],['green']
Energy Efficiency,t is.hail.methods.VEP$$anonfun$16$$anon$1.hasNext(VEP.scala:398); 	at is.hail.sparkextras.OrderedRDD$$anonfun$apply$7$$anon$2.hasNext(OrderedRDD.scala:211); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer$$anonfun$writeRows$1.apply$mcV$sp(WriterContainer.scala:253); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer$$anonfun$writeRows$1.apply(WriterContainer.scala:252); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer$$anonfun$writeRows$1.apply(WriterContainer.scala:252); 	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1348); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer.writeRows(WriterContainer.scala:258); 	... 8 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apa,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1822:5694,schedul,scheduler,5694,https://hail.is,https://github.com/hail-is/hail/issues/1822,1,['schedul'],['scheduler']
Energy Efficiency,t is.hail.sparkextras.OrderedRDD$$anonfun$4.apply(OrderedRDD.scala:70); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$25.apply(RDD.scala:820); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:4654,schedul,scheduler,4654,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['schedul'],['scheduler']
Energy Efficiency,t java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1986); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:63); ... 25 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org.apache.spark.SparkContext.runJob(SparkContext.sca,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3342:6373,schedul,scheduler,6373,https://hail.is,https://github.com/hail-is/hail/issues/3342,1,['schedul'],['scheduler']
Energy Efficiency,t java.lang.ClassLoader.defineClass1(Native Method); 	at java.lang.ClassLoader.defineClass(ClassLoader.java:756); 	at java.lang.ClassLoader.defineClass(ClassLoader.java:635); 	at is.hail.asm4s.HailClassLoader.liftedTree1$1(HailClassLoader.scala:10); 	at is.hail.asm4s.HailClassLoader.loadOrDefineClass(HailClassLoader.scala:6); 	at is.hail.asm4s.ClassesBytes.$anonfun$load$1(ClassBuilder.scala:64); 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198); 	at is.hail.asm4s.ClassesBytes.load(ClassBuilder.scala:62); 	at is.hail.expr.ir.EmitClassBuilder$$anon$1.apply(EmitClassBuilder.scala:715); 	at is.hail.expr.ir.EmitClassBuilder$$anon$1.apply(EmitClassBuilder.scala:708); 	at is.hail.expr.ir.CompileIterator$.$anonfun$forTableStageToRVD$1(Compile.scala:311); 	at is.hail.expr.ir.CompileIterator$.$anonfun$forTableStageToRVD$1$adapted(Compile.scala:310); 	at is.hail.expr.ir.lowering.TableStageToRVD$.$anonfun$apply$9(RVDToTableStage.scala:106); 	at is.hail.sparkextras.ContextRDD.$anonfun$cflatMap$2(ContextRDD.scala:211); 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2(RVD.scala:1234); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1233); 	at is.hail.sparkextras.ContextRDD.$anonfun$crunJobWithIndex$1(ContextRDD.scala:242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:131); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:498); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439); 	at org.apache.spark.exe,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12532:4436,adapt,adapted,4436,https://hail.is,https://github.com/hail-is/hail/issues/12532,2,['adapt'],['adapted']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD.count(RDD.scala:1134); 	at is.hail.variant.VariantSampleMatrix.countVariants(VariantSampleMatrix.scala:810); 	at is.hail.variant.VariantDatasetFunctions$.count$extension(VariantDataset.scala:504); 	at is.h,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882:4627,schedul,scheduler,4627,https://hail.is,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882,1,['schedul'],['scheduler']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1936); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1065); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); 	at org.apache.spark.rdd.RDD.fold(RDD.scala:1059); 	at is.hail.utils.richUtil,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1806:3481,schedul,scheduler,3481,https://hail.is,https://github.com/hail-is/hail/issues/1806,1,['schedul'],['scheduler']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:11,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3901:7763,schedul,scheduler,7763,https://hail.is,https://github.com/hail-is/hail/issues/3901,2,['schedul'],['scheduler']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:11,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8545:10122,schedul,scheduler,10122,https://hail.is,https://github.com/hail-is/hail/issues/8545,1,['schedul'],['scheduler']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:11,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:5442,schedul,scheduler,5442,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['schedul'],['scheduler']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:11,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:3070,schedul,scheduler,3070,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437,1,['schedul'],['scheduler']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:11,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3040:7605,schedul,scheduler,7605,https://hail.is,https://github.com/hail-is/hail/issues/3040,2,['schedul'],['scheduler']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1906); 	at org.elasticsearch.spark.rdd.EsSpark$.doSaveToEs(EsSpark.scala:107); 	at org.elasticsearch.spark.rdd.EsSpark$.saveToEs(EsSpark.scala:79); 	at org.elasticsearch.spark.rdd.EsSpark$.saveToEs(EsSpark.scala:76); 	at is.hail.io.ElasticsearchConnector$.export(ElasticsearchConnector.scala:33); 	at is.hail,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:6397,schedul,scheduler,6397,https://hail.is,https://github.com/hail-is/hail/issues/4250,1,['schedul'],['scheduler']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1936); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1065); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); 	at org.apache.spark.rdd.RDD.fold(RDD.scala:1059); 	at is.hail.utils.richUtil,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:9347,schedul,scheduler,9347,https://hail.is,https://github.com/hail-is/hail/issues/3760,1,['schedul'],['scheduler']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at is.hail.sparkextras.ContextRDD.runJob(ContextRDD.scala:467); 	at is.hail.sparkextras.ContextRDD.head(ContextRDD.scala:444); 	at is.hail.rvd.OrderedRVD.head(OrderedRVD.scala:346); 	at is.hail.rvd.OrderedRVD.head(OrderedRVD.scala:32); 	at is.hail.rvd.RVD$class.takeAsBytes(RVD.scala:247); 	at is.hai,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4055:6456,schedul,scheduler,6456,https://hail.is,https://github.com/hail-is/hail/issues/4055,1,['schedul'],['scheduler']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at is.hail.sparkextras.ContextRDD.runJob(ContextRDD.scala:467); 	at is.hail.sparkextras.ContextRDD.head(ContextRDD.scala:444); 	at is.hail.rvd.UnpartitionedRVD.head(UnpartitionedRVD.scala:23); 	at is.hail.rvd.UnpartitionedRVD.head(UnpartitionedRVD.scala:17); 	at is.hail.rvd.RVD$class.takeAsBytes(RVD,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4114:4320,schedul,scheduler,4320,https://hail.is,https://github.com/hail-is/hail/issues/4114,1,['schedul'],['scheduler']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at is.hail.sparkextras.ContextRDD.runJob(ContextRDD.scala:465); 	at is.hail.sparkextras.ContextRDD.head(ContextRDD.scala:442); 	at is.hail.rvd.OrderedRVD.head(OrderedRVD.scala:286); 	at is.hail.rvd.OrderedRVD.head(OrderedRVD.scala:22); 	at is.hail.rvd.RVD$class.takeAsBytes(RVD.scala:247); 	at is.hai,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3790:7198,schedul,scheduler,7198,https://hail.is,https://github.com/hail-is/hail/issues/3790,1,['schedul'],['scheduler']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:11,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3465:9389,schedul,scheduler,9389,https://hail.is,https://github.com/hail-is/hail/issues/3465,5,['schedul'],['scheduler']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:11,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:4870,schedul,scheduler,4870,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410,2,['schedul'],['scheduler']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094); 	at org.apache.spark.rdd.RDD.count(RDD.scala:1158); 	at is.hail.rvd.RVD$class.count(RVD.scala:183); 	at is.hail.rvd.OrderedRVD.count(OrderedRVD.scala:19); 	at is.hail.methods.LDPrune$$anonfun$9.apply(LDPrune.scala:471); 	at is.hail.me,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:3786,schedul,scheduler,3786,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627,1,['schedul'],['scheduler']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1575); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1563); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1562); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1562); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1790); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1745); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1734); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:619); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126); 	at is.hail.rvd.RVD.aggregateWithPartitionOp(RVD.scala:558); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:808); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:87); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:59); 	at is.hail.expr.ir.InterpretNonCompilable$$anonfun$5.apply(InterpretNonCompilable.scala:16); 	at is.hail.expr.ir.InterpretNonCompil,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5846:6993,schedul,scheduler,6993,https://hail.is,https://github.com/hail-is/hail/issues/5846,1,['schedul'],['scheduler']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1892); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1880); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2113); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2062); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2051); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:11,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:82949,schedul,scheduler,82949,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['schedul'],['scheduler']
Energy Efficiency,t java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at is.hail.sparkextras.ContextRDD.runJob(ContextRDD.scala:456); 	at is.hail.sparkextras.ContextRDD.head(ContextRDD.scala:433); 	at is.hail.rvd.OrderedRVD.head(OrderedRVD.scala:285); 	at is.hail.rvd.OrderedRVD.head(OrderedRVD.scala:21); 	at is.hail.rvd.RVD$class.takeAsBytes(RVD.scala:243); 	at is.hai,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3516:4301,schedul,scheduler,4301,https://hail.is,https://github.com/hail-is/hail/issues/3516,1,['schedul'],['scheduler']
Energy Efficiency,t org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:329); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2717); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2653); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2652); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2652); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1189); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1189); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1189); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2913); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2855); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2844); 	at org.apache.spark.u,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:8442,adapt,adapted,8442,https://hail.is,https://github.com/hail-is/hail/issues/14513,1,['adapt'],['adapted']
Energy Efficiency,"t org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler.handleJobCancellation(DAGScheduler.scala:1457); at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply$mcVI$sp(DAGScheduler.scala:723); at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:723); at org.apache.spark.scheduler.DAGScheduler$$anonfun$doCancelAllJobs$1.apply(DAGScheduler.scala:723); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.doCancelAllJobs(DAGScheduler.scala:723); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onError(DAGScheduler.scala:1741); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:52); 2019-01-22 13:12:06 AbstractConnector: INFO: Stopped Spark@1433e9ec{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2019-01-22 13:12:06 SparkUI: INFO: Stopped Spark web UI at http://10.48.225.55:4040; 2019-01-22 13:12:06 DAGScheduler: INFO: Job 0 failed: fold at RVD.scala:603, took 14.445174 s; 2019-01-22 13:12:06 DAGScheduler: INFO: ResultStage 0 (fold at RVD.scala:603) failed in 14.237 s due to Stage cancelled because SparkContext was shut down; 2019-01-22 13:12:06 root: ERROR: SparkException: Job 0 cancelled because SparkContext was shut down; From org.apache.spark.SparkException: Job 0 cancelled because SparkContext was shut down; at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:820); at org.apache.spark.scheduler.DAGSched",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:205727,schedul,scheduler,205727,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['schedul'],['scheduler']
Energy Efficiency,"t py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745)org.apache.spark.SparkException: Job aborted due to stage failure: Task 22 in stage 5.0 failed 20 times, most recent failure: Lost task 22.19 in stage 5.0 (TID 133, seqr-pipeline-cluster-grch38-w-1.c.seqr-project.internal): org.apache.spark.SparkException: Task failed while writing rows; 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer.writeRows(WriterContainer.scala:261); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.methods.VEP$$anonfun$16$$anon$1.hasNext(VEP.scala:398); 	at is.hail.sparkextras.OrderedRDD$$anonfun$apply$7$$anon$2.hasNext(OrderedRDD.scala:211); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer$$anonfun$writeRows$1.apply$mcV$sp(WriterContainer.scala:253); 	at org.apache.s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1822:4203,schedul,scheduler,4203,https://hail.is,https://github.com/hail-is/hail/issues/1822,1,['schedul'],['scheduler']
Energy Efficiency,t scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3901:7074,schedul,scheduler,7074,https://hail.is,https://github.com/hail-is/hail/issues/3901,2,['schedul'],['scheduler']
Energy Efficiency,t scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3465:8700,schedul,scheduler,8700,https://hail.is,https://github.com/hail-is/hail/issues/3465,5,['schedul'],['scheduler']
Energy Efficiency,t scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:4181,schedul,scheduler,4181,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410,2,['schedul'],['scheduler']
Energy Efficiency,t$$anonfun$33.apply(SparkContext.scala:2125); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:344); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1575); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1563); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1562); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1562); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1790); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1745); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1734); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:619); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126); 	at is.hail.rvd.RVD.aggregateWi,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5846:6656,schedul,scheduler,6656,https://hail.is,https://github.com/hail-is/hail/issues/5846,1,['schedul'],['scheduler']
Energy Efficiency,"t-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,662	job.py	schedule_job:443	schedule job (100, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,663	job.py	schedule_job:443	schedule job (98, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:32,455	job.py	schedule_job:443	schedule job (101, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:32,455	job.py	schedule_job:443	schedule job (102, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:33,456	hail_logging.py	log:40	https POST /pr-11438-default-g6cibyji6520/batch-driver/api/v1alpha/instances/activate done in 3.2369999999998527s: 200; ERROR	2022-03-02 19:06:33,492	job.py	schedule_job:473	error while scheduling job (95, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q	Traceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/connector.py"", line 969, in _wrap_create_connection\n return await self._loop.create_connection(*args, **kwargs) # type: ignore # noqa\n File ""uvloop/loop.pyx"", line 1974, in create_connection\n File ""uvloop/loop.pyx"", line 1951, in uvloop.loop.Loop.create_connection\nConnectionRefusedError: [Errno 111] Connection refused\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n File ""/usr/local/lib/python3.7/dist-packages/batch/driver/job.py"", line 449, in schedule_job\n timeout=aiohttp.ClientTimeout(total=2),\n File ""/usr/local/lib/python3.7/dist-packages/hailtop/httpx.py"", line 113, in request_and_raise_for_status\n resp = await self.client_session._request(method, url, **kwargs)\n File ""/usr/local/lib/python3.7/dist-packages/aiohttp/client.py"", line 521, in _request\n req, traces=traces, timeout=real_timeout\n F",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:2987,schedul,scheduling,2987,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['schedul'],['scheduling']
Energy Efficiency,"t.NativeMethodAccessorImpl.invoke0(Native Method); sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); java.lang.reflect.Method.invoke(Method.java:498); py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); py4j.Gateway.invoke(Gateway.java:280); py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); py4j.commands.CallCommand.execute(CallCommand.java:79); ```. Also under Failed Stages, the Failure Reason was given as:; ```; Job aborted due to stage failure: Task 0 in stage 10.0 failed 20 times, most recent failure: Lost task 0.19 in stage 10.0 (TID 526, ccarey-sw-svrp.c.ukbb-robinson.internal, executor 43): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TBinary$.allocate(TBinary.scala:101); 	at is.hail.annotations.RegionValueBuilder.fixupBinary(RegionValueBuilder.scala:263); 	at is.hail.annotations.RegionValueBuilder.fixupStruct(RegionValueBuilder.scala:319); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:288); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$31$$anonfun$apply$21.apply(Relational.scala:975); 	at is.hail.expr.MatrixMapRows$$anonfun$31$$anonfun$apply$21.apply(Relational.scala:964); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:914); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:908); 	at scala.collection.Iterator$$anon$12.nex",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3508:7902,allocate,allocate,7902,https://hail.is,https://github.com/hail-is/hail/issues/3508,1,['allocate'],['allocate']
Energy Efficiency,t.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: is.hail.utils.HailException: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.io.LoadMatrixParser.parseLine(LoadMatrix.scala:33); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:383); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:377); 	at is.hail.utils.WithContext.wrap(Context.scala:41); 	... 30 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1575); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1563); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1562); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1562); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1790); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1745); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1734); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:6215,schedul,scheduler,6215,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['schedul'],['scheduler']
Energy Efficiency,t.scala:285); 	at org.apache.spark.rdd.UnionRDD.getPartitions(UnionRDD.scala:84); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:250); 	at org.apache.spark.Partitioner$$anonfun$defaultPartitioner$2.apply(Partitioner.scala:66); 	at org.apache.spark.Partitioner$$anonfun$defaultPartitioner$2.apply(Partitioner.scala:66); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.immutable.List.map(List.scala:285); 	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:66); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:329); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:329); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:328); 	at is.hail.methods.MendelErrors.nErrorPerNuclearFamily(MendelErrors.scala:144); 	at is.hail.methods.MendelErrors.fMendelKT(MendelErrors.scala:183); 	at is.hail.variant.MatrixTable.mendelErrors(MatrixTable.scala:1915); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodI,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3039:10207,reduce,reduceByKey,10207,https://hail.is,https://github.com/hail-is/hail/issues/3039,1,['reduce'],['reduceByKey']
Energy Efficiency,t.scala:285); 	at org.apache.spark.rdd.UnionRDD.getPartitions(UnionRDD.scala:84); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:250); 	at org.apache.spark.Partitioner$$anonfun$defaultPartitioner$2.apply(Partitioner.scala:66); 	at org.apache.spark.Partitioner$$anonfun$defaultPartitioner$2.apply(Partitioner.scala:66); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.immutable.List.map(List.scala:285); 	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:66); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:329); 	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:329); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:328); 	at is.hail.methods.MendelErrors.nErrorPerNuclearFamily(MendelErrors.scala:145); 	at is.hail.methods.MendelErrors.fMendelKT(MendelErrors.scala:184); 	at is.hail.variant.MatrixTable.mendelErrors(MatrixTable.scala:1913); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodI,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3074#issuecomment-370494908:8892,reduce,reduceByKey,8892,https://hail.is,https://github.com/hail-is/hail/issues/3074#issuecomment-370494908,1,['reduce'],['reduceByKey']
Energy Efficiency,t; raise reconstructed_error.maybe_user_error(ir); hail.utils.java.FatalError: SocketException: Connection reset. Java stack trace:; javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:226); 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:104); 	at is.hail.relocated.com.google.cloud.storage.UnbufferedReadableByteChannelSession$UnbufferedReadableByteChannel.read(UnbufferedReadableByteChannelSession.java:31); 	at is.hail.relocated.com.google.cloud.storage.DefaultBufferedReadableByteChannel.read(DefaultBufferedReadableByteChannel.java:81); 	at is.hail.relocated.com.google.cloud.storage.StorageByteCh,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12982:3566,Meter,MeteredStream,3566,https://hail.is,https://github.com/hail-is/hail/issues/12982,1,['Meter'],['MeteredStream']
Energy Efficiency,t; raise reconstructed_error.maybe_user_error(ir); hail.utils.java.FatalError: SocketException: Connection reset. Java stack trace:; javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:226); 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:104); 	at is.hail.relocated.com.google.cloud.storage.UnbufferedReadableByteChannelSession$UnbufferedReadableByteChannel.read(UnbufferedReadableByteChannelSession.java:36); 	at is.hail.relocated.com.google.cloud.storage.DefaultBufferedReadableByteChannel.read(DefaultBufferedReadableByteChannel.java:106); 	at is.hail.relocated.com.google.cloud.storage.StorageByteC,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:4454,Meter,MeteredStream,4454,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['Meter'],['MeteredStream']
Energy Efficiency,tClassBuilder$$anon$1.apply(EmitClassBuilder.scala:715); 	at is.hail.expr.ir.EmitClassBuilder$$anon$1.apply(EmitClassBuilder.scala:708); 	at is.hail.expr.ir.CompileIterator$.$anonfun$forTableStageToRVD$1(Compile.scala:311); 	at is.hail.expr.ir.CompileIterator$.$anonfun$forTableStageToRVD$1$adapted(Compile.scala:310); 	at is.hail.expr.ir.lowering.TableStageToRVD$.$anonfun$apply$9(RVDToTableStage.scala:106); 	at is.hail.sparkextras.ContextRDD.$anonfun$cflatMap$2(ContextRDD.scala:211); 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2(RVD.scala:1234); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1233); 	at is.hail.sparkextras.ContextRDD.$anonfun$crunJobWithIndex$1(ContextRDD.scala:242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:131); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:498); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:501); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableAr,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12532:5140,schedul,scheduler,5140,https://hail.is,https://github.com/hail-is/hail/issues/12532,1,['schedul'],['scheduler']
Energy Efficiency,tWriter.scala:190); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:188); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1341); at org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:193); ... 8 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(Sp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2407:7629,schedul,scheduler,7629,https://hail.is,https://github.com/hail-is/hail/issues/2407,1,['schedul'],['scheduler']
Energy Efficiency,"t_errors; return await retry_transient_errors_with_debug_string('', 0, f, *args, **kwargs); File ""/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/hailtop/utils/utils.py"", line 819, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/hail/backend/service_backend.py"", line 517, in _read_output; raise reconstructed_error.maybe_user_error(ir); hail.utils.java.FatalError: HailException: file already exists: gs://aou_analysis/250k/data/utils/aou_mt_sample_qc_250k.ht. Java stack trace:; is.hail.utils.HailException: file already exists: gs://aou_analysis/250k/data/utils/aou_mt_sample_qc_250k.ht; at __C5681Compiled.__m5684begin_group_0(Emit.scala); at __C5681Compiled.__m5683begin_group_0(Emit.scala); at __C5681Compiled.apply(Emit.scala); at is.hail.backend.service.ServiceBackend.$anonfun$execute$1(ServiceBackend.scala:305); at is.hail.backend.service.ServiceBackend.$anonfun$execute$1$adapted(ServiceBackend.scala:305); at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:140); at is.hail.utils.package$.using(package.scala:657); at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:140); at is.hail.backend.service.ServiceBackend.execute(ServiceBackend.scala:305); at is.hail.backend.service.ServiceBackend.execute(ServiceBackend.scala:333); at is.hail.backend.service.ServiceBackendSocketAPI2.$anonfun$parseInputToCommandThunk$15(ServiceBackend.scala:718); at is.hail.backend.service.ServiceBackendSocketAPI2.withIRFunctionsReadFromInput(ServiceBackend.scala:812); at is.hail.backend.service.ServiceBackendSocketAPI2.$anonfun$parseInputToCommandThunk$14(ServiceBackend.scala:716); at is.hail.backend.service.ServiceBackendSocketAPI2.$anonfun$parseInputToCommandThunk$5(ServiceBackend.scala:673); at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:76); at is.hail.utils.package$.using(package.scala:657); at is.hail",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13809:4232,adapt,adapted,4232,https://hail.is,https://github.com/hail-is/hail/issues/13809,1,['adapt'],['adapted']
Energy Efficiency,"tain a fixed width (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91207"">kubernetes/kubernetes#91207</a>, <a href=""https://github.com/iamchuckss""><code>@​iamchuckss</code></a>) [SIG Apps and Node]</li>; <li>Generic ephemeral volumes, a new alpha feature under the <code>GenericEphemeralVolume</code> feature gate, provide a more flexible alternative to <code>EmptyDir</code> volumes: as with <code>EmptyDir</code>, volumes are created and deleted for each pod automatically by Kubernetes. But because the normal provisioning process is used (<code>PersistentVolumeClaim</code>), storage can be provided by third-party storage vendors and all of the usual volume features work. Volumes don't need to be empt; for example, restoring from snapshot is supported. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92784"">kubernetes/kubernetes#92784</a>, <a href=""https://github.com/pohly""><code>@​pohly</code></a>) [SIG API Machinery, Apps, Auth, CLI, Instrumentation, Node, Scheduling, Storage and Testing]</li>; <li>Go1.14.4 is now the minimum version required for building Kubernetes (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92438"">kubernetes/kubernetes#92438</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>) [SIG API Machinery, Auth, CLI, Cloud Provider, Cluster Lifecycle, Instrumentation, Network, Node, Release, Storage and Testing]</li>; <li>Hide managedFields from kubectl edit command (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91946"">kubernetes/kubernetes#91946</a>, <a href=""https://github.com/soltysh""><code>@​soltysh</code></a>) [SIG CLI]</li>; <li>K8s.io/apimachinery - scheme.Convert() now uses only explicitly registered conversions - default reflection based conversion is no longer available. <code>+k8s:conversion-gen</code> tags can be used with the <code>k8s.io/code-generator</code> component to generate conversions. (<a href=""https://gi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:7981,Schedul,Scheduling,7981,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['Schedul'],['Scheduling']
Energy Efficiency,"talError: EsHadoopIllegalArgumentException: Unsupported/Unknown Elasticsearch version 6.0.0. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 12.0 failed 1 times, most recent failure: Lost task 0.0 in stage 12.0 (TID 20050, localhost): org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Cannot detect ES version - typically this happens if the network/Elasticsearch cluster is not accessible or when targeting a WAN/Cloud instance without the proper setting 'es.nodes.wan.only'; 	at org.elasticsearch.hadoop.rest.InitializationUtils.discoverEsVersion(InitializationUtils.java:247); 	at org.elasticsearch.hadoop.rest.RestService.createWriter(RestService.java:545); 	at org.elasticsearch.spark.rdd.EsRDDWriter.write(EsRDDWriter.scala:58); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102); 	at org.elasticsearch.spark.rdd.EsSpark$$anonfun$doSaveToEs$1.apply(EsSpark.scala:102); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Unsupported/Unknown Elasticsearch version 6.0.0; 	at org.elasticsearch.hadoop.util.EsMajorVersion.parse(EsMajorVersion.java:79); 	at org.elasticsearch.hadoop.rest.RestClient.remoteEsVersion(RestClient.java:613); 	at org.elasticsearch.hadoop.rest.InitializationUtils.discoverEsVersion(InitializationUtils.java:240); 	... 10 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4138:2298,schedul,scheduler,2298,https://hail.is,https://github.com/hail-is/hail/issues/4138,1,['schedul'],['scheduler']
Energy Efficiency,tasources.FileFormatWriter$SingleDirectoryWriteTask.execute(FileFormatWriter.scala:244); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:190); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask$3.apply(FileFormatWriter.scala:188); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1341); at org.apache.spark.sql.execution.datasources.FileFormatWriter$.org$apache$spark$sql$execution$datasources$FileFormatWriter$$executeTask(FileFormatWriter.scala:193); ... 8 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2407:7378,schedul,scheduler,7378,https://hail.is,https://github.com/hail-is/hail/issues/2407,1,['schedul'],['scheduler']
Energy Efficiency,teTask(FileFormatWriter.scala:193); ... 8 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1435); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1423); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1422); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1422); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:802); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:802); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1650); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1605); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1594); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:628); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1918); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1931); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1951); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply$mcV$sp(FileFormatWriter.scala:127); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:121); at org.apache.spark.sql.execution.datasources.FileFormatWriter$$anonfun$write$1.apply(FileFormatWriter.scala:121); at org.apache.spark.sql.execution.SQLExecutio,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2407:8050,schedul,scheduler,8050,https://hail.is,https://github.com/hail-is/hail/issues/2407,1,['schedul'],['scheduler']
Energy Efficiency,"tebook; user_id: e7e7b9c420f0b0ff503ab6711355f27748522a8a37d9d22b2c8e0af4; uuid: 84873cf540014e128cce18f5481fb682; name: notebook2-worker-d4snh; namespace: default; resourceVersion: ""41241284""; selfLink: /api/v1/namespaces/default/pods/notebook2-worker-d4snh; uid: 8cb3c1c2-5580-11e9-bcd4-42010a8000c9; spec:; containers:; - command:; - jupyter; - notebook; - --NotebookApp.token=484b71e2c12d42c79b169b1991602d45; - --NotebookApp.base_url=/instance/84873cf540014e128cce18f5481fb682/; - --ip; - 0.0.0.0; - --no-browser; image: gcr.io/hail-vdc/hail-jupyter:2c2281012d0b2171837e99fe50c8656395c7adafd93b3821af6c0a605ffaea1e; imagePullPolicy: IfNotPresent; name: default; ports:; - containerPort: 8888; protocol: TCP; readinessProbe:; failureThreshold: 3; httpGet:; path: /instance/84873cf540014e128cce18f5481fb682/login; port: 8888; scheme: HTTP; periodSeconds: 5; successThreshold: 1; timeoutSeconds: 1; resources:; requests:; cpu: ""1.601""; memory: 1.601G; terminationMessagePath: /dev/termination-log; terminationMessagePolicy: File; volumeMounts:; - mountPath: /gsa-key-secret-name; name: gsa-key-secret-name; readOnly: true; - mountPath: /var/run/secrets/kubernetes.io/serviceaccount; name: user-kmpnh-token-hbdd4; readOnly: true; dnsPolicy: ClusterFirst; nodeName: gke-vdc-non-preemptible-pool-0106a51b-l48l; restartPolicy: Always; schedulerName: default-scheduler; securityContext: {}; serviceAccount: user-kmpnh; serviceAccountName: user-kmpnh; terminationGracePeriodSeconds: 30; tolerations:; - effect: NoExecute; key: node.kubernetes.io/not-ready; operator: Exists; tolerationSeconds: 300; - effect: NoExecute; key: node.kubernetes.io/unreachable; operator: Exists; tolerationSeconds: 300; volumes:; - name: gsa-key-secret-name; secret:; defaultMode: 420; secretName: gsa-key-j7gwm; - name: user-kmpnh-token-hbdd4; secret:; defaultMode: 420; secretName: user-kmpnh-token-hbdd4. hostIP: 10.128.0.32; phase: Running; podIP: 10.32.19.165; qosClass: Burstable; startTime: ""2019-04-02T19:50:21Z""; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5753#issuecomment-479174611:2929,schedul,schedulerName,2929,https://hail.is,https://github.com/hail-is/hail/pull/5753#issuecomment-479174611,4,['schedul'],"['scheduler', 'schedulerName']"
Energy Efficiency,"ted caused by one of the running tasks) Reason: Slave lost; Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 0.0 failed 4 times, most recent failure: Lost task 7.3 in stage 0.0 (TID 86, scc-q16.scc.bu.edu, executor 26): ExecutorLostFailure (executor 26 exited caused by one of the running tasks) Reason: Slave lost; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126); at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1089); at org.apache.spark.rdd.RDDOperationScope$.withScope(RD",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456417572:8844,schedul,scheduler,8844,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456417572,1,['schedul'],['scheduler']
Energy Efficiency,"ted, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]; 2019-01-22 13:12:06 YarnSchedulerBackend$YarnSchedulerEndpoint: ERROR: Error requesting driver to remove executor 14 after disconnection.; org.apache.spark.rpc.RpcEnvStoppedException: RpcEnv already stopped.; at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:155); at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:132); at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:228); at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:515); at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:63); at org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint$$anonfun$org$apache$spark$scheduler$cluster$YarnSchedulerBackend$$handleExecutorDisconnectedFromDriver$2.apply(YarnSchedulerBackend.scala:253); at org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint$$anonfun$org$apache$spark$scheduler$cluster$YarnSchedulerBackend$$handleExecutorDisconnectedFromDriver$2.apply(YarnSchedulerBackend.scala:252); at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:253); at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293); at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136); at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40); at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248); at scala.concurrent.Promise$class.complete(Promise.scala:55); at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:153); at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326); at scala.concurrent.Future$$anonfun$recover$1.apply(Future.scala:326); at scala.concurrent.impl.Callb",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:215097,schedul,scheduler,215097,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['schedul'],['scheduler']
Energy Efficiency,terator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3413:4255,schedul,scheduler,4255,https://hail.is,https://github.com/hail-is/hail/issues/3413,1,['schedul'],['scheduler']
Energy Efficiency,terator.scala:1431); 	at is.hail.asm4s.ModuleBuilder.classesBytes(ClassBuilder.scala:152); 	at is.hail.expr.ir.EmitClassBuilder.resultWithIndex(EmitClassBuilder.scala:706); 	at is.hail.expr.ir.WrappedEmitClassBuilder.resultWithIndex(EmitClassBuilder.scala:174); 	at is.hail.expr.ir.WrappedEmitClassBuilder.resultWithIndex$(EmitClassBuilder.scala:174); 	at is.hail.expr.ir.EmitFunctionBuilder.resultWithIndex(EmitClassBuilder.scala:1078); 	at is.hail.expr.ir.Emit.$anonfun$emitI$238(Emit.scala:2400); 	at is.hail.expr.ir.IEmitCodeGen.map(Emit.scala:336); 	at is.hail.expr.ir.Emit.emitI(Emit.scala:2341); 	at is.hail.expr.ir.Emit.emitI$1(Emit.scala:630); 	at is.hail.expr.ir.Emit.$anonfun$emitVoid$26(Emit.scala:748); 	at is.hail.expr.ir.TableTextFinalizer.writeMetadata(TableWriter.scala:552); 	at is.hail.expr.ir.Emit.emitVoid(Emit.scala:748); 	at is.hail.expr.ir.Emit.emitVoid$1(Emit.scala:627); 	at is.hail.expr.ir.Emit.$anonfun$emitVoid$5(Emit.scala:644); 	at is.hail.expr.ir.Emit.$anonfun$emitVoid$5$adapted(Emit.scala:644); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.Emit.$anonfun$emitVoid$4(Emit.scala:644); 	at is.hail.expr.ir.Emit.$anonfun$emitVoid$4$adapted(Emit.scala:643); 	at is.hail.expr.ir.EmitCodeBuilder$.scoped(EmitCodeBuilder.scala:18); 	at is.hail.expr.ir.EmitCodeBuilder$.scopedVoid(EmitCodeBuilder.scala:28); 	at is.hail.expr.ir.EmitMethodBuilder.voidWithBuilder(EmitClassBuilder.scala:1011); 	at is.hail.expr.ir.Emit.$anonfun$emitVoid$3(Emit.scala:643); 	at is.hail.expr.ir.Emit.$anonfun$emitVoid$3$adapted(Emit.scala:641); 	at scala.collection.Iterator.foreach(Iterator.scala:943); 	at scala.collection.Iterator.foreach$(Iterator.scala:943); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431); 	at is.hail.expr.ir.Emit.emitVoid(Emit.scala:641); 	at is.hail,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12531:6243,adapt,adapted,6243,https://hail.is,https://github.com/hail-is/hail/issues/12531,1,['adapt'],['adapted']
Energy Efficiency,"ternal signal; .; Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 23.0 failed 4 times, most recent failure: Lost task 0.3 in stage 23.0 (TID 26) (all-of-us-56-w-0.c.terra-vpc-sc-8f5cdfd2.internal executor 5): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Container from a bad node: container_1691092255852_0001_01_000005 on host: all-of-us-56-w-0.c.terra-vpc-sc-8f5cdfd2.internal. Exit status: 137. Diagnostics: [2023-08-03 20:14:25.441]Container killed on request. Exit code is 137; [2023-08-03 20:14:25.442]Container exited with a non-zero exit code 137. ; [2023-08-03 20:14:25.442]Killed by external signal; .; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1124); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2491); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2433); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2422); 	at org.apache.spark.u",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287#issuecomment-1664593619:5337,adapt,adapted,5337,https://hail.is,https://github.com/hail-is/hail/issues/13287#issuecomment-1664593619,1,['adapt'],['adapted']
Energy Efficiency,ternal(AbstractStringBuilder.java:124); at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:448); at java.lang.StringBuffer.append(StringBuffer.java:270); at org.apache.log4j.helpers.PatternParser$LiteralPatternConverter.format(PatternParser.java:419); at org.apache.log4j.PatternLayout.format(PatternLayout.java:506); at org.apache.log4j.WriterAppender.subAppend(WriterAppender.java:310); at org.apache.log4j.WriterAppender.append(WriterAppender.java:162); at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251); at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66); at org.apache.log4j.Category.callAppenders(Category.java:206); at org.apache.log4j.Category.forcedLog(Category.java:391); at org.apache.log4j.Category.log(Category.java:856); at org.slf4j.impl.Log4jLoggerAdapter.warn(Log4jLoggerAdapter.java:400); at org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66); at org.apache.spark.scheduler.TaskSetManager.logWarning(TaskSetManager.scala:52); at org.apache.spark.scheduler.TaskSetManager.handleFailedTask(TaskSetManager.scala:693); at org.apache.spark.scheduler.TaskSchedulerImpl.handleFailedTask(TaskSchedulerImpl.scala:421); at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply$mcV$sp(TaskResultGetter.scala:139); at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply(TaskResultGetter.scala:124); at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply(TaskResultGetter.scala:124); at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1953); at org.apache.spark.scheduler.TaskResultGetter$$anon$3.run(TaskResultGetter.scala:124); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ```; `pyhail-submit`:; ```bash; #!/bin/bash. if [ $# -ne 2 ]; then,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1186#issuecomment-267416027:1509,schedul,scheduler,1509,https://hail.is,https://github.com/hail-is/hail/issues/1186#issuecomment-267416027,2,['schedul'],['scheduler']
Energy Efficiency,"ternal. Exit status: 137. Diagnostics: [2023-07-24 13:52:49.515]Container killed on request. Exit code is 137; [2023-07-24 13:52:49.517]Container exited with a non-zero exit code 137. ; [2023-07-24 13:52:49.518]Killed by external signal; .; Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.4 in stage 1.0 (TID 10) (all-of-us-1774-w-0.c.terra-vpc-sc-23dfb1a3.internal executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container from a bad node: container_e01_1690206305672_0001_01_000007 on host: all-of-us-1774-w-0.c.terra-vpc-sc-23dfb1a3.internal. Exit status: 137. Diagnostics: [2023-07-24 13:52:49.515]Container killed on request. Exit code is 137; [2023-07-24 13:52:49.517]Container exited with a non-zero exit code 137. ; [2023-07-24 13:52:49.518]Killed by external signal; .; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1124); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGSchedul",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287:6397,schedul,scheduler,6397,https://hail.is,https://github.com/hail-is/hail/issues/13287,1,['schedul'],['scheduler']
Energy Efficiency,tests are green now,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11323#issuecomment-1041946188:10,green,green,10,https://hail.is,https://github.com/hail-is/hail/pull/11323#issuecomment-1041946188,1,['green'],['green']
Energy Efficiency,textRDD.scala:355); at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$27.apply(ContextRDD.scala:355); at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5.apply(ContextRDD.scala:135); at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5.apply(ContextRDD.scala:135); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4755#issuecomment-438447635:5063,schedul,scheduler,5063,https://hail.is,https://github.com/hail-is/hail/issues/4755#issuecomment-438447635,1,['schedul'],['scheduler']
Energy Efficiency,thIndex$1$$anonfun$apply$27.apply(ContextRDD.scala:355); at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5.apply(ContextRDD.scala:135); at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5.apply(ContextRDD.scala:135); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4755#issuecomment-438447635:5161,schedul,scheduler,5161,https://hail.is,https://github.com/hail-is/hail/issues/4755#issuecomment-438447635,1,['schedul'],['scheduler']
Energy Efficiency,thanks for leading the charge to fix this stuff fast!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8806#issuecomment-629406978:23,charge,charge,23,https://hail.is,https://github.com/hail-is/hail/pull/8806#issuecomment-629406978,1,['charge'],['charge']
Energy Efficiency,the two rewrites have made this much more powerful and understandable,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5245#issuecomment-464144563:42,power,powerful,42,https://hail.is,https://github.com/hail-is/hail/pull/5245#issuecomment-464144563,1,['power'],['powerful']
Energy Efficiency,"think helped to reduce the number of places that are aware of the notion of a default_region. It's really now just isolated to the `InstanceCollectionManager`, since that's the piece of code that's making the decision ""use the default region when the cluster is small"". I didn't quite like the pattern of retrieving a default from a `LocationMonitor` just to give it right back to the location monitor in the next line. I think this way the `LocationMonitor` API is much simpler, and we can actually remove its `default_location` method entirely as I believe it is no longer used. I can do that in a follow-up PR if you like this approach. One other thing is I wanted to articulate the distinction between the ""region CI needs its jobs in"" and the ""default region that batch will spin up workers in for small clusters"". While they are in practice the same, I found that treating them both as the ""default_region"" tied the logic around jobs for CI closely with internal Batch decisions and made it more confusing for me to reason about. I tried to separate out these two concepts so that in the future when jobs support region-specific scheduling it will be easier to excise the CI-specific code from the Batch scheduler. Another thing that I realized during this process is that Azure has regions and zones just like GCP, though they may differ slightly since we don't need to specify a zone for a VM and such. I am fine with using the term ""location"" to mean ""where we scheduled the VM, either zone or region depending on the cloud provider"", but I would also like to follow up with a sweep that makes this language more precise where possible. For example, the `possible_cloud_locations` function is really just `possible_cloud_regions`, and we could even go so far as mandating a `region` field in the global config instead of having `azure_location` and `gcp_region`, which are synonymous even though named differently. It also leads me to wonder why we only schedule in a single region in Azure?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12078#issuecomment-1207095240:1160,schedul,scheduling,1160,https://hail.is,https://github.com/hail-is/hail/pull/12078#issuecomment-1207095240,8,['schedul'],"['schedule', 'scheduled', 'scheduler', 'scheduling']"
Energy Efficiency,"this code](https://github.com/broadinstitute/gnomad_methods/blob/0d2e71f93d5cfceebfad2ab538e47d8457d57d6d/gnomad/sample_qc/sex.py#L18-L46):. ```python; male = karyotype_expr == xy_karyotype_str; female = karyotype_expr == xx_karyotype_str; x_nonpar = locus_expr.in_x_nonpar(); y_par = locus_expr.in_y_par(); y_nonpar = locus_expr.in_y_nonpar(); return (; hl.case(missing_false=True); .when(female & (y_par | y_nonpar), hl.null(hl.tcall)); .when(male & (x_nonpar | y_nonpar) & gt_expr.is_het(), hl.null(hl.tcall)); .when(male & (x_nonpar | y_nonpar), hl.call(gt_expr[0], phased=False)); .default(gt_expr); ); ```; A single partition is taking a very long time to compute. Manual sampling of stack traces via `jstack` or the Spark UI reveals we spend a lot of time in computing the inPar predicates:; ```; app//is.hail.utils.Interval.contains(Interval.scala:67); app//is.hail.variant.ReferenceGenome.$anonfun$inPar$1(ReferenceGenome.scala:298); app//is.hail.variant.ReferenceGenome.$anonfun$inPar$1$adapted(ReferenceGenome.scala:298); app//is.hail.variant.ReferenceGenome$Lambda$924/0x00000008009b2840.apply(Unknown Source); app//scala.collection.IndexedSeqOptimized.prefixLengthImpl(IndexedSeqOptimized.scala:41); app//scala.collection.IndexedSeqOptimized.exists(IndexedSeqOptimized.scala:49); app//scala.collection.IndexedSeqOptimized.exists$(IndexedSeqOptimized.scala:49); app//scala.collection.mutable.ArrayOps$ofRef.exists(ArrayOps.scala:198); app//is.hail.variant.ReferenceGenome.inPar(ReferenceGenome.scala:298); app//is.hail.variant.ReferenceGenome.inYPar(ReferenceGenome.scala:302)__C9622collect_distributed_array_table_native_writer.__m10668inYPar(Unknown Source)__C9622collect_distributed_array_table_native_writer.__m10656split_Let(Unknown Source)__C9622collect_distributed_array_table_native_writer.__m10638split_ToArray_region3_65(Unknown Source)__C9622collect_distributed_array_table_native_writer.__m10638split_ToArray(Unknown Source)__C9622collect_distributed_array_table_native_writer.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13862:1027,adapt,adapted,1027,https://hail.is,https://github.com/hail-is/hail/issues/13862,1,['adapt'],['adapted']
Energy Efficiency,til.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: is.hail.utils.HailException: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.io.LoadMatrixParser.parseLine(LoadMatrix.scala:33); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:383); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:377); 	at is.hail.utils.WithContext.wrap(Context.scala:41); 	... 30 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1575); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1563); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1562); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1562); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1790); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1745); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:6117,schedul,scheduler,6117,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['schedul'],['scheduler']
Energy Efficiency,tingDecimal.readJavaFormatString(FloatingDecimal.java:2043); at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110); at java.lang.Double.parseDouble(Double.java:538); at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:284); at scala.collection.immutable.StringOps.toDouble(StringOps.scala:29); at is.hail.io.vcf.VCFLine.parseDoubleInFormatArray(LoadVCF.scala:371); at is.hail.io.vcf.VCFLine.parseAddFormatArrayDouble(LoadVCF.scala:431); at is.hail.io.vcf.FormatParser.parseAddField(LoadVCF.scala:483); at is.hail.io.vcf.FormatParser.parse(LoadVCF.scala:514); at is.hail.io.vcf.LoadVCF$$anonfun$13.apply(LoadVCF.scala:867); at is.hail.io.vcf.LoadVCF$$anonfun$13.apply(LoadVCF.scala:848); at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:717); ... 35 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3361:6482,schedul,scheduler,6482,https://hail.is,https://github.com/hail-is/hail/issues/3361,1,['schedul'],['scheduler']
Energy Efficiency,"tion.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:389); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1354); 	at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1354); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-a1d6ecc; Error summary: NoSuchElementException: key not found: GT; ```; The file has `GT` in the format field, but it's missing the corresponding header line. Passing a custom `header_file=` fixes the problem, but it's unfortunate that that's required (especially on such a widely used publicly available dataset).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3467:13535,schedul,scheduler,13535,https://hail.is,https://github.com/hail-is/hail/issues/3467,2,['schedul'],['scheduler']
Energy Efficiency,tion.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1354); 	at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1354); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.util.NoSuchElementException: key not found: GT; 	at scala.collection.MapLike$class.default(MapLike.scala:228); 	at scala.collection.AbstractMap.default(Map.scala:59); 	at scala.collection.MapLike$class.apply(MapLike.scala:141); 	at scala.collection.AbstractMap.apply(Map.scala:59); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); 	at scala.collection.TraversableLike$class.map(Trave,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3467:3215,schedul,scheduler,3215,https://hail.is,https://github.com/hail-is/hail/issues/3467,1,['schedul'],['scheduler']
Energy Efficiency,tion.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1354); 	at org.apache.spark.rdd.RDD$$anonfun$take$1$$anonfun$29.apply(RDD.scala:1354); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748)java.util.NoSuchElementException: key not found: GT; 	at scala.collection.MapLike$class.default(MapLike.scala:228); 	at scala.collection.AbstractMap.default(Map.scala:59); 	at scala.collection.MapLike$class.apply(MapLike.scala:141); 	at scala.collection.AbstractMap.apply(Map.scala:59); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); 	at scala.collection.TraversableLike$class.map(TraversableLike.sc,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3467:10041,schedul,scheduler,10041,https://hail.is,https://github.com/hail-is/hail/issues/3467,1,['schedul'],['scheduler']
Energy Efficiency,tionTimer$.time(ExecutionTimer.scala:52); E 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59); E 	at is.hail.backend.service.ServiceBackendSocketAPI2.withExecuteContext$1(ServiceBackend.scala:631); E 	at is.hail.backend.service.ServiceBackendSocketAPI2.executeOneCommand(ServiceBackend.scala:693); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$6(ServiceBackend.scala:459); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$6$adapted(ServiceBackend.scala:458); E 	at is.hail.utils.package$.using(package.scala:635); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$5(ServiceBackend.scala:458); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.services.package$.retryTransientErrors(package.scala:124); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$4(ServiceBackend.scala:458); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$4$adapted(ServiceBackend.scala:456); E 	at is.hail.utils.package$.using(package.scala:635); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$3(ServiceBackend.scala:456); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.services.package$.retryTransientErrors(package.scala:124); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.main(ServiceBackend.scala:456); E 	at is.hail.backend.service.Main$.main(Main.scala:15); E 	at is.hail.backend.service.Main.main(Main.scala); E 	at sun.reflect.GeneratedMethodAccessor90.invoke(Unknown Source); E 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); E 	at java.lang.reflect.Method.invoke(Method.java:498); E 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119); E 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); E 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); E 	at java.util.concurrent.Executors$RunnableAdapte,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12976:6713,adapt,adapted,6713,https://hail.is,https://github.com/hail-is/hail/issues/12976,2,['adapt'],['adapted']
Energy Efficiency,tionTimer$.time(ExecutionTimer.scala:52); E 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59); E 	at is.hail.backend.service.ServiceBackendSocketAPI2.withExecuteContext$1(ServiceBackend.scala:634); E 	at is.hail.backend.service.ServiceBackendSocketAPI2.executeOneCommand(ServiceBackend.scala:697); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$6(ServiceBackend.scala:462); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$6$adapted(ServiceBackend.scala:461); E 	at is.hail.utils.package$.using(package.scala:635); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$5(ServiceBackend.scala:461); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.services.package$.retryTransientErrors(package.scala:134); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$4(ServiceBackend.scala:460); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$4$adapted(ServiceBackend.scala:459); E 	at is.hail.utils.package$.using(package.scala:635); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$3(ServiceBackend.scala:459); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.services.package$.retryTransientErrors(package.scala:134); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.main(ServiceBackend.scala:458); E 	at is.hail.backend.service.Main$.main(Main.scala:15); E 	at is.hail.backend.service.Main.main(Main.scala); E 	at sun.reflect.GeneratedMethodAccessor62.invoke(Unknown Source); E 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); E 	at java.lang.reflect.Method.invoke(Method.java:498); E 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119); E 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); E 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); E 	at java.util.concurrent.Executors$RunnableAdapte,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13074:6427,adapt,adapted,6427,https://hail.is,https://github.com/hail-is/hail/issues/13074,2,['adapt'],['adapted']
Energy Efficiency,titionCounts(MatrixTable.scala:697); 	at is.hail.variant.MatrixTable.countRows(MatrixTable.scala:1284); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745)java.lang.NegativeArraySizeException: null; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.codegen.generated.C4.apply(Unknown Source); 	at is.hail.codegen.generated.C4.apply(Unknown Source); 	at is.hail.io.CompiledPackDecoder.readRegionValue(RowStore.scala:649); 	at is.hail.HailContext$$anon$2.next(HailContext.scala:246); 	at is.hail.HailContext$$anon$2.next(HailContext.scala:219); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.sparkextras.ContextRDD$$anonfun$czip$1$$anon$1.next(ContextRDD.scala:322); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:912); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:906); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3901:10100,allocate,allocate,10100,https://hail.is,https://github.com/hail-is/hail/issues/3901,1,['allocate'],['allocate']
Energy Efficiency,titionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.sp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3235:5230,schedul,scheduler,5230,https://hail.is,https://github.com/hail-is/hail/issues/3235,1,['schedul'],['scheduler']
Energy Efficiency,"titionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55); 	at org.apache.spark.scheduler.Task.run(Task.scala:121); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.21-1d317a44e5fd; Error summary: NoSuchElementException: key not found: GRCh37; ```. ### Error No. 2; ```python; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); /usr/local/lib/python3.6/site-packages/IPython/core/formatters.py in __call__(self, obj); 343 method = get_r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:25500,schedul,scheduler,25500,https://hail.is,https://github.com/hail-is/hail/issues/7044,1,['schedul'],['scheduler']
Energy Efficiency,titionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55); 	at org.apache.spark.scheduler.Task.run(Task.scala:121); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). java.util.NoSuchElementException: key not found: GRCh37; 	at scala.collection.MapLike$class.default(MapLike.scala:228); 	at scala.collection.AbstractMap.default(Map.scala:59); 	at scala.collection.MapLike$class.apply(MapLike.scala:141); 	at scala.collection.AbstractMap.apply(Map.scala:59); 	at is.hail.expr.ir.TypeParserEnvironment.getReferenceGenome(Parser.sc,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:19159,schedul,scheduler,19159,https://hail.is,https://github.com/hail-is/hail/issues/7044,2,['schedul'],['scheduler']
Energy Efficiency,titionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55); 	at org.apache.spark.scheduler.Task.run(Task.scala:121); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.util.NoSuchElementException: key not found: GRCh37; 	at scala.collection.MapLike$class.default(MapLike.scala:228); 	at scala.collection.AbstractMap.default(Map.scala:59); 	at scala.collection.MapLike$class.apply(MapLike.scala:141); 	at scala.collection.AbstractMap.apply(Map.scala:59); 	at is.hail.expr.ir.TypeParserEnvironment.getReferenceGenom,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:7436,schedul,scheduler,7436,https://hail.is,https://github.com/hail-is/hail/issues/7044,2,['schedul'],['scheduler']
Energy Efficiency,"to be a little more in line with need, and to make the non-preemptible pods more packable. The ukbb-rg pods are pretty slow, so I didn't reduce them.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8711:137,reduce,reduce,137,https://hail.is,https://github.com/hail-is/hail/pull/8711,1,['reduce'],['reduce']
Energy Efficiency,"to complete before it starts the next iteration of the scheduler. This leaves the scheduler vulnerable to problematic workers or workers that happen to be preempted during the scheduling process. So, the driver sets a [2 second timeout](https://github.com/hail-is/hail/blob/b27737f67bf9e69f1abed2fec07fc7c921790ef8/batch/batch/driver/job.py#L585) on the call to `/api/v1alpha/batches/jobs/create`. Additionally, this general design means that in the event of a request timeout or transient error, Batch cannot guarantee that there is always at most one concurrent running attempt for a given job. This ends up being a fine (and intentional) concession in practice because the idempotent design of preemptible jobs tends to cover this scenario, but it is regardless wasted compute and cost to users. Nevertheless, we strive to minimize cases where we might halt the scheduling loop or double-schedule work, and one way to do that in the current design is to minimize the variance in latency of `/api/v1alpha/batches/jobs/create`. The largest source of this latency is the request to blob storage. While GCS and ABS are relatively fast and highly available, Batch in Azure Terra requires first obtaining SAS tokens from the Terra control plane, which can introduce much higher and more variable latency. There have also been occurrences in the past of corrupted or deleted specs, which introduce unexpected failure modes that should error the job but instead disrupt the scheduling loop. Many of these problems would be mitigated by moving the read from object storage outside of the `/api/v1alpha/batches/jobs/create` endpoint. The endpoint should push this read into the asynchronous task that ultimately runs the job and therefore return its acknowledgement to the driver faster. If the worker encounters errors later on while reading the spec, those should result in `error`ing the job instead of raising a 500 in the scheduling request. ### Version. 0.2.129. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14456:2414,schedul,scheduling,2414,https://hail.is,https://github.com/hail-is/hail/issues/14456,2,['schedul'],['scheduling']
Energy Efficiency,"to import Python object. As a workaround, you can disable the; behavior via <code>grouped_exception=False</code> keyword argument until v7.0.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9962"">#9962</a>: texinfo: Customizing styles of emphasized text via <code>@definfoenclose</code>; command was not supported because the command was deprecated since texinfo 6.8</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/2068"">#2068</a>: :confval:<code>intersphinx_disabled_reftypes</code> has changed default value; from an empty list to <code>['std:doc']</code> as avoid too surprising silent; intersphinx resolutions.; To migrate: either add an explicit inventory name to the references; intersphinx should resolve, or explicitly set the value of this configuration; variable to an empty list.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10197"">#10197</a>: html theme: Reduce <code>body_min_width</code> setting in basic theme to 360px</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9999"">#9999</a>: LaTeX: separate terms from their definitions by a CR (refs: <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9985"">#9985</a>)</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10062"">#10062</a>: Change the default language to <code>'en'</code> if any language is not set in; <code>conf.py</code></li>; </ul>; <p>5.0.0 final</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10474"">#10474</a>: :confval:<code>language</code> does not accept <code>None</code> as it value. The default; value of <code>language</code> becomes to <code>'en'</code> now.</li>; </ul>; <h2>Deprecated</h2>; <p>5.0.0 b1</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10028"">#10028</a>: jQuery and underscore.js will no longer be automatically inje",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11871:2779,Reduce,Reduce,2779,https://hail.is,https://github.com/hail-is/hail/pull/11871,1,['Reduce'],['Reduce']
Energy Efficiency,"to import Python object. As a workaround, you can disable the; behavior via <code>grouped_exception=False</code> keyword argument until v7.0.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9962"">#9962</a>: texinfo: Customizing styles of emphasized text via <code>@definfoenclose</code>; command was not supported because the command was deprecated since texinfo 6.8</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/2068"">#2068</a>: :confval:<code>intersphinx_disabled_reftypes</code> has changed default value; from an empty list to <code>['std:doc']</code> as avoid too surprising silent; intersphinx resolutions.; To migrate: either add an explicit inventory name to the references; intersphinx should resolve, or explicitly set the value of this configuration; variable to an empty list.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10197"">#10197</a>: html theme: Reduce <code>body_min_width</code> setting in basic theme to 360px</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9999"">#9999</a>: LaTeX: separate terms from their definitions by a CR (refs: <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9985"">#9985</a>)</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10062"">#10062</a>: Change the default language to <code>'en'</code> if any language is not set in; <code>conf.py</code></li>; </ul>; <p>5.0.0 final</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10474"">#10474</a>: :confval:<code>language</code> does not accept <code>None</code> as it value. The default</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/8fe27991ba23268b17fad2e2fe2548074ad6cf26""><code>8fe2799</code></a> Bump to 5.0.1 final<",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11885:3578,Reduce,Reduce,3578,https://hail.is,https://github.com/hail-is/hail/pull/11885,1,['Reduce'],['Reduce']
Energy Efficiency,tor$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1795); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:2998,schedul,scheduler,2998,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627,1,['schedul'],['scheduler']
Energy Efficiency,tor$TaskRunner.run(Executor.scala:500); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2254); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2203); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2202); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2202); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2441); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2383); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2372); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2202); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2223); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2242); 	at is.hail.sparkextras.ContextRDD.runJob(ContextRDD.scala:362); 	at is.hail.rvd.RVD.$anonfun$head$1(RVD.scala:526); 	at is.hail.utils.PartitionCou,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:8567,schedul,scheduler,8567,https://hail.is,https://github.com/hail-is/hail/issues/10682,1,['schedul'],['scheduler']
Energy Efficiency,tor$TaskRunner.run(Executor.scala:501); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1124); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2491); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2433); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2422); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:902); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2204); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2225); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2257); 	at is.hail.sparkextras.ContextRDD.crunJobWithIndex(ContextRDD.scala:238); 	at is.hail.rvd.RVD$.getKeyInfo(RVD.scala:1233); 	at is.hail.rvd.RVD$.ma,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12532:6435,schedul,scheduler,6435,https://hail.is,https://github.com/hail-is/hail/issues/12532,1,['schedul'],['scheduler']
Energy Efficiency,tor(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55); 	at org.apache.spark.scheduler.Task.run(Task.scala:121); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.21-1d317a44e5fd; Error summary: NoSuchElementException: key not found: GRCh37; ```. Thanks!,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:50481,schedul,scheduler,50481,https://hail.is,https://github.com/hail-is/hail/issues/7044,3,['schedul'],['scheduler']
Energy Efficiency,tor.scala:1431); 	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1021); 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2276); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2673); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2609); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2608); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2608); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2861); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSched,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12936:5221,schedul,scheduler,5221,https://hail.is,https://github.com/hail-is/hail/issues/12936,1,['schedul'],['scheduler']
Energy Efficiency,"tors and matrices with primary dimension the number of samples (as in QR), and because BLAS3 matrix multiplication is fast. I also checked that upping to 8 covariates didn't balance things out. It didn't. The fancy approach basically trades X.t * X and generic k-dim solve for a QR on X and triangular k-dim solve...better for larger k and smaller n. ```; Standard. 2 cov; Lin 7s; Score 54.5s; LRT 93s; Wald 90s. 2 cov, QR / TriSolve; Lin 7.42s; Score 53.6s, 53.1s; LRT 2m06s, 1m59s; Wald 1m53s, 1m54s. 8 cov; Lin 7.16s; Score 59.1s; LRT 2m25s, 2m20s, 2m26s; Wald 2m27s, 2m27s, 2m25s. 8 cov, QR / TriSolve; Lin 7.76s; Score 52.7s; LRT 3m30s; Wald 3m26s; ```. For Firth, since I'm using QR anyway, may as will use TriSolve (though the timing is not particularly effected even with 8 covariates):. ```; 2 cov:; Firth 5m 10s, 4m55s, 5m7s. 8 cov:; Firth 10m37s, 10m50s, 10m28s; ```. For reference, here's the core logic of the QR approach. This corresponds to another version of LogisticRegressionFit where I tried to reduce unnecessary computation, see below. ```; while (!converged && !exploded && iter <= maxIter) {; try {; val mu = sigmoid(X * b); val sqrtW = sqrt(mu :* (1d - mu)); val QR = qr.reduced(X(::, *) :* sqrtW). deltaB = TriSolve(QR.r, QR.q.t * ((y - mu) :/ sqrtW)). if (max(abs(deltaB)) < tol) {; converged = true; if (computeScoreR) {; optScore = Some(X.t * (y - mu)); optR = Some(QR.r); }; if (computeSe) {; val invR = inv(QR.r) // could speed up inverting as upper triangular, or avoid altogether as 1 / se(-1) = fit.fisherSqrt(-1, -1); optSe = Some(norm(invR(*, ::))); }; if (computeLogLkld); optLogLkhd = Some(sum(breeze.numerics.log((y :* mu) + ((1d - y) :* (1d - mu))))); } else {; iter += 1; b += deltaB; }; }; ```. ```; case class LogisticRegressionFit(; b: DenseVector[Double],; optScore: Option[DenseVector[Double]],; optR: Option[DenseMatrix[Double]],; optSe: Option[DenseVector[Double]],; optLogLkhd: Option[Double],; nIter: Int,; converged: Boolean,; exploded: Boolean); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1375#issuecomment-279532833:1420,reduce,reduced,1420,https://hail.is,https://github.com/hail-is/hail/pull/1375#issuecomment-279532833,1,['reduce'],['reduced']
Energy Efficiency,"track which version of the deployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": ""https GET /michaelfranklin/query/api/v1alpha/wait done in 50.029999999998836s: 200"", ""remote_address"": ""10.28.127.3"", ""request_start_time"": ""[24/Feb/2021:23:22:35 +0000]"", ""request_duration"": 50.029999999998836, ""response_status"": 200, ""x_real_ip"": ""124.170.20.28"", ""hail_log"": 1}; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,005"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:255"", ""message"": ""Tasks have all completed."", ""hail_log"": 1}; ```. Test dur",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10106:1487,schedul,scheduled,1487,https://hail.is,https://github.com/hail-is/hail/pull/10106,1,['schedul'],['scheduled']
Energy Efficiency,trix.scala:1829); at scala.Array$.tabulate(Array.scala:331); at is.hail.linalg.WriteBlocksRDD.compute(BlockMatrix.scala:1829); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403:12293,schedul,scheduler,12293,https://hail.is,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403,1,['schedul'],['scheduler']
Energy Efficiency,trixTable.countRows(MatrixTable.scala:1284); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745)java.lang.NegativeArraySizeException: null; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.codegen.generated.C4.apply(Unknown Source); 	at is.hail.codegen.generated.C4.apply(Unknown Source); 	at is.hail.io.CompiledPackDecoder.readRegionValue(RowStore.scala:649); 	at is.hail.HailContext$$anon$2.next(HailContext.scala:246); 	at is.hail.HailContext$$anon$2.next(HailContext.scala:219); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.sparkextras.ContextRDD$$anonfun$czip$1$$anon$1.next(ContextRDD.scala:322); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:912); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:906); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(OrderedRVD.scala:912); 	at is.hail.rvd.Ord,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3901:10159,allocate,allocate,10159,https://hail.is,https://github.com/hail-is/hail/issues/3901,1,['allocate'],['allocate']
Energy Efficiency,"troduced they will follow the strucutre outlined for non-primitive types. PFloat32. - Represents a 4 byte float. PFloat64. - Represents an 8 byte float. PInt32. - Represents a 4 byte integer. PInt64. - Represents an 8 byte integer. PVoid. <br/>. # Common methods. ```scala; def constructAtAddress(mb: MethodBuilder, addr: Code[Long], region: Code[Region], srcPType: PType, srcAddress: Code[Long], forceDeep: Boolean): Code[Unit]; def constructAtAddress(addr: Long, region: Region, srcPType: PType, srcAddress: Long, forceDeep: Boolean): Unit; ```. - Constructs a new value at `addr`, from `srcAddrss`; - Performs a deep copy when `srcPType != this`, or when `forceDeep == true`. ```scala; def copyFromType(mb: MethodBuilder, region: Code[Region], srcPType: PType, srcAddress: Code[Long], forceDeep: Boolean): Code[Long] = ...; def copyFromType(region: Region, srcPType: PType, srcAddress: Long, forceDeep: Boolean): Long = ...; ```. - Allocates a new address and calls constructAtAddress; - For operations that can be shallow, returns srcAddress, skipping construction. # <a name=""parray""></a> PArray. An abstract class for immutable ordered collections where all elements are of a single type. Does not contain the value constructor (e.g allocate). ## Core Methods. ```scala; def allocate(region: Region, length: Int): Long = ...; def allocate(region: Code[Region], length: Code[Int]): Code[Long] = ...; ```. - Allocate the memory needed for an array of `length` length. Cannot exceed 2^31 entries. ```scala; def initialize(aoff: Long, length: Int, setMissing: Boolean = false) = ...; def stagedInitialize(aoff: Code[Long], length: Code[Int], setMissing: Boolean = false): Code[Unit] = ...; ```. - Initialize an allocated array by setting its elements to present or missing. ```scala; def isElementMissing(arrayAddress: Long, elementIndex: Int): Boolean= ...; def isElementMissing(arrayAddress: Long, elementIndex: Code[Int]): Code[Boolean] = ...; ```. - Does the element at the given index exist. ``",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7988:3727,Allocate,Allocates,3727,https://hail.is,https://github.com/hail-is/hail/issues/7988,1,['Allocate'],['Allocates']
Energy Efficiency,"ts, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.3M allocated (192.0K blocks / 2.1M chunks), regions.size = 3, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.3M allocated (256.0K blocks / 2.1M chunks), regions.size = 4, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:10.794 : INFO: RegionPool: REPORT_THRESHOLD: 2.4M allocated (320.0K blocks / 2.1M chunks), regions.size = 5, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.286 : INFO: RegionPool: REPORT_THRESHOLD: 28.8M allocated (576.0K blocks / 28.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.657 : INFO: RegionPool: REPORT_THRESHOLD: 30.8M allocated (576.0K blocks / 30.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.683 : INFO: RegionPool: REPORT_THRESHOLD: 32.8M allocated (576.0K blocks / 32.2M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:43:11.709 : INFO: RegionPool: REPORT_THRESHOLD: 32.8M allocated (576.0K blocks / 32.3M chunks), regions.size = 9, 0 current java objects, thread 10: pool-2-thread-2; 2023-09-27 16:44:22.426 GoogleStorageFS$: INFO: createNoCompression: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2-fbd8-4f1b-bcde-fbf29180c347; 2023-09-27 16:44:22.495 GoogleStorageFS$: INFO: close: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2-fbd8-4f1b-bcde-fbf29180c347; 2023-09-27 16:44:22.620 GoogleStorageFS$: INFO: closed: gs://1-day/tmp/hail/TSOfOrgZUmbVixnRiKWQFB/aggregate_intermediates/-Pt3gNtQW5WoBdCTDPQiwHda9c265f2-fbd8-4f1b-bcde-fbf29180c347; 2023-09-27 16:44:22.621 : INFO: TaskReport: stage=0, partition=7028, attempt=0, peakBytes=62266032, peakBytesReadable=59.38 MiB, chunks requested=7212",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:4694,allocate,allocated,4694,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943,1,['allocate'],['allocated']
Energy Efficiency,"turn_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /share/pkg/hail/2018-06-18/install/build/distributions/hail-python.zip/hail/utils/java.py in deco(*args, **kwargs); 194 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 195 'Hail version: %s\n'; --> 196 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; 197 except pyspark.sql.utils.CapturedException as e:; 198 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: SparkException: Job 2 cancelled because SparkContext was shut down. Java stack trace:; org.apache.spark.SparkException: Job 2 cancelled because SparkContext was shut down; at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:820); at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:818); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:818); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:1732); at org.apache.spark.util.EventLoop.stop(EventLoop.scala:83); at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:1651); at org.apache.spark.SparkContext$$anonfun$stop$8.apply$mcV$sp(SparkContext.scala:1921); at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317); at org.apache.spark.SparkContext.stop(SparkContext.scala:1920); at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581); at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216); at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188); at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188); at org.apache.spark.util.SparkShutdownHookManager$$an",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4755:3571,schedul,scheduler,3571,https://hail.is,https://github.com/hail-is/hail/issues/4755,1,['schedul'],['scheduler']
Energy Efficiency,"uctAtAddress(addr: Long, region: Region, srcPType: PType, srcAddress: Long, forceDeep: Boolean): Unit; ```. - Constructs a new value at `addr`, from `srcAddrss`; - Performs a deep copy when `srcPType != this`, or when `forceDeep == true`. ```scala; def copyFromType(mb: MethodBuilder, region: Code[Region], srcPType: PType, srcAddress: Code[Long], forceDeep: Boolean): Code[Long] = ...; def copyFromType(region: Region, srcPType: PType, srcAddress: Long, forceDeep: Boolean): Long = ...; ```. - Allocates a new address and calls constructAtAddress; - For operations that can be shallow, returns srcAddress, skipping construction. # <a name=""parray""></a> PArray. An abstract class for immutable ordered collections where all elements are of a single type. Does not contain the value constructor (e.g allocate). ## Core Methods. ```scala; def allocate(region: Region, length: Int): Long = ...; def allocate(region: Code[Region], length: Code[Int]): Code[Long] = ...; ```. - Allocate the memory needed for an array of `length` length. Cannot exceed 2^31 entries. ```scala; def initialize(aoff: Long, length: Int, setMissing: Boolean = false) = ...; def stagedInitialize(aoff: Code[Long], length: Code[Int], setMissing: Boolean = false): Code[Unit] = ...; ```. - Initialize an allocated array by setting its elements to present or missing. ```scala; def isElementMissing(arrayAddress: Long, elementIndex: Int): Boolean= ...; def isElementMissing(arrayAddress: Long, elementIndex: Code[Int]): Code[Boolean] = ...; ```. - Does the element at the given index exist. ```scala; def loadLength(arrayAddress: Long): Int = ...; def loadLength(arrayAddress: Code[Long]): Code[Int] = ...; ```. - Gets the array length, will not exceed 2^31. ```scala; def loadElement(arrayAddress: Long, elementIndex: Int): Long = ...; def loadElement(arrayAddress: Code[Long], elementIndex: Code[Int]): Code[Long] = ...; ```. - Gets the address of the element at the given index.; - For pointer types loads the address at the offs",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7988:4204,Allocate,Allocate,4204,https://hail.is,https://github.com/hail-is/hail/issues/7988,1,['Allocate'],['Allocate']
Energy Efficiency,"uilder.</li>; <li>Move proto wireformat parsing functionality from the private &quot;parsing; constructor&quot; to the Builder class.</li>; <li>Change the Lite runtime to prefer merging from the wireformat into mutable; messages rather than building up a new immutable object before merging. This; way results in fewer allocations and copy operations.</li>; <li>Make message-type extensions merge from wire-format instead of building up; instances and merging afterwards. This has much better performance.</li>; <li>Fix TextFormat parser to build up recurring (but supposedly not repeated); sub-messages directly from text rather than building a new sub-message and; merging the fully formed message into the existing field.</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-h4h5-3hr4-j3g2"">Security Advisory for Java users</a></li>; </ul>; <h2>Protocol Buffers v3.20.2</h2>; <h1>C++</h1>; <ul>; <li>Reduce memory consumption of MessageSet parsing</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf"">Security Advisory for C++ and Python users</a></li>; </ul>; <h2>Protocol Buffers v3.20.1</h2>; <h1>PHP</h1>; <ul>; <li>Fix building packaged PHP extension (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9727"">#9727</a>)</li>; <li>Fixed composer.json to only advertise compatibility with PHP 7.0+. (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9819"">#9819</a>)</li>; </ul>; <h1>Ruby</h1>; <ul>; <li>Disable the aarch64 build on macOS until it can be fixed. (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9816"">#9816</a>)</li>; </ul>; <h1>Other</h1>; <ul>; <li>Fix versioning issues in 3.20.0</li>; </ul>; <h2>Protocol Buffers v3.20.1-rc1</h2>; <p>#PHP</p>; <ul>; <li>Fix building packaged PHP extension (<a href=""https://github-redirect.dependabot.com/protocol",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12563:1412,Reduce,Reduce,1412,https://hail.is,https://github.com/hail-is/hail/pull/12563,2,"['Reduce', 'consumption']","['Reduce', 'consumption']"
Energy Efficiency,uleBuilder.classesBytes(ClassBuilder.scala:152); 	at is.hail.expr.ir.EmitClassBuilder.resultWithIndex(EmitClassBuilder.scala:660); 	at is.hail.expr.ir.WrappedEmitClassBuilder.resultWithIndex(EmitClassBuilder.scala:155); 	at is.hail.expr.ir.WrappedEmitClassBuilder.resultWithIndex$(EmitClassBuilder.scala:155); 	at is.hail.expr.ir.EmitFunctionBuilder.resultWithIndex(EmitClassBuilder.scala:1052); 	at is.hail.expr.ir.Emit.$anonfun$emitI$225(Emit.scala:2315); 	at is.hail.expr.ir.IEmitCodeGen.map(Emit.scala:320); 	at is.hail.expr.ir.Emit.emitI(Emit.scala:2256); 	at is.hail.expr.ir.Emit.emitI$3(Emit.scala:2458); 	at is.hail.expr.ir.Emit.$anonfun$emit$22(Emit.scala:2546); 	at is.hail.expr.ir.EmitCode$.fromI(Emit.scala:415); 	at is.hail.expr.ir.Emit.emit(Emit.scala:2545); 	at is.hail.expr.ir.Emit.emit$1(Emit.scala:591); 	at is.hail.expr.ir.Emit.emitVoid(Emit.scala:624); 	at is.hail.expr.ir.Emit.$anonfun$emitVoidInSeparateMethod$1(Emit.scala:549); 	at is.hail.expr.ir.Emit.$anonfun$emitVoidInSeparateMethod$1$adapted(Emit.scala:547); 	at is.hail.expr.ir.EmitCodeBuilder$.scoped(EmitCodeBuilder.scala:18); 	at is.hail.expr.ir.EmitCodeBuilder$.scopedVoid(EmitCodeBuilder.scala:28); 	at is.hail.expr.ir.EmitMethodBuilder.voidWithBuilder(EmitClassBuilder.scala:985); 	at is.hail.expr.ir.Emit.emitVoidInSeparateMethod(Emit.scala:547); 	at is.hail.expr.ir.Emit.emitInSeparateMethod(Emit.scala:571); 	at is.hail.expr.ir.Emit.emitI(Emit.scala:760); 	at is.hail.expr.ir.Emit.emitI$1(Emit.scala:600); 	at is.hail.expr.ir.Emit.$anonfun$emitVoid$26(Emit.scala:715); 	at is.hail.expr.ir.RelationalWriter.writeMetadata(TableWriter.scala:341); 	at is.hail.expr.ir.Emit.emitVoid(Emit.scala:715); 	at is.hail.expr.ir.Emit$.$anonfun$apply$3(Emit.scala:70); 	at is.hail.expr.ir.Emit$.$anonfun$apply$3$adapted(Emit.scala:68); 	at is.hail.expr.ir.EmitCodeBuilder$.scoped(EmitCodeBuilder.scala:18); 	at is.hail.expr.ir.EmitCodeBuilder$.scopedVoid(EmitCodeBuilder.scala:28); 	at is.hail.expr.ir.EmitMethodBuilder.voidWith,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12533:19744,adapt,adapted,19744,https://hail.is,https://github.com/hail-is/hail/issues/12533,1,['adapt'],['adapted']
Energy Efficiency,uler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.elasticsearch.hadoop.EsHadoopIllegalArgumentException: Unsupported/Unknown Elasticsearch version 6.0.0; 	at org.elasticsearch.hadoop.util.EsMajorVersion.parse(EsMajorVersion.java:79); 	at org.elasticsearch.hadoop.rest.RestClient.remoteEsVersion(RestClient.java:613); 	at org.elasticsearch.hadoop.rest.InitializationUtils.discoverEsVersion(InitializationUtils.java:240); 	... 10 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoo,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4138:3370,schedul,scheduler,3370,https://hail.is,https://github.com/hail-is/hail/issues/4138,1,['schedul'],['scheduler']
Energy Efficiency,"ull/93264"">kubernetes/kubernetes#93264</a>, <a href=""https://github.com/justaugustus""><code>@​justaugustus</code></a>) [SIG API Machinery, Auth, CLI, Cloud Provider, Cluster Lifecycle, Instrumentation, Network, Node, Release, Scalability, Storage and Testing]</li>; </ul>; </li>; <li>Promote Immutable Secrets/ConfigMaps feature to Beta and enable the feature by default.; This allows to set <code>Immutable</code> field in Secrets or ConfigMap object to mark their contents as immutable. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89594"">kubernetes/kubernetes#89594</a>, <a href=""https://github.com/wojtek-t""><code>@​wojtek-t</code></a>) [SIG Apps and Testing]</li>; <li>Remove <code>BindTimeoutSeconds</code> from schedule configuration <code>KubeSchedulerConfiguration</code> (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91580"">kubernetes/kubernetes#91580</a>, <a href=""https://github.com/cofyc""><code>@​cofyc</code></a>) [SIG Scheduling and Testing]</li>; <li>Remove kubescheduler.config.k8s.io/v1alpha1 (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89298"">kubernetes/kubernetes#89298</a>, <a href=""https://github.com/gavinfish""><code>@​gavinfish</code></a>) [SIG Scheduling]</li>; <li>Reserve plugins that fail to reserve will trigger the unreserve extension point (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92391"">kubernetes/kubernetes#92391</a>, <a href=""https://github.com/adtac""><code>@​adtac</code></a>) [SIG Scheduling and Testing]</li>; <li>Resolve regression in <code>metadata.managedFields</code> handling in update/patch requests submitted by older API clients (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91748"">kubernetes/kubernetes#91748</a>, <a href=""https://github.com/apelisse""><code>@​apelisse</code></a>)</li>; <li>Scheduler: optionally check for available storage capacity before scheduling pods which have unbound volu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:11842,Schedul,Scheduling,11842,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['Schedul'],['Scheduling']
Energy Efficiency,"ult: is.hail.io.bgen.BgenRecordV11$$anon$1; ```; ```; Serialization stack:; 	- object not serializable (class: is.hail.io.bgen.BgenRecordV11$$anon$1, value: BgenRecordV11(0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=0.99798583984375,0.00201416015625,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0,. goes on for a while. field (class: scala.Tuple2, name: _2, type: class java.lang.Object); 	- object (class scala.Tuple2, ([rs149841286:10000179:AAAAAAAC:A,---],BgenRecordV11(0/0:.:.:.:GP=1.0,0.0,0.0, 0/0:.:.:.:GP=1.0,0.0,0.0,. keeps on going like above until remaining stack trace:. at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2527:1547,schedul,scheduler,1547,https://hail.is,https://github.com/hail-is/hail/issues/2527,1,['schedul'],['scheduler']
Energy Efficiency,ultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(Spar,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882:4371,schedul,scheduler,4371,https://hail.is,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882,1,['schedul'],['scheduler']
Energy Efficiency,ultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1936); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1065); 	at org.apache.spark.rdd.RDDOperationScope$.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1806:3225,schedul,scheduler,3225,https://hail.is,https://github.com/hail-is/hail/issues/1806,1,['schedul'],['scheduler']
Energy Efficiency,ultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(Spar,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:5186,schedul,scheduler,5186,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['schedul'],['scheduler']
Energy Efficiency,ultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(Spar,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:2814,schedul,scheduler,2814,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437,1,['schedul'],['scheduler']
Energy Efficiency,ultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1906); 	at org.elasticsearch.spark.rdd.EsSpark$.doSa,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:6141,schedul,scheduler,6141,https://hail.is,https://github.com/hail-is/hail/issues/4250,1,['schedul'],['scheduler']
Energy Efficiency,ultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1936); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1065); 	at org.apache.spark.rdd.RDDOperationScope$.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:9091,schedul,scheduler,9091,https://hail.is,https://github.com/hail-is/hail/issues/3760,1,['schedul'],['scheduler']
Energy Efficiency,"umberFormatException: For input string: ""-66.2667,0,-25.4754""; at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043); at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110); at java.lang.Double.parseDouble(Double.java:538); at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:284); at scala.collection.immutable.StringOps.toDouble(StringOps.scala:29); at is.hail.io.vcf.VCFLine.parseDoubleInFormatArray(LoadVCF.scala:371); at is.hail.io.vcf.VCFLine.parseAddFormatArrayDouble(LoadVCF.scala:431); at is.hail.io.vcf.FormatParser.parseAddField(LoadVCF.scala:483); at is.hail.io.vcf.FormatParser.parse(LoadVCF.scala:514); at is.hail.io.vcf.LoadVCF$$anonfun$13.apply(LoadVCF.scala:867); at is.hail.io.vcf.LoadVCF$$anonfun$13.apply(LoadVCF.scala:848); at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:717); ... 35 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3361:6384,schedul,scheduler,6384,https://hail.is,https://github.com/hail-is/hail/issues/3361,1,['schedul'],['scheduler']
Energy Efficiency,un$apply$8.apply(RVD.scala:218); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1795); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apa,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:2958,schedul,scheduler,2958,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627,1,['schedul'],['scheduler']
Energy Efficiency,un$run$1$$anonfun$apply$5.apply(ContextRDD.scala:135); at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5.apply(ContextRDD.scala:135); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4755#issuecomment-438447635:5258,schedul,scheduler,5258,https://hail.is,https://github.com/hail-is/hail/issues/4755#issuecomment-438447635,1,['schedul'],['scheduler']
Energy Efficiency,"unks), regions.size = 2, 0 current java objects, thread 8: pool-1-thread-1; 2023-05-04 01:04:37.603 : ERROR: SocketException: Connection reset; From javax.net.ssl.SSLException: Connection reset; 	at sun.security.ssl.Alert.createSSLException(Alert.java:127); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267); 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262); 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:138); 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1400); 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1368); 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73); 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:962); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.MeteredStream.read(MeteredStream.java:134); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:226); 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:104); 	at is.hail.relocated.com.google.cloud.storage.UnbufferedReadableByteChannelSession$UnbufferedReadableByteChannel.read(UnbufferedReadableByteChannelSession.java:36); 	at is.hail.relocated.com.google.cloud.storage.DefaultBufferedReadableByteChannel.read(DefaultBufferedReadableByteChannel.java:106); 	at is.hail.relocated.com.google.cloud.sto",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:24436,Meter,MeteredStream,24436,https://hail.is,https://github.com/hail-is/hail/issues/12983,1,['Meter'],['MeteredStream']
Energy Efficiency,"unts distinctlyKeyed firstKey; lastKey)]; }; !37 = ToArray(!s21); !38 = WriteMetadata(!37) [""{\""name\"":\""TableSpecWriter\"",\""path\"":\""/tmp/foo.ht\"",\""typ\"":{\""rowType\"":\""Struct{locus:Locus(GRCh38),alleles:Array[String],data:Array[Struct{}]}\"",\""key\"":[\""locus\"",\""alleles\""],\""globalType\"":\""Struct{new_globals:Array[Struct{}]}\""},\""rowRelPath\"":\""rows\"",\""globalRelPath\"":\""globals\"",\""refRelPath\"":\""references\"",\""log\"":true}""]; !39 = Begin(!34, !36, !38); WriteMetadata(!39) [""{\""name\"":\""RelationalWriter\"",\""path\"":\""/tmp/foo.ht\"",\""overwrite\"":true,\""maybeRefs\"":{\""references\"":[\""GRCh38\""]}}""]. 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:23); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:23); 	at is.hail.utils.package$.fatal(package.scala:89); 	at is.hail.expr.ir.TypeCheck$.apply(TypeCheck.scala:17); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:29); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:19); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:19); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:205); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$sco",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14245:15954,adapt,adapted,15954,https://hail.is,https://github.com/hail-is/hail/issues/14245,1,['adapt'],['adapted']
Energy Efficiency,upload/storage/v1/b/hail-test-ezlis/o?name=fs-suite-tmp-6BO4gZ18Lheigp3ir9RSOh&uploadType=resumable&upload_id=ADPycduiXx2Jtiy_0Ll131_pPeEYKnnA23Hlk28_9TFESUMaubA9OqLK_n8Td5rPhTXnlpssGo796Q4bJxUeblhmSaYcCSWAMg2k; chunkOffset: 16777216; chunkLength: 0; localOffset: 1325400064; remoteOffset: 1342177280; lastChunk: false. 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:131); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:87); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.access$1000(BlobWriteChannel.java:35); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel$1.run(BlobWriteChannel.java:267); 		at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 		at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103); 		at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 		at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.flushBuffer(BlobWriteChannel.java:189); 		at is.hail.relocated.com.google.cloud.BaseWriteChannel.flush(BaseWriteChannel.java:112); 		at is.hail.relocated.com.google.cloud.BaseWriteChannel.write(BaseWriteChannel.java:139); 		at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$flush$1(GoogleStorageFS.scala:297); 		at is.hail.io.fs.GoogleStorageFS$$anon$2.doHandlingRequesterPays(GoogleStorageFS.scala:279); 		at is.hail.io.fs.GoogleStorageFS$$anon$2.flush(GoogleStorageFS.scala:297); 		at is.hail.io.fs.FSPositionedOutputStream.write(FS.scala:219); 		at java.io.DataOutputStream.write(DataOutputStream.java:107); 		at is.hail.fs.FSSuite.$anonfun$testSeekMoreThanMaxInt$1(FSSuite.scala:329); 		at is.hail.fs.FSSuite.$anonfun$testSeekMoreThanMaxInt$1$adapted(FSSuite.scala:323); 		at is.hail.utils.package$.using(package.scala:635); 		... 26 more; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1544209756:9019,adapt,adapted,9019,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1544209756,2,['adapt'],['adapted']
Energy Efficiency,"ured out the ""right"" way to do cancellation. I introduce the following notions:; - a job is cancellable if it is ready or running, it hasn't been cancelled, but if the batch is cancelled, it will be cancelled (not always_run),; - a job is runnable if it is ready but has not been cancelled. Now we aim to incremental maintain the following information:. Globally:; - runnable jobs and cores. Per user:; - runnable and running jobs and cores,; - running cancelled jobs, and; - ready cancelled jobs. The global runnable cores are needed by the instance pool controller. The per-user stats are needed by the three threads of the scheduler:; - for the fair share allocator and the scheduler,; - to cancel running jobs on workers that have been cancelled (because the batch was cancelled),; - to cancel ready jobs that have been cancelled (either because the batch was cancelled or a parent failed). In order to update these values efficiently when a batch is cancelled, we also track in `batch_cancellable_resources` table, per batch:; - cancellable ready jobs and cores,; - cancellable running jobs and cores.; I added a `cancel_batch` procedure that uses these values to update ready_cores and user_resources when a batch is cancelled. I also reorganized the threads of the scheduler. Each one uses the above structures to compute a fair share for each user of work to do in a give iteration (dividing up 1000 tasks, with a per-user min of 20). Those tasks are then executed with 100-way parallelism. Other changes:; - I added a recompute_incremental procedure for recomputing all the incremental structures,; - I added a batches.state field (open, running or complete) and removed the closed column,; - I updated the batch and jobs indexes to make sure all scheduler queries are probably indexed. This isn't the case right now and we're seeing a lot of load on the database because of it. I'm going to do some more testing and possibly rename some stuff, but it is passing and the incremental structur",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7933:940,efficient,efficiently,940,https://hail.is,https://github.com/hail-is/hail/pull/7933,1,['efficient'],['efficiently']
Energy Efficiency,"ut. ```shell; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.128-17247d8990c6; LOGGING: writing to /home/edmund/.local/src/hail/hail-20240508-1553-0.2.128-17247d8990c6.log; Traceback (most recent call last):; File ""/home/edmund/.local/share/pyenv/versions/3.9.18/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.local/share/pyenv/versions/3.9.18/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/__main__.py"", line 39, in <module>; cli.main(); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py"", line 430, in main; run(); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py"", line 284, in run_file; runpy.run_path(target, run_name=""__main__""); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 321, in run_path; return _run_module_code(code, init_globals, run_name,; File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 135, in _run_module_code; _run_code(code, mod_globals, init_globals,; File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 124, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/test.py"", line 34, in <module>; main(); File ""/home/edmund/.local/src/hail/test.py"", line 28, in main; r2_adj = r2_adj.checkpoint(f'{tmp}/adj', overwrite=args.overwrite); Fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14537:2317,adapt,adapter,2317,https://hail.is,https://github.com/hail-is/hail/issues/14537,1,['adapt'],['adapter']
Energy Efficiency,"uteOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55); 	at org.apache.spark.scheduler.Task.run(Task.scala:121); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.21-1d317a44e5fd; Error summary: NoSuchElementException: key not found: GRCh37; ```. ### Error No. 2; ```python; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); /usr/local/lib/python3.6/site-packages/IPython/core/formatters.py in __call__(self, obj); 343 method = get_real_method(obj, self.print_method); 344 if method is not None:; --> 345 return m",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:25580,schedul,scheduler,25580,https://hail.is,https://github.com/hail-is/hail/issues/7044,1,['schedul'],['scheduler']
Energy Efficiency,uteOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55); 	at org.apache.spark.scheduler.Task.run(Task.scala:121); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). java.util.NoSuchElementException: key not found: GRCh37; 	at scala.collection.MapLike$class.default(MapLike.scala:228); 	at scala.collection.AbstractMap.default(Map.scala:59); 	at scala.collection.MapLike$class.apply(MapLike.scala:141); 	at scala.collection.AbstractMap.apply(Map.scala:59); 	at is.hail.expr.ir.TypeParserEnvironment.getReferenceGenome(Parser.scala:136); 	at is.hail.expr.ir.IRParser$.type_expr(Parser.scala:363); 	at is.hail,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:19239,schedul,scheduler,19239,https://hail.is,https://github.com/hail-is/hail/issues/7044,2,['schedul'],['scheduler']
Energy Efficiency,uteOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:324); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:288); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99); 	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55); 	at org.apache.spark.scheduler.Task.run(Task.scala:121); 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:402); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:408); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.util.NoSuchElementException: key not found: GRCh37; 	at scala.collection.MapLike$class.default(MapLike.scala:228); 	at scala.collection.AbstractMap.default(Map.scala:59); 	at scala.collection.MapLike$class.apply(MapLike.scala:141); 	at scala.collection.AbstractMap.apply(Map.scala:59); 	at is.hail.expr.ir.TypeParserEnvironment.getReferenceGenome(Parser.scala:136); 	at is.hail.expr.ir.IRParser$.type_expr(Parser.scala:363); ,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:7516,schedul,scheduler,7516,https://hail.is,https://github.com/hail-is/hail/issues/7044,2,['schedul'],['scheduler']
Energy Efficiency,util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); E 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); E 	at java.lang.Thread.run(Thread.java:750); E ; E java.lang.RuntimeException: Stream is already closed.; E 	at com.azure.storage.common.StorageOutputStream.checkStreamState(StorageOutputStream.java:79); E 	at com.azure.storage.common.StorageOutputStream.flush(StorageOutputStream.java:89); E 	at is.hail.io.fs.AzureStorageFS$$anon$3.close(AzureStorageFS.scala:291); E 	at java.io.FilterOutputStream.close(FilterOutputStream.java:159); E 	at is.hail.utils.package$.using(package.scala:640); E 	at is.hail.io.fs.FS.writePDOS(FS.scala:428); E 	at is.hail.io.fs.FS.writePDOS$(FS.scala:427); E 	at is.hail.io.fs.RouterFS.writePDOS(RouterFS.scala:3); E 	at is.hail.backend.service.ServiceBackend.$anonfun$parallelizeAndComputeWithIndex$3(ServiceBackend.scala:114); E 	at is.hail.backend.service.ServiceBackend.$anonfun$parallelizeAndComputeWithIndex$3$adapted(ServiceBackend.scala:114); E 	at is.hail.backend.service.ServiceBackend$$anon$2.$anonfun$call$1(ServiceBackend.scala:122); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.services.package$.retryTransientErrors(package.scala:124); E 	at is.hail.backend.service.ServiceBackend$$anon$2.call(ServiceBackend.scala:122); E 	at is.hail.backend.service.ServiceBackend$$anon$2.call(ServiceBackend.scala:119); E 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); E 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); E 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); E 	at java.lang.Thread.run(Thread.java:750); E ; E ; E ; E ; E Hail version: 0.2.115-f6017673dbb6; E Error summary: RuntimeException: Stream is already closed. /usr/local/lib/python3.8/dist-packages/hail/backend/service_backend.py:477: FatalError; ------------------------------ Captured log call ----,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12976:22448,adapt,adapted,22448,https://hail.is,https://github.com/hail-is/hail/issues/12976,1,['adapt'],['adapted']
Energy Efficiency,util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); E 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); E 	at java.lang.Thread.run(Thread.java:750); E ; E java.lang.RuntimeException: Stream is already closed.; E 	at com.azure.storage.common.StorageOutputStream.checkStreamState(StorageOutputStream.java:79); E 	at com.azure.storage.common.StorageOutputStream.flush(StorageOutputStream.java:89); E 	at is.hail.io.fs.AzureStorageFS$$anon$3.close(AzureStorageFS.scala:291); E 	at java.io.FilterOutputStream.close(FilterOutputStream.java:159); E 	at is.hail.utils.package$.using(package.scala:640); E 	at is.hail.io.fs.FS.writePDOS(FS.scala:428); E 	at is.hail.io.fs.FS.writePDOS$(FS.scala:427); E 	at is.hail.io.fs.RouterFS.writePDOS(RouterFS.scala:3); E 	at is.hail.backend.service.ServiceBackend.$anonfun$parallelizeAndComputeWithIndex$3(ServiceBackend.scala:114); E 	at is.hail.backend.service.ServiceBackend.$anonfun$parallelizeAndComputeWithIndex$3$adapted(ServiceBackend.scala:114); E 	at is.hail.backend.service.ServiceBackend$$anon$2.$anonfun$call$1(ServiceBackend.scala:122); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.services.package$.retryTransientErrors(package.scala:124); E 	at is.hail.backend.service.ServiceBackend$$anon$2.call(ServiceBackend.scala:122); E 	at is.hail.backend.service.ServiceBackend$$anon$2.call(ServiceBackend.scala:119); E 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); E 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); E 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); E 	at java.lang.Thread.run(Thread.java:750); E ; E ; E ; E ; E Hail version: 0.2.115-f6017673dbb6; E Error summary: RuntimeException: Stream is already closed.; ```. ### Version. 0.2.115-f6017673dbb6. ### Relevant log output. ```shell; ________________________________ test_spectra_4 _________________,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12976:8830,adapt,adapted,8830,https://hail.is,https://github.com/hail-is/hail/issues/12976,1,['adapt'],['adapted']
Energy Efficiency,utionTimer$.time(ExecutionTimer.scala:52); E 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59); E 	at is.hail.backend.service.ServiceBackendSocketAPI2.withExecuteContext$1(ServiceBackend.scala:535); E 	at is.hail.backend.service.ServiceBackendSocketAPI2.executeOneCommand(ServiceBackend.scala:602); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$7(ServiceBackend.scala:433); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$7$adapted(ServiceBackend.scala:432); E 	at is.hail.utils.package$.using(package.scala:640); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$6(ServiceBackend.scala:432); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.services.package$.retryTransientErrors(package.scala:77); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$5(ServiceBackend.scala:432); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$5$adapted(ServiceBackend.scala:430); E 	at is.hail.utils.package$.using(package.scala:640); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$4(ServiceBackend.scala:430); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.services.package$.retryTransientErrors(package.scala:77); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.main(ServiceBackend.scala:430); E 	at is.hail.backend.service.Main$.main(Main.scala:33); E 	at is.hail.backend.service.Main.main(Main.scala); E 	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source); E 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); E 	at java.lang.reflect.Method.invoke(Method.java:498); E 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:105); E 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); E 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); E 	at java.util.concurrent.Executors$RunnableAdapter,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11883#issuecomment-1144890222:3180,adapt,adapted,3180,https://hail.is,https://github.com/hail-is/hail/pull/11883#issuecomment-1144890222,1,['adapt'],['adapted']
Energy Efficiency,"utor driver, partition 0, PROCESS_LOCAL, 4777 bytes); 2018-10-09 14:46:43 Executor: INFO: Running task 0.0 in stage 5.0 (TID 5); 2018-10-09 14:46:43 BlockManager: INFO: Found block rdd_9_0 locally; 2018-10-09 14:46:43 CodeGenerator: INFO: Code generated in 19.341759 ms; 2018-10-09 14:46:43 CodeGenerator: INFO: Code generated in 10.738625 ms; 2018-10-09 14:46:43 SparkContext: INFO: Invoking stop() from shutdown hook; 2018-10-09 14:46:43 AbstractConnector: INFO: Stopped Spark@31b6843e{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}; 2018-10-09 14:46:43 SparkUI: INFO: Stopped Spark web UI at http://10.32.119.167:4040; 2018-10-09 14:46:43 DAGScheduler: INFO: Job 3 failed: fold at RVD.scala:361, took 0.107081 s; 2018-10-09 14:46:43 DAGScheduler: INFO: ResultStage 5 (fold at RVD.scala:361) failed in 0.097 s due to Stage cancelled because SparkContext was shut down; 2018-10-09 14:46:43 LiveListenerBus: ERROR: SparkListenerBus has already stopped! Dropping event SparkListenerStageCompleted(org.apache.spark.scheduler.StageInfo@58127452); 2018-10-09 14:46:43 LiveListenerBus: ERROR: SparkListenerBus has already stopped! Dropping event SparkListenerJobEnd(3,1539121603334,JobFailed(org.apache.spark.SparkException: Job 3 cancelled because SparkContext was shut down)); 2018-10-09 14:46:43 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!; 2018-10-09 14:46:43 MemoryStore: INFO: MemoryStore cleared; 2018-10-09 14:46:43 BlockManager: INFO: BlockManager stopped; 2018-10-09 14:46:43 BlockManagerMaster: INFO: BlockManagerMaster stopped; 2018-10-09 14:46:43 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!; 2018-10-09 14:46:43 SparkContext: INFO: Successfully stopped SparkContext; 2018-10-09 14:46:43 ShutdownHookManager: INFO: Shutdown hook called; 2018-10-09 14:46:43 ShutdownHookManager: INFO: Deleting directory /private/var/folders/w4/9k0my8pd6113d61pq05fvqlr0000gn/T/spark-02128b51-f37e-4798-84bb-d3e3819e51be; ```; </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:48938,schedul,scheduler,48938,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['schedul'],['scheduler']
Energy Efficiency,"v/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95""],""grace"":""48h"",""recursive"":true,""tag_filter_all"":""cache-pr-.*""}; ```. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/b",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:1349,monitor,monitoring,1349,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545,1,['monitor'],['monitoring']
Energy Efficiency,va.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD.count(RDD.scala:1134); 	at is.hail.variant.VariantSampleMatrix.countVariants(VariantSampleMatrix.scala:810); 	at is.hail.variant.VariantDatasetFunctions$.count$extension(VariantDataset.scala:504); 	at is.hail.variant.VariantDatasetFunctions.count(VariantDataset.scala:494); 	at sun.reflect.Nati,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882:4716,schedul,scheduler,4716,https://hail.is,https://github.com/hail-is/hail/pull/1552#issuecomment-287190882,1,['schedul'],['scheduler']
Energy Efficiency,va.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1936); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1065); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); 	at org.apache.spark.rdd.RDD.fold(RDD.scala:1059); 	at is.hail.utils.richUtils.RichRDD$.exists$extension(RichRDD.scala:21); 	at is.hail.utils.richUtils.RichRDD$.foral,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1806:3570,schedul,scheduler,3570,https://hail.is,https://github.com/hail-is/hail/issues/1806,1,['schedul'],['scheduler']
Energy Efficiency,va.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.c,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3901:7852,schedul,scheduler,7852,https://hail.is,https://github.com/hail-is/hail/issues/3901,2,['schedul'],['scheduler']
Energy Efficiency,va.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:363); 	at org.apache.spark.rdd.RDD.c,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8545:10211,schedul,scheduler,10211,https://hail.is,https://github.com/hail-is/hail/issues/8545,1,['schedul'],['scheduler']
Energy Efficiency,"va.lang.Thread.run(Thread.java:745); Caused by: java.lang.NumberFormatException: For input string: ""-66.2667,0,-25.4754""; at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043); at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110); at java.lang.Double.parseDouble(Double.java:538); at scala.collection.immutable.StringLike$class.toDouble(StringLike.scala:284); at scala.collection.immutable.StringOps.toDouble(StringOps.scala:29); at is.hail.io.vcf.VCFLine.parseDoubleInFormatArray(LoadVCF.scala:371); at is.hail.io.vcf.VCFLine.parseAddFormatArrayDouble(LoadVCF.scala:431); at is.hail.io.vcf.FormatParser.parseAddField(LoadVCF.scala:483); at is.hail.io.vcf.FormatParser.parse(LoadVCF.scala:514); at is.hail.io.vcf.LoadVCF$$anonfun$13.apply(LoadVCF.scala:867); at is.hail.io.vcf.LoadVCF$$anonfun$13.apply(LoadVCF.scala:848); at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:717); ... 35 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3361:6344,schedul,scheduler,6344,https://hail.is,https://github.com/hail-is/hail/issues/3361,1,['schedul'],['scheduler']
Energy Efficiency,va.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); 	at org.apache.spark.rdd.RDD.c,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:5531,schedul,scheduler,5531,https://hail.is,https://github.com/hail-is/hail/issues/2743,1,['schedul'],['scheduler']
Energy Efficiency,va.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1913); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:912); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); 	at org.apache.spark.rdd.RDD.c,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437:3159,schedul,scheduler,3159,https://hail.is,https://github.com/hail-is/hail/pull/2722#issuecomment-358198437,1,['schedul'],['scheduler']
Energy Efficiency,va.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1906); 	at org.elasticsearch.spark.rdd.EsSpark$.doSaveToEs(EsSpark.scala:107); 	at org.elasticsearch.spark.rdd.EsSpark$.saveToEs(EsSpark.scala:79); 	at org.elasticsearch.spark.rdd.EsSpark$.saveToEs(EsSpark.scala:76); 	at is.hail.io.ElasticsearchConnector$.export(ElasticsearchConnector.scala:33); 	at is.hail.keytable.KeyTable.exportElasticsearch(KeyTable.scala:751); 	at sun.reflect.NativeMethodA,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:6486,schedul,scheduler,6486,https://hail.is,https://github.com/hail-is/hail/issues/4250,1,['schedul'],['scheduler']
Energy Efficiency,va.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1936); 	at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1065); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358); 	at org.apache.spark.rdd.RDD.fold(RDD.scala:1059); 	at is.hail.utils.richUtils.RichRDD$.exists$extension(RichRDD.scala:29); 	at is.hail.utils.richUtils.RichRDD$.foral,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3760:9436,schedul,scheduler,9436,https://hail.is,https://github.com/hail-is/hail/issues/3760,1,['schedul'],['scheduler']
Energy Efficiency,va.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at is.hail.sparkextras.ContextRDD.runJob(ContextRDD.scala:467); 	at is.hail.sparkextras.ContextRDD.head(ContextRDD.scala:444); 	at is.hail.rvd.OrderedRVD.head(OrderedRVD.scala:346); 	at is.hail.rvd.OrderedRVD.head(OrderedRVD.scala:32); 	at is.hail.rvd.RVD$class.takeAsBytes(RVD.scala:247); 	at is.hail.rvd.OrderedRVD.takeAsBytes(OrderedRVD.scala:32); 	at is.hail.rvd.RVD$class.take(RVD.sca,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4055:6545,schedul,scheduler,6545,https://hail.is,https://github.com/hail-is/hail/issues/4055,1,['schedul'],['scheduler']
Energy Efficiency,va.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at is.hail.sparkextras.ContextRDD.runJob(ContextRDD.scala:467); 	at is.hail.sparkextras.ContextRDD.head(ContextRDD.scala:444); 	at is.hail.rvd.UnpartitionedRVD.head(UnpartitionedRVD.scala:23); 	at is.hail.rvd.UnpartitionedRVD.head(UnpartitionedRVD.scala:17); 	at is.hail.rvd.RVD$class.takeAsBytes(RVD.scala:247); 	at is.hail.rvd.UnpartitionedRVD.takeAsBytes(UnpartitionedRVD.scala:17); 	at,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4114:4409,schedul,scheduler,4409,https://hail.is,https://github.com/hail-is/hail/issues/4114,1,['schedul'],['scheduler']
Energy Efficiency,va.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.c,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3040:7694,schedul,scheduler,7694,https://hail.is,https://github.com/hail-is/hail/issues/3040,2,['schedul'],['scheduler']
Energy Efficiency,va.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at is.hail.sparkextras.ContextRDD.runJob(ContextRDD.scala:465); 	at is.hail.sparkextras.ContextRDD.head(ContextRDD.scala:442); 	at is.hail.rvd.OrderedRVD.head(OrderedRVD.scala:286); 	at is.hail.rvd.OrderedRVD.head(OrderedRVD.scala:22); 	at is.hail.rvd.RVD$class.takeAsBytes(RVD.scala:247); 	at is.hail.rvd.OrderedRVD.takeAsBytes(OrderedRVD.scala:22); 	at is.hail.rvd.RVD$class.take(RVD.sca,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3790:7287,schedul,scheduler,7287,https://hail.is,https://github.com/hail-is/hail/issues/3790,1,['schedul'],['scheduler']
Energy Efficiency,va.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.c,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3465:9478,schedul,scheduler,9478,https://hail.is,https://github.com/hail-is/hail/issues/3465,5,['schedul'],['scheduler']
Energy Efficiency,va.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.c,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410:4959,schedul,scheduler,4959,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-385847410,2,['schedul'],['scheduler']
Energy Efficiency,va.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094); 	at org.apache.spark.rdd.RDD.count(RDD.scala:1158); 	at is.hail.rvd.RVD$class.count(RVD.scala:183); 	at is.hail.rvd.OrderedRVD.count(OrderedRVD.scala:19); 	at is.hail.methods.LDPrune$$anonfun$9.apply(LDPrune.scala:471); 	at is.hail.methods.LDPrune$$anonfun$9.apply(LDPrune.scala:469); 	at is.hail.utils.package$.time(packag,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:3875,schedul,scheduler,3875,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627,1,['schedul'],['scheduler']
Energy Efficiency,va.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1575); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1563); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1562); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1562); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1790); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1745); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1734); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:619); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126); 	at is.hail.rvd.RVD.aggregateWithPartitionOp(RVD.scala:558); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:808); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:87); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:59); 	at is.hail.expr.ir.InterpretNonCompilable$$anonfun$5.apply(InterpretNonCompilable.scala:16); 	at is.hail.expr.ir.InterpretNonCompilable$$anonfun$5.apply(InterpretNonCompilable.scala:16); 	at scala.collection.TraversableL,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5846:7082,schedul,scheduler,7082,https://hail.is,https://github.com/hail-is/hail/issues/5846,1,['schedul'],['scheduler']
Energy Efficiency,va.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1892); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1880); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2113); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2062); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2051); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:385); 	at org.apache.spark.rdd.RDD.c,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:83038,schedul,scheduler,83038,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['schedul'],['scheduler']
Energy Efficiency,va.lang.Thread.run(Thread.java:748); Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at is.hail.sparkextras.ContextRDD.runJob(ContextRDD.scala:456); 	at is.hail.sparkextras.ContextRDD.head(ContextRDD.scala:433); 	at is.hail.rvd.OrderedRVD.head(OrderedRVD.scala:285); 	at is.hail.rvd.OrderedRVD.head(OrderedRVD.scala:21); 	at is.hail.rvd.RVD$class.takeAsBytes(RVD.scala:243); 	at is.hail.rvd.OrderedRVD.takeAsBytes(OrderedRVD.scala:21); 	at is.hail.rvd.RVD$class.take(RVD.sca,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3516:4390,schedul,scheduler,4390,https://hail.is,https://github.com/hail-is/hail/issues/3516,1,['schedul'],['scheduler']
Energy Efficiency,va.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). is.hail.utils.HailException: cannot set missing field for required type +PFloat64; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:18); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:18); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.annotations.RegionValueBuilder.setMissing(RegionValueBuilder.scala:207); 	at is.hail.io.vcf.VCFLine.parseAddInfoArrayDouble(LoadVCF.scala:1034); 	at is.hail.io.vcf.VCFLine.parseAddInfoField(LoadVCF.scala:1055); 	at is.hail.io.vcf.VCFLine.addInfoField(LoadVCF.scala:1075); 	at is.hail.io.vcf.VCFLine.parseAddInfo(LoadVCF.scala:1112); 	at is.hail.io.vcf.LoadVCF$.parseLineInner(LoadVCF.scala:1541); 	at is.hail.io.vcf.LoadVCF$.parseLine(LoadVCF.scala:1409); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1916); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7$adapted(LoadVCF.scala:1909); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:515); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at __C678stream_Let.apply(Emit.scala); 	at is.hail.expr.ir.CompileIterator$$anon$2.step(Compile.scala:302); 	at is.hail.expr.ir.CompileIterator$LongIteratorWrapper.hasNext(Compile.scala:155); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2(RVD.scala:1030); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1029); 	at is.hail.sparkextras.ContextRDD.$anonfun$crunJobWithIndex$1(ContextRDD.scala:242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.e,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:19443,adapt,adapted,19443,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['adapt'],['adapted']
Energy Efficiency,va:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1283); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1271); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1270); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1270); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:697); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:697); at scala.Option.foreach(Option.scala:236); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:697); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1496); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1458); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1447); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:567); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1824); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1837); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1850); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1921); at org.apache.spark.rdd.RDD.count(RDD.scala:1125); at org.broadinstitute.hail.driver.Count$.run(Count.scala:37); at org.broadinstitute.hail.driver.Count$.run(Count.scala:9); at org.broadinstitute.hail.driver.Command.runCommand(Command.scala:23,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/660#issuecomment-242218633:6736,schedul,scheduler,6736,https://hail.is,https://github.com/hail-is/hail/issues/660#issuecomment-242218633,1,['schedul'],['scheduler']
Energy Efficiency,va:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.a,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3379:8873,schedul,scheduler,8873,https://hail.is,https://github.com/hail-is/hail/issues/3379,1,['schedul'],['scheduler']
Energy Efficiency,va:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119); at org.apache.spark.rdd.RDD$$anonfun$reduce$1.apply(RDD.scala:1026); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); at org.apache.spark.rdd.RDD.reduce(RDD.scala:1008); at org.apache.spark.rdd.RDD$$anonf,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3413:4839,schedul,scheduler,4839,https://hail.is,https://github.com/hail-is/hail/issues/3413,1,['schedul'],['scheduler']
Energy Efficiency,va:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.a,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403:12974,schedul,scheduler,12974,https://hail.is,https://github.com/hail-is/hail/issues/9293#issuecomment-677718403,1,['schedul'],['scheduler']
Energy Efficiency,va:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); at org.apache.spark.SparkContext.runJob(SparkContext.scala:1899); at org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:347); at org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:39); at org.apache.spark.sql.Dataset$$anonfun$org$apache$spark$sql$Dataset$$execute$1$1.apply(Dataset.scala:2193); at org.apache.spark.sql.execution.SQLE,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1275:4495,schedul,scheduler,4495,https://hail.is,https://github.com/hail-is/hail/issues/1275,1,['schedul'],['scheduler']
Energy Efficiency,va:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2119); at org.apache.spark.rdd.RDD$$anonfun$aggregate$1.apply(RDD.scala:1115); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); at org.apache.spark.rdd.RDD.aggregate(RDD.scala:1108); at is.hail.table.Table.query,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3063:5940,schedul,scheduler,5940,https://hail.is,https://github.com/hail-is/hail/issues/3063,2,['schedul'],['scheduler']
Energy Efficiency,va:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2094); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.a,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3507:6320,schedul,scheduler,6320,https://hail.is,https://github.com/hail-is/hail/issues/3507,1,['schedul'],['scheduler']
Energy Efficiency,va:613); 	at org.elasticsearch.hadoop.rest.InitializationUtils.discoverEsVersion(InitializationUtils.java:240); 	... 10 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1906); 	at org.elasticsearch.spark.rdd.EsSpark$.doSaveToEs(EsSpark.scala:102); 	at org.elasticsearch.spark.rdd.EsSpark$.saveToEs(EsSpark.scala:76); 	at org.elasticsearch.spark.rdd.EsSpark$.saveToEs(EsSpark.scala:73); 	at is.hail.io.ElasticsearchConnector$.export(ElasticsearchConnector.scala:33); 	at is.hail,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4138:3961,schedul,scheduler,3961,https://hail.is,https://github.com/hail-is/hail/issues/4138,1,['schedul'],['scheduler']
Energy Efficiency,"vated yet; - The SQL user resources table and cancellable resources table needed to be changed to add the n_creating_jobs, n_cancellable_creating_jobs, and the n_cancelled_creating_jobs; - Added a new SQL function `mark_job_creating` that is only called by the job private instance creator.; - A lot of the existing SQL functions had to change to account for the fact that an instance in the pending state can have job-specific operations done such as mark_job_complete if the job is cancelled. In addition, the ""Creating"" state is like ""Running"" for some operations in that an attempt has been created and actions are happening on behalf of the user. **Driver Changes:**; - New cancel_creating_jobs event; - Two separate methods to get the pools or job private UI pages and two separate configuration methods. One each for pool and job-private. **JobPrivateInstanceCollection:**; - Has two new loops: an instance creation loop and a scheduling loop; - The instance creation loop does a fair share calculation that is almost identical to the pool one except the resource being allocated is n_ready_jobs compared to total_jobs rather than ready_cores_mcpu. ; - The instance creation loop needs to extract the machine_type, storage_gib, and preemptible from the spec without hitting GCS. Therefore, it is stored in the ""spec"" field in the database which required changing the batch format version a bit.; - We avoid double scheduling by requiring that there are no live instances assigned to attempts for that job before creating an instance.; - We mark a job as creating after creating the instance for the new attempt; - The number of instances that can be created is similar to the pool control loop. The total number of instances we can create is fed to the fair share allocator.; - I added an asyncio.wait(15) at the end of the instance creation loop body to make sure we didn't run past our GCE limits.; - The scheduling loop iterates over all attempts with active instances in order of time of a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9972:2326,schedul,scheduling,2326,https://hail.is,https://github.com/hail-is/hail/pull/9972,2,"['allocate', 'schedul']","['allocated', 'scheduling']"
Energy Efficiency,"version, deepest)); hail.java.FatalError: SparkException: Failed to get broadcast_4_piece0 of broadcast_4. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 0.0 failed 4 times, most recent failure: Lost task 0.3 in stage 0.0 (TID 6, com2, executor 1): java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1310); 	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); 	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); 	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); 	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:81); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.apache.spark.SparkException: Failed to get broadcast_4_piece0 of broadcast_4; 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:178); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:150); 	at scala.collection.immutable.List.foreach(List.scala:381); 	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broa",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807:1732,schedul,scheduler,1732,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-338418807,1,['schedul'],['scheduler']
Energy Efficiency,"version:; - ci/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Use of a Broken or Risky Cryptographic Algorithm <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6149518](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6149518) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Uncontrolled Resource Consumption (&#x27;Resource Exhaustion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6157248](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6157248) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **451/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.3 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6210214) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *Yo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14236:1290,Consumption,Consumption,1290,https://hail.is,https://github.com/hail-is/hail/pull/14236,1,['Consumption'],['Consumption']
Energy Efficiency,wable.$plus$plus$eq$(Growable.scala:53); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49); 	at scala.collection.TraversableOnce.to(TraversableOnce.scala:366); 	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:364); 	at scala.collection.AbstractIterator.to(Iterator.scala:1431); 	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358); 	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1431); 	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345); 	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1431); 	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1021); 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2276); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2673); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2609); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2608); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.Resiz,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12936:4407,schedul,scheduler,4407,https://hail.is,https://github.com/hail-is/hail/issues/12936,1,['schedul'],['scheduler']
Energy Efficiency,wait for 1h for resources to be scheduled; add timeouts for pods and services; set timeout to 2x average time from a dozen recent successful runs of the step,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6082:32,schedul,scheduled,32,https://hail.is,https://github.com/hail-is/hail/pull/6082,1,['schedul'],['scheduled']
Energy Efficiency,ware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:63); at com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:790); at org.apache.spark.serializer.KryoDeserializationStream.readObject(KryoSerializer.scala:246); at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$8.apply(TorrentBroadcast.scala:293); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1337); at org.apache.spark.broadcast.TorrentBroadcast$.unBlockifyObject(TorrentBroadcast.scala:294); at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:226); at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1303); at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:206); at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:66); at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:66); at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:96); at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70); at is.hail.io.RichRDDRegionValue$$anonfun$5.apply(RowStore.scala:757); at is.hail.io.RichRDDRegionValue$$anonfun$5.apply(RowStore.scala:756); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:108); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3342:14835,schedul,scheduler,14835,https://hail.is,https://github.com/hail-is/hail/issues/3342,2,['schedul'],['scheduler']
Energy Efficiency,we're going to focus on monitoring in the cluster; already removed the upload service,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6310:24,monitor,monitoring,24,https://hail.is,https://github.com/hail-is/hail/pull/6310,1,['monitor'],['monitoring']
Energy Efficiency,"which reduced the diff to 0, and GitHub automatically closed?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5004#issuecomment-448649659:6,reduce,reduced,6,https://hail.is,https://github.com/hail-is/hail/pull/5004#issuecomment-448649659,1,['reduce'],['reduced']
Energy Efficiency,"which simplifies the addition of new test files to `Makefile`). I'm not sure what testing means in this context because it is an approximate algorithm. We added a test that calculates the ranks for a bunch of elements and prints them. This at least verifies we do not segfault on a simple example. Some subset of the interested parties: @jbloom22 @cseed @catoverdrive @patrick-schultz. Next steps:; - translate to Scala and hook into an actual aggregator; - hook into some future C++ aggregator infrastructure. ---; # The Algorithm Idea. The idea is to keep a logarithmic amount of data but still be able to reproduce an approximation of the original rank (how many elements are less than the given element). We start with a buffer of size `2^N`. ```; +-------------+; | |; +-------------+; ```. We insert elements from the stream until the buffer is full:. ```; +-------------+; | 1 2 ... 2^N |; +-------------+; ```. Then we 1) sort the buffer, 2) allocate another buffer of equal size, and 3); copy half the elements, randomly choosing to start from the zeroth or oneth; element. In the figure below we started with the zeroth element. We now consider; the first buffer empty. Note that the second buffer is only half-full. ```; +-------------------------------+; 2 | 1 3 ... 2^N - 1 |; +-------------------------------+; 1 | |; +-------------------------------+; ```. We now fill the first buffer again and repeat the process, now filling the; second buffer entirely and emptying the first buffer again. Because the second; buffer is now full, we run this compaction process on it, producing a third; buffer which is one half full. The probability of any element making it to the; third buffer is 1/4 because it had to survive two coin flips. ```; +-------------------------------+; 3 | # # # # # # # |; +-------------------------------+; 2 | |; +-------------------------------+; 1 | |; +-------------------------------+; ```. When the stream is exhausted, we compact all the buffers (even if th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5332:1294,allocate,allocate,1294,https://hail.is,https://github.com/hail-is/hail/pull/5332,1,['allocate'],['allocate']
Energy Efficiency,"without the need for restarting the process or dropping traffic. This makes regularly updating the cluster configuration whenever new test namespaces are created relatively straightforward and non-disruptive to traffic in other namespaces. The high-level approach is as follows:. 1. Envoy-based gateways and internal-gateways will load their routing configuration from a Kubernetes ConfigMap, which they watch for changes and reconcile their configuration when the ConfigMap changes. The ConfigMap can be populated with a manual deploy and is populated from the beginning with production routes (i.e. batch.hail.is gets routed to batch.default); 2. When running CI, CI will regularly update the ConfigMap with additional routes based on which internal namespaces (dev and PR) are currently active. This requires relatively small changes to CI to track active namespaces but overall is a pretty small change. Note that this does not introduce a dependency on CI to support production traffic, only development traffic.; 3. Deployments that run more than 1 replica (but really can be all of them) are run behind Headless Services, which expose the underlying pod IPs so Envoy can handle load-balancing instead of kube-proxy. This allows Envoy to make smart load-balancing decisions and correctly enforce rate-limiting when using connection pools. The namespace tracking in CI in Point 2 is possible before we make any changes to our networking, so that comes first in #12093. Point 3 is taken care of in #12094, and the rest of Point 2 and Point 1, everything to do with Envoy, is in this PR. ### Additional QoL improvements; - Envoy by default exposes Prometheus metrics that we can use to easily monitor things like rate-limiting, request failures and durations; - Since all Envoy configuration is in the configmap, we don't need to build any images. I suppose we could have done this with NGINX, so this isn't something to fault NGINX for. Just another small win buried in these changes. cc @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12095:5579,monitor,monitor,5579,https://hail.is,https://github.com/hail-is/hail/pull/12095,1,['monitor'],['monitor']
Energy Efficiency,write(MapSerializer.java:106); 	at com.esotericsoftware.kryo.serializers.MapSerializer.write(MapSerializer.java:39); 	at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:552); 	at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); 	... 10 more; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126); 	at is.hail.sparkextras.ContextRDD.aggregate(ContextRDD.scala:193); 	at is.hail.sparkextras.ContextRDD.aggregate(ContextRDD.scala:177); 	at is.hail.sparkextras.ContextRDD.fold(ContextRDD.scala:170); 	at is.hail.rvd.RVD,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4215:3173,schedul,scheduler,3173,https://hail.is,https://github.com/hail-is/hail/issues/4215,1,['schedul'],['scheduler']
Energy Efficiency,writeRows$1.apply(WriterContainer.scala:252); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer$$anonfun$writeRows$1.apply(WriterContainer.scala:252); 	at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1348); 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer.writeRows(WriterContainer.scala:258); 	... 8 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1906); 	at org.apache.spark.sql.execution.datasource,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1822:6266,schedul,scheduler,6266,https://hail.is,https://github.com/hail-is/hail/issues/1822,1,['schedul'],['scheduler']
Energy Efficiency,"writing a simple command such as read and write produces different type of error, but all related to memory issues. ; The most explicit error is: . ```; error='Cannot allocate memory' (errno=12); # There is insufficient memory for the Java Runtime Environment to continue.; # Native memory allocation (mmap) failed to map 7376207872 bytes for committing reserved memory.; ```. But also get this issue in other occasions:. ```; ExecutorLostFailure (executor 2265 exited caused by one of the running tasks) Reason: Container marked as failed: container_1481808189977_0001_01_002296 on host: gnomadpsychk-sw-wpt8.c.wgspd-147615.internal. Exit status: 50. Diagnostics: Exception from container-launch.; Container id: container_1481808189977_0001_01_002296; Exit code: 50; Stack trace: ExitCodeException exitCode=50:; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:582); 	at org.apache.hadoop.util.Shell.run(Shell.java:479); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:773); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Container exited with a non-zero exit code 50. Driver stacktrace:; ```. Log for this last error is here: https://storage.googleapis.com/wgspd_urv/hailNEW.log. I tried different projects and get the same error, both with pyhail and native hail. I don't see the same error when running on cray.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1186:167,allocate,allocate,167,https://hail.is,https://github.com/hail-is/hail/issues/1186,1,['allocate'],['allocate']
Energy Efficiency,xecution.datasources.DefaultWriterContainer.writeRows(WriterContainer.scala:261); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.ArrayIndexOutOfBoundsException. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1202:5117,schedul,scheduler,5117,https://hail.is,https://github.com/hail-is/hail/issues/1202,1,['schedul'],['scheduler']
Energy Efficiency,xt(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-425cc84a9997; Error summary: HailException: array index out of bounds: 2 / 2; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3653:7618,schedul,scheduler,7618,https://hail.is,https://github.com/hail-is/hail/issues/3653,2,['schedul'],['scheduler']
Energy Efficiency,xt(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.hasNext(OrderedRVD.scala:911); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.hasNext(OrderedRVD.scala:911); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.hasNext(OrderedRVD.scala:911); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.utils.package$.getIteratorSizeWithMaxN(package.scala:347); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:433); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:433); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1$$anonfun$apply$34.apply(ContextRDD.scala:458); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1$$anonfun$apply$34.apply(ContextRDD.scala:458); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:458); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:458); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3508:10626,schedul,scheduler,10626,https://hail.is,https://github.com/hail-is/hail/issues/3508,2,['schedul'],['scheduler']
Energy Efficiency,xt(Iterator.scala:444); 	at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1795); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1158); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProces,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627:3097,schedul,scheduler,3097,https://hail.is,https://github.com/hail-is/hail/issues/3446#issuecomment-384671627,1,['schedul'],['scheduler']
Energy Efficiency,xt(LoadVCF.scala:718); 	... 17 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.c,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3015:3594,schedul,scheduler,3594,https://hail.is,https://github.com/hail-is/hail/issues/3015,1,['schedul'],['scheduler']
Energy Efficiency,xt(LoadVCF.scala:737); 	... 34 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2050); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); 	at org.apache.spark.rdd.RDD$$anonfun$take$1.apply(RDD.scala:1354); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); 	at org.apache.spark.rdd.RDD.take(RDD.scala:1327); 	at is.hail.table.Table.take(Table.scala:914); 	,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3467:5630,schedul,scheduler,5630,https://hail.is,https://github.com/hail-is/hail/issues/3467,1,['schedul'],['scheduler']
Energy Efficiency,"xt(OrderedRVD.scala:911); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.utils.package$.getIteratorSizeWithMaxN(package.scala:347); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:433); 	at is.hail.sparkextras.ContextRDD$$anonfun$12.apply(ContextRDD.scala:433); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1$$anonfun$apply$34.apply(ContextRDD.scala:458); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1$$anonfun$apply$34.apply(ContextRDD.scala:458); 	at is.hail.utils.package$.using(package.scala:577); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:458); 	at is.hail.sparkextras.ContextRDD$$anonfun$runJob$1.apply(ContextRDD.scala:458); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2069); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); ```. Under ""Failed Stages"", these were the details for what I was running:; ```; org.apache.spark.SparkContext.runJob(SparkContext.scala:2069); is.hail.sparkextras.ContextRDD.runJob(ContextRDD.scala:456); is.hail.sparkextras.ContextRDD.head(ContextRDD.scala:433); is.hail.rvd.OrderedRVD.head(OrderedRVD.scala:285); is.hail.rvd.OrderedRVD.head(OrderedRVD.scala:21); is.hail.rvd.RVD$class.takeAsBytes(RVD.scala:243); is.hail.rvd.OrderedRVD.takeAsBytes(OrderedRVD.scala:21); is.hail.rvd.RVD$class.take(RVD.scala:247); is.hail.rvd.OrderedRVD.take(OrderedRVD.scala:21); is.hail.table.Table.take(Table.scala:990); is.hail.table.Table.showString(Table.scala:1031); sun.reflect.NativeMetho",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3508:5918,schedul,scheduler,5918,https://hail.is,https://github.com/hail-is/hail/issues/3508,1,['schedul'],['scheduler']
Energy Efficiency,xt.jdler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102) at io.netty.channel.AbstractChannelHandlerContext.invokeChalerContext.java:348) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) at org.apacxt.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelt io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359) at io.netty.channel.AbstractChannelHandlerCtractChannelHandlerContext.java:348) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935) at io.nettyectedKey(NioEventLoop.java:645) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580) at io.netty at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) at io.netty.util.concurrent.Default; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1493); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2107); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); at org.apache.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8106:23907,schedul,scheduler,23907,https://hail.is,https://github.com/hail-is/hail/issues/8106,1,['schedul'],['scheduler']
Energy Efficiency,"xt: INFO: Successfully stopped SparkContext; 2019-01-22 13:12:06 NettyRpcEnv: WARN: Ignored failure: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@115b6ba4 rejected from java.util.concurrent.ScheduledThreadPoolExecutor@3f21bf73[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]; 2019-01-22 13:12:06 YarnSchedulerBackend$YarnSchedulerEndpoint: ERROR: Error requesting driver to remove executor 14 after disconnection.; org.apache.spark.rpc.RpcEnvStoppedException: RpcEnv already stopped.; at org.apache.spark.rpc.netty.Dispatcher.postMessage(Dispatcher.scala:155); at org.apache.spark.rpc.netty.Dispatcher.postLocalMessage(Dispatcher.scala:132); at org.apache.spark.rpc.netty.NettyRpcEnv.ask(NettyRpcEnv.scala:228); at org.apache.spark.rpc.netty.NettyRpcEndpointRef.ask(NettyRpcEnv.scala:515); at org.apache.spark.rpc.RpcEndpointRef.ask(RpcEndpointRef.scala:63); at org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint$$anonfun$org$apache$spark$scheduler$cluster$YarnSchedulerBackend$$handleExecutorDisconnectedFromDriver$2.apply(YarnSchedulerBackend.scala:253); at org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint$$anonfun$org$apache$spark$scheduler$cluster$YarnSchedulerBackend$$handleExecutorDisconnectedFromDriver$2.apply(YarnSchedulerBackend.scala:252); at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:253); at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at org.spark_project.guava.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293); at scala.concurrent.impl.ExecutionContextImpl$$anon$1.execute(ExecutionContextImpl.scala:136); at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:40); at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:248);",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:214785,schedul,scheduler,214785,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['schedul'],['scheduler']
Energy Efficiency,xtRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$32.apply(ContextRDD.scala:422); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$32.apply(ContextRDD.scala:422); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$8.apply(ContextRDD.scala:192); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$8.apply(ContextRDD.scala:192); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.utils.package$.singletonElement(package.scala:603); 	at is.hail.rvd.RVD$$anonfun$aggregateWithPartitionOp$1.apply(RVD.scala:558); 	at is.hail.rvd.RVD$$anonfun$aggregateWithPartitionOp$1.apply(RVD.scala:558); 	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2125); 	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2125); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:344); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1575); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1563); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1562); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1562); 	at org.apache.sp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5846:5728,schedul,scheduler,5728,https://hail.is,https://github.com/hail-is/hail/issues/5846,1,['schedul'],['scheduler']
Energy Efficiency,"xtRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$32.apply(ContextRDD.scala:422); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$32.apply(ContextRDD.scala:422); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$8.apply(ContextRDD.scala:192); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$8.apply(ContextRDD.scala:192); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.utils.package$.singletonElement(package.scala:603); 	at is.hail.rvd.RVD$$anonfun$aggregateWithPartitionOp$1.apply(RVD.scala:558); 	at is.hail.rvd.RVD$$anonfun$aggregateWithPartitionOp$1.apply(RVD.scala:558); 	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2125); 	at org.apache.spark.SparkContext$$anonfun$33.apply(SparkContext.scala:2125); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:344); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.12-13681278eb89; Error summary: HailException: found out of bounds index -1; Resulted from trying to merge -0.0; Indices are [0.0, 2.0, 4.0, 6.0, 8.0, 10.0, 12.0, 14.0, 16.0, 18.0, 20.0, 22.0, 24.0, 26.0, 28.0, 30.0, 32.0, 34.0, 36.0, 38.0, 40.0, 42.0, 44.0, 46.0, 48.0, 50.0, 52.0, 54.0, 56.0, 58.0, 60.0, 62.0, 64.0, 66.0, 68.0, 70.0, 72.0, 74.0, 76.0, 78.0, 80.0, 82.0, 84.0, 86.0, 88.0, 90.0, 92.0, 94.0, 96.0, 98.0, 100.0, 102.0, 104.0, 106.0, 108.0, 110.0, 112.0, 114.0, 116.0, 118.0, 120.0, 122.0, 124.0, 126.0, 128.0, 130.0, 132.0, 134.0, 136.0, 138.0, 140.0, 142.0, 144.0, 146.0, 14",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5846:12296,schedul,scheduler,12296,https://hail.is,https://github.com/hail-is/hail/issues/5846,1,['schedul'],['scheduler']
Energy Efficiency,xtras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$19.apply(ContextRDD.scala:280); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5$$anonfun$apply$6.apply(ContextRDD.scala:129); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5$$anonfun$apply$6.apply(ContextRDD.scala:129); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); 	at scala.collection.AbstractIterator.toArray(Iterator.scala:1336); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:936); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2062); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3901:14912,schedul,scheduler,14912,https://hail.is,https://github.com/hail-is/hail/issues/3901,2,['schedul'],['scheduler']
Energy Efficiency,y one of the running tasks) Reason: Slave lost; Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1517); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2029); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2126); at org.apache.spark.rdd.RDD$$anonfun$fold$1.apply(RDD.scala:1089); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); at org.apache.spark.rdd.RDD.fold(RDD.scala:1083); at is.hail.rvd.RVD.count(RVD.scala:603); at is.hail.expr.ir.Interpret$$anonfun$apply$1.apply$mcJ$sp(Interpret.scala:725); at i,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456417572:9185,schedul,scheduler,9185,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456417572,1,['schedul'],['scheduler']
Energy Efficiency,y$3.apply(RowStore.scala:808); 	at is.hail.io.RichRDDRegionValue$$anonfun$5$$anonfun$apply$1$$anonfun$apply$2$$anonfun$apply$3.apply(RowStore.scala:807); 	at is.hail.utils.package$.using(package.scala:570); 	at is.hail.utils.richUtils.RichHadoopConfiguration$.writeFile$extension(RichHadoopConfiguration.scala:265); 	at is.hail.io.RichRDDRegionValue$$anonfun$5$$anonfun$apply$1$$anonfun$apply$2.apply(RowStore.scala:807); 	at is.hail.io.RichRDDRegionValue$$anonfun$5$$anonfun$apply$1$$anonfun$apply$2.apply(RowStore.scala:804); 	at is.hail.utils.package$.using(package.scala:570); 	at is.hail.io.RichRDDRegionValue$$anonfun$5$$anonfun$apply$1.apply(RowStore.scala:804); 	at is.hail.io.RichRDDRegionValue$$anonfun$5$$anonfun$apply$1.apply(RowStore.scala:803); 	at is.hail.utils.package$.using(package.scala:570); 	at is.hail.utils.richUtils.RichHadoopConfiguration$.writeFile$extension(RichHadoopConfiguration.scala:265); 	at is.hail.io.RichRDDRegionValue$$anonfun$5.apply(RowStore.scala:803); 	at is.hail.io.RichRDDRegionValue$$anonfun$5.apply(RowStore.scala:797); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsWithIndex$1$$anonfun$apply$26.apply(RDD.scala:844); 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:108); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:748). Hail version: devel-df317f3; Error summary: HailException: found non-left aligned variant: 18:76051965:C:G; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3040:14383,schedul,scheduler,14383,https://hail.is,https://github.com/hail-is/hail/issues/3040,2,['schedul'],['scheduler']
Energy Efficiency,y$6(BackendUtils.scala:52) ~[gs:__hail-query-ger0g_jars_be9d88a80695b04a2a9eb5826361e0897d94c042.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.utils.package$.using(package.scala:635) ~[gs:__hail-query-ger0g_jars_be9d88a80695b04a2a9eb5826361e0897d94c042.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162) ~[gs:__hail-query-ger0g_jars_be9d88a80695b04a2a9eb5826361e0897d94c042.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$5(BackendUtils.scala:51) ~[gs:__hail-query-ger0g_jars_be9d88a80695b04a2a9eb5826361e0897d94c042.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$12(Worker.scala:167) ~[gs:__hail-query-ger0g_jars_be9d88a80695b04a2a9eb5826361e0897d94c042.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-query-ger0g_jars_be9d88a80695b04a2a9eb5826361e0897d94c042.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$11(Worker.scala:166) ~[gs:__hail-query-ger0g_jars_be9d88a80695b04a2a9eb5826361e0897d94c042.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$11$adapted(Worker.scala:164) ~[gs:__hail-query-ger0g_jars_be9d88a80695b04a2a9eb5826361e0897d94c042.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.utils.package$.using(package.scala:635) ~[gs:__hail-query-ger0g_jars_be9d88a80695b04a2a9eb5826361e0897d94c042.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.main(Worker.scala:164) ~[gs:__hail-query-ger0g_jars_be9d88a80695b04a2a9eb5826361e0897d94c042.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main$.main(Main.scala:14) ~[gs:__hail-query-ger0g_jars_be9d88a80695b04a2a9eb5826361e0897d94c042.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main.main(Main.scala) ~[gs:__hail-query-ger0g_jars_be9d88a80695b04a2a9eb5826361e0897d94c042.jar.jar:0.0.1-SNAPSHOT]; 	... 11 more; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13356#issuecomment-1719508553:6041,adapt,adapted,6041,https://hail.is,https://github.com/hail-is/hail/issues/13356#issuecomment-1719508553,2,['adapt'],['adapted']
Energy Efficiency,y$mcVI$sp(DAGScheduler.scala:1543); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages$1.apply(DAGScheduler.scala:1529); at scala.collection.mutable.HashSet.foreach(HashSet.scala:78); at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1529); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1505); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1504); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1504); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1732); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1687); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1676); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 2019-01-22 13:12:06 YarnScheduler: INFO: Cancelling stage 0; 2019-01-22 13:12:06 DAGSchedulerEventProcessLoop: ERROR: DAGScheduler failed to cancel all jobs.; java.util.NoSuchElementException: key not found: 70; at scala.collection.MapLike$class.default(MapLike.scala:228); at scala.collection.AbstractMap.default(Map.scala:59); ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:202043,schedul,scheduler,202043,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,2,['schedul'],['scheduler']
Energy Efficiency,y(Executor.scala:403); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:409); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1889); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1877); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1876); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1876); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:926); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:926); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2110); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2059); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2048); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:737); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101); 	at org.apache.spark.SparkContext.runJob(Spar,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8545:9866,schedul,scheduler,9866,https://hail.is,https://github.com/hail-is/hail/issues/8545,1,['schedul'],['scheduler']
Energy Efficiency,y(Executor.scala:408); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1892); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1880); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1879); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1879); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:927); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:927); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2113); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2062); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2051); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2082); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2101); 	at org.apache.spark.SparkContext.runJob(Spar,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:82693,schedul,scheduler,82693,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['schedul'],['scheduler']
Energy Efficiency,"y4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:745); Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 35 in stage 7.0 failed 20 times, most recent failure: Lost task 35.19 in stage 7.0 (TID 6963, gnomad-prod-sw-m8lk.c.broad-mpg-gnomad.internal): org.apache.spark.SparkException: Task failed while writing rows; 	at org.apache.spark.sql.execution.datasources.DefaultWriterContainer.writeRows(WriterContainer.scala:261); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); 	at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand$$anonfun$run$1$$anonfun$apply$mcV$sp$1.apply(InsertIntoHadoopFsRelationCommand.scala:143); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70); 	at org.apache.spark.scheduler.Task.run(Task.scala:86); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: java.lang.ArrayIndexOutOfBoundsException. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGSch",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1202:4660,schedul,scheduler,4660,https://hail.is,https://github.com/hail-is/hail/issues/1202,1,['schedul'],['scheduler']
Energy Efficiency,yWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2673); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2609); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2608); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2608); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2861); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2792); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2257); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2276); 	at org.apache.spark.SparkContext.runJob(Spark,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12936:5631,schedul,scheduler,5631,https://hail.is,https://github.com/hail-is/hail/issues/12936,1,['schedul'],['scheduler']
Energy Efficiency,yWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2717); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2653); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2652); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2652); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1189); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1189); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1189); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2913); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2855); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2844); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:959); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2282); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2301); 	at org.apache.spark.SparkContext.runJob(Spark,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:8807,schedul,scheduler,8807,https://hail.is,https://github.com/hail-is/hail/issues/14513,1,['schedul'],['scheduler']
Energy Efficiency,"ya I think I wanted something like that in concept but agree with your sentiments about the implementation being wasteful. Having `parent_ids` and `rel_parent_ids` that are both just arrays of numbers, where the latter gets transformed and concatenated to the former seems like an efficient and nicely backwards-compatible implementation.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12010#issuecomment-1218087772:281,efficient,efficient,281,https://hail.is,https://github.com/hail-is/hail/pull/12010#issuecomment-1218087772,1,['efficient'],['efficient']
Energy Efficiency,"yload); 216 path = action_routes[action]; 217 port = self._backend_server_port; → 218 resp = self._requests_session.post(f’http://localhost:{port}{path}', data=data); 219 if resp.status_code >= 400:; 220 error_json = orjson.loads(resp.content). File ~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:637, in Session.post(self, url, data, json, **kwargs); 626 def post(self, url, data=None, json=None, **kwargs):; 627 r""""“Sends a POST request. Returns :class:Response object.; 628; 629 :param url: URL for the new :class:Request object.; (…); 634 :rtype: requests.Response; 635 “””; → 637 return self.request(“POST”, url, data=data, json=json, **kwargs). File ~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:589, in Session.request(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json); 584 send_kwargs = {; 585 “timeout”: timeout,; 586 “allow_redirects”: allow_redirects,; 587 }; 588 send_kwargs.update(settings); → 589 resp = self.send(prep, **send_kwargs); 591 return resp. File ~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:703, in Session.send(self, request, **kwargs); 700 start = preferred_clock(); 702 # Send the request; → 703 r = adapter.send(request, **kwargs); 705 # Total elapsed time of the request (approximately); 706 elapsed = preferred_clock() - start. File ~/Library/Python/3.9/lib/python/site-packages/requests/adapters.py:501, in HTTPAdapter.send(self, request, stream, timeout, verify, cert, proxies); 486 resp = conn.urlopen(; 487 method=request.method,; 488 url=url,; (…); 497 chunked=chunked,; 498 ); 500 except (ProtocolError, OSError) as err:; → 501 raise ConnectionError(err, request=request); 503 except MaxRetryError as e:; 504 if isinstance(e.reason, ConnectTimeoutError):; 505 # TODO: Remove this in 3.0.0: see #2811. ConnectionError: (‘Connection aborted.’, RemoteDisconnected(‘Remote end closed connection without response’)); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14557:2579,adapt,adapter,2579,https://hail.is,https://github.com/hail-is/hail/issues/14557,2,['adapt'],"['adapter', 'adapters']"
Energy Efficiency,"ypes are the classes that manage in-memory representations of Hail Types (Virtual Types), for both staged and unstaged code. # Motivation:. - Improve performance by building specialized memory representations for data; - Make it easier for developers to work with in memory representations of Hail types. # Project technical goals:. - Remove requiredness from virtual types; - Implement at least one non-canonical physical type. # Relation to regions. The methods that take regions are those that construct a new in-memory representation (are either `def allocate` or convenience methods that wrap `allocate` and may perform some complex operations before calling `allocate`, e.g `copyFromType`). Allocated addresses may be read using static Region methods (e.g `Region.loadAddress`), because they are absolute memory addresses rather than relative to some region offset. Long-term, methods besides `allocate` and wrapping methods, which need to allocate (for instance lazy-loading BGEN data) will be given the ability to do so without taking region as an argument (values will be associated with the regions that allocated them). Namely, regions may be placed on the values that own them. # Physical Type organization. ## Constructible types. Every PType has a ""fundamentalType"", which is the is the constructible representation for that type. It is, by default equal to the PType itself, but this may not always be the case (e.g [ComplexPType](#complex-ptypes)). ## Collection PTypes. [PArray](#parray). - Concrete implementations (canonical/non). [PSet](#pset). - Concrete implementations (canonical/non). [PDict](#pdict). - Concrete implementations (canonical/non). [PNDArray](#pndict). - Concrete implementations (canonical/non). [PTuple](#ptuple). - Concrete implementations (canonical/non). PStruct. - Concrete implementations (canonical/non). PString. - Concrete implementations (canonical/non). PBinary. - Concrete implementations (canonical/non). ## <a name=""complex-ptypes""></a> Complex PTy",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7988:1106,allocate,allocate,1106,https://hail.is,https://github.com/hail-is/hail/issues/7988,3,['allocate'],"['allocate', 'allocated']"
Energy Efficiency,zableHadoopConfiguration; at java.net.URLClassLoader.findClass(URLClassLoader.java:381); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); at java.lang.Class.forName0(Native Method); at java.lang.Class.forName(Class.java:348); at java.io.ObjectInputStream.resolveClass(ObjectInputStream.java:677); at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1819); at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1713); at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1986); at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535); at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422); at com.esotericsoftware.kryo.serializers.JavaSerializer.read(JavaSerializer.java:63); ... 25 more. Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3342:5847,schedul,scheduler,5847,https://hail.is,https://github.com/hail-is/hail/issues/3342,1,['schedul'],['scheduler']
Energy Efficiency,zationUtils.java:240); 	... 10 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1454); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1442); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1441); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1441); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1667); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1622); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1611); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1873); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1886); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1906); 	at org.elasticsearch.spark.rdd.EsSpark$.doSaveToEs(EsSpark.scala:102); 	at org.elasticsearch.spark.rdd.EsSpark$.saveToEs(EsSpark.scala:76); 	at org.elasticsearch.spark.rdd.EsSpark$.saveToEs(EsSpark.scala:73); 	at is.hail.io.ElasticsearchConnector$.export(ElasticsearchConnector.scala:33); 	at is.hail.keytable.KeyTable.exportElasticsearch(KeyTable.scala:751); 	at sun.reflect.NativeMethodA,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4138:4050,schedul,scheduler,4050,https://hail.is,https://github.com/hail-is/hail/issues/4138,1,['schedul'],['scheduler']
Energy Efficiency,"~I verified this scales all the way to 50,000 partitions but the batch-driver can't schedule these fast enough to make the test fast. They take less than a second but more than 300ms. We'd need like 64 8-core (512 cores) nodes to bring test time down to a reasonable amount. We should strive to get there but batch would need to schedule at 512 jobs per second for that to make sense.~ Hmm, something went wrong. OK, we'll need to revisit 50k partition tables. But let's get this in, the current code is obviously wrong.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13065#issuecomment-1550142533:84,schedul,schedule,84,https://hail.is,https://github.com/hail-is/hail/pull/13065#issuecomment-1550142533,2,['schedul'],['schedule']
Energy Efficiency,"~~Stacked on #9106.~~. Adds an enumeration to control the allocation strategy in emitted code. There are currently three options, `Default`, `OneRegion`, and `ManyRegions`. `OneRegion` replicates the current behavior, and is the default for now. `ManyRegions` always allocates new regions when given the choice. This PR makes Java tests use the `ManyRegions` strategy to catch more lifetime errors. `Default` is somewhere in the middle, and will become the default. It will use one region (at least a constant number of regions) per row of a table. `Default` currently behaves the same as `ManyRegions`. Future work will implement the per-row behavior.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9220:267,allocate,allocates,267,https://hail.is,https://github.com/hail-is/hail/pull/9220,1,['allocate'],['allocates']
Energy Efficiency,"…poses only. This was added to debug if the resource usage monitoring triggered out of disk space errors again. Since, there's been no issues, let's take this out since it's O(n_jobs)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12541:59,monitor,monitoring,59,https://hail.is,https://github.com/hail-is/hail/pull/12541,1,['monitor'],['monitoring']
Integrability,	at is.hail.shadedazure.com.azure.storage.common.implementation.StorageImplUtils.blockWithOptionalTimeout(StorageImplUtils.java:133); 		at is.hail.shadedazure.com.azure.storage.blob.specialized.BlobClientBase.getPropertiesWithResponse(BlobClientBase.java:1379); 		at is.hail.shadedazure.com.azure.storage.blob.specialized.BlobClientBase.getProperties(BlobClientBase.java:1348); 		at is.hail.io.fs.AzureStorageFS.$anonfun$openNoCompression$1(AzureStorageFS.scala:223); 		at is.hail.io.fs.AzureStorageFS.$anonfun$handlePublicAccessError$1(AzureStorageFS.scala:175); 		at is.hail.services.package$.retryTransientErrors(package.scala:124); 		at is.hail.io.fs.AzureStorageFS.handlePublicAccessError(AzureStorageFS.scala:174); 		at is.hail.io.fs.AzureStorageFS.openNoCompression(AzureStorageFS.scala:220); 		at is.hail.io.fs.RouterFS.openNoCompression(RouterFS.scala:20); 		at is.hail.io.fs.FS.openNoCompression(FS.scala:322); 		at is.hail.io.fs.FS.openNoCompression$(FS.scala:322); 		at is.hail.io.fs.RouterFS.openNoCompression(RouterFS.scala:3); 		at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$3(ServiceBackend.scala:459); 		at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 		at is.hail.services.package$.retryTransientErrors(package.scala:124); 		at is.hail.backend.service.ServiceBackendSocketAPI2$.main(ServiceBackend.scala:459); 		at is.hail.backend.service.Main$.main(Main.scala:15); 		at is.hail.backend.service.Main.main(Main.scala); 		at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 		at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 		at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 		at java.lang.reflect.Method.invoke(Method.java:498); 		at is.hail.JVMEntryway$1.run(JVMEntryway.java:119); 		at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 		at java.util.concurrent.FutureTask.run(FutureTask.java:266); 		at java.util.concurrent,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13032#issuecomment-1542906430:1293,Rout,RouterFS,1293,https://hail.is,https://github.com/hail-is/hail/pull/13032#issuecomment-1542906430,1,['Rout'],['RouterFS']
Integrability, 	at is.hail.expr.ir.EmitCode$.fromI(Emit.scala:391); 	at is.hail.expr.ir.Emit.$anonfun$emitI$25(Emit.scala:816); 	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at scala.collection.TraversableLike.map(TraversableLike.scala:286); 	at scala.collection.TraversableLike.map$(TraversableLike.scala:279); 	at scala.collection.AbstractTraversable.map(Traversable.scala:108); 	at is.hail.expr.ir.Emit.emitI(Emit.scala:815); 	at is.hail.expr.ir.Emit$.$anonfun$apply$4(Emit.scala:99); 	at is.hail.expr.ir.EmitCodeBuilder$.scoped(EmitCodeBuilder.scala:19); 	at is.hail.expr.ir.EmitCodeBuilder$.scopedCode(EmitCodeBuilder.scala:24); 	at is.hail.expr.ir.EmitMethodBuilder.emitWithBuilder(EmitClassBuilder.scala:1044); 	at is.hail.expr.ir.WrappedEmitMethodBuilder.emitWithBuilder(EmitClassBuilder.scala:1095); 	at is.hail.expr.ir.WrappedEmitMethodBuilder.emitWithBuilder$(EmitClassBuilder.scala:1095); 	at is.hail.expr.ir.EmitFunctionBuilder.emitWithBuilder(EmitClassBuilder.scala:1192); 	at is.hail.expr.ir.Emit$.apply(Emit.scala:97); 	at is.hail.expr.ir.Compile$.apply(Compile.scala:78); 	at is.hail.TestUtils$.eval(TestUtils.scala:256); 	at is.hail.TestUtils$.$anonfun$assertEvalsTo$5(TestUtils.scala:366); 	at scala.collection.immutable.Set$Set4.foreach(Set.scala:289); 	at is.hail.TestUtils$.$anonfun$assertEvalsTo$4(TestUtils.scala:348); 	at is.hail.TestUtils$.$anonfun$assertEvalsTo$4$adapted(TestUtils.scala:339); 	at is.hail.expr.ir.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:47); 	at is.hail.utils.package$.using(package.scala:618); 	at is.hail.expr.ir.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:47); 	at is.hail.utils.package$.using(package.scala:618); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13);,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10330#issuecomment-827119604:1647,Wrap,WrappedEmitMethodBuilder,1647,https://hail.is,https://github.com/hail-is/hail/pull/10330#issuecomment-827119604,1,['Wrap'],['WrappedEmitMethodBuilder']
Integrability, 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:745). is.hail.utils.HailException: foo: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; offending line: 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:20); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.utils.Context.wrapException(Context.scala:19); 	at is.hail.utils.WithContext.wrap(Context.scala:43); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:377); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:375); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:575); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:573); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$28.apply(ContextRDD.scala:405); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$28.apply(ContextRDD.scala:405); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$8.apply(ContextRDD.scala:192); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$appl,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:10322,wrap,wrapException,10322,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['wrap'],['wrapException']
Integrability," ""/tmp/c38a09976d3c40abbc33f88f4fd39639/pyscripts_Zf07i2.zip/constraint_utils/constraint_basics.py"", line 41, in get_old_mu_data; File ""/tmp/c38a09976d3c40abbc33f88f4fd39639/hail-devel-17a988f2a628.zip/hail/table.py"", line 772, in transmute; File ""<decorator-gen-648>"", line 2, in _select; File ""/tmp/c38a09976d3c40abbc33f88f4fd39639/hail-devel-17a988f2a628.zip/hail/typecheck/check.py"", line 546, in wrapper; File ""/tmp/c38a09976d3c40abbc33f88f4fd39639/hail-devel-17a988f2a628.zip/hail/table.py"", line 438, in _select; File ""/tmp/c38a09976d3c40abbc33f88f4fd39639/hail-devel-17a988f2a628.zip/hail/table.py"", line 447, in _select_scala; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/c38a09976d3c40abbc33f88f4fd39639/hail-devel-17a988f2a628.zip/hail/utils/java.py"", line 210, in deco; hail.utils.java.FatalError: NullPointerException: null. Java stack trace:; java.lang.NullPointerException: null; 	at scala.collection.convert.Wrappers$JListWrapper.length(Wrappers.scala:86); 	at scala.collection.SeqLike$class.size(SeqLike.scala:106); 	at scala.collection.AbstractSeq.size(Seq.scala:41); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:285); 	at scala.collection.AbstractTraversable.toArray(Traversable.scala:104); 	at is.hail.utils.richUtils.RichIterable.toFastIndexedSeq(RichIterable.scala:83); 	at is.hail.table.Table.select(Table.scala:436); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4314#issuecomment-420405267:1746,Wrap,Wrappers,1746,https://hail.is,https://github.com/hail-is/hail/issues/4314#issuecomment-420405267,1,['Wrap'],['Wrappers']
Integrability," ""principals"" for each ""principal"". ""Principal"" is a computer; security term referring to an authenticatable identity. In our system, the; services are each unique principals and every client (e.g. the test_batch CI; step) is also a principal. A principal's certificate is a unforgeable proof of; their identity. A principal's ""key"", in our system, is actually a public-private; (i.e. asymmetric) key pair which the client and server use to establish a; symmetric key for each new connection. A list of trusted principals is a list of; certificates. Every incoming connection must provide a certificate in the; trusted list or the server will drop the connection. Every service depends on the `create_certs` step because their deployment's load; secrets created by `create_certs`. The blog service is implemented by Ghost. Ghost only supports HTTP. As a result; we cannot make all network traffic in our cluster TLS-secured. However, we can; use an nginx sidecar on the blog pod which terminates TLS connections and sends; plaintext traffic on the loopback interface to Ghost. Thus, our goal is: no; plaintext traffic on non-loopback interfaces. Readiness and liveness probes cannot use HTTP. Although k8s supports HTTPS, it; does not support so-called ""mTLS"" or ""mutual TLS."" This is fancy verbiage for; servers that require clients to send trusted certificates. We require; this. There is a lot of information in GitHub issues and the Istio web pages; about this, but at the end of the day, kubernetes does not support this. TCP; probes are the best we can do. There [was a; PR](https://github.com/kubernetes/kubernetes/pull/61231) to allow httpGet probes; to send the kubelet certificate, but it was closed because, apparently, the; [httpGet probes can be targeted at arbitrary IP; addresses](https://github.com/kubernetes/kubernetes/pull/61231#pullrequestreview-104364784) (what; the hell?), ergo Confused Deputy. I also partly resolved the batch [confused deputy; problem](https://en.wikipedia.o",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8513:1419,interface,interface,1419,https://hail.is,https://github.com/hail-is/hail/pull/8513,1,['interface'],['interface']
Integrability," ## Example Draw 1; ```scala; t Struct {; aj0iFnxi: Array[Set[Array[Dict[Empty, Dict[Array[Call], Call]]]]],; dA0IS78I: Set[Empty],; VeGLA3v: Array[Array[Struct {; C: Empty,; sHjMXnj: Boolean,; G: Call; }]],; Ni: Struct {; HCrSI: Empty,; nJt7: Boolean; },; nxb8CkLI: Int,; y4mYv_DvH: Dict[Array[Genotype], Variant]; }; v [ WrappedArray( Set( WrappedArray(null); , WrappedArray(); , WrappedArray(Map(null -> Map(WrappedArray(2) -> 2)), Map(null -> Map(WrappedArray() -> 1)), Map(null -> Map(WrappedArray(1) -> 2))); ); , Set(WrappedArray(Map(null -> null), Map(null -> Map(WrappedArray(2) -> 31, WrappedArray(0) -> 0)))); , Set(WrappedArray(Map(null -> Map()), Map(null -> null))); , Set( WrappedArray(Map()); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> null)); , WrappedArray(); , WrappedArray(null, Map(null -> Map(WrappedArray() -> null)))); , Set(); , Set( WrappedArray(Map(null -> Map(WrappedArray() -> null))); , WrappedArray(); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> Map()), Map(null -> Map(WrappedArray() -> 2)))); , Set(WrappedArray()); , Set( WrappedArray(); , WrappedArray(Map(null -> Map()))); , Set(); , Set( WrappedArray(Map(null -> nu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1902:1133,Wrap,WrappedArray,1133,https://hail.is,https://github.com/hail-is/hail/pull/1902,22,['Wrap'],['WrappedArray']
Integrability," ### What went wrong (all error messages here, including the full java stack trace): HailException: optimization changed type!; before: Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{ABHet:Float64,ABHom:Float64,AC:Array[Int32],AF:Array[Float64],AN:Int32,AS_BaseQRankSum:Array[Float64],AS_FS:Array[Float64],AS_InbreedingCoeff:Array[Float64],AS_InsertSizeRankSum:Array[Float64],AS_MQ:Array[Float64],AS_MQRankSum:Array[Float64],AS_QD:Float64,AS_ReadPosRankSum:Array[Float64],AS_SOR:Array[Float64],BaseQRankSum:Float64,DP:Int32,DS:Boolean,ExcessHet:Float64,FS:Float64,HRun:Int32,HaplotypeScore:Float64,InbreedingCoeff:Float64,LikelihoodRankSum:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,OND:Float64,QD:Float64,RPA:Array[Int32],RU:String,ReadPosRankSum:Float64,ReverseComplementedAlleles:Boolean,SOR:Float64,STR:Boolean,SwappedAlleles:Boolean},a_index:Int32,was_split:Boolean,old_locus:Locus(GRCh37),old_alleles:Array[String]},entry:Struct{AB:Float64,AD:Array[+Int32],DP:Int32,GQ:Int32,GT:Call,MQ0:Int32,PL:Array[+Int32],SB:Array[+Int32]}}; after: Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{ABHet:Float64,ABHom:Float64,AC:Array[Int32],AF:Array[Float64],AN:Int32,AS_BaseQRankSum:Array[Float64],AS_FS:Array[Float64],AS_InbreedingCoeff:Array[Float64],AS_InsertSizeRankSum:Array[Float64],AS_MQ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4827:411,message,messages,411,https://hail.is,https://github.com/hail-is/hail/issues/4827,1,['message'],['messages']
Integrability," ### What you did: ; Ran hail's maximal independent set method with the following code:. ```; related_samples_to_drop_ranked = hl.maximal_independent_set(related_pairs.id1_rank, related_pairs.id2_rank,keep=False, tie_breaker=tie_breaker); ```. where related pairs is structured as:. ```; ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'i': struct {; data_type: str, ; s: str; } ; 'j': struct {; data_type: str, ; s: str; } ; 'id1_rank': struct {; id: struct {; data_type: str, ; s: str; }, ; rank: int32; } ; 'id2_rank': struct {; id: struct {; data_type: str, ; s: str; }, ; rank: int32; } ; ----------------------------------------; Key: ['i', 'j']; ----------------------------------------; ```. and tie_breaker is :. ```; def tie_breaker(l, r):; return hl.or_else(l.rank, max_rank + 1) - hl.or_else(r.rank, max_rank + 1); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; FatalError Traceback (most recent call last); <ipython-input-220-88e7ce1066ed> in <module>; 11 return hl.or_else(l.rank, max_rank + 1) - hl.or_else(r.rank, max_rank + 1); 12 ; ---> 13 related_samples_to_drop_ranked = hl.maximal_independent_set(related_pairs.id1_rank, related_pairs.id2_rank,keep=False, tie_breaker=tie_breaker); 14 #return related_samples_to_drop_ranked.select(**related_samples_to_drop_ranked.node.id).key_by('data_type', 's'). <decorator-gen-1024> in maximal_independent_set(i, j, keep, tie_breaker). /home/hail/hail.zip/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 558 def wrapper(__original_func, *args, **kwargs):; 559 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 560 return __original_func(*args_, **kwargs_); 561 ; 562 return wrapper. /home/hail/hail.zip/hail/methods/misc.py in maximal_independent_set(i, j, keep, tie_breaker); 142 ; 143 edges = t.key_by().select('i', 'j'); --> 144 nodes_in_set = Env.hail()",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4857:971,message,messages,971,https://hail.is,https://github.com/hail-is/hail/issues/4857,1,['message'],['messages']
Integrability, &amp;lt;https://github.com/csm10495&amp;gt;&lt;/code&gt;_ for the fix&lt;/li&gt;; &lt;/ul&gt;; &lt;/li&gt;; &lt;/ul&gt;; &lt;p&gt;2.1.1 (2020-03-18)&lt;/p&gt;; &lt;pre&gt;&lt;code&gt;; * Fix issue with funcargs causing failures. (`[#282](https://github.com/pytest-dev/pytest-html/issues/282) &amp;lt;https://github.com/pytest-dev/pytest-html/issues/282&amp;gt;`_). * Thanks to `@ssbarnea &amp;lt;https://github.com/ssbarnea&amp;gt;`_ for reporting and `@christiansandberg &amp;lt;https://github.com/christiansandberg&amp;gt;`_ for the fix. 2.1.0 (2020-03-09); &lt;/code&gt;&lt;/pre&gt;; &lt;!-- raw HTML omitted --&gt;; &lt;/blockquote&gt;; &lt;p&gt;... (truncated)&lt;/p&gt;; &lt;/details&gt;; &lt;details&gt;; &lt;summary&gt;Commits&lt;/summary&gt;. &lt;ul&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/a1639ef4d9bdc89daa037fd0bfc003bdf2e99865&quot;&gt;&lt;code&gt;a1639ef&lt;/code&gt;&lt;/a&gt; Update CHANGES.rst (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/411&quot;&gt;#411&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/727b305a5707a937b427894360eba11c402b1755&quot;&gt;&lt;code&gt;727b305&lt;/code&gt;&lt;/a&gt; Enable camelcase eslint rule (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/410&quot;&gt;#410&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/dade11a7a1281ca3060bf1149fdc1d6d0763c97e&quot;&gt;&lt;code&gt;dade11a&lt;/code&gt;&lt;/a&gt; fixed css sort tringles (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/409&quot;&gt;#409&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/e00532d9c8a598fb848d16b0ce23665789e3517a&quot;&gt;&lt;code&gt;e00532d&lt;/code&gt;&lt;/a&gt; Use scss nesting &amp;amp; variables (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11524:13653,depend,dependabot,13653,https://hail.is,https://github.com/hail-is/hail/pull/11524,1,['depend'],['dependabot']
Integrability," &lt;/details&gt;. &lt;br /&gt;; </code></pre>. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyjwt&package-manager=pip&previous-version=1.7.1&new-version=2.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11866:15917,depend,dependabot,15917,https://hail.is,https://github.com/hail-is/hail/pull/11866,8,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability," &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/d0984435f92c34547c1fb1c1b68c2cba5d9c568a&quot;&gt;&lt;code&gt;d098443&lt;/code&gt;&lt;/a&gt; Remove pkg_resources (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/396&quot;&gt;#396&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;Additional commits viewable in &lt;a href=&quot;https://github.com/pytest-dev/pytest-html/compare/v1.20.0...v3.1.1&quot;&gt;compare view&lt;/a&gt;&lt;/li&gt;; &lt;/ul&gt;; &lt;/details&gt;. &lt;br /&gt;; </code></pre>. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest-html&package-manager=pip&previous-version=1.20.0&new-version=3.1.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11524:17564,depend,dependabot,17564,https://hail.is,https://github.com/hail-is/hail/pull/11524,1,['depend'],['dependabot']
Integrability," 'cinder': None,; 'config_map': None,; 'downward_api': None,; 'empty_dir': None,; 'fc': None,; 'flex_volume': None,; 'flocker': None,; 'gce_persistent_disk': None,; 'git_repo': None,; 'glusterfs': None,; 'host_path': None,; 'iscsi': None,; 'name': 'default-token-8h99c',; 'nfs': None,; 'persistent_volume_claim': None,; 'photon_persistent_disk': None,; 'portworx_volume': None,; 'projected': None,; 'quobyte': None,; 'rbd': None,; 'scale_io': None,; 'secret': {'default_mode': 420,; 'items': None,; 'optional': None,; 'secret_name': 'default-token-8h99c'},; 'storageos': None,; 'vsphere_volume': None}]},; 'status': {'conditions': [{'last_probe_time': None,; 'last_transition_time': datetime.datetime(2019, 6, 25, 3, 9, 4, tzinfo=tzlocal()),; 'message': None,; 'reason': None,; 'status': 'True',; 'type': 'Initialized'},; {'last_probe_time': None,; 'last_transition_time': datetime.datetime(2019, 6, 25, 3, 9, 4, tzinfo=tzlocal()),; 'message': 'containers with unready status: [main]',; 'reason': 'ContainersNotReady',; 'status': 'False',; 'type': 'Ready'},; {'last_probe_time': None,; 'last_transition_time': datetime.datetime(2019, 6, 25, 3, 9, 4, tzinfo=tzlocal()),; 'message': 'containers with unready status: [main]',; 'reason': 'ContainersNotReady',; 'status': 'False',; 'type': 'ContainersReady'},; {'last_probe_time': None,; 'last_transition_time': datetime.datetime(2019, 6, 25, 3, 9, 4, tzinfo=tzlocal()),; 'message': None,; 'reason': None,; 'status': 'True',; 'type': 'PodScheduled'}],; 'container_statuses': [{'container_id': None,; 'image': 'konradjk/saige:0.35.8.2.2',; 'image_id': '',; 'last_state': {'running': None,; 'terminated': None,; 'waiting': None},; 'name': 'main',; 'ready': False,; 'restart_count': 0,; 'state': {'running': None,; 'terminated': {'container_id': None,; 'exit_code': 0,; 'finished_at': None,; 'message': None,; 'reason': None,; 'signal': None,; 'started_at': None},; 'waiting': None}}],; 'host_ip': '10.128.0.8',; 'init_container_statuses': None,; 'message': N",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6466#issuecomment-505429649:8090,message,message,8090,https://hail.is,https://github.com/hail-is/hail/issues/6466#issuecomment-505429649,1,['message'],['message']
Integrability," (<a href=""https://github-redirect.dependabot.com/fsspec/gcsfs/issues/434"">#434</a>)</li>; <li><a href=""https://github.com/fsspec/gcsfs/commit/8f7115216346648bacc57f5910048cab5735b9b3""><code>8f71152</code></a> Add support to additional 'fixed-key-metadata' (<a href=""https://github-redirect.dependabot.com/fsspec/gcsfs/issues/429"">#429</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/fsspec/gcsfs/compare/2021.04.0...2022.02.0"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11575:2939,Depend,Dependabot,2939,https://hail.is,https://github.com/hail-is/hail/pull/11575,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability," (<a href=""https://github-redirect.dependabot.com/fsspec/gcsfs/issues/445"">#445</a>)</li>; <li><a href=""https://github.com/fsspec/gcsfs/commit/fd67c7d1b6ca9db83a0deadd1557470c37b0836a""><code>fd67c7d</code></a> Update changelog, deps (<a href=""https://github-redirect.dependabot.com/fsspec/gcsfs/issues/443"">#443</a>)</li>; <li><a href=""https://github.com/fsspec/gcsfs/commit/2dc256b7c0df075d44f8d4a0f3400c1b926166ee""><code>2dc256b</code></a> Make tarball creation more reproducible (<a href=""https://github-redirect.dependabot.com/fsspec/gcsfs/issues/442"">#442</a>)</li>; <li><a href=""https://github.com/fsspec/gcsfs/commit/85e2ee2abfa429f3c10cc08dcda8ed30db8ab3b5""><code>85e2ee2</code></a> update deps, changelog (<a href=""https://github-redirect.dependabot.com/fsspec/gcsfs/issues/438"">#438</a>)</li>; <li><a href=""https://github.com/fsspec/gcsfs/commit/cbf751e83785d8b7e5d7ea879e5534e32d633ae0""><code>cbf751e</code></a> Don't touch cache on find with prefix (<a href=""https://github-redirect.dependabot.com/fsspec/gcsfs/issues/437"">#437</a>)</li>; <li><a href=""https://github.com/fsspec/gcsfs/commit/7b5aee98724c7ca44a73524bf448089ac4b79b75""><code>7b5aee9</code></a> for release (<a href=""https://github-redirect.dependabot.com/fsspec/gcsfs/issues/435"">#435</a>)</li>; <li><a href=""https://github.com/fsspec/gcsfs/commit/4de170703d3f245a2e4f5e5c7abcef3ad3ec33c7""><code>4de1707</code></a> fixup references to dask/gcsfs (<a href=""https://github-redirect.dependabot.com/fsspec/gcsfs/issues/434"">#434</a>)</li>; <li><a href=""https://github.com/fsspec/gcsfs/commit/8f7115216346648bacc57f5910048cab5735b9b3""><code>8f71152</code></a> Add support to additional 'fixed-key-metadata' (<a href=""https://github-redirect.dependabot.com/fsspec/gcsfs/issues/429"">#429</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/fsspec/gcsfs/compare/2021.04.0...2022.02.0"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alte",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11575:1677,depend,dependabot,1677,https://hail.is,https://github.com/hail-is/hail/pull/11575,1,['depend'],['dependabot']
Integrability," (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1695"">#1695</a>) (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1760"">#1760</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/803a90b7747b8972f51d1407616c51084d97c589""><code>803a90b</code></a> deps: update dependency com.google.cloud:google-cloud-shared-dependencies to ...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/82aacd7922573d6f4779f21cdc83de10616d7a08""><code>82aacd7</code></a> feat: add Autoclass support and sample (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1697"">#1697</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/7e3175a56a06dac0aa0841f221a486bb69b5c9bf""><code>7e3175a</code></a> deps: update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.17...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/140e90911229c876de7b674dd1e61b278e8b07fd""><code>140e909</code></a> deps: update dependency net.jqwik:jqwik to v1.7.1 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1758"">#1758</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/303ba366cc706dd233d497618bb22f8b018a617b""><code>303ba36</code></a> chore: Set <code>rest_numeric_enums = False</code> for all gapic rules explicitly (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1756"">#1756</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/e2d3851e22adac0c2d3cc25a7c772de7ac9c05aa""><code>e2d3851</code></a> chore: require hashes when installing dependencies in owlbot postprocessor jo...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/a67683558eee7590f98a391d915eb3a19fb88f95""><code>a676835</code></a> chore(deps): update dependency com.google.cloud:libraries-bom to v26.1.4 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/is",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12456:12973,depend,dependency,12973,https://hail.is,https://github.com/hail-is/hail/pull/12456,1,['depend'],['dependency']
Integrability," (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/375"">#375</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/6fa17735fe3edb45483ec5e3abd1f53c24ffa881""><code>6fa1773</code></a> feat!: support string-encoded json (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/339"">#339</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/python-logging/compare/v1.12.1...v3.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=google-cloud-logging&package-manager=pip&previous-version=1.12.1&new-version=3.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11574:14554,depend,dependabot,14554,https://hail.is,https://github.com/hail-is/hail/pull/11574,1,['depend'],['dependabot']
Integrability," (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104736"">kubernetes/kubernetes#104736</a>, <a href=""https://github.com/lauchokyip""><code>@​lauchokyip</code></a>)</li>; <li>Indexed Jobs graduated to stable. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107395"">kubernetes/kubernetes#107395</a>, <a href=""https://github.com/alculquicondor""><code>@​alculquicondor</code></a>)</li>; <li>Introduce a v1alpha1 networking API for ClusterCIDRConfig (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108290"">kubernetes/kubernetes#108290</a>, <a href=""https://github.com/sarveshr7""><code>@​sarveshr7</code></a>)</li>; <li>Introduction of a new &quot;sync_proxy_rules_no_local_endpoints_total&quot; proxy metric. This metric represents the number of services with no internal endpoints. The &quot;traffic_policy&quot; label will contain both &quot;internal&quot; or &quot;external&quot;. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108930"">kubernetes/kubernetes#108930</a>, <a href=""https://github.com/MaxRenaud""><code>@​MaxRenaud</code></a>)</li>; <li>JobReadyPods graduates to Beta and it's enabled by default. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107476"">kubernetes/kubernetes#107476</a>, <a href=""https://github.com/alculquicondor""><code>@​alculquicondor</code></a>)</li>; <li>Kube-apiserver: <code>--audit-log-version</code> and <code>--audit-webhook-version</code> now only support the default value of <code>audit.k8s.io/v1</code>. The v1alpha1 and v1beta1 audit log versions, deprecated since 1.13, have been removed. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108092"">kubernetes/kubernetes#108092</a>, <a href=""https://github.com/carlory""><code>@​carlory</code></a>)</li>; <li>Kube-apiserver: the <code>metadata.selfLink</code> field can no longer be populated by kube-apiserver; it was deprecated in 1.16 and has n",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:7855,depend,dependabot,7855,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['depend'],['dependabot']
Integrability," (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45942"">#45942</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/f61dfde6abbe33e143e83c6685e4b3c1c488f92b""><code>f61dfde</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45936"">#45936</a>: DOC: 1.4.1 release date (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45941"">#45941</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/28f5e9093377f72742b60e458949b7b4714141ed""><code>28f5e90</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45925"">#45925</a>: BUG: rolling(axis=1).apply() raising ValueError (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45939"">#45939</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/0fc655f84c6b51552a7c70f2b92c846b4d24e381""><code>0fc655f</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45920"">#45920</a>: DOC: fix URLs, formatting and typos (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45930"">#45930</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/1418835ea328eb402686c31c8d6de0a99ad55bc9""><code>1418835</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45633"">#45633</a>: DOC: Fix typo in nth docstring (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45924"">#45924</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/f035290718ef8e0683ecb16a20639ed5e57e10eb""><code>f035290</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45853"">#45853</a>: Fixing documentation format in read_csv (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45922"">#45922</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/ebf024eb886a8e81922250a386c8d1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11521:2420,depend,dependabot,2420,https://hail.is,https://github.com/hail-is/hail/pull/11521,2,['depend'],['dependabot']
Integrability," (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5928"">#5928</a>)</p>; </li>; <li>; <p>Added a <code>requests.exceptions.JSONDecodeError</code> to unify JSON exceptions between; Python 2 and 3. This gets raised in the <code>response.json()</code> method, and is; backwards compatible as it inherits from previously thrown exceptions.; Can be caught from <code>requests.exceptions.RequestException</code> as well. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5856"">#5856</a>)</p>; </li>; <li>; <p>Improved error text for misnamed <code>InvalidSchema</code> and <code>MissingSchema</code>; exceptions. This is a temporary fix until exceptions can be renamed; (Schema-&gt;Scheme). (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/6017"">#6017</a>)</p>; </li>; <li>; <p>Improved proxy parsing for proxy URLs missing a scheme. This will address; recent changes to <code>urlparse</code> in Python 3.9+. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5917"">#5917</a>)</p>; </li>; </ul>; <p><strong>Bugfixes</strong></p>; <ul>; <li>; <p>Fixed defect in <code>extract_zipped_paths</code> which could result in an infinite loop; for some paths. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5851"">#5851</a>)</p>; </li>; <li>; <p>Fixed handling for <code>AttributeError</code> when calculating length of files obtained; by <code>Tarfile.extractfile()</code>. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5239"">#5239</a>)</p>; </li>; <li>; <p>Fixed urllib3 exception leak, wrapping <code>urllib3.exceptions.InvalidHeader</code> with; <code>requests.exceptions.InvalidHeader</code>. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5914"">#5914</a>)</p>; </li>; <li>; <p>Fixed bug where two Host headers were sent for chunked requests. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5391"">#5391</a>)</p>; </li>; <li>; <p>Fixed regression in",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11528:1867,depend,dependabot,1867,https://hail.is,https://github.com/hail-is/hail/pull/11528,4,['depend'],['dependabot']
Integrability," (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/133"">#133</a>). Thanks to <a href=""https://github.com/jmsmkn""><code>@​jmsmkn</code></a> and <a href=""https://github.com/adamchainz""><code>@​adamchainz</code></a>!</li>; <li>Fix incorrect documentation for <a href=""https://www.curlylint.org/docs/rules/no_autofocus""><code>no_autofocus</code></a> and <a href=""https://www.curlylint.org/docs/rules/tabindex_no_positive""><code>tabindex_no_positive</code></a>.</li>; </ul>; <h2>v0.13.0 – Quality-of-life improvements</h2>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.13.0"">v0.13.0</a> 2021-04-24</h2>; <p>This release comes with a blog post! Read on <a href=""https://www.curlylint.org/blog/quality-of-life-improvements"">Quality-of-life improvements</a>.</p>; <h3>Added</h3>; <ul>; <li>Implement --template-tags CLI flag (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/25"">#25</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/77"">#77</a>).</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Add more descriptive error message for missing whitespace between HTML attributes (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/23#issuecomment-700622837"">#23 (comment)</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; <li>Move development dependencies from extras to separate <code>requirements.txt</code> (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; <li>Declare support for Python 3.9.</li>; <li>Tentatively declare support for Python 3.10 (tested with <code>Python 3.10.0a6+</code>).</li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Fix Python 3.10 deprecation warning by importing Iterable from collections.abc (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; </ul>; <h2>v0.12.2</h2>; <h2><a href=""https://github.com/thibaudcolas/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11713:1578,depend,dependabot,1578,https://hail.is,https://github.com/hail-is/hail/pull/11713,1,['depend'],['dependabot']
Integrability," (<a href=""https://github.com/googleapis/java-storage/commit/31c1b18acc3c118e39eb613a82ee292f3e246b8f"">31c1b18</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Clarified relative resource names in gRPC IAM RPCs (<a href=""https://github.com/googleapis/java-storage/commit/31c1b18acc3c118e39eb613a82ee292f3e246b8f"">31c1b18</a>)</li>; <li>Clarified the object can be deleted via DeleteObject (<a href=""https://github.com/googleapis/java-storage/commit/31c1b18acc3c118e39eb613a82ee292f3e246b8f"">31c1b18</a>)</li>; <li>Updated the document link for <code>Naming Guidelines</code> (<a href=""https://github.com/googleapis/java-storage/commit/31c1b18acc3c118e39eb613a82ee292f3e246b8f"">31c1b18</a>)</li>; </ul>; <h3>Dependencies</h3>; <ul>; <li>Update dependency com.google.cloud:google-cloud-shared-dependencies to v3.1.0 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1797"">#1797</a>) (<a href=""https://github.com/googleapis/java-storage/commit/b1d026608a5e3772e8bf77f25f1daf68b007427a"">b1d0266</a>)</li>; <li>Update dependency org.apache.httpcomponents:httpclient to v4.5.14 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1795"">#1795</a>) (<a href=""https://github.com/googleapis/java-storage/commit/cf900f4139f30f89e3c0784467ddc12cc00cf81c"">cf900f4</a>)</li>; <li>Update dependency org.apache.httpcomponents:httpcore to v4.4.16 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1786"">#1786</a>) (<a href=""https://github.com/googleapis/java-storage/commit/3bf403e94c035e6cf936e062a1ced2b5221b3912"">3bf403e</a>)</li>; <li>Update dependency org.apache.httpcomponents:httpmime to v4.5.14 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1796"">#1796</a>) (<a href=""https://github.com/googleapis/java-storage/commit/c9ee3ca8820531cd709bb8f8a58a736813346861"">c9ee3ca</a>)</li>; <li>Update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.18 (<a href=""https://github-redi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12545:2273,depend,dependency,2273,https://hail.is,https://github.com/hail-is/hail/pull/12545,2,['depend'],['dependency']
Integrability," (<a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac"">6af2132</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/0ee8d805e9061b52a210d69d46e433c718ad18ff""><code>0ee8d80</code></a> chore(main): release 1.57.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/139"">#139</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/b9dbb219ea46abd9851af1fc41ea37f9d5631c0b""><code>b9dbb21</code></a> feat: add support for Python 3.11 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/145"">#145</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/63ca888512be84508fcf95e4d5d40df036a85e18""><code>63ca888</code></a> feat: add support for Python 3.10 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/143"">#143</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac""><code>6af2132</code></a> chore(python): update dependencies in .kokoro/requirements.txt [autoapprove] ...</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/9ea3530b459269e964fcc98db1c5025e05d6495f""><code>9ea3530</code></a> fix(deps): require protobuf &gt;=3.19.5 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/141"">#141</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/5cf4e0bbfed23d061600d64099f21fcf92ef0cf2""><code>5cf4e0b</code></a> chore: update dependency protobuf &gt;= 3.20.2 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/138"">#138</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/92d9f53f5525ecb9af97c93467",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12514:5367,depend,dependabot,5367,https://hail.is,https://github.com/hail-is/hail/pull/12514,1,['depend'],['dependabot']
Integrability," (<a href=""https://github.com/googleapis/python-api-common-protos/commit/b9dbb219ea46abd9851af1fc41ea37f9d5631c0b"">b9dbb21</a>)</li>; <li>added google.api.JwtLocation.cookie (<a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac"">6af2132</a>)</li>; <li>added google.api.Service.publishing and client libraries settings (<a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac"">6af2132</a>)</li>; <li>new fields in enum google.api.ErrorReason (<a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac"">6af2132</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <ul>; <li>deprecate google.api.BackendRule.min_deadline (<a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac"">6af2132</a>)</li>; <li><strong>deps:</strong> Require protobuf &gt;=3.19.5 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/141"">#141</a>) (<a href=""https://github.com/googleapis/python-api-common-protos/commit/9ea3530b459269e964fcc98db1c5025e05d6495f"">9ea3530</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>minor updates to comments (<a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac"">6af2132</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/python-api-common-protos/blob/main/CHANGELOG.md"">googleapis-common-protos's changelog</a>.</em></p>; <blockquote>; <h2><a href=""https://github.com/googleapis/python-api-common-protos/compare/v1.56.4...v1.57.0"">1.57.0</a> (2022-11-15)</h2>; <h3>Features</h3>; <ul>; <li>Add support for Python 3.10 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/143"">#143</a>) (<a href=""https://github.com/googleapis/python-api-common-prot",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12514:1890,depend,dependabot,1890,https://hail.is,https://github.com/hail-is/hail/pull/12514,1,['depend'],['dependabot']
Integrability," (<a href=""https://github.com/googleapis/python-api-common-protos/commit/b9dbb219ea46abd9851af1fc41ea37f9d5631c0b"">b9dbb21</a>)</li>; <li>added google.api.JwtLocation.cookie (<a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac"">6af2132</a>)</li>; <li>added google.api.Service.publishing and client libraries settings (<a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac"">6af2132</a>)</li>; <li>new fields in enum google.api.ErrorReason (<a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac"">6af2132</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <ul>; <li>deprecate google.api.BackendRule.min_deadline (<a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac"">6af2132</a>)</li>; <li><strong>deps:</strong> Require protobuf &gt;=3.19.5 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/141"">#141</a>) (<a href=""https://github.com/googleapis/python-api-common-protos/commit/9ea3530b459269e964fcc98db1c5025e05d6495f"">9ea3530</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>minor updates to comments (<a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac"">6af2132</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/0ee8d805e9061b52a210d69d46e433c718ad18ff""><code>0ee8d80</code></a> chore(main): release 1.57.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/139"">#139</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/b9dbb219ea46abd9851af1fc41ea37f9d5631c0b""><code>b9dbb21</code></a> feat: add support for Python 3.11 (<a href=""https://github-redirect.dependabot.com/googleapis/py",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12514:4100,depend,dependabot,4100,https://hail.is,https://github.com/hail-is/hail/pull/12514,1,['depend'],['dependabot']
Integrability," (<a href=""https://github.com/utkonos""><code>@​utkonos</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_client/graphs/contributors?from=2022-06-06&amp;to=2022-06-07&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Autkonos+updated%3A2022-06-06..2022-06-07&amp;type=Issues""><code>@​utkonos</code></a></p>; <h2>7.3.2</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v7.3.1...c81771416d9e09e0e92be799f3e8549d0db57e43"">Full Changelog</a>)</p>; <h3>Enhancements made</h3>; <ul>; <li>Correct <code>Any</code> type annotations. <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/791"">#791</a> (<a href=""https://github.com/joouha""><code>@​joouha</code></a>)</li>; </ul>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>[pre-commit.ci] pre-commit autoupdate <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/792"">#792</a> (<a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a>)</li>; <li>Use hatch backend <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/789"">#789</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; <li>[pre-commit.ci] pre-commit autoupdate <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/788"">#788</a> (<a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a>)</li>; <li>Use flit build backend <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/781"">#781</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/c26ce9f8f9c5b697a3f78afeee60ab23e94c3fca""><code>c26ce9f</code></a> Publish 7",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12110:6654,depend,dependabot,6654,https://hail.is,https://github.com/hail-is/hail/pull/12110,1,['depend'],['dependabot']
Integrability," (<a href=""https://redirect.github.com/ipython/ipython/issues/13991"">#13991</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/ad452c1d8bb25e742caa152fb301e0e6626b6faa""><code>ad452c1</code></a> Improve API documentation around configuration of embedded IPython (<a href=""https://redirect.github.com/ipython/ipython/issues/13989"">#13989</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/92027083ab69186db3f104fe38651086bcf4e760""><code>9202708</code></a> Handle OSError cases where traceback frames occur from built files (<a href=""https://redirect.github.com/ipython/ipython/issues/13964"">#13964</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/fc872d6cfab48d861c43c766d583edde73370836""><code>fc872d6</code></a> Allow to dispatch getting documentation on objects</li>; <li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/7.34.0...8.12.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ipython&package-manager=pip&previous-version=7.34.0&new-version=8.12.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12832:2587,Depend,Dependabot,2587,https://hail.is,https://github.com/hail-is/hail/pull/12832,4,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability," (<a href=""https://redirect.github.com/urllib3/urllib3/issues/3058"">#3058</a>)</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/3c0148048a523325819377b23fc67f8d46afc3aa""><code>3c01480</code></a> [1.26] Run coverage even with failed jobs</li>; <li>See full diff in <a href=""https://github.com/urllib3/urllib3/compare/1.26.16...1.26.17"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.16&new-version=1.26.17)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13762:3093,Depend,Dependabot,3093,https://hail.is,https://github.com/hail-is/hail/pull/13762,5,['Depend'],['Dependabot']
Integrability," (but supposedly not repeated); sub-messages directly from text rather than building a new sub-message and; merging the fully formed message into the existing field.</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-h4h5-3hr4-j3g2"">Security Advisory for Java users</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/protocolbuffers/protobuf/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.2&new-version=4.21.9)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12518:2026,depend,dependabot,2026,https://hail.is,https://github.com/hail-is/hail/pull/12518,1,['depend'],['dependabot']
Integrability," (e.g. I refreshed and then got the notebook). > I think imagePullPolicy: Never is a bad idea. Agreed, too aggressive. > I think we should rely on k8s to pull the 5GB jupyter image in a reasonable time period. No. I'm going to be demanding about making our tools responsive with good feedback (not responsive in the sense of responsive web design, but responsive in the sense of fast). It has to be fast, and when can't be, it has to give clear feedback about what it's doing and how long it will take. We routinely see pulling a 5GB image take 1-2m. That's spin up a VM level nonsense. Kubernetes 1.6 had an SLO to schedule 99% of pre-pulled containers within 5s on a 5K node cluster (from the plots it looks like they were closer to 2s):. > Pod startup time: 99% of pods and their containers (with pre-pulled images) start within 5s. from http://webcache.googleusercontent.com/search?q=cache:Soglxt0kAI0J:blog.kubernetes.io/2017/03/scalability-updates-in-kubernetes-1.6.html+&cd=1&hl=en&ct=clnk&gl=us. When we have to pull an image, I want spinner and the estimated spin time. If we have to spin up a node, same. (I know this is a first cut. I'm just saying where I'd like to see us head.). > I just run make clean-jobs, but we could add a delete endpoint and a little web page. OK, here's my picture:; - first time, prompt for password,; - if no notebook is running launch one and go straight there,; - if notebook is running, get a page with a link to the notebook and a link to kill it. That might be considered strange web design (skip the console depending on the state), in which case I'd vote for the console always. (What Jupyter hub does.). > I thought it would take less time to get a subdirectory working than figure out how to add a new domain and a cert and deal with DNS. Fair. I added a wildcard *.staging.hail.is for staging, I'll do the same thing for Hail. Then you don't need to change the DNS to add a domain, and I'll write up instructions for adding a new domain to get certs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4576#issuecomment-431248659:1925,depend,depending,1925,https://hail.is,https://github.com/hail-is/hail/pull/4576#issuecomment-431248659,2,['depend'],['depending']
Integrability," (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jupyter/jupyter_client/blob/main/CHANGELOG.md"">jupyter-client's changelog</a>.</em></p>; <blockquote>; <h2>7.3.4</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v7.3.3...ca4cb2d6a4b95a6925de85a47b323d2235032c74"">Full Changelog</a>)</p>; <h3>Bugs fixed</h3>; <ul>; <li>Revert latest changes to <code>ThreadedZMQSocketChannel</code> because they break Qtconsole <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/803"">#803</a> (<a href=""https://github.com/ccordoba12""><code>@​ccordoba12</code></a>)</li>; </ul>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Fix sphinx 5.0 support <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/804"">#804</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; <li>[pre-commit.ci] pre-commit autoupdate <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/799"">#799</a> (<a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_client/graphs/contributors?from=2022-06-07&amp;to=2022-06-08&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Ablink1073+updated%3A2022-06-07..2022-06-08&amp;type=Issues""><code>@​blink1073</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Accordoba12+updated%3A2022-06-07..2022-06-08&amp;type=Issues""><code>@​ccordoba12</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Apre-commit-ci+updated%3A2022-06-07..2022-06-08&amp;type=Issues""><code>@​pre-commit-ci</code></a></p>; <!-- raw HTML omitted -->; <h2>7.3.3</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v7.3.2...37",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12110:4318,depend,dependabot,4318,https://hail.is,https://github.com/hail-is/hail/pull/12110,1,['depend'],['dependabot']
Integrability," * `mill compile` - compiles the root module (not including tests); * `mill test.compile` - compiles tests (and, transitively, the rest of the root module); * `mill test.test`, or for short `mill test` - run all tests. You can pass options to the test runner (TestNG currently), e.g.* * `mill test -methods is.hail.expr.ir.CallFunctionsSuite.constructors` to run one test, or `mill test -threadcount 4 -parallel classes` to use 4 threads and parallelize over test classes; * `mill test.testOnly is.hail.expr.ir.CallFunctionsSuite` - run all tests in one or more specified classes. You can use `*` to match anything, e.g. `mill test.testOnly ""*.CallFunctionsSuite""`, or `mill test.testOnly ""is.hail.expr.ir.*""`. You can pass options to the test runner (TestNG currently) after a `--`, e.g. `mill test.testOnly ""is.hail.expr.ir.*"" -- -parallel classes`; * `mill __.testCached` - once the codebase is more modularized, will run tests on only modules whose dependencies have changed since the last test run; * `mill reformat` - runs scalafmt on all sources in the root module (currently that's all scala sources, but hopefully not for long). `mill __.reformat` runs scalaformat on all sources in all modules. `mill __.checkFormat` only checks for rule failures (we run this in ci); * `mill fix` - runs scalafix on all sources in the root module (currently that's all scala sources, but hopefully not for long). `mill __.fix` runs scalafix on all sources in all modules. `mill __.fix --check` only checks for rule failures (we run this in ci). You can pass any options to scalafix, e.g. `mill fix --help`.; * `mill inspect` - see the docstring and dependencies for any target, e.g. `mill inspect compile`; * `mill ivyDepsTree` - show the tree of external dependencies of the root module, highlighting potential incompatibilities in transitive dependencies. `mill ivyDepsTree --withCompile --withRuntime` includes compile-only and runtime-only dependencies. Use `--whatDependsOn` to see an inverted tree sh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14147:1804,depend,dependencies,1804,https://hail.is,https://github.com/hail-is/hail/pull/14147,1,['depend'],['dependencies']
Integrability," - <a href=""https://github.com/mkarg""><code>@​mkarg</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1414"">#1414</a>: Fix definition of <code>c.s.j.p.unix.X11.XK_Shift_R</code> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1323"">#1323</a>. Fix crashes in direct callbacks on mac OS aarch64 - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1422"">#1422</a>: Load jawt library relative to <code>sun.boot.library.path</code> system on unix OSes - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1427"">#1427</a>: Rebuild all binaries with fix from <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1422"">#1422</a> and <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1323"">#1323</a> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; </ul>; <h1>Release 5.10.0</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/java-native-access/jna/commit/3705b849892aa3c37e5608e640eff19047811a5c""><code>3705b84</code></a> Release 5.12.1</li>; <li><a href=""https://github.com/java-native-access/jna/commit/2f919e56bad203494fe9589206d6d23f27ef4f26""><code>2f919e5</code></a> Null-check cleanable in Memory#close (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1447"">#1447</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/1eec7dd76830af97ed64ecb2d8d39a56db104dcd""><code>1eec7dd</code></a> Prepare next development iteration</li>; <li><a href=""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:5168,depend,dependabot,5168,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['depend'],['dependabot']
Integrability," ---------------------------------------------------------------------------; LookupError Traceback (most recent call last); <ipython-input-8-b09a26588332> in <module>(); ----> 1 hl.methods.maximal_independent_set(t.idx, t.idx // 2, tie_breaker = lambda i, j: hl.signum(i - j)). ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/projects/hail/python/hail/methods/misc.py in maximal_independent_set(i, j, keep, tie_breaker); 139 .select()); 140 ; --> 141 edges = t.key_by(None).select('i', 'j'); 142 nodes_in_set = Env.hail().utils.Graph.maximalIndependentSet(edges._jt.collect(), node_t._jtype, joption(tie_breaker_hql)); 143 . ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/projects/hail/python/hail/table.py in select(self, *exprs, **named_exprs); 863 row = get_select_exprs('Table.select',; 864 exprs, named_exprs, self._row_indices,; --> 865 protect_keys=True); 866 return self._select('Table.select', value_struct=hl.struct(**row)); 867 . ~/projects/hail/python/hail/utils/misc.py in get_select_exprs(caller, exprs, named_exprs, indices, protect_keys); 314 def get_select_exprs(caller, exprs, named_exprs, indices, protect_keys=True):; 315 from hail.expr.expressions import to_expr, ExpressionException, TopLevelReference, Select; --> 316 exprs = [to_expr(e) if not isinstance(e, str) else indices.source[e] for e in exprs]; 317 named_exprs = {k: to_expr(v) for k, v in named_exprs.items()}; 318 assignments = OrderedDict(). ~/projects/hail/python/hail/utils/misc.py in <listcomp>(.0); 314 def get_select_exprs(caller, exprs, named_exprs, indices, protect_k",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3706:1194,wrap,wrapper,1194,https://hail.is,https://github.com/hail-is/hail/issues/3706,3,['wrap'],['wrapper']
Integrability," .gitignore and exclude regex at time of use</li>; <li><a href=""https://github.com/psf/black/commit/e269f44b25737360e0dc65379f889dfa931dc68a""><code>e269f44</code></a> Lazily import parallelized format modules</li>; <li><a href=""https://github.com/psf/black/commit/c47b91f513052cd39b818ea7c19716423c85c04e""><code>c47b91f</code></a> Fix misdetection of project root with <code>--stdin-filename</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3216"">#3216</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/psf/black/compare/22.3.0...22.8.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=black&package-manager=pip&previous-version=22.3.0&new-version=22.8.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12174:11599,Depend,Dependabot,11599,https://hail.is,https://github.com/hail-is/hail/pull/12174,1,['Depend'],['Dependabot']
Integrability," /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in persist(self, storage_level); 2110 Persisted table.; 2111 """"""; -> 2112 return Env.backend().persist(self); 2113 ; 2114 def unpersist(self) -> 'Table':. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/backend/backend.py in persist(self, dataset); 167 from hail.context import TemporaryFilename; 168 tempfile = TemporaryFilename(prefix=f'persist_{type(dataset).__name__}'); --> 169 persisted = dataset.checkpoint(tempfile.__enter__()); 170 self._persisted_locations[persisted] = (tempfile, dataset); 171 return persisted. <decorator-gen-1330> in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals); 1329 ; 1330 if not _read_if_exists or not hl.hadoop_exists(f'{output}/_SUCCESS'):; -> 1331 self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); 1332 _assert_type = self._type; 1333 _load_refs = False. <decorator-gen-1332> in write(self, output, overwrite, stage_locally, _codec_spec). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/minico",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:4273,wrap,wrapper,4273,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124,1,['wrap'],['wrapper']
Integrability," 1.5.5.; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/erdewit/nest_asyncio/commit/3cfd2c8bc453174ec0be57cd3bb8ec16dbcde1b4""><code>3cfd2c8</code></a> Potential fix for issue <a href=""https://github-redirect.dependabot.com/erdewit/nest_asyncio/issues/65"">#65</a></li>; <li><a href=""https://github.com/erdewit/nest_asyncio/commit/616d9a5e15d8d75e3343422778e49af2e9ac80ea""><code>616d9a5</code></a> Patch asyncio.get_event_loop to not require a running loop, fixes <a href=""https://github-redirect.dependabot.com/erdewit/nest_asyncio/issues/70"">#70</a></li>; <li>See full diff in <a href=""https://github.com/erdewit/nest_asyncio/compare/v1.5.4...v1.5.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=nest-asyncio&package-manager=pip&previous-version=1.5.4&new-version=1.5.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12209:1074,depend,dependabot-security-updates,1074,https://hail.is,https://github.com/hail-is/hail/pull/12209,1,['depend'],['dependabot-security-updates']
Integrability," 1.5.x (CI: Fix matplolib release issues) (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48617"">#48617</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/aabf6597f45436e9ada915ac15d3708f9d4948ca""><code>aabf659</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48587"">#48587</a> on branch 1.5.x (Fix <code>series.str.startswith(tuple)</code>) (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48593"">#48593</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/dfc00bfc5d98f8e2c63356e6a415da8ab7a7b436""><code>dfc00bf</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48397"">#48397</a> on branch 1.5.x (WARN: Remove false positive warning for i...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/3f91207dca8971c723605243f6bc113c739ba637""><code>3f91207</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48572"">#48572</a> on branch 1.5.x (DOC: Fixing styles for the dark theme) (#...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/27fd6c6c5141c5946470f4810858eb903491d651""><code>27fd6c6</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48285"">#48285</a> on branch 1.5.x (WEB: Unpin pydata sphinx theme) (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48585"">#48585</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/9e8d859f46abe33896ed9df8d82587f915cc2529""><code>9e8d859</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48557"">#48557</a> on branch 1.5.x (WEB: Add new footer to web) (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48571"">#48571</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.5...v1.5.0"">compare view</a></li>; </ul>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12292:4867,depend,dependabot,4867,https://hail.is,https://github.com/hail-is/hail/pull/12292,1,['depend'],['dependabot']
Integrability," 1374 rows = self.take(n + 1); 1375 has_more = len(rows) > n; 1376 rows = rows[:n]. </usr/local/lib/python3.6/site-packages/decorator.py:decorator-gen-1029> in take(self, n, _localize). /usr/local/lib/python3.6/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 583 def wrapper(__original_func, *args, **kwargs):; 584 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 585 return __original_func(*args_, **kwargs_); 586 ; 587 return wrapper. /usr/local/lib/python3.6/site-packages/hail/table.py in take(self, n, _localize); 2011 """"""; 2012 ; -> 2013 return self.head(n).collect(_localize); 2014 ; 2015 @typecheck_method(n=int). </usr/local/lib/python3.6/site-packages/decorator.py:decorator-gen-1023> in collect(self, _localize). /usr/local/lib/python3.6/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 583 def wrapper(__original_func, *args, **kwargs):; 584 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 585 return __original_func(*args_, **kwargs_); 586 ; 587 return wrapper. /usr/local/lib/python3.6/site-packages/hail/table.py in collect(self, _localize); 1825 e = construct_expr(ir, hl.tarray(self.row.dtype)); 1826 if _localize:; -> 1827 return Env.backend().execute(e._ir); 1828 else:; 1829 return e. /usr/local/lib/python3.6/site-packages/hail/backend/backend.py in execute(self, ir, timed); 106 ; 107 def execute(self, ir, timed=False):; --> 108 result = json.loads(Env.hc()._jhc.backend().executeJSON(self._to_java_ir(ir))); 109 value = ir.typ._from_json(result['value']); 110 timings = result['timings']. /usr/lib/spark/python/lib/py4j-src.zip/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /usr/local/lib/python3.6/site-packages/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7044:3558,wrap,wrapper,3558,https://hail.is,https://github.com/hail-is/hail/issues/7044,6,['wrap'],['wrapper']
Integrability," 283, in executemany; self._get_db().encoding)); File \""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py\"", line 318, in _do_execute_many; r = await self.execute(sql + postfix); File \""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py\"", line 239, in execute; await self._query(query); File \""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py\"", line 457, in _query; await conn.query(q); File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 428, in query; await self._read_query_result(unbuffered=unbuffered); File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 622, in _read_query_result; await result.read(); File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 1105, in read; first_packet = await self.connection._read_packet(); File \""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py\"", line 593, in _read_packet; packet.check_error(); File \""/usr/local/lib/python3.6/dist-packages/pymysql/protocol.py\"", line 220, in check_error; err.raise_mysql_exception(self._data); File \""/usr/local/lib/python3.6/dist-packages/pymysql/err.py\"", line 109, in raise_mysql_exception; raise errorclass(errno, errval); pymysql.err.IntegrityError: (1062, \""Duplicate entry '27-122310' for key 'PRIMARY'\""). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File \""/usr/local/lib/python3.6/dist-packages/aiohttp/web_protocol.py\"", line 418, in start; resp = await task; File \""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py\"", line 458, in _handle; resp = await handler(request); File \""/usr/local/lib/python3.6/dist-packages/aiohttp/web_middlewares.py\"", line 119, in impl; return await handler(request); File \""/usr/local/lib/python3.6/dist-packages/aiohttp_session/__init__.py\"", line 152, in factory; response = await handler(request); File \""/usr/local/lib/python3.6/dist-packages/prometheus_async/aio/_decorators.py\"", line 42, i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8307:1679,protocol,protocol,1679,https://hail.is,https://github.com/hail-is/hail/pull/8307,1,['protocol'],['protocol']
Integrability," 3.11 tests</li>; <li>Additional commits viewable in <a href=""https://github.com/python-parsy/parsy/compare/v1.1.0...v2.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=parsy&package-manager=pip&previous-version=1.1.0&new-version=2.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>> **Note**; > Automatic rebases have been disabled on this pull request as it has been open for over 30 days.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12934:4586,Depend,Dependabot,4586,https://hail.is,https://github.com/hail-is/hail/pull/12934,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability," 3.2.0.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/ai/nanoid/blob/main/CHANGELOG.md"">nanoid's changelog</a>.</em></p>; <blockquote>; <h1>Change Log</h1>; <p>This project adheres to <a href=""http://semver.org/"">Semantic Versioning</a>.</p>; <h2>3.2</h2>; <ul>; <li>Added <code>--size</code> and <code>--alphabet</code> arguments to binary (by Vitaly Baev).</li>; </ul>; <h2>3.1.32</h2>; <ul>; <li>Reduced <code>async</code> exports size (by Artyom Arutyunyan).</li>; <li>Moved from Jest to uvu (by Vitaly Baev).</li>; </ul>; <h2>3.1.31</h2>; <ul>; <li>Fixed collision vulnerability on object in <code>size</code> (by Artyom Arutyunyan).</li>; </ul>; <h2>3.1.30</h2>; <ul>; <li>Reduced size for project with <code>brotli</code> compression (by Anton Khlynovskiy).</li>; </ul>; <h2>3.1.29</h2>; <ul>; <li>Reduced npm package size.</li>; </ul>; <h2>3.1.28</h2>; <ul>; <li>Reduced npm package size.</li>; </ul>; <h2>3.1.27</h2>; <ul>; <li>Cleaned <code>dependencies</code> from development tools.</li>; </ul>; <h2>3.1.26</h2>; <ul>; <li>Improved performance (by Eitan Har-Shoshanim).</li>; <li>Reduced npm package size.</li>; </ul>; <h2>3.1.25</h2>; <ul>; <li>Fixed <code>browserify</code> support.</li>; </ul>; <h2>3.1.24</h2>; <ul>; <li>Fixed <code>browserify</code> support (by Artur Paikin).</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/ai/nanoid/commit/23b136929a6d58f32e31b269534a3ce3f680a086""><code>23b1369</code></a> Release 3.2 version</li>; <li><a href=""https://github.com/ai/nanoid/commit/967788efce880960512f969a56f8f22f3fc20bae""><code>967788e</code></a> Remove TS test tools</li>; <li><a href=""https://github.com/ai/nanoid/commit/27eaa90cd207a7782bbcf17343092ae87dd62164""><code>27eaa90</code></a> Simplify new binary tool</li>; <li><a href=""https://github.com/ai/nanoid/commit/a9d91239931dc77506381874826d297aee71d6ef""><code>a9d9123</code></a> Update dependencies</li>; <li",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11284:1054,depend,dependencies,1054,https://hail.is,https://github.com/hail-is/hail/pull/11284,2,['depend'],['dependencies']
Integrability," 3.7 due to standard library limitations. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2874"">#2874</a>)</li>; </ul>; <h3>Performance</h3>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/psf/black/blob/main/CHANGES.md"">black's changelog</a>.</em></p>; <blockquote>; <h2>22.8.0</h2>; <h3>Highlights</h3>; <ul>; <li>Python 3.11 is now supported, except for <em>blackd</em> as aiohttp does not support 3.11 as; of publishing (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3234"">#3234</a>)</li>; <li>This is the last release that supports running <em>Black</em> on Python 3.6 (formatting 3.6; code will continue to be supported until further notice)</li>; <li>Reword the stability policy to say that we may, in rare cases, make changes that; affect code that was not previously formatted by <em>Black</em> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3155"">#3155</a>)</li>; </ul>; <h3>Stable style</h3>; <ul>; <li>Fix an infinite loop when using <code># fmt: on/off</code> in the middle of an expression or code; block (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3158"">#3158</a>)</li>; <li>Fix incorrect handling of <code># fmt: skip</code> on colon (<code>:</code>) lines (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3148"">#3148</a>)</li>; <li>Comments are no longer deleted when a line had spaces removed around power operators; (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2874"">#2874</a>)</li>; </ul>; <h3>Preview style</h3>; <ul>; <li>Single-character closing docstring quotes are no longer moved to their own line as; this is invalid. This was a bug introduced in version 22.6.0. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3166"">#3166</a>)</li>; <li><code>--skip-string-normalization</code> / <code>-S</code> now prevents docstring ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12174:5828,depend,dependabot,5828,https://hail.is,https://github.com/hail-is/hail/pull/12174,1,['depend'],['dependabot']
Integrability," 5.0.1.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-chardet&package-manager=pip&previous-version=4.0.4&new-version=5.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12001:907,Depend,Dependabot,907,https://hail.is,https://github.com/hail-is/hail/pull/12001,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability," :doc:<code>aiohttp &lt;index&gt;</code> v3.8.3; fixes that by recovering the original boundary of <code>&lt; 7</code>.; (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/6950"">#6950</a>)</p>; </li>; </ul>; <hr />; <h1>3.8.2 (2022-09-20, subsequently yanked on 2022-09-21)</h1>; <p>.. note::</p>; <p>This release has some compatibility fixes for Python 3.11 but it may; still have some quirks. Some tests are still flaky in the CI.</p>; <p>.. caution::</p>; <p>This release has been yanked from PyPI. Modern pip will not pick it; up automatically. The reason is that is has <code>multidict &lt; 6</code> set in; the distribution package metadata (see :pr:<code>6950</code>). Please, use; <code>aiohttp ~= 3.8.3, != 3.8.1</code> instead, if you can.</p>; <h2>Bugfixes</h2>; <ul>; <li>Added support for registering :rfc:<code>OPTIONS &lt;9110#OPTIONS&gt;</code>; HTTP method handlers via :py:class:<code>~aiohttp.web.RouteTableDef</code>.; (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/4663"">#4663</a>)</li>; <li>Started supporting :rfc:<code>authority-form &lt;9112#authority-form&gt;</code> and; :rfc:<code>absolute-form &lt;9112#absolute-form&gt;</code> URLs on the server-side.; (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/6227"">#6227</a>)</li>; <li>Fixed Python 3.11 incompatibilities by using Cython 0.29.25.; (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/6396"">#6396</a>)</li>; <li>Extended the <code>sock</code> argument typing declaration of the</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/blob/master/CHANGES.rst"">aiohttp's changelog</a>.</em></p>; <blockquote>; <h1>3.8.3 (2022-09-21)</h1>; <p>.. attention::</p>; <p>This is the last :doc:<code>aiohttp &lt;index&gt;</code> release tested under; Python 3.6. The 3.9 stream is droppin",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12296:1861,depend,dependabot,1861,https://hail.is,https://github.com/hail-is/hail/pull/12296,1,['depend'],['dependabot']
Integrability," :pr:<code>2493</code></li>; <li>Parsing of some invalid header characters is more robust. :pr:<code>2494</code></li>; <li>When starting the development server, a warning not to use it in a; production deployment is always shown. :issue:<code>2480</code></li>; <li><code>LocalProxy.__wrapped__</code> is always set to the wrapped object when; the proxy is unbound, fixing an issue in doctest that would cause it; to fail. :issue:<code>2485</code></li>; <li>Address one <code>ResourceWarning</code> related to the socket used by; <code>run_simple</code>. :issue:<code>2421</code></li>; </ul>; <h2>Version 2.2.1</h2>; <p>Released 2022-07-27</p>; <ul>; <li>Fix router so that <code>/path/</code> will match a rule <code>/path</code> if strict; slashes mode is disabled for the rule. :issue:<code>2467</code></li>; <li>Fix router so that partial part matches are not allowed; i.e. <code>/2df</code> does not match <code>/&lt;int&gt;</code>. :pr:<code>2470</code></li>; <li>Fix router static part weighting, so that simpler routes are matched; before more complex ones. :issue:<code>2471</code></li>; <li>Restore <code>ValidationError</code> to be importable from; <code>werkzeug.routing</code>. :issue:<code>2465</code></li>; </ul>; <h2>Version 2.2.0</h2>; <p>Released 2022-07-23</p>; <ul>; <li>Deprecated <code>get_script_name</code>, <code>get_query_string</code>,; <code>peek_path_info</code>, <code>pop_path_info</code>, and; <code>extract_path_info</code>. :pr:<code>2461</code></li>; <li>Remove previously deprecated code. :pr:<code>2461</code></li>; <li>Add MarkupSafe as a dependency and use it to escape values when; rendering HTML. :issue:<code>2419</code></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/werkzeug/commit/15fcb87d36f4ed45b127692d2d739266b918503c""><code>15fcb87</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/wer",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12119:3692,rout,router,3692,https://hail.is,https://github.com/hail-is/hail/pull/12119,2,['rout'],"['router', 'routes']"
Integrability," ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxMjY5MWQyMS0wMzk1LTQxYjMtODBkMi1mMjEyODMwZjY2ZWEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjEyNjkxZDIxLTAzOTUtNDFiMy04MGQyLWYyMTI4MzBmNjZlYSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13873:3723,depend,dependency,3723,https://hail.is,https://github.com/hail-is/hail/pull/13873,2,['depend'],"['dependencies', 'dependency']"
Integrability," </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/5128f7f4ff73b165579006a8336978efaeeca07a""><code>5128f7f</code></a> Fix CHANGES</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/18e718a56f9def7dc40bb9ce3a2962a8fb0c883c""><code>18e718a</code></a> Bump to 4.0.2</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/48d1c4ce923b1da75976d7e2a6ca9234b3092c16""><code>48d1c4c</code></a> Setup towncrier</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/2ede7d73e55f8d1a2279d78861af0009d96219fb""><code>2ede7d7</code></a> Fix annotations on <code>__exit__</code> and <code>__aexit__</code> (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/274"">#274</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/8685c60dc0e82ee246fbe3d1aa272d1dfe57c24c""><code>8685c60</code></a> Bump mypy from 0.910 to 0.920 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/273"">#273</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/f0a0914345b224448220aeb00d71e6a04a5d24bd""><code>f0a0914</code></a> Bump twine from 3.7.0 to 3.7.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/272"">#272</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/e5c813173b8811b30f4a30eeba56fa8808ab15bb""><code>e5c8131</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/271"">#271</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c7e10db3d0965422122bef263fb36f6fd7572330""><code>c7e10db</code></a> Fix linter configs</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/6af8bf421a799208b27d57c6bf69de0d998fedec""><code>6af8bf4</code></a> Bump pre-commit from 2.15 to 2.16.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/269"">#269</a>)<",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:4915,depend,dependabot,4915,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['depend'],['dependabot']
Integrability," </li>; <li>; <p>Fixed handling of Sphinx-style parameter docstrings with asterisks. These; should be escaped with by prepending a &quot;&quot;.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5406"">#5406</a></p>; </li>; <li>; <p>Add <code>endLine</code> and <code>endColumn</code> keys to output of <code>JSONReporter</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5380"">#5380</a></p>; </li>; <li>; <p>Fixed handling of Google-style parameter specifications where descriptions; are on the line following the parameter name. These were generating; false positives for <code>missing-param-doc</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5452"">#5452</a></p>; </li>; <li>; <p>Fix false negative for <code>consider-iterating-dictionary</code> during membership checks encapsulated in iterables; or <code>not in</code> checks</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5323"">#5323</a></p>; </li>; <li>; <p><code>unused-import</code> now check all ancestors for typing guards</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5316"">#5316</a></p>; </li>; </ul>; <h1>What's New in Pylint 2.12.1?</h1>; <p>Release date: 2021-11-25</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/pylint/commit/eec287fae66f8fc514d5daa9caee46fd0e0cb6d9""><code>eec287f</code></a> Bump pylint to 2.12.2, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/7def5278afc86224a98cc9d1706fbd9523ddda1b""><code>7def527</code></a> Add Copyrite configuration for Yu Shao</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/608ed329aaee9e457ac51347699d4892d29df802""><code>608ed32</code></a> Require <code>\</code> for asterisks in Sphinx-style parameter docstrings (<a href=""https://github-redir",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11461:5231,depend,dependabot,5231,https://hail.is,https://github.com/hail-is/hail/pull/11461,2,['depend'],['dependabot']
Integrability," </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/janus/commit/0783f9b7a9bb7e1c095e93ebb4aad4f1e219f512""><code>0783f9b</code></a> Fix coverage upload</li>; <li><a href=""https://github.com/aio-libs/janus/commit/41c49bafb1b192d2ee25b7394cead2386e452dc2""><code>41c49ba</code></a> Make deployment only if checks are green</li>; <li><a href=""https://github.com/aio-libs/janus/commit/ec94b35b2ae095dcb97827f1369c0cd31b7e8e5e""><code>ec94b35</code></a> Fix CI again</li>; <li><a href=""https://github.com/aio-libs/janus/commit/2303208c2f972e38445e7ecec54fda0f3203f566""><code>2303208</code></a> Fix CI</li>; <li><a href=""https://github.com/aio-libs/janus/commit/dff507895bf8d77efea2c4cc1d8b04a8a2986a0b""><code>dff5078</code></a> Bump to 1.0.0</li>; <li><a href=""https://github.com/aio-libs/janus/commit/3421545f3954b7ef6d90e02b7653a7ab685f3e78""><code>3421545</code></a> Bump mypy from 0.910 to 0.920 (<a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/384"">#384</a>)</li>; <li><a href=""https://github.com/aio-libs/janus/commit/56b2d1d8dbd10cce28302a4e1c4224ce219c6246""><code>56b2d1d</code></a> Bump black from 21.11b1 to 21.12b0 (<a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/383"">#383</a>)</li>; <li><a href=""https://github.com/aio-libs/janus/commit/883e82bea0af1d12a68e92148b75b3344b31227a""><code>883e82b</code></a> Update README.rst</li>; <li><a href=""https://github.com/aio-libs/janus/commit/2e30d8a0f3c77c383a39da9b5c233a5c93a049fb""><code>2e30d8a</code></a> Bump coverage from 6.1.2 to 6.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/382"">#382</a>)</li>; <li>See full diff in <a href=""https://github.com/aio-libs/janus/compare/v0.7.0...v1.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=janus&package-manager=pip&previous-version=0.7.0&new-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12436:1652,depend,dependabot,1652,https://hail.is,https://github.com/hail-is/hail/pull/12436,1,['depend'],['dependabot']
Integrability," </ul>; <p>#Other</p>; <ul>; <li>Fix versioning issues in 3.20.0</li>; </ul>; <h2>Protocol Buffers v3.20.0</h2>; <p>2022-03-25 version 3.20.0 (C++/Java/Python/PHP/Objective-C/C#/Ruby/JavaScript)</p>; <h1>Ruby</h1>; <ul>; <li>Dropped Ruby 2.3 and 2.4 support for CI and releases. (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9311"">#9311</a>)</li>; <li>Added Ruby 3.1 support for CI and releases (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9566"">#9566</a>).</li>; <li>Message.decode/encode: Add recursion_limit option (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9218"">#9218</a>/<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9486"">#9486</a>)</li>; <li>Allocate with xrealloc()/xfree() so message allocation is visible to the; Ruby GC. In certain tests this leads to much lower memory usage due to more; frequent GC runs (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9586"">#9586</a>).</li>; <li>Fix conversion of singleton classes in Ruby (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9342"">#9342</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/protocolbuffers/protobuf/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.19.6&new-version=4.21.12)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12563:3491,depend,dependabot,3491,https://hail.is,https://github.com/hail-is/hail/pull/12563,1,['depend'],['dependabot']
Integrability," <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2820"">cbeust/testng#2820</a></li>; <li>Refactoring by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2821"">cbeust/testng#2821</a></li>; <li>Fixing bug with DataProvider retry by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2822"">cbeust/testng#2822</a></li>; <li>Add config key for callback discrepancy behavior by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2823"">cbeust/testng#2823</a></li>; <li>Upgrading versions by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2824"">cbeust/testng#2824</a></li>; <li>Fix <a href=""https://github-redirect.dependabot.com/cbeust/testng/issues/2770"">#2770</a>: FileAlreadyExistsException on copy by <a href=""https://github.com/melloware""><code>@​melloware</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2827"">cbeust/testng#2827</a></li>; <li>JarFileUtils.delete(File f) throw actual exception (instead of FileNotFound) when file cannot be deleted <a href=""https://github-redirect.dependabot.com/cbeust/testng/issues/2825"">#2825</a> by <a href=""https://github.com/speedythesnail""><code>@​speedythesnail</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2826"">cbeust/testng#2826</a></li>; <li>GITHUB-2830 - Failsafe parameter.toString by <a href=""https://github.com/seregamorph""><code>@​seregamorph</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2831"">cbeust/testng#2831</a></li>; <li>Changing assertion message of the osgitest by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""ht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:4411,depend,dependabot,4411,https://hail.is,https://github.com/hail-is/hail/pull/12665,1,['depend'],['dependabot']
Integrability," <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/992"">#992</a>, pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/994"">#994</a>).</li>; <li>Fixed methods in the <code>rrule</code> module not being displayed in the docs. (gh pr; <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1025"">#1025</a>)</li>; <li>Changed some relative links in the exercise documentation to refer to the; document locations in the input tree, rather than the generated HTML files in; the HTML output tree (which presumably will not exist in non-HTML output; formats). (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1078"">#1078</a>).</li>; </ul>; <h2>Misc</h2>; <ul>; <li>Moved <code>test_imports.py</code>, <code>test_internals.py</code> and <code>test_utils.py</code> to; pytest. Reported and fixed by <a href=""https://github.com/jpurviance""><code>@​jpurviance</code></a> (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/978"">#978</a>)</li>; <li>Added project_urls for documentation and source. Patch by <a href=""https://github.com/andriyor""><code>@​andriyor</code></a> (gh pr; <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/975"">#975</a>).</li>; <li>Simplified handling of bytes and bytearray in <code>_parser._timelex</code>. Reported; and fixed by <a href=""https://github.com/frenzymadness""><code>@​frenzymadness</code></a> (gh issue <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1060"">#1060</a>).</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/dateutil/dateutil/commit/6b035517571e63b6a63a493740c5506ec1e5da44""><code>6b03551</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1143"">#1143</a> from mariocj89/pu/2.8.2</li>; <li><a href=""https://github.com/dat",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11518:8264,depend,dependabot,8264,https://hail.is,https://github.com/hail-is/hail/pull/11518,1,['depend'],['dependabot']
Integrability," <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/992"">#992</a>, pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/994"">#994</a>).</li>; <li>Fixed methods in the <code>rrule</code> module not being displayed in the docs. (gh pr; <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1025"">#1025</a>)</li>; <li>Changed some relative links in the exercise documentation to refer to the; document locations in the input tree, rather than the generated HTML files in; the HTML output tree (which presumably will not exist in non-HTML output; formats). (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1078"">#1078</a>).</li>; </ul>; <h2>Misc</h2>; <ul>; <li>Moved <code>test_imports.py</code>, <code>test_internals.py</code> and <code>test_utils.py</code> to; pytest. Reported and fixed by <a href=""https://github.com/jpurviance""><code>@​jpurviance</code></a> (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/978"">#978</a>)</li>; <li>Added project_urls for documentation and source. Patch by <a href=""https://github.com/andriyor""><code>@​andriyor</code></a> (gh pr; <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/975"">#975</a>).</li>; <li>Simplified handling of bytes and bytearray in <code>_parser._timelex</code>. Reported</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/dateutil/dateutil/blob/master/NEWS"">python-dateutil's changelog</a>.</em></p>; <blockquote>; <h1>Version 2.8.2 (2021-07-08)</h1>; <h2>Data updates</h2>; <ul>; <li>Updated tzdata version to 2021a. (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1128"">#1128</a>)</li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>Fixed a bug in the parser where non-<code>ValueError</code> exceptions would be raised; during exception hand",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11518:3943,depend,dependabot,3943,https://hail.is,https://github.com/hail-is/hail/pull/11518,1,['depend'],['dependabot']
Integrability," <a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10544"">#10544</a> from deannagarcia/3.20.x</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/ae718b39020ae6e6f8f5568e357d6893fd0fd29c""><code>ae718b3</code></a> Add missing includes</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/b4c395aaedfacb32e2414d361fa85968c0991b34""><code>b4c395a</code></a> Apply patch</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/6439c5c01349e74d4deb57c844a7ad4b7b13a302""><code>6439c5c</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10531"">#10531</a> from protocolbuffers/deannagarcia-patch-7</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/22c79e6e4ca8be2bc2f700b2cdddca84d84659ce""><code>22c79e6</code></a> Update version.json</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/c1a2d2ec29314975e725021ffe4334926dbaa56c""><code>c1a2d2e</code></a> Fix python release on macos (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10512"">#10512</a>)</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/a826282e15efe3ae3a2aebb040fb1691b2233a1e""><code>a826282</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10505"">#10505</a> from deannagarcia/3.20.x</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/7639a710e10beb47bfc62f363680f7b04e8b3d26""><code>7639a71</code></a> Add version file</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.20.1...v3.20.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.1&new-version=3.20.2)](https://docs.github.com/en/github/managing-security-vuln",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12223:2051,protocol,protocolbuffers,2051,https://hail.is,https://github.com/hail-is/hail/pull/12223,3,['protocol'],['protocolbuffers']
Integrability," <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-storage-blob_12.8.1...azure-storage-blob_12.10.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=azure-storage-blob&package-manager=pip&previous-version=12.8.1&new-version=12.10.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11610:6492,Depend,Dependabot,6492,https://hail.is,https://github.com/hail-is/hail/pull/11610,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability," <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-storage-blob_12.8.1...azure-storage-blob_12.11.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=azure-storage-blob&package-manager=pip&previous-version=12.8.1&new-version=12.11.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11703:6970,Depend,Dependabot,6970,https://hail.is,https://github.com/hail-is/hail/pull/11703,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability," <a href=""https://github.com/benluddy""><code>@​benluddy</code></a>)</li>; <li>CSIStorageCapacity.storage.k8s.io: The v1beta1 version of this API is deprecated in favor of v1, and will be removed in v1.27. If a CSI driver supports storage capacity tracking, then it must get deployed with a release of external-provisioner that supports the v1 API. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108445"">kubernetes/kubernetes#108445</a>, <a href=""https://github.com/pohly""><code>@​pohly</code></a>)</li>; <li>Custom resource requests with <code>fieldValidation=Strict</code> consistently require <code>apiVersion</code> and <code>kind</code>, matching non-strict requests (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/109019"">kubernetes/kubernetes#109019</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>)</li>; <li>Feature of <code>DefaultPodTopologySpread</code> is graduated to GA (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108278"">kubernetes/kubernetes#108278</a>, <a href=""https://github.com/kerthcet""><code>@​kerthcet</code></a>)</li>; <li>Feature of <code>NonPreemptingPriority</code> is graduated to GA (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107432"">kubernetes/kubernetes#107432</a>, <a href=""https://github.com/denkensk""><code>@​denkensk</code></a>)</li>; <li>Feature of <code>PodOverhead</code> is graduated to GA (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108441"">kubernetes/kubernetes#108441</a>, <a href=""https://github.com/pacoxu""><code>@​pacoxu</code></a>)</li>; <li>Fixed OpenAPI serialization of the x-kubernetes-validations field (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107970"">kubernetes/kubernetes#107970</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>)</li>; <li>Fixed failed flushing logs in defer function when kubelet cmd exit 1. (<a href=""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:4917,depend,dependabot,4917,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['depend'],['dependabot']
Integrability," <a href=""https://github.com/gnikonorov""><code>@​gnikonorov</code></a></li>; <li>Assure scm versioning is pypa compatible (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/364"">#364</a>) <a href=""https://github.com/ssbarnea""><code>@​ssbarnea</code></a></li>; <li>Move release from travis to github actions (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/360"">#360</a>) <a href=""https://github.com/ssbarnea""><code>@​ssbarnea</code></a></li>; <li>Respect --show-capture=no flag (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/359"">#359</a>) <a href=""https://github.com/gnikonorov""><code>@​gnikonorov</code></a></li>; <li>Respect pytest --capture=no and -s flags (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/353"">#353</a>) <a href=""https://github.com/gnikonorov""><code>@​gnikonorov</code></a></li>; <li>Stop shadowing the 'format' builtin (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/347"">#347</a>) <a href=""https://github.com/gnikonorov""><code>@​gnikonorov</code></a></li>; <li>Post process html to include teardown in log (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/271"">#271</a>) <a href=""https://github.com/csm10495""><code>@​csm10495</code></a></li>; <li>Avoid pytest 6.0.0 (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/319"">#319</a>) <a href=""https://github.com/ssbarnea""><code>@​ssbarnea</code></a></li>; <li>Rename &quot;slave&quot; -&gt; &quot;worker&quot; for xdist compatibility (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/307"">#307</a>) <a href=""https://github.com/Zac-HD""><code>@​Zac-HD</code></a></li>; <li>Fix embedded images (and videos) (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/298"">#298</a>) <a href=""https://github.com/dhalperi""><code>@​dhalperi</code></a></li>; <li>Fix image missing w",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11524:3838,depend,dependabot,3838,https://hail.is,https://github.com/hail-is/hail/pull/11524,1,['depend'],['dependabot']
Integrability," <a href=""https://pandas.pydata.org/pandas-docs/version/1.4.4/whatsnew/v1.4.4.html"">full whatsnew</a> for a list of all the changes.</p>; <p>The release will be available on the defaults and conda-forge channels:</p>; <pre><code>conda install pandas; </code></pre>; <p>Or via PyPI:</p>; <pre><code>python3 -m pip install --upgrade pandas; </code></pre>; <p>Please report any issues with the release on the <a href=""https://github.com/pandas-dev/pandas/issues"">pandas issue tracker</a>.</p>; <p>Thanks to all the contributors who made this release possible.</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pandas-dev/pandas/commit/87cfe4e38bafe7300a6003a1d18bd80f3f77c763""><code>87cfe4e</code></a> RLS: 1.5.0</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/ecc700c8be8e4af2799dc18ce5f7e6328c80e976""><code>ecc700c</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48627"">#48627</a> on branch 1.5.x (DOC: Last changes to release notes for 1....</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/e726483d70938f3bff67e95358841a1f6271b149""><code>e726483</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48619"">#48619</a> on branch 1.5.x (REGR: Loc.setitem with enlargement raises...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/f83e2fe3327ad85ae2e8c4ba469fe98383243dbf""><code>f83e2fe</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48623"">#48623</a> on branch 1.5.x (REGR/DOC: Docs left navbar broke) (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48625"">#48625</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/4fbb05591979055708162994e96fb4c61cf2a8ab""><code>4fbb055</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12292:2838,depend,dependabot,2838,https://hail.is,https://github.com/hail-is/hail/pull/12292,1,['depend'],['dependabot']
Integrability," <a href=""https://www.npmjs.com/package/avro-js/v/1.11.0"">https://www.npmjs.com/package/avro-js/v/1.11.0</a></li>; <li>Perl: <a href=""https://metacpan.org/release/Avro"">https://metacpan.org/release/Avro</a></li>; <li>Python 3: <a href=""https://pypi.org/project/avro/1.11.0"">https://pypi.org/project/avro/1.11.0</a></li>; <li>Ruby: <a href=""https://rubygems.org/gems/avro/versions/1.11.0"">https://rubygems.org/gems/avro/versions/1.11.0</a></li>; </ul>; <p>Thanks to everyone for contributing!</p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/apache/avro/compare/release-1.10.0...release-1.11.0"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11475:3263,Depend,Dependabot,3263,https://hail.is,https://github.com/hail-is/hail/pull/11475,1,['Depend'],['Dependabot']
Integrability," <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14211:2421,Message,Message,2421,https://hail.is,https://github.com/hail-is/hail/pull/14211,1,['Message'],['Message']
Integrability," <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **/1000** <br/> **Why?** | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `40.5.0 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14365:2491,Message,Message,2491,https://hail.is,https://github.com/hail-is/hail/pull/14365,1,['Message'],['Message']
Integrability," <code>activeselection</code> layout attributes to have persistent and editable selections over cartesian subplots</li>; <li>Add <code>unselected.line.color</code> and <code>unselected.line.opacity</code> options to <code>parcoords</code> trace</li>; <li>Display Plotly's new logo in the modebar</li>; </ul>; </li>; </ul>; <h2>[5.9.0] - 2022-06-23</h2>; <h3>Added</h3>; <ul>; <li><code>pattern_shape</code> options now available in <code>px.timeline()</code> <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3774"">#3774</a></li>; <li><code>facet_*</code> and <code>category_orders</code> now available in <code>px.pie()</code> <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3775"">#3775</a></li>; </ul>; <h3>Performance</h3>; <ul>; <li><code>px</code> methods no longer call <code>groupby</code> on the input dataframe when the result would be a single group, and no longer groups by a lambda, for significant speedups <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3765"">#3765</a> with thanks to <a href=""https://github.com/jvdd""><code>@​jvdd</code></a></li>; </ul>; <h3>Updated</h3>; <ul>; <li>Allow non-string extras in <code>flaglist</code> attributes, to support upcoming changes to <code>ax.automargin</code> in plotly.js <a href=""https://github-redirect.dependabot.com/plotly/plotly.js/pull/6193"">plotly.js#6193</a>, <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3749"">#3749</a></li>; </ul>; <h2>[5.8.2] - 2022-06-10</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed a syntax error that caused rendering issues in Databricks notebooks and likely elsewhere. <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3763"">#3763</a> with thanks to <a href=""https://github.com/fwetdb""><code>@​fwetdb</code></a></li>; </ul>; <h2>[5.8.1] - 2022-06-08</h2>; <p>(no changes, due to a mixup with the build process!)</p>; <h2>[5.8.0] - 2022-05-09</h2>; <h3>Fixed</h3>; <ul>; <li>Improve support for type checking ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12113:2627,depend,dependabot,2627,https://hail.is,https://github.com/hail-is/hail/pull/12113,1,['depend'],['dependabot']
Integrability," <code>browserify</code> support.</li>; </ul>; <h2>3.1.24</h2>; <ul>; <li>Fixed <code>browserify</code> support (by Artur Paikin).</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/ai/nanoid/commit/23b136929a6d58f32e31b269534a3ce3f680a086""><code>23b1369</code></a> Release 3.2 version</li>; <li><a href=""https://github.com/ai/nanoid/commit/967788efce880960512f969a56f8f22f3fc20bae""><code>967788e</code></a> Remove TS test tools</li>; <li><a href=""https://github.com/ai/nanoid/commit/27eaa90cd207a7782bbcf17343092ae87dd62164""><code>27eaa90</code></a> Simplify new binary tool</li>; <li><a href=""https://github.com/ai/nanoid/commit/a9d91239931dc77506381874826d297aee71d6ef""><code>a9d9123</code></a> Update dependencies</li>; <li><a href=""https://github.com/ai/nanoid/commit/32b9bdaab1fbc28576b17de8516164ce0360f292""><code>32b9bda</code></a> Allows passing size or custom alphabet via cli as args (<a href=""https://github-redirect.dependabot.com/ai/nanoid/issues/334"">#334</a>)</li>; <li><a href=""https://github.com/ai/nanoid/commit/246d5f87b6b34e23b5e401bdf3da1f80c810ac4c""><code>246d5f8</code></a> Update vite</li>; <li><a href=""https://github.com/ai/nanoid/commit/afdf9c92b41427f35476fbe14b5af5d73dd7fbdb""><code>afdf9c9</code></a> doc: Fixed Typo (<a href=""https://github-redirect.dependabot.com/ai/nanoid/issues/335"">#335</a>)</li>; <li><a href=""https://github.com/ai/nanoid/commit/90a446fef3ecaac78e5af2ea01025c4f40182e2b""><code>90a446f</code></a> Update benchmark results</li>; <li><a href=""https://github.com/ai/nanoid/commit/8ba2319b579895cc1f9060b9946a44852f97c509""><code>8ba2319</code></a> bench: add <code>@​napi-rs/uuid</code> v4 (<a href=""https://github-redirect.dependabot.com/ai/nanoid/issues/333"">#333</a>)</li>; <li><a href=""https://github.com/ai/nanoid/commit/f4257780ece488734a65c176e80c2fd8ab6aab8e""><code>f425778</code></a> Release 3.1.32 version</li>; <li>Additional commits viewable in <a href=""https://github.com/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11284:2261,depend,dependabot,2261,https://hail.is,https://github.com/hail-is/hail/pull/11284,2,['depend'],['dependabot']
Integrability," <code>{#key}</code> block not being reactive when the key variable is not otherwise used (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7408"">#7408</a>)</li>; <li>Add <code>Symbol</code> as a known global (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7418"">#7418</a>)</li>; </ul>; <h2>3.46.6</h2>; <ul>; <li>Actually include action TypeScript interface in published package (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/pull/7407"">#7407</a>)</li>; </ul>; <h2>3.46.5</h2>; <ul>; <li>Add TypeScript interfaces for typing actions (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/6538"">#6538</a>)</li>; <li>Do not generate <code>unused-export-let</code> warning inside <code>&lt;script context=&quot;module&quot;&gt;</code> blocks (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7055"">#7055</a>)</li>; <li>Do not collapse whitespace-only CSS vars (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7152"">#7152</a>)</li>; <li>Add <code>aria-description</code> to the list of allowed ARIA attributes (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7301"">#7301</a>)</li>; <li>Fix attribute escaping during SSR (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7327"">#7327</a>)</li>; <li>Prevent <code>.innerHTML</code> optimization from being used when <code>style:</code> directive is present (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7386"">#7386</a>)</li>; </ul>; <h2>3.46.4</h2>; <ul>; <li>Avoid <code>maximum call stack size exceeded</code> errors on large components (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/4694"">#4694</a>)</li>; <li>Preserve leading space with <code>preserveWhitespace: true</code> (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/4731"">#4731</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (trun",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12032:5225,depend,dependabot,5225,https://hail.is,https://github.com/hail-is/hail/pull/12032,3,['depend'],['dependabot']
Integrability," <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pandas-dev/pandas/commit/8dab54d6573f7186ff0c3b6364d5e4dd635ff3e7""><code>8dab54d</code></a> RLS: 1.5.2</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/d78c5e624936ea5bc30568fd7d6fc9b5f42d0beb""><code>d78c5e6</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/49806"">#49806</a> on branch 1.5.x (DOC: Update what's new notes for 1.5.2 re...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/98c6139ff12107b9aa34441d25ef1593b6a0adca""><code>98c6139</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/49579"">#49579</a> on Branch 1.5.x (BUG: Behaviour change in 1.5.0 when using...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/9196f8d545d1118f1233c1b45e7b740cb95c370c""><code>9196f8d</code></a> Backport PR STYLE enable pylint: method-cache-max-size-none (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/49784"">#49784</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/8c4b559c87561ca68ccdc3e81ff3c5218c7b4db7""><code>8c4b559</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/49776"">#49776</a> on branch 1.5.x (REGR: arithmetic ops recursion error with...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/1616fb3d2c00905a5f3af510db893206ae00ea09""><code>1616fb3</code></a> Backport PR Revert &quot;Add color and size to arguments (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/44856"">#44856</a>)&quot; (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/49752"">#49752</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/6f8e1745472c9d107367da1e38494425c3938234""><code>6f8e174</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/49720"">#49720</a> on branch 1.5.x (Suppress spurious warni",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12564:3544,depend,dependabot,3544,https://hail.is,https://github.com/hail-is/hail/pull/12564,1,['depend'],['dependabot']
Integrability," <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/plotly/plotly.py/commit/473c263e5e133e5693863baa668751b85900dc11""><code>473c263</code></a> bump plotly.js to 2.14.0</li>; <li><a href=""https://github.com/plotly/plotly.py/commit/f9bd7da02fadbe0e0d2284bee169578bd93dd616""><code>f9bd7da</code></a> Merge branch 'master' into release-5.10.0</li>; <li><a href=""https://github.com/plotly/plotly.py/commit/843b68506a5931d1a0a73617e86281fc643df046""><code>843b685</code></a> version changes for v5.10.0</li>; <li><a href=""https://github.com/plotly/plotly.py/commit/a5f44e34310f23ab35e1c54bc60663fcca9fbe2d""><code>a5f44e3</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/issues/3822"">#3822</a> from plotly/dependabot/npm_and_yarn/packages/javascr...</li>; <li><a href=""https://github.com/plotly/plotly.py/commit/40729acbbeb02fc4031c1299e7ea1715fe2cb8a2""><code>40729ac</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/issues/3819"">#3819</a> from plotly/dependabot/npm_and_yarn/packages/javascr...</li>; <li><a href=""https://github.com/plotly/plotly.py/commit/2d00be3644fdbb01e3c17ac3326b5733991454dd""><code>2d00be3</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/issues/3794"">#3794</a> from plotly/dependabot/npm_and_yarn/packages/javascr...</li>; <li><a href=""https://github.com/plotly/plotly.py/commit/4823ed33db0d7769079c6fd53ae3b2d839321676""><code>4823ed3</code></a> Bump shell-quote in /packages/javascript/jupyterlab-plotly</li>; <li><a href=""https://github.com/plotly/plotly.py/commit/90e540a6906567e825ad4e7840d218a3f0894ce5""><code>90e540a</code></a> Bump terser in /packages/javascript/jupyterlab-plotly</li>; <li><a href=""https://github.com/plotly/plotly.py/commit/7416be0f27a6530899de6ca518e95a67279c0eef""><code>7416be0</code></a> Bump moment in /packages/javascript/jupyterlab-plotly</li>; <li><a href=""https://github.com/plotly/plot",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12113:6420,depend,dependabot,6420,https://hail.is,https://github.com/hail-is/hail/pull/12113,1,['depend'],['dependabot']
Integrability," <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/protocolbuffers/protobuf/releases"">protobuf's releases</a>.</em></p>; <blockquote>; <h2>Protocol Buffers v3.20.2</h2>; <h1>C++</h1>; <ul>; <li>Reduce memory consumption of MessageSet parsing</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf"">Security Advisory for C++ and Python users</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/a20c65f2cd549445fda907f7b83894c8eb7427d6""><code>a20c65f</code></a> Updating changelog</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/c49fe79af9c295960477b7568f1765b202093143""><code>c49fe79</code></a> Updating version.json and repo version numbers to: 20.2</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/806d7e4ce6f1fd0545cae226b94cb0249ea495c7""><code>806d7e4</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10544"">#10544</a> from deannagarcia/3.20.x</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/ae718b39020ae6e6f8f5568e357d6893fd0fd29c""><code>ae718b3</code></a> Add missing includes</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/b4c395aaedfacb32e2414d361fa85968c0991b34""><code>b4c395a</code></a> Apply patch</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/6439c5c01349e74d4deb57c844a7ad4b7b13a302""><code>6439c5c</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10531"">#10531</a> from protocolbuffers/deannagarcia-patch-7</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/22c79e6e4ca8be2bc2f700b2cdddca84d84659ce""><code>22c79e6</code></a> Update version.json</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/c1a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12223:1012,protocol,protocolbuffers,1012,https://hail.is,https://github.com/hail-is/hail/pull/12223,3,['protocol'],['protocolbuffers']
Integrability," <h2>Dependencies</h2>; <p>5.0.0 b1</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10164"">#10164</a>: Support <code>Docutils 0.18</code>_. Patch by Adam Turner.</li>; </ul>; <p>.. _Docutils 0.18: <a href=""https://docutils.sourceforge.io/RELEASE-NOTES.html#release-0-18-2021-10-26"">https://docutils.sourceforge.io/RELEASE-NOTES.html#release-0-18-2021-10-26</a></p>; <h2>Incompatible changes</h2>; <p>5.0.0 b1</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10031"">#10031</a>: autosummary: <code>sphinx.ext.autosummary.import_by_name()</code> now raises; <code>ImportExceptionGroup</code> instead of <code>ImportError</code> when it failed to import; target object. Please handle the exception if your extension uses the; function to import Python object. As a workaround, you can disable the; behavior via <code>grouped_exception=False</code> keyword argument until v7.0.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9962"">#9962</a>: texinfo: Customizing styles of emphasized text via <code>@definfoenclose</code>; command was not supported because the command was deprecated since texinfo 6.8</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/2068"">#2068</a>: :confval:<code>intersphinx_disabled_reftypes</code> has changed default value; from an empty list to <code>['std:doc']</code> as avoid too surprising silent; intersphinx resolutions.; To migrate: either add an explicit inventory name to the references; intersphinx should resolve, or explicitly set the value of this configuration; variable to an empty list.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10197"">#10197</a>: html theme: Reduce <code>body_min_width</code> setting in basic theme to 360px</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9999"">#9999</a>: LaTeX: separate terms from their definitions by a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11871:1989,depend,dependabot,1989,https://hail.is,https://github.com/hail-is/hail/pull/11871,2,['depend'],['dependabot']
Integrability," <h3>API Change</h3>; <ul>; <li>Add 2 new options for kube-proxy running in winkernel mode. <code>--forward-healthcheck-vip</code>, if specified as true, health check traffic whose destination is service VIP will be forwarded to kube-proxy's healthcheck service. <code>--root-hnsendpoint-name</code> specifies the name of the hns endpoint for the root network namespace. This option enables the pass-through load balancers like Google's GCLB to correctly health check the backend services. Without this change, the health check packets is dropped, and Windows node will be considered to be unhealthy by those load balancers. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/99287"">kubernetes/kubernetes#99287</a>, <a href=""https://github.com/anfernee""><code>@​anfernee</code></a>)</li>; <li>Added CEL runtime cost calculation into CustomerResource validation. CustomerResource validation will fail if runtime cost exceeds the budget. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108482"">kubernetes/kubernetes#108482</a>, <a href=""https://github.com/cici37""><code>@​cici37</code></a>)</li>; <li>Added a new metric <code>webhook_fail_open_count</code> to monitor webhooks that fail to open. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107171"">kubernetes/kubernetes#107171</a>, <a href=""https://github.com/ltagliamonte-dd""><code>@​ltagliamonte-dd</code></a>)</li>; <li>Adds a new Status subresource in Network Policy objects (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107963"">kubernetes/kubernetes#107963</a>, <a href=""https://github.com/rikatz""><code>@​rikatz</code></a>)</li>; <li>Adds support for <code>InterfaceNamePrefix</code> and <code>BridgeInterface</code> as arguments to <code>--detect-local-mode</code> option and also introduces a new optional <code>--pod-interface-name-prefix</code> and <code>--pod-bridge-interface</code> flags to kube-proxy. (<a href=""https://gith",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:1859,depend,dependabot,1859,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['depend'],['dependabot']
Integrability," <li>; <p>increases the weight of user specifiable priorities.; The weights of following priority plugins are increased</p>; <ul>; <li><code>TaintTolerations</code> to 3 - as leveraging node tainting to group nodes in the cluster is becoming a widely-adopted practice</li>; <li><code>NodeAffinity</code> to 2</li>; <li><code>InterPodAffinity</code> to 2</li>; </ul>; </li>; <li>; <p>Won't have <code>HealthzBindAddress</code>, <code>MetricsBindAddress</code> fields (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104251"">kubernetes/kubernetes#104251</a>, <a href=""https://github.com/ravisantoshgudimetla""><code>@​ravisantoshgudimetla</code></a>)</p>; </li>; </ul>; </li>; <li>Introduce v1beta2 for Priority and Fairness with no changes in API spec. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104399"">kubernetes/kubernetes#104399</a>, <a href=""https://github.com/tkashem""><code>@​tkashem</code></a>)</li>; <li>JSON log output is configurable and now supports writing info messages to stdout and error messages to stderr. Info messages can be buffered in memory. The default is to write both to stdout without buffering, as before. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104873"">kubernetes/kubernetes#104873</a>, <a href=""https://github.com/pohly""><code>@​pohly</code></a>)</li>; <li>JobTrackingWithFinalizers graduates to beta. Feature is enabled by default. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105687"">kubernetes/kubernetes#105687</a>, <a href=""https://github.com/alculquicondor""><code>@​alculquicondor</code></a>)</li>; <li>Kube-apiserver: Fixes handling of CRD schemas containing literal null values in enums. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104969"">kubernetes/kubernetes#104969</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>)</li>; <li>Kube-apiserver: The <code>rbac.authorization.k8s.io/v1alp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:6944,message,messages,6944,https://hail.is,https://github.com/hail-is/hail/pull/11957,2,['message'],['messages']
Integrability," <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/5046"">#5046</a> Webgl problem in stream app with multiple glyphs</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/6669"">#6669</a> [component: bokehjs] BoxAnnotation does not appear to handle formal NumberSpec</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/8168"">#8168</a> [component: bokehjs] Strange behavior with BoxSelectTool when click+dragging on toolbar</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/8332"">#8332</a> [component: bokehjs] Autohide toolbar quirks</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/8346"">#8346</a> [component: bokehjs] update datasource cause error with webgl backend</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/8469"">#8469</a> Modifying a child element in a tab causes the whole tab to rerender</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/8531"">#8531</a> [component: bokehjs] Save tool in gridplot initiates multiple downloads</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/8684"">#8684</a> Allow at least partial alignment of fixed sized frames</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/9113"">#9113</a> [component: bokehjs] Empty group widgets don't size properly once populated</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/9133"">#9133</a> [BUG] Tabs ignore explicitly set dimensions</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/9208"">#9208</a> [component: bokehjs] [BUG] sizing_mode='stretch_width' makes plot too wide if scrollbar is showing</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/9320"">#9320</a> [BUG] Bokeh rendering performance</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/9448"">#9448</a> [component: bokehj",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12454:2529,depend,dependabot,2529,https://hail.is,https://github.com/hail-is/hail/pull/12454,1,['depend'],['dependabot']
Integrability," <li><a href=""https://github.com/PyCQA/mccabe/commit/4ba21d2e8db92534914a89f44b5dfd0fb2e29e9c""><code>4ba21d2</code></a> Travis CI: allow_failures in Python end of life branches</li>; <li><a href=""https://github.com/PyCQA/mccabe/commit/80794d37d7d3e35cf243877a396e53f70243e154""><code>80794d3</code></a> Apply suggestions from code review</li>; <li><a href=""https://github.com/PyCQA/mccabe/commit/e864119dca577a38552b0d32c66d0ef3dc7779e0""><code>e864119</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pycqa/mccabe/issues/86"">#86</a> from cclauss/patch-1</li>; <li>Additional commits viewable in <a href=""https://github.com/pycqa/mccabe/compare/0.6.1...0.7.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mccabe&package-manager=pip&previous-version=0.6.1&new-version=0.7.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12449:2466,depend,dependabot-security-updates,2466,https://hail.is,https://github.com/hail-is/hail/pull/12449,1,['depend'],['dependabot-security-updates']
Integrability," <li><a href=""https://github.com/PyCQA/pylint/commit/28a33ef874cd63b92a32208e844b97f0c6a2f082""><code>28a33ef</code></a> Update outdated class name in &quot;How to Write a Checker&quot; test example (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5449"">#5449</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/bce059acf1684e35c9a731e27cff2de16bf54de8""><code>bce059a</code></a> Move Sphinx docstrings out of <code>TestParamDocChecker</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5450"">#5450</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/e14596ef44db6efd55c783fc5bffd61d020edc23""><code>e14596e</code></a> Move <code>no-member</code> tests from <code>TestTypeChecker</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5453"">#5453</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/4b70feb297b4aada56b838c1e71f40badccf9472""><code>4b70feb</code></a> <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5452"">#5452</a>: Fix false positive missing-doc-param from multi-line Google-st… (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5459"">#5459</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/35813de38ed58855f1b89fb492dc141d24bf2661""><code>35813de</code></a> Move various tests from <code>TestTypeChecker</code> to functional tests (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5455"">#5455</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/pylint-2.6.0...v2.12.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pylint&package-manager=pip&previous-version=2.6.0&new-version=2.12.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflict",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11461:7813,depend,dependabot,7813,https://hail.is,https://github.com/hail-is/hail/pull/11461,2,['depend'],['dependabot']
Integrability," <li><a href=""https://github.com/apache/spark/commit/7c465bc3154cdd0d578f837c9b82e4289caf0b14""><code>7c465bc</code></a> Preparing Spark release v3.3.1-rc3</li>; <li><a href=""https://github.com/apache/spark/commit/5fe895a65a4a9d65f81d43af473b5e3a855ed8c8""><code>5fe895a</code></a> [SPARK-40660][SQL][3.3] Switch to XORShiftRandom to distribute elements</li>; <li><a href=""https://github.com/apache/spark/commit/5dc9ba0d22741173bd122afb387c54d7ca4bfb6d""><code>5dc9ba0</code></a> [SPARK-40669][SQL][TESTS] Parameterize <code>rowsNum</code> in <code>InMemoryColumnarBenchmark</code></li>; <li>Additional commits viewable in <a href=""https://github.com/apache/spark/compare/v3.1.3...v3.3.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyspark&package-manager=pip&previous-version=3.1.3&new-version=3.3.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12455:2468,depend,dependabot-security-updates,2468,https://hail.is,https://github.com/hail-is/hail/pull/12455,1,['depend'],['dependabot-security-updates']
Integrability," <li><a href=""https://github.com/chalk/ansi-regex/commit/4657833b3419f381c8ef4eb5787e71c5206b1b35""><code>4657833</code></a> fix incorrect format</li>; <li><a href=""https://github.com/chalk/ansi-regex/commit/c3c0b3f2736b9c01feec0fef33980c43720dcde8""><code>c3c0b3f</code></a> Fix potential ReDoS (<a href=""https://github-redirect.dependabot.com/chalk/ansi-regex/issues/37"">#37</a>)</li>; <li><a href=""https://github.com/chalk/ansi-regex/commit/178363b3a297b712a0054e702d8ddde3879913e5""><code>178363b</code></a> Move to GitHub Actions (<a href=""https://github-redirect.dependabot.com/chalk/ansi-regex/issues/35"">#35</a>)</li>; <li><a href=""https://github.com/chalk/ansi-regex/commit/0755e661553387cfebcb62378181e9f55b2567ff""><code>0755e66</code></a> Add <a href=""https://github.com/Qix""><code>@​Qix</code></a>- to funding.yml</li>; <li>See full diff in <a href=""https://github.com/chalk/ansi-regex/compare/v5.0.0...v5.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ansi-regex&package-manager=npm_and_yarn&previous-version=5.0.0&new-version=5.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot canc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11287:2453,Depend,Dependabot,2453,https://hail.is,https://github.com/hail-is/hail/pull/11287,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability," <li><a href=""https://github.com/googleapis/java-storage/commit/b8f43169a504080c55eadc3428d0d7966efdc3d4""><code>b8f4316</code></a> build(deps): update dependency org.apache.maven.plugins:maven-dependency-plug...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/e532a590fd351bb2020b571d21662fbee629038e""><code>e532a59</code></a> build(deps): update dependency org.apache.maven.plugins:maven-surefire-plugin...</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/java-storage/compare/v1.106.0...v2.17.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.cloud:google-cloud-storage&package-manager=gradle&previous-version=1.106.0&new-version=2.17.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12598:16540,Depend,Dependabot,16540,https://hail.is,https://github.com/hail-is/hail/pull/12598,1,['Depend'],['Dependabot']
Integrability," <li><a href=""https://github.com/googleapis/python-storage/commit/7f771077511d6b446686724f48514d5b903ec036""><code>7f77107</code></a> chore(deps): update dependency google-cloud-storage to v2 (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/690"">#690</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/7891dcc6c0bd90da192691025c910cf30c98407b""><code>7891dcc</code></a> chore(main): release 2.0.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/687"">#687</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/python-storage/compare/v1.25.0...v2.1.0"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11520:8835,Depend,Dependabot,8835,https://hail.is,https://github.com/hail-is/hail/pull/11520,1,['Depend'],['Dependabot']
Integrability," <li><a href=""https://github.com/jpadilla/pyjwt/commit/9249fc70b5aede04c3dcb86e4b6560ab7e032563""><code>9249fc7</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/689"">#689</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/jpadilla/pyjwt/compare/1.7.1...2.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyjwt&package-manager=pip&previous-version=1.7.1&new-version=2.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11457:14320,Depend,Dependabot,14320,https://hail.is,https://github.com/hail-is/hail/pull/11457,1,['Depend'],['Dependabot']
Integrability," <li><a href=""https://github.com/lepture/mistune/commit/799cd118cc5e664b72e98410ce1b68645f1a38c0""><code>799cd11</code></a> Version bump 2.0.2</li>; <li><a href=""https://github.com/lepture/mistune/commit/babb0cfa57a983ead615286a2b7c8f6885c46721""><code>babb0cf</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/lepture/mistune/issues/295"">#295</a> from dairiki/bug.escape_url</li>; <li><a href=""https://github.com/lepture/mistune/commit/fc2cd53d7698e432ab5b250ffac53458263a49e2""><code>fc2cd53</code></a> Make mistune.util.escape_url less aggressive</li>; <li><a href=""https://github.com/lepture/mistune/commit/3e8d35215120ac82176f300dd5e20c0bea5464ea""><code>3e8d352</code></a> Version bump 2.0.1</li>; <li>Additional commits viewable in <a href=""https://github.com/lepture/mistune/compare/v0.8.4...v2.0.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mistune&package-manager=pip&previous-version=0.8.4&new-version=2.0.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` wil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12064:4017,depend,dependency-name,4017,https://hail.is,https://github.com/hail-is/hail/pull/12064,1,['depend'],['dependency-name']
Integrability," <li><a href=""https://github.com/psf/requests/commit/31ebb8102c00f8cf8b396a6356743cca4362e07b""><code>31ebb81</code></a> Merge pull request <a href=""https://redirect.github.com/psf/requests/issues/6682"">#6682</a> from frenzymadness/pytest8</li>; <li>Additional commits viewable in <a href=""https://github.com/psf/requests/compare/v2.31.0...v2.32.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=requests&package-manager=pip&previous-version=2.31.0&new-version=2.32.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14555:10504,Depend,Dependabot,10504,https://hail.is,https://github.com/hail-is/hail/pull/14555,1,['Depend'],['Dependabot']
Integrability," <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/a022d1a430db886decf2221b712bc3bd881f5e86""><code>a022d1a</code></a> inspect.getsource can raise TypeError (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/210"">#210</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/compare/1.11.1...1.18.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx-autodoc-typehints&package-manager=pip&previous-version=1.11.1&new-version=1.18.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11773:5629,depend,dependabot-automerge-start,5629,https://hail.is,https://github.com/hail-is/hail/pull/11773,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability," <li>Add local-provisioner entry point to pyproject.toml Fixes <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/800"">#800</a> <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/801"">#801</a> (<a href=""https://github.com/utkonos""><code>@​utkonos</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_client/graphs/contributors?from=2022-06-06&amp;to=2022-06-07&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Autkonos+updated%3A2022-06-06..2022-06-07&amp;type=Issues""><code>@​utkonos</code></a></p>; <h2>v7.3.2</h2>; <h2>7.3.2</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v7.3.1...c81771416d9e09e0e92be799f3e8549d0db57e43"">Full Changelog</a>)</p>; <h3>Enhancements made</h3>; <ul>; <li>Correct <code>Any</code> type annotations. <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/791"">#791</a> (<a href=""https://github.com/joouha""><code>@​joouha</code></a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jupyter/jupyter_client/blob/main/CHANGELOG.md"">jupyter-client's changelog</a>.</em></p>; <blockquote>; <h2>7.3.4</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v7.3.3...ca4cb2d6a4b95a6925de85a47b323d2235032c74"">Full Changelog</a>)</p>; <h3>Bugs fixed</h3>; <ul>; <li>Revert latest changes to <code>ThreadedZMQSocketChannel</code> because they break Qtconsole <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/803"">#803</a> (<a href=""https://github.com/ccordoba12""><code>@​ccordoba12</code></a>)</li>; </ul>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Fix sphinx 5.0 support <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12110:3141,depend,dependabot,3141,https://hail.is,https://github.com/hail-is/hail/pull/12110,1,['depend'],['dependabot']
Integrability," <li>Build macOS arm64 wheels natively <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7852"">#7852</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Fixed typo <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7855"">#7855</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Open 16-bit grayscale PNGs as I;16 <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7849"">#7849</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Handle truncated chunks at the end of PNG images <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7709"">#7709</a> [<a href=""https://github.com/lajiyuan""><code>@​lajiyuan</code></a>]</li>; <li>Match mask size to pasted image size in GifImagePlugin <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7779"">#7779</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Changed SupportsGetMesh protocol to be public <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7841"">#7841</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Release GIL while calling <code>WebPAnimDecoderGetNext</code> <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7782"">#7782</a> [<a href=""https://github.com/evanmiller""><code>@​evanmiller</code></a>]</li>; <li>Fixed reading FLI/FLC images with a prefix chunk <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7804"">#7804</a> [<a href=""https://github.com/twolife""><code>@​twolife</code></a>]</li>; <li>Updated package name for Tidelift <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7810"">#7810</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Removed unused code <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7744"">#7744</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14439:8860,protocol,protocol,8860,https://hail.is,https://github.com/hail-is/hail/pull/14439,3,['protocol'],['protocol']
Integrability," <li>Change the Lite runtime to prefer merging from the wireformat into mutable; messages rather than building up a new immutable object before merging. This; way results in fewer allocations and copy operations.</li>; <li>Make message-type extensions merge from wire-format instead of building up; instances and merging afterwards. This has much better performance.</li>; <li>Fix TextFormat parser to build up recurring (but supposedly not repeated); sub-messages directly from text rather than building a new sub-message and; merging the fully formed message into the existing field.</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-h4h5-3hr4-j3g2"">Security Advisory for Java users</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/protocolbuffers/protobuf/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.2&new-version=4.21.9)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12518:1560,Depend,Dependabot,1560,https://hail.is,https://github.com/hail-is/hail/pull/12518,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability," <li>Fix error message for readable path check that was mixed up with the; executable check. :pr:<code>2236</code></li>; <li>Restore parameter order for <code>Path</code>, placing the <code>executable</code>; parameter at the end. It is recommended to use keyword arguments; instead of positional arguments. :issue:<code>2235</code></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/click/commit/030f53cf677ee1de534359c535d465eed0ec1d99""><code>030f53c</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2238"">#2238</a> from pallets/release-8.1.2</li>; <li><a href=""https://github.com/pallets/click/commit/2f1c35a43652e565802c230dbc47a9a358a0c6fd""><code>2f1c35a</code></a> release version 8.1.2</li>; <li><a href=""https://github.com/pallets/click/commit/77dd30f8c54ebbdfbf461cedcd3d1fc1d7673f95""><code>77dd30f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2237"">#2237</a> from pallets/param-order</li>; <li><a href=""https://github.com/pallets/click/commit/b36bf8f9b36ab7db8cf03cd8eff714dfc33f0c29""><code>b36bf8f</code></a> restore Path param order</li>; <li><a href=""https://github.com/pallets/click/commit/a66119abe973f55b4f5e28dbb0da6f3c32c21af7""><code>a66119a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2236"">#2236</a> from shadchin/patch-1</li>; <li><a href=""https://github.com/pallets/click/commit/92cebe902aa7f03a89f6b261d897964dd9c5fa43""><code>92cebe9</code></a> fix readable path check error message</li>; <li><a href=""https://github.com/pallets/click/commit/456fbb6b0053fb01bedf90b64999b0a3c645a3cd""><code>456fbb6</code></a> start version 8.1.2</li>; <li>See full diff in <a href=""https://github.com/pallets/click/compare/8.1.1...8.1.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11726:1951,depend,dependabot,1951,https://hail.is,https://github.com/hail-is/hail/pull/11726,1,['depend'],['dependabot']
Integrability," <li>Naoto Mizuno (1)</li>; <li>Andrew Nelson (3)</li>; <li>Tyler Reddy (28)</li>; <li>Pamphile Roy (1)</li>; <li>Ewout ter Hoeven (2)</li>; <li>Warren Weckesser (1)</li>; <li>Meekail Zain (1) +</li>; </ul>; <p>A total of 14 people contributed to this release.; People with a &quot;+&quot; by their names contributed a patch for the first time.; This list of names is automatically generated, and may not be fully complete.</p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/scipy/scipy/commit/656076ca6b490f587e9bd9c4cd10cb259a687c5b""><code>656076c</code></a> MAINT: wheel push 1.9.2 [wheel build]</li>; <li><a href=""https://github.com/scipy/scipy/commit/ad0d0f907010fbc8b66cdbe8ce0af2683881a309""><code>ad0d0f9</code></a> REL: set 1.9.2 released [wheel build]</li>; <li><a href=""https://github.com/scipy/scipy/commit/d9ad9801323653a2015b4d3e80d6d3ea93b6c021""><code>d9ad980</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/scipy/scipy/issues/17150"">#17150</a> from tylerjereddy/treddy_scipy_192_more_backports</li>; <li><a href=""https://github.com/scipy/scipy/commit/6b098c25223e224ff44101f86bbc86efecffe1d9""><code>6b098c2</code></a> TST: optimize.milp: remove problematic timeout/iteration test</li>; <li><a href=""https://github.com/scipy/scipy/commit/24dce9760b87934f1be046ec817c758b0f3952dc""><code>24dce97</code></a> DOC: stats.pearsonr: typo in coeffic<em>i</em>ent (<a href=""https://github-redirect.dependabot.com/scipy/scipy/issues/17153"">#17153</a>)</li>; <li><a href=""https://github.com/scipy/scipy/commit/a6ba7cad3b54c35d2ccb55c595691689004742c1""><code>a6ba7ca</code></a> MAINT: misc 1.9.2 updates</li>; <li><a href=""https://github.com/scipy/scipy/commit/ed9760e60a28b8f13e5644494033e2dab9aafbcd""><code>ed9760e</code></a> MAINT: stats.pearson3: fix ppf for negative skew (<a href=""https://github-redirect.dependabot.com/scipy/scipy/issues/17055"">#17055</a>)</li>; <li><a href=""https://github.com/scipy/sci",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12352:1700,depend,dependabot,1700,https://hail.is,https://github.com/hail-is/hail/pull/12352,1,['depend'],['dependabot']
Integrability," <li>Non-graceful node shutdown handling is enabled for stateful workload failovers (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108486"">kubernetes/kubernetes#108486</a>, <a href=""https://github.com/sonasingh46""><code>@​sonasingh46</code></a>)</li>; <li>Omit enum declarations from the static openapi file captured at <a href=""https://git.k8s.io/kubernetes/api/openapi-spec"">https://git.k8s.io/kubernetes/api/openapi-spec</a>. This file is used to generate API clients, and use of enums in those generated clients (rather than strings) can break forward compatibility with additional future values in those fields. See <a href=""https://issue.k8s.io/109177"">https://issue.k8s.io/109177</a> for details. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/109178"">kubernetes/kubernetes#109178</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>)</li>; <li>OpenAPI V3 is turned on by default (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/109031"">kubernetes/kubernetes#109031</a>, <a href=""https://github.com/Jefftree""><code>@​Jefftree</code></a>)</li>; <li>Pod affinity namespace selector and cross-namespace quota graduated to GA. The feature gate <code>PodAffinityNamespaceSelector</code> is locked and will be removed in 1.26. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108136"">kubernetes/kubernetes#108136</a>, <a href=""https://github.com/ahg-g""><code>@​ahg-g</code></a>)</li>; <li>Promote IdentifyPodOS feature to beta. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107859"">kubernetes/kubernetes#107859</a>, <a href=""https://github.com/ravisantoshgudimetla""><code>@​ravisantoshgudimetla</code></a>)</li>; <li>Remove a v1alpha1 networking API for ClusterCIDRConfig (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/109436"">kubernetes/kubernetes#109436</a>, <a href=""https://github.com/JamesLaverack""><code>@​J",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:11133,depend,dependabot,11133,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['depend'],['dependabot']
Integrability," <p>:meth:<code>gidgethub.abc.GitHubAPI.getiter</code> now accepts <code>iterable_key</code> parameter; in order to support the Checks API.; (<code>Issue [#164](https://github.com/brettcannon/gidgethub/issues/164) &lt;https://github.com/brettcannon/gidgethub/issues/164&gt;</code>_)</p>; </li>; <li>; <p>Accept HTTP 202 ACCEPTED as successful.; (<code>PR [#174](https://github.com/brettcannon/gidgethub/issues/174) &lt;https://github.com/brettcannon/gidgethub/pull/174&gt;</code>_)</p>; </li>; </ul>; <h2>5.0.1</h2>; <ul>; <li>Drop the <code>machine-man-preview</code> header from :meth:<code>gidgethub.apps.get_installation_access_token</code>; because it is out of preview. The <code>machine-man-preview</code> is <code>no longer required &lt;https://developer.github.com/changes/#--machine-man-and-sailor-v-previews-graduate&gt;</code>_; as of August 20, 2020.</li>; </ul>; <h2>5.0.0</h2>; <ul>; <li>Add :meth:<code>gidgethub.routing.Router.fetch</code> for obtaining a frozenset of functions; registered to the router that the event would be called on.; (<code>Issue [#74](https://github.com/brettcannon/gidgethub/issues/74) &lt;https://github.com/brettcannon/gidgethub/issues/74&gt;</code>_).</li>; <li>Add support for GitHub Actions Environment Files with :meth:<code>gidgethub.actions.setenv</code>; and :meth:<code>gidgethub.actions.addpath</code>.; (<code>Issue [#137](https://github.com/brettcannon/gidgethub/issues/137) &lt;https://github.com/brettcannon/gidgethub/issues/132&gt;</code>_).</li>; <li>Make router callback execution order non-deterministic to avoid relying on; registration order.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/brettcannon/gidgethub/commit/9660d1e1c0187d9def32c473c8ceefcd130fe26f""><code>9660d1e</code></a> Add .DS_Store to .gitignore file</li>; <li><a href=""https://github.com/brettcannon/gidgethub/commit/ef0368998fe40769f4f20a6c4b6cc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12328:6357,rout,router,6357,https://hail.is,https://github.com/hail-is/hail/pull/12328,1,['rout'],['router']
Integrability," <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9692"">#9692</a>: <code>pytest.approx</code>{.interpreted-text role=&quot;func&quot;} now raises a <code>TypeError</code>{.interpreted-text role=&quot;class&quot;} when given an unordered sequence (such as <code>set</code>{.interpreted-text role=&quot;class&quot;}).</p>; <p>Note that this implies that custom classes which only implement <code>__iter__</code> and <code>__len__</code> are no longer supported as they don't guarantee order.</p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pytest-dev/pytest/commit/0ffe9e07422dfec72479a6d056154ec8b9b0dbae""><code>0ffe9e0</code></a> Prepare release version 7.1.1</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/6f2c1ec0358264f10394fd2459a2e2a00b492844""><code>6f2c1ec</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9784"">#9784</a> from pytest-dev/backport-9768-to-7.1.x</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/a65c47a1a40dad1bb5ce0beb83657d492011a425""><code>a65c47a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9783"">#9783</a> from pytest-dev/backport-9780-to-7.1.x</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/30d995ed25e6d76e85da140663e6253fa5b41935""><code>30d995e</code></a> [pre-commit.ci] auto fixes from pre-commit.com hooks</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/10a14d13181fd69dd0eaf48bf5b3d389de896713""><code>10a14d1</code></a> [7.1.x] testing: fix tests when run under <code>-v</code> or <code>-vv</code></li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/f4cfc596c6574abf68ed49503fd1b8ef1484125d""><code>f4cfc59</code></a> [pre-commit.ci] auto fixes from pre-commit.com hooks</li>; <li><a href=""https://github.com/pytest-dev/pytest/comm",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11619:4505,depend,dependabot,4505,https://hail.is,https://github.com/hail-is/hail/pull/11619,1,['depend'],['dependabot']
Integrability," <p><em>Sourced from <a href=""https://github.com/pytest-dev/pytest/releases"">pytest's releases</a>.</em></p>; <blockquote>; <h2>7.1.0</h2>; <h1>pytest 7.1.0 (2022-03-13)</h1>; <h2>Breaking Changes</h2>; <ul>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/8838"">#8838</a>: As per our policy, the following features have been deprecated in the 6.X series and are now; removed:</p>; <ul>; <li><code>pytest._fillfuncargs</code> function.</li>; <li><code>pytest_warning_captured</code> hook - use <code>pytest_warning_recorded</code> instead.</li>; <li><code>-k -foobar</code> syntax - use <code>-k 'not foobar'</code> instead.</li>; <li><code>-k foobar:</code> syntax.</li>; <li><code>pytest.collect</code> module - import from <code>pytest</code> directly.</li>; </ul>; <p>For more information consult; <a href=""https://docs.pytest.org/en/latest/deprecations.html"">Deprecations and Removals</a> in the docs.</p>; </li>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9437"">#9437</a>: Dropped support for Python 3.6, which reached <a href=""https://devguide.python.org/#status-of-python-branches"">end-of-life</a> at 2021-12-23.</p>; </li>; </ul>; <h2>Improvements</h2>; <ul>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/5192"">#5192</a>: Fixed test output for some data types where <code>-v</code> would show less information.</p>; <p>Also, when showing diffs for sequences, <code>-q</code> would produce full diffs instead of the expected diff.</p>; </li>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9362"">#9362</a>: pytest now avoids specialized assert formatting when it is detected that the default <code>__eq__</code> is overridden in <code>attrs</code> or <code>dataclasses</code>.</p>; </li>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9536"">#9536</a>: When <code>-vv</code> is given on command line, show skippin",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11571:1114,depend,dependabot,1114,https://hail.is,https://github.com/hail-is/hail/pull/11571,2,['depend'],['dependabot']
Integrability," <p>This is a feature release, which includes new features and removes previously deprecated features. The 2.2.x branch is now the supported bugfix branch, the 2.1.x branch will become a tag marking the end of support for that branch. We encourage everyone to upgrade, and to use a tool such as <a href=""https://pypi.org/project/pip-tools/"">pip-tools</a> to pin all dependencies and control upgrades.</p>; <ul>; <li>Changes: <a href=""https://werkzeug.palletsprojects.com/en/2.2.x/changes/#version-2-2-0"">https://werkzeug.palletsprojects.com/en/2.2.x/changes/#version-2-2-0</a></li>; <li>Milestone: <a href=""https://github.com/pallets/werkzeug/milestone/20?closed=1"">https://github.com/pallets/werkzeug/milestone/20?closed=1</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/werkzeug/blob/main/CHANGES.rst"">werkzeug's changelog</a>.</em></p>; <blockquote>; <h2>Version 2.2.2</h2>; <p>Released 2022-08-08</p>; <ul>; <li>Fix router to restore the 2.1 <code>strict_slashes == False</code> behaviour; whereby leaf-requests match branch rules and vice; versa. :pr:<code>2489</code></li>; <li>Fix router to identify invalid rules rather than hang parsing them,; and to correctly parse <code>/</code> within converter arguments. :pr:<code>2489</code></li>; <li>Update subpackage imports in :mod:<code>werkzeug.routing</code> to use the; <code>import as</code> syntax for explicitly re-exporting public attributes.; :pr:<code>2493</code></li>; <li>Parsing of some invalid header characters is more robust. :pr:<code>2494</code></li>; <li>When starting the development server, a warning not to use it in a; production deployment is always shown. :issue:<code>2480</code></li>; <li><code>LocalProxy.__wrapped__</code> is always set to the wrapped object when; the proxy is unbound, fixing an issue in doctest that would cause it; to fail. :issue:<code>2485</code></li>; <li>Address one <code>ResourceWarning</code> relat",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12119:2235,rout,router,2235,https://hail.is,https://github.com/hail-is/hail/pull/12119,1,['rout'],['router']
Integrability," <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/0ee8d805e9061b52a210d69d46e433c718ad18ff""><code>0ee8d80</code></a> chore(main): release 1.57.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/139"">#139</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/b9dbb219ea46abd9851af1fc41ea37f9d5631c0b""><code>b9dbb21</code></a> feat: add support for Python 3.11 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/145"">#145</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/63ca888512be84508fcf95e4d5d40df036a85e18""><code>63ca888</code></a> feat: add support for Python 3.10 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/143"">#143</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac""><code>6af2132</code></a> chore(python): update dependencies in .kokoro/requirements.txt [autoapprove] ...</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/9ea3530b459269e964fcc98db1c5025e05d6495f""><code>9ea3530</code></a> fix(deps): require protobuf &gt;=3.19.5 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/141"">#141</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/5cf4e0bbfed23d061600d64099f21fcf92ef0cf2""><code>5cf4e0b</code></a> chore: update dependency protobuf &gt;= 3.20.2 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/138"">#138</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/92d9f53f5525ecb9af97c93467a594d6b92095cd""><code>92d9f53</code></a> fix(deps): require protobuf&gt;=3.20.2 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/137"">#",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12514:5610,depend,dependencies,5610,https://hail.is,https://github.com/hail-is/hail/pull/12514,1,['depend'],['dependencies']
Integrability," <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aioredis-py/releases"">aioredis's releases</a>.</em></p>; <blockquote>; <h2>v2.0.1</h2>; <p>Version v2.0.1</p>; <h2>Features</h2>; <ul>; <li>Added Python 3.10 to CI &amp; Updated the Docs (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1160"">#1160</a>)</li>; <li>Enable mypy in CI (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1101"">#1101</a>)</li>; <li>Synchronized reading the responses from a connection (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1106"">#1106</a>)</li>; </ul>; <h2>Fixes</h2>; <ul>; <li>Remove del from Redis (Fixes <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1115"">#1115</a>) (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1227"">#1227</a>)</li>; <li>fix socket.error raises (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1129"">#1129</a>)</li>; <li>Fix buffer is closed error when using PythonParser class (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1213"">#1213</a>)</li>; </ul>; <h2>Version v2.0.0</h2>; <p>Version 2.0 is a complete rewrite of aioredis. Starting with this version, aioredis now follows the API of <a href=""https://github.com/andymccurdy/redis-py"">redis-py</a>, so you can easily adapt synchronous code that uses redis-py for async applications with aioredis-py.</p>; <p><strong>NOTE:</strong> This version is <em>not</em> compatible with earlier versions of aioredis. If you upgrade, you will need to make code changes.</p>; <p>For more details, read our <a href=""https://aioredis.readthedocs.io/en/latest/migration/"">documentation on migrating to version 2.0</a>.</p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aioredis-py/blob/master/CHANGELOG.m",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11569:1085,depend,dependabot,1085,https://hail.is,https://github.com/hail-is/hail/pull/11569,1,['depend'],['dependabot']
Integrability," <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/axios/axios/releases"">axios's releases</a>.</em></p>; <blockquote>; <h2>v0.21.2</h2>; <h3>0.21.2 (September 4, 2021)</h3>; <p>Fixes and Functionality:</p>; <ul>; <li>Updating axios requests to be delayed by pre-emptive promise creation (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2702"">#2702</a>)</li>; <li>Adding &quot;synchronous&quot; and &quot;runWhen&quot; options to interceptors api (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2702"">#2702</a>)</li>; <li>Updating of transformResponse (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3377"">#3377</a>)</li>; <li>Adding ability to omit User-Agent header (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3703"">#3703</a>)</li>; <li>Adding multiple JSON improvements (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3688"">#3688</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3763"">#3763</a>)</li>; <li>Fixing quadratic runtime and extra memory usage when setting a maxContentLength (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3738"">#3738</a>)</li>; <li>Adding parseInt to config.timeout (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3781"">#3781</a>)</li>; <li>Adding custom return type support to interceptor (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3783"">#3783</a>)</li>; <li>Adding security fix for ReDoS vulnerability (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3980"">#3980</a>)</li>; </ul>; <p>Internal and Tests:</p>; <ul>; <li>Updating build dev dependancies (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3401"">#3401</a>)</li>; <li>Fixing builds running on Travis CI (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3538"">#3538</a>)</li>; <li>Updating follow rediect version (<a href=""https://github-redirect.dependab",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:1075,depend,dependabot,1075,https://hail.is,https://github.com/hail-is/hail/pull/11080,2,['depend'],['dependabot']
Integrability," <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/tqdm/tqdm/releases"">tqdm's releases</a>.</em></p>; <blockquote>; <h2>tqdm v4.63.0 stable</h2>; <ul>; <li>add <code>__reversed__()</code></li>; <li>add efficient <code>__contains__()</code></li>; <li>improve CLI startup time (replace <code>pkg_resources</code> =&gt; <code>importlib</code>)</li>; <li><code>tqdm.autonotebook</code> warning &amp; <code>std</code> fallback on missing <code>ipywidgets</code> (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1218"">#1218</a> &lt;- <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1082"">#1082</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1217"">#1217</a>)</li>; <li>warn on positional CLI arguments</li>; <li>misc build/test framework updates; <ul>; <li>enable <code>py3.10</code> tests</li>; <li>add <code>conda</code> dependencies</li>; <li>update pre-commit hooks</li>; <li>fix <code>pytest</code> config (<code>nbval</code>, <code>asyncio</code>)</li>; <li>fix dependencies &amp; tests</li>; <li>fix site deployment</li>; </ul>; </li>; </ul>; <h2>tqdm v4.62.3 stable</h2>; <ul>; <li>fix minor typo (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1246"">#1246</a>)</li>; <li>minor example fix (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1246"">#1246</a>)</li>; <li>misc tidying &amp; refactoring</li>; <li>misc build/dev framework updates; <ul>; <li>update dependencies</li>; <li>update linters</li>; <li>update docs deployment branches</li>; </ul>; </li>; <li>misc test/ci updates; <ul>; <li>test forks</li>; <li>tidy OS &amp; Python version tests</li>; <li>bump primary python version 3.7 =&gt; 3.8</li>; <li>beta py3.10 testing</li>; <li>fix py2.7 tests</li>; <li>better timeout handling</li>; </ul>; </li>; </ul>; <h2>tqdm v4.62.2 stable</h2>; <ul>; <li>fix notebook memory leak (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1216"">#1216</a>)</li>; <l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11587:982,depend,dependencies,982,https://hail.is,https://github.com/hail-is/hail/pull/11587,2,['depend'],['dependencies']
Integrability," <ul>; <li>; <p>Drop Python 3.5, the minimal supported version is Python 3.6</p>; </li>; <li>; <p>Support Python 3.9</p>; </li>; <li>; <p>Refomat with <code>black</code></p>; </li>; </ul>; <h2>0.5.0 (2020-04-23)</h2>; <ul>; <li>Remove explicit loop arguments and forbid creating queues outside event loops <a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/246"">#246</a></li>; </ul>; <h2>0.4.0 (2018-07-28)</h2>; <ul>; <li>; <p>Add <code>py.typed</code> macro <a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/89"">#89</a></p>; </li>; <li>; <p>Drop python 3.4 support and fix minimal version python3.5.3 <a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/88"">#88</a></p>; </li>; <li>; <p>Add property with that indicates if queue is closed <a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/86"">#86</a></p>; </li>; </ul>; <h2>0.3.2 (2018-07-06)</h2>; <ul>; <li>Fixed python 3.7 support <a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/97"">#97</a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/janus/commit/0783f9b7a9bb7e1c095e93ebb4aad4f1e219f512""><code>0783f9b</code></a> Fix coverage upload</li>; <li><a href=""https://github.com/aio-libs/janus/commit/41c49bafb1b192d2ee25b7394cead2386e452dc2""><code>41c49ba</code></a> Make deployment only if checks are green</li>; <li><a href=""https://github.com/aio-libs/janus/commit/ec94b35b2ae095dcb97827f1369c0cd31b7e8e5e""><code>ec94b35</code></a> Fix CI again</li>; <li><a href=""https://github.com/aio-libs/janus/commit/2303208c2f972e38445e7ecec54fda0f3203f566""><code>2303208</code></a> Fix CI</li>; <li><a href=""https://github.com/aio-libs/janus/commit/dff507895bf8d77efea2c4cc1d8b04a8a2986a0b""><code>dff5078</code></a> Bump to 1.0.0</li>; <li><a href=""https://github.com/aio-libs/janus/commit/3421545f3954b7ef6d90e02b7653a7ab685f3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11466:2514,depend,dependabot,2514,https://hail.is,https://github.com/hail-is/hail/pull/11466,1,['depend'],['dependabot']
Integrability," <ul>; <li>Fix <code>table</code> plugin</li>; <li>Security fix for CVE-2022-34749</li>; </ul>; <p>Version 2.0.2</p>; <pre><code>; Released on Jan 14, 2022; <p>Fix <code>escape_url</code></p>; <p>Version 2.0.1; </code></pre></p>; <p>Released on Dec 30, 2021</p>; <p>XSS fix for image link syntax.</p>; <p>Version 2.0.0</p>; <pre><code>; Released on Dec 5, 2021; <p>This is the first non-alpha release of mistune v2.</p>; <p>Version 2.0.0rc1; </code></pre></p>; <p>Released on Feb 16, 2021</p>; <p>Version 2.0.0a6</p>; <pre><code>; &lt;/tr&gt;&lt;/table&gt; ; </code></pre>; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/lepture/mistune/commit/b92a5febd4da3d7097a3d2b8d7cac6f5d57ea20c""><code>b92a5fe</code></a> Version bump 2.0.4</li>; <li><a href=""https://github.com/lepture/mistune/commit/98a1c0afc51d4be719cb17401a35e62f46206915""><code>98a1c0a</code></a> Fix url plugin render, <a href=""https://github-redirect.dependabot.com/lepture/mistune/issues/308"">#308</a></li>; <li><a href=""https://github.com/lepture/mistune/commit/979d6d3bfc7d6159f38deb8e751611e4205033f6""><code>979d6d3</code></a> Fix * parsing, <a href=""https://github-redirect.dependabot.com/lepture/mistune/issues/312"">#312</a></li>; <li><a href=""https://github.com/lepture/mistune/commit/f857f048ebb2f6f2bb7ab97dcb7a159172a20649""><code>f857f04</code></a> Trigger GitHub dependency graph</li>; <li><a href=""https://github.com/lepture/mistune/commit/3f422f1e84edae0f39756c45be453ecde534b755""><code>3f422f1</code></a> Version bump 2.0.3</li>; <li><a href=""https://github.com/lepture/mistune/commit/a6d43215132fe4f3d93f8d7e90ba83b16a0838b2""><code>a6d4321</code></a> Fix asteris emphasis regex CVE-2022-34749</li>; <li><a href=""https://github.com/lepture/mistune/commit/5638e460459cb59ceb20e4ce4716c802d4d73c53""><code>5638e46</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/lepture/mistune/issues/307"">#307</a> from jieter/patch",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12066:2311,depend,dependabot,2311,https://hail.is,https://github.com/hail-is/hail/pull/12066,2,['depend'],['dependabot']
Integrability," <ul>; <li>Fix invalid diff output for sets. (<a href=""https://github.com/jirikuncar""><code>@​jirikuncar</code></a> <a href=""https://github.com/danielduhh""><code>@​danielduhh</code></a>) (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/133"">#133</a> <a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/134"">#134</a>)</li>; </ul>; <p>Version 0.8.0 (released 2019-03-17)</p>; <ul>; <li>Respect <code>dot_notation</code> flag in ignore argument (<a href=""https://github.com/yoyonel""><code>@​yoyonel</code></a>) (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/107"">#107</a>)</li>; <li>Adds argument for toggling dot notation in diff. (<a href=""https://github.com/robinchew""><code>@​robinchew</code></a>)</li>; </ul>; <p>Version 0.7.2 (released 2019-02-22)</p>; <ul>; <li>Two NaN values are considered the same, hence they are not shown in <code>diff</code>; output. (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/114"">#114</a>) (<a href=""https://github.com/t-b""><code>@​t-b</code></a>)</li>; <li>Refactors <code>diff</code> method to reduce recursive call stack size. (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/112"">#112</a>); (<a href=""https://github.com/yoyonel""><code>@​yoyonel</code></a>)</li>; <li>Python porting best practice use feature detection instead; of version detection to save an import and pass both PyLint; and Flake8 tests with neither 'pragma' nor 'noqa'. (<a href=""https://github.com/cclauss""><code>@​cclauss</code></a>)</li>; </ul>; <p>Version 0.7.1 (released 2018-05-04)</p>; <ul>; <li>Resolves issue with keys containing dots. (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/101"">#101</a>)</li>; </ul>; <p>Version 0.7.0 (released 2017-10-16)</p>; <ul>; <li>Fixes problem with diff results that reference the original structure by; introduction of <code>deepcopy</code> for",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11485:3797,depend,dependabot,3797,https://hail.is,https://github.com/hail-is/hail/pull/11485,1,['depend'],['dependabot']
Integrability," <ul>; <li>fix intersphinx link for 'requests-oauthlib' (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/921"">#921</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/967be4f4e2a43ba7e240d7acb01b6b992d40e6ec"">967be4f</a>)</li>; <li>note ValueError in <code>verify_oauth2_token</code> (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/928"">#928</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/82bc5f08111de78a2b475b0310d3f35470680dbe"">82bc5f0</a>)</li>; </ul>; <h2>v2.3.3</h2>; <h3>Bug Fixes</h3>; <ul>; <li>add fetch_id_token_credentials (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/866"">#866</a>) (<a href=""https://www.github.com/googleapis/google-auth-library-python/commit/8f1e9cfd56dbaae0dff64499e1d0cf55abc5b97e"">8f1e9cf</a>)</li>; <li>fix error in sign_bytes (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/905"">#905</a>) (<a href=""https://www.github.com/googleapis/google-auth-library-python/commit/ef3128474431b07d1d519209ea61622bc245ce91"">ef31284</a>)</li>; <li>use 'int.to_bytes' and 'int.from_bytes' for py3 (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/904"">#904</a>) (<a href=""https://www.github.com/googleapis/google-auth-library-python/commit/bd0ccc5fe77d55f7a19f5278d6b60587c393ee3c"">bd0ccc5</a>)</li>; </ul>; <h2>v2.3.2</h2>; <h3>Bug Fixes</h3>; <ul>; <li>add clock_skew_in_seconds to verify_token functions (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/894"">#894</a>) (<a href=""https://www.github.com/googleapis/google-auth-library-python/commit/8e95c1e458793593972b6b05a355aaeaecd31670"">8e95c1e</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11546:4004,depend,dependabot,4004,https://hail.is,https://github.com/hail-is/hail/pull/11546,1,['depend'],['dependabot']
Integrability," = ir.typ._from_encoding(result); 102 return (value, timings) if timed else value. File ~/mambaforge/lib/python3.9/site-packages/py4j/java_gateway.py:1304, in JavaMember.__call__(self, *args); 1298 command = proto.CALL_COMMAND_NAME +\; 1299 self.command_header +\; 1300 args_command +\; 1301 proto.END_COMMAND_PART; 1303 answer = self.gateway_client.send_command(command); -> 1304 return_value = get_return_value(; 1305 answer, self.gateway_client, self.target_id, self.name); 1307 for temp_arg in temp_args:; 1308 temp_arg._detach(). File ~/mambaforge/lib/python3.9/site-packages/hail/backend/py4j_backend.py:21, in handle_java_exception.<locals>.deco(*args, **kwargs); 19 import pyspark; 20 try:; ---> 21 return f(*args, **kwargs); 22 except py4j.protocol.Py4JJavaError as e:; 23 s = e.java_exception.toString(). File ~/mambaforge/lib/python3.9/site-packages/py4j/protocol.py:330, in get_return_value(answer, gateway_client, target_id, name); 326 raise Py4JJavaError(; 327 ""An error occurred while calling {0}{1}{2}.\n"".; 328 format(target_id, ""."", name), value); 329 else:; --> 330 raise Py4JError(; 331 ""An error occurred while calling {0}{1}{2}. Trace:\n{3}\n"".; 332 format(target_id, ""."", name, value)); 333 else:; 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; 336 format(target_id, ""."", name)). Py4JError: An error occurred while calling o83._1. Trace:; java.lang.NegativeArraySizeException: -1966455376; 	at py4j.Base64.encodeToChar(Base64.java:681); 	at py4j.Base64.encodeToString(Base64.java:734); 	at py4j.Protocol.encodeBytes(Protocol.java:154); 	at py4j.ReturnObject.getPrimitiveReturnObject(ReturnObject.java:150); 	at py4j.Gateway.getReturnObject(Gateway.java:188); 	at py4j.Gateway.invoke(Gateway.java:283); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.base/java.lang.Thread.run(Thread.java:829); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12035#issuecomment-1186014691:3623,Protocol,Protocol,3623,https://hail.is,https://github.com/hail-is/hail/issues/12035#issuecomment-1186014691,2,['Protocol'],['Protocol']
Integrability," = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1067, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ---------------------------------------------------------------------------; Py4JError Traceback (most recent call last); <ipython-input-40-d6d936b012db> in <module>; 1 gwas = hl.linear_regression_rows(y=mt.pheno.CaffeineConsumption,; 2 x=mt.GT.n_alt_alleles(),; ----> 3 covariates=[1.0]); 4 gwas.row.describe(). <decorator-gen-1697> in linear_regression_rows(y, x, covariates, block_size, pass_through). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 612 def wrapper(__original_func, *args, **kwargs):; 613 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 614 return __original_func(*args_, **kwargs_); 615 ; 616 return wrapper. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/methods/statgen.py in linear_regression_rows(y, x, covariates, block_size, pass_through); 368 ht_result = ht_result.annotate(**{f: ht_result[f][0] for f in fields}); 369 ; --> 370 return ht_result.persist(); 371 ; 372 . <decorator-gen-1111> in persist(self, storage_level). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 612 def wrapper(__original_func, *args, **kwargs):; 613 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 614 return __original_func(*args_, **kwargs_); 615 ; 616 return wrapper. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/table.py in persist(self, storage_level); 1868 Persisted table.; 1869 """"""; -> 1870 return Env.backend().",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9939:5221,wrap,wrapper,5221,https://hail.is,https://github.com/hail-is/hail/issues/9939,3,['wrap'],['wrapper']
Integrability," = tmp_dir). vds = hl.vds.read_vds(vds_file); mt = hl.vds.to_dense_mt(vds); t = gnomad.utils.sparse_mt.default_compute_info(mt); t = t.annotate(info=t.info.drop('AS_SB_TABLE')); t = t.annotate(info = t.info.drop(; 'AS_QUALapprox', 'AS_VarDP', 'AS_SOR', 'AC_raw', 'AC', 'AS_SB'; )); t = t.drop('AS_lowqual'). hl.methods.export_vcf(dataset = t, output = out, tabix = True); ```. [batch-7751958-2713-main.log](https://github.com/hail-is/hail/files/12314207/batch-7751958-2713-main.log). ### Version. 0.2.120. ### Relevant log output. ```shell; Traceback (most recent call last):; File ""/Users/rye/Projects/VQSR/formatting-VQSR-vcf.py"", line 102, in <module>; main(args); File ""/Users/rye/Projects/VQSR/formatting-VQSR-vcf.py"", line 66, in main; hl.methods.export_vcf(dataset = t, output = args.out, tabix = False); File ""<decorator-gen-1440>"", line 2, in export_vcf; File ""/Users/rye/opt/anaconda3/lib/python3.9/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/rye/opt/anaconda3/lib/python3.9/site-packages/hail/methods/impex.py"", line 592, in export_vcf; Env.backend().execute(ir.MatrixWrite(dataset._mir, writer)); File ""/Users/rye/opt/anaconda3/lib/python3.9/site-packages/hail/backend/service_backend.py"", line 535, in execute; return self._cancel_on_ctrl_c(self._async_execute(ir, timed=timed, **kwargs)); File ""/Users/rye/opt/anaconda3/lib/python3.9/site-packages/hail/backend/service_backend.py"", line 526, in _cancel_on_ctrl_c; return async_to_blocking(coro); File ""/Users/rye/opt/anaconda3/lib/python3.9/site-packages/hailtop/utils/utils.py"", line 150, in async_to_blocking; return loop.run_until_complete(task); File ""/Users/rye/opt/anaconda3/lib/python3.9/site-packages/nest_asyncio.py"", line 89, in run_until_complete; return f.result(); File ""/Users/rye/opt/anaconda3/lib/python3.9/asyncio/futures.py"", line 201, in result; raise self._exception; File ""/Users/rye/opt/anaconda3/lib/python3.9/asyncio/tasks.py"", line 256, i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13409:2274,wrap,wrapper,2274,https://hail.is,https://github.com/hail-is/hail/issues/13409,1,['wrap'],['wrapper']
Integrability," Add Windows support to CI (<a href=""https://redirect.github.com/bartdag/py4j/issues/487"">#487</a>)</li>; <li><a href=""https://github.com/py4j/py4j/commit/1c622faa81e983f5ceface5290859d6a49974849""><code>1c622fa</code></a> Migrate nosetest to pytest (<a href=""https://redirect.github.com/bartdag/py4j/issues/481"">#481</a>)</li>; <li><a href=""https://github.com/py4j/py4j/commit/64ba89c5a680218d682161a4a6d952a969d1299b""><code>64ba89c</code></a> Add explanations for releasing Py4J for eclipse. Convert .txt to .md (<a href=""https://redirect.github.com/bartdag/py4j/issues/479"">#479</a>)</li>; <li>See full diff in <a href=""https://github.com/bartdag/py4j/compare/0.10.9.5...0.10.9.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=py4j&package-manager=pip&previous-version=0.10.9.5&new-version=0.10.9.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12978:2684,depend,dependabot-security-updates,2684,https://hail.is,https://github.com/hail-is/hail/pull/12978,1,['depend'],['dependabot-security-updates']
Integrability," Add logback classes that are initialized at build time (<a href=""https://redirect.github.com/Azure/azure-sdk-for-java/issues/36231"">#36231</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/4792bff2b30fb77ca29bd5eaa0502adf68502641""><code>4792bff</code></a> bump the proxy version (<a href=""https://redirect.github.com/Azure/azure-sdk-for-java/issues/36235"">#36235</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-java/compare/azure-core-http-netty_1.13.3...azure-core-http-netty_1.13.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.azure:azure-core-http-netty&package-manager=gradle&previous-version=1.13.3&new-version=1.13.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ign",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13591:3367,Depend,Dependabot,3367,https://hail.is,https://github.com/hail-is/hail/pull/13591,1,['Depend'],['Dependabot']
Integrability," Add missing includes</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/b4c395aaedfacb32e2414d361fa85968c0991b34""><code>b4c395a</code></a> Apply patch</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/6439c5c01349e74d4deb57c844a7ad4b7b13a302""><code>6439c5c</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10531"">#10531</a> from protocolbuffers/deannagarcia-patch-7</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/22c79e6e4ca8be2bc2f700b2cdddca84d84659ce""><code>22c79e6</code></a> Update version.json</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/c1a2d2ec29314975e725021ffe4334926dbaa56c""><code>c1a2d2e</code></a> Fix python release on macos (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10512"">#10512</a>)</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/a826282e15efe3ae3a2aebb040fb1691b2233a1e""><code>a826282</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10505"">#10505</a> from deannagarcia/3.20.x</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/7639a710e10beb47bfc62f363680f7b04e8b3d26""><code>7639a71</code></a> Add version file</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.20.1...v3.20.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.1&new-version=3.20.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12223:2316,protocol,protocolbuffers,2316,https://hail.is,https://github.com/hail-is/hail/pull/12223,3,['protocol'],['protocolbuffers']
Integrability," Allow character detection dependencies to be optional in post-packaging steps</li>; <li><a href=""https://github.com/psf/requests/commit/d6dded3f00afcf56a7e866cb0732799045301eb0""><code>d6dded3</code></a> Merge pull request <a href=""https://redirect.github.com/psf/requests/issues/6700"">#6700</a> from franekmagiera/update-redirect-to-invalid-uri-test</li>; <li><a href=""https://github.com/psf/requests/commit/bf24b7d8d17da34be720c19e5978b2d3bf94a53b""><code>bf24b7d</code></a> Use an invalid URI that will not cause httpbin to throw 500</li>; <li><a href=""https://github.com/psf/requests/commit/2d5f54779ad174035c5437b3b3c1146b0eaf60fe""><code>2d5f547</code></a> Pin 3.8 and 3.9 runners back to macos-13 (<a href=""https://redirect.github.com/psf/requests/issues/6688"">#6688</a>)</li>; <li><a href=""https://github.com/psf/requests/commit/f1bb07d39b74d6444e333879f8b8a3d9dd4d2311""><code>f1bb07d</code></a> Merge pull request <a href=""https://redirect.github.com/psf/requests/issues/6687"">#6687</a> from psf/dependabot/github_actions/github/codeql-act...</li>; <li><a href=""https://github.com/psf/requests/commit/60047ade64b0b882cbc94e047198818ab580911e""><code>60047ad</code></a> Bump github/codeql-action from 3.24.0 to 3.25.0</li>; <li><a href=""https://github.com/psf/requests/commit/31ebb8102c00f8cf8b396a6356743cca4362e07b""><code>31ebb81</code></a> Merge pull request <a href=""https://redirect.github.com/psf/requests/issues/6682"">#6682</a> from frenzymadness/pytest8</li>; <li>Additional commits viewable in <a href=""https://github.com/psf/requests/compare/v2.31.0...v2.32.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=requests&package-manager=pip&previous-version=2.31.0&new-version=2.32.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14555:9293,depend,dependabot,9293,https://hail.is,https://github.com/hail-is/hail/pull/14555,1,['depend'],['dependabot']
Integrability," Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45909"">#45909</a>: BUG: DateOffset(n) not defaulting to days (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45918"">#45918</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.0...v1.4.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pandas&package-manager=pip&previous-version=1.3.0&new-version=1.4.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11539:6616,Depend,Dependabot,6616,https://hail.is,https://github.com/hail-is/hail/pull/11539,1,['Depend'],['Dependabot']
Integrability," Bump astroid to 2.12.9, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/449a95b08e39dd2d6f3a6c3cbf4ace3055340b46""><code>449a95b</code></a> Fixed the <code>__init__</code> of <code>dataclassess</code> with multiple inheritance (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1774"">#1774</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/d15466685643b47f3b8b42ae5c0ba14a429a5293""><code>d154666</code></a> Fix a crash on <code>namedtuples</code> that use <code>typename</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1773"">#1773</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/65bca39bbf254bc760ac9d388e5a09333eaf5c87""><code>65bca39</code></a> Bump astroid to 2.12.8, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/fab511c1477d13262e9e33b015906d4bca683953""><code>fab511c</code></a> Fix crash in <code>dataclass</code> brain (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1770"">#1770</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/0720cbcd05a3938bdf8141328a1ceed1e2f38bed""><code>0720cbc</code></a> Parse default values in <code>dataclass</code> attributes correctly (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1771"">#1771</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/b2dbf7bdaa02436962c4c5ccbc6bbb8b8e0c3295""><code>b2dbf7b</code></a> Bump astroid to 2.12.7, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/fbe7859ec56ab64cc4d1b2604082878fdfdc8a14""><code>fbe7859</code></a> Fix crash in <code>dataclass</code> brain (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1768"">#1768</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/e194631088aee587140c029a0404f8d40c6765b5""><code>e194631</code></a> Bump astroid to 2.12.6, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/1f5dc457729d7219178ace97",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12161:3427,depend,dependabot,3427,https://hail.is,https://github.com/hail-is/hail/pull/12161,1,['depend'],['dependabot']
Integrability," Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **444/1000** <br/> **Why?** Has a fix available, CVSS 4.6 | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **429/1000** <br/> **Why?** Has a fix available, CVSS 4.3 | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **501/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.3 | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **509/1000** <br/> **Why?** Has a fix available, CVSS 5.9 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""mediu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14109:3157,Message,Message,3157,https://hail.is,https://github.com/hail-is/hail/pull/14109,1,['Message'],['Message']
Integrability," Data...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/d9dec94ece852eb25b7c37c6fb48be0ab44aa8d7""><code>d9dec94</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/50682"">#50682</a> on branch 1.5.x (BUG: pivot_table with nested elements and...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/ce123cd0024029bb9138acdcc14382628a9310fc""><code>ce123cd</code></a> REGR: NumPy func warning when dropping nuisance in agg, apply, transform (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/50"">#50</a>...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/54b40379e3fe6825f676cf02767ee81adb6ffeb5""><code>54b4037</code></a> Backport PR on Branch 1.5.x (REV: revert deprecation of Series.<strong>getitem</strong> sl...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/71db310a328a0dfa194ef0fe2b95238817b4f419""><code>71db310</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/50396"">#50396</a> on branch 1.5.x (BUG/COMPAT: fix assert_* functions for ne...</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.5...v1.5.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pandas&package-manager=pip&previous-version=1.3.5&new-version=1.5.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that ha",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12610:5136,depend,dependabot,5136,https://hail.is,https://github.com/hail-is/hail/pull/12610,1,['depend'],['dependabot']
Integrability," Deprecate HTTPResponse.getheaders() and .getheader() methods</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/8b8e4b5a148d0eb706daf5ac48b4423b434495f5""><code>8b8e4b5</code></a> Temporary fix for SLSA generator</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/cc9b0dc10eaf83b1242d710222525edd73555b6d""><code>cc9b0dc</code></a> [1.26] Fix logo URL in README</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/eb47444a9dfaa045cc4753e4d77c57fbdccaa619""><code>eb47444</code></a> [1.26] Fix CI by switching to macOS 11</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/34d7348bb96eca390c2115aeeee31d1147830844""><code>34d7348</code></a> Remove &quot;&lt;4&quot; upper bound from python_requires</li>; <li>See full diff in <a href=""https://github.com/urllib3/urllib3/compare/1.26.12...1.26.13"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.12&new-version=1.26.13)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12506:3405,depend,dependency-name,3405,https://hail.is,https://github.com/hail-is/hail/pull/12506,1,['depend'],['dependency-name']
Integrability, E 	at is.hail.expr.ir.lowering.OptimizePass.transform(LoweringPass.scala:40); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); E 	at is.hail.expr.ir.lowering.OptimizePass.apply(LoweringPass.scala:36); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); E 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); E 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); E 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); E 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); E 	at is.hail.expr.ir.Compile$.$anonfun$apply$4(Compile.scala:45); E 	at is.hail.backend.BackendWithCodeCache.lookupOrCompileCachedFunction(Backend.scala:126); E 	at is.hail.backend.BackendWithCodeCache.lookupOrCompileCachedFunction$(Backend.scala:122); E 	at is.hail.backend.local.LocalBackend.lookupOrCompileCachedFunction(LocalBackend.scala:73); E 	at is.hail.expr.ir.Compile$.apply(Compile.scala:39); E 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$_apply$5(CompileAndEvaluate.scala:66); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:66); E 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$apply$1(CompileAndEvaluate.scala:19); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:19); E 	at i,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:8573,Wrap,WrappedArray,8573,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198,1,['Wrap'],['WrappedArray']
Integrability," Env.hail().utils.ExportType.getExportType(parallel)))); File ""/opt/conda/default/lib/python3.6/site-packages/hail/backend/backend.py"", line 109, in execute; result = json.loads(Env.hc()._jhc.backend().executeJSON(self._to_java_ir(ir))); File ""/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; File ""/opt/conda/default/lib/python3.6/site-packages/hail/utils/java.py"", line 225, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.RuntimeException: error while applying lowering 'InterpretNonCompilable'; at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:26); at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:18); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:18); at is.hail.expr.ir.CompileAndEvaluate$$anonfun$apply$1.apply(CompileAndEvaluate.scala:16); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); at is.hail.expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:14); at is.hail.backend.Backend$$anonfun$execute$1.apply(Backend.scala:56); at is.hail.backend.Backend$$anonfun$execute$1.apply(Backend.scala:56); at is.hail.utils.package$.using(package.scala:596); at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:10); at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:9); at is.hail.utils.package$.using(package.scala:596); at is.hail.annotations.Region$.scoped(Region.scala:18); at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:9); at is.hail.backend.Backend.execute(Backend.scala:56); at is.hail.backend.Backend.executeJSON(Backend.scala:62); at sun.reflect.NativeMe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8161:1600,Wrap,WrappedArray,1600,https://hail.is,https://github.com/hail-is/hail/issues/8161,1,['Wrap'],['WrappedArray']
Integrability," Fix python release on macos (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10512"">#10512</a>)</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/a826282e15efe3ae3a2aebb040fb1691b2233a1e""><code>a826282</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10505"">#10505</a> from deannagarcia/3.20.x</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/7639a710e10beb47bfc62f363680f7b04e8b3d26""><code>7639a71</code></a> Add version file</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.20.1...v3.20.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.1&new-version=3.20.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12223:3148,depend,dependabot-security-updates,3148,https://hail.is,https://github.com/hail-is/hail/pull/12223,3,['depend'],['dependabot-security-updates']
Integrability," For instance, `c`'s environment might add a new bindings (e.g. in the body of a `StreamMap`), or it might drop all bindings, isolating the child, so that it cannot refer to anything bound outside of `x` (e.g. all relational nodes). The binding structure is complicated by the separation of the environment into ""eval"", ""agg"", ""scan"", and ""relational"" scopes. The child `c`'s environment might add new bindings in any of these scopes, and it might modify the parent's environment in other ways, like replacing the ""eval"" scope with the ""agg"" scope. In `Binds.scala`, the encoding of this relationship between parent's and child's environments was split across many methods, separately encoding bindings added to each of the scopes, and a prior modification to the parent scope. This made it difficult to understand the binding behavior of any particular node. And for nodes with more complicated binding behavior, these separate encodings became confusingly entangled. In this PR, `Binds.scala` is rewritten so that the binding behavior of a node is specified in a single place. Instead of computing a list of new bindings, it simply takes the parent's environment and returns the child's. Some use cases do require knowing what new bindings are added by a node in a child's environment. To support this, I made the `BindingEnvironment` interface a trait, and added another implementor `SegregatedBindingEnv`, which wraps two separate `BindingEnvironment`s, and puts all new bindings into the second. This satisfies the invariant that for any function `f(GenericBindingEnv): GenericBindingEnv` which modifies an environment using only the `GenericBindingEnv` interface, and any `env: BindingEnv[T]`,; ```; f(env) == f(SegregatedBindingEnv(env)).unified; ```; i.e. the segregation doesn't have any effect, other than keeping track of which bindings are new. Now that all binding structure for a node is encoded in one place, a future change could move this encoding to live in the node class directly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14404:1715,interface,interface,1715,https://hail.is,https://github.com/hail-is/hail/pull/14404,3,"['interface', 'wrap']","['interface', 'wraps']"
Integrability," HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/psf/black/blob/main/CHANGES.md"">black's changelog</a>.</em></p>; <blockquote>; <h2>22.1.0</h2>; <p>At long last, <em>Black</em> is no longer a beta product! This is the first non-beta release; and the first release covered by our new; <a href=""https://black.readthedocs.io/en/stable/the_black_code_style/index.html#stability-policy"">stability policy</a>.</p>; <h3>Highlights</h3>; <ul>; <li><strong>Remove Python 2 support</strong> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2740"">#2740</a>)</li>; <li>Introduce the <code>--preview</code> flag (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2752"">#2752</a>)</li>; </ul>; <h3>Style</h3>; <ul>; <li>Deprecate <code>--experimental-string-processing</code> and move the functionality under; <code>--preview</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2789"">#2789</a>)</li>; <li>For stubs, one blank line between class attributes and methods is now kept if there's; at least one pre-existing blank line (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2736"">#2736</a>)</li>; <li>Black now normalizes string prefix order (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2297"">#2297</a>)</li>; <li>Remove spaces around power operators if both operands are simple (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2726"">#2726</a>)</li>; <li>Work around bug that causes unstable formatting in some cases in the presence of the; magic trailing comma (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2807"">#2807</a>)</li>; <li>Use parentheses for attribute access on decimal float and int literals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2799"">#2799</a>)</li>; <li>Don't add whitespace for attribute access on hexadecimal, binary, octal, a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11468:7955,depend,dependabot,7955,https://hail.is,https://github.com/hail-is/hail/pull/11468,1,['depend'],['dependabot']
Integrability," Increase <code>stacklevel</code> for the <code>NODE_CTOR_FSPATH_ARG</code> deprecation to point to the; user's code, not pytest.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9871"">#9871</a>: Fix a bizarre (and fortunately rare) bug where the [temp_path]{.title-ref} fixture could raise; an internal error while attempting to get the current user's username.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pytest-dev/pytest/commit/4645bcd44915c2fd6043b101626e5bf1a983ac07""><code>4645bcd</code></a> Remove incorrect output in how-to/fixtures.rst</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/fadfb4f3463bc828535f86682300907a30f240e9""><code>fadfb4f</code></a> Prepare release version 7.1.3</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/ab96ea88e829af05e1491c30214b924c9553697b""><code>ab96ea8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/10258"">#10258</a> from pytest-dev/backport-10252-to-7.1.x</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/fc0e024b118fa63e84637bd5c9242b2b382e58fd""><code>fc0e024</code></a> [7.1.x] Fix regendoc</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/8f5088f4126b61ff76ac9809d5eb27cdbc31f07b""><code>8f5088f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/10249"">#10249</a> from pytest-dev/backport-10231-to-7.1.x</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/aae93d6127c43a7f9036556ba7482019d389e21d""><code>aae93d6</code></a> Ignore type-errors related to attr.asdict</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/71b79fcda5313624544ae501a2045186c1c72244""><code>71b79fc</code></a> [7.1.x] Ignore editable installation modules</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/89f7518cb131579608387936c55f96cd4d3e9d3f""><code>89f7518</code></a> ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12187:4178,depend,dependabot,4178,https://hail.is,https://github.com/hail-is/hail/pull/12187,1,['depend'],['dependabot']
Integrability," Keep Authorization header on subdomain redirects.</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/2ad9e82b6277ae2104f7770e9ff1186cc6da29d4""><code>2ad9e82</code></a> Carry over Host header on relative redirects (<a href=""https://github-redirect.dependabot.com/follow-redirects/follow-redirects/issues/172"">#172</a>)</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/77e2a581e1d1811674b7b74745a9c20a5b939488""><code>77e2a58</code></a> Release version 1.14.4 of the npm package.</li>; <li>Additional commits viewable in <a href=""https://github.com/follow-redirects/follow-redirects/compare/v1.14.1...v1.14.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=follow-redirects&package-manager=npm_and_yarn&previous-version=1.14.1&new-version=1.14.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11283:2583,depend,dependabot-security-updates,2583,https://hail.is,https://github.com/hail-is/hail/pull/11283,2,['depend'],['dependabot-security-updates']
Integrability," Merge pull request <a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/250"">#250</a> from carterbox/no-overflow-naturaldelta</li>; <li><a href=""https://github.com/jmoiron/humanize/commit/e89c8c8e325ccb2b3ee78ef507e9d6805c47a175""><code>e89c8c8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/241"">#241</a> from samueljsb/remove-deprecated-private-function-ali...</li>; <li><a href=""https://github.com/jmoiron/humanize/commit/ffe4bcfaa6cfbd95ba47315f8f71a206485af6ae""><code>ffe4bcf</code></a> Remove deprecated VERSION, use <strong>version</strong> instead</li>; <li><a href=""https://github.com/jmoiron/humanize/commit/eb3e2534267714361da866109bd33ff20e63416c""><code>eb3e253</code></a> Merge branch 'master' into no-overflow-naturaldelta</li>; <li>Additional commits viewable in <a href=""https://github.com/jmoiron/humanize/compare/1.0.0...4.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=humanize&package-manager=pip&previous-version=1.0.0&new-version=4.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` w",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11517:6732,Depend,Dependabot,6732,https://hail.is,https://github.com/hail-is/hail/pull/11517,4,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability," Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3069"">#3069</a> from Textualize/willmcgugan-patch-1</li>; <li><a href=""https://github.com/Textualize/rich/commit/2d035d116e5e91df3b0992c494b5bc6957e57f50""><code>2d035d1</code></a> Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3067"">#3067</a> from LukeSavefrogs/master</li>; <li><a href=""https://github.com/Textualize/rich/commit/33fcafe6ec28c541203ada9a85bf73e31786f61d""><code>33fcafe</code></a> Format <code>test_highlighter.py</code> using <code>black</code></li>; <li><a href=""https://github.com/Textualize/rich/commit/5633a672795e73d6262a4e7fb02b4807bf74c038""><code>5633a67</code></a> Update FUNDING.yml</li>; <li>Additional commits viewable in <a href=""https://github.com/Textualize/rich/compare/v12.6.0...v13.5.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=rich&package-manager=pip&previous-version=12.6.0&new-version=13.5.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` wil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13575:6877,depend,dependency-name,6877,https://hail.is,https://github.com/hail-is/hail/pull/13575,1,['depend'],['dependency-name']
Integrability," Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3069"">#3069</a> from Textualize/willmcgugan-patch-1</li>; <li><a href=""https://github.com/Textualize/rich/commit/2d035d116e5e91df3b0992c494b5bc6957e57f50""><code>2d035d1</code></a> Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3067"">#3067</a> from LukeSavefrogs/master</li>; <li><a href=""https://github.com/Textualize/rich/commit/33fcafe6ec28c541203ada9a85bf73e31786f61d""><code>33fcafe</code></a> Format <code>test_highlighter.py</code> using <code>black</code></li>; <li><a href=""https://github.com/Textualize/rich/commit/5633a672795e73d6262a4e7fb02b4807bf74c038""><code>5633a67</code></a> Update FUNDING.yml</li>; <li>Additional commits viewable in <a href=""https://github.com/Textualize/rich/compare/v12.6.0...v13.5.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=rich&package-manager=pip&previous-version=12.6.0&new-version=13.5.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13380:6877,depend,dependency-name,6877,https://hail.is,https://github.com/hail-is/hail/pull/13380,1,['depend'],['dependency-name']
Integrability," ParamType.to_info_dict() with no name</li>; <li><a href=""https://github.com/pallets/click/commit/19be092b6db4e4300e31906498e354ec0adf870c""><code>19be092</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2217"">#2217</a> from pallets/group-return</li>; <li><a href=""https://github.com/pallets/click/commit/7d3a871eb71694e99438254686c139122bc4be64""><code>7d3a871</code></a> group without command passes return value to result callback</li>; <li>Additional commits viewable in <a href=""https://github.com/pallets/click/compare/8.0.4...8.1.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=click&package-manager=pip&previous-version=8.0.4&new-version=8.1.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11706:7205,Depend,Dependabot,7205,https://hail.is,https://github.com/hail-is/hail/pull/11706,1,['Depend'],['Dependabot']
Integrability," Patch by; Pradyun Gedam.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10648"">#10648</a>: LaTeX: CSS-named-alike additional :ref:<code>'sphinxsetup' &lt;latexsphinxsetup&gt;</code>; keys allow to configure four separate border-widths, four paddings, four; corner radii, a shadow (possibly inset), colours for border, background, shadow; for each of the code-block, topic, attention, caution, danger, error and warning; directives.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10655"">#10655</a>: LaTeX: Explain non-standard encoding in LatinRules.xdy</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10599"">#10599</a>: HTML Theme: Wrap consecutive footnotes in an <code>&lt;aside&gt;</code> element when; using Docutils 0.18 or later, to allow for easier styling. This matches the; behaviour introduced in Docutils 0.19. Patch by Adam Turner.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10518"">#10518</a>: config: Add <code>include_patterns</code> as the opposite of <code>exclude_patterns</code>.; Patch by Adam Turner.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/e712eae382d213ce3f4866ad6f5b3c84ce4f4409""><code>e712eae</code></a> Bump to 5.1.1 final</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/0555345ad715b1e5ec83bce2e4a993441ffb8f29""><code>0555345</code></a> Fix ValueError popping out in <code>sphinx.ext.napoleon</code> (<a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10709"">#10709</a>)</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/9845500ffa6b75266b1e34701c15eb8e586aa17e""><code>9845500</code></a> Improve support for deprecated builders without env arg (<a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10702""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12165:4865,depend,dependabot,4865,https://hail.is,https://github.com/hail-is/hail/pull/12165,1,['depend'],['dependabot']
Integrability," Polish translation (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/182"">#182</a>) <a href=""https://github.com/kpostekk""><code>@​kpostekk</code></a></li>; <li>Add Traditional Chinese (zh-HK) (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/233"">#233</a>) <a href=""https://github.com/edwardmfho""><code>@​edwardmfho</code></a></li>; </ul>; <h2>Changed</h2>; <ul>; <li>Remove redundant setuptools from install_requires (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/232"">#232</a>) <a href=""https://github.com/arthurzam""><code>@​arthurzam</code></a></li>; </ul>; <h2>Deprecated</h2>; <ul>; <li>This is the last release to support Python 3.6</li>; <li>Deprecate private functions (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/234"">#234</a>) <a href=""https://github.com/samueljsb""><code>@​samueljsb</code></a></li>; <li>Reinstate <code>VERSION</code> and deprecate (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/240"">#240</a>) <a href=""https://github.com/hugovk""><code>@​hugovk</code></a></li>; </ul>; <h2>3.12.0</h2>; <h2>Added</h2>; <ul>; <li>Add support for Python 3.10 (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/223"">#223</a>) <a href=""https://github.com/hugovk""><code>@​hugovk</code></a></li>; </ul>; <h2>Changed</h2>; <ul>; <li>Use importlib.metadata to get package version instead of pkg_resources.get_distribution to decrease memory consumption (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/227"">#227</a>) <a href=""https://github.com/akayunov""><code>@​akayunov</code></a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/jmoiron/humanize/commit/a1514eb521c2befe40274674d61aba4f0fbf6137""><code>a1514eb</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/jmoiron/humanize",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11517:3676,depend,dependabot,3676,https://hail.is,https://github.com/hail-is/hail/pull/11517,2,['depend'],['dependabot']
Integrability," Ported the Continuous Integration from Travis to GitHub.</p>; <h2>4.4.2 (2020-02-29)</h2>; <p>Sylvan Mosberger (<a href=""https://github.com/Infinisil"">https://github.com/Infinisil</a>) contributed a patch to; some doctests that were breaking on NixOS.; John Vandenberg (<a href=""https://github.com/jayvdb"">https://github.com/jayvdb</a>) made a case for removing the usage</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/micheles/decorator/commits/5.1.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=decorator&package-manager=pip&previous-version=4.4.0&new-version=5.1.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11799:3062,Depend,Dependabot,3062,https://hail.is,https://github.com/hail-is/hail/pull/11799,1,['Depend'],['Dependabot']
Integrability," Promises flatten the callback tree. ```js; function asyncPromise(arg) {; return new Promise((resolve, reject) => {; const (err, result) = someSynchronousOperation();; ; if(err) {; reject(err);; return;; } ; ; resolve(result);; });; }. asyncPromise(arg).then( r => doSomething(r) ).catch( err => throw new Error(err) ); ```. This has one problem. Chaining promises leads to a potentially hard to follow chain of `.then` `.catch`. As in many other languages, the solution to ""transforming"" async call syntax to sync ones, is to color async functions with a ""async"" and ""await"" clauses. This can be used with any functions that return promises (but not those that just return a callback). Luckily again, JS libraries have been moving towards the Promise-land (sorry) for ~5 years, before Promises were in stdlib (bluebird). ```js; async function usePromise() {; const arg = someSyncOperation();; ; let result;; try {; result = await asyncPromise(arg);; } catch(e) {; // without wrapping catch, will just throw on reject(), unwinding the call stack; doSomethingWIthError(e) ; }; ; doStuffWithResult(result);; }; ```; ### React; What is a react component? A function that returns JSX. React components accept props (HTML attributes `<Component propName={propValue} />`); Stateless vs stateful components; ```jsx; # Stateful; class Stuff extends React.Component {; static getInitialProps() {; ; }. render() {; return <div>Hello World</div>; } ; }. # Stateless; # Note that arrow syntax has an implicit return if you don't create a function block, i. => { return <div>Hello World</div> } is valid too.; () => <div> Hello World </div> ; ```. Stateless ones are typically cheaper, but not necessarily:; * See: [PureComponent](https://reactjs.org/docs/react-api.html#reactpurecomponent); * See: [shouldComponentUpdate lifecycle method](https://reactjs.org/docs/react-component.html#shouldcomponentupdate). #### JSX differences from html; 1. `className` : ""class"" is a reserved word in JSX; used to specify the ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162:6311,wrap,wrapping,6311,https://hail.is,https://github.com/hail-is/hail/pull/5162,1,['wrap'],['wrapping']
Integrability," Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **489/1000** <br/> **Why?** Has a fix available, CVSS 5.5 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6210214) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **519/1000** <br/> **Why?** Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxM2UyYzQ2MC1mZTA2LTQwOTktYWRhYi1lMWY4ZmE5MzFkZTAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjEzZTJjNDYwLWZlMDYtNDA5OS1hZGFiLWUxZjhmYTkzMWRlMCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14329:10239,depend,dependency,10239,https://hail.is,https://github.com/hail-is/hail/pull/14329,2,['depend'],"['dependencies', 'dependency']"
Integrability," RV. 4. The hash function on (options, source) is now beefed up to cope with having only a; few distinct values of options; and is modified with the output of ""$(CXX) --version"",; so that when you upgrade your compiler, you won't get hits on modules compiled with the old; compiler. 5. build.gradle has a new target ""nativeLibPrebuilt"", for updating the prebuilt/lib/linux-x86-64; or prebuilt/lib/darwin. 6. The committed prebuilt libraries are built thus:. darwin - On my MacOS laptop, with the default (clang-based) compiler, -march=sandybridge; From my reading, I believe this should be compatible withall MacBook Pro's; released since 2011, and all versions of MacOS since 10.9 (the first to use; libc++ rather than libstdc++ as the default C++ library) - we're now at 10.13,; with 10.14 arriving some time in the fall. linux-x86-64 - Built on my home desktop running Ubuntu-16.04 LTS, and g++-5.0.4, with; -fabi-version=9. In theory this should work with all systems based on g++5.x and; later. I made some effort to move std::string out of the interfaces between prebuilt; and dynamic code, which gives it some chance of working on systems based on; g++-4.x, but haven't tested that. I'm planning to fire up VM's either in cloud or under VirtualBox, to test this against Ubuntu-14.04,; Ubuntu-18.04, and the latest stable RHEL, which should cover most of the bases. In the interest of getting this committed, I have not made changes relating to logging and; error messages. The DLL's are still in the jar, and I think it has to stay that way because; all nodes need to see libhail.so. The header files are also in the jar, and have to be; unpacked in a convoluted way, and that could probably be simplified if/when we change; the approach to packaging. Once this goes in, I can follow it with a PR which adds the NativePackDecoder in RowStore.scala,; controlled by whether environment variable ""HAIL_ENABLE_CPP_CODEGEN"" is defined; (so defaulting to using the JVM bytecode CompiledPackDecoder).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3973#issuecomment-413997863:1655,interface,interfaces,1655,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-413997863,4,"['interface', 'message']","['interfaces', 'messages']"
Integrability," Security. Preceded by Secure Sockets Layer (SSL) which; is not obsolete and insecure. After SSL version 3, a new version of SSL was; proposed in RFC 2246. This new version was backwards-incompatible and was; thus given a new name: Transport Layer Security. In common discussion, SSL; and TLS are used interchangeable. Indeed, the python TLS library is called; `ssl`. [2] Forward secrecy is a property of an encryption system. Forward secrecy means; a message cannot be decrypted in the future by an adversary who learned one; of the private keys. For example, imagine you are sending sensitive messages; to another individual. If that individual is later coerced into revealing; their secret key, forward secrecy would prevent the coercer from reading; your messages. Forward secrecy is achieved by negotiating a shared private; key between the two parties that is only used for a ""session"" and then; discarded. If the session key is securely discarded and neither key can; recreate it without cooperation from the other key, then *one* leaked key is; insufficient to reveal the messages. ---. Things for you to verify:; - does every service load *its own unqiue* ssl-config secret?; - does every service use an SSL context for serving?; - does everyone who makes http requests to internal services use an SSL client; session?; - do all TLS-secured nginx instances include their http.conf in the `http`; section and the `proxy.conf` file in any proxying sections?; - Do the SSLContext's from `ssl.py` and the nginx configurations generated by; `create_certs.py` actually ensure security?. Post-merge actions:; - deploy gateway; - deploy internal-gateway; - deploy router-resolver. Anticipated outages:. - Before a service is redeployed it will be inaccessible from the outside; because the router will try to speak to it on HTTPS. Services that speak to; one another (ci<->batch, everyone<->auth) will lose connections while the; deploy is happening. Deploy should move smoothly because CI will compl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:12653,message,messages,12653,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['message'],['messages']
Integrability," Series.<strong>getitem</strong> sl...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/71db310a328a0dfa194ef0fe2b95238817b4f419""><code>71db310</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/50396"">#50396</a> on branch 1.5.x (BUG/COMPAT: fix assert_* functions for ne...</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.5...v1.5.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pandas&package-manager=pip&previous-version=1.3.5&new-version=1.5.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12610:5908,Depend,Dependabot,5908,https://hail.is,https://github.com/hail-is/hail/pull/12610,1,['Depend'],['Dependabot']
Integrability," Set[Empty],; VeGLA3v: Array[Array[Struct {; C: Empty,; sHjMXnj: Boolean,; G: Call; }]],; Ni: Struct {; HCrSI: Empty,; nJt7: Boolean; },; nxb8CkLI: Int,; y4mYv_DvH: Dict[Array[Genotype], Variant]; }; v [ WrappedArray( Set( WrappedArray(null); , WrappedArray(); , WrappedArray(Map(null -> Map(WrappedArray(2) -> 2)), Map(null -> Map(WrappedArray() -> 1)), Map(null -> Map(WrappedArray(1) -> 2))); ); , Set(WrappedArray(Map(null -> null), Map(null -> Map(WrappedArray(2) -> 31, WrappedArray(0) -> 0)))); , Set(WrappedArray(Map(null -> Map()), Map(null -> null))); , Set( WrappedArray(Map()); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> null)); , WrappedArray(); , WrappedArray(null, Map(null -> Map(WrappedArray() -> null)))); , Set(); , Set( WrappedArray(Map(null -> Map(WrappedArray() -> null))); , WrappedArray(); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> Map()), Map(null -> Map(WrappedArray() -> 2)))); , Set(WrappedArray()); , Set( WrappedArray(); , WrappedArray(Map(null -> Map()))); , Set(); , Set( WrappedArray(Map(null -> null)); , WrappedArray(Map(null -> Map()))); , Set( WrappedArray(Map(null -> Map(WrappedArray(null) -> 1)), Map(null -> Map(WrappedArray(5) -> 2))); , WrappedArray(Map())); , Set(); , Set(); , Set(WrappedArray(); , WrappedArray(Map(null -> Map()))); , Set(); , Set( null; , WrappedArray()); , Set( WrappedArray(Map(null -> Map(WrappedArray(1) -> 19))); , WrappedArray(Map(null -> Map(WrappedArray(0) -> 2)), Map(null -> Map())); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> Map(WrappedArray(2) -> null)), Map(null -> Map(WrappedArray() -> 17)), Map(null -> Map(WrappedArray() -> 1)))); , Set(WrappedArray(Map(null -> Map(WrappedArray(null) -> 1)), Map(null -> Map(WrappedArray(2) -> 0, WrappedArray() -> null)), Map(), Map())); , Set(WrappedArray(Map(null -> Map()), Map(null -> Map()), Map(null -> Map(WrappedArray(0) -> 0)))); , Set( WrappedArray(); , WrappedArray(Map(null -> Map(WrappedArray(0) -> null)))); ,",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1902:1923,Wrap,WrappedArray,1923,https://hail.is,https://github.com/hail-is/hail/pull/1902,1,['Wrap'],['WrappedArray']
Integrability," SparkUI available at http://wp086-661.broadinstitute.org:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.16-e95038bbed35; LOGGING: writing to /dev/null; Traceback (most recent call last):; File ""/tmp/x"", line 4, in <module>; mt.filter_rows(mt.locus < hl.Locus('1', 1)).show(); File ""</home/BROAD.MIT.EDU/cvittal/.cache/hail-env/lib/python3.6/site-packages/decorator.py:decorator-gen-1000>"", line 2, in show; File ""/home/BROAD.MIT.EDU/cvittal/src/hail-alt/hail/python/hail/typecheck/check.py"", line 585, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/BROAD.MIT.EDU/cvittal/src/hail-alt/hail/python/hail/matrixtable.py"", line 2569, in show; actual_n_cols = self.count_cols(); File ""</home/BROAD.MIT.EDU/cvittal/.cache/hail-env/lib/python3.6/site-packages/decorator.py:decorator-gen-994>"", line 2, in count_cols; File ""/home/BROAD.MIT.EDU/cvittal/src/hail-alt/hail/python/hail/typecheck/check.py"", line 585, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/BROAD.MIT.EDU/cvittal/src/hail-alt/hail/python/hail/matrixtable.py"", line 2404, in count_cols; return Env.backend().execute(ir); File ""/home/BROAD.MIT.EDU/cvittal/src/hail-alt/hail/python/hail/backend/backend.py"", line 108, in execute; result = json.loads(Env.hc()._jhc.backend().executeJSON(self._to_java_ir(ir))); File ""/home/BROAD.MIT.EDU/cvittal/.local/opt/spark/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; File ""/home/BROAD.MIT.EDU/cvittal/src/hail-alt/hail/python/hail/utils/java.py"", line 221, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: MatchError: locus<GRCh37> (of class is.hail.expr.types.virtual.TLocus). Java stack trace:; scala.MatchError: locus<GRCh37> (of class is.hail.expr.types.virtual.TLocus); 	at is.hail.expr.ir.ExtractIntervalFilters$.minimumValueByType(ExtractIntervalFilters.scala:42); 	at is.hail.expr.ir.E",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6458:1754,wrap,wrapper,1754,https://hail.is,https://github.com/hail-is/hail/issues/6458,1,['wrap'],['wrapper']
Integrability," There [was a; PR](kubernetes/kubernetes#61231) to allow httpGet probes; to send the kubelet certificate, but it was closed because, apparently, the; [httpGet probes can be targeted at arbitrary IP; addresses](kubernetes/kubernetes#61231 (review)) (what; the hell?), ergo Confused Deputy. ### Future Work. - Require TLS 1.3 everywhere.; - Comply with Mozilla's ""Modern"" recommendations.; - [Incoming Trust](#incoming-trust).; - Refresh certificates after deploying new ones. ### Footnotes. [1] TLS: Transport Layer Security. Preceded by Secure Sockets Layer (SSL) which; is not obsolete and insecure. After SSL version 3, a new version of SSL was; proposed in RFC 2246. This new version was backwards-incompatible and was; thus given a new name: Transport Layer Security. In common discussion, SSL; and TLS are used interchangeable. Indeed, the python TLS library is called; `ssl`. [2] Forward secrecy is a property of an encryption system. Forward secrecy means; a message cannot be decrypted in the future by an adversary who learned one; of the private keys. For example, imagine you are sending sensitive messages; to another individual. If that individual is later coerced into revealing; their secret key, forward secrecy would prevent the coercer from reading; your messages. Forward secrecy is achieved by negotiating a shared private; key between the two parties that is only used for a ""session"" and then; discarded. If the session key is securely discarded and neither key can; recreate it without cooperation from the other key, then *one* leaked key is; insufficient to reveal the messages. ---. Things for you to verify:; - does every service load *its own unqiue* ssl-config secret?; - does every service use an SSL context for serving?; - does everyone who makes http requests to internal services use an SSL client; session?; - do all TLS-secured nginx instances include their http.conf in the `http`; section and the `proxy.conf` file in any proxying sections?; - Do the SSLContext's",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:12025,message,message,12025,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['message'],['message']
Integrability," This code explains what I found pretty well:. ```python; > mt = hl.balding_nichols_model(1, 10, 10). # Aggregate concatenated alleles (works fine); > mt.aggregate_rows(hl.agg.counter(hl.delimit(mt.alleles, '|'))); {'A|C': 10}. # Group by the array directly (gives an expected error); > mt.aggregate_rows(hl.agg.counter(mt.alleles)); TypeError: unhashable type: 'list'. # Aggregate sorted arrays (works but gives wrong result); > mt.aggregate_rows(hl.agg.counter(hl.delimit(hl.sorted(mt.alleles), '|'))); {'A|A|A|C|\x0b\x00\x00': 2, 'A|A|A|C|C|C': 8}. # Aggregate the sorted arrays directly (segfault); # *This should probably throw ""unhashable type list"" like it does without the sort*; mt.aggregate_rows(hl.agg.counter(hl.sorted(mt.alleles))); ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/opt/conda/envs/hail/lib/python3.7/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty; ...; Py4JError: An error occurred while calling o59.executeJSON; ```. Here is the full [stack trace](https://github.com/hail-is/hail/files/4187400/stacktrace.txt) and [core dump](https://github.com/hail-is/hail/files/4187399/coredump.txt). I think some related questions that arise from this are:. 1. What's the best way to group by an array to avoid the conversion to a delimited string? In this case I could do something like ```mt.aggregate_rows(hl.agg.counter(hl.tuple([mt.alleles[0], mt.alleles[1]])))``` but I can't find a solution for getting a tuple from an array without knowing the length of it beforehand for every row. Is there a more fundamental reason why the API doesn't allow aggregation by arrays even if Spark does?; 2. When the Py4J server crashes, it's no longer reachable from the python clients so I have to restart my process and re-initialize Hail. Is there already functionality implemented for bringing that server up if",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8076:1131,protocol,protocol,1131,https://hail.is,https://github.com/hail-is/hail/issues/8076,1,['protocol'],['protocol']
Integrability," VERIFY_CA, we load server; certs, load client certs, verify clients, and verify (proxied) servers. For Hail principals, we only generate a json configuration; file containing the ssl mode and some named paths. The new `hailtop/ssl.py`; module defines the mapping from configuration to Python's; [`SSLContext`](https://docs.python.org/3.6/library/ssl.html#ssl.SSLContext). There is also one ""curl"" principal: the admin-pod. REQUIRED and DISABLED are; mostly the same because required passes the `insecure` flag. As curl is; client-only, there is no notion of ""incoming connection"". ---. FAQ. Does this recreate certs on each deploy?. Yes. How do services speak to each other while a deploy is happening? Newly deployed; services will only trust newly deployed clients?. `create_certs.py` includes the previous deploy's certificates in the trust; chain, so we can always accept clients from one deploy backwards. Old services; will not trust the new clients, but the `build.yaml` ensures things are deployed; in dependency order. Deploy would never work if a client could depend on; a not-yet-deployed server. ---. Things for you to verify:; - does every service load *its own unqiue* ssl-config secret?; - does every service use an SSL context for serving?; - does everyone who makes http requests to internal services use an SSL client; session?; - do all TLS-secured nginx instances include their http.conf in the `http`; section and the `proxy.conf` file in any proxying sections?; - Do the SSLContext's from `ssl.py` and the nginx configurations generated by; `create_certs.py` obey the aforementioned matrix?. Post-merge actions:; - deploy gateway; - deploy internal-gateway; - deploy router-resolver. Anticipated outages:. - Before a service is redeployed it will be inaccessible from the outside; because the router will try to speak to it on HTTPS. Services that speak to; one another (ci<->batch, everyone<->auth) will lose connections while the; deploy is happening. Deploy should move smoot",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8513:5752,depend,dependency,5752,https://hail.is,https://github.com/hail-is/hail/pull/8513,1,['depend'],['dependency']
Integrability," Windows node will be considered to be unhealthy by those load balancers. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/99287"">kubernetes/kubernetes#99287</a>, <a href=""https://github.com/anfernee""><code>@​anfernee</code></a>)</li>; <li>Added CEL runtime cost calculation into CustomerResource validation. CustomerResource validation will fail if runtime cost exceeds the budget. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108482"">kubernetes/kubernetes#108482</a>, <a href=""https://github.com/cici37""><code>@​cici37</code></a>)</li>; <li>Added a new metric <code>webhook_fail_open_count</code> to monitor webhooks that fail to open. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107171"">kubernetes/kubernetes#107171</a>, <a href=""https://github.com/ltagliamonte-dd""><code>@​ltagliamonte-dd</code></a>)</li>; <li>Adds a new Status subresource in Network Policy objects (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107963"">kubernetes/kubernetes#107963</a>, <a href=""https://github.com/rikatz""><code>@​rikatz</code></a>)</li>; <li>Adds support for <code>InterfaceNamePrefix</code> and <code>BridgeInterface</code> as arguments to <code>--detect-local-mode</code> option and also introduces a new optional <code>--pod-interface-name-prefix</code> and <code>--pod-bridge-interface</code> flags to kube-proxy. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/95400"">kubernetes/kubernetes#95400</a>, <a href=""https://github.com/tssurya""><code>@​tssurya</code></a>)</li>; <li>CEL CRD validation expressions may now reference existing object state using the identifier <code>oldSelf</code>. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108073"">kubernetes/kubernetes#108073</a>, <a href=""https://github.com/benluddy""><code>@​benluddy</code></a>)</li>; <li>CRD deep copies should no longer contain shallow copies of <code>JSONSche",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:2410,depend,dependabot,2410,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['depend'],['dependabot']
Integrability," Windows, macOS, and Linux wheels to be compiled with OpenSSL 3.1.3.; <p>.. _v41-0-3:; </code></pre></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pyca/cryptography/commit/fc11bce6930e591ce26a2317b31b9ce2b3e25512""><code>fc11bce</code></a> bump for 41.0.4 (<a href=""https://redirect.github.com/pyca/cryptography/issues/9629"">#9629</a>)</li>; <li>See full diff in <a href=""https://github.com/pyca/cryptography/compare/41.0.3...41.0.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=41.0.3&new-version=41.0.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major versio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13685:1338,depend,dependabot,1338,https://hail.is,https://github.com/hail-is/hail/pull/13685,3,['depend'],['dependabot']
Integrability," [SIG Apps and Network]</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/bcfd4ed2ec3b2f503adc4f2e681f9404216d302c""><code>bcfd4ed</code></a> chore: update version</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/37f5d63425976b463bb83348d592859a82f2b5af""><code>37f5d63</code></a> chore: update changelog</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/ef2fe15d3473a38f1c13558acf05631d909560ce""><code>ef2fe15</code></a> fix: watch returns raw_object if detection of returned objects fail (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/177"">#177</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/59a6e2a60fb7592e596447555c2da2797b7273a9""><code>59a6e2a</code></a> chore(deps): update sphinx requirement (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/175"">#175</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/f4e11b7223e546515e99c984f9948b6caa06622a""><code>f4e11b7</code></a> chore: update version</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/bf4a9a8eb24149cd68efbc6ae61a6445121f4b70""><code>bf4a9a8</code></a> chore: update setup.py</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/f028cc793e3a2c519be6a52a49fb77ff0b014c9b""><code>f028cc7</code></a> [feat] regenerate client for v1.19.15 (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/172"">#172</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/c876bce774cebdb1eec90c8c957a7b45ec3c1404""><code>c876bce</code></a> chore: update changlog</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/e625e8d296aa8f68d5b0a285e0414c43877f63f5""><code>e625e8d</code></a> [feat] Load kubeconfig from dict (<a href=""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:15140,depend,dependabot,15140,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['depend'],['dependabot']
Integrability," [required] │; │ arguments [ARGUMENTS]... You should use -- if you want to pass option-like arguments through. [default: None] │; ╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯; ╭─ Options ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮; │ --files TEXT Files or directories to add to the working directory of the job. [default: None] │; │ --name TEXT The name of the batch. │; │ --image-name TEXT Name of Docker image for the job (default: hailgenetics/hail) [default: None] │; │ --output -o [text|yaml|json] [default: text] │; │ --help Show this message and exit. │; ╰────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯. (base) dking@wm28c-761 hail % ; (base) dking@wm28c-761 hail % hailctl hdinsight submit --help ; ; Usage: hailctl hdinsight submit [OPTIONS] NAME STORAGE_ACCOUNT HTTP_PASSWORD ; SCRIPT [ARGUMENTS]... ; ; Submit a job to an HDInsight cluster configured for Hail. ; If you wish to pass option-like arguments you should use ""--"". For example: ; ; $ hailctl hdinsight submit name account password script.py --image-name docker.io/image my_script.py -- some-argument --animal dog ; ; ╭─ Arguments ──────────────────────────────────────────────────────────────────────────────────────────",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13447#issuecomment-1681403012:1859,message,message,1859,https://hail.is,https://github.com/hail-is/hail/pull/13447#issuecomment-1681403012,1,['message'],['message']
Integrability," [tqdm](https://github.com/tqdm/tqdm) from 4.42.1 to 4.64.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/tqdm/tqdm/releases"">tqdm's releases</a>.</em></p>; <blockquote>; <h2>tqdm v4.64.1 stable</h2>; <ul>; <li>support <code>ipywidgets&gt;=8</code> (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1366"">#1366</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1361"">#1361</a> &lt;- <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1310"">#1310</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1359"">#1359</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1360"">#1360</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1364"">#1364</a>); <ul>; <li>fix jupyter lab display</li>; <li>update notebook tests</li>; </ul>; </li>; </ul>; <h2>tqdm v4.64.0 stable</h2>; <ul>; <li>add <code>contrib.slack</code> (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1313"">#1313</a>)</li>; </ul>; <h2>tqdm v4.63.2 stable</h2>; <ul>; <li><code>rich</code>: expose <code>options</code> kwargs (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1282"">#1282</a>)</li>; <li><code>autonotebook</code>: re-enable VSCode (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1309"">#1309</a>)</li>; <li>misc docs typos (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1301"">#1301</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1299"">#1299</a>)</li>; <li>update dev dependencies (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1311"">#1311</a>)</li>; </ul>; <h2>tqdm v4.63.1 stable</h2>; <ul>; <li>fix stderr/stdout missing <code>flush()</code> (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1248"">#1248</a> &lt;- <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1177"">#1177</a>)</li>; <li>misc speed improvements/optimisations</li>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12260:1000,depend,dependabot,1000,https://hail.is,https://github.com/hail-is/hail/pull/12260,1,['depend'],['dependabot']
Integrability," __repr__(self):. /opt/conda/miniconda3/lib/python3.8/site-packages/hail/table.py in _ascii_str(self); 1318 return s; 1319; -> 1320 rows, has_more, dtype = self.data(); 1321 fields = list(dtype); 1322 trunc_fields = [trunc(f) for f in fields]. /opt/conda/miniconda3/lib/python3.8/site-packages/hail/table.py in data(self); 1302 row_dtype = t.row.dtype; 1303 t = t.select(**{k: hl._showstr(v) for (k, v) in t.row.items()}); -> 1304 rows, has_more = t._take_n(self.n); 1305 self._data = (rows, has_more, row_dtype); 1306 return self._data. /opt/conda/miniconda3/lib/python3.8/site-packages/hail/table.py in _take_n(self, n); 1449 has_more = False; 1450 else:; -> 1451 rows = self.take(n + 1); 1452 has_more = len(rows) > n; 1453 rows = rows[:n]. <decorator-gen-1116> in take(self, n, _localize). /opt/conda/miniconda3/lib/python3.8/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 575 def wrapper(__original_func, *args, **kwargs):; 576 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 577 return __original_func(*args_, **kwargs_); 578; 579 return wrapper. /opt/conda/miniconda3/lib/python3.8/site-packages/hail/table.py in take(self, n, _localize); 2119 """"""; 2120; -> 2121 return self.head(n).collect(_localize); 2122; 2123 @typecheck_method(n=int). <decorator-gen-1110> in collect(self, _localize). /opt/conda/miniconda3/lib/python3.8/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 575 def wrapper(__original_func, *args, **kwargs):; 576 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 577 return __original_func(*args_, **kwargs_); 578; 579 return wrapper. /opt/conda/miniconda3/lib/python3.8/site-packages/hail/table.py in collect(self, _localize); 1918 e = construct_expr(rows_ir, hl.tarray(t.row.dtype)); 1919 if _localize:; -> 1920 return Env.backend().execute(e._ir); 1921 else:; 1922 return e. /opt/conda/miniconda3/lib/python3.8",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:3586,wrap,wrapper,3586,https://hail.is,https://github.com/hail-is/hail/issues/10682,3,['wrap'],['wrapper']
Integrability," _v41-0-3:; </code></pre></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pyca/cryptography/commit/fc11bce6930e591ce26a2317b31b9ce2b3e25512""><code>fc11bce</code></a> bump for 41.0.4 (<a href=""https://redirect.github.com/pyca/cryptography/issues/9629"">#9629</a>)</li>; <li>See full diff in <a href=""https://github.com/pyca/cryptography/compare/41.0.3...41.0.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=41.0.3&new-version=41.0.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13685:1367,depend,dependabot-automerge-start,1367,https://hail.is,https://github.com/hail-is/hail/pull/13685,6,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability," ```. ### What went wrong (all error messages here, including the full java stack trace):. ```; <StructExpression of type struct{}>; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-51-e812f4924948> in <module>(); 1 print(metrics_ht['vqsr'].globals); ----> 2 hl.eval_expr(metrics_ht['vqsr'].globals). /home/hail/hail.zip/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). /home/hail/hail.zip/hail/expr/expressions/expression_utils.py in eval_expr(expression); 135 Result of evaluating `expression`.; 136 """"""; --> 137 return eval_expr_typed(expression)[0]; 138 ; 139 . /home/hail/hail.zip/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). /home/hail/hail.zip/hail/expr/expressions/expression_utils.py in eval_expr_typed(expression); 169 analyze('eval_expr_typed', expression, Indices(expression._indices.source)); 170 ; --> 171 return expression.collect()[0], expression.dtype; 172 ; 173 . /home/hail/hail.zip/hail/expr/expressions/base_expression.py in collect(self); 755 """"""; 756 uid = Env.get_uid(); --> 757 t = self._to_table(uid); 758 return [r[uid] for r in t._select(""collect"", None, hl.struct(**{uid: t[uid]})).collect()]; 759 . /home/hail/hail.zip/hail/expr/expressions/base_expression.py in _to_table(self, name); 584 source = source.select_globals(**{uid: self}); 585 df = Env.dummy_table(); --> 586 df = df.select(**{name: source.index_globals()[uid]}); 587 return df; 588 elif len(axes) == 1:. /home/hail/hail.zip/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kw",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3728:1269,wrap,wrapper,1269,https://hail.is,https://github.com/hail-is/hail/issues/3728,3,['wrap'],['wrapper']
Integrability," ```; MakeStruct(WrappedArray((elements,Let(__iruid_5,GetField(Literal(struct{rows: array<struct{a: int32, b: str}>, global: struct{x: str}},[ArrayBuffer([0,row0]),[global]]),rows),ToArray(StreamMap(StreamRange(Let(__iruid_6,If(ApplyComparisonOp(LT(int32,int32),ArrayLen(Ref(__iruid_5,array<struct{a: int32, b: str}>)),I32(16)),ArrayLen(Ref(__iruid_5,array<struct{a: int32, b: str}>)),I32(16)),Let(__iruid_7,ApplyBinaryPrimOp(RoundToNegInfDivide(),ArrayLen(Ref(__iruid_5,array<struct{a: int32, b: str}>)),Ref(__iruid_6,int32)),Let(__iruid_8,ApplyBinaryPrimOp(Subtract(),ArrayLen(Ref(__iruid_5,array<struct{a: int32, b: str}>)),ApplyBinaryPrimOp(Multiply(),Ref(__iruid_7,int32),Ref(__iruid_6,int32))),If(ApplyComparisonOp(GTEQ(int32,int32),Ref(__iruid_6,int32),I32(1)),If(ApplyComparisonOp(GT(int32,int32),Ref(__iruid_8,int32),I32(0)),If(ApplyComparisonOp(LT(int32,int32),Ref(__iruid_8,int32),I32(1)),ApplyBinaryPrimOp(Add(),ApplyBinaryPrimOp(Multiply(),Ref(__iruid_7,int32),I32(1)),Ref(__iruid_8,int32)),ApplyBinaryPrimOp(Multiply(),ApplyBinaryPrimOp(Add(),Ref(__iruid_7,int32),I32(1)),I32(1))),ApplyBinaryPrimOp(Multiply(),Ref(__iruid_7,int32),I32(1))),I32(0))))),ApplyBinaryPrimOp(Add(),Let(__iruid_6,If(ApplyComparisonOp(LT(int32,int32),ArrayLen(Ref(__iruid_5,array<struct{a: int32, b: str}>)),I32(16)),ArrayLen(Ref(__iruid_5,array<struct{a: int32, b: str}>)),I32(16)),Let(__iruid_7,ApplyBinaryPrimOp(RoundToNegInfDivide(),ArrayLen(Ref(__iruid_5,array<struct{a: int32, b: str}>)),Ref(__iruid_6,int32)),Let(__iruid_8,ApplyBinaryPrimOp(Subtract(),ArrayLen(Ref(__iruid_5,array<struct{a: i",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8599#issuecomment-617899349:430,Wrap,WrappedArray,430,https://hail.is,https://github.com/hail-is/hail/pull/8599#issuecomment-617899349,1,['Wrap'],['WrappedArray']
Integrability," `advance()` turns the page, `isValid` asks if the page you are on is non-empty, and `value` gives you the value on the current page (which is an error if the page is empty). `StagingIterator` is a subtype of `FlipbookIterator` which adds a bit of state to each page, together with the methods `consume()` and `stage()`. The bit of state on each page tracks whether the value has been ""consumed"" yet. `consume()` can only be called on a valid page which has not yet been consumed, and marks it as consumed. Note that `consume()` does not actually turn the page, so that the value just consumed is kept alive for the consumer to use. `stage()` brings the iterator forward to the next state in which we are on an unconsumed page: if the current page has been consumed, it flips to the next page, but if the current page has not been consumed it does nothing. My goal with the `StagingIterator` interface was to find something simple—to make it easier to write iterator code that is easily understandable and obviously correct and bug-free—and which covers most of the low-level (and bug-prone) ""bookkeeping"" I could find in current iterator code. The `StagingIterator` interface is also needed to implement the Scala `Iterator` methods, and for that reason I made it so that every `FlipbookIterator` is really a `StagingIterator` with a restricted interface, so that `FlipbookIterator` is able to subtype (`BufferedIterator`, and therefore) `Iterator`. The tiny abstract class `StateMachine` can be thought of as a ""naked"" `FlipbookIterator`, with only the core interface methods and without any runtime checking. It is intended to be used only for defining a new `FlipbookIterator` or `StagingIterator`, through the factory methods on their respective companion objects which take a `StateMachine`. I implemented `fliterWhere`, `map`, and `flatMap` on `FlipbookIterator`, allowing the use of for–comprehensions, and on top of that I defined all the varieties of join. Some of the join methods take `Or",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3016:2524,interface,interface,2524,https://hail.is,https://github.com/hail-is/hail/pull/3016,1,['interface'],['interface']
Integrability," `f: (...) => A` to `f: (...) => StackFrame[A]`. Where the former evaluates, executing all recursive calls, and then returns the `A` result, the later returns a description of the work to be done before making any recursive calls. The method `StackFrame[A].run(): A` executes that description in a non-recursive loop. `StackFrame` is a monad, implementing `map` and `flatMap`, which allows the `for` syntactic sugar to be used. When a method makes several recursive calls, this can be significantly more readable. The public api is small. There are the free functions; ```scala; def done[A](result: A): StackFrame[A]; def call[A](body: => StackFrame[A]): StackFrame[A]; ```; and the methods; ```scala; abstract class StackFrame[A] {; def flatMap[B](f: A => StackFrame[B]): StackFrame[B]; def map[B](f: A => B): StackFrame[B] = flatMap(a => Done(f(a))); def run(): A; }; ```; `done` is basically the return statement. `call` is very important: it wraps a recursive call in a thunk, so that returning a `StackFrame` doesn't require descending all the way to the leaves of the recursion. The basic rule is that any cycle of mutually recursive function calls must have at least one `call` on the cycle. Trying to keep it to just one `call` per cycle minimizes the number of closures that must be allocated. As an example, `NormalizeNames.normalizeIR` now returns `StackFrame[BaseIR]`, and `def apply(ir: BaseIR): BaseIR` calls `normalizeIR(ir, ...).run()` to actually run the traversal. The case for `Let` in `normalizeIR` is rewritten from; ```scala; case Let(name, value, body) =>; val newName = gen(); Let(newName, normalize(value), normalize(body, env.copy(eval = env.eval.bind(name, newName)))); ```; to; ```scala; case Let(name, value, body) =>; val newName = gen(); for {; newValue <- normalize(value); newBody <- normalize(body, env.copy(eval = env.eval.bind(name, newName))); } yield Let(newName, newValue, newBody); ```; or without the sugar; ```scala; case Let(name, value, body) =>; val newNa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9320:1890,wrap,wraps,1890,https://hail.is,https://github.com/hail-is/hail/pull/9320,1,['wrap'],['wraps']
Integrability," `f` is a degree-p polynomial. We can combine the above into an estimator for the p-th spectral moment, `𝜇_p = ∑_i 𝜆_i^p`. We get an unbiased estimator by generating a random vector `v`, and using `E(v' (A'A)^p v) = tr((A'A)^p) = 𝜇_p`. The estimator can be computed exactly using the Krylov factorization as above, i.e. `v' (A'A)^p v = V_1[0, :] S^{2p} V_1[0, :]'`. But this estimator has large variance, so we can just average over many independent estimators. We combine `k` random vectors into a random matrix `V_0`, compute `_krylov_factorization(A, V_0, p)`, and then `V'_0 (A'A)^p V_0 = V_1[:k, :] f(S^2) V_1[:k, :]'`, from which we can average the individual estimates. This spectral moments estimator is implemented in `KrylovFactorization.spectral_moments`. # SVD and moments; Finally, in practice we may need to average over too many estimators to get the desired accuracy, so we use one more trick to bring down the variance. This depends on the following property:; * If `Q` is an orthonormal matrix, then `tr(X) = tr(QQ'XQQ') + tr((I-QQ')X(I-QQ'))`, i.e. the trace decomposes into a sum of the traces on the projection onto the subspace spanned by `Q`, and the projection onto its complement. To see this, use the additivity and cyclicity of the trace (`tr(X+Y) = tr(X) + tr(Y)`, `tr(XY) = tr(YX)`). In particular, cyclicity implies `tr(QQ'XQQ') = tr(QQ'X) = tr(XQQ')`. Now we do two passes. In the first pass, we use some method (such as a Krylov factorization) to compute an orthonormal basis `V` for a subspace which approximates the dominant subspace. Even if this is not a very accurate approximation, the result is that `tr(QQ' X^p QQ')` is much larger than the complement `tr((I-QQ')X^p(I-QQ'))`. But the former we can compute exactly, and all the error comes from our estimate of the much smaller piece. This variance reduction trick is implemented in `_pca_and_moments`, which computes two Krylov factorizations. The first is used to compute the principal components, and the `V`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11045:3348,depend,depends,3348,https://hail.is,https://github.com/hail-is/hail/pull/11045,1,['depend'],['depends']
Integrability," a 35K cohort. The VCF format of chr1 is 2.4T.; > ; > Heh. So, yes, ""project"" VCFs grow super-linearly in the number of samples. I (and others) are currently pushing very hard for the VCF spec to support two sparse representations: ""local alleles"" ([samtools/hts-specs#434](https://github.com/samtools/hts-specs/pull/434)) and ""reference blocks"" ([samtools/hts-specs#435](https://github.com/samtools/hts-specs/pull/435)). When using these two sparse representations, you should be able to store 35,000 whole genomes in ~10TiB of GZIP-compressed VCF.; > ; > What is your calling pipeline? Do you generate GVCFs? If yes, I strongly recommend you use the [VDS Combiner](https://hail.is/docs/0.2/vds/hail.vds.combiner.VariantDatasetCombiner.html#hail.vds.combiner.VariantDatasetCombiner) to produce a [VDS](https://hail.is/docs/0.2/vds/index.html). You can read more details in [this recent preprint we wrote](https://www.biorxiv.org/content/10.1101/2024.01.09.574205v1.full.pdf), but a VDS of 35,000 whole genomes should be a few terabytes. I'd guess 4 TiB, but it depends on your reference block granularity. I strongly recommend using size 10 GQ buckets. Looks like VDS is a better solution than HailMatrix. However, we got the joint call result as vcf alreay. Can VDS Combiner read joint call VCF and then save it as VDS format? I cannot find any example to transfer VCF to VDS. Thanks. > ; > > I don't know the Kryo JAR. I tested on both docker images hailgenetics/hail:0.2.126-py3.11 and hailgenetics/hail:0.2.127-py3.11.; > ; > Those should use Kryo 4.0.2. OK. My conclusion is that Kryo still has a bug preventing the serialization of very large objects. This becomes a limitation in Hail: we cannot support PLINK files with tens of millions of variants. Our community is largely transitioning to GVCFs and VDS, so I doubt we'll improve our PLINK1 importer to support such large PLINK1 files. That said, PRs are always welcome if loading such large PLINK1 files is a hard requirement for you all.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14168#issuecomment-1937459344:1073,depend,depends,1073,https://hail.is,https://github.com/hail-is/hail/issues/14168#issuecomment-1937459344,1,['depend'],['depends']
Integrability," a <code>Traversable</code>; representing a directory and (when needed) renders the; full tree to a temporary directory.</li>; </ul>; <h1>v5.8.1</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_resources/issues/253"">#253</a>: In <code>MultiplexedPath</code>, restore expectation that; a compound path with a non-existent directory does not; raise an exception.</li>; </ul>; <h1>v5.8.0</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_resources/issues/250"">#250</a>: Now <code>Traversable.joinpath</code> provides a concrete; implementation, replacing the implementation in <code>.simple</code>; and converging with the behavior in <code>MultiplexedPath</code>.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/python/importlib_resources/commit/31102947fd9babef636d3b82c2a5d58883f9c1f5""><code>3110294</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/python/importlib_resources/issues/255"">#255</a> from python/feature/228-directory-of-resources</li>; <li><a href=""https://github.com/python/importlib_resources/commit/bac6e8e3e6c681d923e1ec78b6f670cee0883ea3""><code>bac6e8e</code></a> Extract function for _is_present_dir.</li>; <li><a href=""https://github.com/python/importlib_resources/commit/9afeb056dfabf8c8cc497cddbabe9ebcd70ff82d""><code>9afeb05</code></a> Merge branch 'main' into feature/228-directory-of-resources</li>; <li><a href=""https://github.com/python/importlib_resources/commit/b8da8446d72b6dbaa34a8fa0f6d0dae238bf00f6""><code>b8da844</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/python/importlib_resources/issues/254"">#254</a> from python/bugfix/253-multiplexed-path-compound-path...</li>; <li><a href=""https://github.com/python/importlib_resources/commit/5a14cdcdfceac0427651af9f4021852c00a507a2""><code>5a14cdc</code></a> Merge branch 'main' of <a href=""https://github.com/python/importlib_re",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12141:1454,depend,dependabot,1454,https://hail.is,https://github.com/hail-is/hail/pull/12141,1,['depend'],['dependabot']
Integrability," a crash in the <code>modified-iterating-dict</code> checker involving instance attri...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/9b359ad676dff97a35321976c19ca0f6c4fc44ad""><code>9b359ad</code></a> Fix <code>unhashable-member</code> crash when <code>lambda</code> used as a dict key (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7454"">#7454</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/5716ad10104a9553ef9d64404b044c04947889b2""><code>5716ad1</code></a> Bump pylint to 2.15.2, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/49b5d5dae6cc49d0572ffa35ae07f46ddc85fa61""><code>49b5d5d</code></a> Upgrade astroid version following 2.12.9 release</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/v2.13.5...v2.15.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pylint&package-manager=pip&previous-version=2.13.5&new-version=2.15.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` wi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12240:2602,depend,dependency-name,2602,https://hail.is,https://github.com/hail-is/hail/pull/12240,1,['depend'],['dependency-name']
Integrability," a data provider during failures by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2820"">cbeust/testng#2820</a></li>; <li>Refactoring by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2821"">cbeust/testng#2821</a></li>; <li>Fixing bug with DataProvider retry by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2822"">cbeust/testng#2822</a></li>; <li>Add config key for callback discrepancy behavior by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2823"">cbeust/testng#2823</a></li>; <li>Upgrading versions by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2824"">cbeust/testng#2824</a></li>; <li>Fix <a href=""https://github-redirect.dependabot.com/cbeust/testng/issues/2770"">#2770</a>: FileAlreadyExistsException on copy by <a href=""https://github.com/melloware""><code>@​melloware</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2827"">cbeust/testng#2827</a></li>; <li>JarFileUtils.delete(File f) throw actual exception (instead of FileNotFound) when file cannot be deleted <a href=""https://github-redirect.dependabot.com/cbeust/testng/issues/2825"">#2825</a> by <a href=""https://github.com/speedythesnail""><code>@​speedythesnail</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2826"">cbeust/testng#2826</a></li>; <li>GITHUB-2830 - Failsafe parameter.toString by <a href=""https://github.com/seregamorph""><code>@​seregamorph</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2831"">cbeust/testng#2831</a></li>; <li>Changing assertion mes",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:4301,depend,dependabot,4301,https://hail.is,https://github.com/hail-is/hail/pull/12665,1,['depend'],['dependabot']
Integrability," a few typos</li>; <li><a href=""https://github.com/oauthlib/oauthlib/commit/bdc486e2bc3a188027a4ebec3a3013e64023ce62""><code>bdc486e</code></a> Fixed isort imports</li>; <li><a href=""https://github.com/oauthlib/oauthlib/commit/7db45bda96ea6f5fde1186e8fd43d75ce6b95ab5""><code>7db45bd</code></a> Fix typo in server.rst</li>; <li><a href=""https://github.com/oauthlib/oauthlib/commit/b14ad85921db2406ecaf5927a8be08a7566c236e""><code>b14ad85</code></a> chore: s/bode_code_verifier/body_code_verifier/g</li>; <li><a href=""https://github.com/oauthlib/oauthlib/commit/b123283ba3d41acb3e787fdf68bd5907972b4bad""><code>b123283</code></a> Allow non-HTTPS issuer when OAUTHLIB_INSECURE_TRANSPORT. (<a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/issues/803"">#803</a>)</li>; <li><a href=""https://github.com/oauthlib/oauthlib/commit/2f887b5a070bf617a471c573ad52fb58251c61af""><code>2f887b5</code></a> Docs: fix Sphinx warnings for better ReadTheDocs generation (<a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/issues/807"">#807</a>)</li>; <li><a href=""https://github.com/oauthlib/oauthlib/commit/d4bafd9f1d0eba3766e933b1ac598cbbf37b8914""><code>d4bafd9</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/issues/797"">#797</a> from cclauss/patch-2</li>; <li>Additional commits viewable in <a href=""https://github.com/oauthlib/oauthlib/compare/v3.2.0...v3.2.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=oauthlib&package-manager=pip&previous-version=3.2.0&new-version=3.2.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: #",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12197:6437,depend,dependabot,6437,https://hail.is,https://github.com/hail-is/hail/pull/12197,2,['depend'],['dependabot']
Integrability," a kind of compilation process. Dev dependencies are pruned, the app is split into static bundles, and minified. Some optimizations, like inlining of some React functions also occurs. This is independent of anything V8 does . This will also show a neat readout of all bundles:; ```; Browser assets sizes after gzip:. 2.79 kB .next/static/gZEz****/pages/_app.js; 2.42 kB .next/static/gZEz****/pages/_error.js; 502 B .next/static/gZEz****/pages/auth0callback.js; 349 B .next/static/gZEz****/pages/index.js; 745 B .next/static/gZEz****/pages/notebook.js; 856 B .next/static/gZEz****/pages/scorecard.js; 243 B .next/static/gZEz****/pages/tutorial.js; 99.4 kB .next/static/chunks/commons.294f****.js; 101 B .next/static/chunks/styles.9f25****.js; 450 B .next/static/css/commons.b770adbe.chunk.css; 5.74 kB .next/static/css/styles.4f393762.chunk.css; 6.93 kB .next/static/runtime/main-76ed****.js; 737 B .next/static/runtime/webpack-8917****.js; ```. Bundling cutoffs can be tweaked, but basically any common dependencies between pages are placed into one chunk. Chunks are loaded in parallel, and no chunks are needed to load the page; it's just HTML on initial render. At least some of the chunks could theoretically be served from a CDN (styles of course, some js). Each package expects a .env file, which organizes the environment variables used in that package. This can be used with Kubernetes. `kubectl create secret generic secretesfile --from-file=prod/env.txt`. The .env for the web app, where localhost would be replaced by our sub.domain. If you get it running, you may notice there isn't a way to log out... I ripped out all of the UI stuff after speaking with Cotton, and began writing a minimal interface. Just clear the cookie if you need to log out. ```; AUTH0_CLIENT_ID=TD78k23CcdM4pMWoYZwYwKJbQPBj06jY; AUTH0_DOMAIN=hail.auth0.com; AUTH0_SCOPE='opened profile repo read:users read:user_idp_tokens'; AUTH0_AUDIENCE='hail'; AUTH0_REDIRECT_URI='https://localhost/auth0callback'; SCORECARD_U",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931#issuecomment-454271935:1661,depend,dependencies,1661,https://hail.is,https://github.com/hail-is/hail/pull/4931#issuecomment-454271935,2,['depend'],['dependencies']
Integrability," a long or tuple of longs which is guaranteed to be distinct on every execution of `child`.; * Uids are typically created at the leaves of pipelines (`TableRead`, `StreamRange`, etc.), and propagated upwards. There was a phase-ordering conflict that had to be worked around:; * IRs must be given explict rng state and uid semantics as early as possible, to ensure determinism.; * The transformation to explicitly pass rng states and uids must happen during IR construction. If it happened later, it would create new IR objects, which would defeat the python CSE pass (which only recognizes equivalent subexpressions when they are represented by the same python object).; * The rng explication requires some type information.; * Types on the python IR are assigned after the IR is fully constructed. To fix this:; * `Ref`'s must be given a type at construction; * `TopLevelReference`s are the only case that needs to be constructed before a type is known. But they are always constructed wrapped in a `SelectFields` or `GetField`, whose type is known at construction. I added new IR classes `SelectedTopLevelReference` and `ProjectedTopLevelReference` for these two cases, which are thin wrappers which don't appear in the rendered IR.; * `construct_expr` always assigns a type to the ir. Bottom-up type construction will later assert equality with the assigned type. This caught some existing bugs, where expression type and ir type didn't agree.; * At construction of the root node of a stream/table/matrixtable pipeline (i.e. a non-stream value ir with at least one stream/table/matrixtable child), recursively rewrite the contained pipeline(s) to make rng states and uids explicit. This is safe, since stream/table/matrixtable IRs won't be CSE'd, because they may only be evaluated once. Contained value IRs are not rewritten, only wrapped with bindings which define the rng state. These are currently non-functional changes, as `ApplySeeded` still uses the old rng, and will ignore the rng state.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11847:1454,wrap,wrapped,1454,https://hail.is,https://github.com/hail-is/hail/pull/11847,3,['wrap'],"['wrapped', 'wrappers']"
Integrability," an array insi...</li>; <li><a href=""https://github.com/apache/spark/commit/31dfbdeb1b076f521bc3fa4fd9b97e425c20da31""><code>31dfbde</code></a> [SPARK-37871][TESTS] Use <code>python3</code> instead of <code>python</code> in BaseScriptTransform...</li>; <li><a href=""https://github.com/apache/spark/commit/deb6776b705423141abe92715c3d93b23f082503""><code>deb6776</code></a> [SPARK-37866][TESTS] Set <code>file.encoding</code> to UTF-8 for SBT tests</li>; <li><a href=""https://github.com/apache/spark/commit/db1023c728c5e0bdcd4ef457cf5f7ba4f13cb79d""><code>db1023c</code></a> [SPARK-37860][UI] Fix taskindex in the stage page task event timeline</li>; <li>Additional commits viewable in <a href=""https://github.com/apache/spark/compare/v3.1.1...v3.2.1"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11547:2385,depend,dependabot-automerge-start,2385,https://hail.is,https://github.com/hail-is/hail/pull/11547,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability," and &quot;runWhen&quot; options to interceptors api (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2702"">#2702</a>)</li>; <li>Updating of transformResponse (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3377"">#3377</a>)</li>; <li>Adding ability to omit User-Agent header (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3703"">#3703</a>)</li>; <li>Adding multiple JSON improvements (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3688"">#3688</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3763"">#3763</a>)</li>; <li>Fixing quadratic runtime and extra memory usage when setting a maxContentLength (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3738"">#3738</a>)</li>; <li>Adding parseInt to config.timeout (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3781"">#3781</a>)</li>; <li>Adding custom return type support to interceptor (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3783"">#3783</a>)</li>; <li>Adding security fix for ReDoS vulnerability (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3980"">#3980</a>)</li>; </ul>; <p>Internal and Tests:</p>; <ul>; <li>Updating build dev dependancies (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3401"">#3401</a>)</li>; <li>Fixing builds running on Travis CI (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3538"">#3538</a>)</li>; <li>Updating follow rediect version (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3694"">#3694</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3771"">#3771</a>)</li>; <li>Updating karma sauce launcher to fix failing sauce tests (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3712"">#3712</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3717"">#3717</a>)</li>; <li>Updating content-type header for application/json to not contain charset fiel",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:1517,depend,dependabot,1517,https://hail.is,https://github.com/hail-is/hail/pull/11080,4,['depend'],['dependabot']
Integrability," and 3.7 (<a href=""https://redirect.github.com/pyasn1/pyasn1-modules/issues/14"">#14</a>)</li>; <li><a href=""https://github.com/pyasn1/pyasn1-modules/commit/9ec54091547330aaf994e82ba759cb1fe071e070""><code>9ec5409</code></a> Drop support for EOL Python 2.7 (<a href=""https://redirect.github.com/pyasn1/pyasn1-modules/issues/12"">#12</a>)</li>; <li><a href=""https://github.com/pyasn1/pyasn1-modules/commit/252ac00bf1e119a044cc579ffade30164e2cdfff""><code>252ac00</code></a> Add support for Python 3.12 (<a href=""https://redirect.github.com/pyasn1/pyasn1-modules/issues/11"">#11</a>)</li>; <li>See full diff in <a href=""https://github.com/pyasn1/pyasn1-modules/compare/v0.3.0...v0.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyasn1-modules&package-manager=pip&previous-version=0.3.0&new-version=0.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14472:2413,depend,dependabot-security-updates,2413,https://hail.is,https://github.com/hail-is/hail/pull/14472,1,['depend'],['dependabot-security-updates']
Integrability," and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if server does not send <code>WWW-Authenticate</code> header in 401 response</li>; <li>Log request and response headers in debug mode</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.4.1 and 7.4.2</li>; <li>Update dependencies</li>; </ul>; <h2>5.0.5</h2>; <p>Maintenance:</p>; <ul>; <li>Publish signed artifacts to Gradle plugin portal</li>; <li>Update dependencies</li>; </ul>; <h2>5.0.4</h2>; <p>Bug fixes:</p>; <ul>; <li>Fix deadlock in <code>DownloadExtension</code> if <code>max-workers</code> equals 1 (thanks to <a href=""https://github.com/beatbrot""><code>@​beatbrot</code></a> for spotting this, see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/205"">#205</a>)</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/1b5d69760d19cb7f88cbc837ee46456c494c0696""><code>1b5d697</code></a> Bump up version number to 5.2.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/7d6de83037ca41cd2f2f31830b43e43720e45b3a""><code>7d6de83</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/1da8f078e22412475b694ce07b890148b8a5e4fc""><code>1da8f07</code></a> Add comment</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/9703f764df56c52626f7d6f44bca8b1d51312389""><code>9703f76</code></a> Use pooling connection manager instead of basic one</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/306172e4c6532e185c8a6a9998bca7d22d2d0c63""><code>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:2845,depend,dependencies,2845,https://hail.is,https://github.com/hail-is/hail/pull/12332,1,['depend'],['dependencies']
Integrability," and <a href=""https://github.com/adamchainz""><code>@​adamchainz</code></a>!</li>; <li>Fix incorrect documentation for <a href=""https://www.curlylint.org/docs/rules/no_autofocus""><code>no_autofocus</code></a> and <a href=""https://www.curlylint.org/docs/rules/tabindex_no_positive""><code>tabindex_no_positive</code></a>.</li>; </ul>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.13.0"">v0.13.0</a> 2021-04-25</h2>; <p>This release comes with a blog post! Read on <a href=""https://www.curlylint.org/blog/quality-of-life-improvements"">Quality-of-life improvements</a>.</p>; <h3>Added</h3>; <ul>; <li>Implement --template-tags CLI flag (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/25"">#25</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/77"">#77</a>).</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Add more descriptive error message for missing whitespace between HTML attributes (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/23#issuecomment-700622837"">#23 (comment)</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; <li>Move development dependencies from extras to separate <code>requirements.txt</code> (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; <li>Declare support for Python 3.9.</li>; <li>Tentatively declare support for Python 3.10 (tested with <code>Python 3.10.0a6+</code>).</li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Fix Python 3.10 deprecation warning by importing Iterable from collections.abc (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; </ul>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.12.2"">v0.12.2</a> 2021-03-06</h2>; <h3>Fixed</h3>; <ul>; <li>The <code>image_alt</code> rule no longer crashes when encountering template conditionals in img attributes (<a href=""https://github-redirect.dep",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11713:5142,depend,dependabot,5142,https://hail.is,https://github.com/hail-is/hail/pull/11713,1,['depend'],['dependabot']
Integrability," and <code>password</code> instead.</li>; <li>old_password authentication method (used by MySQL older than 4.1) is not supported.</li>; <li>MySQL 5.5 and MariaDB 5.5 are not officially supported, although it may still works.</li>; <li>Removed <code>escape_dict</code>, <code>escape_sequence</code>, and <code>escape_string</code> from <code>pymysql</code>; module. They are still in <code>pymysql.converters</code>.</li>; </ul>; <p>Other changes:</p>; <ul>; <li>Connection supports context manager API. <code>__exit__</code> closes the connection. (<a href=""https://github-redirect.dependabot.com/PyMySQL/PyMySQL/issues/886"">#886</a>)</li>; <li>Add MySQL Connector/Python compatible TLS options (<a href=""https://github-redirect.dependabot.com/PyMySQL/PyMySQL/issues/903"">#903</a>)</li>; <li>Major code cleanup; PyMySQL now uses black and flake8.</li>; </ul>; <h2>v0.10.1</h2>; <p>Release date: 2020-09-10</p>; <ul>; <li>Fix missing import of ProgrammingError. (<a href=""https://github-redirect.dependabot.com/PyMySQL/PyMySQL/issues/878"">#878</a>)</li>; <li>Fix auth switch request handling. (<a href=""https://github-redirect.dependabot.com/PyMySQL/PyMySQL/issues/890"">#890</a>)</li>; </ul>; <h2>v0.10.0</h2>; <p>Release date: 2020-07-18</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/b12efdb6c1baa55e58a4384271e33a7351d554d5""><code>b12efdb</code></a> v1.0.2</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/abe83c262ea647a09e0f13587fa91d6a14a71598""><code>abe83c2</code></a> Make 4 more arguments to keyword-only. (<a href=""https://github-redirect.dependabot.com/PyMySQL/PyMySQL/issues/941"">#941</a>)</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/5c6f8bcb741c32719a07e8c95eb8050cb9249511""><code>5c6f8bc</code></a> v1.0.1</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/2d36a195060b46e12f16d8b776468bab53ea6919""><code>2d36a19<",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11595:2392,depend,dependabot,2392,https://hail.is,https://github.com/hail-is/hail/pull/11595,1,['depend'],['dependabot']
Integrability," and BlobInfo.metadata (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1843"">#1843</a>) (<a href=""https://github.com/googleapis/java-storage/commit/c8bf3c70cca81ed87a52939fe7da58889c8f55ce"">c8bf3c7</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Document differing behavior of {get,list}{,default}Acl between HTTP and gRPC (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1820"">#1820</a>) (<a href=""https://github.com/googleapis/java-storage/commit/9511b173e84d2b28ab1a1625b16e3e648c3856fb"">9511b17</a>)</li>; </ul>; <h3>Dependencies</h3>; <ul>; <li>Update dependency com.google.cloud:google-cloud-shared-dependencies to v3.1.1 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1836"">#1836</a>) (<a href=""https://github.com/googleapis/java-storage/commit/3b71fab11ac71039c2a9983821ce02ce25ce311d"">3b71fab</a>)</li>; <li>Update dependency net.jqwik:jqwik to v1.7.2 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1833"">#1833</a>) (<a href=""https://github.com/googleapis/java-storage/commit/83bc261130e89e5994f21e32422054ef6ea2fe8e"">83bc261</a>)</li>; <li>Update dependency org.junit.vintage:junit-vintage-engine to v5.9.2 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1837"">#1837</a>) (<a href=""https://github.com/googleapis/java-storage/commit/5b381845b4f48a691aa3f0cb96599ddefc7e463f"">5b38184</a>)</li>; <li>Update junit-platform.version to v5.9.2 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1838"">#1838</a>) (<a href=""https://github.com/googleapis/java-storage/commit/372521ba80b12e52c74fae5ac766dbe6610ff0b2"">372521b</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.15.1...v2.16.0"">2.16.0</a> (2022-12-06)</h2>; <h3>Features</h3>; <ul>; <li>Add {Compose,Rewrite,StartResumableWrite}Request.object_checksums and Bucket.RetentionPolicy.retention_duration (<a href=""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12598:12192,depend,dependabot,12192,https://hail.is,https://github.com/hail-is/hail/pull/12598,1,['depend'],['dependabot']
Integrability," and BlobInfo.metadata (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1843"">#1843</a>) (<a href=""https://github.com/googleapis/java-storage/commit/c8bf3c70cca81ed87a52939fe7da58889c8f55ce"">c8bf3c7</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Document differing behavior of {get,list}{,default}Acl between HTTP and gRPC (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1820"">#1820</a>) (<a href=""https://github.com/googleapis/java-storage/commit/9511b173e84d2b28ab1a1625b16e3e648c3856fb"">9511b17</a>)</li>; </ul>; <h3>Dependencies</h3>; <ul>; <li>Update dependency com.google.cloud:google-cloud-shared-dependencies to v3.1.1 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1836"">#1836</a>) (<a href=""https://github.com/googleapis/java-storage/commit/3b71fab11ac71039c2a9983821ce02ce25ce311d"">3b71fab</a>)</li>; <li>Update dependency net.jqwik:jqwik to v1.7.2 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1833"">#1833</a>) (<a href=""https://github.com/googleapis/java-storage/commit/83bc261130e89e5994f21e32422054ef6ea2fe8e"">83bc261</a>)</li>; <li>Update dependency org.junit.vintage:junit-vintage-engine to v5.9.2 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1837"">#1837</a>) (<a href=""https://github.com/googleapis/java-storage/commit/5b381845b4f48a691aa3f0cb96599ddefc7e463f"">5b38184</a>)</li>; <li>Update junit-platform.version to v5.9.2 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1838"">#1838</a>) (<a href=""https://github.com/googleapis/java-storage/commit/372521ba80b12e52c74fae5ac766dbe6610ff0b2"">372521b</a>)</li>; </ul>; <h2>v2.16.0</h2>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.15.1...v2.16.0"">2.16.0</a> (2022-12-06)</h2>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12598:5682,depend,dependabot,5682,https://hail.is,https://github.com/hail-is/hail/pull/12598,1,['depend'],['dependabot']
Integrability," and lazy=True</li>; <li><a href=""https://github.com/fonttools/fonttools/commit/1d5feb81e597db8faa53695315befbccf0075b2e""><code>1d5feb8</code></a> ttFont_test: add reproducer for SpooledTemporaryFile has no seekable</li>; <li><a href=""https://github.com/fonttools/fonttools/commit/f1c609aa57fa11ab98f2152275f2c709e06c0680""><code>f1c609a</code></a> .readthedocs.yml: don't use 'legacy' build specification</li>; <li><a href=""https://github.com/fonttools/fonttools/commit/f9b941d226242c6b481e752036654aa346409036""><code>f9b941d</code></a> use python3.10 for ReadTheDocs</li>; <li>Additional commits viewable in <a href=""https://github.com/fonttools/fonttools/compare/4.38.0...4.39.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=fonttools&package-manager=pip&previous-version=4.38.0&new-version=4.39.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12910:17357,depend,dependabot-security-updates,17357,https://hail.is,https://github.com/hail-is/hail/pull/12910,1,['depend'],['dependabot-security-updates']
Integrability," and revert the unnecessary; <code>pylint.version</code> breaking change.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/4399"">#4399</a></p>; </li>; </ul>; <h2>pylint-2.8.0</h2>; <ul>; <li>; <p>New refactoring message <code>consider-using-with</code>. This message is emitted if resource-allocating functions or methods of the; standard library (like <code>open()</code> or <code>threading.Lock.acquire()</code>) that can be used as a context manager are called without; a <code>with</code> block.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/3413"">#3413</a></p>; </li>; <li>; <p>Resolve false positives on unused variables in decorator functions</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/4252"">#4252</a></p>; </li>; <li>; <p>Add new extension <code>ConfusingConsecutiveElifChecker</code>. This optional checker emits a refactoring message (R5601 <code>confusing-consecutive-elif</code>); if if/elif statements with different indentation levels follow directly one after the other.</p>; </li>; <li>; <p>New option <code>--output=&lt;file&gt;</code> to output result to a file rather than printing to stdout.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/1070"">#1070</a></p>; </li>; <li>; <p>Use a prescriptive message for <code>unidiomatic-typecheck</code></p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/3891"">#3891</a></p>; </li>; <li>; <p>Apply <code>const-naming-style</code> to module constants annotated with; <code>typing.Final</code></p>; </li>; <li>; <p>The packaging is now done via setuptools exclusively. <code>doc</code>, <code>tests</code>, <code>man</code>, <code>elisp</code> and <code>Changelog</code> are; not packaged anymore - reducing the size of the package by 75%.</p>; </li>; <li>; <p>Debian packaging is now (officially) done in <a href=""https://salsa.debian.org/python-team/packages/pyli",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11461:1304,message,message,1304,https://hail.is,https://github.com/hail-is/hail/pull/11461,2,['message'],['message']
Integrability," and the first release covered by our new; <a href=""https://black.readthedocs.io/en/stable/the_black_code_style/index.html#stability-policy"">stability policy</a>.</p>; <h3>Highlights</h3>; <ul>; <li><strong>Remove Python 2 support</strong> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2740"">#2740</a>)</li>; <li>Introduce the <code>--preview</code> flag (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2752"">#2752</a>)</li>; </ul>; <h3>Style</h3>; <ul>; <li>Deprecate <code>--experimental-string-processing</code> and move the functionality under; <code>--preview</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2789"">#2789</a>)</li>; <li>For stubs, one blank line between class attributes and methods is now kept if there's; at least one pre-existing blank line (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2736"">#2736</a>)</li>; <li>Black now normalizes string prefix order (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2297"">#2297</a>)</li>; <li>Remove spaces around power operators if both operands are simple (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2726"">#2726</a>)</li>; <li>Work around bug that causes unstable formatting in some cases in the presence of the; magic trailing comma (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2807"">#2807</a>)</li>; <li>Use parentheses for attribute access on decimal float and int literals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2799"">#2799</a>)</li>; <li>Don't add whitespace for attribute access on hexadecimal, binary, octal, and complex; literals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2799"">#2799</a>)</li>; <li>Treat blank lines in stubs the same inside top-level <code>if</code> statements (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2820"">#2820</a>)</li>; <li>Fix unstable formatting with semicolons and arithmetic expressio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11468:8306,depend,dependabot,8306,https://hail.is,https://github.com/hail-is/hail/pull/11468,1,['depend'],['dependabot']
Integrability," another incompatibility with old pict2e LaTeX</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/faccc2182275354ebe7d85ac61dd753887b98315""><code>faccc21</code></a> Fix <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10695"">#10695</a>: old LaTeX does not allow <a href=""https://github.com/ifpackageloaded""><code>@​ifpackageloaded</code></a> usage in body</li>; <li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v3.5.4...v5.1.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx&package-manager=pip&previous-version=3.5.4&new-version=5.1.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12165:8239,depend,dependabot,8239,https://hail.is,https://github.com/hail-is/hail/pull/12165,1,['depend'],['dependabot']
Integrability," as <code>Any</code> as a stop gap measure until <code>8073</code>{.interpreted-text role=&quot;issue&quot;} is fixed.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9791"">#9791</a>: Fixed a path handling code in <code>rewrite.py</code> that seems to work fine, but was incorrect and fails in some systems.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9917"">#9917</a>: Fixed string representation for <code>pytest.approx</code>{.interpreted-text role=&quot;func&quot;} when used to compare tuples.</li>; </ul>; <h2>Improved Documentation</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9937"">#9937</a>: Explicit note that <code>tmpdir</code>{.interpreted-text role=&quot;fixture&quot;} fixture is discouraged in favour of <code>tmp_path</code>{.interpreted-text role=&quot;fixture&quot;}.</li>; </ul>; <h2>Trivial/Internal Changes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/10114"">#10114</a>: Replace <a href=""https://github.com/untitaker/python-atomicwrites"">atomicwrites</a> dependency on windows with [os.replace]{.title-ref}.</li>; </ul>; <h2>7.1.2</h2>; <h1>pytest 7.1.2 (2022-04-23)</h1>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9726"">#9726</a>: An unnecessary <code>numpy</code> import inside <code>pytest.approx</code>{.interpreted-text role=&quot;func&quot;} was removed.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9820"">#9820</a>: Fix comparison of <code>dataclasses</code> with <code>InitVar</code>.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9869"">#9869</a>: Increase <code>stacklevel</code> for the <code>NODE_CTOR_FSPATH_ARG</code> deprecation to point to the; user's code, not pytest.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9871"">#9871</a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12187:2404,depend,dependabot,2404,https://hail.is,https://github.com/hail-is/hail/pull/12187,1,['depend'],['dependabot']
Integrability," as a dtype will now raise a <code>TypeError</code>.</p>; <p>(<a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/19539"">gh-19539</a>)</p>; <h3>Expired deprecations for <code>loads</code>, <code>ndfromtxt</code>, and <code>mafromtxt</code> in npyio</h3>; <p><code>numpy.loads</code> was deprecated in v1.15, with the recommendation that; users use <code>pickle.loads</code> instead. <code>ndfromtxt</code> and <code>mafromtxt</code> were both; deprecated in v1.17 - users should use <code>numpy.genfromtxt</code> instead with; the appropriate value for the <code>usemask</code> parameter.</p>; <p>(<a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/19615"">gh-19615</a>)</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/numpy/numpy/commit/4adc87dff15a247e417d50f10cc4def8e1c17a03""><code>4adc87d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/20685"">#20685</a> from charris/prepare-for-1.22.0-release</li>; <li><a href=""https://github.com/numpy/numpy/commit/fd66547557f57c430d41be2fc0764f74a62e8ccf""><code>fd66547</code></a> REL: Prepare for the NumPy 1.22.0 release.</li>; <li><a href=""https://github.com/numpy/numpy/commit/125304b035effcd82e366e601b102e7347eaa9ba""><code>125304b</code></a> wip</li>; <li><a href=""https://github.com/numpy/numpy/commit/c283859128b1a4b57014581570a23ed7950a24ea""><code>c283859</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/20682"">#20682</a> from charris/backport-20416</li>; <li><a href=""https://github.com/numpy/numpy/commit/5399c03d4a069fe81a1616be0184c9749d7271ee""><code>5399c03</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/20681"">#20681</a> from charris/backport-20954</li>; <li><a href=""https://github.com/numpy/numpy/commit/f9c45f8ebf31340b1a5a0371bfca25afcfc4794e""><code>f9",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11939:3147,depend,dependabot,3147,https://hail.is,https://github.com/hail-is/hail/pull/11939,2,['depend'],['dependabot']
Integrability," at `$http_x_forwarded_proto` which will always have been set to `https` from the gateway? I. Yep. In fact everything request to a Hail service (besides a lets-encrypt path) gets redirected to https. > Or am I misunderstanding how this works?. Nope, you have it correct. $http_x_forwarded_proto should never be absent, and would be fine to use instead of $updated_scheme (but I'd prefer one of those two, rather than https, because otherwise we're not relying on our upstream infrastructure). > * I'm having trouble understanding the difference between `Host` and `X-Forwarded-Host`, still. As I understand it, `Host` is the name of the server that the current request is trying to reach, and `X-Forwarded-Host` is the name of the server that the original request was trying to reach? Which is why `Host` is set to `$service.internal` and `X-Forwarded-Host` is `$http_host` in the internal.hail.is server? . Yeah that's right. Host refers to the current server (or in the proxied case, what gateway set Host to). X-Forwarded-Host is set by gateway to be the $http_host at the time it proxies the request to router, which is going to be blog.hail.is. > I don't quite follow your comment about our use of `Host` being wrong, in this case; I _think_ I understand what you're saying? but I'm not sure why all of our stuff is setting `Host` to `$updated_host` if that's the case, and I don't understand what's happening enough to know what happens if I change it to `proxy_set_header Host $http_host;` instead. I just mean that we're setting Host to the value that X-Forwarded-Host has, when it seems more appropriate for it to be the domain:port of the internal request. So we're relying on X-Forwarded-Host to set that value, but we could, and I think it may be cleaner / more informative, to rely on X-Forwarded-Host all the way through to the internal server that's receiving the request - in this case Ghost's ExpressJS server - instead of rewriting the Host field to be that of the external request.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7381#issuecomment-548082569:1688,rout,router,1688,https://hail.is,https://github.com/hail-is/hail/pull/7381#issuecomment-548082569,1,['rout'],['router']
Integrability, at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$3.apply(Simplify.scala:35); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:19); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Optimize$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$apply$1$$anonfun$apply$mcV$sp$3.apply(Optimize.scala:25); at is.hail.expr.ir.Optimize$$anonfun$is$hail$expr$ir$Optimize$$runOpt$1$1.apply(Optimize.scala:17); at is.hail.expr.ir.Optimize$$anonfun$is$hail$expr$ir$Optimize$$runOpt$1$1.apply(Optimi,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:11128,Wrap,WrappedArray,11128,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Wrap'],['WrappedArray']
Integrability," autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/700"">jpadilla/pyjwt#700</a></li>; <li>Add exception chaining by <a href=""https://github.com/ehdgua01""><code>@​ehdgua01</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/702"">jpadilla/pyjwt#702</a></li>; <li>Revert &quot;Remove arbitrary kwargs.&quot; by <a href=""https://github.com/auvipy""><code>@​auvipy</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/701"">jpadilla/pyjwt#701</a></li>; <li>Bump up version to v2.3.0 by <a href=""https://github.com/jpadilla""><code>@​jpadilla</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/703"">jpadilla/pyjwt#703</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/ehdgua01""><code>@​ehdgua01</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/702"">jpadilla/pyjwt#702</a></li>; <li><a href=""https://github.com/auvipy""><code>@​auvipy</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/701"">jpadilla/pyjwt#701</a></li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/jpadilla/pyjwt/compare/2.2.0...2.3.0"">https://github.com/jpadilla/pyjwt/compare/2.2.0...2.3.0</a></p>; <h2>2.2.0</h2>; <h2>What's Changed</h2>; <ul>; <li>Complete <code>jwt</code> documentation by <a href=""https://github.com/johachi""><code>@​johachi</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/654"">jpadilla/pyjwt#654</a></li>; <li>Ignore coverage files generated during test runs by <a href=""https://github.com/makusu2""><code>@​makusu2</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/617"">jpadilla/pyjwt#617</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/p",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11457:1307,depend,dependabot,1307,https://hail.is,https://github.com/hail-is/hail/pull/11457,1,['depend'],['dependabot']
Integrability," axios since your current version.</p>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=axios&package-manager=npm_and_yarn&previous-version=0.21.1&new-version=0.21.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:14409,Depend,Dependabot,14409,https://hail.is,https://github.com/hail-is/hail/pull/11080,18,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability," black formatting</li>; <li><a href=""https://github.com/chardet/chardet/commit/f1f9d4280e11fb3a9b2d9eaf1827dac9263cb1cb""><code>f1f9d42</code></a> slight increase in performance (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/252"">#252</a>)</li>; <li><a href=""https://github.com/chardet/chardet/commit/f9ef56cfd6c9b24b9c865eae6dc2285c67ffb75c""><code>f9ef56c</code></a> Use Python-3 super() syntax in Latin1Prober (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/240"">#240</a>)</li>; <li><a href=""https://github.com/chardet/chardet/commit/c5e5d5a8f1b6e135a8bffd8d60b2f726bb168339""><code>c5e5d5a</code></a> Simple maintenance improvements (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/244"">#244</a>)</li>; <li><a href=""https://github.com/chardet/chardet/commit/49b8341f507bed68f7d3ff7138bb97047a0e04f0""><code>49b8341</code></a> Configure setuptools using the declarative syntax in setup.cfg (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/239"">#239</a>)</li>; <li><a href=""https://github.com/chardet/chardet/commit/5c73bfcdf819251d1a1d0de672e34480ebafbe1f""><code>5c73bfc</code></a> Run all pre-commit hooks on pull requests (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/236"">#236</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/chardet/chardet/compare/4.0.0...5.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=chardet&package-manager=pip&previous-version=4.0.0&new-version=5.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (depen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12107:5091,depend,dependabot,5091,https://hail.is,https://github.com/hail-is/hail/pull/12107,1,['depend'],['dependabot']
Integrability," building a new sub-message and; merging the fully formed message into the existing field.</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-h4h5-3hr4-j3g2"">Security Advisory for Java users</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/protocolbuffers/protobuf/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.2&new-version=4.21.9)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12518:2055,depend,dependabot-automerge-start,2055,https://hail.is,https://github.com/hail-is/hail/pull/12518,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability," can upgrade without taking any additional action. If you're upgrading from an earlier version or you have explicitly enabled <em>legacy</em> mode, you need to switch to <em>auto</em> or <em>strict</em> mode before upgrading to this version.</li>; <li>Deprecate use of pytest v6.</li>; <li>Fixed an issue which prevented fixture setup from being cached. <code>[#404](https://github.com/pytest-dev/pytest-asyncio/issues/404) &lt;https://github.com/pytest-dev/pytest-asyncio/pull/404&gt;</code>_</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/c8d017407d39dd81d6864fa9a58ba1240d54be9f""><code>c8d0174</code></a> fix: Do not warn about outdated pytest version when pytest&gt;=7 is installed. (...</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/6450ddbe974f5359d56317ba8bdda8b2ab48655a""><code>6450ddb</code></a> Prepare release of v0.20.0. (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/428"">#428</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/150f29c107fbd76641de47e040d43840769ef92c""><code>150f29c</code></a> Build(deps): Bump hypothesis in /dependencies/default (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/427"">#427</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/adc88090f341d9872e9e9b4d22a94cdadf60b3bc""><code>adc8809</code></a> Build(deps): Bump typing-extensions in /dependencies/default (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/425"">#425</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/4abf9d1df228ed8b083721d7affa73e4a08d13c3""><code>4abf9d1</code></a> Build(deps): Bump zipp from 3.8.1 to 3.9.0 in /dependencies/default (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/424"">#424</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12390:4259,depend,dependabot,4259,https://hail.is,https://github.com/hail-is/hail/pull/12390,1,['depend'],['dependabot']
Integrability," central place</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/02b8e1a79d9e00acd61f9ac42e5555619fe2247a""><code>02b8e1a</code></a> Prevent duplicate destination files</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0b65ca2f17c8890a3ec34cf80cde52ee5413cbec""><code>0b65ca2</code></a> Call eachFile action only once per source</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/717877121299cea8f216d3a595eaa56731a6acd3""><code>7178771</code></a> Support changing a target file's relative path in an eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/e5af1bd7f9daa8a9222aee0dd1b703727cb5e94e""><code>e5af1bd</code></a> Bump version number to 5.3.0-SNAPSHOT</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/3.2.0...5.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=3.2.0&new-version=5.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:5202,Depend,Dependabot,5202,https://hail.is,https://github.com/hail-is/hail/pull/12345,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability," changes that will potentially require downstream code changes. Notably, <code>Allele</code> became an interface instead of a concrete class. <code>SimpleAllele</code> may be used as a replacement if you have classes which previously subclassed allele.</p>; <p>New Plugin Infrastructure:; 6a60de7c2 Move API marker annotations into new annotation package. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1558"">#1558</a>); 7ac95d5f7 Plugin framework and interfaces for versioned file format codecs (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1525"">#1525</a>); d40fe5412 Beta implementation of Bundles. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1546"">#1546</a>)</p>; <p>CRAM; 489c4192d Support CRAM reference regions. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1605"">#1605</a>); 22aec6782 Fix decoding of CRAM Scores read feature during normalization. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1592"">#1592</a>); 6507249a4 Make the CRAM MD5 failure message more user friendly. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1607"">#1607</a>); b5af659e6 Fix restoration of read base feature code. <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1379"">#1379</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1590"">#1590</a>); e63c34a92 Ignore TC, TN on CRAM read (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1578"">#1578</a>)</p>; <p>BAM/SAM; 1449dec45 Support loading of CSI from URLs/streams. <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1507"">#1507</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1595"">#1595</a>); a38c78d6c Add an option to SAMFileWriter to disable checking of ordering of rec… (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1599"">#1599</a>); 51aa6ed2b Validate that",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12229:2336,depend,dependabot,2336,https://hail.is,https://github.com/hail-is/hail/pull/12229,2,['depend'],['dependabot']
Integrability," checking of node.docstring (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/704"">#704</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/405a0906c8debafaae419472d3f51b84b7ba5c49""><code>405a090</code></a> simplify PYPY check (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/703"">#703</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/30ec8589e183f76f40764a8dd78591719f521943""><code>30ec858</code></a> remove unused WIN (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/702"">#702</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pyflakes/compare/2.4.0...2.5.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyflakes&package-manager=pip&previous-version=2.4.0&new-version=2.5.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12149:3856,depend,dependabot-security-updates,3856,https://hail.is,https://github.com/hail-is/hail/pull/12149,1,['depend'],['dependabot-security-updates']
Integrability," chore(deps): update github/codeql-action action to v3 (<a href=""https://redirect.github.com/PyMySQL/PyMySQL/issues/1154"">#1154</a>)</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/f13f054abcc18b39855a760a84be0a517f0da658""><code>f13f054</code></a> chore(deps): update actions/setup-python action to v5 (<a href=""https://redirect.github.com/PyMySQL/PyMySQL/issues/1152"">#1152</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/PyMySQL/PyMySQL/compare/v1.1.0...v1.1.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pymysql&package-manager=pip&previous-version=1.1.0&new-version=1.1.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major versio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14556:7884,depend,dependabot,7884,https://hail.is,https://github.com/hail-is/hail/pull/14556,1,['depend'],['dependabot']
Integrability," cleaned the same as using the <code>@option</code> and <code>@command</code>; decorators does. A command's <code>epilog</code> and <code>short_help</code> are also; processed. :issue:<code>1985</code></p>; </li>; <li>; <p>Store unprocessed <code>Command.help</code>, <code>epilog</code> and <code>short_help</code>; strings. Processing is only done when formatting help text for; output. :issue:<code>2149</code></p>; </li>; <li>; <p>Allow empty str input for <code>prompt()</code> when; <code>confirmation_prompt=True</code> and <code>default=&quot;&quot;</code>. :issue:<code>2157</code></p>; </li>; <li>; <p>Windows glob pattern expansion doesn't fail if a value is an invalid</p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/click/commit/a41e349ae738c55bce46dfb8715159463074d6e9""><code>a41e349</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2234"">#2234</a> from pallets/release-8.1.1</li>; <li><a href=""https://github.com/pallets/click/commit/3c301ebacbfe8ec7dc3d9d46ebf517082a8ee4b1""><code>3c301eb</code></a> release version 8.1.1</li>; <li><a href=""https://github.com/pallets/click/commit/d5741a2ca2ebc21d525c903f628b1bebad75b735""><code>d5741a2</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2233"">#2233</a> from henryiii/henryiii/fix/commandtype</li>; <li><a href=""https://github.com/pallets/click/commit/e234cf958d2416d4b20b53ae850c487fed32fa35""><code>e234cf9</code></a> fix(types): decorator typing fails</li>; <li><a href=""https://github.com/pallets/click/commit/fb7c6dbab505c319dfcbb882e66f313fcbf06a0f""><code>fb7c6db</code></a> start version 8.1.1</li>; <li><a href=""https://github.com/pallets/click/commit/e4aceee8d2bf7fe9461915b0a21c4359ddcb8dc2""><code>e4aceee</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/cl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11721:4824,depend,dependabot,4824,https://hail.is,https://github.com/hail-is/hail/pull/11721,1,['depend'],['dependabot']
Integrability," cmd exit 1. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104774"">kubernetes/kubernetes#104774</a>, <a href=""https://github.com/kerthcet""><code>@​kerthcet</code></a>)</li>; <li>Fixes a regression in v1beta1 PodDisruptionBudget handling of <code>strategic merge patch</code>-type API requests for the <code>selector</code> field. Prior to 1.21, these requests would merge <code>matchLabels</code> content and replace <code>matchExpressions</code> content. In 1.21, patch requests touching the <code>selector</code> field started replacing the entire selector. This is consistent with server-side apply and the v1 PodDisruptionBudget behavior, but should not have been changed for v1beta1. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108138"">kubernetes/kubernetes#108138</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>)</li>; <li>Improve kubectl's user help commands readability (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104736"">kubernetes/kubernetes#104736</a>, <a href=""https://github.com/lauchokyip""><code>@​lauchokyip</code></a>)</li>; <li>Indexed Jobs graduated to stable. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107395"">kubernetes/kubernetes#107395</a>, <a href=""https://github.com/alculquicondor""><code>@​alculquicondor</code></a>)</li>; <li>Introduce a v1alpha1 networking API for ClusterCIDRConfig (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108290"">kubernetes/kubernetes#108290</a>, <a href=""https://github.com/sarveshr7""><code>@​sarveshr7</code></a>)</li>; <li>Introduction of a new &quot;sync_proxy_rules_no_local_endpoints_total&quot; proxy metric. This metric represents the number of services with no internal endpoints. The &quot;traffic_policy&quot; label will contain both &quot;internal&quot; or &quot;external&quot;. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/1089",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:6895,depend,dependabot,6895,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['depend'],['dependabot']
Integrability," come with 2 CPU and 7.5 GB each, but not all of that is allocatable to our pods. In reality, somewhere between 5.7-5.9GB ([GCP Docs](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-architecture) say 5.7, GKE console says 5.9) of memory and 1.9CPU are available for us to use. Some of our Big services request 1 CPU and 3.75GB, but then we can never fit two big pods on one node. This is an attempt to standardize our requests so their easier to reason about while hopefully getting better packing. . | resource | Big | Medium | Small |; | --- | --- | --- | --- |; | CPU | 600m | 100m | 20m |; | Memory | 2G | 200M | 20M |. The intentions here are:; - always be able to comfortably get 2 Big pods on a node; - medium pods shouldn't have to force new nodes to spin up just because there's a Big pod there already; - small pods take up minimal resources; - there's ample room for small pods (which are mostly on HPA) to scale up considering most nodes shouldn't be at their medium pod capacity. The ratios don't match exactly, because I didn't want to assign CPU lower than 20m to prevent HPA thrashing we saw with auth and see a bit now with router. Setting it to 20m should hopefully convince k8s that idle small apps don't need to be scaled up under normal fluctuation. ## Big; - query; - batch-driver; - shuffler; - memory. ## Medium; - grafana; - ukbb-browser; - ukbb-static; - blog; - ci; - internal-gateway. ## Small; - amundsen; - router; - gateway; - site; - batch; - address; - atgu; - router-resolver; - ci/test statefulset & deployment; - auth-driver; - echo; - benchmark; - image-fetcher. ### Fun surprises I found along the way; - CI test statefulsets and deployment are getting .5GB and .5 CPU each; - We run a lot of image fetchers because a daemon set gets added per PR namespace. EDIT: It seems that discrepancy between GCP docs and GKE console is the console counts kube-system pods in ""Allocatable Memory"", and it really does take 2GB to run the Kubernetes Engine 🙃",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10117:1171,rout,router,1171,https://hail.is,https://github.com/hail-is/hail/pull/10117,3,['rout'],"['router', 'router-resolver']"
Integrability," complete model context for deserialization of instances (<a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11469"">#11469</a>)</li>; <li><a href=""https://github.com/bokeh/bokeh/commit/64fa0759bab7e2cc48663a2359093dc3e0b58df5""><code>64fa075</code></a> Add OS to bokeh info (<a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11797"">#11797</a>)</li>; <li><a href=""https://github.com/bokeh/bokeh/commit/da7d07ab6cc9fc9e88df7b5ecd39bc5da0b47cd9""><code>da7d07a</code></a> Don't unnecessarily update node/edge renderers in graphs (<a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11808"">#11808</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/bokeh/bokeh/compare/1.3.1...2.4.2"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11540:9048,depend,dependabot-automerge-start,9048,https://hail.is,https://github.com/hail-is/hail/pull/11540,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability," config option allowing to automatically annotate parameter defaults.</li>; </ul>; <h2>1.13.1</h2>; <ul>; <li>Fixed <code>NewType</code> inserts a reference as first argument instead of a string</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/1ef84886873b80ff62ed1ea76e111dd9e96dbf18""><code>1ef8488</code></a> Release 1.17.0</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/aa345ca0475dbe8f4da7f4c7c56832c8d8e6884a""><code>aa345ca</code></a> Add <code>typehints_use_rtype</code> option (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/218"">#218</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/a022d1a430db886decf2221b712bc3bd881f5e86""><code>a022d1a</code></a> inspect.getsource can raise TypeError (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/210"">#210</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/0807d00cf021a01268c158a453dde0f20cafd42b""><code>0807d00</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/215"">#215</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/8b0599d7741452b368880f6235ee0cce8e95fef2""><code>8b0599d</code></a> Handle ForwardRef, expand TypeVar and link Ellipsis (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/214"">#214</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/f75d19be9275b25d2f6caa23392a6072f49c3d56""><code>f75d19b</code></a> Add handling of tuples in type subscriptions (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/212"">#212</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11503:3461,depend,dependabot,3461,https://hail.is,https://github.com/hail-is/hail/pull/11503,2,['depend'],['dependabot']
Integrability," context fixes in <code>{@const}</code> (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/pull/7222"">#7222</a>)</li>; <li>Fix <code>{#key}</code> block not being reactive when the key variable is not otherwise used (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7408"">#7408</a>)</li>; <li>Add <code>Symbol</code> as a known global (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7418"">#7418</a>)</li>; </ul>; <h2>3.46.6</h2>; <ul>; <li>Actually include action TypeScript interface in published package (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/pull/7407"">#7407</a>)</li>; </ul>; <h2>3.46.5</h2>; <ul>; <li>Add TypeScript interfaces for typing actions (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/6538"">#6538</a>)</li>; <li>Do not generate <code>unused-export-let</code> warning inside <code>&lt;script context=&quot;module&quot;&gt;</code> blocks (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7055"">#7055</a>)</li>; <li>Do not collapse whitespace-only CSS vars (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7152"">#7152</a>)</li>; <li>Add <code>aria-description</code> to the list of allowed ARIA attributes (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7301"">#7301</a>)</li>; <li>Fix attribute escaping during SSR (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7327"">#7327</a>)</li>; <li>Prevent <code>.innerHTML</code> optimization from being used when <code>style:</code> directive is present (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7386"">#7386</a>)</li>; </ul>; <h2>3.46.4</h2>; <ul>; <li>Avoid <code>maximum call stack size exceeded</code> errors on large components (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/4694"">#4694</a>)</li>; <li>Preserve leading space with <code>preserveWhitespace: true</code> (<a href=""https:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12032:5085,depend,dependabot,5085,https://hail.is,https://github.com/hail-is/hail/pull/12032,3,['depend'],['dependabot']
Integrability," copy operations.</li>; <li>Make message-type extensions merge from wire-format instead of building up; instances and merging afterwards. This has much better performance.</li>; <li>Fix TextFormat parser to build up recurring (but supposedly not repeated); sub-messages directly from text rather than building a new sub-message and; merging the fully formed message into the existing field.</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-h4h5-3hr4-j3g2"">Security Advisory for Java users</a></li>; </ul>; <h2>Protocol Buffers v3.20.2</h2>; <h1>C++</h1>; <ul>; <li>Reduce memory consumption of MessageSet parsing</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf"">Security Advisory for C++ and Python users</a></li>; </ul>; <h2>Protocol Buffers v3.20.1</h2>; <h1>PHP</h1>; <ul>; <li>Fix building packaged PHP extension (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9727"">#9727</a>)</li>; <li>Fixed composer.json to only advertise compatibility with PHP 7.0+. (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9819"">#9819</a>)</li>; </ul>; <h1>Ruby</h1>; <ul>; <li>Disable the aarch64 build on macOS until it can be fixed. (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9816"">#9816</a>)</li>; </ul>; <h1>Other</h1>; <ul>; <li>Fix versioning issues in 3.20.0</li>; </ul>; <h2>Protocol Buffers v3.20.1-rc1</h2>; <p>#PHP</p>; <ul>; <li>Fix building packaged PHP extension (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9727"">#9727</a>)</li>; </ul>; <p>#Other</p>; <ul>; <li>Fix versioning issues in 3.20.0</li>; </ul>; <h2>Protocol Buffers v3.20.0</h2>; <p>2022-03-25 version 3.20.0 (C++/Java/Python/PHP/Objective-C/C#/Ruby/JavaScript)</p>; <h1>Ruby</h1>; <ul>; <li>Dropped Ruby 2.3 and 2.4 support for CI and releases. (<a href=",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12563:1778,depend,dependabot,1778,https://hail.is,https://github.com/hail-is/hail/pull/12563,1,['depend'],['dependabot']
Integrability," corresponding HTTP counterpart. Buffers are fixed to their specified size (can't arbitrarily grow without bounds), are allocated lazily and only if necessary.</p>; <ol>; <li>Investigation into the possibility of backporting these improvements to the HTTP counterparts is ongoing</li>; </ol>; </li>; <li>; <p>Preview support for Accessing GCS via gRPC</p>; <ol>; <li>Set the environment variable <code>GOOGLE_CLOUD_ENABLE_DIRECT_PATH_XDS=true</code>, then run your program.</li>; </ol>; </li>; </ol>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/java-storage/blob/main/CHANGELOG.md"">google-cloud-storage's changelog</a>.</em></p>; <blockquote>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.15.0...v2.15.1"">2.15.1</a> (2022-11-17)</h2>; <h3>Bug Fixes</h3>; <ul>; <li>Disable REGAPIC transport in storage v2 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1762"">#1762</a>) (<a href=""https://github.com/googleapis/java-storage/commit/13d630e7ce89273c292acca7a7e048218ece4182"">13d630e</a>)</li>; <li>Update GrpcStorageImpl#get(BlobId) to return null on 404 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1772"">#1772</a>) (<a href=""https://github.com/googleapis/java-storage/commit/8c59c64ccf0dd7753467b4c0f0bcf5f4b49c5bf0"">8c59c64</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Annotate all Option factory methods with their Nullability bounds (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1775"">#1775</a>) (<a href=""https://github.com/googleapis/java-storage/commit/3b8d137a113376d7dac9010b9207d435df2622f7"">3b8d137</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.14.0...v2.15.0"">2.15.0</a> (2022-11-07)</h2>; <h3>Features</h3>; <ul>; <li>Add Autoclass support and sample (<a href=""https://github-redirect.de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12529:5921,depend,dependabot,5921,https://hail.is,https://github.com/hail-is/hail/pull/12529,1,['depend'],['dependabot']
Integrability," crash when <code>lambda</code> used as a dict key (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7454"">#7454</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/5716ad10104a9553ef9d64404b044c04947889b2""><code>5716ad1</code></a> Bump pylint to 2.15.2, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/49b5d5dae6cc49d0572ffa35ae07f46ddc85fa61""><code>49b5d5d</code></a> Upgrade astroid version following 2.12.9 release</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/v2.13.5...v2.15.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pylint&package-manager=pip&previous-version=2.13.5&new-version=2.15.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12240:2821,Depend,Dependabot,2821,https://hail.is,https://github.com/hail-is/hail/pull/12240,1,['Depend'],['Dependabot']
Integrability," debugging of JVM crashing in production until the JVM logs are shown on a per-worker page. 2. JVMEntryway is now a real gradle project. I need to compile against log4j, and I didn't want to do that by hand with `javac`. Ignore gradlew, gradlew.bat, and gradle/wrapper, they're programmatically generated by gradle. 3. Add logging to JVMEntryway. JVMEntryway now logs its arguments into the QoB job log. I also log exceptions from the main thread or the cancel thread into the job log. We also flush the logs after the main thread completes, the cancel thread completes, and when the try-catch exits. This should ensure that regardless of what goes wrong (even if both threads fail to start) we at least see the arguments that the JVMEntryway received. 4. Use log4j2 programmatic reconfiguration after every job. This restores log4j2 to well enough working order that, *if you do not try to reconfigure it using log4j1 programmatic configuration*, logs will work. All old versions of Hail use log4j1 programmatic configuration. As a result, **all old versions of Hail will still have no logs**. However, new versions of Hail will log correctly even if an old version of Hail used the JVM before it. 5. `QoBAppender`. This is how we always should have done logging. A custom appender which we can flush and then redirect to a new file at our whim. I followed the log4j2 best practices for creating a new appender. All these annotations, factory methods, and managers are The Right Way, for better or worse. If we ever ban old versions of Hail from the cluster, then we can also eliminate the log4j2 reconfiguration. New versions of Hail work fine without any runtime log configuration (thanks to `QoBAppender`). I would like to eliminate reconfiguration because log4j2 reconfiguration leaves around oprhaned appenders and appender managers. Maybe I'm implementing the Appender or Appender Manager interfaces wrong, but I've read over that code a bunch of times and I cannot sort out what I am missing.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12941:2241,interface,interfaces,2241,https://hail.is,https://github.com/hail-is/hail/pull/12941,1,['interface'],['interfaces']
Integrability," dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1ZDhmZDhmZC1mZGUxLTRiYmMtYWMzMi0xOTE1NmY0ZDFjZjIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjVkOGZkOGZkLWZkZTEtNGJiYy1hYzMyLTE5MTU2ZjRkMWNmMiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/7fad328c-8d01-4768-8813-73d6c644e2d4?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/7fad328c-8d01-4768-8813-73d6c644e2d4?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""5d8fd8fd-fde1-4bbc-ac32-19156f4d1cf2"",""prPublicId"":""5d8fd8fd-fde1-4bbc-ac32-19156f4d1cf2"",""dependencies"":[{""name"":""requests"",""from"":""2.28.2"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""7fad328c-8d01-4768-8813-73d6c644e2d4"",""projectUrl"":""https://app.snyk.io/org/danking/project/7fad328c-8d01-4768-8813-73d6c644e2d4?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[591],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13112:2590,depend,dependencies,2590,https://hail.is,https://github.com/hail-is/hail/pull/13112,1,['depend'],['dependencies']
Integrability," dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2YzU3NmY1Yi1lNGM5LTQ4ZjctYmYxNy04YjEzOTIxODlmZDQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjZjNTc2ZjViLWU0YzktNDhmNy1iZjE3LThiMTM5MjE4OWZkNCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""6c576f5b-e4c9-48f7-bf17-8b1392189fd4"",""prPublicId"":""6c576f5b-e4c9-48f7-bf17-8b1392189fd4"",""dependencies"":[{""name"":""requests"",""from"":""2.28.2"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[591],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13097:2513,depend,dependencies,2513,https://hail.is,https://github.com/hail-is/hail/pull/13097,1,['depend'],['dependencies']
Integrability," dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3ZGVlZGFlMy1mZmE3LTQxYmUtOGY4MS1lNmYwZTA5YTczOTMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjdkZWVkYWUzLWZmYTctNDFiZS04ZjgxLWU2ZjBlMDlhNzM5MyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""7deedae3-ffa7-41be-8f81-e6f0e09a7393"",""prPublicId"":""7deedae3-ffa7-41be-8f81-e6f0e09a7393"",""dependencies"":[{""name"":""urllib3"",""from"":""1.26.16"",""to"":""1.26.17""}],""packageManager"":""pip"",""projectPublicId"":""701495b8-b53d-48af-82fe-1a6c57aa56cb"",""projectUrl"":""https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-URLLIB3-5926907""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[581],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13770:2605,depend,dependencies,2605,https://hail.is,https://github.com/hail-is/hail/pull/13770,1,['depend'],['dependencies']
Integrability," dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIwMzdiOGRmZS1hZDA4LTRmZjUtYTFkOC1hNGM4Nzg2N2NkYjAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjAzN2I4ZGZlLWFkMDgtNGZmNS1hMWQ4LWE0Yzg3ODY3Y2RiMCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""037b8dfe-ad08-4ff5-a1d8-a4c87867cdb0"",""prPublicId"":""037b8dfe-ad08-4ff5-a1d8-a4c87867cdb0"",""dependencies"":[{""name"":""requests"",""from"":""2.28.2"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[591],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13159:2605,depend,dependencies,2605,https://hail.is,https://github.com/hail-is/hail/pull/13159,1,['depend'],['dependencies']
Integrability," dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyNWE2ZGYzMi1kYmEzLTQzOTctYmIyNC0zNjdlMzhmZWQ3ZmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjI1YTZkZjMyLWRiYTMtNDM5Ny1iYjI0LTM2N2UzOGZlZDdmZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""25a6df32-dba3-4397-bb24-367e38fed7fe"",""prPublicId"":""25a6df32-dba3-4397-bb24-367e38fed7fe"",""dependencies"":[{""name"":""urllib3"",""from"":""1.26.17"",""to"":""1.26.18""}],""packageManager"":""pip"",""projectPublicId"":""701495b8-b53d-48af-82fe-1a6c57aa56cb"",""projectUrl"":""https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-URLLIB3-6002459""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[496],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13848:2605,depend,dependencies,2605,https://hail.is,https://github.com/hail-is/hail/pull/13848,1,['depend'],['dependencies']
Integrability," dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzM2VkMzM4Ny0zZTVmLTRkZDgtYjIxYy1iYzIyNzk4ODViZjMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjMzZWQzMzg3LTNlNWYtNGRkOC1iMjFjLWJjMjI3OTg4NWJmMyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""33ed3387-3e5f-4dd8-b21c-bc2279885bf3"",""prPublicId"":""33ed3387-3e5f-4dd8-b21c-bc2279885bf3"",""dependencies"":[{""name"":""requests"",""from"":""2.28.2"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""b72ce54d-5de3-48e5-a1d4-6f8967681a12"",""projectUrl"":""https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[591],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13107:2498,depend,dependencies,2498,https://hail.is,https://github.com/hail-is/hail/pull/13107,1,['depend'],['dependencies']
Integrability," dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzYWEwNDk2OC02NDIxLTRmODktYTBjYy03MjE4MzExNDNiZGQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjNhYTA0OTY4LTY0MjEtNGY4OS1hMGNjLTcyMTgzMTE0M2JkZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""3aa04968-6421-4f89-a0cc-721831143bdd"",""prPublicId"":""3aa04968-6421-4f89-a0cc-721831143bdd"",""dependencies"":[{""name"":""requests"",""from"":""2.28.2"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[591],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13100:2601,depend,dependencies,2601,https://hail.is,https://github.com/hail-is/hail/pull/13100,1,['depend'],['dependencies']
Integrability," dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiNzM2NzI0Yi1hY2RiLTRiOTUtYWQwMy1hYWI3MjkyZGNlYzQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImI3MzY3MjRiLWFjZGItNGI5NS1hZDAzLWFhYjcyOTJkY2VjNCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""b736724b-acdb-4b95-ad03-aab7292dcec4"",""prPublicId"":""b736724b-acdb-4b95-ad03-aab7292dcec4"",""dependencies"":[{""name"":""requests"",""from"":""2.28.2"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[591],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13116:2505,depend,dependencies,2505,https://hail.is,https://github.com/hail-is/hail/pull/13116,1,['depend'],['dependencies']
Integrability," dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlNDQxZTBmNS1jZDQ4LTQzZDUtYTdkMy1kMTM4YzQ2ZTc2NTgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImU0NDFlMGY1LWNkNDgtNDNkNS1hN2QzLWQxMzhjNDZlNzY1OCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""e441e0f5-cd48-43d5-a7d3-d138c46e7658"",""prPublicId"":""e441e0f5-cd48-43d5-a7d3-d138c46e7658"",""dependencies"":[{""name"":""requests"",""from"":""2.28.2"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""5ecb4152-94d0-44ff-86c6-21e542bb123d"",""projectUrl"":""https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[591],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13158:2597,depend,dependencies,2597,https://hail.is,https://github.com/hail-is/hail/pull/13158,1,['depend'],['dependencies']
Integrability," dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlZjQxMWYxOC1hM2JiLTQ1YzgtODFjOS1hNmNhNjI4MWI1ZjMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImVmNDExZjE4LWEzYmItNDVjOC04MWM5LWE2Y2E2MjgxYjVmMyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""ef411f18-a3bb-45c8-81c9-a6ca6281b5f3"",""prPublicId"":""ef411f18-a3bb-45c8-81c9-a6ca6281b5f3"",""dependencies"":[{""name"":""requests"",""from"":""2.28.2"",""to"":""2.31.0""}],""packageManager"":""pip"",""projectPublicId"":""701495b8-b53d-48af-82fe-1a6c57aa56cb"",""projectUrl"":""https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-REQUESTS-5595532""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[591],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Learn about vulnerability in an interactive lesson of Snyk Learn.](https://learn.snyk.io/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13108:2588,depend,dependencies,2588,https://hail.is,https://github.com/hail-is/hail/pull/13108,1,['depend'],['dependencies']
Integrability," deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": ""https GET /michaelfranklin/query/api/v1alpha/wait done in 50.029999999998836s: 200"", ""remote_address"": ""10.28.127.3"", ""request_start_time"": ""[24/Feb/2021:23:22:35 +0000]"", ""request_duration"": 50.029999999998836, ""response_status"": 200, ""x_real_ip"": ""124.170.20.28"", ""hail_log"": 1}; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,005"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:255"", ""message"": ""Tasks have all completed."", ""hail_log"": 1}; ```. Test duration endpoint; ```python; @routes.get('/api/v1alpha/wait'); async def wait_seconds(request):; """"""; Wait query.duration seconds before returning the request.; """"""; duration = request.query.get('duration'); try:; duration = int(duration); except Exception as e:; return web.json_response({; 'error': f'Invalid parameter duration ""{duration}"": {e}',; }, status=422). await asyncio.sleep(int(duration)); e = os.getenv(""TEST_VALUE"", ""None""); return web.json_response({""d"": f""You waited '{duration}' seconds!!"", ""env"": e}); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10106:2426,message,message,2426,https://hail.is,https://github.com/hail-is/hail/pull/10106,2,"['message', 'rout']","['message', 'routes']"
Integrability," deployment</li>; </ul>; </li>; </ul>; <h2>tqdm v4.62.3 stable</h2>; <ul>; <li>fix minor typo (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1246"">#1246</a>)</li>; <li>minor example fix (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1246"">#1246</a>)</li>; <li>misc tidying &amp; refactoring</li>; <li>misc build/dev framework updates; <ul>; <li>update dependencies</li>; <li>update linters</li>; <li>update docs deployment branches</li>; </ul>; </li>; <li>misc test/ci updates; <ul>; <li>test forks</li>; <li>tidy OS &amp; Python version tests</li>; <li>bump primary python version 3.7 =&gt; 3.8</li>; <li>beta py3.10 testing</li>; <li>fix py2.7 tests</li>; <li>better timeout handling</li>; </ul>; </li>; </ul>; <h2>tqdm v4.62.2 stable</h2>; <ul>; <li>fix notebook memory leak (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1216"">#1216</a>)</li>; <li>fix <code>contrib.concurrent</code> with generators (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1233"">#1233</a> &lt;- <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1231"">#1231</a>)</li>; </ul>; <h2>tqdm v4.62.1 stable</h2>; <ul>; <li><code>contrib.logging</code>: inherit existing handler output stream (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1191"">#1191</a>)</li>; <li>fix <code>PermissionError</code> by using <code>weakref</code> in <code>DisableOnWriteError</code> (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1207"">#1207</a>)</li>; <li>fix <code>contrib.telegram</code> creation rate limit handling (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1223"">#1223</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1221"">#1221</a> &lt;- <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1220"">#1220</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1076"">#1076</a>)</li>; <li>tests: fix py27 <code>keras</code> dependencies (<a href",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11587:2165,depend,dependabot,2165,https://hail.is,https://github.com/hail-is/hail/pull/11587,1,['depend'],['dependabot']
Integrability," discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; 0.2-e60bdb1a125a. ### What you did:; ```; def get_counts_agg_expr2(mt: hl.MatrixTable):; return (hl.case(missing_false=True); #0x; .when(hl.is_missing(mt.gt1) & ~mt.missing1,; hl.case(missing_false=True); .when(hl.is_missing(mt.gt2) & ~mt.missing2,[1,0,0,0,0,0,0,0,0]); .when(mt.gt2.is_het(), [0,1,0,0,0,0,0,0,0]); .when(mt.gt2.is_hom_var(), [0,0,1,0,0,0,0,0,0]); .default([0,0,0,0,0,0,0,0,0])); #1x; .when(mt.gt1.is_het(),; hl.case(missing_false=True); .when(hl.is_missing(mt.gt2) & ~mt.missing2,[0,0,0,1,0,0,0,0,0]); .when(mt.gt2.is_het(), [0,0,0,0,1,0,0,0,0]); .when(mt.gt2.is_hom_var(), [0,0,0,0,0,1,0,0,0]); .default([0,0,0,0,0,0,0,0,0])); #2x; .when(mt.gt1.is_hom_var(),; hl.case(missing_false=True); .when(hl.is_missing(mt.gt2) & ~mt.missing2,[0,0,0,0,0,0,1,0,0]); .when(mt.gt2.is_het(), [0,0,0,0,0,0,0,1,0]); .when(mt.gt2.is_hom_var(), [0,0,0,0,0,0,0,0,1]); .default([0,0,0,0,0,0,0,0,0])); .default([0,0,0,0,0,0,0,0,0])); mt = mt.annotate_rows(gt_counts=hl.agg.array_sum(get_counts_agg_expr2(mt))); ```; ### What went wrong (all error messages here, including the full java stack trace):; `gt_counts` is `[]` everywhere:; ```; mt.show(); +---------------+------------+---------------+------------+--------------+; | locus2 | alleles2 | locus1 | alleles1 | gt_counts |; +---------------+------------+---------------+------------+--------------+; | locus<GRCh37> | array<str> | locus<GRCh37> | array<str> | array<int64> |; +---------------+------------+---------------+------------+--------------+; | 1:69173 | [""A"",""T""] | 1:69166 | [""G"",""T""] | [] |; | 1:69946 | [""G"",""A""] | 1:69359 | [""G"",""A""] | [] |; | 1:69947 | [""A"",""G""] | 1:69359 | [""G"",""A""] | [] |; | 1:69735 | [""A"",""G""] | 1:69438 | [""T"",""C""] | [] |; | 1:69496 | [""G"",""A""] | 1:69453 | [""G"",""A""] | [] |; +---------------+------------+---------------+------------+--------------+; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4757:1297,message,messages,1297,https://hail.is,https://github.com/hail-is/hail/issues/4757,1,['message'],['messages']
Integrability," enableSystemLogHandler can be set to true only when enableDebuggingHandlers is also set to true. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/87273"">kubernetes/kubernetes#87273</a>, <a href=""https://github.com/SaranBalaji90""><code>@​SaranBalaji90</code></a>) [SIG Node]</li>; <li>Custom Endpoints are now mirrored to EndpointSlices by a new EndpointSliceMirroring controller. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91637"">kubernetes/kubernetes#91637</a>, <a href=""https://github.com/robscott""><code>@​robscott</code></a>) [SIG API Machinery, Apps, Auth, Cloud Provider, Instrumentation, Network and Testing]</li>; <li>CustomResourceDefinitions added support for marking versions as deprecated by setting <code>spec.versions[*].deprecated</code> to <code>true</code>, and for optionally overriding the default deprecation warning with a <code>spec.versions[*].deprecationWarning</code> field. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92329"">kubernetes/kubernetes#92329</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>) [SIG API Machinery]</li>; <li>EnvVarSource api doc bug fixes (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91194"">kubernetes/kubernetes#91194</a>, <a href=""https://github.com/wawa0210""><code>@​wawa0210</code></a>) [SIG Apps]</li>; <li>Fix bug in reflector that couldn't recover from &quot;Too large resource version&quot; errors (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92537"">kubernetes/kubernetes#92537</a>, <a href=""https://github.com/wojtek-t""><code>@​wojtek-t</code></a>) [SIG API Machinery]</li>; <li>Fixed: log timestamps now include trailing zeros to maintain a fixed width (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91207"">kubernetes/kubernetes#91207</a>, <a href=""https://github.com/iamchuckss""><code>@​iamchuckss</code></a>) [SIG Apps and Node]</li>;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:6181,depend,dependabot,6181,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['depend'],['dependabot']
Integrability," encode(). by <a href=""https://github.com/dajiaji""><code>@​dajiaji</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/673"">jpadilla/pyjwt#673</a></li>; <li>DOC: Clarify RSA encoding and decoding depend on the cryptography package by <a href=""https://github.com/TPXP""><code>@​TPXP</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/664"">jpadilla/pyjwt#664</a></li>; <li>Make typ optional by <a href=""https://github.com/dajiaji""><code>@​dajiaji</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/644"">jpadilla/pyjwt#644</a></li>; <li>Remove arbitrary kwargs. by <a href=""https://github.com/dajiaji""><code>@​dajiaji</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/657"">jpadilla/pyjwt#657</a></li>; <li>Assume JWK is valid for signing if &quot;use&quot; is omitted by <a href=""https://github.com/Klavionik""><code>@​Klavionik</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/668"">jpadilla/pyjwt#668</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/684"">jpadilla/pyjwt#684</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/686"">jpadilla/pyjwt#686</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/689"">jpadilla/pyjwt#689</a></li>; <li>Remove upper bound on cryptography version by <a href=""https://github.com/riconnon""><code>@​riconnon</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/693"">jpadilla/pyjwt#693</a></li>; <li>Add support for Ed448/EdDSA. by <a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11457:4415,depend,dependabot,4415,https://hail.is,https://github.com/hail-is/hail/pull/11457,1,['depend'],['dependabot']
Integrability," extension. This allows multiple files to be downloaded in parallel if the download extension is used. For normal download tasks, multiple files were downloaded in parallel already.</li>; </ul>; <h2>5.1.3</h2>; <p>Bug fixes:</p>; <ul>; <li>Initialize progress logger just before the download starts (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/243"">#243</a>)</li>; </ul>; <h2>5.1.2</h2>; <p>Bug fixes:</p>; <ul>; <li>Do not include default HTTP and HTTPS ports in <code>Host</code> header unless explicitly specified by the user</li>; </ul>; <h2>5.1.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Correctly update cached sources</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.5 and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if server does not send <code>WWW-Authenticate</code> header in 401 response</li>; <li>Log request and response headers in debug mode</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.4.1 and 7.4.2</li>; <li>Update dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0f43ce67de72bd511d849c07bd7728c0d6f2e6dd""><code>0f43ce6</code></a> Document path and relativePath properties</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a8504f9d60d0264808894e4bb80d4a73b8086a3e""><code>a8504f9</code></a> Bump up version number to 5.3.0</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/708067cd11c4a013da7a8c15d91f7f946967cf94""><code>708067c</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/0fdebf3c7ad43ed4739",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:2951,integrat,integration,2951,https://hail.is,https://github.com/hail-is/hail/pull/12345,1,['integrat'],['integration']
Integrability," extension. This allows multiple files to be downloaded in parallel if the download extension is used. For normal download tasks, multiple files were downloaded in parallel already.</li>; </ul>; <h2>5.1.3</h2>; <p>Bug fixes:</p>; <ul>; <li>Initialize progress logger just before the download starts (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/243"">#243</a>)</li>; </ul>; <h2>5.1.2</h2>; <p>Bug fixes:</p>; <ul>; <li>Do not include default HTTP and HTTPS ports in <code>Host</code> header unless explicitly specified by the user</li>; </ul>; <h2>5.1.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Correctly update cached sources</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.5 and 7.5.1</li>; <li>Update dependencies</li>; </ul>; <h2>5.1.0</h2>; <p>New features:</p>; <ul>; <li>Add possibility to enable preemptive Basic authentication (through the new <code>preemptiveAuth</code> flag)</li>; <li>Warn if server does not send <code>WWW-Authenticate</code> header in 401 response</li>; <li>Log request and response headers in debug mode</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Add integration tests for Gradle 7.4.1 and 7.4.2</li>; <li>Update dependencies</li>; </ul>; <h2>5.0.5</h2>; <p>Maintenance:</p>; <ul>; <li>Publish signed artifacts to Gradle plugin portal</li>; <li>Update dependencies</li>; </ul>; <h2>5.0.4</h2>; <p>Bug fixes:</p>; <ul>; <li>Fix deadlock in <code>DownloadExtension</code> if <code>max-workers</code> equals 1 (thanks to <a href=""https://github.com/beatbrot""><code>@​beatbrot</code></a> for spotting this, see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/205"">#205</a>)</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/1b5d69",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12332:2232,integrat,integration,2232,https://hail.is,https://github.com/hail-is/hail/pull/12332,1,['integrat'],['integration']
Integrability," extensions merge from wire-format instead of building up; instances and merging afterwards. This has much better performance.</li>; <li>Fix TextFormat parser to build up recurring (but supposedly not repeated); sub-messages directly from text rather than building a new sub-message and; merging the fully formed message into the existing field.</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-h4h5-3hr4-j3g2"">Security Advisory for Java users</a></li>; </ul>; <h2>Protocol Buffers v3.20.2</h2>; <h1>C++</h1>; <ul>; <li>Reduce memory consumption of MessageSet parsing</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf"">Security Advisory for C++ and Python users</a></li>; </ul>; <h2>Protocol Buffers v3.20.1</h2>; <h1>PHP</h1>; <ul>; <li>Fix building packaged PHP extension (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9727"">#9727</a>)</li>; <li>Fixed composer.json to only advertise compatibility with PHP 7.0+. (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9819"">#9819</a>)</li>; </ul>; <h1>Ruby</h1>; <ul>; <li>Disable the aarch64 build on macOS until it can be fixed. (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9816"">#9816</a>)</li>; </ul>; <h1>Other</h1>; <ul>; <li>Fix versioning issues in 3.20.0</li>; </ul>; <h2>Protocol Buffers v3.20.1-rc1</h2>; <p>#PHP</p>; <ul>; <li>Fix building packaged PHP extension (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9727"">#9727</a>)</li>; </ul>; <p>#Other</p>; <ul>; <li>Fix versioning issues in 3.20.0</li>; </ul>; <h2>Protocol Buffers v3.20.0</h2>; <p>2022-03-25 version 3.20.0 (C++/Java/Python/PHP/Objective-C/C#/Ruby/JavaScript)</p>; <h1>Ruby</h1>; <ul>; <li>Dropped Ruby 2.3 and 2.4 support for CI and releases. (<a href=""https://github-redirect.dependabot.com/prot",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12563:1793,protocol,protocolbuffers,1793,https://hail.is,https://github.com/hail-is/hail/pull/12563,1,['protocol'],['protocolbuffers']
Integrability," extra dependency</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/4a1d10e19fdca00db47fd50725715dc5e4aa68e6""><code>4a1d10e</code></a> consistent ordering</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/bf6c960f60f8a390b47ac55d2ece3ffc419e5dcd""><code>bf6c960</code></a> emoji bars</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/7994aa8285743b351cf1a3b36275335d8d0730b7""><code>7994aa8</code></a> warn once on error</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/a1d4401f186dc5a79b4ad452f38cae75e1f2e6da""><code>a1d4401</code></a> remove unneeded variable</li>; <li>Additional commits viewable in <a href=""https://github.com/tqdm/tqdm/compare/v4.42.1...v4.64.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=tqdm&package-manager=pip&previous-version=4.42.1&new-version=4.64.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12260:5995,depend,dependabot-security-updates,5995,https://hail.is,https://github.com/hail-is/hail/pull/12260,1,['depend'],['dependabot-security-updates']
Integrability," figure out what the tests are doing. We pay about 2 USD per PR test, which is not very high but still higher than I would like. I investigated why and looked at eight recent PR tests (all after Daniel's QoB test reduction):. 1. https://grafana.hail.is/d/8Kldmmynk/job-analytics?from=1695065243258&to=1695070128973&var-namespace=pr-13643-default-w484n4ke6oeg&orgId=1; 2. https://grafana.hail.is/d/8Kldmmynk/job-analytics?from=1694628837271&to=1694632585473&var-namespace=pr-12468-default-y8okmle5k65x&orgId=1; 3. https://grafana.hail.is/d/8Kldmmynk/job-analytics?from=1695078157872&to=1695080578446&var-namespace=pr-13644-default-phtb7scq3qln&orgId=1; 4. https://grafana.hail.is/d/8Kldmmynk/job-analytics?from=1694729270680&to=1694730449193&var-namespace=pr-13376-default-biulo4i0wohp&orgId=1; 5. https://grafana.hail.is/d/8Kldmmynk/job-analytics?from=1694628896138&to=1694632029521&var-namespace=pr-12468-default-y8okmle5k65x&orgId=1; 6. https://grafana.hail.is/d/8Kldmmynk/job-analytics?from=1695077856969&to=1695080563275&var-namespace=pr-13644-default-phtb7scq3qln&orgId=1; 7. https://grafana.hail.is/d/8Kldmmynk/job-analytics?from=1694625081745&to=1694626754800&var-namespace=pr-13430-default-hf2v0q29kgqy&orgId=1; 8. https://grafana.hail.is/d/8Kldmmynk/job-analytics?from=1694729252321&to=1694730683820&var-namespace=pr-13376-default-biulo4i0wohp&orgId=1. In every case, we spin up 32 cores of highcpu VMs but, apparently, never use them. They are live for 20-40 minutes depending on the tests. For the non-preemptible VM, thats about 0.40 USD for 30 minutes. We use 16 highmem cores once for about two minutes but we otherwise let them run idle the whole time. This PR accepts that we will wait 2-3min for a highmem to start when we need it. In exchange, we save about a dollar per PR (50%). I am also investigating why we seem to keep 80 cores alive for about 10 minutes despite being unused. My best guess is fragmentation, probably not much to do about that. cc: @daniel-goldstein, @jigold.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13667:1597,depend,depending,1597,https://hail.is,https://github.com/hail-is/hail/pull/13667,1,['depend'],['depending']
Integrability," file extension to missing index error message <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1512"">#1512</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1567"">#1567</a>); 74b827b67 Improve error message in IntervalTree (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1545"">#1545</a>); 7719274fe Htsget POST request support (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1529"">#1529</a>)</p>; <p>VCF:; aac46ee6d Added GVCF mode for VariantContext type determination (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1544"">#1544</a>); d72d73b01 Add context to exception when the vcf file is invalid <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1565"">#1565</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1566"">#1566</a>); 8466c82dc Respect genotype filtering when calculating AC/AN/AF (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1554"">#1554</a>)</p>; <p>User API:; a4f1f04c8 Allow fluent chaining setters for SAMSequenceRecord (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1563"">#1563</a>)</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/samtools/htsjdk/commit/4a4024a97ee3e87096df6ad9b22c8260bd527772""><code>4a4024a</code></a> Fix temporary directory hijacking or temporary directory information disclosu...</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/9fd0ecf212219d252ab273db0f7b845a59073d64""><code>9fd0ecf</code></a> Disable codecov until we can fix the uploader (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1622"">#1622</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/347c0ac571be29d7aa59fea3090947d9dcc9f8f0""><code>347c0ac</code></a> Fix EdgeReadIterator (<a href=""https://github-redirect.depe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12229:5737,depend,dependabot,5737,https://hail.is,https://github.com/hail-is/hail/pull/12229,1,['depend'],['dependabot']
Integrability," fix default value of app.env</li>; <li>Additional commits viewable in <a href=""https://github.com/pallets/flask/compare/2.0.3...2.2.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=flask&package-manager=pip&previous-version=2.0.3&new-version=2.2.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12206:10198,Depend,Dependabot,10198,https://hail.is,https://github.com/hail-is/hail/pull/12206,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability," fix warnings (<a href=""https://redirect.github.com/pygments/pygments/issues/2403"">#2403</a>)</li>; <li><a href=""https://github.com/pygments/pygments/commit/b018a65cb6ef51596c2cb8d6c97f0d79d9fa2ae7""><code>b018a65</code></a> Prepare for next release.</li>; <li>See full diff in <a href=""https://github.com/pygments/pygments/compare/2.15.0...2.15.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pygments&package-manager=pip&previous-version=2.15.0&new-version=2.15.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12909:4179,Depend,Dependabot,4179,https://hail.is,https://github.com/hail-is/hail/pull/12909,1,['Depend'],['Dependabot']
Integrability," fixed version:; - hail/python/dev/pinned-requirements.txt. <details>; <summary>⚠️ <b>Warning</b></summary>. ```; jupyter 1.0.0 requires notebook, which is not installed.; jupyter 1.0.0 requires qtconsole, which is not installed.; beautifulsoup4 4.12.2 requires soupsieve, which is not installed.; argon2-cffi-bindings 21.2.0 requires cffi, which is not installed.; aiosignal 1.3.1 requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **461/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.5 | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3MThjYjgyZC1jNGU3LTRlNWEtODgzZi02NjQ0NjlmYzA4MGEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjcxOG",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14070:1284,Message,Message,1284,https://hail.is,https://github.com/hail-is/hail/pull/14070,1,['Message'],['Message']
Integrability," flush (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2125"">#2125</a>) (<a href=""https://github.com/googleapis/java-storage/commit/c099a2f4f8ea9afa6953270876653916b021fd9f"">c099a2f</a>)</li>; <li>Update GrpcStorageImpl.createFrom(BlobInfo, Path) to use RewindableContent (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2112"">#2112</a>) (<a href=""https://github.com/googleapis/java-storage/commit/c80505129baa831e492a5514e937875407211595"">c805051</a>)</li>; </ul>; <h3>Documentation</h3>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/googleapis/java-storage/commit/d0b4ef7ac4a1c05658f8c6c3aac4a84e9691a732""><code>d0b4ef7</code></a> chore(main): release 2.26.1 (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2161"">#2161</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/a35d4ce1dc8492ecf2b5db76c137b3bcf5b7b0ca""><code>a35d4ce</code></a> chore(deps): update dependency com.google.cloud:libraries-bom to v26.22.0 (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2"">#2</a>...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/4f5682a4f6d6d5372a2d382ae3e47dace490ca0d""><code>4f5682a</code></a> deps: update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.24...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/8627f7b141a53ca90a997f1f70126b1d1272784a""><code>8627f7b</code></a> chore(deps): update dependency com.google.cloud:google-cloud-storage to v2.26...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/95df758d6753005226556177e68a3e9c630c789b""><code>95df758</code></a> fix: update gRPC writeAndClose to only set finish_write on the last message (...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/e9746f856e9204c1c0ec62f19e6f71ff8a0b9750""><code>e9746f8</code></a> fix: make use of Immutab",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13605:9514,depend,dependency,9514,https://hail.is,https://github.com/hail-is/hail/pull/13605,1,['depend'],['dependency']
Integrability," for each example in test_examples.py</li>; <li><a href=""https://github.com/pyparsing/pyparsing/commit/eb9db9eb65f973f59d2c42ef20c6bb6cd974059a""><code>eb9db9e</code></a> Add common, unicode, and testing to <strong>all</strong></li>; <li>Additional commits viewable in <a href=""https://github.com/pyparsing/pyparsing/compare/pyparsing_3.0.9...3.1.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyparsing&package-manager=pip&previous-version=3.0.9&new-version=3.1.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13345:9807,Depend,Dependabot,9807,https://hail.is,https://github.com/hail-is/hail/pull/13345,1,['Depend'],['Dependabot']
Integrability," for hiding copy button in prompts</li>; <li><a href=""https://github.com/spatialaudio/nbsphinx/commit/8bd255757ade0d072e5e13c9da706e002d6fa050""><code>8bd2557</code></a> Change internal representation of _BROKEN_THUMBNAIL</li>; <li><a href=""https://github.com/spatialaudio/nbsphinx/commit/4fc5c011f5d97b58485ffeb1b02c9f8bae58b657""><code>4fc5c01</code></a> CI: add -y flag to apt-get calls</li>; <li>Additional commits viewable in <a href=""https://github.com/spatialaudio/nbsphinx/compare/0.8.3...0.8.8"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=nbsphinx&package-manager=pip&previous-version=0.8.3&new-version=0.8.8)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11477:7581,depend,dependabot,7581,https://hail.is,https://github.com/hail-is/hail/pull/11477,1,['depend'],['dependabot']
Integrability," for negative numbers (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/41"">#41</a>) <a href=""https://github.com/vishket""><code>@​vishket</code></a></li>; </ul>; <h2>4.2.3</h2>; <h2>Fixed</h2>; <ul>; <li>Update annotations, docs, and tests: <code>naturaltime</code> can also accept a <code>timedelta</code> (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/31"">#31</a>) <a href=""https://github.com/nuztalgia""><code>@​nuztalgia</code></a></li>; </ul>; <h2>4.2.2</h2>; <h2>Fixed</h2>; <ul>; <li>Update annotations: <code>naturadelta</code> and <code>naturaltime</code> can also accept a <code>float</code> (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/29"">#29</a>) <a href=""https://github.com/hugovk""><code>@​hugovk</code></a></li>; </ul>; <h2>4.2.1</h2>; <h2>Fixed</h2>; <ul>; <li>Rename Arabic locale from <code>ar_SA</code> to <code>ar</code> to enable fallbacks (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/27"">#27</a>) <a href=""https://github.com/hugovk""><code>@​hugovk</code></a></li>; <li>Use <code>%d</code> for year translations, convert to string for <code>intcomma</code> after (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/23"">#23</a>) <a href=""https://github.com/carterbox""><code>@​carterbox</code></a></li>; <li>Fix <code>intcomma</code> with <code>ndigits=0</code> (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/26"">#26</a>) <a href=""https://github.com/hugovk""><code>@​hugovk</code></a></li>; </ul>; <h2>4.2.0</h2>; <h2>Added</h2>; <ul>; <li>Add <code>humanize.metric()</code> for converting big/small numbers to SI units (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/22"">#22</a>) <a href=""https://github.com/bwoodsend""><code>@​bwoodsend</code></a></li>; <li>Add type hints (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/iss",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12329:3403,depend,dependabot,3403,https://hail.is,https://github.com/hail-is/hail/pull/12329,1,['depend'],['dependabot']
Integrability," from <a href=""https://github.com/dateutil/dateutil/blob/master/NEWS"">python-dateutil's changelog</a>.</em></p>; <blockquote>; <h1>Version 2.8.2 (2021-07-08)</h1>; <h2>Data updates</h2>; <ul>; <li>Updated tzdata version to 2021a. (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1128"">#1128</a>)</li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>Fixed a bug in the parser where non-<code>ValueError</code> exceptions would be raised; during exception handling; this would happen, for example, if an; <code>IllegalMonthError</code> was raised in <code>dateutil</code> code. Fixed by Mark Bailey.; (gh issue <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/981"">#981</a>, pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/987"">#987</a>).</li>; <li>Fixed the custom <code>repr</code> for <code>dateutil.parser.ParserError</code>, which was not; defined due to an indentation error. (gh issue <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/991"">#991</a>, gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/993"">#993</a>)</li>; <li>Fixed a bug that caused <code>b'</code> prefixes to appear in parse_isodate exception; messages. Reported and fixed by Paul Brown (<a href=""https://github.com/pawl""><code>@​pawl</code></a>) (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1122"">#1122</a>)</li>; <li>Make <code>isoparse</code> raise when trying to parse times with inconsistent use of; <code>:</code> separator. Reported and fixed by <a href=""https://github.com/mariocj89""><code>@​mariocj89</code></a> (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1125"">#1125</a>).</li>; <li>Fixed <code>tz.gettz()</code> not returning local time when passed an empty string.; Reported by <a href=""https://github.com/labrys""><code>@​labrys</code></a> (gh issues <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11518:5466,depend,dependabot,5466,https://hail.is,https://github.com/hail-is/hail/pull/11518,1,['depend'],['dependabot']
Integrability," from <a href=""https://github.com/python/importlib_metadata/blob/main/CHANGES.rst"">importlib-metadata's changelog</a>.</em></p>; <blockquote>; <h1>v4.11.3</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/372"">#372</a>: Removed cast of path items in FastPath, not needed.</li>; </ul>; <h1>v4.11.2</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/369"">#369</a>: Fixed bug where <code>EntryPoint.extras</code> was returning; match objects and not the extras strings.</li>; </ul>; <h1>v4.11.1</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/367"">#367</a>: In <code>Distribution.requires</code> for egg-info, if <code>requires.txt</code>; is empty, return an empty list.</li>; </ul>; <h1>v4.11.0</h1>; <ul>; <li>bpo-46246: Added <code>__slots__</code> to <code>EntryPoints</code>.</li>; </ul>; <h1>v4.10.2</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/365"">#365</a> and bpo-46546: Avoid leaking <code>method_name</code> in; <code>DeprecatedList</code>.</li>; </ul>; <h1>v4.10.1</h1>; <h1>v2.1.3</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/361"">#361</a>: Avoid potential REDoS in <code>EntryPoint.pattern</code>.</li>; </ul>; <h1>v4.10.0</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/354"">#354</a>: Removed <code>Distribution._local</code> factory. This; functionality was created as a demonstration of the; possible implementation. Now, the; <code>pep517 &lt;https://pypi.org/project/pep517&gt;</code>_ package; provides this functionality directly through; <code>pep517.meta.load &lt;https://github.com/pypa/pep517/blob/a942316305395f8f757f210e2b16f738af73f8b8/pep517/meta.py#L63-L73&gt;</code>_.</li>; </ul>; <h1>v4.9.0</h1>; <ul>; <li>Require Python 3.7 or later.</li>; </ul>; <!-- raw HTML omitted -->;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11596:1176,depend,dependabot,1176,https://hail.is,https://github.com/hail-is/hail/pull/11596,1,['depend'],['dependabot']
Integrability," from psf/dependabot/github_actions/github/codeql-act...</li>; <li><a href=""https://github.com/psf/requests/commit/60047ade64b0b882cbc94e047198818ab580911e""><code>60047ad</code></a> Bump github/codeql-action from 3.24.0 to 3.25.0</li>; <li><a href=""https://github.com/psf/requests/commit/31ebb8102c00f8cf8b396a6356743cca4362e07b""><code>31ebb81</code></a> Merge pull request <a href=""https://redirect.github.com/psf/requests/issues/6682"">#6682</a> from frenzymadness/pytest8</li>; <li>Additional commits viewable in <a href=""https://github.com/psf/requests/compare/v2.31.0...v2.32.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=requests&package-manager=pip&previous-version=2.31.0&new-version=2.32.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ign",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14555:10239,Depend,Dependabot,10239,https://hail.is,https://github.com/hail-is/hail/pull/14555,1,['Depend'],['Dependabot']
Integrability," from python/feature/clean-entry-points</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/ac9ff953a00d86c341f2a9a892c914d26075d891""><code>ac9ff95</code></a> Update documentation around removal of SelectableGroups.</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/117d1b470f8c03b4f4e332a95ccfcfebdadb8f52""><code>117d1b4</code></a> Disable flake8 due to incompatibility.</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/2135490a9d965339de71aa18dd2955844db966aa""><code>2135490</code></a> Update changelog</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/6ed01ae3d6cb169e5729ddcf0f6d5a5d77190f7e""><code>6ed01ae</code></a> Merge removal commits into feature/clean-entry-points</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/dde2b9de2973ce1c6fa9ba21dfe81069b0baa77b""><code>dde2b9d</code></a> Remove support for cast of iterable of entry points to dict. Ref <a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/97"">#97</a>.</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/0c819641d314ac496eb32b55f2b15215fa6fa55f""><code>0c81964</code></a> Remove compatibility for EntryPoints.<strong>getitem</strong> by index.</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/47544ce7303da9b2147c6603a674a1f82225248f""><code>47544ce</code></a> Remove DeprecatedList</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/7e5bae4c7fbd30366e49249825171b193dff22d4""><code>7e5bae4</code></a> Remove SelectableGroups</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/9a6641b91088daaa4ae0134d24fc130f1da69a37""><code>9a6641b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/401"">#401</a> from CAM-Gerlach/add-note-api-docs</li>; <li>Additional commits viewable in <a href=""https://github.com/python/importlib_metadata/compare/v3.10.1...v5.0.0"">compa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12391:3837,depend,dependabot,3837,https://hail.is,https://github.com/hail-is/hail/pull/12391,1,['depend'],['dependabot']
Integrability," from showtraceback()</li>; <li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/7.34.0...8.10.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ipython&package-manager=pip&previous-version=7.34.0&new-version=8.10.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12683:2856,Depend,Dependabot,2856,https://hail.is,https://github.com/hail-is/hail/pull/12683,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability," guaranteed</li>; <li><a href=""https://github.com/corydolphin/flask-cors/commit/566aef21accd0a15cf127a41edbe14a40c80728c""><code>566aef2</code></a> Fixed over-indentation</li>; <li><a href=""https://github.com/corydolphin/flask-cors/commit/8a4e6e7057924d124a39ec08f446345bc19e4c5b""><code>8a4e6e7</code></a> Update changelog to give proper kudos to <a href=""https://github.com/juanmaneo""><code>@​juanmaneo</code></a> and <a href=""https://github.com/jdevera""><code>@​jdevera</code></a></li>; <li>See full diff in <a href=""https://github.com/corydolphin/flask-cors/compare/3.0.8...3.0.9"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=flask-cors&package-manager=pip&previous-version=3.0.8&new-version=3.0.9)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10464:3304,Depend,Dependabot,3304,https://hail.is,https://github.com/hail-is/hail/pull/10464,1,['Depend'],['Dependabot']
Integrability," hail/python/hailtop/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-5663682](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-5663682) | `cryptography:` <br> `40.0.2 -> 41.0.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmZWM3ZmQ2Ny0xZmE0LTRlNzEtODQ4Ni1hMDk5YThmYWM3NzgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImZlYzdmZDY3LTFmYTQtNGU3MS04NDg2LWEwOTlhOGZhYzc3OCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13138:1247,depend,dependency,1247,https://hail.is,https://github.com/hail-is/hail/pull/13138,2,['depend'],"['dependencies', 'dependency']"
Integrability," hail/python/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **658/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.3 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-5798483](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-5798483) | `aiohttp:` <br> `3.8.4 -> 3.8.5` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlMjk5ZmU1Ni0wNGI1LTQ3MzEtYmUzYS03M2ZmYzgxZTZjYjgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImUyOTlmZTU2LTA0YjUtNDczMS1iZTNhLTczZmZjODFlNmNiOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13283:1339,depend,dependency,1339,https://hail.is,https://github.com/hail-is/hail/pull/13283,2,['depend'],"['dependencies', 'dependency']"
Integrability," has much better performance.</li>; <li>Fix TextFormat parser to build up recurring (but supposedly not repeated); sub-messages directly from text rather than building a new sub-message and; merging the fully formed message into the existing field.</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-h4h5-3hr4-j3g2"">Security Advisory for Java users</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/protocolbuffers/protobuf/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.2&new-version=4.21.9)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12518:1880,Depend,Dependabot,1880,https://hail.is,https://github.com/hail-is/hail/pull/12518,1,['Depend'],['Dependabot']
Integrability," header). /opt/conda/lib/python3.7/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 575 def wrapper(__original_func, *args, **kwargs):; 576 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 577 return __original_func(*args_, **kwargs_); 578 ; 579 return wrapper. /opt/conda/lib/python3.7/site-packages/hail/expr/expressions/base_expression.py in export(self, path, delimiter, missing, header); 1068 **{output_col_name: hl.delimit(column_names, delimiter)}); 1069 file_contents = header_table.union(file_contents); -> 1070 file_contents.export(path, delimiter=delimiter, header=False); 1071 ; 1072 @typecheck_method(n=int, _localize=bool). <decorator-gen-1190> in export(self, output, types_file, header, parallel, delimiter). /opt/conda/lib/python3.7/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 575 def wrapper(__original_func, *args, **kwargs):; 576 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 577 return __original_func(*args_, **kwargs_); 578 ; 579 return wrapper. /opt/conda/lib/python3.7/site-packages/hail/table.py in export(self, output, types_file, header, parallel, delimiter); 1097 parallel = ir.ExportType.default(parallel); 1098 Env.backend().execute(; -> 1099 ir.TableWrite(self._tir, ir.TableTextWriter(output, types_file, header, parallel, delimiter))); 1100 ; 1101 def group_by(self, *exprs, **named_exprs) -> 'GroupedTable':. /opt/conda/lib/python3.7/site-packages/hail/backend/py4j_backend.py in execute(self, ir, timed); 103 return (value, timings) if timed else value; 104 except FatalError as e:; --> 105 raise e.maybe_user_error(ir) from None; 106 ; 107 async def _async_execute(self, ir, timed=False):. /opt/conda/lib/python3.7/site-packages/hail/backend/py4j_backend.py in execute(self, ir, timed); 97 # print(self._hail_package.expr.ir.Pretty.apply(jir, True, -1)); 98 try:; ---> 99 result_tuple = self._jba",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287#issuecomment-1664593619:1718,wrap,wrapper,1718,https://hail.is,https://github.com/hail-is/hail/issues/13287#issuecomment-1664593619,3,['wrap'],['wrapper']
Integrability," header). /opt/conda/lib/python3.7/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 575 def wrapper(__original_func, *args, **kwargs):; 576 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 577 return __original_func(*args_, **kwargs_); 578 ; 579 return wrapper. /opt/conda/lib/python3.7/site-packages/hail/expr/expressions/base_expression.py in export(self, path, delimiter, missing, header); 1068 **{output_col_name: hl.delimit(column_names, delimiter)}); 1069 file_contents = header_table.union(file_contents); -> 1070 file_contents.export(path, delimiter=delimiter, header=False); 1071 ; 1072 @typecheck_method(n=int, _localize=bool). <decorator-gen-1193> in export(self, output, types_file, header, parallel, delimiter). /opt/conda/lib/python3.7/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 575 def wrapper(__original_func, *args, **kwargs):; 576 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 577 return __original_func(*args_, **kwargs_); 578 ; 579 return wrapper. /opt/conda/lib/python3.7/site-packages/hail/table.py in export(self, output, types_file, header, parallel, delimiter); 1097 parallel = ir.ExportType.default(parallel); 1098 Env.backend().execute(; -> 1099 ir.TableWrite(self._tir, ir.TableTextWriter(output, types_file, header, parallel, delimiter))); 1100 ; 1101 def group_by(self, *exprs, **named_exprs) -> 'GroupedTable':. /opt/conda/lib/python3.7/site-packages/hail/backend/py4j_backend.py in execute(self, ir, timed); 103 return (value, timings) if timed else value; 104 except FatalError as e:; --> 105 raise e.maybe_user_error(ir) from None; 106 ; 107 async def _async_execute(self, ir, timed=False):. /opt/conda/lib/python3.7/site-packages/hail/backend/py4j_backend.py in execute(self, ir, timed); 97 # print(self._hail_package.expr.ir.Pretty.apply(jir, True, -1)); 98 try:; ---> 99 result_tuple = self._jba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287:3001,wrap,wrapper,3001,https://hail.is,https://github.com/hail-is/hail/issues/13287,3,['wrap'],['wrapper']
Integrability," hl.utils.range_matrix_table(4, 4); mt2 = hl.utils.range_matrix_table(4, 4); mt2 = mt2.annotate_entries(x=mt2.row_idx + mt2.col_idx); mt.select_entries(a=mt2[mt.row_idx, mt.col_idx].x,; b=mt2[mt.row_idx, mt.col_idx].x)._force_count_rows(); ```. ### What went wrong (all error messages here, including the full java stack trace):. ```; Error; Traceback (most recent call last):; File ""/Users/jbloom/anaconda/envs/py36/lib/python3.6/unittest/case.py"", line 59, in testPartExecutor; yield; File ""/Users/jbloom/anaconda/envs/py36/lib/python3.6/unittest/case.py"", line 605, in run; testMethod(); File ""/Users/jbloom/hail/python/hail/tests/test_api.py"", line 1557, in test_force_bug; b=mt2[mt.row_idx, mt.col_idx].x)._force_count_rows(); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 1171, in select_entries; return self._select_entries(""MatrixTable.select_entries"", hl.struct(**entry)); File ""/Users/jbloom/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 2844, in _select_entries; base, cleanup = self._process_joins(s); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 2503, in _process_joins; return process_joins(self, exprs, broadcast_f); File ""/Users/jbloom/hail/python/hail/utils/misc.py"", line 356, in process_joins; left = j.join_func(left); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 2414, in joiner; col_exprs = {col_uid: src_cols_indexed.index(*col_exprs)[col_uid]}); File ""/Users/jbloom/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 2443, in _annotate_all; analyze(""MatrixTable.annotate_rows"", row_struct, self._row_indices); File ""/Users/jbloom/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/jbloom/hail/python/hail/expr/expressions/expression_utils.py"", line 105, in analyze; raise errors[0]; hai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3763:1860,wrap,wrapper,1860,https://hail.is,https://github.com/hail-is/hail/issues/3763,1,['wrap'],['wrapper']
Integrability," href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5988"">#5988</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/b25859c4a56ccce61087f7a1270f40deaed68169""><code>b25859c</code></a> Fix false positive for <code>superfluous-parens</code> for <code>return (a or b) in iterable</code>...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/0e1ca11ac65cbe5a65437518fca1e25f1ad0e48e""><code>0e1ca11</code></a> Bump pylint to 2.13.1, update changelog</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/v2.12.2...v2.13.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pylint&package-manager=pip&previous-version=2.12.2&new-version=2.13.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11702:5062,Depend,Dependabot,5062,https://hail.is,https://github.com/hail-is/hail/pull/11702,1,['Depend'],['Dependabot']
Integrability," href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11205"">#11205</a> [component: bokehjs] [BUG] Hover tooltip breaks with full-circle wedge</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11339"">#11339</a> [BUG] Toggling layout's visibility results with overlapping widgets</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11462"">#11462</a> [component: bokehjs] [BUG] Existing ColorBar tick-digits don't react to theme changes</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11475"">#11475</a> [component: bokehjs] [BUG] SVG export breaks for Wedges</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11623"">#11623</a> [BUG] Placement of toolbar location is broken for gridplots</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11643"">#11643</a> Refs are not resolved in data models' default values</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11673"">#11673</a> [component: bokehjs] [BUG] JavaScript error when setting LabelSet text to None</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11694"">#11694</a> Custom extension breaks with id as key in a dict param</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11750"">#11750</a> [component: bokehjs] [BUG] Hover tool takes long time to render (-&gt; <a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11629"">#11629</a>)</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11770"">#11770</a> [component: bokehjs] [BUG] Linking an axis range can lead to other axis range autoscaling improperly</li>; </ul>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/bokeh/bokeh/commit/17a0b288052afac80ebcf0aa74e3915452fce3ca""><code>17a0b28</code></a> Deploymen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12454:6769,depend,dependabot,6769,https://hail.is,https://github.com/hail-is/hail/pull/12454,1,['depend'],['dependabot']
Integrability," href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/74"">brettcannon/gidgethub#74</a>).</li>; <li>Add support for GitHub Actions Environment Files with <code>gidgethub.actions.setenv</code>; and <code>gidgethub.actions.addpath</code>.; [Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/137"">#137</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/132"">brettcannon/gidgethub#132</a>).</li>; <li>Make router callback execution order non-deterministic to avoid relying on; registration order.; [Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/74"">#74</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/74"">brettcannon/gidgethub#74</a>).</li>; <li>Fix mypy errors in <code>gidgethub.httpx.GitHubAPI._request</code>[Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/133"">#133</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/133"">brettcannon/gidgethub#133</a>).</li>; <li>Make the minimum version of PyJWT be v2.0.0.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/brettcannon/gidgethub/blob/main/docs/changelog.rst"">gidgethub's changelog</a>.</em></p>; <blockquote>; <h2>5.2.1</h2>; <ul>; <li>; <p>Fix cgi and importlib_resources deprecations.; (<code>PR [#185](https://github.com/brettcannon/gidgethub/issues/185) &lt;https://github.com/brettcannon/gidgethub/pull/185&gt;_</code>)</p>; </li>; <li>; <p>Add support for Python 3.11 and drop EOL Python 3.6; (<code>PR [#184](https://github.com/brettcannon/gidgethub/issues/184) &lt;https://github.com/brettcannon/gidgethub/pull/184&gt;_</code>)</p>; </li>; </ul>; <h2>5.2.0</h2>; <ul>; <li>Make the minimum version of PyJWT be v2.4.0.</li>; </ul>; <h2>5.1.0</h2>; <ul>; <li>; <p>Use <code>X-Hub-Signature-256</code> header for webhook validation when availa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12328:3953,depend,dependabot,3953,https://hail.is,https://github.com/hail-is/hail/pull/12328,1,['depend'],['dependabot']
Integrability," href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2837"">cbeust/testng#2837</a></li>; <li>Support getting dependencies info for a test by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2839"">cbeust/testng#2839</a></li>; <li>Honour regex in dependsOnMethods by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2838"">cbeust/testng#2838</a></li>; <li>Ensure All tests run all the time by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2842"">cbeust/testng#2842</a></li>; <li>Deprecate support for running Spock Tests by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2846"">cbeust/testng#2846</a></li>; <li>Streamline dependsOnMethods for configurations by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2845"">cbeust/testng#2845</a></li>; <li>Ensure ITestContext available for JUnit4 tests by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2848"">cbeust/testng#2848</a></li>; <li>Deprecate support for running JUnit tests by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2849"">cbeust/testng#2849</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/gruenich""><code>@​gruenich</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2781"">cbeust/testng#2781</a></li>; <li><a href=""https://github.com/anatolyuzhakov""><code>@​anatolyuzhakov</code>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:7355,depend,dependsOnMethods,7355,https://hail.is,https://github.com/hail-is/hail/pull/12665,1,['depend'],['dependsOnMethods']
Integrability," href=""https://github-redirect.dependabot.com/fsspec/gcsfs/issues/438"">#438</a>)</li>; <li><a href=""https://github.com/fsspec/gcsfs/commit/cbf751e83785d8b7e5d7ea879e5534e32d633ae0""><code>cbf751e</code></a> Don't touch cache on find with prefix (<a href=""https://github-redirect.dependabot.com/fsspec/gcsfs/issues/437"">#437</a>)</li>; <li><a href=""https://github.com/fsspec/gcsfs/commit/7b5aee98724c7ca44a73524bf448089ac4b79b75""><code>7b5aee9</code></a> for release (<a href=""https://github-redirect.dependabot.com/fsspec/gcsfs/issues/435"">#435</a>)</li>; <li><a href=""https://github.com/fsspec/gcsfs/commit/4de170703d3f245a2e4f5e5c7abcef3ad3ec33c7""><code>4de1707</code></a> fixup references to dask/gcsfs (<a href=""https://github-redirect.dependabot.com/fsspec/gcsfs/issues/434"">#434</a>)</li>; <li><a href=""https://github.com/fsspec/gcsfs/commit/8f7115216346648bacc57f5910048cab5735b9b3""><code>8f71152</code></a> Add support to additional 'fixed-key-metadata' (<a href=""https://github-redirect.dependabot.com/fsspec/gcsfs/issues/429"">#429</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/fsspec/gcsfs/compare/2021.04.0...2022.02.0"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11575:2394,depend,dependabot,2394,https://hail.is,https://github.com/hail-is/hail/pull/11575,1,['depend'],['dependabot']
Integrability," href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30412"">#30412</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/9479089ac8cb99e66a71eab687b06ce220a94838""><code>9479089</code></a> xds interop: choose correct cluster in grpc_xds_k8s_lb_python.sh (1.48.x back...</li>; <li><a href=""https://github.com/grpc/grpc/commit/d2054ec6c6e8abcecf0e24b0b4ee75035d80c3cc""><code>d2054ec</code></a> Bump version to 1.48.0 (on v1.48.x branch) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30326"">#30326</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/4c51abf12053e3c43a62059c693322ea992b35ce""><code>4c51abf</code></a> Bump version to 1.48.0-pre1 (on v1.48.x branch) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30194"">#30194</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/46bd0be2c99aa8228ec5d93d8a27f20ab0c61956""><code>46bd0be</code></a> Bump core version to 26.0.0 for upcoming release (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30163"">#30163</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/grpc/grpc/compare/v1.47.0...v1.48.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=grpcio&package-manager=pip&previous-version=1.47.0&new-version=1.48.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwrit",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12201:5915,depend,dependabot,5915,https://hail.is,https://github.com/hail-is/hail/pull/12201,1,['depend'],['dependabot']
Integrability," href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/896"">#896</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/915"">#915</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/921"">#921</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/928"">#928</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/934"">#934</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/microsoft/debugpy/commit/8b5eeee7e0b1678e701b07d94e6c3cf07b923597""><code>8b5eeee</code></a> Fix <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/1008"">#1008</a>: Re-attaching continuously creates 'accept_worker' threads in debugpy</li>; <li><a href=""https://github.com/microsoft/debugpy/commit/71d42ed63fdbac538b3341a2dc585583eb44e881""><code>71d42ed</code></a> Support top-level async. Fixes <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/951"">#951</a></li>; <li><a href=""https://github.com/microsoft/debugpy/commit/6e247fb17bc15488a2cbefb7eed80c87179b147c""><code>6e247fb</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/1009"">#1009</a> from rchiodo/rchiodo/missed_thread_for_self_trace</li>; <li><a href=""https://github.com/microsoft/debugpy/commit/cccfb954bd7321fbb25f234f0c9a2e8372646297""><code>cccfb95</code></a> Missed a thread to allow debugging</li>; <li><a href=""https://github.com/microsoft/debugpy/commit/6c19aba462d2a9b6ea79d5cbce2886bd961823eb""><code>6c19aba</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/1007"">#1007</a> from rchiodo/rchiodo/allow_adapter_debugging</li>; <li><a href=""https://github.com/microsoft/debugpy/commit/10d8839a4cac4bdaf99cfe44ca2ee5479c95c003""><code>10d8839</code></a> Review feedback</li>; <li><a href=""https://github.com/microsoft/debugpy/commit/83ff280",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12103:3291,depend,dependabot,3291,https://hail.is,https://github.com/hail-is/hail/pull/12103,2,['depend'],['dependabot']
Integrability," href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9660"">#9660</a> from pytest-dev/backport-9646-to-7.0.x</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/37d434f5fcb5f80188b3d5b8f22d418dc191b955""><code>37d434f</code></a> [7.0.x] Delay warning about collector/item diamond inheritance</li>; <li>Additional commits viewable in <a href=""https://github.com/pytest-dev/pytest/compare/6.2.5...7.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest&package-manager=pip&previous-version=6.2.5&new-version=7.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11516:7062,depend,dependabot-automerge-start,7062,https://hail.is,https://github.com/hail-is/hail/pull/11516,6,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability," href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1507"">#1507</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1595"">#1595</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/22aec6782b33f8d169a5d1cf63e952126a3f09e0""><code>22aec67</code></a> Fix decoding of CRAM Scores read feature during normalization. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1592"">#1592</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/samtools/htsjdk/compare/2.24.1...3.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.github.samtools:htsjdk&package-manager=gradle&previous-version=2.24.1&new-version=3.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12310:9095,Depend,Dependabot,9095,https://hail.is,https://github.com/hail-is/hail/pull/12310,1,['Depend'],['Dependabot']
Integrability," href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1595"">#1595</a>); a38c78d6c Add an option to SAMFileWriter to disable checking of ordering of rec… (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1599"">#1599</a>); 51aa6ed2b Validate that SAM header tag keys are exactly 2 characters long (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1561"">#1561</a>); fbd9e96d5 Deprecate OTHER as a PL value (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1552"">#1552</a>); d5f7e106b Adding PL Tag 'DNBSEQ' as the Platform/Technology for BGI/MGI (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1547"">#1547</a>)</p>; <p>Misc Improvements; f461401e3 Silence AsciiLineReader warning when creating a FASTA sequence index (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1559"">#1559</a>); 8f82871c1 Update explain samflags script to python3 (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1585"">#1585</a>); 4ba4c0678 Update to new version of the snappy library which will work with M1 macs (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1580"">#1580</a>); e92706452 add predicate to GFF3Codec to give a chance to filter out some unused attributes (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1575"">#1575</a>); c647764b0 Some long reads tests using PacBio data. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1564"">#1564</a>); 57c3f03eb remove hardcoded .idx (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1568"">#1568</a>); a94a32512 Add file extension to missing index error message <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1512"">#1512</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1567"">#1567</a>); 74b827b67 Improve error message in IntervalTree (<a href=""https://github-redirect.dependabot.com",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12229:4056,depend,dependabot,4056,https://hail.is,https://github.com/hail-is/hail/pull/12229,1,['depend'],['dependabot']
Integrability," href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1595"">#1595</a>); a38c78d6c Add an option to SAMFileWriter to disable checking of ordering of rec… (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1599"">#1599</a>); 51aa6ed2b Validate that SAM header tag keys are exactly 2 characters long (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1561"">#1561</a>); fbd9e96d5 Deprecate OTHER as a PL value (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1552"">#1552</a>); d5f7e106b Adding PL Tag 'DNBSEQ' as the Platform/Technology for BGI/MGI (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1547"">#1547</a>)</p>; <p>Misc Improvements; f461401e3 Silence AsciiLineReader warning when creating a FASTA sequence index (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1559"">#1559</a>); 8f82871c1 Update explain samflags script to python3 (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1585"">#1585</a>); 4ba4c0678 Update to new version of the snappy library which will work with M1 macs (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1580"">#1580</a>); e92706452 add predicate to GFF3Codec to give a chance to filter out some unused attributes (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1575"">#1575</a>); c647764b0 Some long reads tests using PacBio data. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1564"">#1564</a>)</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/samtools/htsjdk/commit/02942a97ef6e7e14019efa502b0b03fea3c68c1f""><code>02942a9</code></a> Remove deprecation from Allele.acceptableAlleleBases <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1623"">#1623</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12310:5142,depend,dependabot,5142,https://hail.is,https://github.com/hail-is/hail/pull/12310,1,['depend'],['dependabot']
Integrability," href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/350"">spyder-ide/qtpy#350</a></li>; <li>PR: Add note to readme about use with Pyright by <a href=""https://github.com/CAM-Gerlach""><code>@​CAM-Gerlach</code></a> in <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/353"">spyder-ide/qtpy#353</a></li>; <li>PR: Add wrapper around sip/shiboken isdeleted/isvalid (compat.py) by <a href=""https://github.com/zjp""><code>@​zjp</code></a> in <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/354"">spyder-ide/qtpy#354</a></li>; <li>PR: Fix PyQt6 typing import for Qt by <a href=""https://github.com/tlambert03""><code>@​tlambert03</code></a> in <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/358"">spyder-ide/qtpy#358</a></li>; <li>PR: Add initial <code>Methods, helpers and QtPy namespace specifics</code> section to the README by <a href=""https://github.com/dalthviz""><code>@​dalthviz</code></a> in <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/357"">spyder-ide/qtpy#357</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/DaelonSuzuka""><code>@​DaelonSuzuka</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/344"">spyder-ide/qtpy#344</a></li>; <li><a href=""https://github.com/zjp""><code>@​zjp</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/354"">spyder-ide/qtpy#354</a></li>; </ul>; <p><strong>Full commits list between this release and the previous one</strong>: <a href=""https://github.com/spyder-ide/qtpy/compare/v2.1.0...v2.2.0"">https://github.com/spyder-ide/qtpy/compare/v2.1.0...v2.2.0</a>; <strong>Full Changelog</strong>: <a href=""https://github.com/spyder-ide/qtpy/blob/master/CHANGELOG.md#version-220-2022-08-10"">CHANGELOG.md - Version 2.2.0 (2022-08-10)</a></p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced fr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12194:1935,depend,dependabot,1935,https://hail.is,https://github.com/hail-is/hail/pull/12194,1,['depend'],['dependabot']
Integrability," href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/25"">#25</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/77"">#77</a>).</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Add more descriptive error message for missing whitespace between HTML attributes (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/23#issuecomment-700622837"">#23 (comment)</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; <li>Move development dependencies from extras to separate <code>requirements.txt</code> (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; <li>Declare support for Python 3.9.</li>; <li>Tentatively declare support for Python 3.10 (tested with <code>Python 3.10.0a6+</code>).</li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Fix Python 3.10 deprecation warning by importing Iterable from collections.abc (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; </ul>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.12.2"">v0.12.2</a> 2021-03-06</h2>; <h3>Fixed</h3>; <ul>; <li>The <code>image_alt</code> rule no longer crashes when encountering template conditionals in img attributes (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/57"">#57</a>). Thanks to <a href=""https://github.com/adrien-delhorme""><code>@​adrien-delhorme</code></a>.</li>; </ul>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.12.1"">v0.12.1</a> 2021-03-06</h2>; <h3>Fixed</h3>; <ul>; <li>The project’s sdist now includes all needed files to run the test suite (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/49"">#49</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/50"">#50</a>). Thanks to <a href=""https://github.com/jayvdb""><code>@​jayvdb</code></a>.</li>; </ul>; </blockquote>; </details>; <d",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11494:4181,depend,dependabot,4181,https://hail.is,https://github.com/hail-is/hail/pull/11494,3,['depend'],['dependabot']
Integrability," href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/25"">#25</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/77"">#77</a>).</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Add more descriptive error message for missing whitespace between HTML attributes (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/23#issuecomment-700622837"">#23 (comment)</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; <li>Move development dependencies from extras to separate <code>requirements.txt</code> (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; <li>Declare support for Python 3.9.</li>; <li>Tentatively declare support for Python 3.10 (tested with <code>Python 3.10.0a6+</code>).</li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Fix Python 3.10 deprecation warning by importing Iterable from collections.abc (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; </ul>; <h2>v0.12.2</h2>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.12.2"">v0.12.2</a> 2021-03-06</h2>; <h3>Fixed</h3>; <ul>; <li>The <code>image_alt</code> rule no longer crashes when encountering template conditionals in img attributes (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/57"">#57</a>). Thanks to <a href=""https://github.com/adrien-delhorme""><code>@​adrien-delhorme</code></a>.</li>; </ul>; <h2>v0.12.1</h2>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.12.1"">v0.12.1</a> 2021-03-06</h2>; <h3>Fixed</h3>; <ul>; <li>The project’s sdist now includes all needed files to run the test suite (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/49"">#49</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/50"">#50</a>). Thanks to <a href=""https://github.com/jayvdb""><code>@​jayvdb</code></a>.</li>; ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11494:1632,depend,dependabot,1632,https://hail.is,https://github.com/hail-is/hail/pull/11494,3,['depend'],['dependabot']
Integrability," href=""https://github.com/Azure/azure-sdk-for-java/commit/44d679faee209611bee14fcea08207f9753bb466""><code>44d679f</code></a> Increment versions for appcomplianceautomation releases (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32155"">#32155</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/020145e20dff874555f4e610bc9b5b39213b1740""><code>020145e</code></a> move processor-lifecycle-manager from messaging to service module (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32152"">#32152</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/69d2f672399502021a8f8918a7d5962c3005f687""><code>69d2f67</code></a> [Automation] Generate Fluent Lite from appcomplianceautomation#package-2022-1...</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/20a07b197d8afa5f0f5f65b9e448c938ffad354e""><code>20a07b1</code></a> November 2022 release (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32153"">#32153</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/17da0b33c07ee121d68a957879e314fb2bceba5e""><code>17da0b3</code></a> mgmt, update codegen for dependency conflict (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32150"">#32150</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-java/compare/azure-storage-blob_12.13.0...azure-storage-blob_12.20.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.azure:azure-storage-blob&package-manager=gradle&previous-version=12.13.0&new-version=12.20.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can al",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12477:5149,depend,dependabot,5149,https://hail.is,https://github.com/hail-is/hail/pull/12477,1,['depend'],['dependabot']
Integrability," href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/289a94f694645c642ae67b2d5972d3f9fdadb928""><code>289a94f</code></a> Remove old classes that are deprecated for 2 years</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/fa1f45b556341b2c34e9bf63c06a5068571cd337""><code>fa1f45b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/108"">#108</a> from AzureAD/actionable-encryption-exceptions</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/effe77842d25a8b093d18d9e33347f13e2ee094f""><code>effe778</code></a> Provide actionable messages for 2 dpapi errors</li>; <li><a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/commit/b674b6a07ca27b2c1b6f371040f035a546cfd468""><code>b674b6a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/AzureAD/microsoft-authentication-extensions-for-python/issues/107"">#107</a> from AzureAD/file600</li>; <li>Additional commits viewable in <a href=""https://github.com/AzureAD/microsoft-authentication-extensions-for-python/compare/0.3.1...1.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=msal-extensions&package-manager=pip&previous-version=0.3.1&new-version=1.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11992:4291,depend,dependabot,4291,https://hail.is,https://github.com/hail-is/hail/pull/11992,1,['depend'],['dependabot']
Integrability," href=""https://github.com/ahg-g""><code>@​ahg-g</code></a>)</li>; <li>The AnyVolumeDataSource feature is now beta, and the feature gate is enabled by default. In order to provide user feedback on PVCs with data sources, deployers must install the VolumePopulators CRD and the data-source-validator controller. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108736"">kubernetes/kubernetes#108736</a>, <a href=""https://github.com/bswartz""><code>@​bswartz</code></a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/9ecc1143a8f7b34264b48dea12edd4d66230476f""><code>9ecc114</code></a> [chore] update version</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/ae5fd81a0fbea7d7fdac8d418876acaa288bcc0f""><code>ae5fd81</code></a> fix: config reader handles bool types (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/218"">#218</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/7bbb327cee0d4ed908a5deb28aaf5a9ccc1f4602""><code>7bbb327</code></a> [chore] update version</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/4d52e04e03c0195eef581919f9efa4b6d0bd35ea""><code>4d52e04</code></a> [chore] update changelog</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/078dde081f8be6b190bbe9271d9f8d3839b617c7""><code>078dde0</code></a> fixed watch.stream bug of not working with apis with follow kwarg (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/216"">#216</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/3ecb956c6af223b343ea5695d377982e98d4341c""><code>3ecb956</code></a> [chore] update version</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/65ce783fc3f015f9e464a90c028b902b58023c9b""><code>65ce783</code></a> [feat] regen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:14409,depend,dependabot,14409,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['depend'],['dependabot']
Integrability," href=""https://github.com/aio-libs/aiohttp-jinja2/commit/91c004dd135b18c3ffbc69646fc7f8706273e866""><code>91c004d</code></a> Auto-merge (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_jinja2/issues/468"">#468</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp_jinja2/compare/v1.1.1...v1.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp-jinja2&package-manager=pip&previous-version=1.1.1&new-version=1.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11576:7036,Depend,Dependabot,7036,https://hail.is,https://github.com/hail-is/hail/pull/11576,1,['Depend'],['Dependabot']
Integrability," href=""https://github.com/aio-libs/aiohttp-session/commit/44e60f51bdb1ecfc22fa8bc87e8d025f2f17cd90""><code>44e60f5</code></a> Minor changes to typing. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/672"">#672</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/bf9a5f0b87470dd145cff326b0b05f898f775d94""><code>bf9a5f0</code></a> Fix session resetting before expiry. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/671"">#671</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/36b8a0a5ed2caaaba9d5d3ece8aaf03ca45b6c34""><code>36b8a0a</code></a> Allow passing Fernet to Encrypted Cookie Storage (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/448"">#448</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/984decc496fe92e053c14949c8d3a60bacd62426""><code>984decc</code></a> Test on Python up to 3.10 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/634"">#634</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/936f76351450066903002d60286110007310a44f""><code>936f763</code></a> Bump aiomcache from 0.6.0 to 0.7.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/665"">#665</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/29ddff39290f4e2fbc7b9feb94eb622763e156e2""><code>29ddff3</code></a> Bump pytest-aiohttp from 0.3.0 to 1.0.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/668"">#668</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/3bc517092aff39330f2f96315e6f542e23415831""><code>3bc5170</code></a> Bump multidict from 5.2.0 to 6.0.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/670"">#670</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp_session/compare/v2.7.0...v2.11.0"">compare view</a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11544:3382,depend,dependabot,3382,https://hail.is,https://github.com/hail-is/hail/pull/11544,2,['depend'],['dependabot']
Integrability," href=""https://github.com/boto/boto3/commit/1de404aff4ecb1c5560b4e023f0614d8149622ed""><code>1de404a</code></a> fix typo: 'are specified the' should be 'are specified in the' (<a href=""https://github-redirect.dependabot.com/boto/boto3/issues/3499"">#3499</a>)</li>; <li><a href=""https://github.com/boto/boto3/commit/47f20744b3c57223da5e14e185120586f8212af8""><code>47f2074</code></a> Merge branch 'release-1.26.13'</li>; <li><a href=""https://github.com/boto/boto3/commit/3d4081ccb7c350538ba3d6a5073c59575a812eb0""><code>3d4081c</code></a> Merge branch 'release-1.26.13' into develop</li>; <li>Additional commits viewable in <a href=""https://github.com/boto/boto3/compare/1.26.7...1.26.15"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=boto3&package-manager=pip&previous-version=1.26.7&new-version=1.26.15)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12498:9589,depend,dependabot-security-updates,9589,https://hail.is,https://github.com/hail-is/hail/pull/12498,1,['depend'],['dependabot-security-updates']
Integrability," href=""https://github.com/dateutil/dateutil/commit/ee85831cc25d34ff597cfb3f2d90ce5904dbc561""><code>ee85831</code></a> Build releases with Python 3.9</li>; <li><a href=""https://github.com/dateutil/dateutil/commit/6b337ea412d399fb48771c544b1a6880763b46c6""><code>6b337ea</code></a> Automate cutting new releases</li>; <li><a href=""https://github.com/dateutil/dateutil/commit/9c2ad8f981ece1bdb3d52527f1cb39523b11d862""><code>9c2ad8f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1056"">#1056</a> from ffe4/issue_1029</li>; <li>Additional commits viewable in <a href=""https://github.com/dateutil/dateutil/compare/2.8.1...2.8.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=python-dateutil&package-manager=pip&previous-version=2.8.1&new-version=2.8.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11518:11438,depend,dependabot-security-updates,11438,https://hail.is,https://github.com/hail-is/hail/pull/11518,1,['depend'],['dependabot-security-updates']
Integrability," href=""https://github.com/elastic/elasticsearch-hadoop/commit/0a8e0bca839408ba7cdd4e1e4ef669894f29e96f""><code>0a8e0bc</code></a> [DOCS] Add 8.5.0 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2032"">#2032</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/4d09926f840998a20d4f45380723d2d77b46544a""><code>4d09926</code></a> [DOCS] Add 8.4.3 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2028"">#2028</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/d498aa068ef552aef9de3325e9d105611e5adbba""><code>d498aa0</code></a> Update index.adoc (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2000"">#2000</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/elastic/elasticsearch-hadoop/compare/v8.4.3...v8.6.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.elasticsearch:elasticsearch-spark-20_2.12&package-manager=gradle&previous-version=8.4.3&new-version=8.6.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI pass",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12623:5435,Depend,Dependabot,5435,https://hail.is,https://github.com/hail-is/hail/pull/12623,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability," href=""https://github.com/grpc/grpc/commit/46bd0be2c99aa8228ec5d93d8a27f20ab0c61956""><code>46bd0be</code></a> Bump core version to 26.0.0 for upcoming release (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30163"">#30163</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/grpc/grpc/compare/v1.47.0...v1.48.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=grpcio&package-manager=pip&previous-version=1.47.0&new-version=1.48.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12201:6708,Depend,Dependabot,6708,https://hail.is,https://github.com/hail-is/hail/pull/12201,1,['Depend'],['Dependabot']
Integrability," href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2848"">cbeust/testng#2848</a></li>; <li>Deprecate support for running JUnit tests by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2849"">cbeust/testng#2849</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/gruenich""><code>@​gruenich</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2781"">cbeust/testng#2781</a></li>; <li><a href=""https://github.com/anatolyuzhakov""><code>@​anatolyuzhakov</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2793"">cbeust/testng#2793</a></li>; <li><a href=""https://github.com/spkrka""><code>@​spkrka</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2802"">cbeust/testng#2802</a></li>; <li><a href=""https://github.com/JLLeitschuh""><code>@​JLLeitschuh</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2806"">cbeust/testng#2806</a></li>; <li><a href=""https://github.com/seregamorph""><code>@​seregamorph</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2808"">cbeust/testng#2808</a></li>; <li><a href=""https://github.com/melloware""><code>@​melloware</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2827"">cbeust/testng#2827</a></li>; <li><a href=""https://github.com/speedythesnail""><code>@​speedythesnail</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2826"">cbeust/testng#2826</a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <detai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:8622,depend,dependabot,8622,https://hail.is,https://github.com/hail-is/hail/pull/12665,1,['depend'],['dependabot']
Integrability," href=""https://github.com/pandas-dev/pandas/commit/659de5fea920f15e88bed4cf43dc13df8569abad""><code>659de5f</code></a> DOC: Fix whatsnew (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/50821"">#50821</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/5aff5c9f62893a863d003ee15ba216a71f1bb4f3""><code>5aff5c9</code></a> Manual backport fix github quota (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/50827"">#50827</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/c2ab9024379fd63b1a213e385726a4f2928b5c34""><code>c2ab902</code></a> Manually Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/50809"">#50809</a> (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/50813"">#50813</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/24316d0bfe530ccf2cd36d7457db1584c31198f1""><code>24316d0</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/50800"">#50800</a> on branch 1.5.x (DOC: Clean up 1.5.x whatsnews) (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/50807"">#50807</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/4ea0840aa3d42a6d6176e979d0719884e26ec2e6""><code>4ea0840</code></a> BUG: Change FutureWarning to DeprecationWarning for inplace setitem with Data...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/d9dec94ece852eb25b7c37c6fb48be0ab44aa8d7""><code>d9dec94</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/50682"">#50682</a> on branch 1.5.x (BUG: pivot_table with nested elements and...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/ce123cd0024029bb9138acdcc14382628a9310fc""><code>ce123cd</code></a> REGR: NumPy func warning when dropping nuisance in agg, apply, transform (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/50"">#50</a>...</li>; <li",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12610:3740,depend,dependabot,3740,https://hail.is,https://github.com/hail-is/hail/pull/12610,1,['depend'],['dependabot']
Integrability," href=""https://github.com/prometheus/client_python/commit/da15e4a4d671b8aea0e60fc859d5df8102be3897""><code>da15e4a</code></a> Change to imports to fix go-to-declaration in editors (<a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/747"">#747</a>)</li>; <li><a href=""https://github.com/prometheus/client_python/commit/3ef865e1cccae66f63ae764762a700c5775a5190""><code>3ef865e</code></a> Allow to add labels inside a context manager (<a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/730"">#730</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/prometheus/client_python/compare/v0.11.0...v0.13.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=prometheus-client&package-manager=pip&previous-version=0.11.0&new-version=0.13.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11515:5642,depend,dependabot-security-updates,5642,https://hail.is,https://github.com/hail-is/hail/pull/11515,1,['depend'],['dependabot-security-updates']
Integrability," href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf"">Security Advisory for C++ and Python users</a></li>; </ul>; <h2>Protocol Buffers v3.20.1</h2>; <h1>PHP</h1>; <ul>; <li>Fix building packaged PHP extension (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9727"">#9727</a>)</li>; <li>Fixed composer.json to only advertise compatibility with PHP 7.0+. (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9819"">#9819</a>)</li>; </ul>; <h1>Ruby</h1>; <ul>; <li>Disable the aarch64 build on macOS until it can be fixed. (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9816"">#9816</a>)</li>; </ul>; <h1>Other</h1>; <ul>; <li>Fix versioning issues in 3.20.0</li>; </ul>; <h2>Protocol Buffers v3.20.1-rc1</h2>; <p>#PHP</p>; <ul>; <li>Fix building packaged PHP extension (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9727"">#9727</a>)</li>; </ul>; <p>#Other</p>; <ul>; <li>Fix versioning issues in 3.20.0</li>; </ul>; <h2>Protocol Buffers v3.20.0</h2>; <p>2022-03-25 version 3.20.0 (C++/Java/Python/PHP/Objective-C/C#/Ruby/JavaScript)</p>; <h1>Ruby</h1>; <ul>; <li>Dropped Ruby 2.3 and 2.4 support for CI and releases. (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9311"">#9311</a>)</li>; <li>Added Ruby 3.1 support for CI and releases (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9566"">#9566</a>).</li>; <li>Message.decode/encode: Add recursion_limit option (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9218"">#9218</a>/<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9486"">#9486</a>)</li>; <li>Allocate with xrealloc()/xfree() so message allocation is visible to the; Ruby GC. In certain tests this leads to much lower memory usage due to more; frequent GC runs (<a href=""https://github-redirect.depend",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12563:2442,protocol,protocolbuffers,2442,https://hail.is,https://github.com/hail-is/hail/pull/12563,1,['protocol'],['protocolbuffers']
Integrability," href=""https://github.com/pyca/cryptography/commit/0918c7236c94c29272e0790ba0227cfa9401943b""><code>0918c72</code></a> Bump coverage from 7.2.6 to 7.2.7 (<a href=""https://redirect.github.com/pyca/cryptography/issues/8985"">#8985</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pyca/cryptography/compare/40.0.2...41.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=40.0.2&new-version=41.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13146:5395,Depend,Dependabot,5395,https://hail.is,https://github.com/hail-is/hail/pull/13146,1,['Depend'],['Dependabot']
Integrability," href=""https://github.com/pyca/cryptography/commit/8867724b2b6db528d2900414ef86c122a1f5602a""><code>8867724</code></a> fix README for python3 (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7947"">#7947</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pyca/cryptography/compare/38.0.4...39.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=38.0.4&new-version=39.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12668:6731,Depend,Dependabot,6731,https://hail.is,https://github.com/hail-is/hail/pull/12668,4,['Depend'],['Dependabot']
Integrability," href=""https://github.com/pytest-dev/pytest-asyncio/commit/c8d017407d39dd81d6864fa9a58ba1240d54be9f""><code>c8d0174</code></a> fix: Do not warn about outdated pytest version when pytest&gt;=7 is installed. (...</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/6450ddbe974f5359d56317ba8bdda8b2ab48655a""><code>6450ddb</code></a> Prepare release of v0.20.0. (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/428"">#428</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/150f29c107fbd76641de47e040d43840769ef92c""><code>150f29c</code></a> Build(deps): Bump hypothesis in /dependencies/default (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/427"">#427</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/adc88090f341d9872e9e9b4d22a94cdadf60b3bc""><code>adc8809</code></a> Build(deps): Bump typing-extensions in /dependencies/default (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/425"">#425</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/4abf9d1df228ed8b083721d7affa73e4a08d13c3""><code>4abf9d1</code></a> Build(deps): Bump zipp from 3.8.1 to 3.9.0 in /dependencies/default (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/424"">#424</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/eb487bcb076f44dedcdb33e74972bf06c37027ee""><code>eb487bc</code></a> Build(deps): Bump hypothesis in /dependencies/default (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/423"">#423</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/907c461f172e52159a595e2592176c7feac04a43""><code>907c461</code></a> Refactor pytest_pycollect_makeitems (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/421"">#421</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/d45ab217c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12390:4844,depend,dependabot,4844,https://hail.is,https://github.com/hail-is/hail/pull/12390,1,['depend'],['dependabot']
Integrability," href=""https://github.com/python-jsonschema/jsonschema/commit/aeecae37b17b430c328d3c3e15bec90d30c8848b""><code>aeecae3</code></a> Squashed 'json/' changes from d40b3e62f..cf78d97d0</li>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/2f3a79c61176f60c9244d07fa8afb728218270ff""><code>2f3a79c</code></a> Merge commit 'aeecae37b17b430c328d3c3e15bec90d30c8848b'</li>; <li>Additional commits viewable in <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.6.0...v4.6.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jsonschema&package-manager=pip&previous-version=4.6.0&new-version=4.6.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11981:4433,depend,dependabot,4433,https://hail.is,https://github.com/hail-is/hail/pull/11981,1,['depend'],['dependabot']
Integrability," href=""https://github.com/scipy/scipy/commit/5cdc2fe96af0c56ea1a89e7c5373c26a9549e3af""><code>5cdc2fe</code></a> MAINT:linalg:Remove memcpy from lu</li>; <li><a href=""https://github.com/scipy/scipy/commit/d9ac3f329cde53765073e6df5ff1d80f7bc40d39""><code>d9ac3f3</code></a> FIX:linalg:Guard against possible permute_l out of bound behavior</li>; <li><a href=""https://github.com/scipy/scipy/commit/7ec501097b3a22569025bf0d62cb2d89474c812b""><code>7ec5010</code></a> BUG: fix handling for <code>factorial(..., exact=False)</code> for 0-dim array inputs (#...</li>; <li><a href=""https://github.com/scipy/scipy/commit/90415c6890365585576e96e42c5aeba253da0091""><code>90415c6</code></a> BUG: Fix work array construction for various weight shapes. (<a href=""https://redirect.github.com/scipy/scipy/issues/18741"">#18741</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/scipy/scipy/compare/v1.9.3...v1.11.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=scipy&package-manager=pip&previous-version=1.9.3&new-version=1.11.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reope",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13228:4554,Depend,Dependabot,4554,https://hail.is,https://github.com/hail-is/hail/pull/13228,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability," href=""https://github.com/vitejs/vite/commit/c0d6c60"">c0d6c60</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8534"">#8534</a></li>; </ul>; <h2><!-- raw HTML omitted -->2.9.11 (2022-06-10)<!-- raw HTML omitted --></h2>; <ul>; <li>fix: respect server.headers in static middlewares (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8481"">#8481</a>) (<a href=""https://github.com/vitejs/vite/commit/ab7dc1c"">ab7dc1c</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8481"">#8481</a></li>; <li>fix(dev): avoid FOUC when swapping out link tag (fix <a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/7973"">#7973</a>) (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8495"">#8495</a>) (<a href=""https://github.com/vitejs/vite/commit/01fa807"">01fa807</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/7973"">#7973</a> <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8495"">#8495</a></li>; </ul>; <h2><!-- raw HTML omitted -->2.9.10 (2022-06-06)<!-- raw HTML omitted --></h2>; <ul>; <li>feat: treat Astro file scripts as TS (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8151"">#8151</a>) (<a href=""https://github.com/vitejs/vite/commit/9fdd0a3"">9fdd0a3</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8151"">#8151</a></li>; <li>feat: new hook <code>configurePreviewServer</code> (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/7658"">#7658</a>) (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8437"">#8437</a>) (<a href=""https://github.com/vitejs/vite/commit/7b972bc"">7b972bc</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/7658"">#7658</a> <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8437"">#8437</a></li>; <li>fix: remove empty chunk css imports when using esnext (<a href=""https://g",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12142:3484,depend,dependabot,3484,https://hail.is,https://github.com/hail-is/hail/pull/12142,2,['depend'],['dependabot']
Integrability," href=""https://pandas.pydata.org/pandas-docs/version/1.5.0/whatsnew/v1.5.0.html"">full whatsnew</a> for a list of all the changes. pandas 1.5.0 supports Python 3.8 and higher.</p>; <p>The release will be available on the defaults and conda-forge channels:</p>; <p><code>conda install -c conda-forge pandas</code></p>; <p>Or via PyPI:</p>; <p><code>python3 -m pip install --upgrade pandas</code></p>; <p>Please report any issues with the release on the <a href=""https://github.com/pandas-dev/pandas/issues"">pandas issue tracker</a>.</p>; <h2>Pandas 1.5.0rc0</h2>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pandas-dev/pandas/commit/8dab54d6573f7186ff0c3b6364d5e4dd635ff3e7""><code>8dab54d</code></a> RLS: 1.5.2</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/d78c5e624936ea5bc30568fd7d6fc9b5f42d0beb""><code>d78c5e6</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/49806"">#49806</a> on branch 1.5.x (DOC: Update what's new notes for 1.5.2 re...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/98c6139ff12107b9aa34441d25ef1593b6a0adca""><code>98c6139</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/49579"">#49579</a> on Branch 1.5.x (BUG: Behaviour change in 1.5.0 when using...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/9196f8d545d1118f1233c1b45e7b740cb95c370c""><code>9196f8d</code></a> Backport PR STYLE enable pylint: method-cache-max-size-none (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/49784"">#49784</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/8c4b559c87561ca68ccdc3e81ff3c5218c7b4db7""><code>8c4b559</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/49776"">#49776</a> on branch 1.5.x (REGR: arithmetic ops recursion error with...</li>; <li><a ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12564:2905,depend,dependabot,2905,https://hail.is,https://github.com/hail-is/hail/pull/12564,1,['depend'],['dependabot']
Integrability," href=""https://redirect.github.com/googleapis/java-storage/issues/2190"">#2190</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/5c048c499eef224dade8f4409dfae732cb5a7017""><code>5c048c4</code></a> deps: update actions/checkout action to v4 (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2189"">#2189</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/java-storage/compare/v2.17.1...v2.27.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.cloud:google-cloud-storage&package-manager=gradle&previous-version=2.17.1&new-version=2.27.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major versio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13624:15726,depend,dependabot,15726,https://hail.is,https://github.com/hail-is/hail/pull/13624,1,['depend'],['dependabot']
Integrability," href=""https://redirect.github.com/pyasn1/pyasn1-modules/issues/12"">#12</a>)</li>; <li><a href=""https://github.com/pyasn1/pyasn1-modules/commit/252ac00bf1e119a044cc579ffade30164e2cdfff""><code>252ac00</code></a> Add support for Python 3.12 (<a href=""https://redirect.github.com/pyasn1/pyasn1-modules/issues/11"">#11</a>)</li>; <li>See full diff in <a href=""https://github.com/pyasn1/pyasn1-modules/compare/v0.3.0...v0.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyasn1-modules&package-manager=pip&previous-version=0.3.0&new-version=0.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14472:2645,depend,dependabot-automerge-start,2645,https://hail.is,https://github.com/hail-is/hail/pull/14472,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability," href=""https://redirect.github.com/pyparsing/pyparsing/issues/493"">#493</a></li>; <li><a href=""https://github.com/pyparsing/pyparsing/commit/5b939ccc12e6213edbcecca7546472561788f3e9""><code>5b939cc</code></a> Use reset_pyparsing_context for each example in test_examples.py</li>; <li><a href=""https://github.com/pyparsing/pyparsing/commit/eb9db9eb65f973f59d2c42ef20c6bb6cd974059a""><code>eb9db9e</code></a> Add common, unicode, and testing to <strong>all</strong></li>; <li>Additional commits viewable in <a href=""https://github.com/pyparsing/pyparsing/compare/pyparsing_3.0.9...3.1.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyparsing&package-manager=pip&previous-version=3.0.9&new-version=3.1.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13345:9542,Depend,Dependabot,9542,https://hail.is,https://github.com/hail-is/hail/pull/13345,1,['Depend'],['Dependabot']
Integrability," human curated changelist.</p>; <h2>Changes</h2>; <ul>; <li>Prep version 3.0.0 for release (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/362"">#362</a>) <a href=""https://github.com/gnikonorov""><code>@​gnikonorov</code></a></li>; </ul>; <h2>Major Changes</h2>; <ul>; <li>Stop shadowing the 'format' builtin (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/347"">#347</a>) <a href=""https://github.com/gnikonorov""><code>@​gnikonorov</code></a></li>; <li>Drop support for legacy Python 2.7 (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/230"">#230</a>) <a href=""https://github.com/hugovk""><code>@​hugovk</code></a></li>; </ul>; <h2>Minor Changes</h2>; <ul>; <li>Add support for py39 (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/345"">#345</a>) <a href=""https://github.com/ssbarnea""><code>@​ssbarnea</code></a></li>; <li>Enable py38 testing (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/326"">#326</a>) <a href=""https://github.com/ssbarnea""><code>@​ssbarnea</code></a></li>; <li>Strip ANSI escape sequences when ansi2html is missing (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/315"">#315</a>) <a href=""https://github.com/BeyondEvil""><code>@​BeyondEvil</code></a></li>; <li>Make the links column in the results table sortable (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/324"">#324</a>) <a href=""https://github.com/gnikonorov""><code>@​gnikonorov</code></a></li>; <li>Make the maximum asset filename length configurable. (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/313"">#313</a>) <a href=""https://github.com/D3X""><code>@​D3X</code></a></li>; <li>Fix broken development docs (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/316"">#316</a>) <a href=""https://github.com/BeyondEvil""><code>@​BeyondEvil</code></a></li>; <li>U",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11524:1498,depend,dependabot,1498,https://hail.is,https://github.com/hail-is/hail/pull/11524,1,['depend'],['dependabot']
Integrability," identify invalid rules rather than hang parsing them,; and to correctly parse <code>/</code> within converter arguments. :pr:<code>2489</code></li>; <li>Update subpackage imports in :mod:<code>werkzeug.routing</code> to use the; <code>import as</code> syntax for explicitly re-exporting public attributes.; :pr:<code>2493</code></li>; <li>Parsing of some invalid header characters is more robust. :pr:<code>2494</code></li>; <li>When starting the development server, a warning not to use it in a; production deployment is always shown. :issue:<code>2480</code></li>; <li><code>LocalProxy.__wrapped__</code> is always set to the wrapped object when; the proxy is unbound, fixing an issue in doctest that would cause it; to fail. :issue:<code>2485</code></li>; <li>Address one <code>ResourceWarning</code> related to the socket used by; <code>run_simple</code>. :issue:<code>2421</code></li>; </ul>; <h2>Version 2.2.1</h2>; <p>Released 2022-07-27</p>; <ul>; <li>Fix router so that <code>/path/</code> will match a rule <code>/path</code> if strict; slashes mode is disabled for the rule. :issue:<code>2467</code></li>; <li>Fix router so that partial part matches are not allowed; i.e. <code>/2df</code> does not match <code>/&lt;int&gt;</code>. :pr:<code>2470</code></li>; <li>Fix router static part weighting, so that simpler routes are matched; before more complex ones. :issue:<code>2471</code></li>; <li>Restore <code>ValidationError</code> to be importable from; <code>werkzeug.routing</code>. :issue:<code>2465</code></li>; </ul>; <h2>Version 2.2.0</h2>; <p>Released 2022-07-23</p>; <ul>; <li>Deprecated <code>get_script_name</code>, <code>get_query_string</code>,; <code>peek_path_info</code>, <code>pop_path_info</code>, and; <code>extract_path_info</code>. :pr:<code>2461</code></li>; <li>Remove previously deprecated code. :pr:<code>2461</code></li>; <li>Add MarkupSafe as a dependency and use it to escape values when; rendering HTML. :issue:<code>2419</code></li>; </ul>; <!-- raw HTML omit",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12119:3377,rout,router,3377,https://hail.is,https://github.com/hail-is/hail/pull/12119,1,['rout'],['router']
Integrability," in <code>px.timeline()</code> <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3774"">#3774</a></li>; <li><code>facet_*</code> and <code>category_orders</code> now available in <code>px.pie()</code> <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3775"">#3775</a></li>; </ul>; <h3>Performance</h3>; <ul>; <li><code>px</code> methods no longer call <code>groupby</code> on the input dataframe when the result would be a single group, and no longer groups by a lambda, for significant speedups <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3765"">#3765</a> with thanks to <a href=""https://github.com/jvdd""><code>@​jvdd</code></a></li>; </ul>; <h3>Updated</h3>; <ul>; <li>Allow non-string extras in <code>flaglist</code> attributes, to support upcoming changes to <code>ax.automargin</code> in plotly.js <a href=""https://github-redirect.dependabot.com/plotly/plotly.js/pull/6193"">plotly.js#6193</a>, <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3749"">#3749</a></li>; </ul>; <h2>[5.8.2] - 2022-06-10</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed a syntax error that caused rendering issues in Databricks notebooks and likely elsewhere. <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3763"">#3763</a> with thanks to <a href=""https://github.com/fwetdb""><code>@​fwetdb</code></a></li>; </ul>; <h2>[5.8.1] - 2022-06-08</h2>; <p>(no changes, due to a mixup with the build process!)</p>; <h2>[5.8.0] - 2022-05-09</h2>; <h3>Fixed</h3>; <ul>; <li>Improve support for type checking and IDE auto-completion by bypassing lazy-loading when type checking. <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3425"">#3425</a> with thanks to <a href=""https://github.com/JP-Ellis""><code>@​JP-Ellis</code></a></li>; <li>line dash-style validators are now correctly used everywhere so that values like <code>10px 2px</code> are accepted <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12113:3055,depend,dependabot,3055,https://hail.is,https://github.com/hail-is/hail/pull/12113,1,['depend'],['dependabot']
Integrability," in RFC 2246. This new version was backwards-incompatible and was; thus given a new name: Transport Layer Security. In common discussion, SSL; and TLS are used interchangeable. Indeed, the python TLS library is called; `ssl`. [2] Forward secrecy is a property of an encryption system. Forward secrecy means; a message cannot be decrypted in the future by an adversary who learned one; of the private keys. For example, imagine you are sending sensitive messages; to another individual. If that individual is later coerced into revealing; their secret key, forward secrecy would prevent the coercer from reading; your messages. Forward secrecy is achieved by negotiating a shared private; key between the two parties that is only used for a ""session"" and then; discarded. If the session key is securely discarded and neither key can; recreate it without cooperation from the other key, then *one* leaked key is; insufficient to reveal the messages. ---. Things for you to verify:; - does every service load *its own unqiue* ssl-config secret?; - does every service use an SSL context for serving?; - does everyone who makes http requests to internal services use an SSL client; session?; - do all TLS-secured nginx instances include their http.conf in the `http`; section and the `proxy.conf` file in any proxying sections?; - Do the SSLContext's from `ssl.py` and the nginx configurations generated by; `create_certs.py` actually ensure security?. Post-merge actions:; - deploy gateway; - deploy internal-gateway; - deploy router-resolver. Anticipated outages:. - Before a service is redeployed it will be inaccessible from the outside; because the router will try to speak to it on HTTPS. Services that speak to; one another (ci<->batch, everyone<->auth) will lose connections while the; deploy is happening. Deploy should move smoothly because CI will completely; transmit the deploy batch to batch before batch goes dark.; - dev namespaces will be broken until the owner redeploys the router, etc.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:13238,rout,router-resolver,13238,https://hail.is,https://github.com/hail-is/hail/pull/8561,3,['rout'],"['router', 'router-resolver']"
Integrability," in create-release.yml</li>; <li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v6.2.1...v7.1.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx&package-manager=pip&previous-version=6.2.1&new-version=7.1.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13295:7401,Depend,Dependabot,7401,https://hail.is,https://github.com/hail-is/hail/pull/13295,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability," in for loops that reference <code>self</code> if the binary operation that; started the for loop uses a <code>self</code> that is encapsulated in tuples or lists.</p>; <p>Ref <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1360"">PyCQA/astroid#1360</a>; Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/4826"">#4826</a></p>; </li>; <li>; <p>Output better error message if unsupported file formats are used with <code>pyreverse</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5950"">#5950</a></p>; </li>; <li>; <p>Fix pyreverse diagrams type hinting for classmethods and staticmethods.</p>; </li>; <li>; <p>Fix pyreverse diagrams type hinting for methods returning None.</p>; </li>; <li>; <p>Fix matching <code>--notes</code> options that end in a non-word character.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5840"">#5840</a></p>; </li>; <li>; <p>Updated the position of messages for class and function defintions to no longer cover; the complete definition. Only the <code>def</code> or <code>class</code> + the name of the class/function; are covered.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5466"">#5466</a></p>; </li>; <li>; <p><code>using-f-string-in-unsupported-version</code> and <code>using-final-decorator-in-unsupported-version</code> msgids; were renamed from <code>W1601</code> and <code>W1602</code> to <code>W2601</code> and <code>W2602</code>. Disabling using these msgids will break.; This is done in order to restore consistency with the already existing msgids for <code>apply-builtin</code> and; <code>basestring-builtin</code> from the now deleted python 3K+ checker. There is now a check that we're not using; existing msgids or symbols from deleted checkers.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5729"">#5729</a></p>; </li>; <li>; <p>The line numbering for messag",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11674:1473,message,messages,1473,https://hail.is,https://github.com/hail-is/hail/pull/11674,1,['message'],['messages']
Integrability," in intcomma()</li>; <li><a href=""https://github.com/python-humanize/humanize/commit/d8e27393dbf4ed3645ffc3464c9c44f4d8e47534""><code>d8e2739</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/52"">#52</a> from Luflosi/fix-intcomma-with-str-and-ndigits</li>; <li>Additional commits viewable in <a href=""https://github.com/python-humanize/humanize/compare/1.1.0...4.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=humanize&package-manager=pip&previous-version=1.1.0&new-version=4.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12329:7732,depend,dependabot-automerge-start,7732,https://hail.is,https://github.com/hail-is/hail/pull/12329,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability," in menu (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1151"">#1151</a>)</li>; <li>Respect tab order for prev/next buttons (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1051"">#1051</a>)</li>; </ul>; <h2>Fixes</h2>; <ul>; <li>Updated Google analytics integration (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1129"">#1129</a>)</li>; <li>Add classifier separation on Sphinx 2+ HTML4 writer (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1192"">#1192</a>)</li>; <li>Added missing space char in footer (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1188"">#1188</a>)</li>; <li>Fix navigation right padding on level2+ elements (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1068"">#1068</a>)</li>; <li>Fix navigation expansion button sizes (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1067"">#1067</a>)</li>; <li>Wrap inline literals (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1050"">#1050</a>)</li>; <li>Fix aria labels (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1056"">#1056</a>)</li>; <li>Don't toggle navigation terminal nodes (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1049"">#1049</a>)</li>; <li>Fix <code>&lt;pre&gt;</code> overflow (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1220"">#1220</a>)</li>; <li>Fix literal/ref style inside <code>&lt;dl&gt;</code> (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1088"">#1088</a>)</li>; </ul>; <p>Other Changes</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/readthedocs/sphinx_rt",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11464:3686,depend,dependabot,3686,https://hail.is,https://github.com/hail-is/hail/pull/11464,2,['depend'],['dependabot']
Integrability," in the Hail SSL; Config. The external client context does not load the hail certificate chain. I intend all Hail's HTTP(S) requests to use `httpx.py` (so named to not conflict; with modules named `http`). Again, I have simplified the landscape. We now have; two functions:. - `httpx.client_session`: The constructor for all asynchronous, HTTPS client; sessions.; - `httpx.blocking_client_session`: The constructor for all synchronous, HTTPS; client sessions. Both sessions have the exact same configuration parameters. The API is exactly; the same except the blocking client session replaces asynchronous methods with; synchronous ones. Both sessions accept the `aiohttp.ClientSession` constructor parameters. They; support one new parameter and modify the behavior of one old parameter.; - `retry_transient`: when set to `True` this parameter will retry all transient; errors in all requests made by this session. This defaults to `True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager. Its; `response_coroutine` field is a coroutine that includes the retry and; raise-for-status logic. - The `HailResolver` overrides domain name resolution to first consult the Hail; `address` service. `address` is effectively a domain name server. It watches; kubernetes services and publishes the pod IPs. It supports two name styles:; `service` and `service.namespace`. The former uses the deploy config to; determine in which namespace to find the given service. Currently, the; cl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9554:1537,message,message,1537,https://hail.is,https://github.com/hail-is/hail/pull/9554,1,['message'],['message']
Integrability," in the middle of lines when; <code>lstrip_blocks</code> is enabled. :issue:<code>1138</code></li>; <li>:class:<code>~nativetypes.NativeEnvironment</code> doesn't evaluate; intermediate strings during rendering. This prevents early; evaluation which could change the value of an expression.; :issue:<code>1186</code></li>; </ul>; <h2>Version 2.11.1</h2>; <p>Released 2020-01-30</p>; <ul>; <li>Fix a bug that prevented looking up a key after an attribute; (<code>{{ data.items[1:] }}</code>) in an async template. :issue:<code>1141</code></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/jinja/commit/cf215390d4a4d6f0a4de27e2687eed176878f13d""><code>cf21539</code></a> release version 2.11.3</li>; <li><a href=""https://github.com/pallets/jinja/commit/15ef8f09b659f9100610583938005a7a10472d4d""><code>15ef8f0</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/jinja/issues/1343"">#1343</a> from pallets/urlize-speedup</li>; <li><a href=""https://github.com/pallets/jinja/commit/ef658dc3b6389b091d608e710a810ce8b87995b3""><code>ef658dc</code></a> speed up urlize matching</li>; <li><a href=""https://github.com/pallets/jinja/commit/eeca0fecc3318d43f61bc340ad61db641b861ade""><code>eeca0fe</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/jinja/issues/1207"">#1207</a> from mhansen/patch-1</li>; <li><a href=""https://github.com/pallets/jinja/commit/2dd769111cbb1a2637f805b3b4c652ec8096d371""><code>2dd7691</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/jinja/issues/1209"">#1209</a> from mhansen/patch-3</li>; <li><a href=""https://github.com/pallets/jinja/commit/48929401db7228db04dfd8e88115dd5c30dc2d86""><code>4892940</code></a> do_dictsort: update example ready to copy/paste</li>; <li><a href=""https://github.com/pallets/jinja/commit/7db7d336ba12574e6205fdd929386fd529e3fad4",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10209:5414,depend,dependabot,5414,https://hail.is,https://github.com/hail-is/hail/pull/10209,1,['depend'],['dependabot']
Integrability," in under ten seconds - in; that realm compilation time could become a critical factor as a serial bottleneck. [The place where persistent cacheing of compiled files helps most of all is in testing,; where you really are running the exact same queries over and over again on the same; small datasets, and in many cases after making small changes which only affect a few; of the queries]. b) We may actually have some version of the locking problem even if we don't try to reuse the files -; since we have several workers on a node, and possibly a master as well, all needing to put code; into a file (or wait for someone else to populate the file) so that they can load it. Depending on ; precisely how Spark manages things (which I wouldn't want to depend on too much anyway). In fact it's essential that all the workers share the same DLL file, because otherwise they'd be; trying to load multiple DLL's defining the same symbols. That aspect of it could be handled by; putting the files into a per-process directory and using in-memory (std::mutex) synchronization.; But y'know, given that we have to write the DLL's out, it just seemed natural to let them persist; (and until debugging it on MacOS, I thought I could manage it with nothing but atomic file-create; and atomic-rename, but that didn't quite pan out). As for writing LLVM IR, it can definitely be done, because that's what Endeca/Oracle did. But there; was such a huge learning curve that only 3 people ever did it successfully (I wasn't one of them),; and debugging seemed very unpleasant and slow. [It was also a masterful achievement in ; job-security-through-obscurity, because no-one in management was going to mess with the; two people who wrote it - until the whole project got canned]. ... and in the time I was there, the Endeca/Oracle stuff wasn't distributed, which could be another; place where the generate-LLVM-IR needs some kind of extra glue for distributing compiled code,; whereas the conventional DLL's are trivial",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3973#issuecomment-412742385:1831,synchroniz,synchronization,1831,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-412742385,2,['synchroniz'],['synchronization']
Integrability," inside of the parentheses. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2760"">#2760</a>)</li>; <li><code>from __future__ import annotations</code> statement now implies Python 3.7+ (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2690"">#2690</a>)</li>; </ul>; <h3>Performance</h3>; <ul>; <li>Speed-up the new backtracking parser about 4X in general (enabled when <code>--target-version</code> is set to 3.10 and higher). (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2728"">#2728</a>)</li>; <li>Black is now compiled with mypyc for an overall 2x speed-up. 64-bit Windows, MacOS, and Linux (not including musl) are supported. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/1009"">#1009</a>, <a href=""https://github-redirect.dependabot.com/psf/black/issues/2431"">#2431</a>)</li>; </ul>; <h3>Configuration</h3>; <ul>; <li>Do not accept bare carriage return line endings in pyproject.toml (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2408"">#2408</a>)</li>; <li>Add configuration option (<code>python-cell-magics</code>) to format cells with custom magics in Jupyter Notebooks (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2744"">#2744</a>)</li>; <li>Allow setting custom cache directory on all platforms with environment variable <code>BLACK_CACHE_DIR</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2739"">#2739</a>).</li>; <li>Enable Python 3.10+ by default, without any extra need to specify -<code>-target-version=py310</code>. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2758"">#2758</a>)</li>; <li>Make passing <code>SRC</code> or <code>--code</code> mandatory and mutually exclusive (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2804"">#2804</a>)</li>; </ul>; <h3>Output</h3>; <ul>; <li>Improve error message for invalid regular expression (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2678"">#2678<",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11468:4668,depend,dependabot,4668,https://hail.is,https://github.com/hail-is/hail/pull/11468,1,['depend'],['dependabot']
Integrability," is no longer supported.</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/4c24f4f2d09d3e00668cb273f5257dd2b19c115a""><code>4c24f4f</code></a> [Storage][Hotfix] Fix <code>BlobSasPermission</code> default value for Tag (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23651"">#23651</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/699acfe143cc0ca570de2d040c8ffcf7cb2a3c55""><code>699acfe</code></a> [Storage] Fix <code>detination_lease</code> type hint (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23417"">#23417</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/5b6ff12ffbb3cc440bc73b4e714ec260ab0f03ac""><code>5b6ff12</code></a> [Storage] Update <code>rename_directory</code> lease param name (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23411"">#23411</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/4513dbda0f23964a7690eee938f9fdaf91cf33b8""><code>4513dbd</code></a> [Storage] Fix duplicate type signatures in async (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23375"">#23375</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/1ed6c301cff55f240cc968eb2482a58a688ef352""><code>1ed6c30</code></a> [pipeline] update existing README.md to drop py2 (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23332"">#23332</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/f7136780995ccd504770976549d603b7e6187ced""><code>f713678</code></a> [Storage] Remove batch delete files feature for GA release (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23320"">#23320</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11703:3906,depend,dependabot,3906,https://hail.is,https://github.com/hail-is/hail/pull/11703,1,['depend'],['dependabot']
Integrability, is.hail.expr.ir.Emit$$anonfun$emit$11.apply(Emit.scala:2384); 	at is.hail.expr.ir.EmitCode$.fromI(Emit.scala:283); 	at is.hail.expr.ir.Emit.emit(Emit.scala:2384); 	at is.hail.expr.ir.Emit.emit(Emit.scala:1013); 	at is.hail.expr.ir.Emit$$anonfun$13$$anon$2.emit(Emit.scala:464); 	at is.hail.expr.ir.EmitUtils$$anonfun$wrapToMethod$1.apply(Emit.scala:426); 	at is.hail.expr.ir.EmitUtils$$anonfun$wrapToMethod$1.apply(Emit.scala:426); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at is.hail.expr.ir.EmitUtils$.wrapToMethod(Emit.scala:426); 	at is.hail.expr.ir.Emit.wrapToMethod(Emit.scala:468); 	at is.hail.expr.ir.Emit.wrapToMethod$2(Emit.scala:1044); 	at is.hail.expr.ir.Emit.emit(Emit.scala:1594); 	at is.hail.expr.ir.Emit.emitFallback$1(Emit.scala:692); 	at is.hail.expr.ir.Emit.emitI(Emit.scala:975); 	at is.hail.expr.ir.Emit.emitI(Emit.scala:675); 	at is.hail.expr.ir.Emit$$anonfun$apply$13.apply(Emit.scala:91); 	at is.hail.expr.ir.Emit$$anonfun$apply$13.apply(Emit.scala:90); 	at is.hail.expr.ir.EmitCodeBuilder$.scoped(EmitCodeBuilder.scala:14); 	at is.hail.expr.ir.EmitCodeBuilder$.scopedCode(EmitCodeBuilder.scala:19); 	at is.hail.expr.ir.EmitMethodBuilder.emitWithBuilder(EmitClassBuilder.scala:1091); 	at is.hail.expr.ir.WrappedEmitMethodBuilder$class.emitWithBuilder(EmitClassBuilder.scala:1111); 	at is.hail.expr.ir.EmitFunctionBuilder.emitWithBuilder(EmitClassBuilder.scala:1215); 	at is.hail.expr.ir.Emit$.apply(Emit.scala:90); 	at is.hail.expr.ir.Compile$.apply(Compile.scala:71); 	at is.hail.expr.ir.CompileAndEvaluate$$anonfun$2.apply(CompileAndEvaluate.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9128:11312,wrap,wrapToMethod,11312,https://hail.is,https://github.com/hail-is/hail/issues/9128,1,['wrap'],['wrapToMethod']
Integrability, is.hail.expr.ir.lowering.InterpretNonCompilablePass$.transform(LoweringPass.scala:67); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:15); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:15); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:12); 	at is.hail.expr.ir.lowering.InterpretNonCompilablePass$.apply(LoweringPass.scala:62); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:14); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:12); 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:12); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:29); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:381); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$1(SparkBackend.scala:365); 	at is.hail.expr.ir.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:47); 	at is.hail.utils.package$.using(package.scala:627); 	at is.hail.expr.ir.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:47); 	at is.hail.utils.package$.using(package.scala:627); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:46); 	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:275); 	at is.hail.backend.spark.SparkBackend.execute(SparkBackend.scala:362); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeJSON$1(SparkBackend.scala:406); 	at is.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:12109,Wrap,WrappedArray,12109,https://hail.is,https://github.com/hail-is/hail/issues/10682,1,['Wrap'],['WrappedArray']
Integrability, is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3$$anonfun$1.apply(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3$$anonfun$1.apply(LoweringPass.scala:13); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); 	at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3.apply(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3.apply(LoweringPass.scala:11); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); 	at is.hail.expr.ir.lowering.LoweringPass$class.apply(LoweringPass.scala:11); 	at is.hail.expr.ir.lowering.InterpretNonCompilablePass$.apply(LoweringPass.scala:43); 	at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:20); 	at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:18); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:18); 	at is.hail.expr.ir.CompileAndEvaluate$$anonfun$apply$1.apply(CompileAndEvaluate.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); 	at is.hail.expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:14); 	at is.hail.backend.Backend$$anonfun$execute$1.apply(Backend.scala:56); 	at is.hail.backend.Backend$$anonfun$execute$1.apply(Backend.scala:56); 	at is.hail.utils.package$.using(package.scala:596); 	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:10); 	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:9); 	at is.hail.utils.package$.using(package.scala:596); 	at is.hail.annotations.Region$.scoped(Region.scala:18); 	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:9); 	at is.hail.backend.Backend.execute(Backend.scala:56); 	at is.hail.backend.Backend.executeJSON(Backend.scala:62); 	at sun.r,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8545:13084,Wrap,WrappedArray,13084,https://hail.is,https://github.com/hail-is/hail/issues/8545,1,['Wrap'],['WrappedArray']
Integrability, is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3$$anonfun$1.apply(LoweringPass.scala:15); 	at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3$$anonfun$1.apply(LoweringPass.scala:15); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); 	at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3.apply(LoweringPass.scala:15); 	at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3.apply(LoweringPass.scala:13); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); 	at is.hail.expr.ir.lowering.LoweringPass$class.apply(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.InterpretNonCompilablePass$.apply(LoweringPass.scala:45); 	at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:20); 	at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:18); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:18); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:27); 	at is.hail.backend.Backend.is$hail$backend$Backend$$_execute(Backend.scala:90); 	at is.hail.backend.Backend$$anonfun$execute$1.apply(Backend.scala:78); 	at is.hail.backend.Backend$$anonfun$execute$1.apply(Backend.scala:77); 	at is.hail.utils.package$.using(package.scala:602); 	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:10); 	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:9); 	at is.hail.utils.package$.using(package.scala:602); 	at is.hail.annotations.Region$.scoped(Region.scala:18); 	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:9); 	at is.hail.backend.Backend.execute(Backend.scala:77); 	at is.hail.backend.Backend.executeJSON(Backend.scala:96); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.Na,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:85911,Wrap,WrappedArray,85911,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['Wrap'],['WrappedArray']
Integrability," is.hail.keytable.KeyTable.export(KeyTable.scala:537); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748). ```. I instead tried to run the same code in two separate jupyter notebooks, with the same code inside but different ways to initialize the hailcontext, one like this (works and exports):. ```; from hail import *; hc = HailContext(); ```; With startup messages looking like this:. ```; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 18/01/08 13:51:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/01/08 13:51:03 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).; 18/01/08 13:51:03 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/home/ludvig/Programs/hail/jars/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 18/01/08 13:51:03 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/home/ludvig/Programs/ha",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783:5665,message,messages,5665,https://hail.is,https://github.com/hail-is/hail/issues/2527#issuecomment-355985783,1,['message'],['messages']
Integrability," is.hail.rvd.RVD$$anonfun$37.apply(RVD.scala:1059); at is.hail.rvd.RVD$$anonfun$37.apply(RVD.scala:1057); at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$27.apply(ContextRDD.scala:355); at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$27.apply(ContextRDD.scala:355); at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5.apply(ContextRDD.scala:135); at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$5.apply(ContextRDD.scala:135); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310). Hail version: 0.2-721af83bc30a; Error summary: OutOfMemoryError: Java heap space; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1035, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 883, in send_command; response = connection.send_command(command); File ""/share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1040, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving. ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4755#issuecomment-438447635:10987,protocol,protocol,10987,https://hail.is,https://github.com/hail-is/hail/issues/4755#issuecomment-438447635,2,['protocol'],['protocol']
Integrability," jwt.decode(verify=...) by <a href=""https://github.com/akx""><code>@​akx</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/742"">jpadilla/pyjwt#742</a></li>; <li>Don't mutate options dictionary in .decode_complete() by <a href=""https://github.com/akx""><code>@​akx</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/743"">jpadilla/pyjwt#743</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/748"">jpadilla/pyjwt#748</a></li>; <li>Replace various string interpolations with f-strings by <a href=""https://github.com/akx""><code>@​akx</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/744"">jpadilla/pyjwt#744</a></li>; <li>Update CHANGELOG.rst by <a href=""https://github.com/hipertracker""><code>@​hipertracker</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/751"">jpadilla/pyjwt#751</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/hugovk""><code>@​hugovk</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/699"">jpadilla/pyjwt#699</a></li>; <li><a href=""https://github.com/rekyungmin""><code>@​rekyungmin</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/705"">jpadilla/pyjwt#705</a></li>; <li><a href=""https://github.com/sseering""><code>@​sseering</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/661"">jpadilla/pyjwt#661</a></li>; <li><a href=""https://github.com/estin""><code>@​estin</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/713"">jpadilla/pyjwt#713</a></li>; <li><a href=""https://github.com/woodruffw""><code>@​woodruffw</code></a> made their ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11866:5597,depend,dependabot,5597,https://hail.is,https://github.com/hail-is/hail/pull/11866,1,['depend'],['dependabot']
Integrability," k,; 103 compute_loadings). <decorator-gen-1780> in pca(entry_expr, k, compute_loadings). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/methods/pca.py in pca(entry_expr, k, compute_loadings); 209 'k': k,; 210 'computeLoadings': compute_loadings; --> 211 })).persist()); 212 ; 213 g = t.index_globals(). <decorator-gen-1340> in persist(self, storage_level). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in persist(self, storage_level); 2110 Persisted table.; 2111 """"""; -> 2112 return Env.backend().persist(self); 2113 ; 2114 def unpersist(self) -> 'Table':. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/backend/backend.py in persist(self, dataset); 167 from hail.context import TemporaryFilename; 168 tempfile = TemporaryFilename(prefix=f'persist_{type(dataset).__name__}'); --> 169 persisted = dataset.checkpoint(tempfile.__enter__()); 170 self._persisted_locations[persisted] = (tempfile, dataset); 171 return persisted. <decorator-gen-1330> in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[...",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:3173,wrap,wrapper,3173,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124,1,['wrap'],['wrapper']
Integrability," lab display</li>; <li>update notebook tests</li>; </ul>; </li>; </ul>; <h2>tqdm v4.64.0 stable</h2>; <ul>; <li>add <code>contrib.slack</code> (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1313"">#1313</a>)</li>; </ul>; <h2>tqdm v4.63.2 stable</h2>; <ul>; <li><code>rich</code>: expose <code>options</code> kwargs (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1282"">#1282</a>)</li>; <li><code>autonotebook</code>: re-enable VSCode (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1309"">#1309</a>)</li>; <li>misc docs typos (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1301"">#1301</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1299"">#1299</a>)</li>; <li>update dev dependencies (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1311"">#1311</a>)</li>; </ul>; <h2>tqdm v4.63.1 stable</h2>; <ul>; <li>fix stderr/stdout missing <code>flush()</code> (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1248"">#1248</a> &lt;- <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1177"">#1177</a>)</li>; <li>misc speed improvements/optimisations</li>; </ul>; <h2>tqdm v4.63.0 stable</h2>; <ul>; <li>add <code>__reversed__()</code></li>; <li>add efficient <code>__contains__()</code></li>; <li>improve CLI startup time (replace <code>pkg_resources</code> =&gt; <code>importlib</code>)</li>; <li><code>tqdm.autonotebook</code> warning &amp; <code>std</code> fallback on missing <code>ipywidgets</code> (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1218"">#1218</a> &lt;- <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1082"">#1082</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1217"">#1217</a>)</li>; <li>warn on positional CLI arguments</li>; <li>misc build/test framework updates; <ul>; <li>enable <code>py3.10</code> tests</li>; <li>add <code>conda</code> dependencies</li>; <li>update pre-commit hooks</li>;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12260:1818,depend,dependabot,1818,https://hail.is,https://github.com/hail-is/hail/pull/12260,1,['depend'],['dependabot']
Integrability," make code changes.</p>; <p>For more details, read our <a href=""https://aioredis.readthedocs.io/en/latest/migration/"">documentation on migrating to version 2.0</a>.</p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aioredis-py/blob/master/CHANGELOG.md"">aioredis's changelog</a>.</em></p>; <blockquote>; <h2>2.0.1 - (2021-12-20)</h2>; <h3>Features</h3>; <ul>; <li>Added Python 3.10 to CI &amp; Updated the Docs; (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1160"">#1160</a>)</li>; <li>Enable mypy in CI (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1101"">#1101</a>)</li>; <li>Synchronized reading the responses from a connection; (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1106"">#1106</a>)</li>; </ul>; <h3>Fixes</h3>; <ul>; <li>Remove <strong>del</strong> from Redis (Fixes <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1115"">#1115</a>); (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1227"">#1227</a>)</li>; <li>fix socket.error raises (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1129"">#1129</a>)</li>; <li>Fix buffer is closed error when using PythonParser class; (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1213"">#1213</a>)</li>; </ul>; <h2>2.0.0 - (2021-03-18)</h2>; <h3>Features</h3>; <ul>; <li>; <p>Port redis-py's client implementation to aioredis.<br />; (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/891"">#891</a>)</p>; </li>; <li>; <p>Make hiredis an optional dependency.<br />; (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/917"">#917</a>)</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/224f8",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11569:2756,depend,dependabot,2756,https://hail.is,https://github.com/hail-is/hail/pull/11569,1,['depend'],['dependabot']
Integrability," marked as &quot;Deprecated&quot; and has been removed in kubernetes 1.23 . (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/106366"">kubernetes/kubernetes#106366</a>, <a href=""https://github.com/cyclinder""><code>@​cyclinder</code></a>)</li>; <li>Skip x-kubernetes-validations rules if having fundamental error against the OpenAPIv3 schema. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108859"">kubernetes/kubernetes#108859</a>, <a href=""https://github.com/cici37""><code>@​cici37</code></a>)</li>; <li>Support for gRPC probes is now in beta. GRPCContainerProbe feature gate is enabled by default. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108522"">kubernetes/kubernetes#108522</a>, <a href=""https://github.com/SergeyKanzhelev""><code>@​SergeyKanzhelev</code></a>)</li>; <li>Suspend job to GA. The feature gate <code>SuspendJob</code> is locked and will be removed in 1.26. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108129"">kubernetes/kubernetes#108129</a>, <a href=""https://github.com/ahg-g""><code>@​ahg-g</code></a>)</li>; <li>The AnyVolumeDataSource feature is now beta, and the feature gate is enabled by default. In order to provide user feedback on PVCs with data sources, deployers must install the VolumePopulators CRD and the data-source-validator controller. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108736"">kubernetes/kubernetes#108736</a>, <a href=""https://github.com/bswartz""><code>@​bswartz</code></a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/9ecc1143a8f7b34264b48dea12edd4d66230476f""><code>9ecc114</code></a> [chore] update version</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/ae5fd81a0fbea7d7fdac8d418876acaa288bcc0f""><code>ae5fd81</code></",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:13328,depend,dependabot,13328,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['depend'],['dependabot']
Integrability," md5 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1815"">#1815</a>) (<a href=""https://github.com/googleapis/java-storage/commit/46625729b6fd62d8f133c3fb2d8ee00eb64ee8e9"">4662572</a>)</li>; <li>Update GrpcConversions to use Bucket.RetentionPolicy.retention_duration (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1798"">#1798</a>) (<a href=""https://github.com/googleapis/java-storage/commit/82fb014508178e8ad3fd08e9efc757a8e47564da"">82fb014</a>)</li>; <li>Update GrpcStorageImpl#update to support fine-grained update of BucketInfo.labels and BlobInfo.metadata (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1843"">#1843</a>) (<a href=""https://github.com/googleapis/java-storage/commit/c8bf3c70cca81ed87a52939fe7da58889c8f55ce"">c8bf3c7</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Document differing behavior of {get,list}{,default}Acl between HTTP and gRPC (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1820"">#1820</a>) (<a href=""https://github.com/googleapis/java-storage/commit/9511b173e84d2b28ab1a1625b16e3e648c3856fb"">9511b17</a>)</li>; </ul>; <h3>Dependencies</h3>; <ul>; <li>Update dependency com.google.cloud:google-cloud-shared-dependencies to v3.1.1 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1836"">#1836</a>) (<a href=""https://github.com/googleapis/java-storage/commit/3b71fab11ac71039c2a9983821ce02ce25ce311d"">3b71fab</a>)</li>; <li>Update dependency net.jqwik:jqwik to v1.7.2 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1833"">#1833</a>) (<a href=""https://github.com/googleapis/java-storage/commit/83bc261130e89e5994f21e32422054ef6ea2fe8e"">83bc261</a>)</li>; <li>Update dependency org.junit.vintage:junit-vintage-engine to v5.9.2 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1837"">#1837</a>) (<a href=""https://github.com/googleapis/java-storage",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12598:5080,depend,dependabot,5080,https://hail.is,https://github.com/hail-is/hail/pull/12598,2,['depend'],['dependabot']
Integrability," minor update to URL highlighting</p>; <h2>[13.5.1] - 2023-07-31</h2>; <h3>Fixed</h3>; <ul>; <li>Fix tilde character (<code>~</code>) not included in link regex when printing to console <a href=""https://redirect.github.com/Textualize/rich/issues/3057"">Textualize/rich#3057</a></li>; </ul>; <h2>Mostly cake, one or two puppies</h2>; <p><a href=""https://textual.textualize.io/blog/2023/07/29/pull-requests-are-cake-or-puppies/"">https://textual.textualize.io/blog/2023/07/29/pull-requests-are-cake-or-puppies/</a></p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/Textualize/rich/blob/master/CHANGELOG.md"">rich's changelog</a>.</em></p>; <blockquote>; <h2>[13.7.0] - 2023-11-15</h2>; <h3>Added</h3>; <ul>; <li>Adds missing parameters to Panel.fit <a href=""https://redirect.github.com/Textualize/rich/issues/3142"">Textualize/rich#3142</a></li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Some text goes missing during wrapping when it contains double width characters <a href=""https://redirect.github.com/Textualize/rich/issues/3176"">Textualize/rich#3176</a></li>; <li>Ensure font is correctly inherited in exported HTML <a href=""https://redirect.github.com/Textualize/rich/issues/3104"">Textualize/rich#3104</a></li>; <li>Fixed typing for <code>FloatPrompt</code>.</li>; </ul>; <h2>[13.6.0] - 2023-09-30</h2>; <h3>Added</h3>; <ul>; <li>Added Python 3.12 to classifiers.</li>; </ul>; <h2>[13.5.3] - 2023-09-17</h2>; <h3>Fixed</h3>; <ul>; <li>Markdown table rendering issue with inline styles and links <a href=""https://redirect.github.com/Textualize/rich/issues/3115"">Textualize/rich#3115</a></li>; <li>Fix Markdown code blocks on a light background <a href=""https://redirect.github.com/Textualize/rich/issues/3123"">Textualize/rich#3123</a></li>; </ul>; <h2>[13.5.2] - 2023-08-01</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed Text.expand_tabs assertion error</li>; </ul>; <h2>[13.5.1] - 2023-07-31</h2>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14012:2698,wrap,wrapping,2698,https://hail.is,https://github.com/hail-is/hail/pull/14012,2,['wrap'],['wrapping']
Integrability," mode</li>; <li>Use 12 character short IDs for consistency with Docker CLI</li>; <li>Ignore trailing whitespace in <code>.dockerignore</code> files</li>; <li>Fix IPv6 host parsing when explicit port specified</li>; <li>Fix <code>ProxyCommand</code> option for SSH connections</li>; <li>Do not spawn extra subshell when launching external SSH client</li>; <li>Improve exception semantics to preserve context</li>; <li>Documentation improvements (formatting, examples, typos, missing params)</li>; </ul>; <h3>🔧 Miscellaneous</h3>; <ul>; <li>Upgrade dependencies in <code>requirements.txt</code> to latest versions</li>; <li>Remove extraneous transitive dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/docker/docker-py/commit/30022984f6445fbc322cbe97bb99aab1ddb1e4fd""><code>3002298</code></a> socket: handle npipe close on Windows (<a href=""https://github-redirect.dependabot.com/docker/docker-py/issues/3056"">#3056</a>)</li>; <li><a href=""https://github.com/docker/docker-py/commit/bc0a5fbacd7617fd338d121adca61600fc70d221""><code>bc0a5fb</code></a> test: use anonymous volume for prune (<a href=""https://github-redirect.dependabot.com/docker/docker-py/issues/3051"">#3051</a>)</li>; <li><a href=""https://github.com/docker/docker-py/commit/923e067dddc3d4b86e4e620a99fcdcdafbd17a98""><code>923e067</code></a> api: add support for floats to docker logs params since / until (<a href=""https://github-redirect.dependabot.com/docker/docker-py/issues/3031"">#3031</a>)</li>; <li><a href=""https://github.com/docker/docker-py/commit/1c27ec1f0c34f6b9510f5caadada5fd8ecc430d9""><code>1c27ec1</code></a> ci: use latest stable syntax for Dockerfiles (<a href=""https://github-redirect.dependabot.com/docker/docker-py/issues/3035"">#3035</a>)</li>; <li><a href=""https://github.com/docker/docker-py/commit/2494d63f36eba0e1811f05e7b2136f8b30f7cdb7""><code>2494d63</code></a> docs: install pack",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12475:4729,depend,dependabot,4729,https://hail.is,https://github.com/hail-is/hail/pull/12475,1,['depend'],['dependabot']
Integrability," module not being displayed in the docs. (gh pr; <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1025"">#1025</a>)</li>; <li>Changed some relative links in the exercise documentation to refer to the; document locations in the input tree, rather than the generated HTML files in; the HTML output tree (which presumably will not exist in non-HTML output; formats). (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1078"">#1078</a>).</li>; </ul>; <h2>Misc</h2>; <ul>; <li>Moved <code>test_imports.py</code>, <code>test_internals.py</code> and <code>test_utils.py</code> to; pytest. Reported and fixed by <a href=""https://github.com/jpurviance""><code>@​jpurviance</code></a> (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/978"">#978</a>)</li>; <li>Added project_urls for documentation and source. Patch by <a href=""https://github.com/andriyor""><code>@​andriyor</code></a> (gh pr; <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/975"">#975</a>).</li>; <li>Simplified handling of bytes and bytearray in <code>_parser._timelex</code>. Reported; and fixed by <a href=""https://github.com/frenzymadness""><code>@​frenzymadness</code></a> (gh issue <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1060"">#1060</a>).</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/dateutil/dateutil/commit/6b035517571e63b6a63a493740c5506ec1e5da44""><code>6b03551</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1143"">#1143</a> from mariocj89/pu/2.8.2</li>; <li><a href=""https://github.com/dateutil/dateutil/commit/cf44dd0c66827070cf9dd7b30f126b3ab2e110b5""><code>cf44dd0</code></a> Manual cleanup for 2.8.2 NEWS</li>; <li><a href=""https://github.com/dateutil/dateutil/commit/561167183d4cad190059975e5c0826e3587d3c97""><code>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11518:8494,depend,dependabot,8494,https://hail.is,https://github.com/hail-is/hail/pull/11518,1,['depend'],['dependabot']
Integrability," module not being displayed in the docs. (gh pr; <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1025"">#1025</a>)</li>; <li>Changed some relative links in the exercise documentation to refer to the; document locations in the input tree, rather than the generated HTML files in; the HTML output tree (which presumably will not exist in non-HTML output; formats). (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1078"">#1078</a>).</li>; </ul>; <h2>Misc</h2>; <ul>; <li>Moved <code>test_imports.py</code>, <code>test_internals.py</code> and <code>test_utils.py</code> to; pytest. Reported and fixed by <a href=""https://github.com/jpurviance""><code>@​jpurviance</code></a> (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/978"">#978</a>)</li>; <li>Added project_urls for documentation and source. Patch by <a href=""https://github.com/andriyor""><code>@​andriyor</code></a> (gh pr; <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/975"">#975</a>).</li>; <li>Simplified handling of bytes and bytearray in <code>_parser._timelex</code>. Reported</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/dateutil/dateutil/blob/master/NEWS"">python-dateutil's changelog</a>.</em></p>; <blockquote>; <h1>Version 2.8.2 (2021-07-08)</h1>; <h2>Data updates</h2>; <ul>; <li>Updated tzdata version to 2021a. (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1128"">#1128</a>)</li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>Fixed a bug in the parser where non-<code>ValueError</code> exceptions would be raised; during exception handling; this would happen, for example, if an; <code>IllegalMonthError</code> was raised in <code>dateutil</code> code. Fixed by Mark Bailey.; (gh issue <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/981"">#",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11518:4173,depend,dependabot,4173,https://hail.is,https://github.com/hail-is/hail/pull/11518,1,['depend'],['dependabot']
Integrability," more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiN2QwMTZlZS0zODA0LTQwMjItOWE0Yi01MzExNjZhNjBjMWQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImI3ZDAxNmVlLTM4MDQtNDAyMi05YTRiLTUzMTE2NmE2MGMxZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""b7d016ee-3804-4022-9a4b-531166a60c1d"",""prPublicId"":""b7d016ee-3804-4022-9a4b-531166a60c1d"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.3"",""to"":""41.0.4""}],""packageManager"":""pip"",""projectPublicId"":""701495b8-b53d-48af-82fe-1a6c57aa56cb"",""projectUrl"":""https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-5914629""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""priorityScore""],""priorityScoreList"":[611],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Denial of Service (DoS)](https://learn.snyk.io/lesson/redos/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13698:2603,depend,dependencies,2603,https://hail.is,https://github.com/hail-is/hail/pull/13698,1,['depend'],['dependencies']
Integrability," moving them out of the SciPy repository, hosting them externally and</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/scipy/scipy/commit/dde50595862a4f9cede24b5d1c86935c30f1f88a""><code>dde5059</code></a> REL: 1.10.0 final [wheel build]</li>; <li><a href=""https://github.com/scipy/scipy/commit/7856f281b016c585b82d03723c4494bcdbdcd4a5""><code>7856f28</code></a> Merge pull request <a href=""https://redirect.github.com/scipy/scipy/issues/17696"">#17696</a> from tylerjereddy/treddy_110_final_prep</li>; <li><a href=""https://github.com/scipy/scipy/commit/205b6243c6d075d05695e7ac6d007e0f03bfbf42""><code>205b624</code></a> DOC: add missing author</li>; <li><a href=""https://github.com/scipy/scipy/commit/1ab9f1b10145f0a974d5531700e72d1fb4229b76""><code>1ab9f1b</code></a> DOC: update 1.10.0 relnotes</li>; <li><a href=""https://github.com/scipy/scipy/commit/ac2f45fbe1e39a8f52c1ea2e68764009f02973c0""><code>ac2f45f</code></a> MAINT: integrate._qmc_quad: mark as private with preceding underscore</li>; <li><a href=""https://github.com/scipy/scipy/commit/3e0ae1a21f51ebee3a77733c42700d87a0c35d7d""><code>3e0ae1a</code></a> REV: integrate.qmc_quad: delay release to SciPy 1.11.0</li>; <li><a href=""https://github.com/scipy/scipy/commit/34cdf05c86548de1c4ca1b2798cdc23885af807b""><code>34cdf05</code></a> MAINT: FFT pybind11 fixups</li>; <li><a href=""https://github.com/scipy/scipy/commit/843500aabde17aaf1eec65c589d50bd12ee35039""><code>843500a</code></a> Merge pull request <a href=""https://redirect.github.com/scipy/scipy/issues/17689"">#17689</a> from mdhaber/gh17686</li>; <li><a href=""https://github.com/scipy/scipy/commit/089924b61012a106ffa4f58939b0180124051a0b""><code>089924b</code></a> REL: integrate.qmc_quad: remove from release notes</li>; <li><a href=""https://github.com/scipy/scipy/commit/3e47110f10e3267d228e9da84174f3cee325e7c3""><code>3e47110</code></a> REL: 1.10.0rc3 unreleased</",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13227:3793,integrat,integrate,3793,https://hail.is,https://github.com/hail-is/hail/pull/13227,1,['integrat'],['integrate']
Integrability," neither a string or c...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c48c45a88c74c0429f184c48334a513806c6a16c""><code>c48c45a</code></a> Fix E1102 / <code>not-callable</code> false positive for property that returns a lambd...</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/v2.13.4...v2.13.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pylint&package-manager=pip&previous-version=2.13.4&new-version=2.13.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11739:5500,Depend,Dependabot,5500,https://hail.is,https://github.com/hail-is/hail/pull/11739,1,['Depend'],['Dependabot']
Integrability," no longer crashes when encountering template conditionals in img attributes (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/57"">#57</a>). Thanks to <a href=""https://github.com/adrien-delhorme""><code>@​adrien-delhorme</code></a>.</li>; </ul>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.12.1"">v0.12.1</a> 2021-03-06</h2>; <h3>Fixed</h3>; <ul>; <li>The project’s sdist now includes all needed files to run the test suite (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/49"">#49</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/50"">#50</a>). Thanks to <a href=""https://github.com/jayvdb""><code>@​jayvdb</code></a>.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/e6f6869fddbf307e3267ac164561c669039d557a""><code>e6f6869</code></a> Release v0.13.0 (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/78"">#78</a>)</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/2afa4b2934c3b61b96259d548c26cd49e03daf24""><code>2afa4b2</code></a> Implement --template-tags CLI flag</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/28316eea40acb6f67f267a0fa1545d81fb3ed59a""><code>28316ee</code></a> Re-add repo token</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/27b6bf942a0e9205d918efff1c6bab87ed80a460""><code>27b6bf9</code></a> Add website .nvmrc for Netlify</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/fd8964ab2ecc7662c6b88575f5b89de7a2fbde3d""><code>fd8964a</code></a> Revert &quot;Switch to official GitHub Actions coveralls integration&quot;</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/bc4ec76844853c0fe57b595b18116b2ca33b10bd""><code>bc4ec76</code></a> Use correct lcov path for Coveralls integration</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11494:5409,depend,dependabot,5409,https://hail.is,https://github.com/hail-is/hail/pull/11494,2,['depend'],['dependabot']
Integrability," not require calling &quot;exec&quot;).; Added a way to mimic functools.wraps-generated decorators.; Ported the Continuous Integration from Travis to GitHub.</p>; <h2>4.4.2 (2020-02-29)</h2>; <p>Sylvan Mosberger (<a href=""https://github.com/Infinisil"">https://github.com/Infinisil</a>) contributed a patch to; some doctests that were breaking on NixOS.; John Vandenberg (<a href=""https://github.com/jayvdb"">https://github.com/jayvdb</a>) made a case for removing the usage</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/micheles/decorator/commits/5.1.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=decorator&package-manager=pip&previous-version=4.4.0&new-version=5.1.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11799:3005,depend,dependabot-security-updates,3005,https://hail.is,https://github.com/hail-is/hail/pull/11799,1,['depend'],['dependabot-security-updates']
Integrability," notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiorwlock/releases"">aiorwlock's releases</a>.</em></p>; <blockquote>; <h2>aiorwlock 1.2.0</h2>; <h1>Changes</h1>; <ul>; <li>Fix a bug that makes concurrent writes possible under some (rare) conjunctions (<a href=""https://github-redirect.dependabot.com/aio-libs/aiorwlock/issues/235"">#235</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiorwlock/blob/master/CHANGES.rst"">aiorwlock's changelog</a>.</em></p>; <blockquote>; <p>1.3.0 (2022-1-18); ^^^^^^^^^^^^^^^^^^</p>; <ul>; <li>Dropped Python 3.6 support</li>; <li>Python 3.10 is officially supported</li>; <li>Drop deprecated <code>loop</code> parameter from <code>RWLock</code> constructor</li>; </ul>; <p>1.2.0 (2021-11-09); ^^^^^^^^^^^^^^^^^^</p>; <ul>; <li>Fix a bug that makes concurrent writes possible under some (rare) conjunctions (<a href=""https://github-redirect.dependabot.com/aio-libs/aiorwlock/issues/235"">#235</a>)</li>; </ul>; <p>1.1.0 (2021-09-27); ^^^^^^^^^^^^^^^^^^</p>; <ul>; <li>Remove explicit loop usage in <code>asyncio.sleep()</code> call, make the library forward; compatible with Python 3.10</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiorwlock/commit/6599d10ba16f95f19d5b5963a00aa857bc98f656""><code>6599d10</code></a> Bump to 1.3.0</li>; <li><a href=""https://github.com/aio-libs/aiorwlock/commit/d4b41f54b57caf316c41c3973ab82bd53a418ff8""><code>d4b41f5</code></a> Drop deprecated 'loop' parameter from RWLock constructor</li>; <li><a href=""https://github.com/aio-libs/aiorwlock/commit/3edb2a1bc1636832df12671f035e21dd74440824""><code>3edb2a1</code></a> Fix tests</li>; <li><a href=""https://github.com/aio-libs/aiorwlock/commit/45a7418474a55defe9c53fd8e38df60af514cf84""><code>45a7418</code></a> Fix linters</li>; <li><a href=""https://github.com/aio-libs/aiorwlock/commit/e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11514:1101,depend,dependabot,1101,https://hail.is,https://github.com/hail-is/hail/pull/11514,1,['depend'],['dependabot']
Integrability," now parse starred expressions in the target of <code>for</code> and <code>async for</code>; statements, e.g <code>for item in *items_1, *items_2: pass</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2879"">#2879</a>).</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/psf/black/commit/ae2c0758c9e61a385df9700dc9c231bf54887041""><code>ae2c075</code></a> Prepare release 22.3.0 (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2968"">#2968</a>)</li>; <li><a href=""https://github.com/psf/black/commit/e9681a40dcb3d38b56b301d811bb1c55201fd97e""><code>e9681a4</code></a> Fix _unicodefun patch code for Click 8.1.0 (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2966"">#2966</a>)</li>; <li><a href=""https://github.com/psf/black/commit/ac7402cbf6a0deb5c74e9abcffc5bd7b1148fda5""><code>ac7402c</code></a> Bump sphinx from 4.4.0 to 4.5.0 in /docs (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2959"">GH-2959</a>)</li>; <li><a href=""https://github.com/psf/black/commit/f239d227c003c52126239e1b9a37c36c2b2b8305""><code>f239d22</code></a> Enforce no formatting changes for PRs via CI (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2951"">GH-2951</a>)</li>; <li><a href=""https://github.com/psf/black/commit/bd1e98034907463f5d86f4d87e89202dc6c34dd4""><code>bd1e980</code></a> Remove unnecessary parentheses from <code>except</code> clauses (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2939"">#2939</a>)</li>; <li><a href=""https://github.com/psf/black/commit/14d84ba2e96c5ca1351b8fe4d0d415cc148f4117""><code>14d84ba</code></a> Resolve new flake8-bugbear errors (B020) (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2950"">GH-2950</a>)</li>; <li><a href=""https://github.com/psf/black/commit/14e5ce5412efa53438df0180e735b3834df3b579""><code>14e5ce5</code></a> Remove unnecessary parentheses from tuple unpacking in <code>for",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11696:7069,depend,dependabot,7069,https://hail.is,https://github.com/hail-is/hail/pull/11696,1,['depend'],['dependabot']
Integrability," of GHA artifacts to upload and combine coverag...</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/6bad9acc951aabc8f90c1c95591c4b876b2a70e6""><code>6bad9ac</code></a> Test against Python 3.11</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/06406c5f795e85aca1792a52010d94c54a21fbd8""><code>06406c5</code></a> [1.26] Mention pool size when discarding connections (<a href=""https://github-redirect.dependabot.com/urllib3/urllib3/issues/2497"">#2497</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/urllib3/urllib3/compare/1.26.5...1.26.8"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.5&new-version=1.26.8)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11532:7863,Depend,Dependabot,7863,https://hail.is,https://github.com/hail-is/hail/pull/11532,1,['Depend'],['Dependabot']
Integrability," of XCFramework binary distribution via Cocoapod (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/28749"">#28749</a>).</p>; <p>This brings in significant speed up to local compile time and includes support for Apple Silicon build.</p>; <ul>; <li>The following binary pods are made available for ObjC V1 &amp; V2 API</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/grpc/grpc/commit/d52ed193d11dee797c0d51dc8db06032998b33f4""><code>d52ed19</code></a> Bump version to v1.48.1 (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30782"">#30782</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/2c7ba6410e5f9849a4848ff2e23839d6f8339f1e""><code>2c7ba64</code></a> xDS interop: Python LB tests build and use the python server (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30637"">#30637</a>) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30655"">#30655</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/d0f491285f74f8b07dec7f1c745a6636f3a691de""><code>d0f4912</code></a> Bump version to 1.48.1-pre1 (on v1.48.x branch) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30627"">#30627</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/a8065cb662ca35f2b57efd636b1ac193d327ed74""><code>a8065cb</code></a> Backport EventEngine Forkables (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30605"">#30605</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/796a8ddcfe629c1ef7beae117efce2004886ecd9""><code>796a8dd</code></a> xDS interop: add missing image tagging to the buildscripts (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30520"">#30520</a>) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30529"">#30529</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/0d20b3fac16f901bd19f116b71cfec538bb57160""><code>0d20b3f<",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12201:3782,depend,dependabot,3782,https://hail.is,https://github.com/hail-is/hail/pull/12201,1,['depend'],['dependabot']
Integrability," of methods now have emit and code variants: getEmitParam, getCodeParam, invokeCode, invokeEmit (where code, emit refer to the return value).; - I made the minimal changes to get things working again. Some code still code parameters to pass emit values. I will fix these in a later PR.; - Where possible, make the class implemented by Compile concrete rather than generic. I think this can be pushed through the entire code base and we can remove the option to build generic methods. We should have done this a long time ago.; - ModuleBuilder can now create type-specialized tuple types. This is used for EmitCode return values. I'm not sure if this is actually used yet.; - Require RVDType rowType to be required. Require TypeValue global type to be required. Fix lots of places to make this true. In a few spots (e.g. TableMap{Rows, Globals}), I had to wrap the IR being compiled in a Coalesce with a Die to make sure the return type is required.; - Cleaned up the dependent function interface to be closer to what we have now with MethodBuilder, etc. DependentFunctionBuilder is now just an `apply_method: DependentMethodBuilder`, EmitFunctionBuilder analogously. DependentMethodBuilder wraps a MethodBuilder, EmitMethodBuilder wraps a DependentMethodBuilder and an EmitMethodBuilder.; - Add equality comparison to TypeInfo[_]; - Add methods to convert IndexedSeq[Code[_]] to/from PCode and EmitCode. These are used to pass EmitCode as arguments to method invocation. If an emit parameter is required, the missingness boolean is omitted, otherwise it is present. Furthermore, this change also adds requiredness to many things and improves ptype interfaces:; - added PType.literalPType that infers PTypes from Scala literals, use in a few places (emit for Literal, BroadcastRegionValue constructor from annotation, etc.); - require Table global and row types to be required; - same for MatrixValue, but also cols and entries (the entries array, not individual entries, which an be missing); - Don't ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8371:1463,depend,dependent,1463,https://hail.is,https://github.com/hail-is/hail/pull/8371,2,"['depend', 'interface']","['dependent', 'interface']"
Integrability," of singleton classes in Ruby (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9342"">#9342</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/protocolbuffers/protobuf/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.19.6&new-version=4.21.12)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12563:4566,Depend,Dependabot,4566,https://hail.is,https://github.com/hail-is/hail/pull/12563,1,['Depend'],['Dependabot']
Integrability," offset if not at char boundary</li>; <li>Additional commits viewable in <a href=""https://github.com/ijl/orjson/compare/3.6.4...3.6.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=orjson&package-manager=pip&previous-version=3.6.4&new-version=3.6.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11572:4972,Depend,Dependabot,4972,https://hail.is,https://github.com/hail-is/hail/pull/11572,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability," on light</li>; <li><a href=""https://github.com/Textualize/rich/commit/a972ca05522577de2f98eb7c957deead9c87b38f""><code>a972ca0</code></a> changelog</li>; <li><a href=""https://github.com/Textualize/rich/commit/bef0e50b63cf7294ae6c27bf8a79cbe3592599a0""><code>bef0e50</code></a> Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3130"">#3130</a> from Textualize/fix-table-inline-styles</li>; <li><a href=""https://github.com/Textualize/rich/commit/e30b822ecc264c5c4f984a023124d31d8052de49""><code>e30b822</code></a> Fix markdown table rendering issue.</li>; <li>Additional commits viewable in <a href=""https://github.com/Textualize/rich/compare/v12.6.0...v13.5.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=rich&package-manager=pip&previous-version=12.6.0&new-version=13.5.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13651:7175,depend,dependabot-security-updates,7175,https://hail.is,https://github.com/hail-is/hail/pull/13651,2,['depend'],['dependabot-security-updates']
Integrability," on widgets JSON reprs (<a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/issues/1829"">#1829</a>) by <a href=""https://github.com/martinRenou""><code>@​martinRenou</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1830"">jupyter/nbconvert#1830</a></li>; <li>Remove tests from bdist by <a href=""https://github.com/TiagodePAlves""><code>@​TiagodePAlves</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1822"">jupyter/nbconvert#1822</a></li>; <li>Encode SVG image data as UTF-8 before calling lxml cleaner (fixes <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/issues/1836"">#1836</a>) by <a href=""https://github.com/emarsden""><code>@​emarsden</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1837"">jupyter/nbconvert#1837</a></li>; <li>Handle nbformat 5.5 by <a href=""https://github.com/blink1073""><code>@​blink1073</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1841"">jupyter/nbconvert#1841</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/TiagodePAlves""><code>@​TiagodePAlves</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1764"">jupyter/nbconvert#1764</a></li>; <li><a href=""https://github.com/konstin""><code>@​konstin</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1782"">jupyter/nbconvert#1782</a></li>; <li><a href=""https://github.com/paoloalba""><code>@​paoloalba</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1785"">jupyter/nbconvert#1785</a></li>; <li><a href=""https://github.com/veghdev""><code>@​veghdev</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1761"">jupyter/nbconvert#1761</a></li>; <li><a href=""https://github.c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12126:4327,depend,dependabot,4327,https://hail.is,https://github.com/hail-is/hail/pull/12126,1,['depend'],['dependabot']
Integrability," out some unused attributes (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1575"">#1575</a>); c647764b0 Some long reads tests using PacBio data. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1564"">#1564</a>); 57c3f03eb remove hardcoded .idx (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1568"">#1568</a>); a94a32512 Add file extension to missing index error message <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1512"">#1512</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1567"">#1567</a>); 74b827b67 Improve error message in IntervalTree (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1545"">#1545</a>); 7719274fe Htsget POST request support (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1529"">#1529</a>)</p>; <p>VCF:; aac46ee6d Added GVCF mode for VariantContext type determination (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1544"">#1544</a>); d72d73b01 Add context to exception when the vcf file is invalid <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1565"">#1565</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1566"">#1566</a>); 8466c82dc Respect genotype filtering when calculating AC/AN/AF (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1554"">#1554</a>)</p>; <p>User API:; a4f1f04c8 Allow fluent chaining setters for SAMSequenceRecord (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1563"">#1563</a>)</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/samtools/htsjdk/commit/4a4024a97ee3e87096df6ad9b22c8260bd527772""><code>4a4024a</code></a> Fix temporary directory hijacking or temporary directory information disclosu...</li>; <li><a href=""https://github.com/samtools/htsjdk/co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12229:5343,depend,dependabot,5343,https://hail.is,https://github.com/hail-is/hail/pull/12229,1,['depend'],['dependabot']
Integrability," overloaded method value save with alternatives:; (javaRDD: org.apache.spark.api.java.JavaRDD[org.bson.Document])Unit <and>; (dataFrameWriter: org.apache.spark.sql.DataFrameWriter[_])Unit <and>; [D](dataset: org.apache.spark.sql.Dataset[D])Unit <and>; [D](rdd: org.apache.spark.rdd.RDD[D])(implicit evidence$5: scala.reflect.ClassTag[D])Unit; cannot be applied to (org.apache.spark.sql.DataFrameWriter); MongoSpark.save(kt.toDF(sqlContext); ^; /gpfs/home/tpathare/haillatest/hail/src/main/scala/is/hail/sparkextras/OrderedRDD.scala:382: class PartitionCoalescer in package rdd cannot be accessed in package org.apache.spark.rdd; override def coalesce(maxPartitions: Int, shuffle: Boolean = false, partitionCoalescer: Option[PartitionCoalescer] = Option.empty); ^; missing or invalid dependency detected while loading class file 'package.class'.; Could not access type DataFrame in package org.apache.spark.sql.package,; because it (or its dependencies) are missing. Check your build definition for; missing or conflicting dependencies. (Re-run with `-Ylog-classpath` to see the problematic classpath.); A full rebuild may help if 'package.class' was compiled against an incompatible version of org.apache.spark.sql.package.; /gpfs/home/tpathare/haillatest/hail/src/main/scala/is/hail/variant/VariantSampleMatrix.scala:1143: ambiguous reference to overloaded definition,; both method coalesce in class OrderedRDD of type (maxPartitions: Int, shuffle: Boolean, partitionCoalescer: Option[<error>])(implicit ord: Ordering[(is.hail.variant.Variant, (is.hail.annotations.Annotation, Iterable[is.hail.variant.Genotype]))])org.apache.spark.rdd.RDD[(is.hail.variant.Variant, (is.hail.annotations.Annotation, Iterable[is.hail.variant.Genotype]))]; and method coalesce in class RDD of type (numPartitions: Int, shuffle: Boolean)(implicit ord: Ordering[(is.hail.variant.Variant, (is.hail.annotations.Annotation, Iterable[is.hail.variant.Genotype]))])org.apache.spark.rdd.RDD[(is.hail.variant.Variant, (is.hail.a",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1327#issuecomment-277494831:1942,depend,dependencies,1942,https://hail.is,https://github.com/hail-is/hail/issues/1327#issuecomment-277494831,1,['depend'],['dependencies']
Integrability," pages/; * scorecard.tsx; * scorecard/; * users.tsx. These 'pages' components are just like normal react components, except they expose `getInitialProps`, described above. Each page file must export 1 default component:. ```js; #Page file; import React from 'react';. const index = () => <div>Hello World</div>; export default index;; ```. There is nothing else to do to get routing to work, a quite nice solution. ### JS pragma; 1. `this` is different than in most (every?) other language. scope of this is bound to caller, not object containing the method; * Solution: use arrow functions. ```js; class Something {; constructor() {; this.bar = 'foo';; } ; //Do; onSubmit = () => {; console.log(this.bar) //prints foo; }. // Don't; onSubmitBad() {; console.log(this.bar) //may be undefined; }; }. const barrer = new Something();; console.info(""good"", barrer.onSubmit());; console.info(""bad"", barrer.onSubmitBad());; ```. # Tips . ### Client-side routing; Wrap a normal anchor tag in `<Link ></Link>`; ex:; ```jsx; <Link href='/path/to/page'><a>Page Name</a></Link>; ```. This simply adds the client-side routing logic, and passes the href to <a href=. . ### Prefetching; One of the neat things about Next is how easy it makes prefetching pages. This allows perceived page loading times on the order of 5ms, even when the page requires very complex state (say a GraphQL or series of REST calls with large responses). ```jsx; <Link href='/expensive-page' prefetch><a>Expensive Page</a></Link>; ```; ### Make your app do ONLY server-side routing; Meaning every time you click on a link in your page, you hit the server, just like the first visited page. . Simply use `<a>` directly. ### Caching and sidecar requests; Broadly, there are three strategies: browser caching, server caching, and service-worker caching. In this project we will likely use all three. Server caching is an excellent strategy for pages that serve only public data. In this strategy we pre-generate the static html, serve that, a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162:13424,rout,routing,13424,https://hail.is,https://github.com/hail-is/hail/pull/5162,2,"['Wrap', 'rout']","['Wrap', 'routing']"
Integrability," parameter of <code>naturaldelta</code> (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/248"">#248</a>) <a href=""https://github.com/carterbox""><code>@​carterbox</code></a></li>; </ul>; <h2>3.13.1</h2>; <h2>Fixed</h2>; <ul>; <li>Temporarily comment out to avoid warning during <code>import humanize</code> (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/243"">#243</a>) <a href=""https://github.com/hugovk""><code>@​hugovk</code></a></li>; </ul>; <h2>3.13.0</h2>; <h2>Added</h2>; <ul>; <li>Add da_DK language (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/238"">#238</a>) <a href=""https://github.com/dejurin""><code>@​dejurin</code></a></li>; <li>Fix and add Russian and Ukrainian words (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/235"">#235</a>) <a href=""https://github.com/dejurin""><code>@​dejurin</code></a></li>; <li>Add missing strings for Polish translation (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/182"">#182</a>) <a href=""https://github.com/kpostekk""><code>@​kpostekk</code></a></li>; <li>Add Traditional Chinese (zh-HK) (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/233"">#233</a>) <a href=""https://github.com/edwardmfho""><code>@​edwardmfho</code></a></li>; </ul>; <h2>Changed</h2>; <ul>; <li>Remove redundant setuptools from install_requires (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/232"">#232</a>) <a href=""https://github.com/arthurzam""><code>@​arthurzam</code></a></li>; </ul>; <h2>Deprecated</h2>; <ul>; <li>This is the last release to support Python 3.6</li>; <li>Deprecate private functions (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/234"">#234</a>) <a href=""https://github.com/samueljsb""><code>@​samueljsb</code></a></li>; <li>Reinstate <code>VERSION</code> and deprecate (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/240"">#240</a>) <a href=""ht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11517:2735,depend,dependabot,2735,https://hail.is,https://github.com/hail-is/hail/pull/11517,2,['depend'],['dependabot']
Integrability," pervasive (but minor) improvements to Hail's I/O infrastructure. We should start with the egregious examples. Consider `AzureStorageFS.createNoCompression`'s [`OutputStream`](https://github.com/hail-is/hail/blob/main/hail/src/main/scala/is/hail/io/fs/AzureStorageFS.scala#L332-L342):; ```scala; val os: PositionedOutputStream = new FSPositionedOutputStream(4 * 1024 * 1024) {; private[this] val client: BlockBlobClient = blockBlobClient; private[this] val blobOutputStream = client.getBlobOutputStream(true). override def flush(): Unit = {; bb.flip(). if (bb.limit() > 0) {; blobOutputStream.write(bb.array(), 0, bb.limit()); }. bb.clear(); }; // ...; }; ```. Notice how we already have a `ByteBuffer` but we convert it to an array and send that to the OutputStream. Instead, we could just use the [`ByteChannel` methods of `BlockBlobClient`](https://learn.microsoft.com/en-us/java/api/com.azure.storage.blob.specialized.blockblobclient?view=azure-java-stable#com-azure-storage-blob-specialized-blockblobclient-openseekablebytechannelwrite(com-azure-storage-blob-options-blockblobseekablebytechannelwriteoptions)). The [read case also supports a channel](https://learn.microsoft.com/en-us/java/api/com.azure.storage.blob.specialized.blobclientbase?view=azure-java-stable#com-azure-storage-blob-specialized-blobclientbase-openseekablebytechannelread(com-azure-storage-blob-options-blobseekablebytechannelreadoptions-com-azure-core-util-context)). The next, more complicated problem, is the InputBuffer and OutputBuffer interfaces. These assume their sources/sinks are `java.io.InputStream` and `java.io.OutputStream`. Moreover, they too rely on and expose `Array[Byte]` interfaces (e.g. `readBytesArray` and the implementation of `StreamInputBuffer.readBytes`). Let's start with InputBuffer and the decoders and use decoding of VDS variant matrix tables as our benchmark. ```python3; import hail as hl; hl.init(master='local[1]'); vds = hl.vds.read_vds(...); vds.variant_data._force_count_rows(); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13840:1702,interface,interfaces,1702,https://hail.is,https://github.com/hail-is/hail/issues/13840,2,['interface'],['interfaces']
Integrability," pivot_table when ...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/c9252cfd111fab8f8361613a8ca518de1207d51a""><code>c9252cf</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/49614"">#49614</a> on branch 1.5.x (CI: Updating website sync to new server) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.5...v1.5.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pandas&package-manager=pip&previous-version=1.3.5&new-version=1.5.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12564:6201,depend,dependabot-automerge-start,6201,https://hail.is,https://github.com/hail-is/hail/pull/12564,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability," pod IPs underlying a Service so that our proxies can properly load-balance across persistent connections. ## Solution. This PR addresses the two goals outlined above and does so through using Envoy, a load-balancer/proxy that is well-suited to this sort of highly-dynamic cluster configuration. Envoy does not have the constraint that all upstream services must be available at start-time, and has a very convenient API for updating the cluster configuration without the need for restarting the process or dropping traffic. This makes regularly updating the cluster configuration whenever new test namespaces are created relatively straightforward and non-disruptive to traffic in other namespaces. The high-level approach is as follows:. 1. Envoy-based gateways and internal-gateways will load their routing configuration from a Kubernetes ConfigMap, which they watch for changes and reconcile their configuration when the ConfigMap changes. The ConfigMap can be populated with a manual deploy and is populated from the beginning with production routes (i.e. batch.hail.is gets routed to batch.default); 2. When running CI, CI will regularly update the ConfigMap with additional routes based on which internal namespaces (dev and PR) are currently active. This requires relatively small changes to CI to track active namespaces but overall is a pretty small change. Note that this does not introduce a dependency on CI to support production traffic, only development traffic.; 3. Deployments that run more than 1 replica (but really can be all of them) are run behind Headless Services, which expose the underlying pod IPs so Envoy can handle load-balancing instead of kube-proxy. This allows Envoy to make smart load-balancing decisions and correctly enforce rate-limiting when using connection pools. The namespace tracking in CI in Point 2 is possible before we make any changes to our networking, so that comes first in #12093. Point 3 is taken care of in #12094, and the rest of Point 2 and Poi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12095:4471,rout,routes,4471,https://hail.is,https://github.com/hail-is/hail/pull/12095,1,['rout'],['routes']
Integrability," providing support for skipping encryption of the AS2 message body when a HTTPS URL is also specified.</li>; </ul>; <h1>1.26.12</h1>; <ul>; <li>api-change:<code>amplify</code>: [<code>botocore</code>] Adds a new value (WEB_COMPUTE) to the Platform enum that allows customers to create Amplify Apps with Server-Side Rendering support.</li>; <li>api-change:<code>appflow</code>: [<code>botocore</code>] AppFlow simplifies the preparation and cataloging of SaaS data into the AWS Glue Data Catalog where your data can be discovered and accessed by AWS analytics and ML services. AppFlow now also supports data field partitioning and file size optimization to improve query performance and reduce cost.</li>; <li>api-change:<code>appsync</code>: [<code>botocore</code>] This release introduces the APPSYNC_JS runtime, and adds support for JavaScript in AppSync functions and AppSync pipeline resolvers.</li>; <li>api-change:<code>dms</code>: [<code>botocore</code>] Adds support for Internet Protocol Version 6 (IPv6) on DMS Replication Instances</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/boto/boto3/commit/f38ce50a317baf6715870b2706100d43b80b0c73""><code>f38ce50</code></a> Merge branch 'release-1.26.16'</li>; <li><a href=""https://github.com/boto/boto3/commit/33d7d6f020510890b93edf49de3f81c0ba208cb3""><code>33d7d6f</code></a> Bumping version to 1.26.16</li>; <li><a href=""https://github.com/boto/boto3/commit/fb642196bd5dda0f48636e3eeae5f983835fcef5""><code>fb64219</code></a> Add changelog entries from botocore</li>; <li><a href=""https://github.com/boto/boto3/commit/cc2984fc4fe2a399404a81711eb9ece3fb8d6eb7""><code>cc2984f</code></a> Merge branch 'release-1.26.15'</li>; <li><a href=""https://github.com/boto/boto3/commit/9280e856b07feef67b8dc08c3663ffd0b65b8f55""><code>9280e85</code></a> Merge branch 'release-1.26.15' into develop</li>; <li><a href=""https://github.com/boto/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12502:6519,Protocol,Protocol,6519,https://hail.is,https://github.com/hail-is/hail/pull/12502,1,['Protocol'],['Protocol']
Integrability," provisioning process is used (<code>PersistentVolumeClaim</code>), storage can be provided by third-party storage vendors and all of the usual volume features work. Volumes don't need to be empt; for example, restoring from snapshot is supported. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92784"">kubernetes/kubernetes#92784</a>, <a href=""https://github.com/pohly""><code>@​pohly</code></a>) [SIG API Machinery, Apps, Auth, CLI, Instrumentation, Node, Scheduling, Storage and Testing]</li>; <li>Go1.14.4 is now the minimum version required for building Kubernetes (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92438"">kubernetes/kubernetes#92438</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>) [SIG API Machinery, Auth, CLI, Cloud Provider, Cluster Lifecycle, Instrumentation, Network, Node, Release, Storage and Testing]</li>; <li>Hide managedFields from kubectl edit command (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91946"">kubernetes/kubernetes#91946</a>, <a href=""https://github.com/soltysh""><code>@​soltysh</code></a>) [SIG CLI]</li>; <li>K8s.io/apimachinery - scheme.Convert() now uses only explicitly registered conversions - default reflection based conversion is no longer available. <code>+k8s:conversion-gen</code> tags can be used with the <code>k8s.io/code-generator</code> component to generate conversions. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/90018"">kubernetes/kubernetes#90018</a>, <a href=""https://github.com/wojtek-t""><code>@​wojtek-t</code></a>) [SIG API Machinery, Apps and Testing]</li>; <li>Kube-proxy: add <code>--bind-address-hard-fail</code> flag to treat failure to bind to a port as fatal (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89350"">kubernetes/kubernetes#89350</a>, <a href=""https://github.com/SataQiu""><code>@​SataQiu</code></a>) [SIG Cluster Lifecycle and Network]</li>; <li>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:8491,depend,dependabot,8491,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['depend'],['dependabot']
Integrability," publish sdist/wheel to PyPI (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/202"">#202</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/961624063383cbcdc78a61b1d18448429a61a489""><code>9616240</code></a> [chore] update changelog</li>; <li>Additional commits viewable in <a href=""https://github.com/tomplus/kubernetes_asyncio/compare/v19.15.1...23.6.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=kubernetes-asyncio&package-manager=pip&previous-version=19.15.1&new-version=23.6.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:16074,depend,dependabot-automerge-start,16074,https://hail.is,https://github.com/hail-is/hail/pull/11957,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability," pull request <a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2252"">#2252</a> from daschuer/worktree_fix</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/fd0177ae3ae5f94b36aafb54ab496f76fcead7b9""><code>fd0177a</code></a> implement default_install_hook_types</li>; <li>Additional commits viewable in <a href=""https://github.com/pre-commit/pre-commit/compare/v2.17.0...v2.18.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pre-commit&package-manager=pip&previous-version=2.17.0&new-version=2.18.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11731:13373,depend,dependabot-automerge-start,13373,https://hail.is,https://github.com/hail-is/hail/pull/11731,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability," pybind11 fixups</li>; <li><a href=""https://github.com/scipy/scipy/commit/843500aabde17aaf1eec65c589d50bd12ee35039""><code>843500a</code></a> Merge pull request <a href=""https://redirect.github.com/scipy/scipy/issues/17689"">#17689</a> from mdhaber/gh17686</li>; <li><a href=""https://github.com/scipy/scipy/commit/089924b61012a106ffa4f58939b0180124051a0b""><code>089924b</code></a> REL: integrate.qmc_quad: remove from release notes</li>; <li><a href=""https://github.com/scipy/scipy/commit/3e47110f10e3267d228e9da84174f3cee325e7c3""><code>3e47110</code></a> REL: 1.10.0rc3 unreleased</li>; <li>Additional commits viewable in <a href=""https://github.com/scipy/scipy/compare/v1.9.3...v1.10.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=scipy&package-manager=pip&previous-version=1.9.3&new-version=1.10.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13227:5168,depend,dependabot-security-updates,5168,https://hail.is,https://github.com/hail-is/hail/pull/13227,1,['depend'],['dependabot-security-updates']
Integrability," pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **451/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.3 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6210214) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI0Y2E5NmE2ZC02MjMxLTQ1YTctYmQyOS1kYTA0ZmZhNTliYzQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjRjYTk2YTZkLTYyMzEtNDVhNy1iZDI5LWRhMDRmZmE1OWJjNCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14238:1591,depend,dependency,1591,https://hail.is,https://github.com/hail-is/hail/pull/14238,2,['depend'],"['dependencies', 'dependency']"
Integrability," rST to md/MyST (<a href=""https://github-redirect.dependabot.com/hynek/prometheus-async/issues/27"">#27</a>)</li>; <li><a href=""https://github.com/hynek/prometheus-async/commit/36bfe3f427c4206828d2d99f5aeefac2ec8d8226""><code>36bfe3f</code></a> count_exceptions only needs an Incrementer</li>; <li><a href=""https://github.com/hynek/prometheus-async/commit/82766062e8d64b56999d150dd2b4f60d4b6dd33d""><code>8276606</code></a> Expand regression test to signatures</li>; <li>Additional commits viewable in <a href=""https://github.com/hynek/prometheus-async/compare/19.2.0...22.1.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=prometheus-async&package-manager=pip&previous-version=19.2.0&new-version=22.1.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11536:4510,Depend,Dependabot,4510,https://hail.is,https://github.com/hail-is/hail/pull/11536,1,['Depend'],['Dependabot']
Integrability," rare cases, make changes that; affect code that was not previously formatted by <em>Black</em> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3155"">#3155</a>)</li>; </ul>; <h3>Stable style</h3>; <ul>; <li>Fix an infinite loop when using <code># fmt: on/off</code> in the middle of an expression or code; block (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3158"">#3158</a>)</li>; <li>Fix incorrect handling of <code># fmt: skip</code> on colon (<code>:</code>) lines (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3148"">#3148</a>)</li>; <li>Comments are no longer deleted when a line had spaces removed around power operators; (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2874"">#2874</a>)</li>; </ul>; <h3>Preview style</h3>; <ul>; <li>Single-character closing docstring quotes are no longer moved to their own line as; this is invalid. This was a bug introduced in version 22.6.0. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3166"">#3166</a>)</li>; <li><code>--skip-string-normalization</code> / <code>-S</code> now prevents docstring prefixes from being; normalized as expected (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3168"">#3168</a>)</li>; <li>When using <code>--skip-magic-trailing-comma</code> or <code>-C</code>, trailing commas are stripped from; subscript expressions with more than 1 element (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3209"">#3209</a>)</li>; <li>Implicitly concatenated strings inside a list, set, or tuple are now wrapped inside; parentheses (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3162"">#3162</a>)</li>; <li>Fix a string merging/split issue when a comment is present in the middle of implicitly; concatenated strings on its own line (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3227"">#3227</a>)</li>; </ul>; <h3><em>Blackd</em></h3>; <ul>; <li><code>blackd</code> now supports e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12174:6693,depend,dependabot,6693,https://hail.is,https://github.com/hail-is/hail/pull/12174,1,['depend'],['dependabot']
Integrability," reducing regex; backtracking. Email matching requires a word character at the start; of the domain part, and only word characters in the TLD. :pr:<code>1343</code></li>; </ul>; <h2>Version 2.11.2</h2>; <p>Released 2020-04-13</p>; <ul>; <li>Fix a bug that caused callable objects with <code>__getattr__</code>, like; :class:<code>~unittest.mock.Mock</code> to be treated as a; :func:<code>contextfunction</code>. :issue:<code>1145</code></li>; <li>Update <code>wordcount</code> filter to trigger :class:<code>Undefined</code> methods; by wrapping the input in :func:<code>soft_str</code>. :pr:<code>1160</code></li>; <li>Fix a hang when displaying tracebacks on Python 32-bit.; :issue:<code>1162</code></li>; <li>Showing an undefined error for an object that raises; <code>AttributeError</code> on access doesn't cause a recursion error.; :issue:<code>1177</code></li>; <li>Revert changes to :class:<code>~loaders.PackageLoader</code> from 2.10 which; removed the dependency on setuptools and pkg_resources, and added; limited support for namespace packages. The changes caused issues; when using Pytest. Due to the difficulty in supporting Python 2 and; :pep:<code>451</code> simultaneously, the changes are reverted until 3.0.; :pr:<code>1182</code></li>; <li>Fix line numbers in error messages when newlines are stripped.; :pr:<code>1178</code></li>; <li>The special <code>namespace()</code> assignment object in templates works in; async environments. :issue:<code>1180</code></li>; <li>Fix whitespace being removed before tags in the middle of lines when; <code>lstrip_blocks</code> is enabled. :issue:<code>1138</code></li>; <li>:class:<code>~nativetypes.NativeEnvironment</code> doesn't evaluate; intermediate strings during rendering. This prevents early; evaluation which could change the value of an expression.; :issue:<code>1186</code></li>; </ul>; <h2>Version 2.11.1</h2>; <p>Released 2020-01-30</p>; <ul>; <li>Fix a bug that prevented looking up a key after an attribute; (<code>{{ data",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10209:3852,depend,dependency,3852,https://hail.is,https://github.com/hail-is/hail/pull/10209,1,['depend'],['dependency']
Integrability," release to v4</li>; <li>Additional commits viewable in <a href=""https://github.com/jaraco/keyrings.alt/compare/v3.5.2...v4.2.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=keyrings-alt&package-manager=pip&previous-version=3.5.2&new-version=4.2.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12448:4067,Depend,Dependabot,4067,https://hail.is,https://github.com/hail-is/hail/pull/12448,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability," releases</a>.</em></p>; <blockquote>; <h2>v1.23.5</h2>; <h1>NumPy 1.23.5 Release Notes</h1>; <p>NumPy 1.23.5 is a maintenance release that fixes bugs discovered after; the 1.23.4 release and keeps the build infrastructure current. The; Python versions supported for this release are 3.8-3.11.</p>; <h2>Contributors</h2>; <p>A total of 7 people contributed to this release. People with a &quot;+&quot; by; their names contributed a patch for the first time.</p>; <ul>; <li><a href=""https://github.com/DWesl""><code>@​DWesl</code></a></li>; <li>Aayush Agrawal +</li>; <li>Adam Knapp +</li>; <li>Charles Harris</li>; <li>Navpreet Singh +</li>; <li>Sebastian Berg</li>; <li>Tania Allard</li>; </ul>; <h2>Pull requests merged</h2>; <p>A total of 10 pull requests were merged for this release.</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22489"">#22489</a>: TST, MAINT: Replace most setup with setup_method (also teardown)</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22490"">#22490</a>: MAINT, CI: Switch to cygwin/cygwin-install-action@v2</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22494"">#22494</a>: TST: Make test_partial_iteration_cleanup robust but require leak...</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22592"">#22592</a>: MAINT: Ensure graceful handling of large header sizes</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22593"">#22593</a>: TYP: Spelling alignment for array flag literal</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22594"">#22594</a>: BUG: Fix bounds checking for <code>random.logseries</code></li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22595"">#22595</a>: DEV: Update GH actions and Dockerfile for Gitpod</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22596"">#22596</a>: CI: Only fetch in actions/checkout</li>; <li><a href=""https:/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12515:1187,depend,dependabot,1187,https://hail.is,https://github.com/hail-is/hail/pull/12515,1,['depend'],['dependabot']
Integrability," remote-tracking branch 'upstream/main' into connect-with-mac</li>; <li><a href=""https://github.com/docker/docker-py/commit/58aa62bb154a2ccea433cf475aefbd695fb5abc8""><code>58aa62b</code></a> swarm: add sysctl support for services (<a href=""https://github-redirect.dependabot.com/docker/docker-py/issues/3029"">#3029</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/docker/docker-py/compare/5.0.3...6.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=docker&package-manager=pip&previous-version=5.0.3&new-version=6.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12475:7673,depend,dependabot-automerge-start,7673,https://hail.is,https://github.com/hail-is/hail/pull/12475,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability," request from GHSA-px8h-6qxv-m22q</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/8c2b4b82d0cade0d37e6a88e2cd2413878e8ebd4""><code>8c2b4b8</code></a> don't strip leading = when parsing cookie</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/7c7ce5cb73f3f7d3b9c09340e4f322aeb583dbc5""><code>7c7ce5c</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/pallets/werkzeug/issues/2585"">#2585</a>)</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/19ae03e6a39b3f63fd08fef4fddae4385cdddf25""><code>19ae03e</code></a> [pre-commit.ci] auto fixes from pre-commit.com hooks</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/a83d3b8bf070810874c8e8d03dcce270666e10fe""><code>a83d3b8</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li>Additional commits viewable in <a href=""https://github.com/pallets/werkzeug/compare/2.2.2...2.2.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=werkzeug&package-manager=pip&previous-version=2.2.2&new-version=2.2.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` w",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12703:4922,Depend,Dependabot,4922,https://hail.is,https://github.com/hail-is/hail/pull/12703,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability," requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **556/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.4 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-JINJA2-6150717](https://snyk.io/vuln/SNYK-PYTHON-JINJA2-6150717) | `jinja2:` <br> `3.1.2 -> 3.1.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlOTc1OTMyYy1kNmNhLTQ0NTUtYmU4ZC04NzY1ZGY0MTZjMWMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImU5NzU5MzJjLWQ2Y2EtNDQ1NS1iZThkLTg3NjVkZjQxNmMxYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14141:1889,depend,dependency,1889,https://hail.is,https://github.com/hail-is/hail/pull/14141,2,['depend'],"['dependencies', 'dependency']"
Integrability," requires frozenlist, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **556/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.4 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-JINJA2-6150717](https://snyk.io/vuln/SNYK-PYTHON-JINJA2-6150717) | `jinja2:` <br> `3.1.2 -> 3.1.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlYTQ5ODFkZC02M2FmLTQ4YzYtYTIwMC05NjkyZjg2ZTlhNjIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImVhNDk4MWRkLTYzYWYtNDhjNi1hMjAwLTk2OTJmODZlOWE2MiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14140:1445,depend,dependency,1445,https://hail.is,https://github.com/hail-is/hail/pull/14140,2,['depend'],"['dependencies', 'dependency']"
Integrability," return __original_func(*args_, **kwargs_); /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/expr/expressions/typed_expressions.py:309: in map; array_map = hl.array(self)._ir_lambda_method(transform_ir, f, self._type.element_type, lambda t: self._type.__class__(t)); /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/expr/expressions/base_expression.py:706: in _ir_lambda_method; f(expressions.construct_variable(new_id, input_type, self._indices, self._aggregations))); /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/typecheck/check.py:371: in f; ret = x(*args); /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/experimental/sparse_mt/sparse_split_multi.py:199: in transform_entries; return hl.bind(with_local_a_index, lai); <decorator-gen-746>:2: in bind; ???; /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/typecheck/check.py:584: in wrapper; return __original_func(*args_, **kwargs_); /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/expr/functions.py:537: in bind; lambda_result = to_expr(f(*args)); /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/experimental/sparse_mt/sparse_split_multi.py:190: in with_local_a_index; return hl.bind(with_pl, new_pl); <decorator-gen-746>:2: in bind; ???; /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/typecheck/check.py:584: in wrapper; return __original_func(*args_, **kwargs_); /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/expr/functions.py:537: in bind; lambda_result = to_expr(f(*args)); /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/experimental/sparse_mt/sparse_split_multi.py:156: in with_pl; new_exprs['PGT'] = hl.rbind(; /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/expr/functions.py:588: in rbind; return hl.bind(f, *args, _ctx=_ctx); <decorator-gen-746>:2:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13337:3614,wrap,wrapper,3614,https://hail.is,https://github.com/hail-is/hail/issues/13337,1,['wrap'],['wrapper']
Integrability, scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:9118,Wrap,WrappedArray,9118,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Wrap'],['WrappedArray']
Integrability, scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.colle,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:10086,Wrap,WrappedArray,10086,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Wrap'],['WrappedArray']
Integrability," scans accordingly. Spilling ten local files and then reading them in is probably in the noise of timings. 🎉. ---. ### Implementation Notes. I had to add two new file operations to the `RichHadoopConfiguration` because I need seekable file input streams. I don't like the names. I'm not sure what to do here. Hadoop really screws us with the seek-ability on compressed streams. The implementation is rather simple, it just maintains an array of the per-partition results. The index of the array corresponds to the partition index. The sparsity of that array is controlled by how often we spill. For an operation with a huge number of partitions that are often spilled (e.g. large number of partitions, each with a lot of data), we may want to use a `Map` instead of an `Array`. The use of `ObjectOutputStream` without a try-catch-finally block is non-standard. I was having trouble seeking to individual classes when I used one ObjectOutputStream to output each partition's array. There were these ""bad header"" messages. This seems to work. I don't close the OOS because I'm going to re-use the underlying output stream on the next partition. We use O(n_spills) files. ---. ### Timings. Master 0.2.14-4da055db5a7b; ```; In [1]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(10000, n_partitions=10000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; CPU times: user 1.45 s, sys: 333 ms, total: 1.78 s; Wall time: 24.6 s; In [3]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(1000000, n_partitions=1000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; CPU times: user 6.23 ms, sys: 1.96 ms, total: 8.19 ms; Wall time: 1.33 s; ```; This branch; ```; In [1]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(10000, n_partitions=10000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; CPU times: user 1.4 s, sys: 362 ms, total: 1.76 s; Wall time: 25.6 s. In [2]: %%time ; ...: ; .",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6333:1526,message,messages,1526,https://hail.is,https://github.com/hail-is/hail/pull/6333,1,['message'],['messages']
Integrability," secret generic secretesfile --from-file=prod/env.txt`. The .env for the web app, where localhost would be replaced by our sub.domain. If you get it running, you may notice there isn't a way to log out... I ripped out all of the UI stuff after speaking with Cotton, and began writing a minimal interface. Just clear the cookie if you need to log out. ```; AUTH0_CLIENT_ID=TD78k23CcdM4pMWoYZwYwKJbQPBj06jY; AUTH0_DOMAIN=hail.auth0.com; AUTH0_SCOPE='opened profile repo read:users read:user_idp_tokens'; AUTH0_AUDIENCE='hail'; AUTH0_REDIRECT_URI='https://localhost/auth0callback'; SCORECARD_URL='https://scorecard.localhost/json'; SCORECARD_USER_URL='https://scorecard.localhost/json/users'; GRAPHQL_URL='https://localhost/api/graphql'; ```. The .env for the gateway; ```; AUTH0_WEB_KEY_SET_URL=https://hail.auth0.com/.well-known/jwks.json; AUTH0_AUDIENCE=hail; AUTH0_DOMAIN=https://hail.auth0.com/. AUTH0_MANAGEMENT_API_CLIENT=eqDY6HWOKd6MzC8kWCFaZUAoZgNUHypA; AUTH0_MANAGEMENT_API_SECRET=<I'll give this>; AUTH0_MANAGEMENT_API_TOKEN_URL=https://hail.auth0.com/oauth/token; AUTH0_MANAGEMENT_API_URL=https://hail.auth0.com/api/v2/users; AUTH0_MANAGEMENT_API_AUDIENCE=https://hail.auth0.com/api/v2/; ```. Organization of the web app is simple. There is a pages directory. Routes match the folder structure. Pages that don't need to maintain their own state look a lot like HTML wrapped in a function:. ```js; export default function() { <div>Hello World </div> }; ```. or in JS ES6 form:; ```js; export default () => <div>Hello World</div>; ``` . Performance is excellent. SSR should run about as fast as jinja2 (will be getting faster in 2019). Client side interactions are obviously far more performant. Bundle sizes are on a downward trajectory; react + react-dom is about as big as jQuery today, and reducing that is a focus on facebook in 2019. There are alternatives to react-dom that are under 10kb, but in practice 20kb is nothing to worry about, especially when initial load doesn't require it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931#issuecomment-454271935:3337,Rout,Routes,3337,https://hail.is,https://github.com/hail-is/hail/pull/4931#issuecomment-454271935,3,"['Rout', 'wrap']","['Routes', 'wrapped']"
Integrability," service tests were removed) had to be marked as; failing. Here are the bugs I fixed:. 1. Correct the error message raised when tests are run in a non-main thread (we look for this; message and start an event loop for Hail's async code because asyncio refuses to start an event; loop in a non-main thread). 2. Use a `SafeRow` to copy the globals data out of a Region and into durable, GC'ed objects. 3. Re-enable serialization of GoogleStorageFS (including its private key, which we really shouldn't; do; Tim is working on it), which was broken (presumably) when we changed Scala versions. The; `var` modifier ensures the name is compiled as a JVM field. 4. Correctly convert from a `Byte` to an `Int`. By default `Byte` to `Int` conversion (which is done; automatically when you return a `Byte` from a function whose return type is `Int`) is; sign-preserving. That means that the byte `0000 1111` is converted to the `Int` 15 and the byte; `1000 1111` is converted to the `Int` -113. The contract of; [`InputStream.read`](https://docs.oracle.com/javase/8/docs/api/java/io/InputStream.html#read--); is to return the unsigned integeral value of the next `Byte` or `-1` if we've reached the end of; the stream. `DataInputStream` treats any negative value as EOS which lead to perplexing EOSes; when reading data from GCS. 5. Retain the `gs://` protocol when reading MTs and Ts. `uriPath` strips *all* protocols. Before the; Query Service, these code paths were only used by the LocalBackend. In the LocalBackend, the only; URIs generated are `file://`. However, UNIX/JVM file system operations do not support URIs, they; want bare paths. 6. Implement missing cases for EShuffle and PShuffle. 7. BLAS and LAPACK need to be thread-local. 8. The LSM-tree used by the Shuffler needs to permit multiple values for the same key. There was; some subtlety here around fine-grained locking. Unfortunately, the LSM doesn't expose the right; operations (putIfAbsent) to make this easy, so I had to use a concurren",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10390:2588,contract,contract,2588,https://hail.is,https://github.com/hail-is/hail/pull/10390,1,['contract'],['contract']
Integrability," set request method and body</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/82e70cae2a8d48b4f5165a9b543d4e65bb793d88""><code>82e70ca</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/86a15f1c16eb729dc71b6caf30237d07b8e0bb01""><code>86a15f1</code></a> Fix compiler warnings and deprecations</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/86363072c8239330b28976109a622bdd073507b6""><code>8636307</code></a> Negative timeouts are actually not allowed</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/4ff0ff0e63e0dd45f231990d0dcebffde6e6b709""><code>4ff0ff0</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a1858b494b5f3a51ccef7580c243c6dfdf520731""><code>a1858b4</code></a> Merge pull request <a href=""https://redirect.github.com/michel-kraemer/gradle-download-task/issues/295"">#295</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/c1e212c0fb41b3ea9185a9ea463fb1ea7142f748""><code>c1e212c</code></a> Add integration tests for Gradle 8.0 and 8.0.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/304f68e25f53633a92a4d2d6ce003a4986929503""><code>304f68e</code></a> Fix type inference issue</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/5.3.1...5.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=5.3.1&new-version=5.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as lo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12893:2213,depend,dependabot,2213,https://hail.is,https://github.com/hail-is/hail/pull/12893,1,['depend'],['dependabot']
Integrability," setting title and help message <a href=""https://redirect.github.com/jupyter-lsp/jupyterlab-lsp/issues/999"">#999</a> and <a href=""https://redirect.github.com/jupyter-lsp/jupyterlab-lsp/issues/1010"">#1010</a></li>; </ul>; </li>; <li>maintenance:; <ul>; <li>fix bootstrap script <a href=""https://redirect.github.com/jupyter-lsp/jupyterlab-lsp/issues/1021"">#1021</a></li>; <li>bump axios from 1.2.1 to 1.6.2 <a href=""https://redirect.github.com/jupyter-lsp/jupyterlab-lsp/issues/1019"">#1019</a></li>; <li>bump <code>@​babel/traverse</code> from 7.22.5 to 7.23.4 <a href=""https://redirect.github.com/jupyter-lsp/jupyterlab-lsp/issues/1020"">#1020</a></li>; </ul>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/jupyter-lsp/jupyterlab-lsp/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jupyter-lsp&package-manager=pip&previous-version=2.2.1&new-version=2.2.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` w",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14171:3459,depend,dependency-name,3459,https://hail.is,https://github.com/hail-is/hail/pull/14171,1,['depend'],['dependency-name']
Integrability," severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Use of a Broken or Risky Cryptographic Algorithm <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6149518](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6149518) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Uncontrolled Resource Consumption (&#x27;Resource Exhaustion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6157248](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6157248) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxZDhjNDI0MS1hOTllLTQwZDktOTM5Yy0zZWMzM2NkNTI0ZjkiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjFkOGM0MjQxLWE5OWUtNDBkOS05MzljLTNlYzMzY2Q1MjRmOSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14230:2055,depend,dependency,2055,https://hail.is,https://github.com/hail-is/hail/pull/14230,2,['depend'],"['dependencies', 'dependency']"
Integrability," six==1.16.0; Using cached six-1.16.0-py2.py3-none-any.whl (11 kB); Collecting sortedcontainers==2.4.0; Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB); Collecting tabulate==0.9.0; Using cached tabulate-0.9.0-py3-none-any.whl (35 kB); Collecting tenacity==8.2.3; Using cached tenacity-8.2.3-py3-none-any.whl (24 kB); Collecting tornado==6.3.3; Using cached tornado-6.3.3-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB); Collecting typer==0.9.0; Using cached typer-0.9.0-py3-none-any.whl (45 kB); Collecting typing-extensions==4.7.1; Using cached typing_extensions-4.7.1-py3-none-any.whl (33 kB); Collecting tzdata==2023.3; Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB); Collecting urllib3==1.26.16; Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB); Collecting uvloop==0.17.0; Using cached uvloop-0.17.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB); Collecting wrapt==1.15.0; Using cached wrapt-1.15.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB); Collecting xyzservices==2023.7.0; Using cached xyzservices-2023.7.0-py3-none-any.whl (56 kB); Collecting yarl==1.9.2; Using cached yarl-1.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (269 kB); Building wheels for collected packages: avro; Building wheel for avro (pyproject.toml): started; Building wheel for avro (pyproject.toml): finished with status 'done'; Created wheel for avro: filename=avro-1.11.2-py2.py3-none-any.whl size=119738 sha256=d7f238f86de270b449b018590930a06270766887328bdb51066eccff2cd696a6; Stored in directory: /home/hadoop/.cache/pip/wheels/e3/a2/1e/5c1be0865f4170a89de34e0a798f32f674a7eaf63a93272c7f; Successfully built avro; Installing collected packages: sortedcontainers, pytz, py4j, commonmark, azure-common, xyzservices, wrapt, uvloop, urllib3, tzdata, typing-extensions, tornado, tenacity, tabulate, six, regex, pyyaml, python-json-",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:40869,wrap,wrapt-,40869,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221,1,['wrap'],['wrapt-']
Integrability," skip_bad_ad); 377 pargs.append('--store-gq'); 378 ; --> 379 return self.run_command(None, pargs); 380 ; 381 def index_bgen(self, path):. /Users/tpoterba/hail/python/pyhail/context.pyc in run_command(self, vds, pargs); 43 jstate = self._jstate(vds.jvds if vds != None else None); 44 result = cmd.run(jstate,; ---> 45 cmd_args); 46 return VariantDataset(self, result.vds()); 47 . /Users/tpoterba/spark-1.6.2-bin-hadoop2.6/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py in __call__(self, *args); 811 answer = self.gateway_client.send_command(command); 812 return_value = get_return_value(; --> 813 answer, self.gateway_client, self.target_id, self.name); 814 ; 815 for temp_arg in temp_args:. /Users/tpoterba/spark-1.6.2-bin-hadoop2.6/python/pyspark/sql/utils.pyc in deco(*a, **kw); 43 def deco(*a, **kw):; 44 try:; ---> 45 return f(*a, **kw); 46 except py4j.protocol.Py4JJavaError as e:; 47 s = e.java_exception.toString(). /Users/tpoterba/spark-1.6.2-bin-hadoop2.6/python/lib/py4j-0.9-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 306 raise Py4JJavaError(; 307 ""An error occurred while calling {0}{1}{2}.\n"".; --> 308 format(target_id, ""."", name), value); 309 else:; 310 raise Py4JError(. Py4JJavaError: An error occurred while calling o92.run.; : org.broadinstitute.hail.utils.package$FatalException: arguments refer to no files; 	at org.broadinstitute.hail.utils.package$.fatal(package.scala:27); 	at org.broadinstitute.hail.driver.VCFImporter$class.globAllVcfs(ImportVCF.scala:17); 	at org.broadinstitute.hail.driver.ImportVCF$.globAllVcfs(ImportVCF.scala:33); 	at org.broadinstitute.hail.driver.ImportVCF$.run(ImportVCF.scala:83); 	at org.broadinstitute.hail.driver.ImportVCF$.run(ImportVCF.scala:33); 	at org.broadinstitute.hail.driver.Command.runCommand(Command.scala:258); 	at org.broadinstitute.hail.driver.Command.run(Command.scala:263); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1096:1383,protocol,protocol,1383,https://hail.is,https://github.com/hail-is/hail/issues/1096,1,['protocol'],['protocol']
Integrability," speaking to servers with certs they didn't trust. Now everyone trusts everyone. As long as the root key is not leaked this is OK. Only `create_certs` mounts this secret. The key is used to sign every certificate and the cert is included in each principal's incoming and outgoing trust lists. The root certificate and key are never re-created, so our deploys have no downtime and we avoid addressing the rotation problem. I removed all the trust specifications. A later PR will resolve rotation and mTLS. That PR will restore the trust specifications. I didn't change the structure of the secrets (they still have an incoming and outgoing trust list which only contains the root cert) because I need this structure for mTLS anyway. The original PR text follows. ---. ## HTTPS and TLS. HTTP is implemented on TCP/IP. HTTPS is also implemented on TCP/IP and differs; very mildly. After the socket is opened, a TLS [1] connection is established; over the socket. Thereafter, every HTTP message is encrypted and transported by; the TLS machinery. The HTTP protocol is unchanged. The default port fort HTTP is; 80 and the default port for HTTPS 443, however any port may be used. There are currently four versions of TLS, the latest is TLS 1.3. All versions of; SSL are considered insecure. The OpenSSL library implements TLS. There are other implementations, such as; LibreSSL, but they implement roughly the same interface as OpenSSL. The TLS protocol defines both a scheme for the *encryption of messages* and for; the *authentication of parties*. The protocol defines authentication as; optional. In practice, at least one party presents authentication. For example,; public web servers authenticate themselves to clients but clients do not; reciprocate. ### Authentication; #### X.509 Certificates. TLS uses X.509 Certificates for authentication. X.509 is a rather complicated; standard. X.509 Certificates can be serialized in a variety of ways. We use the; Privacy-enhanced Electronic Mail (PEM) fil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:1532,message,message,1532,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['message'],['message']
Integrability," special accounting for pypy when computing the stack level for text encod...</li>; <li><a href=""https://github.com/jaraco/zipp/commit/2ec3ed8567d0842675c38fd8ef0a28db668e602d""><code>2ec3ed8</code></a> Add another test at another magnitude.</li>; <li><a href=""https://github.com/jaraco/zipp/commit/d9bf5aab8b39c6a124d9499ae0315d3bf2ac2f46""><code>d9bf5aa</code></a> Fix name generator for width=1</li>; <li>Additional commits viewable in <a href=""https://github.com/jaraco/zipp/compare/v3.17.0...v3.18.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=zipp&package-manager=pip&previous-version=3.17.0&new-version=3.18.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major versio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14473:3317,depend,dependabot,3317,https://hail.is,https://github.com/hail-is/hail/pull/14473,1,['depend'],['dependabot']
Integrability," static part weighting, so that simpler routes are matched; before more complex ones. :issue:<code>2471</code></li>; <li>Restore <code>ValidationError</code> to be importable from; <code>werkzeug.routing</code>. :issue:<code>2465</code></li>; </ul>; <h2>Version 2.2.0</h2>; <p>Released 2022-07-23</p>; <ul>; <li>Deprecated <code>get_script_name</code>, <code>get_query_string</code>,; <code>peek_path_info</code>, <code>pop_path_info</code>, and; <code>extract_path_info</code>. :pr:<code>2461</code></li>; <li>Remove previously deprecated code. :pr:<code>2461</code></li>; <li>Add MarkupSafe as a dependency and use it to escape values when; rendering HTML. :issue:<code>2419</code></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/werkzeug/commit/15fcb87d36f4ed45b127692d2d739266b918503c""><code>15fcb87</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/werkzeug/issues/2499"">#2499</a> from pallets/release-2.2.2</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/87b082a02373aa2feba5750f5768efd6013f701d""><code>87b082a</code></a> release version 2.2.2</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/110b4cdbc1c86125065e56c8d64d0c560883b42b""><code>110b4cd</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/werkzeug/issues/2498"">#2498</a> from pallets/socket-warning</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/b484e5497d12a11766544d79d320d5953d3a753d""><code>b484e54</code></a> handle unclosed socket resource warning</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/bebf46d336782e70510f00e3a08db1e1453ce68a""><code>bebf46d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/werkzeug/issues/2497"">#2497</a> from pallets/local-wrapped</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/82d3fba4e7955e0",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12119:4693,depend,dependabot,4693,https://hail.is,https://github.com/hail-is/hail/pull/12119,1,['depend'],['dependabot']
Integrability," still isn't quite right?. I also saw some issues with sockets timing out but I don't know what to make of those yet.; ```; _______________________________ test_union_rows1 _______________________________. @test_timeout(local=3 * 60); def test_union_rows1():; vds = hl.vds.read_vds(os.path.join(resource('vds'), '1kg_chr22_5_samples.vds')); ; vds1 = hl.vds.filter_intervals(vds,; [hl.parse_locus_interval('chr22:start-10754094', reference_genome='GRCh38')],; split_reference_blocks=True); vds2 = hl.vds.filter_intervals(vds,; [hl.parse_locus_interval('chr22:10754094-end', reference_genome='GRCh38')],; split_reference_blocks=True); ; ; vds_union = vds1.union_rows(vds2); > assert hl.vds.to_dense_mt(vds)._same(hl.vds.to_dense_mt(vds_union)). test/hail/vds/test_vds.py:597: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; <decorator-gen-1386>:2: in _same; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/matrixtable.py:3762: in _same; return self._localize_entries(entries_name, cols_name)._same(; <decorator-gen-1276>:2: in _same; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/table.py:3658: in _same; mismatched_globals, mismatched_rows = t.aggregate(hl.tuple((; <decorator-gen-1216>:2: in aggregate; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/table.py:1285: in aggregate; return Env.backend().execute(hl.ir.MakeTuple([agg_ir]))[0]; /usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py:86: in execute; raise e.maybe_user_error(ir) from None; /usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py:76: in execute; result_tuple = self._jbackend.executeEncod",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:999,wrap,wrapper,999,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198,1,['wrap'],['wrapper']
Integrability," stream-style serialization (<a href=""https://redirect.github.com/Azure/azure-sdk-for-java/issues/36461"">#36461</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/910c88d6e85ba55d62062bf502055dfefa109530""><code>910c88d</code></a> mgmt compute, support convenience API listVmByVmss (<a href=""https://redirect.github.com/Azure/azure-sdk-for-java/issues/36631"">#36631</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-java/compare/azure-core-http-netty_1.13.3...azure-core-http-netty_1.13.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.azure:azure-core-http-netty&package-manager=gradle&previous-version=1.13.3&new-version=1.13.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ign",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13597:3900,Depend,Dependabot,3900,https://hail.is,https://github.com/hail-is/hail/pull/13597,1,['Depend'],['Dependabot']
Integrability," string interpolations with f-strings by <a href=""https://github.com/akx""><code>@​akx</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/744"">jpadilla/pyjwt#744</a></li>; <li>Update CHANGELOG.rst by <a href=""https://github.com/hipertracker""><code>@​hipertracker</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/751"">jpadilla/pyjwt#751</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/hugovk""><code>@​hugovk</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/699"">jpadilla/pyjwt#699</a></li>; <li><a href=""https://github.com/rekyungmin""><code>@​rekyungmin</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/705"">jpadilla/pyjwt#705</a></li>; <li><a href=""https://github.com/sseering""><code>@​sseering</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/661"">jpadilla/pyjwt#661</a></li>; <li><a href=""https://github.com/estin""><code>@​estin</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/713"">jpadilla/pyjwt#713</a></li>; <li><a href=""https://github.com/woodruffw""><code>@​woodruffw</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/725"">jpadilla/pyjwt#725</a></li>; <li><a href=""https://github.com/guneybilen""><code>@​guneybilen</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/727"">jpadilla/pyjwt#727</a></li>; <li><a href=""https://github.com/dmahr1""><code>@​dmahr1</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/734"">jpadilla/pyjwt#734</a></li>; <li><a href=""https://github.com/israelabraham""><code>@​israelabraham</code></a> made their first contribution in <a href=",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11866:6252,depend,dependabot,6252,https://hail.is,https://github.com/hail-is/hail/pull/11866,1,['depend'],['dependabot']
Integrability, sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at sparklyr.Invoke.invoke(invoke.scala:139); 	at sparklyr.StreamHandler.handleMethodCall(stream.scala:123); 	at sparklyr.StreamHandler.read(stream.scala:66); 	at sparklyr.BackendHandler.channelRead0(handler.scala:51); 	at sparklyr.BackendHandler.channelRead0(handler.scala:4); 	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105); 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357); 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343); 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336); 	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102); 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357); 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343); 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336); 	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:293); 	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:267); 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:357); 	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:343); 	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:336); 	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294); 	at io.netty.channel.Abs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:4765,Message,MessageToMessageDecoder,4765,https://hail.is,https://github.com/hail-is/hail/issues/4513,2,['Message'],['MessageToMessageDecoder']
Integrability," system roots implementation. (<a href=""https://github-redirect.dependabot.com/grpc/grpc/pull/29436"">#29436</a>)</li>; <li>xDS: Workaround to get gRPC clients working with istio. (<a href=""https://github-redirect.dependabot.com/grpc/grpc/pull/29841"">#29841</a>)</li>; </ul>; <h2>Python</h2>; <ul>; <li>Set Correct Platform Tag in Wheels on Mac OS with Python 3.10. (<a href=""https://github-redirect.dependabot.com/grpc/grpc/pull/29857"">#29857</a>)</li>; <li>[Aio] Ensure Core channel closes when deallocated. (<a href=""https://github-redirect.dependabot.com/grpc/grpc/pull/29797"">#29797</a>)</li>; <li>[Aio] Fix the wait_for_termination return value. (<a href=""https://github-redirect.dependabot.com/grpc/grpc/pull/29795"">#29795</a>)</li>; </ul>; <h2>Ruby</h2>; <ul>; <li>Make the gem build on TruffleRuby. (<a href=""https://github-redirect.dependabot.com/grpc/grpc/pull/27660"">#27660</a>)</li>; <li>Support for prebuilt Ruby binary on x64-mingw-ucrt platform. (<a href=""https://github-redirect.dependabot.com/grpc/grpc/pull/29684"">#29684</a>)</li>; <li>[Ruby] Add ruby_abi_version to exported symbols. (<a href=""https://github-redirect.dependabot.com/grpc/grpc/pull/28976"">#28976</a>)</li>; </ul>; <h2>Objective-C</h2>; <p>First developer preview of XCFramework binary distribution via Cocoapod (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/28749"">#28749</a>).</p>; <p>This brings in significant speed up to local compile time and includes support for Apple Silicon build.</p>; <ul>; <li>The following binary pods are made available for ObjC V1 &amp; V2 API</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/grpc/grpc/commit/d52ed193d11dee797c0d51dc8db06032998b33f4""><code>d52ed19</code></a> Bump version to v1.48.1 (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30782"">#30782</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/2c7ba6",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12201:2535,depend,dependabot,2535,https://hail.is,https://github.com/hail-is/hail/pull/12201,1,['depend'],['dependabot']
Integrability," tasks</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/34e2dd41477f18b1ae3d6d5a71dca5449d6cd1e0""><code>34e2dd4</code></a> Downgrade slf4j to fix warning on console about missing slf4j provider</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/b3fa29f9ffb4d4544e13ef84601e371fb2778ddf""><code>b3fa29f</code></a> Revert &quot;Update Apache HttpClient to 5.2.1&quot;</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/01f05e046be0dca18f506723c79e88f208336e71""><code>01f05e0</code></a> Add integration tests for Gradle 6.9.3 and 7.6</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a998a544908a8b39f713f4526f717fcb328c06eb""><code>a998a54</code></a> Upgrade Gradle to 7.6</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/5.3.0...5.3.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=5.3.0&new-version=5.3.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12707:3273,Depend,Dependabot,3273,https://hail.is,https://github.com/hail-is/hail/pull/12707,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability," test</li>; <li><a href=""https://github.com/Textualize/rich/commit/f6eca21a9b3910456c5be7efee5c7f22c79d1873""><code>f6eca21</code></a> fix markdown on light</li>; <li><a href=""https://github.com/Textualize/rich/commit/a972ca05522577de2f98eb7c957deead9c87b38f""><code>a972ca0</code></a> changelog</li>; <li><a href=""https://github.com/Textualize/rich/commit/bef0e50b63cf7294ae6c27bf8a79cbe3592599a0""><code>bef0e50</code></a> Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3130"">#3130</a> from Textualize/fix-table-inline-styles</li>; <li><a href=""https://github.com/Textualize/rich/commit/e30b822ecc264c5c4f984a023124d31d8052de49""><code>e30b822</code></a> Fix markdown table rendering issue.</li>; <li>Additional commits viewable in <a href=""https://github.com/Textualize/rich/compare/v12.6.0...v13.5.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=rich&package-manager=pip&previous-version=12.6.0&new-version=13.5.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` wil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13651:7015,depend,dependency-name,7015,https://hail.is,https://github.com/hail-is/hail/pull/13651,2,['depend'],['dependency-name']
Integrability," tests for Gradle 8.0 and 8.0.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/304f68e25f53633a92a4d2d6ce003a4986929503""><code>304f68e</code></a> Fix type inference issue</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/5.3.1...5.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=5.3.1&new-version=5.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12893:3399,Depend,Dependabot,3399,https://hail.is,https://github.com/hail-is/hail/pull/12893,1,['Depend'],['Dependabot']
Integrability," that change, it features the following user-facing changes:</p>; <ul>; <li>Added a prober for Johab Korean (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/207"">#207</a>, <a href=""https://github.com/grizlupo""><code>@​grizlupo</code></a>)</li>; <li>Added a prober for UTF-16/32 BE/LE (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/109"">#109</a>, <a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/206"">#206</a>, <a href=""https://github.com/jpz""><code>@​jpz</code></a>)</li>; <li>Added test data for Croatian, Czech, Hungarian, Polish, Slovak, Slovene, Greek, and Turkish, which should help prevent future errors with those languages</li>; <li>Improved XML tag filtering, which should improve accuracy for XML files (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/208"">#208</a>)</li>; <li>Tweaked <code>SingleByteCharSetProber</code> confidence to match latest uchardet (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/209"">#209</a>)</li>; <li>Made <code>detect_all</code> return child prober confidences (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/210"">#210</a>)</li>; <li>Updated examples in docs (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/223"">#223</a>, <a href=""https://github.com/domdfcoding""><code>@​domdfcoding</code></a>)</li>; <li>Documentation fixes (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/212"">#212</a>, <a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/224"">#224</a>, <a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/225"">#225</a>, <a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/226"">#226</a>, <a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/220"">#220</a>, <a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/221"">#221</a>, <a href=""https://github-redirect.dependabot.com/chard",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12107:1376,depend,dependabot,1376,https://hail.is,https://github.com/hail-is/hail/pull/12107,1,['depend'],['dependabot']
Integrability," the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""domain"": ""global"",; ""reason"": ""forbidden""; }; ]; }; }. 		at com.google.api.client.http.HttpResponseException$Builder.build(HttpResponseException.java:293) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1118) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1022) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		... 48 more; Caused by: com.google.api.client.http.HttpResponseException: 403 Forbidden; POST https://storage.googleapis.com/upload/storage/v1/b/neale-bge/o?name=foo.ht/index/part-0-c7ba7549-bf68-42db-a8ef-0f1b13721c79.idx/index&uploadType=resumable; {; ""error"": {; ""code"": 403,; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""errors"": [; {; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""domain"": ""global"",; ""reason"": ""forbidden""; }; ]; }; }. 	at com.google.api.client.http.HttpResponseException$Builder.build(HttpResponseException.java:293) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1118) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpStorageRpc.java:1022) ~[gs:__hail-que",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:27294,message,message,27294,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['message'],['message']
Integrability," the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI5NmE4NGVhMS1hYzgxLTQxYmEtOGYzNC02MGU1ZTdhYzNjZTMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6Ijk2YTg0ZWExLWFjODEtNDFiYS04ZjM0LTYwZTVlN2FjM2NlMyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""96a84ea1-ac81-41ba-8f34-60e5e7ac3ce3"",""prPublicId"":""96a84ea1-ac81-41ba-8f34-60e5e7ac3ce3"",""dependencies"":[{""name"":""setuptools"",""from"":""39.0.1"",""to"":""65.5.1""}],""packageManager"":""pip"",""projectPublicId"":""20159ae6-a5aa-42fa-845a-c89f5bcbf999"",""projectUrl"":""https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-SETUPTOOLS-3180412""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[509],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [Regular Expression Denial of Service (ReDoS)](https://learn.snyk.io/lessons/redos/javascript/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12896:2739,depend,dependencies,2739,https://hail.is,https://github.com/hail-is/hail/pull/12896,1,['depend'],['dependencies']
Integrability," the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version: devel-5b299ddae758. ### What you did:. ```; conc.describe(); ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'locus': locus<GRCh37> ; 'alleles': array<str> ; 'a_index': int32 ; 'was_split': bool ; 'concordance': array<struct {; concordance_matrix: struct {; n_discordant: int64, ; concordance: array<array<int64>>; }, ; meta: dict<str, str>; }> ; 'metrics': array<struct {; score: float64, ; positive_train: bool, ; negative_train: bool, ; rank: int64, ; meta: dict<str, str>; }> ; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------. conc.aggregate(hl.agg.count_where(hl.sum(conc.concordance[0].concordance_matrix.concordance[:2].map(lambda x: hl.sum(x[:2])))>0)). ```. ### What went wrong (all error messages here, including the full java stack trace):. ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-143-c80e74dd23d2> in <module>(); ----> 1 conc.aggregate(hl.agg.count_where(hl.sum(conc.concordance[0].concordance_matrix.concordance[:2].map(lambda x: hl.sum(x[:2])))>0)). /home/hail/hail.zip/hail/table.py in aggregate(self, expr); 1107 analyze('Table.aggregate', expr, self._global_indices, {self._row_axis}); 1108 ; -> 1109 result_json = base._jt.aggregateJSON(expr._ast.to_hql()); 1110 return expr.dtype._from_json(result_json); 1111 . /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 194 raise FatalE",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3729:1084,message,messages,1084,https://hail.is,https://github.com/hail-is/hail/issues/3729,1,['message'],['messages']
Integrability," the position of messages for class and function defintions to no longer cover; the complete definition. Only the <code>def</code> or <code>class</code> + the name of the class/function; are covered.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5466"">#5466</a></p>; </li>; <li>; <p><code>using-f-string-in-unsupported-version</code> and <code>using-final-decorator-in-unsupported-version</code> msgids; were renamed from <code>W1601</code> and <code>W1602</code> to <code>W2601</code> and <code>W2602</code>. Disabling using these msgids will break.; This is done in order to restore consistency with the already existing msgids for <code>apply-builtin</code> and; <code>basestring-builtin</code> from the now deleted python 3K+ checker. There is now a check that we're not using; existing msgids or symbols from deleted checkers.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5729"">#5729</a></p>; </li>; <li>; <p>The line numbering for messages related to function arguments is now more accurate. This can; require some message disables to be relocated to updated positions.</p>; </li>; <li>; <p>Add <code>--recursive</code> option to allow recursive discovery of all modules and packages in subtree. Running pylint with; <code>--recursive=y</code> option will check all discovered <code>.py</code> files and packages found inside subtree of directory provided; as parameter to pylint.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/352"">#352</a></p>; </li>; <li>; <p>Add <code>modified-iterating-list</code>, <code>modified-iterating-dict</code> and <code>modified-iterating-set</code>,; emitted when items are added to or removed from respectively a list, dictionary or; set being iterated through.</p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/pylint/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11674:2468,message,messages,2468,https://hail.is,https://github.com/hail-is/hail/pull/11674,1,['message'],['messages']
Integrability," the warnings plugin (<a href=""https://redirect.github.com/psf/requests/issues/6416"">#6416</a>)</li>; <li><a href=""https://github.com/psf/requests/commit/a7da1ab3498b10ec3a3582244c94b2845f8a8e71""><code>a7da1ab</code></a> try on ubuntu 22.04 (<a href=""https://redirect.github.com/psf/requests/issues/6418"">#6418</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/psf/requests/compare/v2.28.2...v2.31.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=requests&package-manager=pip&previous-version=2.28.2&new-version=2.31.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13091:7809,depend,dependabot-automerge-start,7809,https://hail.is,https://github.com/hail-is/hail/pull/13091,12,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability," time</li>; <li>Additional commits viewable in <a href=""https://github.com/cbeust/testng/compare/testng-6.8.21...7.7.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.testng:testng&package-manager=gradle&previous-version=6.8.21&new-version=7.7.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:17255,Depend,Dependabot,17255,https://hail.is,https://github.com/hail-is/hail/pull/12665,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability," to 1.0.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/668"">#668</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/3bc517092aff39330f2f96315e6f542e23415831""><code>3bc5170</code></a> Bump multidict from 5.2.0 to 6.0.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/670"">#670</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp_session/compare/v2.7.0...v2.11.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp-session&package-manager=pip&previous-version=2.7.0&new-version=2.11.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11544:4898,depend,dependabot,4898,https://hail.is,https://github.com/hail-is/hail/pull/11544,1,['depend'],['dependabot']
Integrability," to 2.9.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5273"">#5273</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/c688451ce31b914c71b11d2ac6c326b0c87e6d1f""><code>c688451</code></a> Removed duplicate timeout parameter in ClientSession reference docs. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5262"">#5262</a>) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10115:9422,depend,dependabot,9422,https://hail.is,https://github.com/hail-is/hail/pull/10115,1,['depend'],['dependabot']
Integrability," to 3 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/154"">tox-dev/py-filelock#154</a></li>; <li>Bump actions/download-artifact from 2 to 3 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/152"">tox-dev/py-filelock#152</a></li>; <li>Bump pre-commit/action from 2.0.3 to 3.0.0 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/151"">tox-dev/py-filelock#151</a></li>; <li>Bump actions/checkout from 2 to 3 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/153"">tox-dev/py-filelock#153</a></li>; <li>Bump actions/setup-python from 2 to 4 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/150"">tox-dev/py-filelock#150</a></li>; <li>Add timeout unit to docstrings by <a href=""https://github.com/jnordberg""><code>@​jnordberg</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/148"">tox-dev/py-filelock#148</a></li>; <li>Unify badges style by <a href=""https://github.com/DeadNews""><code>@​DeadNews</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/155"">tox-dev/py-filelock#155</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/156"">tox-dev/py-filelock#156</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/157"">tox-dev/py-fil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12157:1536,depend,dependabot,1536,https://hail.is,https://github.com/hail-is/hail/pull/12157,2,['depend'],['dependabot']
Integrability," to 3.0.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/python-logging/releases"">google-cloud-logging's releases</a>.</em></p>; <blockquote>; <h2>v3.0.0</h2>; <h2><a href=""https://github.com/googleapis/python-logging/compare/v2.7.0...v3.0.0"">3.0.0</a> (2022-01-27)</h2>; <h3>⚠ BREAKING CHANGES</h3>; <ul>; <li>make logging API more friendly to use (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/422"">#422</a>)</li>; <li>api consistency between HTTP and Gapic layers (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/375"">#375</a>)</li>; <li>support string-encoded json (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/339"">#339</a>)</li>; <li>Infer default resource in logger (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/315"">#315</a>)</li>; <li>support json logs (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/316"">#316</a>)</li>; <li>deprecate AppEngineHandler and ContainerEngineHandler (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/310"">#310</a>)</li>; </ul>; <h3>Features</h3>; <ul>; <li>add api key support (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/472"">#472</a>) (<a href=""https://github.com/googleapis/python-logging/commit/81ca8c616acb988be1fbecfc2a0b1a5b39280149"">81ca8c6</a>)</li>; <li>add json_fields extras argument for adding to jsonPayload (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/447"">#447</a>) (<a href=""https://github.com/googleapis/python-logging/commit/a760e02371a55d6262e42de9e0222fffa2c7192b"">a760e02</a>)</li>; <li>avoid importing grpc when explicitly disabled (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/416"">#416</a>) (<a href=""https://github.com/googleapis/python-logging/commit/818213e14",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11574:1081,depend,dependabot,1081,https://hail.is,https://github.com/hail-is/hail/pull/11574,1,['depend'],['dependabot']
Integrability," to 41.0.4 (<a href=""https://redirect.github.com/urllib3/urllib3/issues/3131"">#3131</a>)</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/d9f85a749488188c286cd50606d159874db94d5f""><code>d9f85a7</code></a> Release 2.0.5</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/d41f4122966f7f4f5f92001ad518e5d9dafcc886""><code>d41f412</code></a> Undeprecate pyOpenSSL module (<a href=""https://redirect.github.com/urllib3/urllib3/issues/3127"">#3127</a>)</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/b6c04cb3e62ef5a0e4947d037c12fb3ca79e024a""><code>b6c04cb</code></a> Fix a link to &quot;absolute URI&quot; definition (<a href=""https://redirect.github.com/urllib3/urllib3/issues/3128"">#3128</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/urllib3/urllib3/compare/1.26.17...2.0.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.17&new-version=2.0.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` w",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13852:14133,depend,dependency-name,14133,https://hail.is,https://github.com/hail-is/hail/pull/13852,1,['depend'],['dependency-name']
Integrability," to <code>1.34.0</code>.</li>; <li>Updated <code>azure-core-http-netty</code> to <code>1.12.7</code>.</li>; </ul>; <h2>azure-communication-chat_1.3.3</h2>; <h2>1.3.3 (2022-11-10)</h2>; <h3>Other Changes</h3>; <h4>Dependency Updates</h4>; <ul>; <li>Upgraded <code>azure-communication-common</code> to 1.2.3</li>; <li>Upgraded <code>azure-core</code> to 1.34.0</li>; </ul>; <h2>azure-data-schemaregistry_1.3.1</h2>; <h2>1.3.1 (2022-11-16)</h2>; <h3>Other Changes</h3>; <h4>Dependency Updates</h4>; <ul>; <li>Update <code>azure-core</code> dependency to <code>1.34.0</code>.</li>; <li>Update <code>azure-core-http-netty</code> dependency to <code>1.12.7</code>.</li>; </ul>; <h2>azure-sdk-bom_1.2.8</h2>; <p>No release notes provided.</p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/89123194fe6a4a2f2cdc58535abea9d75d753a79""><code>8912319</code></a> Identity 1.7.1 patch (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32140"">#32140</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/fe0a0dad4771fb7c6105cc412cf9cc8d10722e59""><code>fe0a0da</code></a> Updated versions after patch release. (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32231"">#32231</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/4fc24620f120643d18f85aca1bf3ee53daf7f124""><code>4fc2462</code></a> Increment versions for eventgrid releases (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32230"">#32230</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/de48207d7f57407cebfa549c843135dadeeab15c""><code>de48207</code></a> Nikoudsi/batch data plane sdk release for 2022 10 01 API Change (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32162"">#32162</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/11f08f973490521",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12508:1588,depend,dependabot,1588,https://hail.is,https://github.com/hail-is/hail/pull/12508,1,['depend'],['dependabot']
Integrability," to CSS template files</li>; <li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v3.5.4...v5.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx&package-manager=pip&previous-version=3.5.4&new-version=5.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11925:6950,Depend,Dependabot,6950,https://hail.is,https://github.com/hail-is/hail/pull/11925,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability," to a fixed version:; - hail/python/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiNzM2NzI0Yi1hY2RiLTRiOTUtYWQwMy1hYWI3MjkyZGNlYzQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImI3MzY3MjRiLWFjZGItNGI5NS1hZDAzLWFhYjcyOTJkY2VjNCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13116:1224,depend,dependency,1224,https://hail.is,https://github.com/hail-is/hail/pull/13116,2,['depend'],"['dependencies', 'dependency']"
Integrability," to a fixed version:; - hail/python/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlNDQxZTBmNS1jZDQ4LTQzZDUtYTdkMy1kMTM4YzQ2ZTc2NTgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImU0NDFlMGY1LWNkNDgtNDNkNS1hN2QzLWQxMzhjNDZlNzY1OCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13158:1316,depend,dependency,1316,https://hail.is,https://github.com/hail-is/hail/pull/13158,2,['depend'],"['dependencies', 'dependency']"
Integrability," to be compliant with RFC7517. `[#624](https://github.com/jpadilla/pyjwt/issues/624) &lt;https://github.com/jpadilla/pyjwt/pull/624&gt;`__; - Allow to verify with private key on ECAlgorithm, as well as on Ed25519Algorithm. `[#645](https://github.com/jpadilla/pyjwt/issues/645) &lt;https://github.com/jpadilla/pyjwt/pull/645&gt;`__; &lt;/tr&gt;&lt;/table&gt; ; </code></pre>; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/98620ab2a396a5c887a494259d49552c2093e1ad""><code>98620ab</code></a> Bump up version to v2.3.0 (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/703"">#703</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/f9db1d7b3acbe81daea7bc79cbc731f7c900221f""><code>f9db1d7</code></a> Revert &quot;Remove arbitrary kwargs. (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/657"">#657</a>)&quot; (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/701"">#701</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/828a20a47ef7af5cddfe12b482a90df07cd1b323""><code>828a20a</code></a> Add exception chaining (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/702"">#702</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/cf545e4bfc087e863b7c7a2a2313d52fe8f107ca""><code>cf545e4</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/700"">#700</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/6223ba13780a941a3f4c9dec62f282bdd9b5afb0""><code>6223ba1</code></a> Bump up version to v2.2.0 (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/697"">#697</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/258d7bab0ecb86be91738ac1e23744429280acd1""><code>258d7ba</code></a> Use timezone package as Python 3.5+ is required (<a href=""https://github-redirect.dependabot.com/jpad",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11457:11529,depend,dependabot,11529,https://hail.is,https://github.com/hail-is/hail/pull/11457,1,['depend'],['dependabot']
Integrability," to latest models</li>; <li><a href=""https://github.com/boto/botocore/commit/7b4b3bbb13a5d59097e6d5f178de58e280fdb553""><code>7b4b3bb</code></a> Resolve endpoint with default partition when no region is set (<a href=""https://github-redirect.dependabot.com/boto/botocore/issues/2818"">#2818</a>)</li>; <li><a href=""https://github.com/boto/botocore/commit/cc3f1c22f55ba50ca792eb73e7a6f721abdcc5ee""><code>cc3f1c2</code></a> Fix: S3 Object Lambda requests miss x-amz-content-sha256 headers (<a href=""https://github-redirect.dependabot.com/boto/botocore/issues/2819"">#2819</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/boto/botocore/compare/1.29.13...1.29.16"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=botocore&package-manager=pip&previous-version=1.29.13&new-version=1.29.16)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12503:3870,depend,dependabot-security-updates,3870,https://hail.is,https://github.com/hail-is/hail/pull/12503,1,['depend'],['dependabot-security-updates']
Integrability," to the public? This is a; classic cryptography problem called [key; exchange](https://en.wikipedia.org/wiki/Key_exchange). The classic solution to; this problem is [Diffie-Hellman key; exchange](https://en.wikipedia.org/wiki/Diffie–Hellman_key_exchange). The; Wikipedia article has ""General overview"" which is quite clear. In addition to a key, the parties must agree on a cipher. There are many old,; insecure ciphers available. In the future I intend all our servers to refuse to; use insecure ciphers. Mozilla; [has a list of secure cipher suites](https://wiki.mozilla.org/Security/Server_Side_TLS#Recommended_configurations). ## New Hail Concepts. Every principal in our system has a secret: `ssl-config-NAME`. These secrets are; automatically created for a particular namespace by `tls/create_certs.py`. Who; trusts who (i.e. who is allowed to talk to whom) is defined by; `tls/config.yaml`. For example, `site` is defined in `config.yaml` as follows:. ```; - name: site; domain: site; kind: nginx; incoming:; - admin-pod; - router; ```. A principal named ""site"" exists. Site's domain names are `site`,; `site.NAMESPACE`, `site.NAMESPACE.svc.cluster.local`. Site's configuration files; should be in NGINX configuration file format. Site accepts incoming requests; from the principals named admin-pod and router. Site is not permitted to make; any outgoing requests. `create_certs.py` will create a new secret named; `ssl-config-site` which contains five files:. - `site-config-http.conf`: an NGINX configuration file that configures TLS for; incoming requests.; - `site-config-proxy.conf`: an NGINX configuration file that configures TLS for; outgoing (proxy_pass) requests.; - `site-key.pem`: a private key.; - `site-cert.pem`: a certificate.; - `site-incoming.pem`: a list of certificates trusted for incoming requests.; - `site-outgoing.pem`: a list of certificates expected from outgoing requests. If site makes an HTTP request to a server and that server does not return a; certificate in `",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:6644,rout,router,6644,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['rout'],['router']
Integrability," to theme changes</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11475"">#11475</a> [component: bokehjs] [BUG] SVG export breaks for Wedges</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11623"">#11623</a> [BUG] Placement of toolbar location is broken for gridplots</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11643"">#11643</a> Refs are not resolved in data models' default values</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11673"">#11673</a> [component: bokehjs] [BUG] JavaScript error when setting LabelSet text to None</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11694"">#11694</a> Custom extension breaks with id as key in a dict param</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11750"">#11750</a> [component: bokehjs] [BUG] Hover tool takes long time to render (-&gt; <a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11629"">#11629</a>)</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11770"">#11770</a> [component: bokehjs] [BUG] Linking an axis range can lead to other axis range autoscaling improperly</li>; </ul>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/bokeh/bokeh/commit/17a0b288052afac80ebcf0aa74e3915452fce3ca""><code>17a0b28</code></a> Deployment updates for release 3.0.1</li>; <li><a href=""https://github.com/bokeh/bokeh/commit/3f9d1fa63050d1f15238223cda9ac06ba4245cb6""><code>3f9d1fa</code></a> Merge deployment staging branch staging-3.0.1rc1</li>; <li><a href=""https://github.com/bokeh/bokeh/commit/07246bb64c9f2cb46952eeeec07d1f09fa82835a""><code>07246bb</code></a> Deployment updates for release 3.0.1rc1</li>; <li><a href=""https://github.com/bokeh/bokeh/commit/46fbb8edfcba1c26eb62c2f48eac7697f397dfe9""><code>46fbb8e</c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12454:7249,depend,dependabot,7249,https://hail.is,https://github.com/hail-is/hail/pull/12454,1,['depend'],['dependabot']
Integrability," to; authenticate with the proxy.</p>; <p>In cases where Requests receives a redirect response, it previously reattached; the <code>Proxy-Authorization</code> header incorrectly, resulting in the value being; sent through the tunneled connection to the destination server. Users who rely on; defining their proxy credentials in the URL are <em>strongly</em> encouraged to upgrade; to Requests 2.31.0+ to prevent unintentional leakage and rotate their proxy; credentials once the change has been fully deployed.</p>; <p>Users who do not use a proxy or do not supply their proxy credentials through; the user information portion of their proxy URL are not subject to this; vulnerability.</p>; <p>Full details can be read in our <a href=""https://github.com/psf/requests/security/advisories/GHSA-j8r2-6x86-q33q"">Github Security Advisory</a>; and <a href=""https://nvd.nist.gov/vuln/detail/CVE-2023-32681"">CVE-2023-32681</a>.</p>; </li>; </ul>; <h2>2.30.0 (2023-05-03)</h2>; <p><strong>Dependencies</strong></p>; <ul>; <li>; <p>⚠️ Added support for urllib3 2.0. ⚠️</p>; <p>This may contain minor breaking changes so we advise careful testing and; reviewing <a href=""https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html"">https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html</a>; prior to upgrading.</p>; <p>Users who wish to stay on urllib3 1.x can pin to <code>urllib3&lt;2</code>.</p>; </li>; </ul>; <h2>2.29.0 (2023-04-26)</h2>; <p><strong>Improvements</strong></p>; <ul>; <li>Requests now defers chunked requests to the urllib3 implementation to improve; standardization. (<a href=""https://redirect.github.com/psf/requests/issues/6226"">#6226</a>)</li>; <li>Requests relaxes header component requirements to support bytes/str subclasses. (<a href=""https://redirect.github.com/psf/requests/issues/6356"">#6356</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/psf/requests/commit/147c8511ddbfa5e8f71bbf5c18ede0c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13091:4296,Depend,Dependencies,4296,https://hail.is,https://github.com/hail-is/hail/pull/13091,6,['Depend'],['Dependencies']
Integrability," tqbHQbDv: Dict[AltAllele, Long],; HUh: Set[Double],; Xgb26Wlws: Double,; qe_XlLJt7_X: Dict[Double, Int],; U: Array[Call],; j: Double; }; v [ 1; , 5/6:.:.:.:GP=0.0,0.0,6.103515625E-4,0.0,0.0,0.0,0.0,0.00286865234375,0.0,0.058441162109375,0.0,0.0,0.0,0.00567626953125,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.004730224609375,0.153839111328125,0.0,0.0,0.0,0.704742431640625,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018402099609375,0.050689697265625,0.0,0.0,0.0,0.0,0.0,0.0,376902925948550232; , 2147483647; , 1; , true; , 15:396751431-18:1945111790; , Map(GT/C -> -9223372036854775808, GC/TGTG -> 0, GTCAC/AC -> 1, TCG/G -> -2853243060319614448, TTTG/G -> 0); , Set(0.0, 1.2590508536333097E308, -26.66700965052354, -1.0, 1.7976931348623157E308); , -44.18866673875504; , Map(4.9E-324 -> 1069254047, -29.21881886290265 -> 0, -7.511481628119398E307 -> -51783790, 78.3075905923555 -> -1679218199, -1.0 -> -1476797686, 66.69344244874847 -> -2147483648, -74.87563451361888 -> -50, 8.529797881337316E306 -> -38); , WrappedArray(2, 2, null, 2, 2, 1); , 1.7044473544408425E308; ]; ```; ```scala; t Struct{; jHUkH: Interval,; c: Struct{; EZyb77: Boolean,; qckA6k: Empty; },; K: Interval,; X: Locus,; BuujVaardN: Call,; drTH1J: Set[Locus],; DJL9uj7D: Variant,; vwuq: Set[Int],; cKAObAm1oh7: Boolean,; FqhLLOlV4p: Struct{; Ri631ZK2TiA: Empty; },; vtQ: Set[String],; HzHvw: Locus,; g: Double,; inwJHuBmLUM: Boolean,; Q: Float,; i: Genotype,; q: Float,; p_Wmn2Q: Variant,; Y6foXEa7F: Dict[Set[Float], Double],; SuXouO__uX: Int,; hrfM: Locus,; k: Variant,; V1WzY: Struct{; xWj: Struct{; bg: AltAllele; }; },; L3Ol_: Call,; Bmt: Variant,; EExpF_H: Struct{; DyAZQ1pL: Empty; },; JSc3FhxVxoM: Array[Dict[String, Empty]],; Iuu: Dict[Variant, Double],; qXBGmKS: Long,; QQfQtf3ct: Call,; bSsLYsTDI: Array[Array[Call]],; ad1iBzwaFZf: Dict[String, Locus],; Z2cD2KmFIkG: Call,; VSqH: AltAllele,; XVZqCYGf3_: Double,; NBdmoAaGkoL: Boolean,; r: Array[AltAllele],; W_NOSJIvTd: Double,; s3B8QiAqQ: Long,; lk: Float,; S1Fo: Float,; PEcTjU8vo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1903:1345,Wrap,WrappedArray,1345,https://hail.is,https://github.com/hail-is/hail/pull/1903,1,['Wrap'],['WrappedArray']
Integrability," typos (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1301"">#1301</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1299"">#1299</a>)</li>; <li>update dev dependencies (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1311"">#1311</a>)</li>; </ul>; <h2>tqdm v4.63.1 stable</h2>; <ul>; <li>fix stderr/stdout missing <code>flush()</code> (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1248"">#1248</a> &lt;- <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1177"">#1177</a>)</li>; <li>misc speed improvements/optimisations</li>; </ul>; <h2>tqdm v4.63.0 stable</h2>; <ul>; <li>add <code>__reversed__()</code></li>; <li>add efficient <code>__contains__()</code></li>; <li>improve CLI startup time (replace <code>pkg_resources</code> =&gt; <code>importlib</code>)</li>; <li><code>tqdm.autonotebook</code> warning &amp; <code>std</code> fallback on missing <code>ipywidgets</code> (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1218"">#1218</a> &lt;- <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1082"">#1082</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1217"">#1217</a>)</li>; <li>warn on positional CLI arguments</li>; <li>misc build/test framework updates; <ul>; <li>enable <code>py3.10</code> tests</li>; <li>add <code>conda</code> dependencies</li>; <li>update pre-commit hooks</li>; <li>fix <code>pytest</code> config (<code>nbval</code>, <code>asyncio</code>)</li>; <li>fix dependencies &amp; tests</li>; <li>fix site deployment</li>; </ul>; </li>; </ul>; <h2>tqdm v4.62.3 stable</h2>; <ul>; <li>fix minor typo (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1246"">#1246</a>)</li>; <li>minor example fix (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1246"">#1246</a>)</li>; <li>misc tidying &amp; refactoring</li>; <li>misc build/dev framework updates; <ul>; <li>update dependencies</li>; <li>update linters</li>; <l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12260:2390,depend,dependabot,2390,https://hail.is,https://github.com/hail-is/hail/pull/12260,1,['depend'],['dependabot']
Integrability," update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/fbe7859ec56ab64cc4d1b2604082878fdfdc8a14""><code>fbe7859</code></a> Fix crash in <code>dataclass</code> brain (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1768"">#1768</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/e194631088aee587140c029a0404f8d40c6765b5""><code>e194631</code></a> Bump astroid to 2.12.6, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/1f5dc457729d7219178ace9705d8445e89513472""><code>1f5dc45</code></a> Handle <code>dataclass</code> <code>kw_only</code> keyword correctly (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1764"">#1764</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/astroid/compare/v2.11.5...v2.12.9"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=astroid&package-manager=pip&previous-version=2.11.5&new-version=2.12.9)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` w",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12161:4894,depend,dependency-name,4894,https://hail.is,https://github.com/hail-is/hail/pull/12161,1,['depend'],['dependency-name']
Integrability," url, **kwargs); usr/local/lib/python3.9/dist-packages/hailtop/aiocloud/common/session.py:105: in request; return await retry_transient_errors(self._request_with_valid_authn, method, url, **kwargs); usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py:780: in retry_transient_errors; return await retry_transient_errors_with_debug_string('', 0, f, *args, **kwargs); usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py:796: in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); usr/local/lib/python3.9/dist-packages/hailtop/aiocloud/common/session.py:117: in _request_with_valid_authn; return await self._http_session.request(method, url, **kwargs); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. async def request_and_raise_for_status():; json_data = kwargs.pop('json', None); if json_data is not None:; if kwargs.get('data') is not None:; raise ValueError('data and json parameters cannot be used at the same time'); kwargs['data'] = aiohttp.BytesPayload(; value=orjson.dumps(json_data),; # https://github.com/ijl/orjson#serialize; #; # ""The output is a bytes object containing UTF-8""; encoding=""utf-8"",; content_type=""application/json"",; ); resp = await self.client_session._request(method, url, **kwargs); if raise_for_status:; if resp.status >= 400:; # reason should always be not None for a started response; assert resp.reason is not None; body = (await resp.read()).decode(); await resp.release(); > raise ClientResponseError(; resp.request_info,; resp.history,; status=resp.status,; message=resp.reason,; headers=resp.headers,; body=body,; ); E hailtop.httpx.ClientResponseError: 400, message='Bad Request', url=URL('http://internal.hail/pr-14351-default-yojxd4mck4io/batch/api/v1alpha/batches/321/update-fast') body=""400: error while inserting job group 1 into batch 321: (1213, 'Deadlock found when trying to get lock; try restarting transaction')""; ```. ### Version. 0.2.128. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14413:3500,message,message,3500,https://hail.is,https://github.com/hail-is/hail/issues/14413,2,['message'],['message']
Integrability," via &quot;argsCanBeInterpretedByShell&quot;</li>; <li><a href=""https://github.com/microsoft/debugpy/commit/6b276e339cd850c5f8c93ff4bdbd305dd963d7bb""><code>6b276e3</code></a> Step in/step over support for IPython. Fixes <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/869"">#869</a></li>; <li><a href=""https://github.com/microsoft/debugpy/commit/a294092d9c6d8459126ecb8f537b6012fb7e7d28""><code>a294092</code></a> Properly stop at line 1 in frame eval mode. Fixes <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/995"">#995</a></li>; <li>Additional commits viewable in <a href=""https://github.com/microsoft/debugpy/compare/v1.6.0...v1.6.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=debugpy&package-manager=pip&previous-version=1.6.0&new-version=1.6.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12103:5682,depend,dependabot-security-updates,5682,https://hail.is,https://github.com/hail-is/hail/pull/12103,2,['depend'],['dependabot-security-updates']
Integrability," view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.1&new-version=3.20.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12223:4173,depend,dependabot,4173,https://hail.is,https://github.com/hail-is/hail/pull/12223,24,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability," view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=requests&package-manager=pip&previous-version=2.28.2&new-version=2.31.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13091:8602,depend,dependabot,8602,https://hail.is,https://github.com/hail-is/hail/pull/13091,48,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability," view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=rich&package-manager=pip&previous-version=12.6.0&new-version=13.6.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>. > **Note**; > Automatic rebases have been disabled on this pull request as it has been open for over 30 days.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13758:8038,depend,dependabot,8038,https://hail.is,https://github.com/hail-is/hail/pull/13758,22,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability," view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=rich&package-manager=pip&previous-version=12.6.0&new-version=13.7.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>. > **Note**; > Automatic rebases have been disabled on this pull request as it has been open for over 30 days.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14012:8757,depend,dependabot,8757,https://hail.is,https://github.com/hail-is/hail/pull/14012,22,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability," view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=rich&package-manager=pip&previous-version=12.6.0&new-version=13.7.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>. > **Note**; > Automatic rebases have been disabled on this pull request as it has been open for over 30 days.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14376:7818,depend,dependabot,7818,https://hail.is,https://github.com/hail-is/hail/pull/14376,22,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability," vs Callable special-casing that was broken in refactoring (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/13784"">#13784</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/d03f201762df7138c6da157b5cbb8e634acef45f""><code>d03f201</code></a> Suggest using upper bound for unbound tvar (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/13730"">#13730</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/5b17cc6c393280326ed15d763e599cbaeefbc0e6""><code>5b17cc6</code></a> Fix overload overlap check for UninhabitedType (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/13461"">#13461</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/c7b4714e1f5e3cb8f3fec7426b6538fe1a3dcab1""><code>c7b4714</code></a> Update version to 0.981</li>; <li><a href=""https://github.com/python/mypy/commit/2bd7da21462a59643f2aec546304db1a624ba285""><code>2bd7da2</code></a> [0.980 backport] build changes (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/13688"">#13688</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/2b2953a1392368f623331d5168ccdfd39e37bbee""><code>2b2953a</code></a> [0.980 backport] Update pos-only unit tests for Python 3.10.7 (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/13660"">#13660</a>) (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/13665"">#13665</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/ada007841f6a96f68d114769624a0f7b523814a7""><code>ada0078</code></a> Remove dev from version</li>; <li><a href=""https://github.com/python/mypy/commit/efd1d38fb1db188e56fe6068ebe69d2164462b34""><code>efd1d38</code></a> [0.980 backport] Fix stubtest custom_typeshed_dir regression (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/13656"">#13656</a>) (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/13658"">#13658</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/70bc34837ecbafc528e511a462192",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12291:1383,depend,dependabot,1383,https://hail.is,https://github.com/hail-is/hail/pull/12291,1,['depend'],['dependabot']
Integrability," warnings for better ReadTheDocs generation (<a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/issues/807"">#807</a>)</li>; <li><a href=""https://github.com/oauthlib/oauthlib/commit/d4bafd9f1d0eba3766e933b1ac598cbbf37b8914""><code>d4bafd9</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/issues/797"">#797</a> from cclauss/patch-2</li>; <li>Additional commits viewable in <a href=""https://github.com/oauthlib/oauthlib/compare/v3.2.0...v3.2.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=oauthlib&package-manager=pip&previous-version=3.2.0&new-version=3.2.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12197:7378,depend,dependabot,7378,https://hail.is,https://github.com/hail-is/hail/pull/12197,2,['depend'],['dependabot']
Integrability," we will keep a ClassLoader full of a bunch of; JIT-optimized Hail classes. I did not include that in this PR because we need to finish eliminating; global state used by Hail. Currently, two executions would try to re-use compiled class names for; different code, leading to very weird errors. # Changes to File Systems. Hail has three four file system interfaces:. | File System Interface | Public | Language | Async |; | ----------------------- | ------ | -------- | ----- |; | hail.utils.hadoop_utils | Yes | Python | no |; | hail.fs | Yes | Python | no |; | hailtop.aiotools.fs | No | Python | yes |; | is.hail.io.fs | No | Scala | no |. `hail.fs` is technically in the public API (via `hl.current_backend().fs`), but I doubt anyone uses; it. `hail.utils.hadoop_utils` is a shim over `hail.fs`, there are no direct concrete implementations of; it. This PR adds `hail.fs.RouterFS` to `hail.fs`, a synchronous wrapper around; `hailtop.aiotools.fs.AsyncRouterFS`. A ""router"" file system is one which operates on URLs instead of; paths. It uses the URL's protocol to determine which concrete file system to use. For example, a; router fs can `open` both `gs://danking/abc` and `s3a://danking/abc`. Each Hail Query Python Backend is associated with one file system class. This PR associates the; ServiceBackend with `RouterFS`, enabling `hl.current_backend().fs.open`, `hl.hadoop_open`, etc. to; read from S3, GCS, ABS, and the local file system. We should deprecate `hail.utils.hadoop_utils`; because it is not Hadoop-specific. We should instead advertise the class-based `hail.fs` or create a; new function-based interface (e.g. `hl.fs.open(...)`. # Test Clean-up. The Hail Query local and spark tests should now work in Azure. I moved all the `hail.fs` and; `hailtop.aiotools.fs` tests into two build.yaml steps: `test_hail_python_fs` and; `test_hail_scala_fs`. These tests are exhaustive: they test every file system: S3, ABS, and GCS. The only file system tests that remain in the Hail Query test",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11194:4917,rout,router,4917,https://hail.is,https://github.com/hail-is/hail/pull/11194,1,['rout'],['router']
Integrability," we write out the reference genome and seem to support it just fine in Scala. I want to be able to do e.g.:. ```; >>> import hail as hl; >>> rg = hl.ReferenceGenome(""foo"", ['a', 'b'], {'a': 4, 'b': 6}); >>> t = hl.utils.range_table(10); >>> t = t.annotate(locus=hl.locus_from_global_position(t.idx, reference_genome='foo')); >>> t.write('test.t'); ```. and then, in a separate instance of hail, do:. ```; >>> import hail as hl; >>> t = hl.read_table('test.t'); ```. Currently, I get the following error:; ```; Traceback (most recent call last):; File ""/anaconda3/lib/python3.6/site-packages/parsimonious/nodes.py"", line 217, in visit; return method(node, [self.visit(n) for n in node]); File ""/Users/wang/code/hail/hail/python/hail/expr/type_parsing.py"", line 80, in visit_locus; return hl.tlocus(gr); File ""<decorator-gen-56>"", line 2, in __init__; File ""/Users/wang/code/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); File ""/Users/wang/code/hail/hail/python/hail/typecheck/check.py"", line 512, in check_all; args_.append(checker.check(arg, name, arg_name)); File ""/Users/wang/code/hail/hail/python/hail/typecheck/check.py"", line 56, in check; return tc.check(x, caller, param); File ""/Users/wang/code/hail/hail/python/hail/typecheck/check.py"", line 303, in check; return f(tc.check(x, caller, param)); File ""/Users/wang/code/hail/hail/python/hail/genetics/reference_genome.py"", line 10, in <lambda>; reference_genome_type = oneof(transformed((str, lambda x: hl.get_reference(x))), rg_type); File ""/Users/wang/code/hail/hail/python/hail/context.py"", line 362, in get_reference; return ReferenceGenome._references[name]; KeyError: 'foo'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-1214>"", line 2, in read_table; File ""/Users/wang/code/hail/hail/python/hail/typecheck/check",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6907:966,wrap,wrapper,966,https://hail.is,https://github.com/hail-is/hail/issues/6907,1,['wrap'],['wrapper']
Integrability," when displaying warnings,; making whitespace issues easier to identify.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10571"">#10571</a>: quickstart: Reduce content in the generated <code>conf.py</code> file. Patch by; Pradyun Gedam.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10648"">#10648</a>: LaTeX: CSS-named-alike additional :ref:<code>'sphinxsetup' &lt;latexsphinxsetup&gt;</code>; keys allow to configure four separate border-widths, four paddings, four; corner radii, a shadow (possibly inset), colours for border, background, shadow; for each of the code-block, topic, attention, caution, danger, error and warning; directives.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10655"">#10655</a>: LaTeX: Explain non-standard encoding in LatinRules.xdy</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10599"">#10599</a>: HTML Theme: Wrap consecutive footnotes in an <code>&lt;aside&gt;</code> element when; using Docutils 0.18 or later, to allow for easier styling. This matches the; behaviour introduced in Docutils 0.19. Patch by Adam Turner.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10518"">#10518</a>: config: Add <code>include_patterns</code> as the opposite of <code>exclude_patterns</code>.; Patch by Adam Turner.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/e712eae382d213ce3f4866ad6f5b3c84ce4f4409""><code>e712eae</code></a> Bump to 5.1.1 final</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/0555345ad715b1e5ec83bce2e4a993441ffb8f29""><code>0555345</code></a> Fix ValueError popping out in <code>sphinx.ext.napoleon</code> (<a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10709"">#10709</a>)</li>; <li><a href=""ht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12165:4610,Wrap,Wrap,4610,https://hail.is,https://github.com/hail-is/hail/pull/12165,1,['Wrap'],['Wrap']
Integrability," when no region is set (<a href=""https://github-redirect.dependabot.com/boto/botocore/issues/2818"">#2818</a>)</li>; <li><a href=""https://github.com/boto/botocore/commit/cc3f1c22f55ba50ca792eb73e7a6f721abdcc5ee""><code>cc3f1c2</code></a> Fix: S3 Object Lambda requests miss x-amz-content-sha256 headers (<a href=""https://github-redirect.dependabot.com/boto/botocore/issues/2819"">#2819</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/boto/botocore/compare/1.29.13...1.29.16"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=botocore&package-manager=pip&previous-version=1.29.13&new-version=1.29.16)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12503:4073,depend,dependabot,4073,https://hail.is,https://github.com/hail-is/hail/pull/12503,1,['depend'],['dependabot']
Integrability," when passing to postcss (fix <a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/7822"">#7822</a>) (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/7827"">#7827</a>) (<a href=""https://github.com/vitejs/vite/commit/72f17f8"">72f17f8</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/7822"">#7822</a> <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/7827"">#7827</a></li>; <li>fix(css): var in image-set (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/7921"">#7921</a>) (<a href=""https://github.com/vitejs/vite/commit/e96b908"">e96b908</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/7921"">#7921</a></li>; <li>fix(ssr): allow ssrTransform to parse hashbang (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8005"">#8005</a>) (<a href=""https://github.com/vitejs/vite/commit/6420ba0"">6420ba0</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8005"">#8005</a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/vitejs/vite/commit/d93ac8eca16534eb5474c19899bc130019b30a71""><code>d93ac8e</code></a> release: v2.9.13</li>; <li><a href=""https://github.com/vitejs/vite/commit/e109d64331d9fa57753832762c3573c3532a6947""><code>e109d64</code></a> fix: backport <a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8804"">#8804</a>, /@fs/ dir traversal with escaped chars (fixes <a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8498"">#8498</a>) (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8"">#8</a>...</li>; <li><a href=""https://github.com/vitejs/vite/commit/1afc1c2370e09998f800f9067491a25e9dd463a0""><code>1afc1c2</code></a> fix(wasm): support decoding data URL in Node &lt; v16 (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12142:10640,depend,dependabot,10640,https://hail.is,https://github.com/hail-is/hail/pull/12142,2,['depend'],['dependabot']
Integrability," who are comfortable with the idea of a counter but not with `group_by`. I added a new dataset for doctests and I realized a couple things:; - doctest_write_data.py is not deterministic; - if I add/change one dataset, my commit explodes with changes to all the datasets (see above); - doctest_write_data.py has to be run by *me*, it's not run by CI. I also noticed that when you specify no `row_key` to `import_matrix_table` you get a row key called `row_id`, which is annoying. Anyway now when someone asks how to count the mutations in each gene by consequence type we can point them to the `counter` docs. ---. Adding a dataset caused a bunch of docs failure that lead me to change how we do doctesting. The changes are summarized below.; - ignore `python/.eggs`; - make `PARALLELISM` configurable in `Makefile`; - fix `make pytest` (it referenced a non-extant target); - add `make doctest` (this and `pytest` use setup.py to replicate the environment the user would have after installation, I prefer this approach because I need not manually install any dependencies, setup.py handles that, it also configures spark correctly without environment variables); - harmonize `doctest` and `pytest` parameters in `build.gradle` and `Makefile`; - clean up import order in `conftest.py` to match pylint's desired ordering; - use a `temple.TemporaryDirectory` for all doctest and test output, which is automatically cleaned up (if you want to interrogate it you can `ctrl-z` a running doctest); this allows us to not copy the entire python directory into a build directory before running pytest; - *important:* re-generate all input datasets on every run of the tests. Previously, there was a file `doctest_write_data.py` which you were supposed to run when you changed the datasets, but if Hail changes then the random datasets generated by `doctest_write_data.py` might change. This means when I came along to add a new dataset, I had to address all the test failures introduced since the last time `doct",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6856:1126,depend,dependencies,1126,https://hail.is,https://github.com/hail-is/hail/pull/6856,1,['depend'],['dependencies']
Integrability," with M1 macs (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1580"">#1580</a>); e92706452 add predicate to GFF3Codec to give a chance to filter out some unused attributes (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1575"">#1575</a>); c647764b0 Some long reads tests using PacBio data. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1564"">#1564</a>); 57c3f03eb remove hardcoded .idx (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1568"">#1568</a>); a94a32512 Add file extension to missing index error message <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1512"">#1512</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1567"">#1567</a>); 74b827b67 Improve error message in IntervalTree (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1545"">#1545</a>); 7719274fe Htsget POST request support (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1529"">#1529</a>)</p>; <p>VCF:; aac46ee6d Added GVCF mode for VariantContext type determination (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1544"">#1544</a>); d72d73b01 Add context to exception when the vcf file is invalid <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1565"">#1565</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1566"">#1566</a>); 8466c82dc Respect genotype filtering when calculating AC/AN/AF (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1554"">#1554</a>)</p>; <p>User API:; a4f1f04c8 Allow fluent chaining setters for SAMSequenceRecord (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1563"">#1563</a>)</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/samtools/htsjdk/commit/4a4024a97ee3e87096df6ad9b22c8260bd527",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12229:5176,depend,dependabot,5176,https://hail.is,https://github.com/hail-is/hail/pull/12229,1,['depend'],['dependabot']
Integrability," would get reset before the cookie expiry.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp-session/blob/master/CHANGES.txt"">aiohttp-session's changelog</a>.</em></p>; <blockquote>; <h1>2.11.0 (2021-01-31)</h1>; <ul>; <li>Support initialising <code>EncryptedCookieStorage</code> with <code>Fernet</code> object directly.</li>; <li>Fix an issue where the session would get reset before the cookie expiry.</li>; </ul>; <h1>2.10.0 (2021-12-30)</h1>; <ul>; <li>Typing support</li>; <li>Add samesite cookie option</li>; <li>Support aioredis 2</li>; </ul>; <h1>2.9.0 (2019-11-04)</h1>; <ul>; <li>Fix memcached expiring time (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/398"">#398</a>)</li>; </ul>; <h1>2.8.0 (2019-09-17)</h1>; <ul>; <li>Make this compatible with Python 3.7+. Import from collections.abc, instead; of from collections. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/373"">#373</a>)</li>; </ul>; <h1>2.7.0 (2018-10-13)</h1>; <ul>; <li>; <p>Reset a session if the session age &gt; max_age (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/331"">#331</a>)</p>; </li>; <li>; <p>Reset a session on TTL expiration for EncryptedCookieStorage (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/326"">#326</a>)</p>; </li>; </ul>; <h1>2.6.0 (2018-09-12)</h1>; <ul>; <li>Create a new session if <code>NaClCookieStorage</code> cannot decode a; corrupted cookie (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/317"">#317</a>)</li>; </ul>; <h1>2.5.0 (2018-05-12)</h1>; <ul>; <li>Add an API for requesting new session explicitly (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/281"">#281</a>)</li>; </ul>; <h1>2.4.0 (2018-05-04)</h1>; <ul>; <li>Fix a bug for session fixation (<a href=""https://github-redirect.dependab",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11577:1468,depend,dependabot,1468,https://hail.is,https://github.com/hail-is/hail/pull/11577,1,['depend'],['dependabot']
Integrability," wrong (all error messages here, including the full java stack trace):. ```; Error; Traceback (most recent call last):; File ""/Users/jbloom/anaconda/envs/py36/lib/python3.6/unittest/case.py"", line 59, in testPartExecutor; yield; File ""/Users/jbloom/anaconda/envs/py36/lib/python3.6/unittest/case.py"", line 605, in run; testMethod(); File ""/Users/jbloom/hail/python/hail/tests/test_api.py"", line 1557, in test_force_bug; b=mt2[mt.row_idx, mt.col_idx].x)._force_count_rows(); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 1171, in select_entries; return self._select_entries(""MatrixTable.select_entries"", hl.struct(**entry)); File ""/Users/jbloom/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 2844, in _select_entries; base, cleanup = self._process_joins(s); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 2503, in _process_joins; return process_joins(self, exprs, broadcast_f); File ""/Users/jbloom/hail/python/hail/utils/misc.py"", line 356, in process_joins; left = j.join_func(left); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 2414, in joiner; col_exprs = {col_uid: src_cols_indexed.index(*col_exprs)[col_uid]}); File ""/Users/jbloom/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/jbloom/hail/python/hail/matrixtable.py"", line 2443, in _annotate_all; analyze(""MatrixTable.annotate_rows"", row_struct, self._row_indices); File ""/Users/jbloom/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/jbloom/hail/python/hail/expr/expressions/expression_utils.py"", line 105, in analyze; raise errors[0]; hail.expr.expressions.base_expression.ExpressionException: MatrixTable.annotate_rows expects an expression from source <hail.matrixtable.MatrixTable object at 0x10889c908>, found expression derived from <hail.matrixtable.MatrixTable object at 0x108acbf60>; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3763:2478,wrap,wrapper,2478,https://hail.is,https://github.com/hail-is/hail/issues/3763,2,['wrap'],['wrapper']
Integrability," x, and 1 additional covariate...; /broad/software/free/Linux/redhat_7_x86_64/pkgs/jdk1.8.0_181/bin/java: symbol lookup error: /tmp/jniloader1327638724610654731netlib-native_system-linux-x86_64.so: undefined symbol: cblas_dgemm; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/home/unix/dking/.conda/envs/hail/lib/python3.7/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/home/unix/dking/.conda/envs/hail/lib/python3.7/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/home/unix/dking/.conda/envs/hail/lib/python3.7/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ---------------------------------------------------------------------------; Py4JError Traceback (most recent call last); <ipython-input-3-9b1033d0ac55> in <module>; ----> 1 t = hl.linear_regression_rows(x=mt.GT.n_alt_alleles(), y=mt.pop, covariates=[1]). <decorator-gen-1332> in linear_regression_rows(y, x, covariates, block_size, pass_through). ~/.conda/envs/hail/lib/python3.7/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 559 def wrapper(__original_func, *args, **kwargs):; 560 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 561 return __original_func(*args_, **kwargs_); 562 ; 563 return wrapper. ~/.conda/envs/hail/lib/python3.7/site-packages/hail/methods/statgen.py in linear_regression_rows(y, x, covariates, block_size, pass_through); 434 ht_result = ht_result.annotate(**{f: ht_result[f][0] for f in fields}); 435 ; --> 436 return ht_result.persist(); 437 ; 4",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5559:2389,protocol,protocol,2389,https://hail.is,https://github.com/hail-is/hail/issues/5559,1,['protocol'],['protocol']
Integrability," x:; File ""/home/edmund/.local/src/hail/hail/python/hail/expr/functions.py"", line 3531, in any; return collection.any(f); File ""<decorator-gen-510>"", line 2, in any; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/hail/python/hail/expr/expressions/typed_expressions.py"", line 68, in any; return hl.array(self).fold(lambda accum, elt: accum | f(elt), False); File ""<decorator-gen-518>"", line 2, in fold; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/hail/python/hail/expr/expressions/typed_expressions.py"", line 221, in fold; return collection._to_stream().fold(lambda x, y: f(x, y), zero); File ""<decorator-gen-650>"", line 2, in fold; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/hail/python/hail/expr/expressions/typed_expressions.py"", line 4522, in fold; body = to_expr(f(accum_ref, elt_ref)); File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 364, in f; ret = x(*args); File ""/home/edmund/.local/src/hail/hail/python/hail/expr/expressions/typed_expressions.py"", line 221, in <lambda>; return collection._to_stream().fold(lambda x, y: f(x, y), zero); File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 364, in f; ret = x(*args); File ""/home/edmund/.local/src/hail/hail/python/hail/expr/expressions/typed_expressions.py"", line 68, in <lambda>; return hl.array(self).fold(lambda accum, elt: accum | f(elt), False); File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 364, in f; ret = x(*args); File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 364, in f; ret = x(*args); File ""test.py"", line 11, in <lambda>; (m",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13046#issuecomment-1624278982:6243,wrap,wrapper,6243,https://hail.is,https://github.com/hail-is/hail/issues/13046#issuecomment-1624278982,1,['wrap'],['wrapper']
Integrability," | --- | --- | --- |; | this PR | 48 | 39.35 |; | this PR with one monolithic method | 235 | 73 |; | master (5fe6737263b4) | 91s | 83.5 |. I was disappointed with the performance of the monolithic method, so I dug in with `-XX:+PrintCompilation` and found that the JIT was having trouble doing on-stack replacement of the entry parsing loop. There was a cryptic message about the stack not being empty during an OSR compilation. I take this result as evidence that, in the JVM, small, fine-grained methods are critical for reliable performance. The new code, after JIT warming, is reading at 250 MB/s (1GB / 40 seconds) which is a half to a third of the performance of `cat`. It's more than twice as fast as the old code. Aside: using the staged stuff is hard, especially when using multiple methods. A couple thoughts:; - Because SRVB generates a fresh SRVB for arrays and structs, you must thread the srvb through your code gen rather than using a single field, this is annoying and error prone; - `init` is not a first class thing in `FunctionBuilder` and I've arguably made the whole situation more ugly by exposing `addInitInstructions`. Without the ability to place code in the constructor, it is hard to coordinate work between multiple methods.; - When using lots of methods, there's a lot of bookkeeping. I would like a way to define a ""staged class"" that wraps up some of the boilerplate. Not totally clear what I want here, just less boilerplate. Aside2: This is still pretty slow!? Splitting into multiple methods allowed me to interrogate where time was spent. The answer is ""method4"" which is `parseEntries`. This code includes the loop, the srvb state management, the Region manipulation, and checking for the missing value. I'd be surprised its the checking for missing value because I delegate to `String.regionMatches` for the heavy lifting and that does not show up in the profiler. I'm left to conclude that either srvb state management or writing/reading to regions is expensive.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6987:2641,wrap,wraps,2641,https://hail.is,https://github.com/hail-is/hail/pull/6987,1,['wrap'],['wraps']
Integrability," | NULL | ref | PRIMARY | 12 | 35 | 100.00 | Using temporary |. If I replace `ORDER BY batches.id DESC` with `ORDER BY job_groups.batch_id DESC` the query plan excludes a filesort. | id | select_type | table | partitions | type | key | key_len | rows | filtered | Extra |; | -- | ----------------- | ------------------------------------ | ---------- | ------ | ----------- | ------- | ------- | -------- | ------------------------------------------------------------------------- |; | 1 | PRIMARY | job_groups | NULL | range | PRIMARY | 8 | 5420371 | 10.00 | Using where; Backward index scan; Using index; Rematerialize (<derived3>) |; | 1 | PRIMARY | batches | NULL | eq_ref | PRIMARY | 8 | 1 | 50.00 | Using where |; | 1 | PRIMARY | billing_projects | NULL | eq_ref | PRIMARY | 302 | 1 | 100.00 | Using index |; | 1 | PRIMARY | job_groups_n_jobs_in_complete_states | NULL | eq_ref | PRIMARY | 12 | 1 | 100.00 | NULL |; | 1 | PRIMARY | job_groups_cancelled | NULL | ref | PRIMARY | 8 | 1 | 100.00 | Using index |; | 1 | PRIMARY | job_group_self_and_ancestors | NULL | eq_ref | PRIMARY | 16 | 1 | 100.00 | Using index |; | 1 | PRIMARY | billing_project_users | NULL | eq_ref | PRIMARY | 604 | 1 | 100.00 | Using index |; | 1 | PRIMARY | <derived3> | NULL | ALL | NULL | NULL | 2 | 100.00 | Using where |; | 3 | DEPENDENT DERIVED | <derived4> | NULL | ALL | NULL | NULL | 35 | 100.00 | NULL |; | 3 | DEPENDENT DERIVED | resources | NULL | eq_ref | resource_id | 4 | 1 | 100.00 | NULL |; | 4 | DEPENDENT DERIVED | aggregated_job_group_resources_v3 | NULL | ref | PRIMARY | 12 | 35 | 100.00 | Using temporary |. As far as I can tell this is a query planner ""bug"" in MySQL. batches.id and job_groups.batch_id are equal because of the `ON` sub-clause of the `LEFT JOIN` clause. This change ensures that everywhere we query the job_groups table we order by batch_id and job_group_id *from that table* in descending order. This ensures were consistent across the codebase. This query now takes 0.01 seconds.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14377:5420,DEPEND,DEPENDENT,5420,https://hail.is,https://github.com/hail-is/hail/pull/14377,3,['DEPEND'],['DEPENDENT']
Integrability," | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-WHEEL-3180413](https://snyk.io/vuln/SNYK-PYTHON-WHEEL-3180413) | `wheel:` <br> `0.30.0 -> 0.38.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2NTQzMzZlYi02MmRmLTQ0ODAtOTFkOS0xZDg4N2FmNmQwMTUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjY1NDMzNmViLTYyZGYtNDQ4MC05MWQ5LTFkODg3YWY2ZDAxNSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14205:10681,depend,dependency,10681,https://hail.is,https://github.com/hail-is/hail/pull/14205,2,['depend'],"['dependencies', 'dependency']"
Integrability," | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **539/1000** <br/> **Why?** Has a fix available, CVSS 6.5 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | **589/1000** <br/> **Why?** Has a fix available, CVSS 7.5 | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-WHEEL-3180413](https://snyk.io/vuln/SNYK-PYTHON-WHEEL-3180413) | `wheel:` <br> `0.30.0 -> 0.38.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3YmFjNzAzOC00ZmQzLTQ3YmItOGUwMy0yNjRmYTUxNDRlNGQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjdiYWM3MDM4LTRmZDMtNDdiYi04ZTAzLTI2NGZhNTE0NGU0ZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14108:9665,depend,dependency,9665,https://hail.is,https://github.com/hail-is/hail/pull/14108,2,['depend'],"['dependencies', 'dependency']"
Integrability,"!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/axios/axios/blob/master/CHANGELOG.md"">axios's changelog</a>.</em></p>; <blockquote>; <h3>0.21.2 (September 4, 2021)</h3>; <p>Fixes and Functionality:</p>; <ul>; <li>Updating axios requests to be delayed by pre-emptive promise creation (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2702"">#2702</a>)</li>; <li>Adding &quot;synchronous&quot; and &quot;runWhen&quot; options to interceptors api (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2702"">#2702</a>)</li>; <li>Updating of transformResponse (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3377"">#3377</a>)</li>; <li>Adding ability to omit User-Agent header (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3703"">#3703</a>)</li>; <li>Adding multiple JSON improvements (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3688"">#3688</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3763"">#3763</a>)</li>; <li>Fixing quadratic runtime and extra memory usage when setting a maxContentLength (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3738"">#3738</a>)</li>; <li>Adding parseInt to config.timeout (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3781"">#3781</a>)</li>; <li>Adding custom return type support to interceptor (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3783"">#3783</a>)</li>; <li>Adding security fix for ReDoS vulnerability (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3980"">#3980</a>)</li>; </ul>; <p>Internal and Tests:</p>; <ul>; <li>Updating build dev dependancies (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3401"">#3401</a>)</li>; <li>Fixing builds running on Travis CI (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3538"">#3538</a>)</l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:6518,depend,dependabot,6518,https://hail.is,https://github.com/hail-is/hail/pull/11080,2,['depend'],['dependabot']
Integrability,"![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **561/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.5 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6210214) | `cryptography:` <br> `3.3.2 -> 42.0.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **519/1000** <br/> **Why?** Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI5ZjJhMGZlMy1kYmVkLTQ2YzAtYmQyMC0yMjM3NzFiYzE0OTciLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjlmMmEwZmUzLWRiZWQtNDZjMC1iZDIwLTIyMzc3MWJjMTQ5NyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14327:10251,depend,dependency,10251,https://hail.is,https://github.com/hail-is/hail/pull/14327,2,['depend'],"['dependencies', 'dependency']"
Integrability,"""). We use the IndexReader in `PartitionNativeIntervalReader`, `PartitionNativeReaderIndexed`, and `PartitionZippedIndexedNativeReader`. 1. `PartitionNativeIntervalReader` is only used by `query_table`. 2. `PartitionNativeReaderIndexed` is only used by `IndexedRVDSpec2.readTableStage` which is used by `TableNativeReader` when there is a new partitioner. 3. `PartitionZippedIndexedNativeReader` is only sued by `AbstractRVDSpec.readZippedLowered` when there is a new partitioner. Two is for tables, three is for matrix tables. In `readZippedLowered` we explicitly [drop the file protocol](https://github.com/hail-is/hail/blob/1dedf3c63f9aabf1b6ce538165360056f82f76e4/hail/src/main/scala/is/hail/rvd/AbstractRVDSpec.scala#L154-L155):. ```; val absPathLeft = removeFileProtocol(pathLeft); val absPathRight = removeFileProtocol(pathRight); ```. We have done this, by various names, since this lowered code path was added. I added `removeFileProtocol` because stripping the protocol in Query-on-Batch prevented the reading and writing of gs:// URIs, the only URIs I could read in QoB. `uriPath` (the function whose use I replaced with `removeFileProtocol`) was added by Cotton [a very long time ago](https://github.com/hail-is/hail/commit/92a9936e11d2f56b88390bee5dc4de489e188f02). It seems he added it so that he could use HDFS to generate a temporary file path on the local filesystem but pass the file path to binary tools that know nothing of HDFS and file:// URIs. #9522 added the lowered code path and thus introduced this bug. It attempted to mirror the extant code in [`readIndexedPartitions`](https://github.com/hail-is/hail/blob/2b0aded9206849252b453dd80710cea8d2156793/hail/src/main/scala/is/hail/HailContext.scala#L421-L440) which *does not* strip any protocols from the path. This has gone undetected because we never try to read data through the OS's filesystem. We always use gs://, Azure, or s3:// because we do not test in environments that have a networked file system mounted in the O",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14057:1176,protocol,protocol,1176,https://hail.is,https://github.com/hail-is/hail/pull/14057,1,['protocol'],['protocol']
Integrability,""", ""message"": ""started k8s state refresh""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,085"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""refresh_k8s_pods:1210"", ""message"": ""k8s had 3 pods""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,088"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1145"", ""message"": ""update job (11, 1, 'output') with pod batch-11-job-1-4f1118""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,090"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1145"", ""message"": ""update job (11, 2, 'output') with pod batch-11-job-2-ad1587""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,093"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1145"", ""message"": ""update job (11, 3, 'output') with pod batch-11-job-3-d826dd""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,093"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""refresh_k8s_pods:1221"", ""message"": ""restarting ready and running jobs with pods not seen in k8s""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,093"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""refresh_k8s_pods:1225"", ""message"": ""restarting job (9, 1, 'main')""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,093"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1145"", ""message"": ""update job (9, 1, 'main') with pod None""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,093"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1148"", ""message"": ""job (9, 1, 'main') mark unscheduled""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,106"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""refresh_k8s_pvc:1237"", ""message"": ""k8s had 3 pvcs""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,113"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""refresh_k8s_state:1264"", ""message"": ""k8s state refresh complete""}; ```. Because job 1's batch is cancelled, we never restart the job/pod. However, the batch is stuck in an inco",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6617:15845,message,message,15845,https://hail.is,https://github.com/hail-is/hail/issues/6617,1,['message'],['message']
Integrability,"""/usr/local/lib/python3.6/dist-packages/hailtop/utils/utils.py"", line 33, in blocking_to_async; thread_pool, lambda: fun(*args, **kwargs)); File ""/usr/lib/python3.6/concurrent/futures/thread.py"", line 56, in run; result = self.fn(*self.args, **self.kwargs); File ""/usr/local/lib/python3.6/dist-packages/hailtop/utils/utils.py"", line 33, in <lambda>; thread_pool, lambda: fun(*args, **kwargs)); File ""/usr/local/lib/python3.6/dist-packages/batch/google_storage.py"", line 53, in _read_gs_file; content = f.download_as_string(); File ""/usr/local/lib/python3.6/dist-packages/google/cloud/storage/blob.py"", line 697, in download_as_string; self.download_to_file(string_buffer, client=client, start=start, end=end); File ""/usr/local/lib/python3.6/dist-packages/google/cloud/storage/blob.py"", line 638, in download_to_file; _raise_from_invalid_response(exc); File ""/usr/local/lib/python3.6/dist-packages/google/cloud/storage/blob.py"", line 2034, in _raise_from_invalid_response; raise exceptions.from_http_status(response.status_code, message, response=response); google.api_core.exceptions.Forbidden: 403 GET https://www.googleapis.com/download/storage/v1/b/hail-batch2-nru9x/o/cd50b95a89914efb897965a5e982a29d%2F1%2F1%2Fsetup%2Fjob.log?alt=media: ('Request failed with status code', 403, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>); ```. - The first error is caused by the driver object is only available on the batch2-driver instance. Now the front end sends a request to the driver to get the logs if the job is running. I purposefully left the driver and front end calling the same function in case the job terminates before the driver handles the request from the front end. - Unified the Instance_ID between the front_end and the driver. I thought this was causing the second bug where gcs was unauthorized, but Tim was running in the default namespace, so they had the same instance id. - I checked and we're loading the same gsa-key in both the front end and driver.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7412:5506,message,message,5506,https://hail.is,https://github.com/hail-is/hail/pull/7412,1,['message'],['message']
Integrability,""">#10621</a> [component: bokehjs] [BUG] [MINOR] 2.3.0dev3, plot's inner_width property always sent on redraw even if unchanged</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/10804"">#10804</a> [BUG] export does not respect current theme</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11033"">#11033</a> [component: bokehjs] [BUG] add_layout(LinearAxis) in click handler crashes client</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11116"">#11116</a> [component: bokehjs] [BUG] ColorBars do not update when their properties are updated</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11205"">#11205</a> [component: bokehjs] [BUG] Hover tooltip breaks with full-circle wedge</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11339"">#11339</a> [BUG] Toggling layout's visibility results with overlapping widgets</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11462"">#11462</a> [component: bokehjs] [BUG] Existing ColorBar tick-digits don't react to theme changes</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11475"">#11475</a> [component: bokehjs] [BUG] SVG export breaks for Wedges</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11623"">#11623</a> [BUG] Placement of toolbar location is broken for gridplots</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11643"">#11643</a> Refs are not resolved in data models' default values</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11673"">#11673</a> [component: bokehjs] [BUG] JavaScript error when setting LabelSet text to None</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11694"">#11694</a> Custom extension breaks with id as key in a dict param</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11750"">#11750",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12454:6134,depend,dependabot,6134,https://hail.is,https://github.com/hail-is/hail/pull/12454,1,['depend'],['dependabot']
Integrability,""">#12435</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/67088e558dc24a2c6c231db542a367923dfdc049""><code>67088e5</code></a> Pin the version of bugbear (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/12436"">#12436</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/367b29d4aac16fc7493abffe2df0d8f477c23923""><code>367b29d</code></a> Make order of processing the builtins SCC predictable (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/12431"">#12431</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/f81b228e66d8a95cc39247f189e7be7e894f7f92""><code>f81b228</code></a> Fix inheritance false positives with dataclasses/attrs (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/12411"">#12411</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/7e09c2a100209072429e290d2f7b9b8007b8629c""><code>7e09c2a</code></a> Support overriding dunder attributes in Enum subclass (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/12138"">#12138</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/837543efb616b14e2f800db6962d216621dee4d7""><code>837543e</code></a> Fix crash in match statement if class name is undefined (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/12417"">#12417</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/6606dbe98d09170d3ad810bc791a16d99ceb2281""><code>6606dbe</code></a> Allow non-final <strong>match_args</strong> and overriding (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/12415"">#12415</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/626147a761891362dbf6e845c99031e2e043d0f4""><code>626147a</code></a> Fix small conditional overload regression (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/12336"">#12336</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/8e9ac1576b2d9b93bfe67dcf3a553e479f9af971""><code>8e9ac15</code></a> Bump version to 0.942+dev</li>; <li>Add",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11667:1509,depend,dependabot,1509,https://hail.is,https://github.com/hail-is/hail/pull/11667,2,['depend'],['dependabot']
Integrability,""">#133</a>). Thanks to <a href=""https://github.com/jmsmkn""><code>@​jmsmkn</code></a> and <a href=""https://github.com/adamchainz""><code>@​adamchainz</code></a>!</li>; <li>Fix incorrect documentation for <a href=""https://www.curlylint.org/docs/rules/no_autofocus""><code>no_autofocus</code></a> and <a href=""https://www.curlylint.org/docs/rules/tabindex_no_positive""><code>tabindex_no_positive</code></a>.</li>; </ul>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.13.0"">v0.13.0</a> 2021-04-25</h2>; <p>This release comes with a blog post! Read on <a href=""https://www.curlylint.org/blog/quality-of-life-improvements"">Quality-of-life improvements</a>.</p>; <h3>Added</h3>; <ul>; <li>Implement --template-tags CLI flag (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/25"">#25</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/77"">#77</a>).</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Add more descriptive error message for missing whitespace between HTML attributes (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/23#issuecomment-700622837"">#23 (comment)</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; <li>Move development dependencies from extras to separate <code>requirements.txt</code> (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; <li>Declare support for Python 3.9.</li>; <li>Tentatively declare support for Python 3.10 (tested with <code>Python 3.10.0a6+</code>).</li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Fix Python 3.10 deprecation warning by importing Iterable from collections.abc (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; </ul>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.12.2"">v0.12.2</a> 2021-03-06</h2>; <h3>Fixed</h3>; <ul>; <li>The <code>image_alt</code> rule no longer crashes when encou",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11713:5053,message,message,5053,https://hail.is,https://github.com/hail-is/hail/pull/11713,1,['message'],['message']
Integrability,""">#172</a>)</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/77e2a581e1d1811674b7b74745a9c20a5b939488""><code>77e2a58</code></a> Release version 1.14.4 of the npm package.</li>; <li>Additional commits viewable in <a href=""https://github.com/follow-redirects/follow-redirects/compare/v1.14.1...v1.14.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=follow-redirects&package-manager=npm_and_yarn&previous-version=1.14.1&new-version=1.14.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11283:2905,Depend,Dependabot,2905,https://hail.is,https://github.com/hail-is/hail/pull/11283,2,['Depend'],['Dependabot']
Integrability,""">#2686</a>)</li>; <li>Fix cases that contain multiple top-level as-expressions, like <code>case 1 as a, 2 as b</code>; (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2716"">#2716</a>)</li>; <li>Fix call patterns that contain as-expressions with keyword arguments, like; <code>case Foo(bar=baz as quux)</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2749"">#2749</a>)</li>; <li>Tuple unpacking on <code>return</code> and <code>yield</code> constructs now implies 3.8+ (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2700"">#2700</a>)</li>; <li>Unparenthesized tuples on annotated assignments (e.g; <code>values: Tuple[int, ...] = 1, 2, 3</code>) now implies 3.8+ (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2708"">#2708</a>)</li>; <li>Fix handling of standalone <code>match()</code> or <code>case()</code> when there is a trailing newline or a; comment inside of the parentheses. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2760"">#2760</a>)</li>; <li><code>from __future__ import annotations</code> statement now implies Python 3.7+ (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2690"">#2690</a>)</li>; </ul>; <h3>Performance</h3>; <ul>; <li>Speed-up the new backtracking parser about 4X in general (enabled when; <code>--target-version</code> is set to 3.10 and higher). (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2728"">#2728</a>)</li>; <li><em>Black</em> is now compiled with <a href=""https://github.com/mypyc/mypyc"">mypyc</a> for an overall 2x; speed-up. 64-bit Windows, MacOS, and Linux (not including musl) are supported. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/1009"">#1009</a>,; <a href=""https://github-redirect.dependabot.com/psf/black/issues/2431"">#2431</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a hre",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11468:10756,depend,dependabot,10756,https://hail.is,https://github.com/hail-is/hail/pull/11468,1,['depend'],['dependabot']
Integrability,""">#3487</a> with thanks to <a href=""https://github.com/Skn0tt""><code>@​Skn0tt</code></a></li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Fixed ValueError when <code>ff.create_annotated_heatmap</code> passes <code>rgba()</code> colors into <code>to_rgb_color_list</code> <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/issues/3478"">#3478</a> with thanks to <a href=""https://github.com/janosh""><code>@​janosh</code></a></li>; </ul>; <h3>Updated</h3>; <ul>; <li>Updated Plotly.js to from version 2.6.3 to version 2.8.3. See the <a href=""https://github.com/plotly/plotly.js/blob/master/CHANGELOG.md#280----2021-12-10"">plotly.js CHANGELOG</a> for more information. Notable changes include:; <ul>; <li>Horizontal color bars</li>; <li><code>texttemplate</code> for histogram-like and heatmap-like traces</li>; </ul>; </li>; </ul>; <h2>[5.4.0] - 2021-11-15</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed error when serializing dict with mix of string and non-string keys <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/issues/3380"">#3380</a></li>; </ul>; <h3>Updated</h3>; <ul>; <li>The JSON serialization engines no longer sort their keys <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/issues/3380"">#3380</a></li>; <li>Updated Plotly.js to from version 2.4.2 to version 2.6.3. See the <a href=""https://github.com/plotly/plotly.js/blob/master/CHANGELOG.md#263----2021-11-12"">plotly.js CHANGELOG</a> for more information. Notable changes include:; <ul>; <li>New subplot type <code>smith</code> that supports <code>scattersmith</code> trace types for visualizing data in the complex domain</li>; <li>Changes to Plotly.js packaging</li>; </ul>; </li>; </ul>; <h2>[5.3.1] - 2021-08-31</h2>; <h3>Updated</h3>; <ul>; <li>Updated Plotly.js to from version 2.4.1 to version 2.4.2. See the <a href=""https://github.com/plotly/plotly.js/blob/master/CHANGELOG.md#240----2021-08-27"">plotly.js CHANGELOG</a> for more information. These changes are reflected in the auto-generated <code>plo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11535:3203,depend,dependabot,3203,https://hail.is,https://github.com/hail-is/hail/pull/11535,1,['depend'],['dependabot']
Integrability,""">#3694</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3771"">#3771</a>)</li>; <li>Updating karma sauce launcher to fix failing sauce tests (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3712"">#3712</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3717"">#3717</a>)</li>; <li>Updating content-type header for application/json to not contain charset field, according do RFC 8259 (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2154"">#2154</a>)</li>; <li>Fixing tests by bumping karma-sauce-launcher version (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3813"">#3813</a>)</li>; <li>Changing testing process from Travis CI to GitHub Actions (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3938"">#3938</a>)</li>; </ul>; <p>Documentation:</p>; <ul>; <li>Updating documentation around the use of <code>AUTH_TOKEN</code> with multiple domain endpoints (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3539"">#3539</a>)</li>; <li>Remove duplication of item in changelog (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3523"">#3523</a>)</li>; <li>Fixing gramatical errors (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2642"">#2642</a>)</li>; <li>Fixing spelling error (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3567"">#3567</a>)</li>; <li>Moving gitpod metion (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2637"">#2637</a>)</li>; <li>Adding new axios documentation website link (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3681"">#3681</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3707"">#3707</a>)</li>; <li>Updating documentation around dispatching requests (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3772"">#3772</a>)</li>; <li>Adding documentation for the type guard isAxiosError (<a href=""https://github-redirect.dependabot.com/ax",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:3104,depend,dependabot,3104,https://hail.is,https://github.com/hail-is/hail/pull/11080,4,['depend'],['dependabot']
Integrability,""">#3953</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/axios/axios/compare/v0.21.1...v0.21.2"">compare view</a></li>; </ul>; </details>; <details>; <summary>Maintainer changes</summary>; <p>This version was pushed to npm by <a href=""https://www.npmjs.com/~jasonsaayman"">jasonsaayman</a>, a new releaser for axios since your current version.</p>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=axios&package-manager=npm_and_yarn&previous-version=0.21.1&new-version=0.21.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:14342,Depend,Dependabot,14342,https://hail.is,https://github.com/hail-is/hail/pull/11080,2,['Depend'],['Dependabot']
Integrability,""">#467</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-jinja2/commit/375021b6ea333846746a0a72a5d4ef13dcfeb944""><code>375021b</code></a> Bump mypy from 0.902 to 0.910 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_jinja2/issues/461"">#461</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-jinja2/commit/53fc0bc7c5e8d2f057e88410f8c60c113a6d8d68""><code>53fc0bc</code></a> Bump pytest-cov from 2.11.1 to 2.12.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_jinja2/issues/452"">#452</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-jinja2/commit/9331f1529411fadefdd1505d9c849cbdafd0ca9a""><code>9331f15</code></a> Bump pre-commit from 2.12.1 to 2.14.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_jinja2/issues/470"">#470</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-jinja2/commit/161dd3e3c3024099ad33d02118b1ed9b1bc8da38""><code>161dd3e</code></a> Squash commit (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_jinja2/issues/472"">#472</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-jinja2/commit/3ccaf1f39faea4751ceeaa43c242b5f5512d52dc""><code>3ccaf1f</code></a> Auto-merge again (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_jinja2/issues/471"">#471</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-jinja2/commit/56a314431277a964d20f5deb008df5fe52d80622""><code>56a3144</code></a> Remove if (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_jinja2/issues/469"">#469</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-jinja2/commit/91c004dd135b18c3ffbc69646fc7f8706273e866""><code>91c004d</code></a> Auto-merge (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_jinja2/issues/468"">#468</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp_jinja2/compare/v1.1.1...v1.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://depen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11576:5488,depend,dependabot,5488,https://hail.is,https://github.com/hail-is/hail/pull/11576,1,['depend'],['dependabot']
Integrability,""">#703</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/30ec8589e183f76f40764a8dd78591719f521943""><code>30ec858</code></a> remove unused WIN (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/702"">#702</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pyflakes/compare/2.4.0...2.5.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyflakes&package-manager=pip&previous-version=2.4.0&new-version=2.5.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12149:4178,Depend,Dependabot,4178,https://hail.is,https://github.com/hail-is/hail/pull/12149,1,['Depend'],['Dependabot']
Integrability,""">#8049</a>/a379e634 backport][3.9] Set cause for ClientPayloadError (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8050"">#8050</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/437ac47fe332106a07a2d5335bb89619f1bc23f7""><code>437ac47</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7995"">#7995</a>/43a5bc50 backport][3.9] Fix examples of <code>fallback_charset_resolver</code>...</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/034e5e34ee11c6138c773d85123490e691e1b708""><code>034e5e3</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8042"">#8042</a>/4b91b530 backport][3.9] Tightening the runtime type check for ssl (...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.9.1...v3.9.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.9.1&new-version=3.9.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` wil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14212:6883,depend,dependency-name,6883,https://hail.is,https://github.com/hail-is/hail/pull/14212,6,['depend'],['dependency-name']
Integrability,""">#9521</a>: Add test coverage to assertion rewrite path.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pytest-dev/pytest/commit/3f12087fe0d86a319216653b08b66a96d400bee2""><code>3f12087</code></a> [pre-commit.ci] auto fixes from pre-commit.com hooks</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/bc3021cdfd76507aa3d9e278bd885da9bc1907b2""><code>bc3021c</code></a> Prepare release version 7.0.1</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/591d476f14e3e83d90fbea75d326a93c5e368708""><code>591d476</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9673"">#9673</a> from nicoddemus/backport-9511</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/6ca733e8f19fa5c4271bf3e5bb295c8b62757e4a""><code>6ca733e</code></a> Enable testing with Python 3.11 (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9511"">#9511</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/ac37b1b1139eaa71b3bcb16b630abfc0223241ef""><code>ac37b1b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9671"">#9671</a> from nicoddemus/backport-9668</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/c891e402ac28f20dd3d018dc25f1ea1a273997be""><code>c891e40</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9672"">#9672</a> from nicoddemus/backport-9669</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/e2753a2b8b55de73adcc992036d0dc52facdbab9""><code>e2753a2</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9669"">#9669</a> from hugovk/ci-only-update-plugin-list-for-upstream</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/b5a154c1d961dbc19a3c00d798de2f27aaa5ace5""><code>b5a154c</cod",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11516:4785,depend,dependabot,4785,https://hail.is,https://github.com/hail-is/hail/pull/11516,3,['depend'],['dependabot']
Integrability,"""><code>0e0e46f</code></a> backport: initialize openssl's legacy provider in rust (<a href=""https://redirect.github.com/pyca/cryptography/issues/10323"">#10323</a>) (<a href=""https://redirect.github.com/pyca/cryptography/issues/10333"">#10333</a>)</li>; <li>See full diff in <a href=""https://github.com/pyca/cryptography/compare/42.0.2...42.0.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=42.0.2&new-version=42.0.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14332:3807,Depend,Dependabot,3807,https://hail.is,https://github.com/hail-is/hail/pull/14332,3,['Depend'],['Dependabot']
Integrability,"""><code>13ca0da</code></a> Fix tox deps inheritance</li>; <li><a href=""https://github.com/pyasn1/pyasn1-modules/commit/00fa3b9d15c783389afee7887f5ba3738a005545""><code>00fa3b9</code></a> Run unittests across many Python versions</li>; <li>Additional commits viewable in <a href=""https://github.com/pyasn1/pyasn1-modules/compare/v0.2.8...v0.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyasn1-modules&package-manager=pip&previous-version=0.2.8&new-version=0.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12928:9569,Depend,Dependabot,9569,https://hail.is,https://github.com/hail-is/hail/pull/12928,1,['Depend'],['Dependabot']
Integrability,"""><code>2ef893a</code></a> Merge <a href=""https://github.com/jaraco/skeleton"">https://github.com/jaraco/skeleton</a></li>; <li><a href=""https://github.com/python/importlib_metadata/commit/97e0293b8bf317b54f49c25add7d44830f9180fe""><code>97e0293</code></a> In _read_egg_info_reqs, when requires.txt exists but is empty, return an empt...</li>; <li>Additional commits viewable in <a href=""https://github.com/python/importlib_metadata/compare/0.1...v4.11.3"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11596:5181,Depend,Dependabot,5181,https://hail.is,https://github.com/hail-is/hail/pull/11596,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"""><code>3bf403e</code></a> deps: update dependency org.apache.httpcomponents:httpcore to v4.4.16 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1786"">#1786</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/java-storage/compare/v1.106.0...v2.16.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.cloud:google-cloud-storage&package-manager=gradle&previous-version=1.106.0&new-version=2.16.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12545:13426,Depend,Dependabot,13426,https://hail.is,https://github.com/hail-is/hail/pull/12545,1,['Depend'],['Dependabot']
Integrability,"""><code>5399bd3</code></a> chore(deps): update dependency google-api-python-client to v2.38.0 (<a href=""https://github-redirect.dependabot.com/googleapis/google-api-python-client/issues/1703"">#1703</a>)</li>; <li><a href=""https://github.com/googleapis/google-api-python-client/commit/8f2c948ddd238726b4af5506e7f44337f21e74c5""><code>8f2c948</code></a> chore(main): release 2.38.0 (<a href=""https://github-redirect.dependabot.com/googleapis/google-api-python-client/issues/1696"">#1696</a>)</li>; <li><a href=""https://github.com/googleapis/google-api-python-client/commit/07bfa5c5308f432272213c6c4a395cc14c4c5b0d""><code>07bfa5c</code></a> chore: Update discovery artifacts (<a href=""https://github-redirect.dependabot.com/googleapis/google-api-python-client/issues/1701"">#1701</a>)</li>; <li><a href=""https://github.com/googleapis/google-api-python-client/commit/58ef3e0171d10c7884523faec8e45907a8ff3032""><code>58ef3e0</code></a> chore: Update discovery artifacts (<a href=""https://github-redirect.dependabot.com/googleapis/google-api-python-client/issues/1700"">#1700</a>)</li>; <li><a href=""https://github.com/googleapis/google-api-python-client/commit/835818d4e815b6e56cab2c554e0938b3342e0519""><code>835818d</code></a> chore: reduce commits in discovery document update PR (<a href=""https://github-redirect.dependabot.com/googleapis/google-api-python-client/issues/1699"">#1699</a>)</li>; <li><a href=""https://github.com/googleapis/google-api-python-client/commit/a47764bc0ee296365e196daa39d038035325d5ed""><code>a47764b</code></a> docs: fix typo and unnecessary word in docstring (<a href=""https://github-redirect.dependabot.com/googleapis/google-api-python-client/issues/1692"">#1692</a>)</li>; <li><a href=""https://github.com/googleapis/google-api-python-client/commit/755cff661f95430dee01e676f63267ae0b97119c""><code>755cff6</code></a> chore(deps): update dependency google-api-python-client to v2.37.0 (<a href=""https://github-redirect.dependabot.com/googleapis/google-api-python-client/issues/1690"">#",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11541:34000,depend,dependabot,34000,https://hail.is,https://github.com/hail-is/hail/pull/11541,1,['depend'],['dependabot']
Integrability,"""><code>5716ad1</code></a> Bump pylint to 2.15.2, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/49b5d5dae6cc49d0572ffa35ae07f46ddc85fa61""><code>49b5d5d</code></a> Upgrade astroid version following 2.12.9 release</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/v2.13.5...v2.15.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pylint&package-manager=pip&previous-version=2.13.5&new-version=2.15.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12240:3086,Depend,Dependabot,3086,https://hail.is,https://github.com/hail-is/hail/pull/12240,1,['Depend'],['Dependabot']
Integrability,"""><code>7178771</code></a> Support changing a target file's relative path in an eachFile action</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/e5af1bd7f9daa8a9222aee0dd1b703727cb5e94e""><code>e5af1bd</code></a> Bump version number to 5.3.0-SNAPSHOT</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/3.2.0...5.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=3.2.0&new-version=5.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12345:5712,depend,dependabot-automerge-start,5712,https://hail.is,https://github.com/hail-is/hail/pull/12345,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"""><code>76dec68</code></a> Add documentation for renderer heading when TOC enabled</li>; <li><a href=""https://github.com/lepture/mistune/commit/799cd118cc5e664b72e98410ce1b68645f1a38c0""><code>799cd11</code></a> Version bump 2.0.2</li>; <li><a href=""https://github.com/lepture/mistune/commit/babb0cfa57a983ead615286a2b7c8f6885c46721""><code>babb0cf</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/lepture/mistune/issues/295"">#295</a> from dairiki/bug.escape_url</li>; <li><a href=""https://github.com/lepture/mistune/commit/fc2cd53d7698e432ab5b250ffac53458263a49e2""><code>fc2cd53</code></a> Make mistune.util.escape_url less aggressive</li>; <li><a href=""https://github.com/lepture/mistune/commit/3e8d35215120ac82176f300dd5e20c0bea5464ea""><code>3e8d352</code></a> Version bump 2.0.1</li>; <li>Additional commits viewable in <a href=""https://github.com/lepture/mistune/compare/v0.8.4...v2.0.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mistune&package-manager=pip&previous-version=0.8.4&new-version=2.0.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` wi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12064:3918,Depend,Dependabot,3918,https://hail.is,https://github.com/hail-is/hail/pull/12064,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"""><code>96a0cdf</code></a> PythonTracebackLexer: minor tweak in docstring</li>; <li><a href=""https://github.com/pygments/pygments/commit/569eea6ee85ec4d679bb38a890c167b58ee727dd""><code>569eea6</code></a> Enable Sphinx nitpicky mode and fix warnings (<a href=""https://redirect.github.com/pygments/pygments/issues/2403"">#2403</a>)</li>; <li><a href=""https://github.com/pygments/pygments/commit/b018a65cb6ef51596c2cb8d6c97f0d79d9fa2ae7""><code>b018a65</code></a> Prepare for next release.</li>; <li>See full diff in <a href=""https://github.com/pygments/pygments/compare/2.15.0...2.15.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pygments&package-manager=pip&previous-version=2.15.0&new-version=2.15.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12909:3914,Depend,Dependabot,3914,https://hail.is,https://github.com/hail-is/hail/pull/12909,1,['Depend'],['Dependabot']
Integrability,"""><code>970cd31</code></a> Bump flake8-bugbear from 22.9.23 to 22.10.25 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/764"">#764</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/bf16648feca6571649849bca65ca1d9b36f8b417""><code>bf16648</code></a> Bump types-redis from 4.3.21.2 to 4.3.21.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/762"">#762</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/07a709a0f408e54b294b28b81968d2b79f188290""><code>07a709a</code></a> Bump redis from 4.3.3 to 4.3.4 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/759"">#759</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp_session/compare/v2.7.0...v2.12.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp-session&package-manager=pip&previous-version=2.7.0&new-version=2.12.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12499:5092,depend,dependency-name,5092,https://hail.is,https://github.com/hail-is/hail/pull/12499,1,['depend'],['dependency-name']
Integrability,"""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/159"">tox-dev/py-filelock#159</a></li>; <li>Bump dependencies by <a href=""https://github.com/gaborbernat""><code>@​gaborbernat</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/160"">tox-dev/py-filelock#160</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/162"">tox-dev/py-filelock#162</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/dependabot""><code>@​dependabot</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/154"">tox-dev/py-filelock#154</a></li>; <li><a href=""https://github.com/jnordberg""><code>@​jnordberg</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/148"">tox-dev/py-filelock#148</a></li>; <li><a href=""https://github.com/DeadNews""><code>@​DeadNews</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/155"">tox-dev/py-filelock#155</a></li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/tox-dev/py-filelock/compare/3.7.1...3.8.0"">https://github.com/tox-dev/py-filelock/compare/3.7.1...3.8.0</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/24b26b6be356de80d7212a9f7621d81c6d3eec8d""><code>24b26b6</code></a> Delete main.pdf</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/f7e72dd59b230b2751b10023851b01655d60bac6""><code>f7e72dd</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/issues/162"">#162</a>)</li>; <li><a href=""https://github.com/tox-dev/py-file",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12157:3887,depend,dependabot,3887,https://hail.is,https://github.com/hail-is/hail/pull/12157,1,['depend'],['dependabot']
Integrability,"""><code>dc7c5a1</code></a> [Storage] API View Feedback For STG84 GA (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25085"">#25085</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/9f66f6bce7d777b34c03dc9a633148acd0c4f238""><code>9f66f6b</code></a> [Storage] Revert removing aiohttp dependency for storage.blob.aio (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25084"">#25084</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/e40d3e1d985cee13a2e0d070fb8e04958905f468""><code>e40d3e1</code></a> [storage.blob] Remove aiohttp as dependency for storage.blob.aio (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/24965"">#24965</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/7915719f211cc1217dfca6f3973a2b1f04c2e3f5""><code>7915719</code></a> [Storage] Prepare for STG83 GA release (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25040"">#25040</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/155eb8b69b3cd2f8ef992cf1436bf2751769ac42""><code>155eb8b</code></a> [Storage] Add <code>progress_hook</code> to file-share upload/download (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/24997"">#24997</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/66dd3bef2d6e531e83cefd65be4cbbf41fcf2531""><code>66dd3be</code></a> [Storage] Fix more flaky lease tests (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25011"">#25011</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/030141734a239fa6fb1aa7a8c43d322c82753510""><code>0301417</code></a> [Storage] Add argument to perf tests to use client-side encryption (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/24978"">#24978</a>)</li>; <li>Additional commits viewable in",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12109:3473,depend,dependabot,3473,https://hail.is,https://github.com/hail-is/hail/pull/12109,1,['depend'],['dependabot']
Integrability,"""><code>dfab9b2</code></a> 👹 Feed the hobgoblins (delint).</li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/757afb5d5f3ada3d954eff981e9279f4e348f1e9""><code>757afb5</code></a> ⚫ Fade to black.</li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/1614724e27124672f723735ff208a59a94d5c252""><code>1614724</code></a> Update changelog</li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/fc04fc95dbcb5008c80e1814d2850de35802420a""><code>fc04fc9</code></a> Merge branch 'main' into cryptodome</li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/799b8da31058a63fd47a1cf1d341e5acbe3a1e8a""><code>799b8da</code></a> Run crypto tests against both crypto implementations.</li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/f36ec65595bc6b59243adc0cb9e5a1a367f1e50b""><code>f36ec65</code></a> Consolidate logic for resolving crypto lib.</li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/3de7f4007c4cf749b97dd3acba4b00d7cf0b55a1""><code>3de7f40</code></a> Remove dependency on deprecated keyring.util.properties. Fixes <a href=""https://github-redirect.dependabot.com/jaraco/keyrings.alt/issues/47"">#47</a>.</li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/010fe59c64ffacbc0f97405d3bf21072d811baf1""><code>010fe59</code></a> Merge <a href=""https://github.com/jaraco/skeleton"">https://github.com/jaraco/skeleton</a></li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/47c2cb324e20f784289496ef3a7b19a1cd23d196""><code>47c2cb3</code></a> Also update release to v4</li>; <li>Additional commits viewable in <a href=""https://github.com/jaraco/keyrings.alt/compare/v3.5.2...v4.2.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=keyrings-alt&package-manager=pip&previous-version=3.5.2&new-version=4.2.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-securit",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12448:2722,depend,dependency,2722,https://hail.is,https://github.com/hail-is/hail/pull/12448,1,['depend'],['dependency']
Integrability,"""><code>f461401</code></a> Silence AsciiLineReader warning when creating a FASTA sequence index (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1559"">#1559</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/1449dec45b4e95293db14595ec0d11a3839bac23""><code>1449dec</code></a> Support loading of CSI from URLs/streams. <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1507"">#1507</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1595"">#1595</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/22aec6782b33f8d169a5d1cf63e952126a3f09e0""><code>22aec67</code></a> Fix decoding of CRAM Scores read feature during normalization. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1592"">#1592</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/samtools/htsjdk/compare/2.24.1...3.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.github.samtools:htsjdk&package-manager=gradle&previous-version=2.24.1&new-version=3.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@depe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12310:8755,Depend,Dependabot,8755,https://hail.is,https://github.com/hail-is/hail/pull/12310,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"""><code>fd80cb7</code></a> [AutoRelease] t2-storage-2021-09-14-45016(Do not merge) (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/20678"">#20678</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/8be2477705853969ceb2d274fcae6f55b266f0e3""><code>8be2477</code></a> [STG78]Address comments (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/20539"">#20539</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/d79015f6078353dcbec65117028014c406108bfa""><code>d79015f</code></a> Check fd is reg file or symlink in get_length before using st_size. (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/19725"">#19725</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/15cd636dd91c9a870667effc0a78aae58992ae37""><code>15cd636</code></a> [Storage] Move test keys into CredScan-suppressed helper files (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/20330"">#20330</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/ae49de0ea62fc45e5a72808db2fd3eec4261d65f""><code>ae49de0</code></a> [Storage]Address comments for STG78 GA (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/20491"">#20491</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/e572c97e53510572b0a515547bb711a9c7282ae5""><code>e572c97</code></a> [Storage]fix live test (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/20463"">#20463</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/d3d7e3e719a079415b0d955112b7e185791b5f0c""><code>d3d7e3e</code></a> Fix type annotation in azure.storage.blob (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/20084"">#20084</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/7e7f55233be72e999ffee255697665921df14f7",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11484:1537,depend,dependabot,1537,https://hail.is,https://github.com/hail-is/hail/pull/11484,2,['depend'],['dependabot']
Integrability,""">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyasn1-modules&package-manager=pip&previous-version=0.3.0&new-version=0.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14472:3438,depend,dependabot,3438,https://hail.is,https://github.com/hail-is/hail/pull/14472,11,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,""">https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-1</a></li>; <li>Click 8.1 changes: <a href=""https://click.palletsprojects.com/en/8.1.x/changes/#version-8-1-0"">https://click.palletsprojects.com/en/8.1.x/changes/#version-8-1-0</a></li>; <li>MarkupSafe 2.1 changes: <a href=""https://markupsafe.palletsprojects.com/en/2.1.x/changes/#version-2-1-1"">https://markupsafe.palletsprojects.com/en/2.1.x/changes/#version-2-1-1</a></li>; <li>ItsDangerous 2.1 changes: <a href=""https://itsdangerous.palletsprojects.com/en/2.1.x/changes/#version-2-1-2"">https://itsdangerous.palletsprojects.com/en/2.1.x/changes/#version-2-1-2</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/flask/blob/main/CHANGES.rst"">flask's changelog</a>.</em></p>; <blockquote>; <h2>Version 2.2.2</h2>; <p>Released 2022-08-08</p>; <ul>; <li>Update Werkzeug dependency to &gt;= 2.2.2. This includes fixes related; to the new faster router, header parsing, and the development; server. :pr:<code>4754</code></li>; <li>Fix the default value for <code>app.env</code> to be <code>&quot;production&quot;</code>. This; attribute remains deprecated. :issue:<code>4740</code></li>; </ul>; <h2>Version 2.2.1</h2>; <p>Released 2022-08-03</p>; <ul>; <li>Setting or accessing <code>json_encoder</code> or <code>json_decoder</code> raises a; deprecation warning. :issue:<code>4732</code></li>; </ul>; <h2>Version 2.2.0</h2>; <p>Released 2022-08-01</p>; <ul>; <li>; <p>Remove previously deprecated code. :pr:<code>4667</code></p>; <ul>; <li>Old names for some <code>send_file</code> parameters have been removed.; <code>download_name</code> replaces <code>attachment_filename</code>, <code>max_age</code>; replaces <code>cache_timeout</code>, and <code>etag</code> replaces <code>add_etags</code>.; Additionally, <code>path</code> replaces <code>filename</code> in; <code>send_from_directory</code>.</li>; <li>The <code>RequestContext.g</code> prop",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12206:5304,rout,router,5304,https://hail.is,https://github.com/hail-is/hail/pull/12206,1,['rout'],['router']
Integrability,""">jpadilla/pyjwt#713</a></li>; <li><a href=""https://github.com/woodruffw""><code>@​woodruffw</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/725"">jpadilla/pyjwt#725</a></li>; <li><a href=""https://github.com/guneybilen""><code>@​guneybilen</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/727"">jpadilla/pyjwt#727</a></li>; <li><a href=""https://github.com/dmahr1""><code>@​dmahr1</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/734"">jpadilla/pyjwt#734</a></li>; <li><a href=""https://github.com/israelabraham""><code>@​israelabraham</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/738"">jpadilla/pyjwt#738</a></li>; <li><a href=""https://github.com/fviard""><code>@​fviard</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/723"">jpadilla/pyjwt#723</a></li>; <li><a href=""https://github.com/akx""><code>@​akx</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/742"">jpadilla/pyjwt#742</a></li>; <li><a href=""https://github.com/hipertracker""><code>@​hipertracker</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/751"">jpadilla/pyjwt#751</a></li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/jpadilla/pyjwt/compare/2.3.0...2.4.0"">https://github.com/jpadilla/pyjwt/compare/2.3.0...2.4.0</a></p>; <h2>2.3.0</h2>; <h2>What's Changed</h2>; <ul>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/700"">jpadilla/pyjwt#700</a></li>; <li>Add exception chaining by <a href=""https://github.com/ehdgua01""><code>@​ehdgua",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11866:7484,depend,dependabot,7484,https://hail.is,https://github.com/hail-is/hail/pull/11866,1,['depend'],['dependabot']
Integrability,""">sphinx's changelog</a>.</em></p>; <blockquote>; <h1>Release 5.1.1 (released Jul 26, 2022)</h1>; <h2>Bugs fixed</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10701"">#10701</a>: Fix ValueError in the new <code>deque</code> based <code>sphinx.ext.napolean</code>; iterator implementation.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10702"">#10702</a>: Restore compatability with third-party builders.</li>; </ul>; <h1>Release 5.1.0 (released Jul 24, 2022)</h1>; <h2>Dependencies</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10656"">#10656</a>: Support <code>Docutils 0.19</code>_. Patch by Adam Turner.</li>; </ul>; <p>.. _Docutils 0.19: <a href=""https://docutils.sourceforge.io/RELEASE-NOTES.html#release-0-19-2022-07-05"">https://docutils.sourceforge.io/RELEASE-NOTES.html#release-0-19-2022-07-05</a></p>; <h2>Deprecated</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10467"">#10467</a>: Deprecated <code>sphinx.util.stemmer</code> in favour of <code>snowballstemmer</code>.; Patch by Adam Turner.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9856"">#9856</a>: Deprecated <code>sphinx.ext.napoleon.iterators</code>.</li>; </ul>; <h2>Features added</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10444"">#10444</a>: html theme: Allow specifying multiple CSS files through the <code>stylesheet</code>; setting in <code>theme.conf</code> or by setting <code>html_style</code> to an iterable of strings.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10366"">#10366</a>: std domain: Add support for emphasising placeholders in :rst:dir:<code>option</code>; directives through a new :confval:<code>option_emphasise_placeholders</code> configuration; option.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12165:2544,depend,dependabot,2544,https://hail.is,https://github.com/hail-is/hail/pull/12165,1,['depend'],['dependabot']
Integrability,"""Invalid Allele"" message when alt ref is <DEL>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3413:17,message,message,17,https://hail.is,https://github.com/hail-is/hail/issues/3413,1,['message'],['message']
Integrability,"""T"", ""A""])]. expr = hl.any(; lambda x:; (mt.locus.contig == hl.literal(x[0])) & \; (mt.locus.position == hl.literal(int(x[1]))) & \; (mt.alleles == hl.literal(x[2])),; variants; ). hl.eval(expr). ```; Leads to the following error (which looks like the bug!):; ```; Traceback (most recent call last):; File ""test.py"", line 10, in <module>; expr = hl.any(lambda x:; File ""/home/edmund/.local/src/hail/hail/python/hail/expr/functions.py"", line 3531, in any; return collection.any(f); File ""<decorator-gen-510>"", line 2, in any; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/hail/python/hail/expr/expressions/typed_expressions.py"", line 68, in any; return hl.array(self).fold(lambda accum, elt: accum | f(elt), False); File ""<decorator-gen-518>"", line 2, in fold; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/hail/python/hail/expr/expressions/typed_expressions.py"", line 221, in fold; return collection._to_stream().fold(lambda x, y: f(x, y), zero); File ""<decorator-gen-650>"", line 2, in fold; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/hail/python/hail/expr/expressions/typed_expressions.py"", line 4522, in fold; body = to_expr(f(accum_ref, elt_ref)); File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 364, in f; ret = x(*args); File ""/home/edmund/.local/src/hail/hail/python/hail/expr/expressions/typed_expressions.py"", line 221, in <lambda>; return collection._to_stream().fold(lambda x, y: f(x, y), zero); File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 364, in f; ret = x(*args); File ""/home/edmund/.local/src/hail/hail/python/hail/expr/expressions/typed_",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13046#issuecomment-1624278982:5884,wrap,wrapper,5884,https://hail.is,https://github.com/hail-is/hail/issues/13046#issuecomment-1624278982,1,['wrap'],['wrapper']
Integrability,"""contract types""? What's that mean?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1813#issuecomment-317562462:1,contract,contract,1,https://hail.is,https://github.com/hail-is/hail/issues/1813#issuecomment-317562462,1,['contract'],['contract']
Integrability,"""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/665"">#665</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/29ddff39290f4e2fbc7b9feb94eb622763e156e2""><code>29ddff3</code></a> Bump pytest-aiohttp from 0.3.0 to 1.0.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/668"">#668</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/3bc517092aff39330f2f96315e6f542e23415831""><code>3bc5170</code></a> Bump multidict from 5.2.0 to 6.0.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/670"">#670</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp_session/compare/v2.7.0...v2.11.0"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11577:5584,depend,dependabot-automerge-start,5584,https://hail.is,https://github.com/hail-is/hail/pull/11577,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1106"">#1106</a>)</li>; </ul>; <h3>Fixes</h3>; <ul>; <li>Remove <strong>del</strong> from Redis (Fixes <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1115"">#1115</a>); (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1227"">#1227</a>)</li>; <li>fix socket.error raises (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1129"">#1129</a>)</li>; <li>Fix buffer is closed error when using PythonParser class; (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1213"">#1213</a>)</li>; </ul>; <h2>2.0.0 - (2021-03-18)</h2>; <h3>Features</h3>; <ul>; <li>; <p>Port redis-py's client implementation to aioredis.<br />; (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/891"">#891</a>)</p>; </li>; <li>; <p>Make hiredis an optional dependency.<br />; (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/917"">#917</a>)</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/224f843bd4b33d657770bded6f86ce33b881257c""><code>224f843</code></a> Release version 2.0.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1247"">#1247</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/a9825c2ac35939b9ad8928e9468335d8efab963f""><code>a9825c2</code></a> Bump py-actions/py-dependency-install from 2.1.0 to 3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1239"">#1239</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/7f65c4ccb0e954c17f2a3e1ecc665c62e4a1aaeb""><code>7f65c4c</code></a> Remove <strong>del</strong> from Redis (Fixes <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1115"">#1115</a>) (<a href=""https://github-redirect.dependabot.com/aio-libs/aio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11569:3548,depend,dependabot,3548,https://hail.is,https://github.com/hail-is/hail/pull/11569,1,['depend'],['dependabot']
Integrability,"""https://github-redirect.dependabot.com/boto/boto3/issues/3499"">#3499</a>)</li>; <li><a href=""https://github.com/boto/boto3/commit/47f20744b3c57223da5e14e185120586f8212af8""><code>47f2074</code></a> Merge branch 'release-1.26.13'</li>; <li><a href=""https://github.com/boto/boto3/commit/3d4081ccb7c350538ba3d6a5073c59575a812eb0""><code>3d4081c</code></a> Merge branch 'release-1.26.13' into develop</li>; <li>Additional commits viewable in <a href=""https://github.com/boto/boto3/compare/1.26.7...1.26.15"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=boto3&package-manager=pip&previous-version=1.26.7&new-version=1.26.15)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12498:9792,depend,dependabot,9792,https://hail.is,https://github.com/hail-is/hail/pull/12498,1,['depend'],['dependabot']
Integrability,"""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/160"">#160</a>)</li>; <li>Adds <code>assert_no_diff</code> helper to assist pytest users (<a href=""https://github.com/joesolly""><code>@​joesolly</code></a>) (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/153"">#153</a>)</li>; <li>Migrates CI to gh-actions (<a href=""https://github.com/ParthS007""><code>@​ParthS007</code></a> <a href=""https://github.com/diegodelemos""><code>@​diegodelemos</code></a>) (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/145"">#145</a>)</li>; <li>Removes dependency on pkg_resources (<a href=""https://github.com/eldruin""><code>@​eldruin</code></a>)</li>; </ul>; <p>Version 0.8.1 (released 2019-12-13)</p>; <ul>; <li>Fix invalid diff output for sets. (<a href=""https://github.com/jirikuncar""><code>@​jirikuncar</code></a> <a href=""https://github.com/danielduhh""><code>@​danielduhh</code></a>) (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/133"">#133</a> <a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/134"">#134</a>)</li>; </ul>; <p>Version 0.8.0 (released 2019-03-17)</p>; <ul>; <li>Respect <code>dot_notation</code> flag in ignore argument (<a href=""https://github.com/yoyonel""><code>@​yoyonel</code></a>) (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/107"">#107</a>)</li>; <li>Adds argument for toggling dot notation in diff. (<a href=""https://github.com/robinchew""><code>@​robinchew</code></a>)</li>; </ul>; <p>Version 0.7.2 (released 2019-02-22)</p>; <ul>; <li>Two NaN values are considered the same, hence they are not shown in <code>diff</code>; output. (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/114"">#114</a>) (<a href=""https://github.com/t-b""><code>@​t-b</code></a>)</li>; <li>Refactors <code>diff</code> method to reduce recursive call stack size. (<a href=""https://github-red",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11485:3023,depend,dependabot,3023,https://hail.is,https://github.com/hail-is/hail/pull/11485,1,['depend'],['dependabot']
Integrability,"""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92667"">kubernetes/kubernetes#92667</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>) [SIG API Machinery and Testing]</li>; <li>CertificateSigningRequest API conditions were updated:; <ul>; <li>a <code>status</code> field was added; this field defaults to <code>True</code>, and may only be set to <code>True</code> for <code>Approved</code>, <code>Denied</code>, and <code>Failed</code> conditions</li>; <li>a <code>lastTransitionTime</code> field was added</li>; <li>a <code>Failed</code> condition type was added to allow signers to indicate permanent failure; this condition can be added via the <code>certificatesigningrequests/status</code> subresource.</li>; <li><code>Approved</code> and <code>Denied</code> conditions are mutually exclusive</li>; <li><code>Approved</code>, <code>Denied</code>, and <code>Failed</code> conditions can no longer be removed from a CSR (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/90191"">kubernetes/kubernetes#90191</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>) [SIG API Machinery, Apps, Auth, CLI and Node]</li>; </ul>; </li>; <li>Cluster admins can now turn off /logs endpoint in kubelet by setting enableSystemLogHandler to false in their kubelet configuration file. enableSystemLogHandler can be set to true only when enableDebuggingHandlers is also set to true. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/87273"">kubernetes/kubernetes#87273</a>, <a href=""https://github.com/SaranBalaji90""><code>@​SaranBalaji90</code></a>) [SIG Node]</li>; <li>Custom Endpoints are now mirrored to EndpointSlices by a new EndpointSliceMirroring controller. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91637"">kubernetes/kubernetes#91637</a>, <a href=""https://github.com/robscott""><code>@​robscott</code></a>) [SIG API Machinery, Apps, Auth, Cloud Provider, Instrumentati",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:4832,depend,dependabot,4832,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['depend'],['dependabot']
Integrability,"""https://github-redirect.dependabot.com/lepture/mistune/issues/307"">#307</a> from jieter/patch-1</li>; <li><a href=""https://github.com/lepture/mistune/commit/0eba47196a81453bafe1f2492748a87475063dff""><code>0eba471</code></a> Fix typo in guide.rst</li>; <li><a href=""https://github.com/lepture/mistune/commit/61e9337884e20f9f8fdc0b7788d319afdd259729""><code>61e9337</code></a> Fix table plugin</li>; <li><a href=""https://github.com/lepture/mistune/commit/76dec68c4514c2612ef9263b49c6ec7f4d77bd14""><code>76dec68</code></a> Add documentation for renderer heading when TOC enabled</li>; <li>Additional commits viewable in <a href=""https://github.com/lepture/mistune/compare/v0.8.4...v2.0.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mistune&package-manager=pip&previous-version=0.8.4&new-version=2.0.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12066:4222,depend,dependabot-security-updates,4222,https://hail.is,https://github.com/hail-is/hail/pull/12066,2,['depend'],['dependabot-security-updates']
Integrability,"""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2301"">#2301</a> from jeff-m-sullivan/rscript-path</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/d65016042b67d09139876e1903e839a168dfa7c3""><code>d650160</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2252"">#2252</a> from daschuer/worktree_fix</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/fd0177ae3ae5f94b36aafb54ab496f76fcead7b9""><code>fd0177a</code></a> implement default_install_hook_types</li>; <li>Additional commits viewable in <a href=""https://github.com/pre-commit/pre-commit/compare/v2.17.0...v2.18.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pre-commit&package-manager=pip&previous-version=2.17.0&new-version=2.18.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11731:13141,depend,dependabot-security-updates,13141,https://hail.is,https://github.com/hail-is/hail/pull/11731,1,['depend'],['dependabot-security-updates']
Integrability,"""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2312"">#2312</a> PR by <a href=""https://github.com/mblayman""><code>@​mblayman</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2311"">#2311</a> issue by <a href=""https://github.com/mblayman""><code>@​mblayman</code></a>.</li>; </ul>; </li>; <li>Upgrade <code>ruby-build</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2319"">#2319</a> PR by <a href=""https://github.com/jalessio""><code>@​jalessio</code></a>.</li>; </ul>; </li>; <li>Add top level <code>default_install_hook_types</code> which will be installed when; <code>--hook-types</code> is not specified in <code>pre-commit install</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2322"">#2322</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; </ul>; <h3>Fixes</h3>; <ul>; <li>Fix typo in help message for <code>--from-ref</code> and <code>--to-ref</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2266"">#2266</a> PR by <a href=""https://github.com/leetrout""><code>@​leetrout</code></a>.</li>; </ul>; </li>; <li>Prioritize binary builds for R dependencies.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2277"">#2277</a> PR by <a href=""https://github.com/lorenzwalthert""><code>@​lorenzwalthert</code></a>.</li>; </ul>; </li>; <li>Fix handling of git worktrees.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2252"">#2252</a> PR by <a href=""https://github.com/daschuer""><code>@​daschuer</code></a>.</li>; </ul>; </li>; <li>Fix handling of <code>$R_HOME</code> for R hooks.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2301"">#2301</a> PR by <a href=""https://github.com/jeff-m-sullivan""><code>@​jeff-m-sullivan</code></a>.</",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11731:8078,message,message,8078,https://hail.is,https://github.com/hail-is/hail/pull/11731,1,['message'],['message']
Integrability,"""https://github.com/Klavionik""><code>@​Klavionik</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/668"">jpadilla/pyjwt#668</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/684"">jpadilla/pyjwt#684</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/686"">jpadilla/pyjwt#686</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/689"">jpadilla/pyjwt#689</a></li>; <li>Remove upper bound on cryptography version by <a href=""https://github.com/riconnon""><code>@​riconnon</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/693"">jpadilla/pyjwt#693</a></li>; <li>Add support for Ed448/EdDSA. by <a href=""https://github.com/dajiaji""><code>@​dajiaji</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/675"">jpadilla/pyjwt#675</a></li>; <li>Chore: inline Variables that immediately Returned by <a href=""https://github.com/yezz123""><code>@​yezz123</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/690"">jpadilla/pyjwt#690</a></li>; <li>Use timezone package as Python 3.5+ is required by <a href=""https://github.com/kkirsche""><code>@​kkirsche</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/694"">jpadilla/pyjwt#694</a></li>; <li>Bump up version to v2.2.0 by <a href=""https://github.com/jpadilla""><code>@​jpadilla</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/697"">jpadilla/pyjwt#697</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/TPXP",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11457:5314,depend,dependabot,5314,https://hail.is,https://github.com/hail-is/hail/pull/11457,1,['depend'],['dependabot']
Integrability,"""https://github.com/PyCQA/flake8/commit/d7baba5f14091e7975d2abb3ba9bf321b5be6102""><code>d7baba5</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pycqa/flake8/issues/1406"">#1406</a> from asottile/update-versions</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/d79021aafc809d999c4cbbc0a513a5ceb473efa2""><code>d79021a</code></a> update dependency versions</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/283f0c81241673221d9628beb11e2d7356826f00""><code>283f0c8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pycqa/flake8/issues/1404"">#1404</a> from PyCQA/drop-xdg-config</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/807904aebc20814ac595b0004ab526fffb5ef681""><code>807904a</code></a> Drop support for Home and XDG config files</li>; <li>Additional commits viewable in <a href=""https://github.com/pycqa/flake8/compare/3.8.3...4.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=flake8&package-manager=pip&previous-version=3.8.3&new-version=4.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` wil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11456:2236,Depend,Dependabot,2236,https://hail.is,https://github.com/hail-is/hail/pull/11456,4,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"""https://github.com/aio-libs/aiohttp-jinja2/commit/3ccaf1f39faea4751ceeaa43c242b5f5512d52dc""><code>3ccaf1f</code></a> Auto-merge again (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_jinja2/issues/471"">#471</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-jinja2/commit/56a314431277a964d20f5deb008df5fe52d80622""><code>56a3144</code></a> Remove if (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_jinja2/issues/469"">#469</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-jinja2/commit/91c004dd135b18c3ffbc69646fc7f8706273e866""><code>91c004d</code></a> Auto-merge (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_jinja2/issues/468"">#468</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp_jinja2/compare/v1.1.1...v1.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp-jinja2&package-manager=pip&previous-version=1.1.1&new-version=1.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` wi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11576:6548,depend,dependency-name,6548,https://hail.is,https://github.com/hail-is/hail/pull/11576,1,['depend'],['dependency-name']
Integrability,"""https://github.com/aio-libs/aiohttp-jinja2/commit/56a314431277a964d20f5deb008df5fe52d80622""><code>56a3144</code></a> Remove if (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_jinja2/issues/469"">#469</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-jinja2/commit/91c004dd135b18c3ffbc69646fc7f8706273e866""><code>91c004d</code></a> Auto-merge (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_jinja2/issues/468"">#468</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp_jinja2/compare/v1.1.1...v1.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp-jinja2&package-manager=pip&previous-version=1.1.1&new-version=1.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11576:6771,Depend,Dependabot,6771,https://hail.is,https://github.com/hail-is/hail/pull/11576,1,['Depend'],['Dependabot']
Integrability,"""https://github.com/aio-libs/aiohttp-session/commit/970cd31ce41162d9893c975f05e7082d32a4cece""><code>970cd31</code></a> Bump flake8-bugbear from 22.9.23 to 22.10.25 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/764"">#764</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/bf16648feca6571649849bca65ca1d9b36f8b417""><code>bf16648</code></a> Bump types-redis from 4.3.21.2 to 4.3.21.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/762"">#762</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/07a709a0f408e54b294b28b81968d2b79f188290""><code>07a709a</code></a> Bump redis from 4.3.3 to 4.3.4 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/759"">#759</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp_session/compare/v2.7.0...v2.12.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp-session&package-manager=pip&previous-version=2.7.0&new-version=2.12.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12499:4993,Depend,Dependabot,4993,https://hail.is,https://github.com/hail-is/hail/pull/12499,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"""https://github.com/blink1073""><code>@​blink1073</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1774"">jupyter/nbconvert#1774</a></li>; <li>Switch to hatch build backend by <a href=""https://github.com/blink1073""><code>@​blink1073</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1777"">jupyter/nbconvert#1777</a></li>; <li>switch from entrypoints to importlib-metadata by <a href=""https://github.com/konstin""><code>@​konstin</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1782"">jupyter/nbconvert#1782</a></li>; <li>Add recursive flag for glob notebook search by <a href=""https://github.com/paoloalba""><code>@​paoloalba</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1785"">jupyter/nbconvert#1785</a></li>; <li>Updates for sphinx 5.0 support by <a href=""https://github.com/blink1073""><code>@​blink1073</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1788"">jupyter/nbconvert#1788</a></li>; <li>Fixed unique div ids in lab template, fixed <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/issues/1759"">#1759</a> by <a href=""https://github.com/veghdev""><code>@​veghdev</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1761"">jupyter/nbconvert#1761</a></li>; <li>WebPDFExporter: Emulate media print by <a href=""https://github.com/martinRenou""><code>@​martinRenou</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1791"">jupyter/nbconvert#1791</a></li>; <li>Fix fonts overriden by user stylesheet by inheriting styles by <a href=""https://github.com/dakoop""><code>@​dakoop</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1793"">jupyter/nbconvert#1793</a></li>; <li>Fix lab template output alignment by <a href=""https://github.com/dakoop""><code>@​dakoop</code></a> in <a href=""https://github-redirect.dep",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12126:1552,depend,dependabot,1552,https://hail.is,https://github.com/hail-is/hail/pull/12126,1,['depend'],['dependabot']
Integrability,"""https://github.com/johachi""><code>@​johachi</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/654"">jpadilla/pyjwt#654</a></li>; <li>Ignore coverage files generated during test runs by <a href=""https://github.com/makusu2""><code>@​makusu2</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/617"">jpadilla/pyjwt#617</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/656"">jpadilla/pyjwt#656</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/658"">jpadilla/pyjwt#658</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/667"">jpadilla/pyjwt#667</a></li>; <li>Fix aud validation to support {'aud': null} case. by <a href=""https://github.com/dajiaji""><code>@​dajiaji</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/670"">jpadilla/pyjwt#670</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/678"">jpadilla/pyjwt#678</a></li>; <li>Prefer headers['alg'] to algorithm parameter in encode(). by <a href=""https://github.com/dajiaji""><code>@​dajiaji</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/673"">jpadilla/pyjwt#673</a></li>; <li>DOC: Clarify RSA encoding and decoding depend on the cryptography package by <a href=""https://github.com/TPXP""><code>@​TPXP</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/664"">jpadilla/pyjwt#664</a></li>; <li>Mak",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11457:2848,depend,dependabot,2848,https://hail.is,https://github.com/hail-is/hail/pull/11457,1,['depend'],['dependabot']
Integrability,"""https://github.com/jpadilla/pyjwt/releases"">pyjwt's releases</a>.</em></p>; <blockquote>; <h2>2.4.0</h2>; <h2>Security</h2>; <ul>; <li>[CVE-2022-29217] Prevent key confusion through non-blocklisted public key formats. <a href=""https://github.com/jpadilla/pyjwt/security/advisories/GHSA-ffqj-6fqr-9h24"">https://github.com/jpadilla/pyjwt/security/advisories/GHSA-ffqj-6fqr-9h24</a></li>; </ul>; <h2>What's Changed</h2>; <ul>; <li>Add support for Python 3.10 by <a href=""https://github.com/hugovk""><code>@​hugovk</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/699"">jpadilla/pyjwt#699</a></li>; <li>Don't use implicit optionals by <a href=""https://github.com/rekyungmin""><code>@​rekyungmin</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/705"">jpadilla/pyjwt#705</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/708"">jpadilla/pyjwt#708</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/710"">jpadilla/pyjwt#710</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/711"">jpadilla/pyjwt#711</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/712"">jpadilla/pyjwt#712</a></li>; <li>documentation fix: show correct scope for decode_complete() by <a href=""https://github.com/sseering""><code>@​sseering</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/661"">jpadilla/pyjwt#661</a></li>; <li>[pre-commit.ci] p",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11866:1139,depend,dependabot,1139,https://hail.is,https://github.com/hail-is/hail/pull/11866,1,['depend'],['dependabot']
Integrability,"""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2834"">cbeust/testng#2834</a></li>; <li>Avoid Compilation errors on Semeru JDK flavour. by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2835"">cbeust/testng#2835</a></li>; <li>Add addition yml extension by <a href=""https://github.com/speedythesnail""><code>@​speedythesnail</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2837"">cbeust/testng#2837</a></li>; <li>Support getting dependencies info for a test by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2839"">cbeust/testng#2839</a></li>; <li>Honour regex in dependsOnMethods by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2838"">cbeust/testng#2838</a></li>; <li>Ensure All tests run all the time by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2842"">cbeust/testng#2842</a></li>; <li>Deprecate support for running Spock Tests by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2846"">cbeust/testng#2846</a></li>; <li>Streamline dependsOnMethods for configurations by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2845"">cbeust/testng#2845</a></li>; <li>Ensure ITestContext available for JUnit4 tests by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2848"">cbeust/testng#2848</a></li>; <li>Deprecate support for runni",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:6827,depend,dependabot,6827,https://hail.is,https://github.com/hail-is/hail/pull/12665,1,['depend'],['dependabot']
Integrability,"""https://github.com/luhn""><code>@​luhn</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/806"">oauthlib/oauthlib#806</a></li>; <li>GitHub Action to lint Python code by <a href=""https://github.com/cclauss""><code>@​cclauss</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/797"">oauthlib/oauthlib#797</a></li>; <li>Docs: fix Sphinx warnings for better ReadTheDocs generation by <a href=""https://github.com/JonathanHuot""><code>@​JonathanHuot</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/807"">oauthlib/oauthlib#807</a></li>; <li>Allow non-HTTPS issuer when OAUTHLIB_INSECURE_TRANSPORT. by <a href=""https://github.com/luhn""><code>@​luhn</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/803"">oauthlib/oauthlib#803</a></li>; <li>chore: fix typo in test by <a href=""https://github.com/tamanobi""><code>@​tamanobi</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/816"">oauthlib/oauthlib#816</a></li>; <li>Fix typo in server.rst by <a href=""https://github.com/NemanjaT""><code>@​NemanjaT</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/819"">oauthlib/oauthlib#819</a></li>; <li>Fixed isort imports by <a href=""https://github.com/dasm""><code>@​dasm</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/820"">oauthlib/oauthlib#820</a></li>; <li>docs: Fix a few typos by <a href=""https://github.com/timgates42""><code>@​timgates42</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/822"">oauthlib/oauthlib#822</a></li>; <li>docs: fix typos by <a href=""https://github.com/kianmeng""><code>@​kianmeng</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/823"">oauthlib/oauthlib#823</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/ariebovenberg""><code>@​ariebovenberg</code></a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12197:2085,depend,dependabot,2085,https://hail.is,https://github.com/hail-is/hail/pull/12197,2,['depend'],['dependabot']
Integrability,"""https://github.com/mblayman""><code>@​mblayman</code></a>.</li>; </ul>; </li>; <li>Upgrade <code>ruby-build</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2319"">#2319</a> PR by <a href=""https://github.com/jalessio""><code>@​jalessio</code></a>.</li>; </ul>; </li>; <li>Add top level <code>default_install_hook_types</code> which will be installed when; <code>--hook-types</code> is not specified in <code>pre-commit install</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2322"">#2322</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; </ul>; <h3>Fixes</h3>; <ul>; <li>Fix typo in help message for <code>--from-ref</code> and <code>--to-ref</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2266"">#2266</a> PR by <a href=""https://github.com/leetrout""><code>@​leetrout</code></a>.</li>; </ul>; </li>; <li>Prioritize binary builds for R dependencies.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2277"">#2277</a> PR by <a href=""https://github.com/lorenzwalthert""><code>@​lorenzwalthert</code></a>.</li>; </ul>; </li>; <li>Fix handling of git worktrees.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2252"">#2252</a> PR by <a href=""https://github.com/daschuer""><code>@​daschuer</code></a>.</li>; </ul>; </li>; <li>Fix handling of <code>$R_HOME</code> for R hooks.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2301"">#2301</a> PR by <a href=""https://github.com/jeff-m-sullivan""><code>@​jeff-m-sullivan</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2300"">#2300</a> issue by <a href=""https://github.com/jeff-m-sullivan""><code>@​jeff-m-sullivan</code></a>.</li>; </ul>; </li>; <li>Fix a rare race condition in change stashing.; <ul>; <li><a hr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11731:8373,depend,dependencies,8373,https://hail.is,https://github.com/hail-is/hail/pull/11731,1,['depend'],['dependencies']
Integrability,"""https://github.com/pallets/click/commit/3c301ebacbfe8ec7dc3d9d46ebf517082a8ee4b1""><code>3c301eb</code></a> release version 8.1.1</li>; <li><a href=""https://github.com/pallets/click/commit/d5741a2ca2ebc21d525c903f628b1bebad75b735""><code>d5741a2</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2233"">#2233</a> from henryiii/henryiii/fix/commandtype</li>; <li>Additional commits viewable in <a href=""https://github.com/pallets/click/compare/8.0.4...8.1.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=click&package-manager=pip&previous-version=8.0.4&new-version=8.1.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11801:7223,depend,dependabot,7223,https://hail.is,https://github.com/hail-is/hail/pull/11801,1,['depend'],['dependabot']
Integrability,"""https://github.com/plotly/plotly.py/commit/4823ed33db0d7769079c6fd53ae3b2d839321676""><code>4823ed3</code></a> Bump shell-quote in /packages/javascript/jupyterlab-plotly</li>; <li><a href=""https://github.com/plotly/plotly.py/commit/90e540a6906567e825ad4e7840d218a3f0894ce5""><code>90e540a</code></a> Bump terser in /packages/javascript/jupyterlab-plotly</li>; <li><a href=""https://github.com/plotly/plotly.py/commit/7416be0f27a6530899de6ca518e95a67279c0eef""><code>7416be0</code></a> Bump moment in /packages/javascript/jupyterlab-plotly</li>; <li><a href=""https://github.com/plotly/plotly.py/commit/04cde137943b334bfb2c2706accd35d217c05fd4""><code>04cde13</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/issues/3818"">#3818</a> from plotly/docs-5-10</li>; <li>Additional commits viewable in <a href=""https://github.com/plotly/plotly.py/compare/v5.5.0...v5.10.0"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12113:7797,Depend,Dependabot,7797,https://hail.is,https://github.com/hail-is/hail/pull/12113,1,['Depend'],['Dependabot']
Integrability,"""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-h4h5-3hr4-j3g2"">Security Advisory for Java users</a></li>; </ul>; <h2>Protocol Buffers v3.20.2</h2>; <h1>C++</h1>; <ul>; <li>Reduce memory consumption of MessageSet parsing</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf"">Security Advisory for C++ and Python users</a></li>; </ul>; <h2>Protocol Buffers v3.20.1</h2>; <h1>PHP</h1>; <ul>; <li>Fix building packaged PHP extension (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9727"">#9727</a>)</li>; <li>Fixed composer.json to only advertise compatibility with PHP 7.0+. (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9819"">#9819</a>)</li>; </ul>; <h1>Ruby</h1>; <ul>; <li>Disable the aarch64 build on macOS until it can be fixed. (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9816"">#9816</a>)</li>; </ul>; <h1>Other</h1>; <ul>; <li>Fix versioning issues in 3.20.0</li>; </ul>; <h2>Protocol Buffers v3.20.1-rc1</h2>; <p>#PHP</p>; <ul>; <li>Fix building packaged PHP extension (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9727"">#9727</a>)</li>; </ul>; <p>#Other</p>; <ul>; <li>Fix versioning issues in 3.20.0</li>; </ul>; <h2>Protocol Buffers v3.20.0</h2>; <p>2022-03-25 version 3.20.0 (C++/Java/Python/PHP/Objective-C/C#/Ruby/JavaScript)</p>; <h1>Ruby</h1>; <ul>; <li>Dropped Ruby 2.3 and 2.4 support for CI and releases. (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9311"">#9311</a>)</li>; <li>Added Ruby 3.1 support for CI and releases (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9566"">#9566</a>).</li>; <li>Message.decode/encode: Add recursion_limit option (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9218"">#9218</a>/<a href=""https://github-redirect.dep",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12563:2162,protocol,protocolbuffers,2162,https://hail.is,https://github.com/hail-is/hail/pull/12563,1,['protocol'],['protocolbuffers']
Integrability,"""https://github.com/pytest-dev/pytest-asyncio/commit/13d4b79f7ff0d9d0ea70880b3276f85dea7f1f15""><code>13d4b79</code></a> Remove unused function <code>_removesuffix</code></li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/cdd2c4906835b6f627d681fbee5d487554884e5f""><code>cdd2c49</code></a> Use <code>FixtureRequest</code> instead of <code>SubRequest</code></li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/c3429fa4d72239be9b428342f0f1407e0840b9ec""><code>c3429fa</code></a> Build(deps): Bump packaging from 23.2 to 24.0 in /dependencies/docs</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/5f2338dfc9f9b5ac2c27d3bef490fa3e2cd7c156""><code>5f2338d</code></a> Build(deps): Bump pypa/gh-action-pypi-publish from 1.8.12 to 1.8.14</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/726c6e0f3c185f10d8a842bcd1d781de32a3b2f5""><code>726c6e0</code></a> Build(deps): Bump coverage from 7.4.3 to 7.4.4 in /dependencies/default</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/8bd8288709717165b352c7f2f207c8e4ef624a01""><code>8bd8288</code></a> Build(deps): Bump pytest from 8.0.2 to 8.1.1 in /dependencies/default</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/ef3b3477070d6a270e1bb2c1d438c64dba42724c""><code>ef3b347</code></a> Build(deps): Bump packaging from 23.2 to 24.0 in /dependencies/default</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/b22d84e1f0d53920352be4c66d1b6c7f7a9ce005""><code>b22d84e</code></a> [docs] Fixes the example showing how to run all tests in a session-scoped loop.</li>; <li>Additional commits viewable in <a href=""https://github.com/pytest-dev/pytest-asyncio/compare/v0.21.1...v0.23.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest-asyncio&package-manager=pip&previous-version=0.21.1&new-version=0.23.6)]",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14507:8369,depend,dependencies,8369,https://hail.is,https://github.com/hail-is/hail/pull/14507,1,['depend'],['dependencies']
Integrability,"""https://github.com/pytest-dev/pytest-asyncio/commit/150f29c107fbd76641de47e040d43840769ef92c""><code>150f29c</code></a> Build(deps): Bump hypothesis in /dependencies/default (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/427"">#427</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/adc88090f341d9872e9e9b4d22a94cdadf60b3bc""><code>adc8809</code></a> Build(deps): Bump typing-extensions in /dependencies/default (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/425"">#425</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/4abf9d1df228ed8b083721d7affa73e4a08d13c3""><code>4abf9d1</code></a> Build(deps): Bump zipp from 3.8.1 to 3.9.0 in /dependencies/default (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/424"">#424</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/eb487bcb076f44dedcdb33e74972bf06c37027ee""><code>eb487bc</code></a> Build(deps): Bump hypothesis in /dependencies/default (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/423"">#423</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/907c461f172e52159a595e2592176c7feac04a43""><code>907c461</code></a> Refactor pytest_pycollect_makeitems (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/421"">#421</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/d45ab217c80117854b510edc6c9fdd457b6b07fc""><code>d45ab21</code></a> feat: Add deprecation warning for pytest &lt; 7. (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/420"">#420</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/cab20f4d346e9e52e5ffc93854de3ec881e7d342""><code>cab20f4</code></a> Build(deps): Bump importlib-metadata in /dependencies/default (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/415""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12390:5381,depend,dependencies,5381,https://hail.is,https://github.com/hail-is/hail/pull/12390,1,['depend'],['dependencies']
Integrability,"""https://github.com/tox-dev/py-filelock/commit/558c67f85a6f23b22831e81d792bb21471c12393""><code>558c67f</code></a> Bump build dependencies</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/fc2edee8ecf5d4eae99e6e7502671a094e9d60d2""><code>fc2edee</code></a> Bump dependencies</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/3b3f562be03ae963dadd1360a04b430e37b4bfd9""><code>3b3f562</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/issues/159"">#159</a>)</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/e3894f669319c4371cd398f39fe99c57c8395212""><code>e3894f6</code></a> Check 3.11 support (<a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/issues/158"">#158</a>)</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/1957538dea683fda4cca8650efd35b97ccab04ab""><code>1957538</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/issues/157"">#157</a>)</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/e6c1a64d24eb9f1524cc0464bf6acd87a82b08fd""><code>e6c1a64</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/issues/156"">#156</a>)</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/fbf0e45745556f508b0861f370ba8af13a09d07e""><code>fbf0e45</code></a> Add funding</li>; <li>Additional commits viewable in <a href=""https://github.com/tox-dev/py-filelock/compare/3.7.1...3.8.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=filelock&package-manager=pip&previous-version=3.7.1&new-version=3.8.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12157:6002,depend,dependabot,6002,https://hail.is,https://github.com/hail-is/hail/pull/12157,1,['depend'],['dependabot']
Integrability,"""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8534"">#8534</a>) (<a href=""https://github.com/vitejs/vite/commit/c0d6c60"">c0d6c60</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8534"">#8534</a></li>; </ul>; <h2><!-- raw HTML omitted -->2.9.11 (2022-06-10)<!-- raw HTML omitted --></h2>; <ul>; <li>fix: respect server.headers in static middlewares (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8481"">#8481</a>) (<a href=""https://github.com/vitejs/vite/commit/ab7dc1c"">ab7dc1c</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8481"">#8481</a></li>; <li>fix(dev): avoid FOUC when swapping out link tag (fix <a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/7973"">#7973</a>) (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8495"">#8495</a>) (<a href=""https://github.com/vitejs/vite/commit/01fa807"">01fa807</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/7973"">#7973</a> <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8495"">#8495</a></li>; </ul>; <h2><!-- raw HTML omitted -->2.9.10 (2022-06-06)<!-- raw HTML omitted --></h2>; <ul>; <li>feat: treat Astro file scripts as TS (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8151"">#8151</a>) (<a href=""https://github.com/vitejs/vite/commit/9fdd0a3"">9fdd0a3</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8151"">#8151</a></li>; <li>feat: new hook <code>configurePreviewServer</code> (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/7658"">#7658</a>) (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8437"">#8437</a>) (<a href=""https://github.com/vitejs/vite/commit/7b972bc"">7b972bc</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/7658"">#7658</a> <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8437"">#8437</a><",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12142:3401,depend,dependabot,3401,https://hail.is,https://github.com/hail-is/hail/pull/12142,2,['depend'],['dependabot']
Integrability,"""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8805"">#8805</a>) (<a href=""https://github.com/vitejs/vite/commit/e109d64"">e109d64</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8498"">#8498</a> <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8805"">#8805</a></li>; <li>fix(wasm): support decoding data URL in Node &lt; v16 (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8668"">#8668</a>) (<a href=""https://github.com/vitejs/vite/commit/1afc1c2"">1afc1c2</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8668"">#8668</a></li>; </ul>; <h2><!-- raw HTML omitted -->2.9.12 (2022-06-10)<!-- raw HTML omitted --></h2>; <ul>; <li>fix: outdated optimized dep removed from module graph (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8534"">#8534</a>) (<a href=""https://github.com/vitejs/vite/commit/c0d6c60"">c0d6c60</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8534"">#8534</a></li>; </ul>; <h2><!-- raw HTML omitted -->2.9.11 (2022-06-10)<!-- raw HTML omitted --></h2>; <ul>; <li>fix: respect server.headers in static middlewares (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8481"">#8481</a>) (<a href=""https://github.com/vitejs/vite/commit/ab7dc1c"">ab7dc1c</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8481"">#8481</a></li>; <li>fix(dev): avoid FOUC when swapping out link tag (fix <a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/7973"">#7973</a>) (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8495"">#8495</a>) (<a href=""https://github.com/vitejs/vite/commit/01fa807"">01fa807</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/7973"">#7973</a> <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8495"">#8495</a></li>; </ul>; <h2><!-- raw HTML omitted -->2.9.10 (2022-06-06)<!-- raw",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12142:2597,depend,dependabot,2597,https://hail.is,https://github.com/hail-is/hail/pull/12142,2,['depend'],['dependabot']
Integrability,"""https://redirect.github.com/Textualize/rich/issues/3104"">#3104</a> (<a href=""https://redirect.github.com/Textualize/rich/issues/3105"">#3105</a>)</li>; <li><a href=""https://github.com/Textualize/rich/commit/9f620dc50c0008c35e9f8493f198e6e593574a70""><code>9f620dc</code></a> Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3191"">#3191</a> from Textualize/assorted-docs-and-tidying</li>; <li>Additional commits viewable in <a href=""https://github.com/Textualize/rich/compare/v12.6.0...v13.7.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=rich&package-manager=pip&previous-version=12.6.0&new-version=13.7.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14012:7964,depend,dependabot-automerge-start,7964,https://hail.is,https://github.com/hail-is/hail/pull/14012,4,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"""https://redirect.github.com/Textualize/rich/issues/3105"">#3105</a>)</li>; <li><a href=""https://github.com/Textualize/rich/commit/9f620dc50c0008c35e9f8493f198e6e593574a70""><code>9f620dc</code></a> Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3191"">#3191</a> from Textualize/assorted-docs-and-tidying</li>; <li>Additional commits viewable in <a href=""https://github.com/Textualize/rich/compare/v12.6.0...v13.7.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=rich&package-manager=pip&previous-version=12.6.0&new-version=13.7.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14012:8054,Depend,Dependabot,8054,https://hail.is,https://github.com/hail-is/hail/pull/14012,2,['Depend'],['Dependabot']
Integrability,"""https://redirect.github.com/bartdag/py4j/issues/481"">#481</a>)</li>; <li><a href=""https://github.com/py4j/py4j/commit/64ba89c5a680218d682161a4a6d952a969d1299b""><code>64ba89c</code></a> Add explanations for releasing Py4J for eclipse. Convert .txt to .md (<a href=""https://redirect.github.com/bartdag/py4j/issues/479"">#479</a>)</li>; <li>See full diff in <a href=""https://github.com/bartdag/py4j/compare/0.10.9.5...0.10.9.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=py4j&package-manager=pip&previous-version=0.10.9.5&new-version=0.10.9.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12978:2916,depend,dependabot-automerge-start,2916,https://hail.is,https://github.com/hail-is/hail/pull/12978,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"""response_status"": 200, ""response_size"": 158, ""request_header"": {""Referer"": ""-"", ""User-Agent"": ""Python/3.6 aiohttp/3.5.4""}}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:34,957"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""cancel:862"", ""message"": ""batch 9 cancelled""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:34,958"", ""filename"": ""web_log.py"", ""funcNameAndLine"": ""log:233"", ""message"": ""10.32.4.199 [11/Jul/2019:14:19:34 +0000] \""PATCH /api/v1alpha/batches/9/cancel HTTP/1.1\"" 200 158 \""-\"" \""Python/3.6 aiohttp/3.5.4\"""", ""remote_address"": ""10.32.4.199"", ""request_start_time"": ""[11/Jul/2019:14:19:34 +0000]"", ""first_request_line"": ""PATCH /api/v1alpha/batches/9/cancel HTTP/1.1"", ""response_status"": 200, ""response_size"": 158, ""request_header"": {""Referer"": ""-"", ""User-Agent"": ""Python/3.6 aiohttp/3.5.4""}}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:34,967"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1145"", ""message"": ""update job (9, 1, 'main') with pod batch-9-job-1-c8b9b2""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:34,969"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""set_state:501"", ""message"": ""job (9, 1, 'main') changed state: Ready -> Cancelled""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:34,974"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""_delete_pvc:251"", ""message"": ""deleting persistent volume claim batch-9-job-1-c8b9b2""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:34,976"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1145"", ""message"": ""update job (9, 1, 'main') with pod batch-9-job-1-c8b9b2""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:34,977"", ""filename"": ""web_log.py"", ""funcNameAndLine"": ""log:233"", ""message"": ""10.32.4.199 [11/Jul/2019:14:19:34 +0000] \""GET /api/v1alpha/batches/9 HTTP/1.1\"" 200 279 \""-\"" \""Python/3.6 aiohttp/3.5.4\"""", ""remote_address"": ""10.32.4.199"", ""request_start_time"": ""[11/Jul/2019:14:19:34 +0000]"", ""first_request_line"": ""GET /api/v1alpha/batches/9 HTTP/1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6617:2717,message,message,2717,https://hail.is,https://github.com/hail-is/hail/issues/6617,1,['message'],['message']
Integrability,# Batch Inter-Job File Dependencies. The important addition of this PR is a `copy_service_account_name` field on batch jobs that permits the client to authorize with some GCP credentials stored in a k8s secret. The copy pods and the main pod only share the `/io` folder (k8s forbids mounting a volume as `/`). This interface is pretty onerous. Pipelines will be updated to use this interface. Pipelines is becoming the easy-to-use interface to batch.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5574:23,Depend,Dependencies,23,https://hail.is,https://github.com/hail-is/hail/pull/5574,4,"['Depend', 'interface']","['Dependencies', 'interface']"
Integrability,"# Commit 1. This rule that we add per job network namespace. > iptables -w {IPTABLES_WAIT_TIMEOUT_SECS} --append FORWARD --out-interface {self.veth_host} --in-interface {self.internet_interface} --jump ACCEPT. is functionally equivalent to this single line . > iptables --append FORWARD --in-interface $INTERNET_INTERFACE --destination 172.20.0.0/15 --jump ACCEPT. so better have 1 rule than O(slots) rules. It would be nice to eliminate the one remaining rule that we append per-network namespace. Without that rule [this test](https://github.com/hail-is/hail/blob/9da1c759efe9fcbbd9ad02ee7c8bf725974270e9/batch/test/test_dag.py#L117) will fail because the iptables rules won't allow `curl $HAIL_BATCH_WORKER_IP:$HAIL_BATCH_WORKER_PORT` from inside the job container. The request leaves the job's network namespace to the host (whose IP it is), and then returns right back to the network namespace. I have this strict rule such that jobs cannot communicate with each other, but so far don't know how in iptables to specify that the sending/receiving interfaces or IPs must match without listing them explicitly. That being said, this is also a side-effect of `HAIL_BATCH_WORKER_IP` being an in-cluster ip address `10.128.x.x` and thus known to the host. I believe if we made this the public IP (forcing the request to leave through the ethernet device I think) the test could work without this rule. Jobs can still communicate with themselves within their own network namespace (localhost still works fine), and we strictly prohibit workers talking to each other, so I don't see any reason why we shouldn't go the public ip approach. # Commit 2; This gives the external ip address to a job container that opens a port instead of using the private one. This just seems to make more sense to me and also allows us to delete that iptables rule. This ensures that iptables rules don't grow linearly with number of jobs (they'll be 1:1 with jobs that open ports but that makes more sense).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11250:127,interface,interface,127,https://hail.is,https://github.com/hail-is/hail/pull/11250,4,['interface'],"['interface', 'interfaces']"
Integrability,"# People. @cseed @jigold @akotlar @danking @tpoterba. # Plan. We want to describe build processes like this:. ```; - type: namespace; name: ns; - type: image; name: hail-pr-builder; context: ../; dockerfile: ../Dockerfile; - type: exec; name: build-jar; image: hail-pr-builder; namespace: ns; command: [""./gradlew"", ""test"", ""shadowJar""]; outputs:; - ""build/libs/hail-all-spark.jar""; - type: exec; name: pytests; image: hail-pr-builder; dependsOn:; - build-jar; command: [""./run-python-tests-using-input-jar.sh""]; ```. A series of steps that get us there:. - [x] (https://github.com/hail-is/hail/pull/5231) jobs may only depend on other jobs in the same batch ; - [x] (https://github.com/hail-is/hail/pull/5232) a batch can be `closed` indicating no more jobs will be added; - [ ] (https://github.com/hail-is/hail/pull/5233) a batch is automatically closed after 30 minutes; - [ ] add ""outputs"" to batch jobs. When a batch job is complete, the batch system copies its outputs to some durable storage (e.g. GCS), this is not user-visible; - [ ] add input/output dependencies to batch jobs. A batch job always receives the output of its parents. The data is copied (somehow) from the durable storage to the pod's filesystem at the path `/input/PARENT_JOB_NAME` and set to permissions 777. The copying is done in a secure way. In particular, the job container can be completely unprivileged (e.g. no credentials in the job's image, no credentials in the mounted volumes, no way to escalate to these credentials); - [ ] parse and run a series of `exec` commands that execute in parallel but no namespace dependencies and no image dependencies. This immediately puts us in a better place wrt logging. All artifacts, such as HTML reports are served through the batch outputs mechanism described above. Job file dependencies are handled exactly as described in input/output dependencies above.; - [ ] allow ""finalizer"" jobs. A finalizer job executes when its parents are all complete or cancelled. It is not c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5193:436,depend,dependsOn,436,https://hail.is,https://github.com/hail-is/hail/issues/5193,2,['depend'],"['depend', 'dependsOn']"
Integrability,"# logLkhd given by global.lmmreg.fit.logLkhdVals; df = read.table('delta.m.25.tsv', header=T, sep=""\t""). ##### method to estimate sigma, the standard deviation of normal approximation of confidence interval for h2; ### h2 = sigmoid(-ln(delta)); df$h2 = 1 / (1 + exp(df$logDelta)). ### fit parabola near maximum logLkhd of h2; maxRow = which.max(df$logLkhd). # h2; x1 = df$h2[maxRow - 1]; x2 = df$h2[maxRow]; x3 = df$h2[maxRow + 1]. # logLkhd at h2; y1 = df$logLkhd[maxRow - 1]; y2 = df$logLkhd[maxRow]; y3 = df$logLkhd[maxRow + 1]. # find a in logLkhd = a * x^2 + b * x + c; a = (x3 * (y2 - y1) + x2 * (y1 - y3) + x1 * (y3 - y2)) / ((x2 - x1) * (x1 - x3) * (x3 - x2)). # logLkhd = - (x - mu)^2 / (2 * sigma^2) + const = -1 / (2 * sigma^2) * x^2 + lower order terms; sigma2 = 1 / (-2 * a); sigma = sqrt(sigma2). ##### Method to plot normalized likelihood function of h2 and normal approximation; # shift log lkhd to have max of 0, to prevent numerical issues; maxLogLkhd = max(df$logLkhd); df$logLkhd = df$logLkhd - maxLogLkhd. ### integrate in h2 coordinates; df$width = df$h2 * (1 - df$h2) # d(h2) / d (ln(delta)) = - h2 * (1 - h2); total = sum(exp(df$logLkhd) * df$width) # normalization constant; df$posterior = exp(df$logLkhd) * df$width / total # normalized likelihood of h2 = posterior of h2 with uniform prior. ### normal approximation; meanPost = sum(df$h2 * df$posterior); sdPost = sqrt(sum((df$h2 - meanPost)**2 * df$posterior)); df$normalApproxPost = dnorm(df$h2, meanPost, sdPost). ### plots; qplot(x = logDelta, y = logLkhd, data = df, geom = 'line', xlab='ln(delta)', ylab='logLkhd(delta)'); qplot(x = h2 , y = logLkhd, data = df, xlim =c(0,1), geom = 'line', xlab = 'h2', ylab='logLkhd(h2)'); qplot(x = h2 , y = posterior, data = df, xlim =c(0,1), geom = 'line', xlab = 'h2', ylab='posterior(h2)'); qplot(x = h2, y = normalApproxPost, data = df, xlim =c(0,1), geom = 'line', xlab = 'h2', ylab='normalApprox(h2)'). ##### Reality check that sigma and sdPost are close; sigma; sdPost; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1720#issuecomment-297590538:1222,integrat,integrate,1222,https://hail.is,https://github.com/hail-is/hail/pull/1720#issuecomment-297590538,1,['integrat'],['integrate']
Integrability,"## Change Description. Fixes #14597. ## Security Assessment. Delete all except the correct answer:; - This change has a high security impact; - [ ] Required: The impact has been assessed and approved by appsec; - This change has a medium security impact; - This change has a low security impact; - This change has no security impact. ### Impact Description. For none/low impact: a quick one/two sentence justification of the rating.; - Example: ""Docs only"", ""Low-level refactoring of non-security code"", etc.; For medium/high impact: provide a description of the impact and the mitigations in place.; - Example: ""New UI text field added in analogy to existing elements, with input strings escaped and validated against code injection"". (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14745:724,inject,injection,724,https://hail.is,https://github.com/hail-is/hail/pull/14745,1,['inject'],['injection']
Integrability,"## Change Description. Fixes #<issue_number> (delete if N/A). Brief description and justification of what this PR is doing. ## Security Assessment. Delete all except the correct answer:; - This change has a high security impact; - [ ] Required: The impact has been assessed and approved by appsec; - This change has a medium security impact; - This change has a low security impact; - This change has no security impact. ### Impact Description. For none/low impact: a quick one/two sentence justification of the rating.; - Example: ""Docs only"", ""Low-level refactoring of non-security code"", etc.; For medium/high impact: provide a description of the impact and the mitigations in place.; - Example: ""New UI text field added in analogy to existing elements, with input strings escaped and validated against code injection"". (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14732:811,inject,injection,811,https://hail.is,https://github.com/hail-is/hail/pull/14732,2,['inject'],['injection']
Integrability,"## Change Description. On windows, gcloud is 'gcloud.cmd' and as such, it needs to be run via the command shell. Other platforms are not affected. This change is in response to Nico Valencia having difficulties running hailctl on Windows. ## Security Assessment. Delete all except the correct answer:; - This change has a medium security impact. ### Impact Description. Technically speaking, this opens up users of `hailctl dataproc` to command injection, but only on platforms where `sys.platform == 'win32'`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14736:445,inject,injection,445,https://hail.is,https://github.com/hail-is/hail/pull/14736,1,['inject'],['injection']
Integrability,"## Mill setup. There is a mill wrapper script `millw` checked into the repo in the `hail/` subdirectory. You can either invoke it directly, as we did with `gradlew`, or copy it somewhere on your path and rename it `mill`. This way you can just run `mill ...`, and it will identify the correct version of mill to use for the project you're in and invoke that. For more details on the installation options, see the github for the wrapper script [here](https://github.com/lefou/millw). To verify that it's working, and download the actual mill jar, run `./millw --version` (or `mill --version` if you put it on your path) from the `hail/` subdirectory. It should report version `0.11.6`. ## Mill from the command line. * `mill clean` - delete all output files (in `hail/hail/out`). Or only delete the output of one target, e.g. `mill clean test.compile`; * `mill compile` - compiles the root module (not including tests); * `mill test.compile` - compiles tests (and, transitively, the rest of the root module); * `mill test.test`, or for short `mill test` - run all tests. You can pass options to the test runner (TestNG currently), e.g.* * `mill test -methods is.hail.expr.ir.CallFunctionsSuite.constructors` to run one test, or `mill test -threadcount 4 -parallel classes` to use 4 threads and parallelize over test classes; * `mill test.testOnly is.hail.expr.ir.CallFunctionsSuite` - run all tests in one or more specified classes. You can use `*` to match anything, e.g. `mill test.testOnly ""*.CallFunctionsSuite""`, or `mill test.testOnly ""is.hail.expr.ir.*""`. You can pass options to the test runner (TestNG currently) after a `--`, e.g. `mill test.testOnly ""is.hail.expr.ir.*"" -- -parallel classes`; * `mill __.testCached` - once the codebase is more modularized, will run tests on only modules whose dependencies have changed since the last test run; * `mill reformat` - runs scalafmt on all sources in the root module (currently that's all scala sources, but hopefully not for long). `mill __.ref",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14147:31,wrap,wrapper,31,https://hail.is,https://github.com/hail-is/hail/pull/14147,2,['wrap'],['wrapper']
Integrability,"## `JoinPoint` interface for nontrivial, type-safe control flow in the JVM backend. This PR implements a ""join-point"" abstraction for the JVM backend. Join-points are a primitive; control flow construct that allow sophisticated forms of branching to be implemented in a type safe; way, without having to directly manipulate labels and jumps at the JVM bytecode level. Importantly,; they will enable the kinds of branching needed by stream-deforestation techniques that; @patrick-schultz and I have been discussing, for which while loops and if's were not sufficient. We've also discussed plans for implementing join points as a feature in the IR. ### Notable examples:. * Implementation of `whileLoop` (emits bytecode identical to current version):; ```scala; def whileLoop(cond: Code[Boolean], body: Code[Unit]): Code[Unit] =; JoinPoint.CallCC[Unit] { (jb, break) =>; val continue = jb.joinPoint(); val loopBody = jb.joinPoint(); continue.define { _ => JoinPoint.mux(cond, loopBody, break) }; loopBody.define { _ => Code(body, continue(())) }; continue(()); }; ```. * Mutual recursion:; ```scala; def parity(; n: Code[Int],; even: Code[Ctrl],; odd: Code[Ctrl]; ): Code[Ctrl] = {; val isEven = jb.joinPoint[Code[Int]](mb); val isOdd = jb.joinPoint[Code[Int]](mb); isEven.define { i => (i ceq 0).mux(even, isOdd(i - 1)) }; isOdd.define { i => (i ceq 0).mux(odd, isEven(i - 1)) }; isEven(n); }; ```. ### Classes of interest (tl;dr). - `JoinPoint` - Non-returning function. Used to implement control flow in a type-safe, functional way.; - `ParameterPack` - Trait used for tuple deforesting. Allows join-points to be provided multiple; arguments.; - `JoinPointBuilder` - Used to define new join points.; - `CallCC` - Entry-point for expressions with complex control flow. Provides a `JoinPointBuilder`; and a `JoinPoint` to return a value from the expression. ### `JoinPoint`. A `JoinPoint[A]` acts like a non-returning function with an argument of type `A`. The type of an; applied join point is `Code[C",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7055:15,interface,interface,15,https://hail.is,https://github.com/hail-is/hail/pull/7055,1,['interface'],['interface']
Integrability,"### Change Description. The changes in #14708 caused our vep images to be rebuilt, breaking them. The solution here is the one that we should have done from the beginning, install dependencies through the system package manager. In the interest of my sanity and effort, I only added the libraries that were being problematic from CPAN to the list of system installed ones. ### Security Assessment; - [x] This change has no security impact",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14713:180,depend,dependencies,180,https://hail.is,https://github.com/hail-is/hail/pull/14713,1,['depend'],['dependencies']
Integrability,"### Hail version: 0.2.8. ### What you did:. ```python; smt = hl.methods.balding_nichols_model(3, 100, 200); smt = smt.annotate_cols(s=hl.str(smt.sample_idx)).key_cols_by('s'); smt.make_table().to_pandas(); ```; ### What went wrong (all error messages here, including the full java stack trace):. ```; 2019-01-26 19:03:28 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 100 samples, and 200 variants...; 2019-01-26 19:03:28 Hail: INFO: Coerced sorted dataset; 2019-01-26 19:03:29 Hail: INFO: Coerced sorted dataset; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-59-9addf4eaf59b> in <module>; 1 smt = hl.methods.balding_nichols_model(3, 100, 200); 2 smt = smt.annotate_cols(s=hl.str(smt.sample_idx)).key_cols_by('s'); ----> 3 smt.make_table().to_pandas(). <decorator-gen-1366> in to_pandas(self, flatten). ~/anaconda3/lib/python3.6/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 558 def wrapper(__original_func, *args, **kwargs):; 559 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 560 return __original_func(*args_, **kwargs_); 561 ; 562 return wrapper. ~/anaconda3/lib/python3.6/site-packages/hail/table.py in to_pandas(self, flatten); 2703 ; 2704 """"""; -> 2705 return Env.spark_backend('to_pandas').to_pandas(self, flatten); 2706 ; 2707 @staticmethod. ~/anaconda3/lib/python3.6/site-packages/hail/backend/backend.py in to_pandas(self, t, flatten); 66 ; 67 def to_pandas(self, t, flatten):; ---> 68 return self.to_spark(t, flatten).toPandas(); 69 ; 70 def from_pandas(self, df, key):. ~/anaconda3/lib/python3.6/site-packages/hail/backend/backend.py in to_spark(self, t, flatten); 63 if flatten:; 64 t = t.flatten(); ---> 65 return pyspark.sql.DataFrame(t._jt.toDF(Env.hc()._jsql_context), Env.sql_context()); 66 ; 67 def to_pandas(self, t, flatten):. ~/anaconda3/lib/python3.6/site-packages/py4j/jav",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5212:242,message,messages,242,https://hail.is,https://github.com/hail-is/hail/issues/5212,1,['message'],['messages']
Integrability,"### Hail version: ; 0.1-74bf1eb. ### What you did: ; Export vcf to local file:// path. ### What went wrong (all error messages here, including the full java stack trace): ; When exporting vcf to path that begins with 'file://', I get the error: `ClassNotFoundException: Class org.apache.hadoop.mapred.DirectFileOutputCommitter not found`. I am using Spark 2.2.1 (prebuilt with hadoop2.7) with AWS-Hadoop 2.7.4. I have the following settings in spark config and am using a custom directParquetOutputCommitter. Standard writes to 'file://' of Spark dataframes work without issue. Thanks for any help!. ```; spark.sql.parquet.output.committer.class org.apache.spark.sql.parquet.DirectParquetOutputCommitter; spark.hadoop.mapred.output.committer.class org.apache.hadoop.mapred.DirectFileOutputCommitter; spark.hadoop.mapreduce.use.directfileoutputcommitter true; spark.hadoop.spark.sql.parquet.output.committer.class org.apache.spark.sql.parquet.DirectParquetOutputCommitter; ```. Code and stack trace:; ```; ================================================================================================== FAILURES ===================================================================================================; __________________________________________________________________________________________ TestHAIL.test_export_vcf ___________________________________________________________________________________________. self = <test_hail.TestHAIL testMethod=test_export_vcf>. def test_export_vcf(self):; # define files; bgen_file = os.path.join(self.testdir, 'example.10bits.bgen'); sample_file = os.path.join(self.testdir, 'example.sample'); # make index; self.hc.index_bgen(bgen_file); # load to vds; bgen_vds = self.hc.import_bgen(bgen_file, sample_file=sample_file); # export vcf; out_path = 'file://' + os.path.join(self.tmpdir, 'test_vcf_export.vcf.bgz'); > bgen_vds.export_vcf(out_path, export_pp=False, parallel=False). tests/hail/test_hail.py:55:; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3946:118,message,messages,118,https://hail.is,https://github.com/hail-is/hail/issues/3946,1,['message'],['messages']
Integrability,"### Hail version: ; 0.2.9-8588a25687af. ### What you did: ; tbl.export(""filename"", header=False, types_file=None). ### What went wrong (all error messages here, including the full java stack trace):; No errors, but two files were written to my working directory; None and .None.crc. The file contains column types as if the 'types_file = None' was interpreted as 'types_file = ""None""'",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5266:146,message,messages,146,https://hail.is,https://github.com/hail-is/hail/issues/5266,1,['message'],['messages']
Integrability,"### Hail version:. 9e4ca83b6b0d. ### What you did:. ### What went wrong (all error messages here, including the full java stack trace):. `hl.eval_expr(hl.is_snp(hl.literal('A'), hl.literal('A')))` should return false, i.e. ['A', 'A'] shouldn't be considered a snp.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3712:83,message,messages,83,https://hail.is,https://github.com/hail-is/hail/issues/3712,1,['message'],['messages']
Integrability,"### Hail version:. d5007d8878f2dc330dd2f01c1c0251785f259dac. ### What you did:. ```; ds = hl.import_vcf(resource(""sample.vcf"")); ds_duplicate = ds.annotate_rows(duplicate = [1,2]); ds_duplicate = ds_duplicate.explode_rows(ds_duplicate['duplicate']); result = hl.ld_prune(ds_duplicate.GT); result.show(); ```. ### What went wrong (all error messages here, including the full java stack trace):. ```; Java stack trace:; java.lang.AssertionError: assertion failed: absoluteUpperIndexBounds length 197 did not match GridPartition nRows 394; 	at scala.Predef$.assert(Predef.scala:170); 	at is.hail.methods.UpperIndexBounds$.computeCoverByUpperTriangularBlocks(UpperIndexBounds.scala:69); 	at is.hail.linalg.BlockMatrix.filteredEntriesTable(BlockMatrix.scala:1198); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3835:340,message,messages,340,https://hail.is,https://github.com/hail-is/hail/issues/3835,1,['message'],['messages']
Integrability,"### Hail version:. de61119ceec6. ### What you did:; ```; ht1 = hl.Table.parallelize([; {'k': 'foo', 'b': 1},; {'k': 'bar', 'b': 2},; {'k': 'bar', 'b': 2}],; hl.tstruct(k=hl.tstr, b=hl.tint32),; key='k'). # IllegalArgumentException: requirement failed; ht1.group_by().aggregate(mean_b = hl.agg.mean(ht1.b)).show(). # ClassCastException: is.hail.rvd.UnpartitionedRVD cannot be cast to is.hail.rvd.OrderedRVD; ht1.group_by('k').aggregate(mean_b = hl.agg.mean(ht1.b)).show(); ```; ### What went wrong (all error messages here, including the full java stack trace):. bad error messages",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4070:508,message,messages,508,https://hail.is,https://github.com/hail-is/hail/issues/4070,2,['message'],['messages']
Integrability,"### Hail version:. eb5d13fe97fc. ### What you did:. ```; t1 = hl.Table.parallelize([; {'a': 'foo', 'b': 1},; {'a': 'bar', 'b': 2},; {'a': 'bar', 'b': 2}],; hl.tstruct(a=hl.tstr, b=hl.tint32),; key='a'); t2 = hl.Table.parallelize([; {'t': 'foo', 'x': 3.14},; {'t': 'bar', 'x': 2.78},; {'t': 'bar', 'x': -1},; {'t': 'quam', 'x': 0}],; hl.tstruct(t=hl.tstr, x=hl.tfloat64),; key='t'). t1.join(t2, how='outer').show(). # or. t1.join(t2, how='right').show(); ```. ### What went wrong (all error messages here, including the full java stack trace):. FatalError: HailException: OrderedRVD error! Unexpected PK in partition 1; Range bounds for partition 1: ([bar]-[foo]]; Invalid PK: [quam]; Full key: [quam]. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 19.0 failed 1 times, most recent failure: Lost task 0.0 in stage 19.0 (TID 24, localhost, executor driver): is.hail.utils.HailException: OrderedRVD error! Unexpected PK in partition 1; Range bounds for partition 1: ([bar]-[foo]]; Invalid PK: [quam]; Full key: [quam]; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1031); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1012); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:462); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.RVD$$anonfun$4$$anon$1.hasNext(RVD.scala:226); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.hasNext(OrderedRVD.scala:1015); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); 	at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); 	at is.hail.utils.richUtils",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4055:490,message,messages,490,https://hail.is,https://github.com/hail-is/hail/issues/4055,1,['message'],['messages']
Integrability,"### Hail version:. f2b0dca9f506. ### What you did:; ```; ht = hl.Table.parallelize([; {'a': '1', 'c': .5,'d': 'foo'},; {'a': '1', 'c': .6,'d': 'foo'},; ], hl.tstruct(a=hl.tstr,; c=hl.tfloat32, d=hl.tstr)); mt = ht.to_matrix_table(['a'], ['d']). mt.entries().show(); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; FatalError: AssertionError: assertion failed. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 4.0 failed 1 times, most recent failure: Lost task 0.0 in stage 4.0 (TID 7, localhost, executor driver): java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.RegionValueBuilder.endArray(RegionValueBuilder.scala:167); 	at is.hail.expr.ir.TableToMatrixTable$$anonfun$75$$anonfun$apply$25.apply(MatrixIR.scala:1878); 	at is.hail.expr.ir.TableToMatrixTable$$anonfun$75$$anonfun$apply$25.apply(MatrixIR.scala:1849); 	at is.hail.utils.FlipbookIterator$$anon$4.<init>(FlipbookIterator.scala:133); 	at is.hail.utils.FlipbookIterator.map(FlipbookIterator.scala:131); 	at is.hail.expr.ir.TableToMatrixTable$$anonfun$75.apply(MatrixIR.scala:1849); 	at is.hail.expr.ir.TableToMatrixTable$$anonfun$75.apply(MatrixIR.scala:1840); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$18.apply(ContextRDD.scala:293); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$18.apply(ContextRDD.scala:293); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$22$$anonfun$apply$23.apply(ContextRDD.scala:310); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$22$$anonfun$apply$23.apply(ContextRDD.scala:310); 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.hasNext(OrderedRVD.scala:1014); 	at scala.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4114:302,message,messages,302,https://hail.is,https://github.com/hail-is/hail/issues/4114,1,['message'],['messages']
Integrability,"### Hail version:; 0.1 only - this already works in 0.2. ### What you did:; I'm calling kt.export_elasticsearch(..) on this keytable schema:. ```; ...; aIndex: Int,; alt: String,; codingGeneIds: Set[String],; contig: String,; docId: String,; domains: Set[String],; end: Int,; filters: Set[String],; geneIds: Set[String],; pos: Int,; ref: String,; rsid: String,; start: Int,; variantId: String,; vep: Array[Struct{; gene_id: String,; gene_symbol: String,; protein_id: String,; transcript_id: String,; hgvs: String,; major_consequence: String,; major_consequence_rank: Int,; category: String; }],; wasSplit: Boolean,; ```. ### What went wrong (all error messages here, including the full java stack trace):. Having `vep: Array[Struct..]` in the schema leads to . ```; 2018-09-02 07:06:06,821 INFO ==> exporting data to elasticasearch. Write mode: upsert, blocksize: 1000; Config Map(es.batch.size.entries -> 1000, es.index.auto.create -> true, es.mapping.id -> docId, es.write.operation -> upsert, es.port -> 9200, es.nodes -> 10.56.10.4); [Stage 3:> (0 + 100) / 1000]Traceback (most recent call last):; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/load_dataset_to_es.py"", line 734, in <module>; run_pipeline(); File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/load_dataset_to_es.py"", line 726, in run_pipeline; hc, vds = step2_export_to_elasticsearch(hc, vds, args); File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/load_dataset_to_es.py"", line 565, in step2_export_to_elasticsearch; disable_index_for_fields=(""sortedTranscriptConsequences"", ),; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/load_dataset_to_es.py"", line 358, in export_to_elasticsearch; verbose=True,; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/hail_scripts.zip/hail_scripts/v01/utils/elasticsearch_client.py"", line 140, in export_vds_to_elasticsearch; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/hail_scripts.zip/hail_scripts/v01/utils/elasticsearch_client.py"", line 287, in export_kt_to_elasticsearch; File ""<decorator-gen-143>"", line 2, in expo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:652,message,messages,652,https://hail.is,https://github.com/hail-is/hail/issues/4250,1,['message'],['messages']
Integrability,"### Hail version:; 18d0195e6; ### What you did:; ```; import hail as hl; contigs = {'0{}'.format(x):str(x) for x in range(1, 10)}; mt = hl.methods.import_bgen('gs://fc-7d5088b4-7673-45b5-95c2-17ae00a04183/imputed/ukb_imp_chr22_v3.bgen',; ['GT'],; sample_file='gs://phenotype_31063/ukb31063.autosomes.sample',; contig_recoding=contigs,; min_partitions=100); sampleids = hl.import_table('gs://ukb31063-mega-gwas/qc/ukb31063.gwas_samples.txt', delimiter='\s+').key_by('s'); og_sample = mt.filter_cols(hl.is_defined(sampleids[mt.s])); og_sample = og_sample.annotate_rows(pca_af=hl.agg.mean(og_sample.GT.n_alt_alleles()) / 2); og_sample._force_count_rows(); ```; The important part is that I used `annotate_rows` on a sufficiently large dataset.; ### What went wrong (all error messages here, including the full java stack trace):; Container failures; ```; Job aborted due to stage failure: Task 5 in stage 9.0 failed 20 times, most recent failure: Lost task 5.19 in stage 9.0 (TID 603, dk-w-0.c.broad-ctsa.internal, executor 63): ExecutorLostFailure (executor 63 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 15.9 GB of 12 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.; ```; This is due to `collectPerPartition` allowing regions to grow without bound.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3920:773,message,messages,773,https://hail.is,https://github.com/hail-is/hail/issues/3920,1,['message'],['messages']
Integrability,"### Hail version:; 1f253167d53c; ### What you did:; ```; hl.eval_expr(hl.literal(hl.tuple([3]))); hl.eval_expr(hl.literal(hl.literal(3))); ```; ### What went wrong (all error messages here, including the full java stack trace):; ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-3-4a1008efb336> in <module>(); ----> 1 hl.eval_expr(hl.literal(hl.tuple([3]))[0]). ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/projects/hail/python/hail/expr/expressions/expression_utils.py in eval_expr(expression); 136 Result of evaluating `expression`.; 137 """"""; --> 138 return eval_expr_typed(expression)[0]; 139 ; 140 . ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/projects/hail/python/hail/expr/expressions/expression_utils.py in eval_expr_typed(expression); 172 analyze('eval_expr_typed', expression, Indices(expression._indices.source)); 173 ; --> 174 return expression.collect()[0], expression.dtype; 175 ; 176 . ~/projects/hail/python/hail/expr/expressions/base_expression.py in collect(self); 762 """"""; 763 uid = Env.get_uid(); --> 764 t = self._to_table(uid); 765 return [r[uid] for r in t._select(""collect"", None, hl.struct(**{uid: t[uid]})).collect()]; 766 . ~/projects/hail/python/hail/expr/expressions/base_expression.py in _to_table(self, name); 582 # scalar expression; 583 df = Env.dummy_table(); --> 584 df = df.select(**{name: self}); 585 return df; 586 elif len(axes) == 0:. ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrap",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3708:175,message,messages,175,https://hail.is,https://github.com/hail-is/hail/issues/3708,4,"['message', 'wrap']","['messages', 'wrapper']"
Integrability,"### Hail version:; 1f253167d; ### What you did:; ```; import hail as hl; t = hl.utils.range_table(10); hl.methods.maximal_independent_set(t.idx, t.idx // 2, tie_breaker = lambda i, j: hl.signum(i - j)) ; ```; ### What went wrong (all error messages here, including the full java stack trace):; ```; ---------------------------------------------------------------------------; LookupError Traceback (most recent call last); <ipython-input-8-b09a26588332> in <module>(); ----> 1 hl.methods.maximal_independent_set(t.idx, t.idx // 2, tie_breaker = lambda i, j: hl.signum(i - j)). ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/projects/hail/python/hail/methods/misc.py in maximal_independent_set(i, j, keep, tie_breaker); 139 .select()); 140 ; --> 141 edges = t.key_by(None).select('i', 'j'); 142 nodes_in_set = Env.hail().utils.Graph.maximalIndependentSet(edges._jt.collect(), node_t._jtype, joption(tie_breaker_hql)); 143 . ~/projects/hail/python/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). ~/projects/hail/python/hail/table.py in select(self, *exprs, **named_exprs); 863 row = get_select_exprs('Table.select',; 864 exprs, named_exprs, self._row_indices,; --> 865 protect_keys=True); 866 return self._select('Table.select', value_struct=hl.struct(**row)); 867 . ~/projects/hail/python/hail/utils/misc.py in get_select_exprs(caller, exprs, named_exprs, indices, protect_keys); 314 def get_select_exprs(caller, exprs, named_exprs, indices, protect_keys=True):; 315 from hail.expr.expressions import to_expr, ExpressionException, TopLevelReference, Select; --> 316 exprs = [to_expr(e) ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3706:240,message,messages,240,https://hail.is,https://github.com/hail-is/hail/issues/3706,4,"['message', 'wrap']","['messages', 'wrapper']"
Integrability,"### Hail version:; 2018-06-04; ### What you did:; ### What went wrong (all error messages here, including the full java stack trace):; The docs for [`liftover`](https://hail.is/docs/devel/functions/genetics.html?highlight=liftover#hail.expr.functions.liftover) confusingly use `.value` to convert an expression to a value. Users are apt to copy paste them and not understand what the `.value` is doing. We should uniformly use `hl.eval_expr` which is less surprising.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3709:81,message,messages,81,https://hail.is,https://github.com/hail-is/hail/issues/3709,1,['message'],['messages']
Integrability,"### Hail version:; 6195693b3; ### What you did:; ```mt.filter_cols(hl.literal(set(max_downsample1)).contains(mt.col_idx))```. ### What went wrong (all error messages here, including the full java stack trace):; ```Hail cannot automatically impute type of <class 'numpy.int64'>: 129```. Hail should understand the usual numpy int types.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3699:157,message,messages,157,https://hail.is,https://github.com/hail-is/hail/issues/3699,1,['message'],['messages']
Integrability,"### Hail version:; Latest build of `devel` from https://storage.googleapis.com/hail-common/distributions/devel/Hail-devel-5d0f74cef4f2-Spark-2.2.0.zip. ### What you did:; 1. Import VCF file into MatrixTable.; 2. Annotate VCF file with `output = hl.vep(input, 'vep.properties', csq=True)`.; 3. Attempt to view output with `output.rows().show()`. With `csq=False`, step 3 succeeds. ### What went wrong (all error messages here, including the full java stack trace):; ```; 2018-06-19 17:15:41 Hail: INFO: vep: annotated 2 variants; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/opt/hail/python/hail/table.py"", line 1195, in show; print(self._show(n,width, truncate, types)); File ""/opt/hail/python/hail/table.py"", line 1198, in _show; return self._jt.showString(n, joption(truncate), types, width); File ""/opt/spark-2.2.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/opt/hail/python/hail/utils/java.py"", line 196, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: MatchError: [Ljava.lang.String;@7cd5fe91 (of class [Ljava.lang.String;). Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 11.0 failed 1 times, most recent failure: Lost task 0.0 in stage 11.0 (TID 11, localhost, executor driver): scala.MatchError: [Ljava.lang.String;@7cd5fe91 (of class [Ljava.lang.String;); 	at is.hail.annotations.RegionValueBuilder.addAnnotation(RegionValueBuilder.scala:489); 	at is.hail.methods.VEP$$anonfun$9$$anonfun$apply$4.apply(VEP.scala:350); 	at is.hail.methods.VEP$$anonfun$9$$anonfun$apply$4.apply(VEP.scala:345); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$16$$anon$3.next(Or",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3790:411,message,messages,411,https://hail.is,https://github.com/hail-is/hail/issues/3790,2,"['message', 'wrap']","['messages', 'wrapper']"
Integrability,"### Hail version:; `08224c6ab`; ### What you did:; Tried to load a plink dataset that was split by chromosome.; ```; files = [(; f'gs://fc-9a7c5487-04c9-4182-b3ec-13de7f6b409b/genotype/ukb_cal_chr{i}_v2.bed',; f'gs://fc-9a7c5487-04c9-4182-b3ec-13de7f6b409b/genotype/ukb_snp_chr{i}_v2.bim'; ) for i in range(1,23)]; mts = [hl.import_plink(bed=f[0],bim=f[1],fam=""gs://phenotype_31063/ukb31063.fam"") for f in files]; mt = mts[0].union_rows(*mts[1:]); ```; ### What went wrong (all error messages here, including the full java stack trace):; It loaded each plink file serially rather than in parallel, thus wasting many cores of my cluster (and my time).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3975:484,message,messages,484,https://hail.is,https://github.com/hail-is/hail/issues/3975,1,['message'],['messages']
Integrability,"### Hail version:; `30bc2bcdf2ba`; ### What you did:; ```python; t = hl.import_table('/path/to/thing', ; delimiter='\s+',; impute=True); ```; on a file with two extra new lines at the end.; ### What went wrong (all error messages here, including the full java stack trace):; The task failed 14 times in the background rather than eagerly failing.; ```; is.hail.utils.HailException: pheno_31063_eur_gwas_skin_color.clumped.gz: expected 13 fields, but found 1 offending line: 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:20) 	at is.hail.utils.package$.fatal(package.scala:26) 	at is.hail.utils.Context.wrapException(Context.scala:19) 	at is.hail.utils.WithContext.foreach(Context.scala:51) 	at is.hail.utils.TextTableReader$$anonfun$5$$anonfun$apply$2.apply(TextTableReader.scala:126) 	at is.hail.utils.TextTableReader$$anonfun$5$$anonfun$apply$2.apply(TextTableReader.scala:126) 	at scala.collection.Iterator$class.foreach(Iterator.scala:893) 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336) 	at is.hail.utils.TextTableReader$$anonfun$5.apply(TextTableReader.scala:126) 	at is.hail.utils.TextTableReader$$anonfun$5.apply(TextTableReader.scala:122) 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797) 	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:797) 	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38) 	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323) 	at org.apache.spark.rdd.RDD.iterator(RDD.scala:287) 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87) 	at org.apache.spark.scheduler.Task.run(Task.scala:108) 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:338) 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) 	at java.lang.Thread.run(Thread.java:748) Caused by: is.hail.uti",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4100:221,message,messages,221,https://hail.is,https://github.com/hail-is/hail/issues/4100,2,"['message', 'wrap']","['messages', 'wrapException']"
Integrability,"### Hail version:; `6d4d50458`; ### What you did:; ```; label_expr = (hl.case(missing_false=True); .when(ht[tp_col] & ~ht[fp_col], ""TP""); .when(ht[fp_col] & ~ht[tp_col], ""FP”)); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; I’m getting an error that reads,; Traceback (most recent call last):; File ""/tmp/99ecf728f92847f2bfddb1e75cbd0a4e/variantqc.py"", line 567, in <module>; try_slack(args.slack_channel, main, args); File ""/tmp/99ecf728f92847f2bfddb1e75cbd0a4e/pyscripts_SuuLaL.zip/gnomad_hail/utils/slack.py"", line 112, in try_slack; File ""/tmp/99ecf728f92847f2bfddb1e75cbd0a4e/pyscripts_SuuLaL.zip/gnomad_hail/utils/slack.py"", line 95, in try_slack; File ""/tmp/99ecf728f92847f2bfddb1e75cbd0a4e/variantqc.py"", line 508, in main; run_hash = train_rf(data_type, args) if args.train_rf else args.run_hash; File ""/tmp/99ecf728f92847f2bfddb1e75cbd0a4e/variantqc.py"", line 422, in train_rf; fp_to_tp=args.fp_to_tp); File ""/tmp/99ecf728f92847f2bfddb1e75cbd0a4e/variantqc.py"", line 240, in sample_rf_training_examples; train_col: train_expr}); File ""/tmp/99ecf728f92847f2bfddb1e75cbd0a4e/hail-6d4d50458.zip/hail/table.py"", line 720, in annotate; File ""/tmp/99ecf728f92847f2bfddb1e75cbd0a4e/hail-6d4d50458.zip/hail/utils/misc.py"", line 336, in get_annotate_exprs; File ""/tmp/99ecf728f92847f2bfddb1e75cbd0a4e/hail-6d4d50458.zip/hail/utils/misc.py"", line 336, in <dictcomp>; File ""/tmp/99ecf728f92847f2bfddb1e75cbd0a4e/hail-6d4d50458.zip/hail/expr/expressions/base_expression.py"", line 102, in to_expr; File ""/tmp/99ecf728f92847f2bfddb1e75cbd0a4e/hail-6d4d50458.zip/hail/expr/expressions/base_expression.py"", line 93, in impute_type; hail.expr.expressions.base_expression.ExpressionException: Hail cannot automatically impute type of <class 'hail.expr.builders.CaseBuilder'>: <hail.expr.builders.CaseBuilder object at 0x7f2ad03c74e0>; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3696:214,message,messages,214,https://hail.is,https://github.com/hail-is/hail/issues/3696,1,['message'],['messages']
Integrability,"### Hail version:; `784ab2796878`; ### What you did:; ```; In [1]: import hail as hl; ...: ; ...: t1kg = hl.balding_nichols_model(3, 100, 100); ...: print(t1kg.describe()); ...: t1kg = t1kg_sm.repartition(500) ; ...: t1kg = t1kg._filter_partitions([1]); ...: t1kg = hl.split_multi(t1kg); ...: t1kg._force_count_rows(); ```; ### What went wrong (all error messages here, including the full java stack trace):; ```; FatalError: HailException: optimization changed type!; before: Matrix{global:Struct{bn:Struct{n_populations:Int32,n_samples:Int32,n_variants:Int32,n_partitions:Int32,pop_dist:Array[Int32],fst:Array[Float64],mixture:Boolean}},col_key:[sample_idx],col:Struct{sample_idx:Int32,pop:Int32},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh37),alleles:Array[String],ancestral_af:Float64,af:Array[Float64],a_index:Int32,was_split:Boolean,old_locus:Locus(GRCh37),old_alleles:Array[String]},entry:Struct{GT:Call}}; after: Matrix{global:Struct{bn:Struct{n_populations:Int32,n_samples:Int32,n_variants:Int32,n_partitions:Int32,pop_dist:Array[Int32],fst:Array[Float64],mixture:Boolean}},col_key:[sample_idx],col:Struct{sample_idx:Int32,pop:Int32},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh37),alleles:Array[String],ancestral_af:Float64,af:Array[Float64],a_index:Int32,was_split:Boolean,old_locus:Locus(GRCh37),old_alleles:Array[String]},entry:Struct{GT:Call}}; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4527:355,message,messages,355,https://hail.is,https://github.com/hail-is/hail/issues/4527,1,['message'],['messages']
Integrability,"### Hail version:; ```; 0.2.8-590ea4ae3b83; ```; ### What you did:; ```; hl.import_bgen(; ""/Users/dking/projects/hail-data/caitlin/ukb_imp_chr22_v3.bgen"",; entry_fields=[]; ).count_rows(); ```. ### What went wrong (all error messages here, including the full java stack trace):; A spark stage was triggered. I expected it to read the number of rows from the index.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5182:225,message,messages,225,https://hail.is,https://github.com/hail-is/hail/issues/5182,1,['message'],['messages']
Integrability,"### Hail version:; `a230321`; ### What you did:; `mt.GT[1]` on a haploid call; ### What went wrong (all error messages here, including the full java stack trace):; ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 9716 in stage 3.0 failed 20 times, most recent failure: Lost task 9716.19 in stage 3.0 (TID 10515, pbt-sw-nkpn.c.broad-mpg-gnomad.internal, executor 306): java.lang.IllegalArgumentException: requirement failed; at scala.Predef$.require(Predef.scala:212); at is.hail.variant.Call$.alleleByIndex(Call.scala:128); at is.hail.expr.FunctionRegistry$$anonfun$11.apply$mcIII$sp(FunctionRegistry.scala:682); at is.hail.expr.FunctionRegistry$$anonfun$11.apply(FunctionRegistry.scala:682); at is.hail.expr.FunctionRegistry$$anonfun$11.apply(FunctionRegistry.scala:682); at is.hail.expr.BinaryFun.apply(Fun.scala:122); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3713:110,message,messages,110,https://hail.is,https://github.com/hail-is/hail/issues/3713,1,['message'],['messages']
Integrability,"### Hail version:; `devel-62679fc21687`; ### What you did:; [ran a PRS script](https://gist.github.com/danking/9c9d77afb3ff318adc7bf79bb52d4f7d); Cluster had 100 pre-emptibles.; ![tasks page showing failures due to container exit](https://user-images.githubusercontent.com/106194/44540204-293de580-a6d4-11e8-90b8-1ecaaec45443.png); ![Job 12 page show mapPartitionsWithIndex running](https://user-images.githubusercontent.com/106194/44540205-293de580-a6d4-11e8-9893-af8edc382906.png); ![executors page showing 202 active executors, 100 dead](https://user-images.githubusercontent.com/106194/44540178-15927f00-a6d4-11e8-99e1-78755df3756c.png). This `mapPartitionsWithIndex` call is in the tree aggregate of context rdd. Judging from the fact that it's the first one, this is probably the first step of the aggregation.; ; ### What went wrong (all error messages here, including the full java stack trace):; Workers exceed memory limits, e.g. (from hail.log):; ```; 2018-08-22 17:28:37 YarnSchedulerBackend$YarnSchedulerEndpoint: WARN: Container killed by YARN for exceeding memory limits. 12.2 GB of 12 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.; 2018-08-22 17:28:37 YarnScheduler: ERROR: Lost executor 431 on pca-sw-pd61.c.daly-ibd.internal: Container killed by YARN for exceeding memory limits. 12.2 GB of 12 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.; 2018-08-22 17:28:37 TaskSetManager: WARN: Lost task 1047.0 in stage 16.0 (TID 20251, pca-sw-pd61.c.daly-ibd.internal, executor 431): ExecutorLostFailure (executor 431 exited caused by one of the running tasks) Reason: Container killed by YARN for exceeding memory limits. 12.2 GB of 12 GB physical memory used. Consider boosting spark.yarn.executor.memoryOverhead.; 2018-08-22 17:28:37 TaskSetManager: WARN: Lost task 1046.0 in stage 16.0 (TID 20250, pca-sw-pd61.c.daly-ibd.internal, executor 431): ExecutorLostFailure (executor 431 exited caused by one of the running tasks) ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4202:851,message,messages,851,https://hail.is,https://github.com/hail-is/hail/issues/4202,1,['message'],['messages']
Integrability,"### Hail version:; devel-10a75bb57a6f; ### What you did:. ```; def test_rekey_correct_partition_key(self):; ht = hl.utils.range_table(5); ht = ht.add_index('a'); ht = ht.key_by('idx', 'a'); ht = ht.annotate(b=ht.idx); ht = ht.key_by('idx', 'b'); self.assertEqual(ht.aggregate(agg.sum(ht.idx)), 10); ```. ### What went wrong (all error messages here, including the full java stack trace):. ```; Java stack trace:; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.rvd.OrderedRVDType.<init>(OrderedRVDType.scala:21); 	at is.hail.rvd.OrderedRVDType.copy(OrderedRVDType.scala:121); 	at is.hail.expr.TableKeyBy.execute(Relational.scala:1857); 	at is.hail.expr.TableMapRows.execute(Relational.scala:2090); 	at is.hail.expr.TableKeyBy.execute(Relational.scala:1846); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:520); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:39); 	at is.hail.table.Table.aggregate(Table.scala:465); 	at is.hail.table.Table.aggregate(Table.scala:446); 	at is.hail.table.Table.aggregateJSON(Table.scala:436); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3748:335,message,messages,335,https://hail.is,https://github.com/hail-is/hail/issues/3748,1,['message'],['messages']
Integrability,"### Hail version:; fd300f29c00349d2a9d26835e35be2b142a3505f; ### What you did:; `make -C src/main/c prebuilt && ./gradlew testCppCodegen`; ### What went wrong (all error messages here, including the full java stack trace):; ```; testCppCodegen; :compileJava UP-TO-DATE; :generateBuildInfo; :nativeLib; tar -xzf libsimdpp-2.1.tar.gz; :compileScala UP-TO-DATE; :processResources UP-TO-DATE; :classes UP-TO-DATE; :compileTestJava UP-TO-DATE; :compileTestScala UP-TO-DATE; :processTestResources UP-TO-DATE; :testClasses UP-TO-DATE; :testCppCodegen; Running test: Test method testReadWrite(is.hail.annotations.AnnotationsSuite). Gradle suite > Gradle test > is.hail.annotations.AnnotationsSuite.testReadWrite FAILED; org.apache.spark.SparkException at AnnotationsSuite.scala:76; Caused by: java.lang.AssertionError; Running test: Test method testEmptyKeys(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testEmptyKeys FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testIntervalIterator(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testIntervalIterator FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testIntervalIteratorWorksWithGeneralEndpoints(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testIntervalIteratorWorksWithGeneralEndpoints FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testIterateFromUntil(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testIterateFromUntil FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testLowerBound(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testLowerBound FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testQueryByKey(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testQueryByKey FAILED; java.lang.AssertionError at",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4718:170,message,messages,170,https://hail.is,https://github.com/hail-is/hail/issues/4718,1,['message'],['messages']
Integrability,"### Hail version:; latest master. ### What you did:; remove `region.clear()` from the `it.map` function inside `RVD.persistRVRDD`. ### What went wrong (all error messages here, including the full java stack trace):. `LDPruneSuite.testNoPrune` fails giving 313 variants instead of 338.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3398:162,message,messages,162,https://hail.is,https://github.com/hail-is/hail/issues/3398,1,['message'],['messages']
Integrability,"### Hail version:; master branch version. ### What you did; ./gradlew -Dspark.version=2.1.0 shadowJar archiveZip. ### What went wrong (all error messages here, including the full java stack trace):. -XPS-8700:~/Downloads/hail$ ./gradlew -Dspark.version=2.1.0 shadowJar archiveZip; 669187030305. FAILURE: Build failed with an exception. * Where:; Build file '/home/test/Downloads/hail/build.gradle' line: 57. * What went wrong:; A problem occurred evaluating root project 'hail'.; > Unknown Spark version 2.1.0. Set breeze.version and py4j.version properties for Spark 2.1.0. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 2.33 secs",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3001:145,message,messages,145,https://hail.is,https://github.com/hail-is/hail/issues/3001,1,['message'],['messages']
Integrability,"### Hail version:; reported on Jan 11 9:45 by @nikbaya on [zulip](https://hail.zulipchat.com/#narrow/stream/123010-Hail-0.2E2.20support/topic/import_table.20IncompleteParseError). `00f9b64d8`; ### What you did:. ```; import hail as hl; phesant_still_more1 = hl.import_table('gs://ukb31063-mega-gwas/phenotype-files/still-more-phesant/neale_lab_parsed_and_restricted_to_QCed_samples_cat_variables_both_sexes.1.tsv',; missing='',impute=True,types={'all_sexes$userId':hl.tstr}).rename({'all_sexes$userId':'s'}); ```; ### What went wrong (all error messages here, including the full java stack trace):. ```; ---------------------------------------------------------------------------; IncompleteParseError Traceback (most recent call last); <ipython-input-2-ebe253e83367> in <module>(); 1 phesant_still_more1 = hl.import_table('gs://ukb31063-mega-gwas/phenotype-files/still-more-phesant/neale_lab_parsed_and_restricted_to_QCed_samples_cat_variables_both_sexes.1.tsv',; ----> 2 missing='',impute=True,types={'all_sexes$userId':hl.tstr}).rename({'all_sexes$userId':'s'}); 3 # phesant_still_more2 = hl.import_table('gs://ukb31063-mega-gwas/phenotype-files/still-more-phesant/neale_lab_parsed_and_restricted_to_QCed_samples_cat_variables_both_sexes.2.tsv',; 4 # missing='',impute=True,types={'all_sexes$userId':hl.tstr}). <decorator-gen-1108> in import_table(paths, key, min_partitions, impute, no_header, comment, delimiter, missing, types, quote, skip_blank_lines, force_bgz). /home/hail/hail.zip/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 558 def wrapper(__original_func, *args, **kwargs):; 559 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 560 return __original_func(*args_, **kwargs_); 561; 562 return wrapper. /home/hail/hail.zip/hail/methods/impex.py in import_table(paths, key, min_partitions, impute, no_header, comment, delimiter, missing, types, quote, skip_blank_lines, force_bgz); 1327 delimiter, missing, no_header, impu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5119:545,message,messages,545,https://hail.is,https://github.com/hail-is/hail/issues/5119,1,['message'],['messages']
Integrability,"### Summary of Changes. - make the vectorized IBS tests depend on libsmidpp, I have no idea how this wasn't failing builds before. - fix `generate-build-info.sh` to actually set `BRANCH` instead of setting the `DATE` to the current git branch. Also remove unnecessary parameter passing to `echo_build_properties`. - remove `doctest` as a separate build step (it's now part of python tests). - fix `DOCS_STATUS` in `hail-ci-build.sh`. - remove some unused files: `list_pypi_versions.py`, `publish-to-pypi.sh` (which duplicates, wrongly, `python/deploy.sh`. - simplify `python/deploy.sh`, by managing copied files in make, we no longer clean up files, but the JAR is only 30 MB anyway. - small change to `conftest.py` triggered a bad diff: I added a `try`/`finally` block to ensure we always return to the original working directory. I also fixed the path. - Use pytest [recommended directory structure](https://docs.pytest.org/en/latest/goodpractices.html) when your tests directory is a python module [1]. In particular, we now use:. ```; python/; - setup.py; - src/; - hail/; - __init__.py; - ...; - tests/; - __init__.py; - ...; ```. - Calculate number of cores using python's multiprocessing and use that as a default PARALLELISM parameter. - Move non-java/scala specific functionality out of `build.gradle` and into a `Makefile`. - The resulting rules are more succinct and correctly rely on file-system modification dependencies. - No use of `SPARK_HOME` and `PYTHONPATH`, and limited use of `PYSPARK_SUBMIT_ARGS`. Python tests now rely on the python package directly which handles correctly handles dependencies like `pyspark`. - There are also some phony targets for convenience: `jar`, `zip`, `pip-install`, `docs`, and `docs-no-test`. - Fix configuration of Spark version for the python package. The version is written by make into `python/spark_version` and read by `python/setup.py`. Many of the tests pass against 2.3.0, but there's some floating point value changes. - add breezeVersions ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5130:56,depend,depend,56,https://hail.is,https://github.com/hail-is/hail/pull/5130,1,['depend'],['depend']
Integrability,"### What happened?. - [ ] Document the AsyncFS interface, RouterAsyncFS, and the three clouds.; - [ ] Do a critical pass of the interfaces and make sure public methods don't have underscores and private methods do. When in doubt, make it private.; - [ ] Same as above but for parameters. For this, be particularly aggressive about making parameters private!; - [ ] Downgrade positional arguments to keyword-arguments as much as is feasible without severely degrading UX. ### Version. 0.2.126. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14021:47,interface,interface,47,https://hail.is,https://github.com/hail-is/hail/issues/14021,3,"['Rout', 'interface']","['RouterAsyncFS', 'interface', 'interfaces']"
Integrability,"### What happened?. > I'm hitting a 500 error when I try to open a notebook on a dataproc cluster started with hail 0.2.116. hailctl dataproc connect mw nb will open the google bucket and I am able to see all ipynb files but when I try opening one, I'm met with the 500. I have no issue with hail 0.2.113. Error from the logs:. ```; May 16 14:17:07 mw116-m python[8309]: [D 14:17:07.035 NotebookApp] Path notebook/css/override.css served from /opt/conda/miniconda3/lib/python3.10/site-packages/notebook/static/notebook/css/override.css; May 16 14:17:07 mw116-m python[8309]: [E 14:17:07.041 NotebookApp] Uncaught exception GET /notebooks/gnomad-mwilson/v4/sample_qc_defs.ipynb (127.0.0.1); May 16 14:17:07 mw116-m python[8309]: HTTPServerRequest(protocol='http', host='localhost:8123', method='GET', uri='/notebooks/gnomad-mwilson/v4/sample_qc_defs.ipynb', version='HTTP/1.1', remote_ip='127.0.0.1'); May 16 14:17:07 mw116-m python[8309]: Traceback (most recent call last):; May 16 14:17:07 mw116-m python[8309]: File ""/opt/conda/miniconda3/lib/python3.10/site-packages/tornado/web.py"", line 1786, in _execute; May 16 14:17:07 mw116-m python[8309]: result = await result; May 16 14:17:07 mw116-m python[8309]: File ""/opt/conda/miniconda3/lib/python3.10/site-packages/tornado/gen.py"", line 786, in run; May 16 14:17:07 mw116-m python[8309]: yielded = self.gen.send(value); May 16 14:17:07 mw116-m python[8309]: File ""/opt/conda/miniconda3/lib/python3.10/site-packages/notebook/notebook/handlers.py"", line 95, in get; May 16 14:17:07 mw116-m python[8309]: self.write(self.render_template('notebook.html',; May 16 14:17:07 mw116-m python[8309]: File ""/opt/conda/miniconda3/lib/python3.10/site-packages/notebook/base/handlers.py"", line 507, in render_template; May 16 14:17:07 mw116-m python[8309]: return template.render(**ns); May 16 14:17:07 mw116-m python[8309]: File ""/opt/conda/miniconda3/lib/python3.10/site-packages/jinja2/environment.py"", line 1301, in render; May 16 14:17:07 mw116-m python[8309",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13059:746,protocol,protocol,746,https://hail.is,https://github.com/hail-is/hail/issues/13059,1,['protocol'],['protocol']
Integrability,"### What happened?. A simple `hl.init()` fails, that used to work. Maybe an error with Spark, not an expert. ### Version. 0.2.108. ### Relevant log output. ```shell; ~ » python3; Python 3.10.9 (main, Dec 15 2022, 17:11:09) [Clang 14.0.0 (clang-1400.0.29.202)] on darwin; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import hail as hl; >>> hl.init(); 2023-01-27 17:15:28.940 WARN NativeCodeLoader:60 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-1758>"", line 2, in init; File ""/opt/homebrew/lib/python3.10/site-packages/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/homebrew/lib/python3.10/site-packages/hail/context.py"", line 345, in init; return init_spark(; File ""<decorator-gen-1760>"", line 2, in init_spark; File ""/opt/homebrew/lib/python3.10/site-packages/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/homebrew/lib/python3.10/site-packages/hail/context.py"", line 424, in init_spark; backend = SparkBackend(; File ""/opt/homebrew/lib/python3.10/site-packages/hail/backend/spark_backend.py"", line 188, in __init__; self._jbackend = hail_package.backend.spark.SparkBackend.apply(; File ""/opt/homebrew/lib/python3.10/site-packages/py4j/java_gateway.py"", line 1304, in __call__; return_value = get_return_value(; File ""/opt/homebrew/lib/python3.10/site-packages/py4j/protocol.py"", line 326, in get_return_value; raise Py4JJavaError(; py4j.protocol.Py4JJavaError: An error occurred while calling z:is.hail.backend.spark.SparkBackend.apply.; : java.lang.IllegalAccessError: class org.apache.spark.storage.StorageUtils$ (in unnamed module @0x4d740d85) cannot access class sun.n",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12630:874,wrap,wrapper,874,https://hail.is,https://github.com/hail-is/hail/issues/12630,1,['wrap'],['wrapper']
Integrability,"### What happened?. As [Patrick noted](https://github.com/hail-is/hail/pull/13619#pullrequestreview-1626963641):. > [StreamMap with requiresMemoryManagementPerElement] could be generally useful when the producer didn't care about memory management, but the map body allocates a lot and wants to free after each row---and then use that to make these smarter:. Consider, for example, `split_multi`. In both the sparse and non-sparse split-multi, we take an array which necessarily fits in memory, the alleles array, and generate a full row for each allele. The `StreamMap` which generates the rows should be memory managed. For a Python-level example consider this expression:. ```python3; hl.range(100).map(lambda x: hl.range(1_000_000)).map(hl.sum); ```. Although `free` ing each integer generated by the `range` is silly, we *do* want to free the 1M element array! In the current interface, it is not possible to request this. Indeed, this operation would consume 100GB of RAM if the simplifier wasn't able to fuse the sum and range. ### Version. 0.2.122. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13623:881,interface,interface,881,https://hail.is,https://github.com/hail-is/hail/issues/13623,1,['interface'],['interface']
Integrability,"### What happened?. At time of writing, building hail with `SPARK_VERSION=3.4.0` errors with the following message:. ```; hail/src/main/scala/is/hail/HailContext.scala:119:21: value implOpMulMatrix_DMD_DVD_eq_DVD is not a member of object breeze.linalg.DenseMatrix; ```. This is due to a major version upgrade and breaking change in the Breeze library on which spark and hail depend. The exact error is a rename and refactor. The method `DenseMatrix.implOpMulMatrix_DMD_DVD_eq_DVD` is now `HasOps.impl_OpMulMatrix_DMD_DVD_eq_DVD`. Notice the method name change and the fact that `HasOps` does not exist in the version of Breeze (1.x) that is used in Spark 3.3. Hail should build with Spark 3.4, but since we only officially support one version of Spark (whichever Dataproc currently is running), it would be reasonable to wait to fully upgrade to Spark 3.4 when [Dataproc 2.2](https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.2) is GA instead of trying to do something hacky to support both versions of Breeze. ### Version. 0.2.126. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13971:107,message,message,107,https://hail.is,https://github.com/hail-is/hail/issues/13971,2,"['depend', 'message']","['depend', 'message']"
Integrability,### What happened?. Bad error message. Should be a user-level nice error. https://discuss.hail.is/t/error-while-ld-pruning-variants-hail-utils-java-fatalerror-illegalargumentexception-requirement-failed/3371. ### Version. 0.2.114. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12971:30,message,message,30,https://hail.is,https://github.com/hail-is/hail/issues/12971,1,['message'],['message']
Integrability,"### What happened?. Batch now has the ability to offer a metadata server endpoint in the network namespaces of a `DockerJob`. We should add this functionality to `JVMJob`s so that QoB jobs can use the google default credential flow instead of relying on a GSA key file in the job container. While the implementation here could be trivial, we should make sure to load test it properly as QoB jobs can be very short (100s of ms). The simplest route would be to create/close a metadata server in the `JVMContainer` at the start/end of every job. If this incurs a penalty, since these `JVMContainer`s are long-lived we can run a long-lived metadata server and swap out the underlying credentials when user jobs start/stop. ### Version. 0.2.130. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14487:441,rout,route,441,https://hail.is,https://github.com/hail-is/hail/issues/14487,1,['rout'],['route']
Integrability,"### What happened?. Batch now supports organizing jobs into a hierarchy through job groups, but this is so far only used internally by Query on Batch. Users who want to leverage this structure cannot do so through the `hailtop.batch` interface. All jobs created by e.g. `b.new_job()` are implicitly assigned to the ""root"" job group. We should add the following to `hailtop.batch`:. - A `JobGroup` class to the public interface that shares any relevant methods that currently exist on the `Batch` class like `new_{bash|python}_job`, `wait`, etc.; - A method on `Batch` to create a new job group and a method on `JobGroup` to create a child job group; - A `JobGroup` should *not* have a `run` method, because there is no sound way in the lower-level batch client currently to only submit a subset of staged jobs/groups and it's unclear whether that behavior would ever be desired. ### Version. 0.2.132. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14610:234,interface,interface,234,https://hail.is,https://github.com/hail-is/hail/issues/14610,2,['interface'],['interface']
Integrability,"### What happened?. Consider these two programs. The first is faster, taking advantage of the fact that the count of the number of first alternate allele observations depends only on `variant_data`. Could Hail do this automatically? Could we modify variant_qc to facilitate this optimization?; ```; vds = hl.vds.read_vds(""some_very_big.vds""); mt = vds.variant_data; mt = hl.split_multi_hts(mt); mt = hl.variant_qc(mt); mt = mt.annotate_rows(AC100 = mt.variant_qc.AC[1] > 99); mt = mt.filter_rows(mt.AC100); vds.variant_data = mt; mt = hl.vds.to_dense_mt(vds); mt.write(""filtered.mt"", overwrite=True); ```; ```; vds = hl.vds.read_vds(""some_very_big.vds""); mt = hl.vds.to_dense_mt(vds); mt = hl.split_multi_hts(mt); mt = hl.variant_qc(mt); mt = mt.annotate_rows(AC100 = mt.variant_qc.AC[1] > 99); mt = mt.filter_rows(mt.AC100); mt.write(""filtered.mt"", overwrite=True); ```. ### Version. 0.2.124. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13695:167,depend,depends,167,https://hail.is,https://github.com/hail-is/hail/issues/13695,1,['depend'],['depends']
Integrability,"### What happened?. Currently, almost all of our tests are integration tests which require:; 1. Compiling Scala code.; 2. Building a JAR (takes ~30 seconds on my MBP); 3. Running pytest (can take as long as 20 seconds). All of this is a lot slower than iterating with a live running Scala process. We should have tests of various parts of the compiler operating at the IR level. For example, MatrixIR to TableIR lowering should have plenty of in Scala IR-level tests. Likewise for TableIR to CDAIR. The optimizer/simplifier should also have tests at each level which assert certain kinds of code is sufficiently cleaned up by the optimizer. ### Version. 0.2.122. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13638:59,integrat,integration,59,https://hail.is,https://github.com/hail-is/hail/issues/13638,1,['integrat'],['integration']
Integrability,"### What happened?. Hail propagates nicely explained error messages from java to python when an exception is thrown in the user's pipeline. However, the hail python front end does not handle a situation where the java backend disappears entirely, which can happen in the case of an OOM killer killing the JVM. The result is an error as seen below. In such a scenario, the python front end should add a useful message suggesting that the backend is not reachable and might have run out of memory. ### Version. 0.2.130. ### Relevant log output. ```shell; File ~/Library/Python/3.9/lib/python/site-packages/hail/table.py:2814, in Table.collect(self, _localize, _timed); 2812 e = construct_expr(rows_ir, hl.tarray(t.row.dtype)); 2813 if _localize:; → 2814 return Env.backend().execute(e._ir, timed=_timed); 2815 else:; 2816 return e. File ~/Library/Python/3.9/lib/python/site-packages/hail/backend/backend.py:188, in Backend.execute(self, ir, timed); 186 payload = ExecutePayload(self._render_ir(ir), ‘{“name”:“StreamBufferSpec”}’, timed); 187 try:; → 188 result, timings = self._rpc(ActionTag.EXECUTE, payload); 189 except FatalError as e:; 190 raise e.maybe_user_error(ir) from None. File ~/Library/Python/3.9/lib/python/site-packages/hail/backend/py4j_backend.py:218, in Py4JBackend._rpc(self, action, payload); 216 path = action_routes[action]; 217 port = self._backend_server_port; → 218 resp = self._requests_session.post(f’http://localhost:{port}{path}', data=data); 219 if resp.status_code >= 400:; 220 error_json = orjson.loads(resp.content). File ~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:637, in Session.post(self, url, data, json, **kwargs); 626 def post(self, url, data=None, json=None, **kwargs):; 627 r""""“Sends a POST request. Returns :class:Response object.; 628; 629 :param url: URL for the new :class:Request object.; (…); 634 :rtype: requests.Response; 635 “””; → 637 return self.request(“POST”, url, data=data, json=json, **kwargs). File ~/Library/Python/3.9/l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14557:59,message,messages,59,https://hail.is,https://github.com/hail-is/hail/issues/14557,2,['message'],"['message', 'messages']"
Integrability,"### What happened?. Here's a tail of the log showing the rapidly increasing RAM use. I'm working on a simple replicable pipeline now. Does not depend on the use of `filter_changed_loci`. ```; 2023-09-11 16:22:59.815 : INFO: RegionPool: REPORT_THRESHOLD: 1.0G allocated (662.3M blocks / 363.4M chunks), regions.size = 3, 0 current java objects, thread 24: Thread-3; 2023-09-11 16:23:01.488 : INFO: executing D-Array [table_scan_prefix_sums_singlestage] with 1 tasks, contexts size = 430.00 B, globals size = 2.52 MiB; 2023-09-11 16:23:01.540 : INFO: RegionPool: initialized for thread 115: Executor task launch worker for task 0.0 in stage 37.0 (TID 442); 2023-09-11 16:23:01.567 : INFO: RegionPool: REPORT_THRESHOLD: 2.2M allocated (64.0K blocks / 2.1M chunks), regions.size = 1, 0 current java objects, thread 115: Executor task launch worker for task 0.0 in stage 37.0 (TID 442); 2023-09-11 16:23:01.572 : INFO: RegionPool: REPORT_THRESHOLD: 4.2M allocated (64.0K blocks / 4.1M chunks), regions.size = 1, 0 current java objects, thread 115: Executor task launch worker for task 0.0 in stage 37.0 (TID 442); 2023-09-11 16:23:01.573 : INFO: RegionPool: REPORT_THRESHOLD: 4.3M allocated (64.0K blocks / 4.2M chunks), regions.size = 1, 0 current java objects, thread 115: Executor task launch worker for task 0.0 in stage 37.0 (TID 442); 2023-09-11 16:23:01.573 : INFO: RegionPool: REPORT_THRESHOLD: 4.3M allocated (128.0K blocks / 4.2M chunks), regions.size = 2, 0 current java objects, thread 115: Executor task launch worker for task 0.0 in stage 37.0 (TID 442); 2023-09-11 16:23:01.573 : INFO: RegionPool: REPORT_THRESHOLD: 12.3M allocated (192.0K blocks / 12.1M chunks), regions.size = 3, 0 current java objects, thread 115: Executor task launch worker for task 0.0 in stage 37.0 (TID 442); 2023-09-11 16:23:01.579 : INFO: RegionPool: REPORT_THRESHOLD: 12.4M allocated (192.0K blocks / 12.2M chunks), regions.size = 3, 0 current java objects, thread 115: Executor task launch worker for task 0.0 in",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13606:143,depend,depend,143,https://hail.is,https://github.com/hail-is/hail/issues/13606,1,['depend'],['depend']
Integrability,"### What happened?. I executed; ```; vds = hl.vds.filter_intervals(vds, pca_snps, keep=True); ```; And got this error. `pca_snps` is a Table. ; ```; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-1640>"", line 2, in filter_intervals; File ""/Users/juliasealock/opt/miniconda3/lib/python3.9/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/juliasealock/opt/miniconda3/lib/python3.9/site-packages/hail/vds/methods.py"", line 739, in filter_intervals; return _parameterized_filter_intervals(vds, intervals, keep=keep,; File ""<decorator-gen-1636>"", line 2, in _parameterized_filter_intervals; File ""/Users/juliasealock/opt/miniconda3/lib/python3.9/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/juliasealock/opt/miniconda3/lib/python3.9/site-packages/hail/vds/methods.py"", line 613, in _parameterized_filter_intervals; ref_intervals = intervals.map(; AttributeError: 'list' object has no attribute 'map'; ```. ### Version. 0.2.113. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12920:388,wrap,wrapper,388,https://hail.is,https://github.com/hail-is/hail/issues/12920,2,['wrap'],['wrapper']
Integrability,"### What happened?. I expected this to raise an error with a message like ""when indexing a matrix table, you must provide a row key and column key"".; ```; In [3]: import hail as hl; ...: mt = hl.balding_nichols_model(1, 1, 1); ...: mt2 = hl.balding_nichols_model(1,1,1); ...: ; ...: mt.annotate_rows(x=mt2[mt.locus, mt.alleles]); 2024-02-01 13:16:23.573 Hail: INFO: balding_nichols_model: generating genotypes for 1 populations, 1 samples, and 1 variants...; 2024-02-01 13:16:23.594 Hail: INFO: balding_nichols_model: generating genotypes for 1 populations, 1 samples, and 1 variants...; ---------------------------------------------------------------------------; ExpressionException Traceback (most recent call last); Cell In[3], line 5; 2 mt = hl.balding_nichols_model(1, 1, 1); 3 mt2 = hl.balding_nichols_model(1,1,1); ----> 5 mt.annotate_rows(x=mt2[mt.locus, mt.alleles]). File ~/projects/hail/hail/python/hail/matrixtable.py:818, in MatrixTable.__getitem__(self, item); 815 col_key = wrap_to_tuple(exprs[1]); 817 try:; --> 818 return self.index_entries(row_key, col_key); 819 except TypeError as e:; 820 raise invalid_usage from e. File ~/projects/hail/hail/python/hail/matrixtable.py:3193, in MatrixTable.index_entries(self, row_exprs, col_exprs); 3191 return self.index_entries(tuple(row_exprs[0].values()), col_exprs); 3192 elif len(row_exprs) != len(self.row_key):; -> 3193 raise ExpressionException(; 3194 f'Key mismatch: matrix table has {len(self.row_key)} row key fields, '; 3195 f'found {len(row_exprs)} index expressions'; 3196 ); 3197 else:; 3198 raise ExpressionException(; 3199 f""Key type mismatch: Cannot index matrix table with given expressions\n""; 3200 f"" MatrixTable row key: {', '.join(str(t) for t in self.row_key.dtype.values())}\n""; 3201 f"" Row index expressions: {', '.join(str(e.dtype) for e in row_exprs)}""; 3202 ). ExpressionException: Key mismatch: matrix table has 2 row key fields, found 1 index expressions; ```. ### Version. 0.2.127. ### Relevant log output. _No r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14237:61,message,message,61,https://hail.is,https://github.com/hail-is/hail/issues/14237,1,['message'],['message']
Integrability,### What happened?. I expected to see no error messages in the logs for a JVM container. Instead I found errors relating to assertion errors when setting up log4j. https://console.cloud.google.com/logs/query;query=%2528%0Aresource.type%3D%22gce_instance%22%0AlogName:%22jvm-2%22%0Alabels.%22compute.googleapis.com%2Fresource_name%22:%22batch-worker-default-standard-np-xj3g%22%0A%2529;timeRange=PT1H;summaryFields=:false:32:beginning;cursorTimestamp=2023-07-13T18:49:03.668876534Z?project=hail-vdc. ### Version. 0.2.119. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13242:47,message,messages,47,https://hail.is,https://github.com/hail-is/hail/issues/13242,1,['message'],['messages']
Integrability,### What happened?. I'm not sure why but the latest version of asyncio seems to use different event loops for non-default-scoped fixtures from the event loops for the tests. This causes issues with aiohttp.ClientSession which expects the event loop at allocation time to match the event loop at request time. It seems this was [an intentional change](https://github.com/pytest-dev/pytest-asyncio/issues/706#issue-2023749871) in pytest-asyncio 0.23.0. The pytest-asyncio website [documents how to ensure every test uses the same event loop](https://pytest-asyncio.readthedocs.io/en/latest/how-to-guides/run_session_tests_in_same_loop.html) ([archive](https://web.archive.org/web/20240108222050/https://pytest-asyncio.readthedocs.io/en/latest/how-to-guides/run_session_tests_in_same_loop.html)) but this does not appear to ensure that a module or session scoped fixtures share the same event loop as their dependent tests (I've created [an issue](https://github.com/pytest-dev/pytest-asyncio/issues/744) for this). ### Version. 42bf4517e6. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14130:904,depend,dependent,904,https://hail.is,https://github.com/hail-is/hail/issues/14130,1,['depend'],['dependent']
Integrability,"### What happened?. I've been trying to run VEP on ~3k variants using QoB but keep getting an output: 'ERROR: could not find log file' error (full error attached). I was able to run chr1 and chr2 separately but when I tried, I still got the same error message.; [vep_batch_error.txt](https://hail.zulipchat.com/user_uploads/4771/FwakSVmKTEQI7695UCsdF1fw/vep_batch_error.txt). I've also tried running it on dataproc but it takes hours and won't progress, which is weird for only 3k variants. trying again now on dataproc with high memory machines. The code I'm using is:; ```python3; import hail as hl; hl.init(gcs_requester_pays_configuration='daly-neale-sczmeta', driver_cores=8, driver_memory='highmem'); HT = 'gs://schema_jsealock/de_novo_analysis/schema1_de_novo_variants_grch38.ht'. ht = hl.read_table(HT).key_by(); ht = ht.key_by(ht.locus, ht.alleles).select(); ht_vep = hl.vep(ht, ""gs://hail-us-vep/vep95-GRCh38-loftee-gcloud.json""); ht_vep.write(""gs://schema_jsealock/de_novo_analysis/downsampled_vep95_annotated_de_novo_variants.ht"", overwrite=True); ```. ### Version. 0.2.126. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13989:252,message,message,252,https://hail.is,https://github.com/hail-is/hail/issues/13989,1,['message'],['message']
Integrability,"### What happened?. It might also be good to consider a better public-facing name. While nearly all jobs in Batch are scheduled on shared machines, a user sometimes wants a custom machine type that we don't offer shared pools for. The solution in that instance is a ""job-private"" machine, where we spin up a machine that lives and dies along with the single job that's scheduled on it. There is no public interface for this yet, and our few users that use it (for whom this feature was developed) do `j._machine_type = '<gcp-machine-type>'` to opt into this functionality. This feature is gaining more traction and we should create a proper API for it instead of using a private field. This shouldn't be much code at all, but we should spend a little thought on naming and ensure that it is properly documented and discoverable. There should also be a clear distinction in the documentation on the intended use case of this feature, how it differs from shared pools, and the cost penalty of using it (they pay for the lifetime of the instance not just the job). ### Version. 0.2.130. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14500:405,interface,interface,405,https://hail.is,https://github.com/hail-is/hail/issues/14500,1,['interface'],['interface']
Integrability,"### What happened?. Job groups are as of writing not generally usable in the public interface, but Query on Batch now uses them to structure actions and stages of computation. For example, a Hail Query session will have one Batch with the following job group structure:. ```; 1. read_table job group; - driver read_table job; 2. execute job group; - driver job; - stage 1 job group; - partition 1 job; - partition 2 job; …; - stage 2 job group; - partition 1 job; - partition 2 job; …; ```. but the current batch UI just has a jobs table listing all of the jobs in order of submission. It would be a huge boon to UX for users to be get a high level view of the structure of their query and to contextualize a failed job through its action > stage > partition structure. This should be an almost entirely front end change. It will likely involve additional HTTP endpoints but should not affect the batch data model or the way QoB engages with it. ### Version. 0.2.131. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14598:84,interface,interface,84,https://hail.is,https://github.com/hail-is/hail/issues/14598,1,['interface'],['interface']
Integrability,"### What happened?. Lindo tried to use JobResourceFiles a second time after updating the original batch, but got `FileNotFoundError`. This is because the default behavior is to delete temporary files with `b.run()`. We should add this use case to our documentation, but it might also be a good idea to eagerly catch these errors if possible and provide a better error message. I don't think we can change the default value at this point. https://hail.zulipchat.com/#narrow/stream/223457-Hail-Batch-support/topic/File.20dependency.20error/near/416647170. ### Version. 0.2.127. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14177:368,message,message,368,https://hail.is,https://github.com/hail-is/hail/issues/14177,1,['message'],['message']
Integrability,"### What happened?. One of our unit tests recently changed from taking around 20 seconds to being aborted by a time out after six hours — see populationgenomics/production-pipelines#352. This change turned out to coincide with the release of hail 0.2.113 and the unit test's `pip` selecting the new release. PR #12780 added a recursive `add_dependents` function to `LocalBackend`, that appears to be used to compute the transitive dependencies of each job. Profiling our unit test indicates that it is spending six hours inside this function with no end in sight. Running the job locally for a few seconds with more logging shows that it is calling `add_dependents` with the same `ancestor` and `child` millions of times. I'm not sure whether it's in an actual infinite loop or “merely” a combinatorial disaster than might terminate after a few months of runtime…. The following change, for example,. ```diff; --- a/hail/python/hailtop/batch/backend.py; +++ b/hail/python/hailtop/batch/backend.py; @@ -268,7 +268,7 @@ class LocalBackend(Backend[None]):; def add_dependents(ancestor, child):; dependent_jobs[ancestor].add(child); for ancestor_parent in ancestor._dependencies:; - add_dependents(ancestor_parent, child); + if child not in dependent_jobs[ancestor_parent]: add_dependents(ancestor_parent, child); ; for j in jobs:; for parent in j._dependencies:; ```. reduces it to calling it only once or twice for each `ancestor`/`child` combination, and returns the unit test to completing in ~20 seconds. I am not familiar enough with the data structure to say if that is a correct fix, but something of this nature appears to be needed to return this transitive dependency computation to a sensible runtime. ### Version. 0.2.113. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12915:431,depend,dependencies,431,https://hail.is,https://github.com/hail-is/hail/issues/12915,2,['depend'],"['dependencies', 'dependency']"
Integrability,"### What happened?. Removing the FIXME messages in `hailtop.batch_client.aioclient` in favor of a proper issue. This error needs to be fixed for `hailtop.batch_client.aioclient.JobGroup` as well once that code merges with #14282. ```python3; # FIXME Error if this is called while within a job of the same Batch; async def wait(; self,; *,; disable_progress_bar: bool = False,; description: str = '',; progress: Optional[BatchProgressBar] = None,; starting_job: int = 1,; ) -> Dict[str, Any]:; self._raise_if_not_created(); if description:; description += ': '; if progress is not None:; return await self._wait(description, progress, disable_progress_bar, starting_job); with BatchProgressBar(disable=disable_progress_bar) as progress2:; return await self._wait(description, progress2, disable_progress_bar, starting_job); ```. I'm not sure what the best fix is for this. An advanced user who wants to use Batch inside of Batch should really be making separate job groups from the job that job group is in and waiting for the job group that job is not a part of. ### Version. 0.2.128. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14338:39,message,messages,39,https://hail.is,https://github.com/hail-is/hail/issues/14338,1,['message'],['messages']
Integrability,"### What happened?. Reproduction steps - . - Log into [batch.hail.is](https://batch.hail.is/); - Go to the batches page; - Click Logout; - Get ""401: unauthorized"" message page (but user is never actually logged out); - Go to [auth.hail.is](https://auth.hail.is/); - Click logout; - Logout succeeds. Expected:; - Successful logout from any source page. ### Version. Batch - 0.2.132. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14635:163,message,message,163,https://hail.is,https://github.com/hail-is/hail/issues/14635,1,['message'],['message']
Integrability,"### What happened?. See #14385 for details. The minimum supported TLS version for the `batch` and `CI` ABS storage accounts is 1.0, but since these are internal storage accounts, we should abide by [recommended TLS versions](https://developers.cloudflare.com/ssl/reference/protocols/#decide-which-version-to-use). I would assume that our fairly up-to-date python libs are using 1.3, but we should verify this and then upgrade the minimum TLS version to 1.3. ### Version. 0.2.128. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14392:273,protocol,protocols,273,https://hail.is,https://github.com/hail-is/hail/issues/14392,1,['protocol'],['protocols']
Integrability,"### What happened?. See [Batch Metadata Server RFC](https://github.com/hail-is/hail-rfcs/blob/main/rfc/0012-keyless-job-auth.rst) for background. The objective of this issue is to fully remove GSA key files from Batch job filesystems, preventing possible exfiltration of long-lived credentials. Each remaining task should get its own issue if there isn't already one. Breakdown of tasks:. - [X] Implement a Batch metadata server and expose it in GCP `DockerJob`s (#14019); - [ ] Add metadata server support for `JVMJob`s aka Query-on-Batch in GCP (#14487); - [ ] Add metadata server support in Azure; - [ ] Deprecate and remove support for key files in `DockerJob`s; - [ ] Deprecate and remove support for key files in `JVMJob`s. This requires dropping support for old versions of hail that depend on the key file (up to and including at least 0.2.130). These steps get us past the security milestone of not exposing GSA key files to jobs and risking exfiltration. We might be able to go even further and get rid of key files entirely, which would reduce our operational burden of securing and rotating them.; - [ ] In GCP, use Service Account Impersonation to have the Batch Worker identity impersonate user GSAs, allowing it to create metadata server access tokens without the key files themselves; - [ ] In Azure, investigate if something like the above is even possible. At time of writing, it does not appear that there is an alternative other than storing credentials or adding users to the VM's metadata server. It is unclear whether this can be done dynamically and with what frequency and feels like not their intended use case. ### Version. 0.2.130. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14486:791,depend,depend,791,https://hail.is,https://github.com/hail-is/hail/issues/14486,1,['depend'],['depend']
Integrability,### What happened?. See: https://hail.zulipchat.com/#narrow/stream/128581-Cloud-support/topic/requester.20pays.20in.20batch. We need a way to configure the RouterFS in a Python file. Maybe `hfs.init`? I'm not sure. ### Version. 0.2.120. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13567:156,Rout,RouterFS,156,https://hail.is,https://github.com/hail-is/hail/issues/13567,1,['Rout'],['RouterFS']
Integrability,"### What happened?. Tasks that depend on the DB and TaskManager, like the scheduler, need to be properly cancelled upon shutdown before the DB/TaskManager are shutdown. This causes noisy errors in the logs and alerts. ### Version. 0.2.120. ### Relevant log output. ```shell; Traceback (most recent call last):; File ""/usr/local/lib/python3.8/dist-packages/gear/database.py"", line 190, in async_init; self.conn = await aenter(self.conn_context_manager); File ""/usr/local/lib/python3.8/dist-packages/gear/database.py"", line 79, in aenter; return await acontext_manager.__aenter__() # pylint: disable=unnecessary-dunder-call; File ""/usr/local/lib/python3.8/dist-packages/aiomysql/utils.py"", line 134, in __aenter__; self._conn = await self._coro; File ""/usr/local/lib/python3.8/dist-packages/aiomysql/pool.py"", line 139, in _acquire; raise RuntimeError(""Cannot acquire connection after closing pool""); RuntimeError: Cannot acquire connection after closing pool. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.8/dist-packages/hailtop/utils/utils.py"", line 895, in retry_long_running; return await f(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/hailtop/utils/utils.py"", line 917, in run_if_changed; should_wait = await f(*args, **kwargs); File ""/usr/local/lib/python3.8/dist-packages/batch/driver/instance_collection/pool.py"", line 591, in schedule_loop_body; user_resources = await self.compute_fair_share(); File ""/usr/local/lib/python3.8/dist-packages/batch/driver/instance_collection/pool.py"", line 499, in compute_fair_share; return await self._compute_fair_share(free_cores_mcpu); File ""/usr/local/lib/python3.8/dist-packages/batch/driver/instance_collection/pool.py"", line 525, in _compute_fair_share; async for record in records:; File ""/usr/local/lib/python3.8/dist-packages/gear/database.py"", line 320, in execute_and_fetchall; async with self.start() as tx:; File ""/usr/local/lib/python3.8/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13324:31,depend,depend,31,https://hail.is,https://github.com/hail-is/hail/issues/13324,1,['depend'],['depend']
Integrability,"### What happened?. The `hailtop.batch` client uploads a script file when the command becomes too large. This functionality frees users from thinking about the size of their commands. It's a great abstraction!. The client *does not* provide a mechanism to automatically upload local files or local directories which means that users must messily combine all their code and supporting data into one big file. For example,. ```python; local_in = hb.read_input('/path/to/local/script.sh'); local_data = hb.read_input('/path/to/small/local/reference.dat'). j = b.new_job(); j.command(f'bash {local_in} {local_data} {other_job.out_file} > {j.out_file}'); ```. It need not necessarily be `hb.read_input`, but it does seem like a good way to re-use an extant interface. `hailtop.batch` should upload those files when it uploads large script files and then download them to the appropriate jobs. ### Version. 0.2.128. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14354:752,interface,interface,752,https://hail.is,https://github.com/hail-is/hail/issues/14354,1,['interface'],['interface']
Integrability,"### What happened?. The `hailtop` package contains some public interfaces like the `hailtop.batch` module, but also some internal utility modules that are subject to change without warning, like `hailtop.utils` or `hailtop.auth`. It is non-obvious which modules are considered ""private"" and therefore will likely encounter breaking changes, leading to unfortunate incompatibilities like with [changing the name of the rich progress bar](https://github.com/hail-is/hail/pull/13832#issuecomment-1788106993). We should do some investigative work to discern what functionality in `hailtop` people (primarily the `gnomad` team) depend on and create stable interfaces for that code, then mark the rest as being private or more obviously subject to change. ### Version. 0.2.126. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14007:63,interface,interfaces,63,https://hail.is,https://github.com/hail-is/hail/issues/14007,3,"['depend', 'interface']","['depend', 'interfaces']"
Integrability,"### What happened?. The new UI for the batch and job pages is very shiny, but at CPG we've been collecting a few presentation issues with it — which are at least partly due to the way we use Hail (our automated batch submission tools for one thing) differing from the way you do. * Our batch names tend to be very long and without whitespace, which makes the Batch name column even wider than it was in the old UI and makes the table very wide. This column could probably benefit from some maximum-width settings and perhaps word-wrapping hints. * I miss the start-time column on the batches list page, which gave an idea of which batches are recent and which are from last week etc. (There'd be alternatives to adding a column to convey this information — e.g., there could be subheading rows in the table saying “Yesterday”, …, “Monday July 15th”, etc.). * On the job page the entry labeled Pending is actually the total of pending and running jobs, which is a bit misleading. ### Version. 0.2.132. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14628:530,wrap,wrapping,530,https://hail.is,https://github.com/hail-is/hail/issues/14628,1,['wrap'],['wrapping']
Integrability,"### What happened?. The spark and local backends use `py4j` to execute methods on java backends. `py4j` uses a TCP socket and a text-based protocol to communicate between python and the jvm and handles marshaling of data between the two processes. Unfortunately it has poor memory performance with large byte arrays, as the text protocol requires base64 encoding byte arrays and it uses Java `String`s which, being UTF-16, more than double the size of the original data in memory. Hail should not use `py4j` for these operations and just open its own connection to the java backend. This gives us the control to not use more memory than is necessary to just ship bytes back and forth. This also provides an opportunity to deduplicate some code as the `ServiceBackend` already communicates writes its inputs over a socket instead of using `py4j` (there is no live JVM to communicate to in the `ServiceBackend` case, so it must serialize the requested operation to be run at a later time on a different machine). ### Version. 0.2.124. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13756:139,protocol,protocol,139,https://hail.is,https://github.com/hail-is/hail/issues/13756,2,['protocol'],['protocol']
Integrability,"### What happened?. The use of the term ""shard"" to mean ""partition"" is an unnecessary synonym which may lead to user confusion. We should deprecate that argument and eliminate the terminology from our interface as much as possible. `Table.export` should accept `header_per_partition` instead. We should deprecate the `shard-manifest.txt` file and start also writing `manifest.txt`. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13511:201,interface,interface,201,https://hail.is,https://github.com/hail-is/hail/issues/13511,1,['interface'],['interface']
Integrability,"### What happened?. This is a follow up issue to a comment in the job groups PR #14282. The queries for the scheduler and canceller both pull the job groups that are schedulable/cancellable and then makes one of two queries depending on if the job is always run. This can be confusing that there's two similar queries and requires multiple calls to the database. There's a question here on whether it is possible to come up with a more efficient query given the indices we have or do we need to create a new index to support this. In case it's hard to find the exact comment in the PR, I pasted an example thread below:. Example comment from Dan: https://github.com/hail-is/hail/pull/14170/files#r1476847018. This is my concrete critqiue: the two SQL queries are nearly the same, but they are long enough to; make seeing that challenging. ```sql; SELECT jobs.batch_id, jobs.job_id; FROM jobs FORCE INDEX(jobs_batch_id_state_always_run_cancelled); WHERE batch_id = %s AND job_group_id = %s AND state = 'Ready' AND always_run = 0; LIMIT %s;; ```. ```sql; SELECT jobs.batch_id, jobs.job_id; FROM jobs FORCE INDEX(jobs_batch_id_state_always_run_cancelled); WHERE batch_id = %s AND job_group_id = %s AND state = 'Ready' AND always_run = 0 AND cancelled = 1; LIMIT %s;; ```. They only differ in the cancelled condition. As a reader, I'd prefer code that revealed that; similarity and used names to suggest what the difference was doing, and maybe a comment, if there is; no better way to say it, indicaing what you indicated in your GitHub comment. ```python3; if job_group['cancelled']:; where_job_needs_cancelling = '' # every job in a cancelled group needs cancelling; else:; where_job_needs_cancelling = 'AND jobs.cancelled' # jobs.cancelled means child of a failed job; query_for_jobs_to_be_cancelled = f""""""; SELECT jobs.batch_id, jobs.job_id; FROM jobs FORCE INDEX(jobs_batch_id_state_always_run_cancelled); WHERE batch_id = %s; AND job_group_id = %s; AND state = 'Ready'; AND NOT always_run; {where_j",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14412:224,depend,depending,224,https://hail.is,https://github.com/hail-is/hail/issues/14412,1,['depend'],['depending']
Integrability,"### What happened?. We observed this error log message . ```; deleting disk batch-disk-3d106c666a364d82bec3 from instance that no longer exists; ```. followed by what appears to be an endless stream of the following assertion error in the background task loop that tries to delete orphaned disks:. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py"", line 915, in retry_long_running; return await f(*args, **kwargs); File ""/usr/local/lib/python3.9/dist-packages/hailtop/utils/utils.py"", line 959, in loop; await f(*args, **kwargs); File ""/usr/local/lib/python3.9/dist-packages/batch/cloud/gcp/driver/driver.py"", line 180, in delete_orphaned_disks; await delete_orphaned_disks(; File ""/usr/local/lib/python3.9/dist-packages/batch/cloud/gcp/driver/disks.py"", line 30, in delete_orphaned_disks; async for disk in await compute_client.list(f'/zones/{zone}/disks', params=params):; File ""/usr/local/lib/python3.9/dist-packages/hailtop/aiocloud/aiogoogle/client/compute_client.py"", line 59, in __anext__; assert 'pageToken' not in self._request_params; AssertionError; ```. This is an invalid state for the `PagedIterator` to be in, and could imply that this garbage disk collection loop just doesn't work. We should track down the broken invariant here and fix it, if possible testing that the async iterator works correctly. ### Version. 0.2.132. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14613:47,message,message,47,https://hail.is,https://github.com/hail-is/hail/issues/14613,1,['message'],['message']
Integrability,"### What happened?. When trying to union the rows of MatrixTables, I get `AttributeError: module 'hail' has no attribute 'ir'`:; ```; ---------------------------------------------------------------------------; AttributeError Traceback (most recent call last); Input In [20], in <cell line: 1>(); ----> 1 mts[0].union_rows(mts[1]). File <decorator-gen-1309>:2, in union_rows(_check_cols, *datasets). File ~/.local/lib/python3.9/site-packages/hail/typecheck/check.py:584, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 581 @decorator; 582 def wrapper(__original_func, *args, **kwargs):; 583 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 584 return __original_func(*args_, **kwargs_). File ~/.local/lib/python3.9/site-packages/hail/matrixtable.py:3858, in MatrixTable.union_rows(_check_cols, *datasets); 3854 raise ValueError(error_msg.format(; 3855 ""col key types"", 0, first.col_key.dtype, i + 1, next.col_key.dtype; 3856 )); 3857 if _check_cols:; -> 3858 wrong_keys = hl.eval(hl.rbind(first.col_key.collect(_localize=False), lambda first_keys: (; 3859 hl.enumerate([mt.col_key.collect(_localize=False) for mt in datasets[1:]]); 3860 .find(lambda x: ~(x[1] == first_keys))[0]))); 3861 if wrong_keys is not None:; 3862 raise ValueError(f""'MatrixTable.union_rows' expects all datasets to have the same columns. ""; 3863 f""Datasets 0 and {wrong_keys + 1} have different columns (or possibly different order).""). File <decorator-gen-561>:2, in collect(self, _localize). File ~/.local/lib/python3.9/site-packages/hail/typecheck/check.py:584, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 581 @decorator; 582 def wrapper(__original_func, *args, **kwargs):; 583 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 584 return __original_func(*args_, **kwargs_). File ~/.local/lib/python3.9/site-packages/hail/expr/expressions/base_expression.py:1129, in Expression.collect(self, _loca",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13230:493,wrap,wrapper,493,https://hail.is,https://github.com/hail-is/hail/issues/13230,2,['wrap'],['wrapper']
Integrability,### What happened?. [Open ID Connect](https://auth0.com/docs/authenticate/protocols/openid-connect-protocol) is a standard that allows you to basically exchange a proof of identity from identity provider X for an authorized token at identity provider Y. We should support using GCP credentials + OIDC to copy files to and from AWS and Azure. We should then remove the AWS and Azure keys from our GCP deployment that are used to run inter-cloud copy tests. ### Version. 0.2.122. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13613:74,protocol,protocols,74,https://hail.is,https://github.com/hail-is/hail/issues/13613,2,['protocol'],"['protocol', 'protocols']"
Integrability,"### What happened?. [SAIGE](https://github.com/weizhouUMICH/SAIGE) and its competitor [REGENIE](https://rgcgithub.github.io/regenie/) are the standard bearers for modern GWAS. Hail should expose SAIGE within the Hail Query language. The interface should roughly match `hl.linear_regression_rows`. A Batch pipeline would serve the needs of Broadies (and, indeed, such a pipeline already exists) but has two downsides:; 1. There is substantial I/O involved in exporting the data from Hail-native formats to SAIGE-compatible formats.; 2. Non-Broadies cannot use this pipeline. Query language support for SAIGE would transform the accessibility of SAIGE by making it usable at scale by anyone with access to Hail, which is basically anyone with a large dataset (e.g. [DNANexus](https://med.stanford.edu/gbsc/projects/vapahcs.html), [AoU RWB](https://support.researchallofus.org/hc/en-us/articles/6090679838100-How-to-Work-with-All-of-Us-Genomic-Data-Hail-Plink-), [MVP](https://med.stanford.edu/gbsc/projects/vapahcs.html), [FinnGen](https://www.medrxiv.org/content/10.1101/2022.03.03.22271360v1.full)). There are two options:; 1. Determine and implement the linear algebraic primitives necessary for SAIGE.; 2. Compile and link directly against SAIGE. Expose these functions, via JNI, to the Hail Query language. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13442:237,interface,interface,237,https://hail.is,https://github.com/hail-is/hail/issues/13442,1,['interface'],['interface']
Integrability,"### What happened?. [a user attempted to run `conda install bioconda::hail` or some variation of that](https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/jdk11/near/418930859), and it looks like [the hail package on anaconda.org](https://anaconda.org/bioconda/hail) has [a dependency](https://bioconda.github.io/recipes/hail/README.html) on `openjdk 8.*`, which prevents users from using `openjdk 11.*` with it, and is also a pretty old version from over a year ago. the recipe for the hail package on anaconda.org should be updated to have accurate dependencies and use the current version of hail, or we should ask that it be removed if we recommend only installing hail through `pip`. ### Version. n/a. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14229:302,depend,dependency,302,https://hail.is,https://github.com/hail-is/hail/issues/14229,2,['depend'],"['dependencies', 'dependency']"
Integrability,"### What happened?. `StructExpression` s are Dict-like and we rely on this behavior for methods like `.items()`. We should probably ban the use of names like `items` so that you can always iterate over a struct expressions field names and field value expressions. ```python3; ht = ht.group_by(; 'gene'; ).aggregate(; items=hl.agg.take(ht.key, max(list(n_dict.values())), ordering = ht.rand_id); ); ```; ```; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); /tmp/ipykernel_9677/3768472856.py in <cell line: 1>(); ----> 1 ht = ht.group_by('gene').aggregate(items=hl.agg.take(ht.key, max(list(n_dict.values())), ordering = ht.rand_id)). <decorator-gen-1202> in aggregate(self, **named_exprs). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 582 def wrapper(__original_func, *args, **kwargs):; 583 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 584 return __original_func(*args_, **kwargs_); 585; 586 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in aggregate(self, **named_exprs); 243; 244 key_struct = self._key_expr; --> 245 return Table(ir.TableKeyByAndAggregate(base._tir,; 246 hl.struct(**named_exprs)._ir,; 247 key_struct._ir,. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in __init__(self, tir); 365; 366 for k, v in itertools.chain(self._globals.items(),; --> 367 self._row.items()):; 368 self._set_field(k, v); 369. TypeError: 'ArrayStructExpression' object is not callable; ```. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13495:841,wrap,wrapper,841,https://hail.is,https://github.com/hail-is/hail/issues/13495,3,['wrap'],['wrapper']
Integrability,"### What happened?. ```; In [9]: import hail as hl; ...: mt = hl.utils.range_matrix_table(2,2); ...: mt = mt.annotate_entries(prod = mt.row_idx * mt.col_idx); ...: hl.logistic_regression_rows(y=mt.row_idx, x=mt.prod, test='wald', covariates=[1.0]).describe(); ---------------------------------------------------------------------------; KeyError Traceback (most recent call last); Cell In[9], line 4; 2 mt = hl.utils.range_matrix_table(2,2); 3 mt = mt.annotate_entries(prod = mt.row_idx * mt.col_idx); ----> 4 hl.logistic_regression_rows(y=mt.row_idx, x=mt.prod, test='wald', covariates=[1.0]).describe(). File <decorator-gen-1708>:2, in logistic_regression_rows(test, y, x, covariates, pass_through, max_iterations, tolerance). File ~/projects/hail/hail/python/hail/typecheck/check.py:587, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 584 @decorator; 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_). File ~/projects/hail/hail/python/hail/methods/statgen.py:921, in logistic_regression_rows(test, y, x, covariates, pass_through, max_iterations, tolerance); 918 if not y_is_list:; 919 result = result.transmute(**result.logistic_regression[0]); --> 921 return result.persist(). File <decorator-gen-1242>:2, in persist(self, storage_level). File ~/projects/hail/hail/python/hail/typecheck/check.py:587, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 584 @decorator; 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_). File ~/projects/hail/hail/python/hail/table.py:2112, in Table.persist(self, storage_level); 2076 @typecheck_method(storage_level=storage_level); 2077 def persist(self, storage_level='MEMORY_AND_DISK') -> 'Tab",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13788:813,wrap,wrapper,813,https://hail.is,https://github.com/hail-is/hail/issues/13788,2,['wrap'],['wrapper']
Integrability,"### What happened?. ```; Python 3.10.14 (main, Mar 19 2024, 21:46:16) [Clang 15.0.0 (clang-1500.1.0.2.5)] on darwin; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import hail as hl; >>> hl.init(backend='batch'); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-1610>"", line 2, in init; File ""/Users/cvittal/src/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); File ""/Users/cvittal/src/hail/hail/python/hail/typecheck/check.py"", line 554, in check_all; kwargs_[arg_name] = arg_check(arg, name, arg_name, checker); File ""/Users/cvittal/src/hail/hail/python/hail/typecheck/check.py"", line 592, in arg_check; return checker.check(arg, function_name, arg_name); File ""/Users/cvittal/src/hail/hail/python/hail/typecheck/check.py"", line 82, in check; return tc.check(x, caller, param); File ""/Users/cvittal/src/hail/hail/python/hail/typecheck/check.py"", line 61, in check; return self.tc.check(x, caller, param); File ""/Users/cvittal/src/hail/hail/python/hail/typecheck/check.py"", line 51, in tc; t = self.f(); File ""/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/typing.py"", line 957, in __call__; result = self.__origin__(*args, **kwargs); File ""/opt/homebrew/Cellar/python@3.10/3.10.14/Frameworks/Python.framework/Versions/3.10/lib/python3.10/typing.py"", line 387, in __call__; raise TypeError(f""Cannot instantiate {self!r}""); TypeError: Cannot instantiate typing.Literal; ```. Introduced in #14512. ### Version. main. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14573:442,wrap,wrapper,442,https://hail.is,https://github.com/hail-is/hail/issues/14573,1,['wrap'],['wrapper']
Integrability,"### What happened?. ```python3; --- Logging error ---; Traceback (most recent call last):; File ""/usr/lib/python3.9/logging/__init__.py"", line 1083, in emit; msg = self.format(record); File ""/usr/lib/python3.9/logging/__init__.py"", line 927, in format; return fmt.format(record); File ""/usr/local/lib/python3.9/dist-packages/pythonjsonlogger/jsonlogger.py"", line 246, in format; return self.serialize_log_record(log_record); File ""/usr/local/lib/python3.9/dist-packages/pythonjsonlogger/jsonlogger.py"", line 215, in serialize_log_record; return ""%s%s"" % (self.prefix, self.jsonify_log_record(log_record)); File ""/usr/local/lib/python3.9/dist-packages/pythonjsonlogger/jsonlogger.py"", line 207, in jsonify_log_record; return self.json_serializer(log_record,; File ""/usr/local/lib/python3.9/dist-packages/hailtop/hail_logging.py"", line 18, in logger_json_serializer; assert default is None and cls is OrJsonEncoder and indent is None and ensure_ascii is False, (; AssertionError: (None, <class 'hailtop.hail_logging.OrJsonEncoder'>, None, False); Call stack:; File ""/usr/local/lib/python3.9/dist-packages/aiohttp/client.py"", line 367, in __del__; self._loop.call_exception_handler(context); File ""/usr/lib/python3.9/asyncio/base_events.py"", line 1779, in call_exception_handler; self.default_exception_handler(context); File ""/usr/lib/python3.9/asyncio/base_events.py"", line 1753, in default_exception_handler; logger.error('\n'.join(log_lines), exc_info=exc_info); Message: 'Unclosed client session\nclient_session: <aiohttp.client.ClientSession object at 0x7ff9c8559490>'. ```. https://cloudlogging.app.goo.gl/PafWAh6xZEuQFhr78. ### Version. 0.2.127. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14261:1464,Message,Message,1464,https://hail.is,https://github.com/hail-is/hail/issues/14261,1,['Message'],['Message']
Integrability,"### What happened?. `hailctl dataproc start` fails with an error message like the one below because [in Dataproc 2.2](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/network#:~:text=Internal%20addresses%20only%20(no%2Daddress)%20is%20set%20by%20default%20when%20creating%20a%20Dataproc%202.2%20image%20version%20cluster.%20You%20can%20use%20the%20gcloud%20dataproc%20clusters%20create%20%2D%2Dpublic%2Dip%2Daddress%20flag%20to%20enable%20public%20IP%20addresses.), clusters are created without public internet access by default. A workaround is to pass the `--public-ip-address` flag to the command. Error message:. ```python; pip packages are ['setuptools', 'mkl<2020', 'lxml<5', 'https://github.com/hail-is/jgscm/archive/v0.1.13+hail.zip', 'ipykernel==6.22.0', 'ipywidgets==8.0.6', 'jupyter-console==6.6.3', 'nbconvert==7.3.1', 'notebook==6.5.6', 'qtconsole==5.4.2', 'aiodns==2.0.0', 'aiohttp==3.9.5', 'aiosignal==1.3.1', 'async-timeout==4.0.3', 'attrs==23.2.0', 'avro==1.11.3', 'azure-common==1.1.28', 'azure-core==1.30.2', 'azure-identity==1.17.1', 'azure-mgmt-core==1.4.0', 'azure-mgmt-storage==20.1.0', 'azure-storage-blob==12.20.0', 'bokeh==3.3.4', 'boto3==1.34.138', 'botocore==1.34.138', 'cachetools==5.3.3', 'certifi==2024.6.2', 'cffi==1.16.0', 'charset-normalizer==3.3.2', 'click==8.1.7', 'commonmark==0.9.1', 'contourpy==1.2.1', 'cryptography==42.0.8', 'decorator==4.4.2', 'deprecated==1.2.14', 'dill==0.3.8', 'frozenlist==1.4.1', 'google-auth==2.31.0', 'google-auth-oauthlib==0.8.0', 'humanize==1.1.0', 'idna==3.7', 'isodate==0.6.1', 'janus==1.0.0', 'jinja2==3.1.4', 'jmespath==1.0.1', 'jproperties==2.1.1', 'markupsafe==2.1.5', 'msal==1.29.0', 'msal-extensions==1.2.0', 'msrest==0.7.1', 'multidict==6.0.5', 'nest-asyncio==1.6.0', 'numpy==1.26.4', 'oauthlib==3.2.2', 'orjson==3.10.6', 'packaging==24.1', 'pandas==2.2.2', 'parsimonious==0.10.0', 'pillow==10.4.0', 'plotly==5.22.0', 'portalocker==2.10.0', 'protobuf==3.20.2', 'py4j==0.10.9.7', 'pyasn1==0.6.0', 'pyasn1-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14652:65,message,message,65,https://hail.is,https://github.com/hail-is/hail/issues/14652,2,['message'],['message']
Integrability,"### What happened?. `hl.maximal_independent_set` should return the same independent set regardless of the ordering of the input table. gnomAD team reports that the returned set can differ depending on whether or not the input table had been written or came directly from PC-Relate. I have yet to create a simple reproducible example. Permuting the entries in this array does not change the output. I always get 'a' and 'b'. I suspect this is because what really matters is the order in which we traverse the entries of the multi map which depends on the hash of the nodes. I think a durable fix might be to eliminate the MultiMap, insert all the nodes into the binary heap, then increment priority for each edge detected. This will perform more reflows of the heap, but eliminates the non-determinism of MultiMap iteration order. ```; import hail as hl; ht = hl.Table.parallelize([; hl.Struct(i=hl.Struct(s=x[0]), j=hl.Struct(s=x[1])); for x in [('c', 'a'), ('a', 'b'), ('b', 'c'), ]; ]); hl.maximal_independent_set(ht.i, ht.j, False).collect(); ```. ### Version. 0.2.122. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13635:188,depend,depending,188,https://hail.is,https://github.com/hail-is/hail/issues/13635,2,['depend'],"['depending', 'depends']"
Integrability,"### What happened?. e.g. see an attempt to use build_python_image to execute some Hail code in the cloud: https://hail.zulipchat.com/#narrow/stream/223457-Hail-Batch-support/topic/Error.20in.20QoB.3A.20unknown.20opcode. We should provide users with a simple and straightforward project structure and mechanism for working with a local Python project, its Python dependencies, including, possibly, Hail. It seems to me that a relatively straightforward way to do this would be to recommend the user create a normal, installable python package (and provide instructions on doing so), and then to provide some Hail Batch client functionality that builds an image based on `hailgenetics/hail` (if Hail is required) or `hailgenetics/python-dill` or a user-provided base image (which must have Python, but we'll ensure dill gets installed). The Dockerfile should look something like:. ```; FROM {base_image}; COPY {users_project_dir} /users_project; RUN pip install /users_project; ```. And then that image can be used as the python_default_image (maybe also the default_image?). ### Version. 0.2.117. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13161:362,depend,dependencies,362,https://hail.is,https://github.com/hail-is/hail/issues/13161,1,['depend'],['dependencies']
Integrability,"### What happened?. https://ci.hail.is/batches/7450431/jobs/109. After https://github.com/hail-is/hail/pull/13043 merges, we'll always recur through the causal chain so we just need to retry `java.net.SocketTimeoutException: connect timed out`. ```; E is.hail.relocated.org.apache.http.conn.ConnectTimeoutException: Connect to internal.hail:80 [internal.hail/10.128.0.57] failed: connect timed out; E 	at is.hail.relocated.org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:151); E 	at is.hail.relocated.org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:376); E 	at is.hail.relocated.org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:393); E 	at is.hail.relocated.org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:236); E 	at is.hail.relocated.org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:186); E 	at is.hail.relocated.org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89); E 	at is.hail.relocated.org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:110); E 	at is.hail.relocated.org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185); E 	at is.hail.relocated.org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83); E 	at is.hail.relocated.org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108); E 	at is.hail.services.Requester.$anonfun$requestWithHandler$1(Requester.scala:79); E 	at is.hail.services.package$.retryTransientErrors(package.scala:134); E 	at is.hail.services.Requester.requestWithHandler(Requester.scala:78); E 	at is.hail.services.Requester.request(Requester.scala:104); E 	at is.hail.services.batch_client.BatchClient.post(BatchClient.scala:60); E 	at is.hail.services.batch_client.BatchClient.$anonfun$update$1(BatchClient.scala:92); E 	at is.hail.services.p",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13074:949,Protocol,ProtocolExec,949,https://hail.is,https://github.com/hail-is/hail/issues/13074,2,['Protocol'],['ProtocolExec']
Integrability,"### What happened?. https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/SocketException.20when.20writing.20Table. Issues two and three at that Zulip thread have stack traces indicating that a single partition table went through the single partition fast path on the Driver. The Driver is allowed to execute single partition tables on itself rather than on a worker. BackendUtils.scala:38 implements this behavior. We need a `retryTransientErrors` around that line. ### Version. 0.2.115-71fc978b5c22. ### Relevant log output. ```shell; mt.write(str(out_mt_path), overwrite=True); File ""<decorator-gen-1244>"", line 2, in write; File ""/usr/local/lib/python3.10/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/usr/local/lib/python3.10/site-packages/hail/matrixtable.py"", line 2740, in write; Env.backend().execute(ir.MatrixWrite(self._mir, writer)); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 487, in execute; return self._cancel_on_ctrl_c(self._async_execute(ir, timed=timed)); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 479, in _cancel_on_ctrl_c; return async_to_blocking(coro); File ""/usr/local/lib/python3.10/site-packages/hailtop/utils/utils.py"", line 154, in async_to_blocking; return loop.run_until_complete(task); File ""/usr/local/lib/python3.10/site-packages/nest_asyncio.py"", line 90, in run_until_complete; return f.result(); File ""/usr/local/lib/python3.10/asyncio/futures.py"", line 201, in result; raise self._exception.with_traceback(self._exception_tb); File ""/usr/local/lib/python3.10/asyncio/tasks.py"", line 232, in __step; result = coro.send(None); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_backend.py"", line 506, in _async_execute; _, resp, timings = await self._rpc('execute(...)', inputs, ir=ir, progress=progress); File ""/usr/local/lib/python3.10/site-packages/hail/backend/service_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12982:739,wrap,wrapper,739,https://hail.is,https://github.com/hail-is/hail/issues/12982,1,['wrap'],['wrapper']
Integrability,"### What you did:. ```; ht.group_by('model', 'rank_id', 'bin').aggregate(titv=ht.n_ti/ht.n_tv, ; min_score=hl.agg.min(ht.min_score),; max_score=hl.agg.min(ht.max_score); ).show(); ```; ### What went wrong (all error messages here, including the full java stack trace):; ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-26-65c5654a1482> in <module>(); 1 ht.group_by('model', 'rank_id', 'bin').aggregate(titv=ht.n_ti/ht.n_tv, ; 2 min_score=hl.agg.min(ht.min_score),; ----> 3 max_score=hl.agg.min(ht.max_score); 4 ).show(). /home/hail/gnomad_hail/utils/plotting.py in new_show(t, n, width, truncate, types); 24 ; 25 def new_show(t, n=10, width=170, truncate=40, types=True):; ---> 26 old_show(t, n, width, truncate, types); 27 hl.Table.show = new_show; 28 . /home/hail/hail.zip/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). /home/hail/hail.zip/hail/table.py in show(self, n, width, truncate, types); 1215 Print an extra header line with the type of each field.; 1216 """"""; -> 1217 print(self._show(n,width, truncate, types)); 1218 ; 1219 def _show(self, n=10, width=90, truncate=None, types=True):. /home/hail/hail.zip/hail/table.py in _show(self, n, width, truncate, types); 1218 ; 1219 def _show(self, n=10, width=90, truncate=None, types=True):; -> 1220 return self._jt.showString(n, joption(truncate), types, width); 1221 ; 1222 def index(self, *exprs):. /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwarg",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4110:1171,wrap,wrapper,1171,https://hail.is,https://github.com/hail-is/hail/issues/4110,3,['wrap'],['wrapper']
Integrability,"###Hail version; N/A Kubernetes v1 API, cluster version 1.10.11. ### What you did; Attempted to schedule a pod through app.hail.is. Waited ~20 minutes. ### What went wrong (all error messages here, including the full java stack trace); Simply stuck in Not PodScheduled (status.condition contains an entry of {status: False, type: PodScheduled} ). This status is also verified using kubectl get pods -w. Total number of pods did not seem onerous by quantity alone, so this must be an issue of resource utilization by some of these pods. ```sh; NAME READY STATUS RESTARTS AGE; apiserver-8658d59d48-r8p6w 1/1 Running 0 9d; auth-gateway-deployment-7d7cf8846f-l5m9b 1/1 Running 0 14h; batch-deployment-6448f84d9c-gxn2c 1/1 Running 0 1h; dk-test-58dffcd944-9xkkx 1/1 Running 0 11d; frontend-766c875db4-cmpvx 1/1 Running 0 8d; gateway-deployment-78c4dd64f5-tdnnc 1/1 Running 0 1h; hail-ci-deployment-5744fd6964-s29xb 1/1 Running 0 1h; image-fetcher-bkpcc 1/1 Running 0 23m; image-fetcher-gb9rs 1/1 Running 0 26m; image-fetcher-glj5p 1/1 Running 0 25m; image-fetcher-kjd7z 1/1 Running 0 23m; image-fetcher-vhv74 1/1 Running 0 25m; image-fetcher-zppvc 1/1 Running 0 24m; notebook-api-deployment-7bb85bfd-z6mvp 1/1 Running 0 12h; notebook-deployment-8546dbcb7c-zfc4r 1/1 Running 0 1h; notebook-worker-2lt2l 1/1 Running 0 46m; notebook-worker-77nqq 1/1 Running 0 1h; notebook-worker-fljx6 1/1 Running 0 3h; notebook-worker-gm6lz 1/1 Running 0 36m; notebook-worker-kj7bb 1/1 Running 0 3h; notebook-worker-n8dgv 0/1 Pending 0 4m; notebook-worker-pshdf 1/1 Running 0 35m; scorecard-deployment-654f774444-vwpzr 1/1 Running 0 51m; site-deployment-6789bd6c5b-lxbxk 1/1 Running 0 51m; spark-master-6f7678b449-jcbnp 1/1 Running 0 9d; spark-worker-569866dff7-l452k 1/1 Running 0 9d; spark-worker-569866dff7-xzmx4 1/1 Running 0 9d; upload-658d7f8c7d-gvj4h 1/1 Running 0 51m; web-deployment-bc6497cdb-qfc9g 1/1 Running 0 2h; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5269:183,message,messages,183,https://hail.is,https://github.com/hail-is/hail/issues/5269,1,['message'],['messages']
Integrability,"#104693</a>, <a href=""https://github.com/ravisantoshgudimetla""><code>@​ravisantoshgudimetla</code></a>)</li>; <li>Introduce <code>v1beta3</code> API for scheduler. This version; <ul>; <li>; <p>increases the weight of user specifiable priorities.; The weights of following priority plugins are increased</p>; <ul>; <li><code>TaintTolerations</code> to 3 - as leveraging node tainting to group nodes in the cluster is becoming a widely-adopted practice</li>; <li><code>NodeAffinity</code> to 2</li>; <li><code>InterPodAffinity</code> to 2</li>; </ul>; </li>; <li>; <p>Won't have <code>HealthzBindAddress</code>, <code>MetricsBindAddress</code> fields (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104251"">kubernetes/kubernetes#104251</a>, <a href=""https://github.com/ravisantoshgudimetla""><code>@​ravisantoshgudimetla</code></a>)</p>; </li>; </ul>; </li>; <li>Introduce v1beta2 for Priority and Fairness with no changes in API spec. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104399"">kubernetes/kubernetes#104399</a>, <a href=""https://github.com/tkashem""><code>@​tkashem</code></a>)</li>; <li>JSON log output is configurable and now supports writing info messages to stdout and error messages to stderr. Info messages can be buffered in memory. The default is to write both to stdout without buffering, as before. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104873"">kubernetes/kubernetes#104873</a>, <a href=""https://github.com/pohly""><code>@​pohly</code></a>)</li>; <li>JobTrackingWithFinalizers graduates to beta. Feature is enabled by default. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105687"">kubernetes/kubernetes#105687</a>, <a href=""https://github.com/alculquicondor""><code>@​alculquicondor</code></a>)</li>; <li>Kube-apiserver: Fixes handling of CRD schemas containing literal null values in enums. (<a href=""https://github-redirect.dependabot.com/kubernetes/kuberne",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:6723,depend,dependabot,6723,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['depend'],['dependabot']
Integrability,"#10544</a> from deannagarcia/3.20.x</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/ae718b39020ae6e6f8f5568e357d6893fd0fd29c""><code>ae718b3</code></a> Add missing includes</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/b4c395aaedfacb32e2414d361fa85968c0991b34""><code>b4c395a</code></a> Apply patch</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/6439c5c01349e74d4deb57c844a7ad4b7b13a302""><code>6439c5c</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10531"">#10531</a> from protocolbuffers/deannagarcia-patch-7</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/22c79e6e4ca8be2bc2f700b2cdddca84d84659ce""><code>22c79e6</code></a> Update version.json</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/c1a2d2ec29314975e725021ffe4334926dbaa56c""><code>c1a2d2e</code></a> Fix python release on macos (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10512"">#10512</a>)</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/a826282e15efe3ae3a2aebb040fb1691b2233a1e""><code>a826282</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10505"">#10505</a> from deannagarcia/3.20.x</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/7639a710e10beb47bfc62f363680f7b04e8b3d26""><code>7639a71</code></a> Add version file</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.20.1...v3.20.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.1&new-version=3.20.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot wi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12223:2212,depend,dependabot,2212,https://hail.is,https://github.com/hail-is/hail/pull/12223,3,['depend'],['dependabot']
Integrability,"#11699, still trying to sort out the shaded azure dependency, this is operating under the assumption that we can use the azure dependency specified in the build.gradle",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11617#issuecomment-1082248758:50,depend,dependency,50,https://hail.is,https://github.com/hail-is/hail/pull/11617#issuecomment-1082248758,2,['depend'],['dependency']
Integrability,"#1223</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1221"">#1221</a> &lt;- <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1220"">#1220</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1076"">#1076</a>)</li>; <li>tests: fix py27 <code>keras</code> dependencies (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1222"">#1222</a>)</li>; <li>misc tidy: use relative imports (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1222"">#1222</a>)</li>; <li>minor documentation updates (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1222"">#1222</a>)</li>; </ul>; <h2>tqdm v4.62.0 stable</h2>; <ul>; <li><code>asyncio.gather</code> API consistency with stdlib (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1212"">#1212</a>)</li>; <li>fix shutdown exception (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1209"">#1209</a> &lt;- <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1198"">#1198</a>)</li>; <li>misc build framework updates (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1209"">#1209</a>)</li>; <li>add <a href=""https://github.com/sponsors/tqdm/dashboard/tiers?frequency=one-time"">GH Sponsors</a> &amp; <a href=""https://tqdm.github.io/merch"">merch</a> links</li>; </ul>; <h2>tqdm v4.61.2 stable</h2>; <ul>; <li>install <code>colorama</code> on Windows (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1139"">#1139</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/454"">#454</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/tqdm/tqdm/commit/f3fb54eb161a9f5de13352e16a70a9960946605b""><code>f3fb54e</code></a> bump version, merge pull request <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1302"">#1302</a> from tqdm/devel</li>; <li><a href=""https://",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11587:3838,depend,dependabot,3838,https://hail.is,https://github.com/hail-is/hail/pull/11587,1,['depend'],['dependabot']
Integrability,"#14609 broke the routing for https://hail.is. The `domains` variable here indicates to `gateway` which domains in incoming requests should be routed to the given service. Since #14609 changed the `service` parameter from `str` to `Service`, it silently broke this branch. This wasn't covered by the envoy config generation tests because we didn't have a `www` service in the test configuration. I've added it so that this branch is covered. Fixes #14616",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14617:17,rout,routing,17,https://hail.is,https://github.com/hail-is/hail/pull/14617,2,['rout'],"['routed', 'routing']"
Integrability,"#1593</a>)&quot;</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/7346f5be31b446b466a1f627a9a687d884eef8b9""><code>7346f5b</code></a> Allow the BAM index to be up to 5 seconds older than the BAM before warning (...</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/067c5536a575ae36bf7e7d7323b1f2847caa3efd""><code>067c553</code></a> Fix HtsCRAMCodec test data provider. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1632"">#1632</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/14a8cc022c98caa27df9d5aa876aeb5394f197ad""><code>14a8cc0</code></a> Use allele info in VariantContext comparisons for stable sorts (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1593"">#1593</a>)</li>; <li>See full diff in <a href=""https://github.com/samtools/htsjdk/compare/3.0.2...3.0.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.github.samtools:htsjdk&package-manager=gradle&previous-version=3.0.2&new-version=3.0.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and bl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12700:3235,depend,dependency-name,3235,https://hail.is,https://github.com/hail-is/hail/pull/12700,1,['depend'],['dependency-name']
Integrability,"#206</a>, <a href=""https://github.com/jpz""><code>@​jpz</code></a>)</li>; <li>Added test data for Croatian, Czech, Hungarian, Polish, Slovak, Slovene, Greek, and Turkish, which should help prevent future errors with those languages</li>; <li>Improved XML tag filtering, which should improve accuracy for XML files (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/208"">#208</a>)</li>; <li>Tweaked <code>SingleByteCharSetProber</code> confidence to match latest uchardet (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/209"">#209</a>)</li>; <li>Made <code>detect_all</code> return child prober confidences (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/210"">#210</a>)</li>; <li>Updated examples in docs (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/223"">#223</a>, <a href=""https://github.com/domdfcoding""><code>@​domdfcoding</code></a>)</li>; <li>Documentation fixes (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/212"">#212</a>, <a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/224"">#224</a>, <a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/225"">#225</a>, <a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/226"">#226</a>, <a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/220"">#220</a>, <a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/221"">#221</a>, <a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/244"">#244</a> from too many to mention)</li>; <li>Minor performance improvements (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/252"">#252</a>, <a href=""https://github.com/deedy5""><code>@​deedy5</code></a>)</li>; <li>Add support for Python 3.10 when testing (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/232"">#232</a>, <a href=""https://github.com/jdufresne""><code>@​jdufresne</code></a>)</li>; <li>Lots",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12107:1846,depend,dependabot,1846,https://hail.is,https://github.com/hail-is/hail/pull/12107,1,['depend'],['dependabot']
Integrability,"#21981</a>)</li>; </ul>; <h3>Other Changes</h3>; <ul>; <li>Removed <code>resource_id</code>, please use <code>identity_config</code> instead.</li>; <li>Renamed argument name <code>get_assertion</code> to <code>func</code> for <code>ClientAssertionCredential</code>.</li>; </ul>; <h2>azure-identity_1.9.0b1</h2>; <h2>1.9.0b1 (2022-03-08)</h2>; <h3>Features Added</h3>; <ul>; <li>Added <code>validate_authority</code> support for msal client (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22625"">#22625</a>)</li>; <li>Added <code>resource_id</code> support for user-assigned managed identity (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22329"">#22329</a>)</li>; <li>Added <code>ClientAssertionCredential</code> support (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22328"">#22328</a>)</li>; <li>Updated App service API version to &quot;2019-08-01&quot; (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23034"">#23034</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/e650a8ca8b4cf01ec7a2961f4a50187d1528a122""><code>e650a8c</code></a> update troubleshooting (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23681"">#23681</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/58613a167a5383a459a57b34c6208d7762b90264""><code>58613a1</code></a> enable pii logging (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23658"">#23658</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/ab4c52ce05bb3fda401a834cbf669c32d6d83b90""><code>ab4c52c</code></a> add doc string for authority setting (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23659"">#23659</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11752:2005,depend,dependabot,2005,https://hail.is,https://github.com/hail-is/hail/pull/11752,1,['depend'],['dependabot']
Integrability,"#22328</a>)</li>; <li>Updated App service API version to &quot;2019-08-01&quot; (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23034"">#23034</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/e650a8ca8b4cf01ec7a2961f4a50187d1528a122""><code>e650a8c</code></a> update troubleshooting (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23681"">#23681</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/58613a167a5383a459a57b34c6208d7762b90264""><code>58613a1</code></a> enable pii logging (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23658"">#23658</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/ab4c52ce05bb3fda401a834cbf669c32d6d83b90""><code>ab4c52c</code></a> add doc string for authority setting (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23659"">#23659</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/68dda72cab22a13014012c6b88137684180e941b""><code>68dda72</code></a> add app service api 2017 backward compatibility support (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23626"">#23626</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/1b23cab27114193fa8c19bfd47627093052d8212""><code>1b23cab</code></a> remove validate_authority (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23625"">#23625</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/a6a41458f5d15d47fe508629056b7c90185d4060""><code>a6a4145</code></a> refresh async oob (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23551"">#23551</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/95139f477dcda4de7f6fab56c17e7081f035595d""><",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11752:2886,depend,dependabot,2886,https://hail.is,https://github.com/hail-is/hail/pull/11752,1,['depend'],['dependabot']
Integrability,"#385</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/d84d66c2a4107f5f9a20c53e870a27fb1250ea3d"">d84d66c</a>)</li>; </ul>; <h2>v2.8.0</h2>; <h2><a href=""https://github.com/googleapis/python-api-core/compare/v2.7.3...v2.8.0"">2.8.0</a> (2022-05-18)</h2>; <h3>Features</h3>; <ul>; <li>adds support for audience in client_options (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/379"">#379</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/c97c4980125a86f384cdf12720df7bb1a2adf9d2"">c97c498</a>)</li>; <li>adds support for audience in client_options. (<a href=""https://github.com/googleapis/python-api-core/commit/c97c4980125a86f384cdf12720df7bb1a2adf9d2"">c97c498</a>)</li>; </ul>; <h2>v2.7.3</h2>; <h3><a href=""https://github.com/googleapis/python-api-core/compare/v2.7.2...v2.7.3"">2.7.3</a> (2022-04-29)</h3>; <h3>Bug Fixes</h3>; <ul>; <li>Avoid AttributeError if grpcio-status is not installed (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/370"">#370</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/022add16266f9c07f0f88eea13472cc2e0bfc991"">022add1</a>)</li>; </ul>; <h2>v2.7.2</h2>; <h3><a href=""https://github.com/googleapis/python-api-core/compare/v2.7.1...v2.7.2"">2.7.2</a> (2022-04-13)</h3>; <h3>Bug Fixes</h3>; <ul>; <li>allow grpc without grpcio-status (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/355"">#355</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/112049e79f5a5b0a989d85d438a1bd29485f46f7"">112049e</a>)</li>; <li>remove dependency on pkg_resources (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/361"">#361</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/523dbd0b10d37ffcf83fa751f0bad313f162abf1"">523dbd0</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>So",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11970:3062,depend,dependabot,3062,https://hail.is,https://github.com/hail-is/hail/pull/11970,1,['depend'],['dependabot']
Integrability,#4659 removed this dependency.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4670:19,depend,dependency,19,https://hail.is,https://github.com/hail-is/hail/pull/4670,1,['depend'],['dependency']
Integrability,"#485</a></p>; </li>; <li>; <p>Support Python 3.7 &amp; 3.8 <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/493"">#493</a></p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiomysql/blob/master/CHANGES.txt"">aiomysql's changelog</a>.</em></p>; <blockquote>; <p>0.0.22 (2021-11-14); ^^^^^^^^^^^^^^^^^^^</p>; <ul>; <li>Support python 3.10 <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/505"">#505</a></li>; </ul>; <p>0.0.21 (2020-11-26); ^^^^^^^^^^^^^^^^^^^</p>; <ul>; <li>; <p>Allow to use custom Cursor subclasses <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/374"">#374</a></p>; </li>; <li>; <p>Fill Connection class with actual client version <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/388"">#388</a></p>; </li>; <li>; <p>Fix legacy <strong>aiter</strong> methods <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/403"">#403</a></p>; </li>; <li>; <p>Fix &amp; update docs <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/418"">#418</a> <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/437"">#437</a></p>; </li>; <li>; <p>Ignore pyenv's .python-version file <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/424"">#424</a></p>; </li>; <li>; <p>Replace asyncio.streams.IncompleteReadError with asyncio.IncompleteReadError <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/460"">#460</a> <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/454"">#454</a></p>; </li>; <li>; <p>Add support for SQLAlchemy default parameters <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/455"">#455</a> <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/466"">#466</a></p>; </li>; <li>; <p>Update dependencies <a href=""https://github-redirect.depe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11543:2727,depend,dependabot,2727,https://hail.is,https://github.com/hail-is/hail/pull/11543,1,['depend'],['dependabot']
Integrability,"#665</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/29ddff39290f4e2fbc7b9feb94eb622763e156e2""><code>29ddff3</code></a> Bump pytest-aiohttp from 0.3.0 to 1.0.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/668"">#668</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/3bc517092aff39330f2f96315e6f542e23415831""><code>3bc5170</code></a> Bump multidict from 5.2.0 to 6.0.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/670"">#670</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp_session/compare/v2.7.0...v2.11.0"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11577:5674,Depend,Dependabot,5674,https://hail.is,https://github.com/hail-is/hail/pull/11577,1,['Depend'],['Dependabot']
Integrability,"#803</a> : Metadata endpoint support of non-HTTPS</li>; <li>CVE-2022-36087</li>; </ul>; <p>OAuth1.0:</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/issues/818"">#818</a> : Allow IPv6 being parsed by signature</li>; </ul>; <p>General:</p>; <ul>; <li>Improved and fixed documentation warnings.</li>; <li>Cosmetic changes based on isort</li>; </ul>; <h2>What's Changed</h2>; <ul>; <li>add missing slots to TokenBase by <a href=""https://github.com/ariebovenberg""><code>@​ariebovenberg</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/804"">oauthlib/oauthlib#804</a></li>; <li>Add CORS support for Refresh Token Grant. by <a href=""https://github.com/luhn""><code>@​luhn</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/806"">oauthlib/oauthlib#806</a></li>; <li>GitHub Action to lint Python code by <a href=""https://github.com/cclauss""><code>@​cclauss</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/797"">oauthlib/oauthlib#797</a></li>; <li>Docs: fix Sphinx warnings for better ReadTheDocs generation by <a href=""https://github.com/JonathanHuot""><code>@​JonathanHuot</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/807"">oauthlib/oauthlib#807</a></li>; <li>Allow non-HTTPS issuer when OAUTHLIB_INSECURE_TRANSPORT. by <a href=""https://github.com/luhn""><code>@​luhn</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/803"">oauthlib/oauthlib#803</a></li>; <li>chore: fix typo in test by <a href=""https://github.com/tamanobi""><code>@​tamanobi</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/816"">oauthlib/oauthlib#816</a></li>; <li>Fix typo in server.rst by <a href=""https://github.com/NemanjaT""><code>@​NemanjaT</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/819"">oauthlib/oauthlib#819</a></li>; <li>Fixed isort imports by <a h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12197:1392,depend,dependabot,1392,https://hail.is,https://github.com/hail-is/hail/pull/12197,2,['depend'],['dependabot']
Integrability,"#8495</a>) (<a href=""https://github.com/vitejs/vite/commit/01fa807"">01fa807</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/7973"">#7973</a> <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8495"">#8495</a></li>; </ul>; <h2><!-- raw HTML omitted -->2.9.10 (2022-06-06)<!-- raw HTML omitted --></h2>; <ul>; <li>feat: treat Astro file scripts as TS (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8151"">#8151</a>) (<a href=""https://github.com/vitejs/vite/commit/9fdd0a3"">9fdd0a3</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8151"">#8151</a></li>; <li>feat: new hook <code>configurePreviewServer</code> (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/7658"">#7658</a>) (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8437"">#8437</a>) (<a href=""https://github.com/vitejs/vite/commit/7b972bc"">7b972bc</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/7658"">#7658</a> <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8437"">#8437</a></li>; <li>fix: remove empty chunk css imports when using esnext (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8345"">#8345</a>) (<a href=""https://github.com/vitejs/vite/commit/9fbc1a9"">9fbc1a9</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8345"">#8345</a></li>; <li>fix: EPERM error on Windows when processing dependencies (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8235"">#8235</a>) (<a href=""https://github.com/vitejs/vite/commit/dfe4307"">dfe4307</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8235"">#8235</a></li>; <li>fix(css): remove <code>?used</code> hack (fixes <a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/6421"">#6421</a>, <a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8245"">#8245</a>) (<a href",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12142:4274,depend,dependabot,4274,https://hail.is,https://github.com/hail-is/hail/pull/12142,2,['depend'],['dependabot']
Integrability,"#879</a> (<a href=""https://github.com/kevin-bates""><code>@​kevin-bates</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_client/graphs/contributors?from=2022-11-10&amp;to=2022-11-15&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Ameeseeksmachine+updated%3A2022-11-10..2022-11-15&amp;type=Issues""><code>@​meeseeksmachine</code></a></p>; <!-- raw HTML omitted -->; <h2>7.4.5</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v7.4.4...d27c8a497c6cbb1a232fbbe75cb1fd0f53faa9b0"">Full Changelog</a>)</p>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>[7.x] Handle Jupyter Core Warning <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/875"">#875</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; <li>Clean up 7.x workflows <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/865"">#865</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_client/graphs/contributors?from=2022-10-25&amp;to=2022-11-10&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Ablink1073+updated%3A2022-10-25..2022-11-10&amp;type=Issues""><code>@​blink1073</code></a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/f71daff259071f3077810d9a4256876b441f5ab5""><code>f71daff</code></a> Publish 7.4.6</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/3394591f161be4a19f9e61c66ba510d7e29afd59""><code>3394591</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/879"">#879</a> on branch 7.x (Reconcil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12467:3616,depend,dependabot,3616,https://hail.is,https://github.com/hail-is/hail/pull/12467,1,['depend'],['dependabot']
Integrability,"#908</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/jupyter/jupyter_client/compare/v7.4.8...v8.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jupyter-client&package-manager=pip&previous-version=7.4.8&new-version=8.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12656:9464,Depend,Dependabot,9464,https://hail.is,https://github.com/hail-is/hail/pull/12656,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"#94654</a>, <a href=""https://github.com/wojtek-t""><code>@​wojtek-t</code></a>) [SIG Instrumentation]</li>; <li>A new alpha-level field, <code>SupportsFsGroup</code>, has been introduced for CSIDrivers to allow them to specify whether they support volume ownership and permission modifications. The <code>CSIVolumeSupportFSGroup</code> feature gate must be enabled to allow this field to be used. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92001"">kubernetes/kubernetes#92001</a>, <a href=""https://github.com/huffmanca""><code>@​huffmanca</code></a>) [SIG API Machinery, CLI and Storage]</li>; <li>Added pod version skew strategy for seccomp profile to synchronize the deprecated annotations with the new API Server fields. Please see the corresponding section <a href=""https://github.com/kubernetes/enhancements/blob/master/keps/sig-node/135-seccomp/README.md#version-skew-strategy"">in the KEP</a> for more detailed explanations. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91408"">kubernetes/kubernetes#91408</a>, <a href=""https://github.com/saschagrunert""><code>@​saschagrunert</code></a>) [SIG Apps, Auth, CLI and Node]</li>; <li>Adds the ability to disable Accelerator/GPU metrics collected by Kubelet (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91930"">kubernetes/kubernetes#91930</a>, <a href=""https://github.com/RenaudWasTaken""><code>@​RenaudWasTaken</code></a>) [SIG Node]</li>; <li>Admission webhooks can now return warning messages that are surfaced to API clients, using the <code>.response.warnings</code> field in the admission review response. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92667"">kubernetes/kubernetes#92667</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>) [SIG API Machinery and Testing]</li>; <li>CertificateSigningRequest API conditions were updated:; <ul>; <li>a <code>status</code> field was added; this field defaults to",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:3172,depend,dependabot,3172,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['depend'],['dependabot']
Integrability,"#9634 Introduced a large performance regression in the `linear_regression_rows_nd` benchmark (making it about 4x slower). This PR fixes that by doing two things:. 1. Move all the global into one single `annotate_globals` expression, so that CSE can work properly. This required fixing a bug in some ndarray expressions that were not correctly tracking their source tables. To make sure I was only referencing the global versions of this computed things, rather accidentally recomputing, I wrapped the global setup in a function to scope the variables. This improvement was minor, didn't hit the real root of the problem. 2. Much more significantly, and not 100% clear why: `process_y_group` is now a function that returns a python dictionary, instead of a hail struct. I can guess that the allocation required by making a struct was wasteful, but it seems crazy that it was ""make the benchmark 4x slower"" amounts of wasteful. . While this is not user facing yet, would be good to get this in before an eventual 0.2.60 release if we want to avoid benchmarks regressing between versions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9666:489,wrap,wrapped,489,https://hail.is,https://github.com/hail-is/hail/pull/9666,1,['wrap'],['wrapped']
Integrability,"#9660</a> from pytest-dev/backport-9646-to-7.0.x</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/37d434f5fcb5f80188b3d5b8f22d418dc191b955""><code>37d434f</code></a> [7.0.x] Delay warning about collector/item diamond inheritance</li>; <li>Additional commits viewable in <a href=""https://github.com/pytest-dev/pytest/compare/6.2.5...7.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest&package-manager=pip&previous-version=6.2.5&new-version=7.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11516:7152,Depend,Dependabot,7152,https://hail.is,https://github.com/hail-is/hail/pull/11516,3,['Depend'],['Dependabot']
Integrability,"#PdhEnumObjectItems (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1442"">#1442</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/99fcfa822db86b1f2ba5823dbf17efeb3d246ad5""><code>99fcfa8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1444"">#1444</a> from matthiasblaesing/update_libffi</li>; <li><a href=""https://github.com/java-native-access/jna/commit/9e473350a5ad5e04aab8b01e4018f973976e19f8""><code>9e47335</code></a> Update CHANGES.md</li>; <li>Additional commits viewable in <a href=""https://github.com/java-native-access/jna/compare/5.6.0...5.12.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=net.java.dev.jna:jna&package-manager=gradle&previous-version=5.6.0&new-version=5.12.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:8151,depend,dependabot-security-updates,8151,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['depend'],['dependabot-security-updates']
Integrability,$$rewriteMatrixNode(Simplify.scala:68); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:31); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.co,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:8171,Wrap,WrappedArray,8171,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Wrap'],['WrappedArray']
Integrability,"$11$adapted(Worker.scala:164) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.utils.package$.using(package.scala:637) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.main(Worker.scala:164) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main$.main(Main.scala:14) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main.main(Main.scala) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	... 12 more; 	Suppressed: is.hail.relocated.com.google.cloud.storage.StorageException: 403 Forbidden; POST https://storage.googleapis.com/upload/storage/v1/b/neale-bge/o?name=foo.ht/index/part-0-c7ba7549-bf68-42db-a8ef-0f1b13721c79.idx/index&uploadType=resumable; {; ""error"": {; ""code"": 403,; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""errors"": [; {; ""message"": ""dking-ae4q6@hail-vdc.iam.gserviceaccount.com does not have storage.objects.create access to the Google Cloud Storage object. Permission 'storage.objects.create' denied on resource (or it may not exist)."",; ""domain"": ""global"",; ""reason"": ""forbidden""; }; ]; }; }. 		at is.hail.relocated.com.google.cloud.storage.StorageException.translate(StorageException.java:165) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:298) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 		at is.hail.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.open(HttpSt",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:17565,message,message,17565,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['message'],['message']
Integrability,$anonfun$toArrayInt$extension$1.apply(Filter.scala:18); at org.broadinstitute.hail.methods.AnnotationValueString$$anonfun$toArrayInt$extension$1.apply(Filter.scala:18); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186); at scala.collection.TraversableLike$class.map(TraversableLike.scala:245); at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); at org.broadinstitute.hail.methods.AnnotationValueString$.toArrayInt$extension(Filter.scala:18); at __wrapper$1$c1aef7d48806473ea6c7fc7ceb61989c.__wrapper$1$c1aef7d48806473ea6c7fc7ceb61989c$$anonfun$wrapper$1$__vaClass$1$__info$$anonfun$3.apply(<no source file>:11); at __wrapper$1$c1aef7d48806473ea6c7fc7ceb61989c.__wrapper$1$c1aef7d48806473ea6c7fc7ceb61989c$$anonfun$wrapper$1$__vaClass$1$__info$$anonfun$3.apply(<no source file>:11); at scala.Option.map(Option.scala:146); at __wrapper$1$c1aef7d48806473ea6c7fc7ceb61989c.__wrapper$1$c1aef7d48806473ea6c7fc7ceb61989c$$anonfun$wrapper$1$__vaClass$1$__info.<init>(<no source file>:11); at __wrapper$1$c1aef7d48806473ea6c7fc7ceb61989c.__wrapper$1$c1aef7d48806473ea6c7fc7ceb61989c$$anonfun$wrapper$1$__vaClass$1.<init>(<no source file>:23); at __wrapper$1$c1aef7d48806473ea6c7fc7ceb61989c.__wrapper$1$c1aef7d48806473ea6c7fc7ceb61989c$$anonfun$wrapper$1.apply(<no source file>:32); at __wrapper$1$c1aef7d48806473ea6c7fc7ceb61989c.__wrapper$1$c1aef7d48806473ea6c7fc7ceb61989c$$anonfun$wrapper$1.apply(<no source file>:2); at org.broadinstitute.hail.methods.FilterVariantCondition.apply(Filter.scala:613); at org.broadinstitute.hail.driver.FilterVariants$$anonfun$2.apply(FilterVariants.scala:45); at org.broadinstitute.hail.driver.FilterVariants$$anonfun$2.apply(FilterVariants.scala:45); at org.broadinstitute.hail.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/120:2178,wrap,wrapper,2178,https://hail.is,https://github.com/hail-is/hail/issues/120,1,['wrap'],['wrapper']
Integrability,$apply$24.apply(Emit.scala:811); 	at is.hail.expr.ir.IEmitCode.map(Emit.scala:234); 	at is.hail.expr.ir.Emit$$anonfun$emitI$10$$anonfun$apply$23.apply(Emit.scala:811); 	at is.hail.expr.ir.Emit$$anonfun$emitI$10$$anonfun$apply$23.apply(Emit.scala:810); 	at is.hail.expr.ir.IEmitCode.flatMap(Emit.scala:241); 	at is.hail.expr.ir.Emit$$anonfun$emitI$10.apply(Emit.scala:810); 	at is.hail.expr.ir.Emit$$anonfun$emitI$10.apply(Emit.scala:809); 	at is.hail.expr.ir.IEmitCode.flatMap(Emit.scala:241); 	at is.hail.expr.ir.Emit.emitI(Emit.scala:809); 	at is.hail.expr.ir.Emit.is$hail$expr$ir$Emit$$emitI$3(Emit.scala:1035); 	at is.hail.expr.ir.Emit$$anonfun$emit$11.apply(Emit.scala:2385); 	at is.hail.expr.ir.Emit$$anonfun$emit$11.apply(Emit.scala:2384); 	at is.hail.expr.ir.EmitCode$.fromI(Emit.scala:283); 	at is.hail.expr.ir.Emit.emit(Emit.scala:2384); 	at is.hail.expr.ir.Emit.emit(Emit.scala:1013); 	at is.hail.expr.ir.Emit$$anonfun$13$$anon$2.emit(Emit.scala:464); 	at is.hail.expr.ir.EmitUtils$$anonfun$wrapToMethod$1.apply(Emit.scala:426); 	at is.hail.expr.ir.EmitUtils$$anonfun$wrapToMethod$1.apply(Emit.scala:426); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at is.hail.expr.ir.EmitUtils$.wrapToMethod(Emit.scala:426); 	at is.hail.expr.ir.Emit.wrapToMethod(Emit.scala:468); 	at is.hail.expr.ir.Emit.wrapToMethod$2(Emit.scala:1044); 	at is.hail.expr.ir.Emit.emit(Emit.scala:1594); 	at is.hail.expr.ir.Emit.emitFallback$1(Emit.scala:692); 	at is.hail.expr.ir.Emit.emitI(Emit.scala:975); 	at is.hail.expr.ir.Emit.emitI(Emit.scala:675); 	at is.hail.expr.ir.Emit$$anonfun$ap,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9128:10639,wrap,wrapToMethod,10639,https://hail.is,https://github.com/hail-is/hail/issues/9128,1,['wrap'],['wrapToMethod']
Integrability,$expr$ir$Simplify$$rewriteMatrixNode(Simplify.scala:68); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:31); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:8150,Wrap,WrappedArray,8150,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Wrap'],['WrappedArray']
Integrability,"&gt; Don't mutate options dictionary in .decode_complete() (&lt;a href=&quot;https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/743&quot;&gt;#743&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/jpadilla/pyjwt/commit/1f1fe15bb41846c602b3e106176b2c692b93a613&quot;&gt;&lt;code&gt;1f1fe15&lt;/code&gt;&lt;/a&gt; Add a deprecation warning when jwt.decode() is called with the legacy verify=...&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/jpadilla/pyjwt/commit/35fa28e59d99b99c6a780d2a029a74d6bbba8b1e&quot;&gt;&lt;code&gt;35fa28e&lt;/code&gt;&lt;/a&gt; [pre-commit.ci] pre-commit autoupdate (&lt;a href=&quot;https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/740&quot;&gt;#740&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;Additional commits viewable in &lt;a href=&quot;https://github.com/jpadilla/pyjwt/compare/1.7.1...2.4.0&quot;&gt;compare view&lt;/a&gt;&lt;/li&gt;; &lt;/ul&gt;; &lt;/details&gt;. &lt;br /&gt;; </code></pre>. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyjwt&package-manager=pip&previous-version=1.7.1&new-version=2.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11866:14634,Depend,Dependabot,14634,https://hail.is,https://github.com/hail-is/hail/pull/11866,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,&gt;... (truncated)&lt;/p&gt;; &lt;/details&gt;; &lt;details&gt;; &lt;summary&gt;Commits&lt;/summary&gt;. &lt;ul&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/a1639ef4d9bdc89daa037fd0bfc003bdf2e99865&quot;&gt;&lt;code&gt;a1639ef&lt;/code&gt;&lt;/a&gt; Update CHANGES.rst (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/411&quot;&gt;#411&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/727b305a5707a937b427894360eba11c402b1755&quot;&gt;&lt;code&gt;727b305&lt;/code&gt;&lt;/a&gt; Enable camelcase eslint rule (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/410&quot;&gt;#410&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/dade11a7a1281ca3060bf1149fdc1d6d0763c97e&quot;&gt;&lt;code&gt;dade11a&lt;/code&gt;&lt;/a&gt; fixed css sort tringles (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/409&quot;&gt;#409&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/e00532d9c8a598fb848d16b0ce23665789e3517a&quot;&gt;&lt;code&gt;e00532d&lt;/code&gt;&lt;/a&gt; Use scss nesting &amp;amp; variables (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/393&quot;&gt;#393&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/9bd4907682f10849dde1fe866b5a71402c74e551&quot;&gt;&lt;code&gt;9bd4907&lt;/code&gt;&lt;/a&gt; remove all read the doc documentation from the repo (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/405&quot;&gt;#405&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/21fafe40b19e7d1c8b4b8bceb7fe1410e2cbdc2a&quot;&gt;&lt;code&gt;21fafe4&lt;/code&gt;&lt;/a&gt; Document how to modify the environment section after tests are finis,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11524:14300,depend,dependabot,14300,https://hail.is,https://github.com/hail-is/hail/pull/11524,1,['depend'],['dependabot']
Integrability,"&quot; error with a retry option. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104699"">kubernetes/kubernetes#104699</a>, <a href=""https://github.com/vincepri""><code>@​vincepri</code></a>)</li>; <li>Implement support for recovering from volume expansion failures (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/106154"">kubernetes/kubernetes#106154</a>, <a href=""https://github.com/gnufied""><code>@​gnufied</code></a>) [SIG API Machinery, Apps and Storage]</li>; <li>In kubelet, log verbosity and flush frequency can also be configured via the configuration file and not just via command line flags. In other commands (kube-apiserver, kube-controller-manager), the flags are listed in the &quot;Logs flags&quot; group and not under &quot;Global&quot; or &quot;Misc&quot;. The type for <code>-vmodule</code> was made a bit more descriptive (<code>pattern=N,...</code> instead of <code>moduleSpec</code>). (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/106090"">kubernetes/kubernetes#106090</a>, <a href=""https://github.com/pohly""><code>@​pohly</code></a>) [SIG API Machinery, Architecture, CLI, Cluster Lifecycle, Instrumentation, Node and Scheduling]</li>; <li>Introduce <code>OS</code> field in the PodSpec (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104693"">kubernetes/kubernetes#104693</a>, <a href=""https://github.com/ravisantoshgudimetla""><code>@​ravisantoshgudimetla</code></a>)</li>; <li>Introduce <code>v1beta3</code> API for scheduler. This version; <ul>; <li>; <p>increases the weight of user specifiable priorities.; The weights of following priority plugins are increased</p>; <ul>; <li><code>TaintTolerations</code> to 3 - as leveraging node tainting to group nodes in the cluster is becoming a widely-adopted practice</li>; <li><code>NodeAffinity</code> to 2</li>; <li><code>InterPodAffinity</code> to 2</li>; </ul>; </li>; <li>; <p>Won't have <code>HealthzBindAddress</",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:5325,depend,dependabot,5325,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['depend'],['dependabot']
Integrability,"&quot;How to Write a Checker&quot; test example (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5449"">#5449</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/bce059acf1684e35c9a731e27cff2de16bf54de8""><code>bce059a</code></a> Move Sphinx docstrings out of <code>TestParamDocChecker</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5450"">#5450</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/e14596ef44db6efd55c783fc5bffd61d020edc23""><code>e14596e</code></a> Move <code>no-member</code> tests from <code>TestTypeChecker</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5453"">#5453</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/4b70feb297b4aada56b838c1e71f40badccf9472""><code>4b70feb</code></a> <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5452"">#5452</a>: Fix false positive missing-doc-param from multi-line Google-st… (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5459"">#5459</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/35813de38ed58855f1b89fb492dc141d24bf2661""><code>35813de</code></a> Move various tests from <code>TestTypeChecker</code> to functional tests (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5455"">#5455</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/pylint-2.6.0...v2.12.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pylint&package-manager=pip&previous-version=2.6.0&new-version=2.12.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11461:7963,depend,dependabot,7963,https://hail.is,https://github.com/hail-is/hail/pull/11461,2,['depend'],['dependabot']
Integrability,"')],; split_reference_blocks=True); ; ; vds_union = vds1.union_rows(vds2); > assert hl.vds.to_dense_mt(vds)._same(hl.vds.to_dense_mt(vds_union)). test/hail/vds/test_vds.py:597: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; <decorator-gen-1386>:2: in _same; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/matrixtable.py:3762: in _same; return self._localize_entries(entries_name, cols_name)._same(; <decorator-gen-1276>:2: in _same; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/table.py:3658: in _same; mismatched_globals, mismatched_rows = t.aggregate(hl.tuple((; <decorator-gen-1216>:2: in aggregate; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/table.py:1285: in aggregate; return Env.backend().execute(hl.ir.MakeTuple([agg_ir]))[0]; /usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py:86: in execute; raise e.maybe_user_error(ir) from None; /usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py:76: in execute; result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); /usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py:1321: in __call__; return_value = get_return_value(; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . args = ('xro552', <py4j.java_gateway.GatewayClient object at 0x7f01e1182160>, 'o1', 'executeEncode'); kwargs = {}; pyspark = <module 'pyspark' from '/usr/local/lib/python3.9/dist-packages/pyspark/__init__.py'>; s = 'java.lang.RuntimeException: invalid memory access: 120001305f726574/00000004: not in 7f15e9ffb1f8/00010000'; tpl = JavaObject id=o553; deepest = 'RuntimeExce",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:1596,wrap,wrapper,1596,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198,1,['wrap'],['wrapper']
Integrability,"', 'https://github.com/hail-is/jgscm/archive/v0.1.13+hail.zip', 'ipykernel==6.22.0', 'ipywidgets==8.0.6', 'jupyter-console==6.6.3', 'nbconvert==7.3.1', 'notebook==6.5.6', 'qtconsole==5.4.2', 'aiodns==2.0.0', 'aiohttp==3.9.5', 'aiosignal==1.3.1', 'async-timeout==4.0.3', 'attrs==23.2.0', 'avro==1.11.3', 'azure-common==1.1.28', 'azure-core==1.30.2', 'azure-identity==1.17.1', 'azure-mgmt-core==1.4.0', 'azure-mgmt-storage==20.1.0', 'azure-storage-blob==12.20.0', 'bokeh==3.3.4', 'boto3==1.34.138', 'botocore==1.34.138', 'cachetools==5.3.3', 'certifi==2024.6.2', 'cffi==1.16.0', 'charset-normalizer==3.3.2', 'click==8.1.7', 'commonmark==0.9.1', 'contourpy==1.2.1', 'cryptography==42.0.8', 'decorator==4.4.2', 'deprecated==1.2.14', 'dill==0.3.8', 'frozenlist==1.4.1', 'google-auth==2.31.0', 'google-auth-oauthlib==0.8.0', 'humanize==1.1.0', 'idna==3.7', 'isodate==0.6.1', 'janus==1.0.0', 'jinja2==3.1.4', 'jmespath==1.0.1', 'jproperties==2.1.1', 'markupsafe==2.1.5', 'msal==1.29.0', 'msal-extensions==1.2.0', 'msrest==0.7.1', 'multidict==6.0.5', 'nest-asyncio==1.6.0', 'numpy==1.26.4', 'oauthlib==3.2.2', 'orjson==3.10.6', 'packaging==24.1', 'pandas==2.2.2', 'parsimonious==0.10.0', 'pillow==10.4.0', 'plotly==5.22.0', 'portalocker==2.10.0', 'protobuf==3.20.2', 'py4j==0.10.9.7', 'pyasn1==0.6.0', 'pyasn1-modules==0.4.0', 'pycares==4.4.0', 'pycparser==2.22', 'pygments==2.18.0', 'pyjwt==2.8.0', 'python-dateutil==2.9.0.post0', 'python-json-logger==2.0.7', 'pytz==2024.1', 'pyyaml==6.0.1', 'regex==2024.5.15', 'requests==2.32.3', 'requests-oauthlib==2.0.0', 'rich==12.6.0', 'rsa==4.9', 's3transfer==0.10.2', 'scipy==1.11.4', 'shellingham==1.5.4', 'six==1.16.0', 'sortedcontainers==2.4.0', 'tabulate==0.9.0', 'tenacity==8.4.2', 'tornado==6.4.1', 'typer==0.12.3', 'typing-extensions==4.12.2', 'tzdata==2024.1', 'urllib3==1.26.19', 'uvloop==0.19.0', 'wrapt==1.16.0', 'xyzservices==2024.6.0', 'yarl==1.9.4')' returned non-zero exit status 1.; ```. ### Version. 0.2.132. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14652:7268,wrap,wrapt,7268,https://hail.is,https://github.com/hail-is/hail/issues/14652,1,['wrap'],['wrapt']
Integrability,"': '6a744afc-154f-4b48-b4bb-51a15078d999', 'Content-Type': 'application/json', 'Date': 'Thu, 11 Jul 2019 14:19:39 GMT', 'Content-Length': '179'})\nHTTP response body: {\""kind\"":\""Status\"",\""apiVersion\"":\""v1\"",\""metadata\"":{},\""status\"":\""Failure\"",\""message\"":\""container \\\""main\\\"" in pod \\\""batch-9-job-1-c8b9b2\\\"" is terminated\"",\""reason\"":\""BadRequest\"",\""code\"":400}\n\n""}; ```. And finally, this k8s refresh loop sequence repeats until CI kills the tests due to a timeout. ```; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,070"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""refresh_k8s_state:1261"", ""message"": ""started k8s state refresh""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,085"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""refresh_k8s_pods:1210"", ""message"": ""k8s had 3 pods""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,088"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1145"", ""message"": ""update job (11, 1, 'output') with pod batch-11-job-1-4f1118""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,090"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1145"", ""message"": ""update job (11, 2, 'output') with pod batch-11-job-2-ad1587""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,093"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1145"", ""message"": ""update job (11, 3, 'output') with pod batch-11-job-3-d826dd""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,093"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""refresh_k8s_pods:1221"", ""message"": ""restarting ready and running jobs with pods not seen in k8s""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,093"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""refresh_k8s_pods:1225"", ""message"": ""restarting job (9, 1, 'main')""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:23:41,093"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1145"", ""message"": ""update job (9, 1, 'main') with pod None""}; {""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6617:15230,message,message,15230,https://hail.is,https://github.com/hail-is/hail/issues/6617,1,['message'],['message']
Integrability,"': 'ContainersReady'},; {'last_probe_time': None,; 'last_transition_time': datetime.datetime(2019, 6, 25, 3, 9, 4, tzinfo=tzlocal()),; 'message': None,; 'reason': None,; 'status': 'True',; 'type': 'PodScheduled'}],; 'container_statuses': [{'container_id': None,; 'image': 'konradjk/saige:0.35.8.2.2',; 'image_id': '',; 'last_state': {'running': None,; 'terminated': None,; 'waiting': None},; 'name': 'main',; 'ready': False,; 'restart_count': 0,; 'state': {'running': None,; 'terminated': {'container_id': None,; 'exit_code': 0,; 'finished_at': None,; 'message': None,; 'reason': None,; 'signal': None,; 'started_at': None},; 'waiting': None}}],; 'host_ip': '10.128.0.8',; 'init_container_statuses': None,; 'message': None,; 'nominated_node_name': None,; 'phase': 'Pending',; 'pod_ip': None,; 'qos_class': 'Burstable',; 'reason': None,; 'start_time': datetime.datetime(2019, 6, 25, 3, 9, 4, tzinfo=tzlocal())}}; File ""/usr/local/lib/python3.6/dist-packages/batch/k8s.py"", line 53, in wrapped; **kwargs),; File ""/usr/local/lib/python3.6/dist-packages/batch/blocking_to_async.py"", line 6, in blocking_to_async; thread_pool, lambda: fun(*args, **kwargs)); File ""/usr/lib/python3.6/concurrent/futures/thread.py"", line 56, in run; result = self.fn(*self.args, **self.kwargs); File ""/usr/local/lib/python3.6/dist-packages/batch/blocking_to_async.py"", line 6, in <lambda>; thread_pool, lambda: fun(*args, **kwargs)); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/apis/core_v1_api.py"", line 18538, in read_namespaced_pod_log; (data) = self.read_namespaced_pod_log_with_http_info(name, namespace, **kwargs); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/apis/core_v1_api.py"", line 18644, in read_namespaced_pod_log_with_http_info; collection_formats=collection_formats); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/api_client.py"", line 334, in call_api; _return_http_data_only, collection_formats, _preload_content, _request_timeout); File ""/usr/local/lib/p",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6466#issuecomment-505429649:9422,wrap,wrapped,9422,https://hail.is,https://github.com/hail-is/hail/issues/6466#issuecomment-505429649,1,['wrap'],['wrapped']
Integrability,"'</li>; <li><a href=""https://github.com/boto/boto3/commit/42b3e0d3c1d02acaa4c0c4127e9523d2c389b675""><code>42b3e0d</code></a> Merge branch 'release-1.21.11' into develop</li>; <li><a href=""https://github.com/boto/boto3/commit/bc87db2261257cf3437824d07080fc061847f21c""><code>bc87db2</code></a> Bumping version to 1.21.11</li>; <li>Additional commits viewable in <a href=""https://github.com/boto/boto3/compare/1.17.54...1.21.13"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=boto3&package-manager=pip&previous-version=1.17.54&new-version=1.21.13)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11504:7791,depend,dependabot-automerge-start,7791,https://hail.is,https://github.com/hail-is/hail/pull/11504,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"'</li>; <li><a href=""https://github.com/boto/boto3/commit/833a8e625aee254eb061f0b40addf016426245d2""><code>833a8e6</code></a> Merge branch 'release-1.21.10' into develop</li>; <li><a href=""https://github.com/boto/boto3/commit/72d60e1e6174f42e260256d4490048506d170bb8""><code>72d60e1</code></a> Bumping version to 1.21.10</li>; <li>Additional commits viewable in <a href=""https://github.com/boto/boto3/compare/1.17.54...1.21.12"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=boto3&package-manager=pip&previous-version=1.17.54&new-version=1.21.12)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11486:7219,depend,dependabot-automerge-start,7219,https://hail.is,https://github.com/hail-is/hail/pull/11486,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"'reason': None,; 'status': 'True',; 'type': 'Initialized'},; {'last_probe_time': None,; 'last_transition_time': datetime.datetime(2019, 6, 25, 3, 9, 4, tzinfo=tzlocal()),; 'message': 'containers with unready status: [main]',; 'reason': 'ContainersNotReady',; 'status': 'False',; 'type': 'Ready'},; {'last_probe_time': None,; 'last_transition_time': datetime.datetime(2019, 6, 25, 3, 9, 4, tzinfo=tzlocal()),; 'message': 'containers with unready status: [main]',; 'reason': 'ContainersNotReady',; 'status': 'False',; 'type': 'ContainersReady'},; {'last_probe_time': None,; 'last_transition_time': datetime.datetime(2019, 6, 25, 3, 9, 4, tzinfo=tzlocal()),; 'message': None,; 'reason': None,; 'status': 'True',; 'type': 'PodScheduled'}],; 'container_statuses': [{'container_id': None,; 'image': 'konradjk/saige:0.35.8.2.2',; 'image_id': '',; 'last_state': {'running': None,; 'terminated': None,; 'waiting': None},; 'name': 'main',; 'ready': False,; 'restart_count': 0,; 'state': {'running': None,; 'terminated': {'container_id': None,; 'exit_code': 0,; 'finished_at': None,; 'message': None,; 'reason': None,; 'signal': None,; 'started_at': None},; 'waiting': None}}],; 'host_ip': '10.128.0.8',; 'init_container_statuses': None,; 'message': None,; 'nominated_node_name': None,; 'phase': 'Pending',; 'pod_ip': None,; 'qos_class': 'Burstable',; 'reason': None,; 'start_time': datetime.datetime(2019, 6, 25, 3, 9, 4, tzinfo=tzlocal())}}; File ""/usr/local/lib/python3.6/dist-packages/batch/k8s.py"", line 53, in wrapped; **kwargs),; File ""/usr/local/lib/python3.6/dist-packages/batch/blocking_to_async.py"", line 6, in blocking_to_async; thread_pool, lambda: fun(*args, **kwargs)); File ""/usr/lib/python3.6/concurrent/futures/thread.py"", line 56, in run; result = self.fn(*self.args, **self.kwargs); File ""/usr/local/lib/python3.6/dist-packages/batch/blocking_to_async.py"", line 6, in <lambda>; thread_pool, lambda: fun(*args, **kwargs)); File ""/usr/local/lib/python3.6/dist-packages/kubernetes/client/apis/co",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6466#issuecomment-505429649:8991,message,message,8991,https://hail.is,https://github.com/hail-is/hail/issues/6466#issuecomment-505429649,1,['message'],['message']
Integrability,"'s changelog</a>.</em></p>; <blockquote>; <h1>Release 5.0.2 (released Jun 17, 2022)</h1>; <h2>Features added</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10523"">#10523</a>: HTML Theme: Expose the Docutils's version info tuple as a template; variable, <code>docutils_version_info</code>. Patch by Adam Turner.</li>; </ul>; <h2>Bugs fixed</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10538"">#10538</a>: autodoc: Inherited class attribute having docstring is documented even; if :confval:<code>autodoc_inherit_docstring</code> is disabled</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10509"">#10509</a>: autosummary: autosummary fails with a shared library</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10497"">#10497</a>: py domain: Failed to resolve strings in Literal. Patch by Adam Turner.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10523"">#10523</a>: HTML Theme: Fix double brackets on citation references in Docutils 0.18+.; Patch by Adam Turner.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10534"">#10534</a>: Missing CSS for nav.contents in Docutils 0.18+. Patch by Adam Turner.</li>; </ul>; <h1>Release 5.0.1 (released Jun 03, 2022)</h1>; <h2>Bugs fixed</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10498"">#10498</a>: gettext: TypeError is raised when sorting warning messages if a node; has no line number. Patch by Adam Turner.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10493"">#10493</a>: HTML Theme: :rst:dir:<code>topic</code> directive is rendered incorrectly with; Docutils 0.18. Patch by Adam Turner.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10495"">#10495</a>: IndexError is raised for a :rst:role:<code>kbd</code> role ha",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11925:2252,depend,dependabot,2252,https://hail.is,https://github.com/hail-is/hail/pull/11925,1,['depend'],['dependabot']
Integrability,"'s changelog</a>.</em></p>; <blockquote>; <h2>2022-11-03 3.0.1:</h2>; <ul>; <li>; <p>bugfixes:</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/12537"">#12537</a> [BUG] ImportError: cannot import name 'NotRequired' from 'typing_extensions'</li>; </ul>; </li>; <li>; <p>tasks:</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/12528"">#12528</a> [component: docs] Update tutorial link</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/12533"">#12533</a> [component: examples] [BUG] Units in blackbody example should be upright</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/12525"">#12525</a> [component: examples] Added metadata to bokeh\examples\plotting\checkout_form.py</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/12539"">#12539</a> [component: build] Remove runtime dependency on typing_extensions</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/12546"">#12546</a> [component: examples] Apply blackbody example label edits (<a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/12534"">#12534</a>) to the ts example as well</li>; </ul>; </li>; </ul>; <h2>2022-10-30 3.0:</h2>; <ul>; <li>bugfixes:; <ul>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/5046"">#5046</a> Webgl problem in stream app with multiple glyphs</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/6669"">#6669</a> [component: bokehjs] BoxAnnotation does not appear to handle formal NumberSpec</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/8168"">#8168</a> [component: bokehjs] Strange behavior with BoxSelectTool when click+dragging on toolbar</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/8332"">#8332</a> [component: bokehjs] Autohide toolbar quirks</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12454:1232,depend,dependabot,1232,https://hail.is,https://github.com/hail-is/hail/pull/12454,1,['depend'],['dependabot']
Integrability,"'s releases</a>.</em></p>; <blockquote>; <h2>v3.0.0</h2>; <h2><a href=""https://github.com/googleapis/python-logging/compare/v2.7.0...v3.0.0"">3.0.0</a> (2022-01-27)</h2>; <h3>⚠ BREAKING CHANGES</h3>; <ul>; <li>make logging API more friendly to use (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/422"">#422</a>)</li>; <li>api consistency between HTTP and Gapic layers (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/375"">#375</a>)</li>; <li>support string-encoded json (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/339"">#339</a>)</li>; <li>Infer default resource in logger (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/315"">#315</a>)</li>; <li>support json logs (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/316"">#316</a>)</li>; <li>deprecate AppEngineHandler and ContainerEngineHandler (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/310"">#310</a>)</li>; </ul>; <h3>Features</h3>; <ul>; <li>add api key support (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/472"">#472</a>) (<a href=""https://github.com/googleapis/python-logging/commit/81ca8c616acb988be1fbecfc2a0b1a5b39280149"">81ca8c6</a>)</li>; <li>add json_fields extras argument for adding to jsonPayload (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/447"">#447</a>) (<a href=""https://github.com/googleapis/python-logging/commit/a760e02371a55d6262e42de9e0222fffa2c7192b"">a760e02</a>)</li>; <li>avoid importing grpc when explicitly disabled (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/416"">#416</a>) (<a href=""https://github.com/googleapis/python-logging/commit/818213e143d6a1941211a48e0b23069a426ac300"">818213e</a>)</li>; <li>Infer default resource in logger (<a href=""https://github-redirect.dependabot.com/googleapis/python-loggi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11574:1242,depend,dependabot,1242,https://hail.is,https://github.com/hail-is/hail/pull/11574,1,['depend'],['dependabot']
Integrability,"'s the only event loop that will exist forever. Pytest (and newer version of IPython, afaict) violate this pretty liberally. ~~pytest_asyncio has [explicit instructions on how to run every test in the same event loop](https://pytest-asyncio.readthedocs.io/en/latest/how-to-guides/run_session_tests_in_same_loop.html). I've implemented those here.~~ [These instructions don't work](https://github.com/pytest-dev/pytest-asyncio/issues/744). It seems that the reliable way to ensure we're using one event loop everywhere is to use pytest-asyncio < 0.23 and to define an event_loop fixture with scope `'session'`. I also switched test_batch.py into pytest-only style. This allows me to use session-scoped fixtures so that they exist exactly once for the entire test suite execution. Also:; - `RouterAsyncFS` methods must either be a static method or an async method. We must not create an FS in a sync method. Both `parse_url` and `copy_part_size` now both do not allocate an FS.; - `httpx.py` now eagerly errors if the running event loop in `request` differs from that at allocation time. Annoying but much better error message than this nonsense about timeout context managers.; - `hail_event_loop` either gets the current thread's event loop (running or not, doesn't matter to us) or creates a fresh event loop and sets it as the current thread's event loop. The previous code didn't guarantee we'd get an event loop b/c `get_event_loop` fails if `set_event_loop` was previously called.; - `conftest.py` is inherited downward, so I lifted fixtures out of test_copy.py and friends and into a common `hailtop/conftest.py`; - I added `make -C hail pytest-inter-cloud` for testing the inter cloud directory. You still need appropriate permissions and authn.; - I removed extraneous pytest.mark.asyncio since we use auto mode everywhere.; - `FailureInjectingClientSession` creates an `aiohttp.ClientSession` and therefore must be used while an event loop is running. Easiest fix was to make the test async.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14097:1301,message,message,1301,https://hail.is,https://github.com/hail-is/hail/pull/14097,1,['message'],['message']
Integrability,"'tsv']}; bgzip {j.counts['tsv']}; gatk IndexFeatureFile --input {j.counts['tsv.gz']}; """"""). b.write_output(j.counts['tsv.gz'], output_path); b.write_output(j.counts['tsv.gz.tbi'], output_index_path); ```. (Trying to use `b.write_output(j.counts, output_base)` to write out the whole ResourceGroup fails because the `…/counts.counts.tsv` file no longer exists because it was removed by `bgzip`. In any case, we don't want to write that one to the final bucket anyway. Hence the two separate `write_output` invocations for the two desired output files.). This fails in the second `write_output` with a fairly mysterious exception:. ```; File ""…"", line 92, in test; b.write_output(j.counts['tsv.gz.tbi'], output_index_path); File ""…/lib/python/site-packages/hailtop/batch/batch.py"", line 595, in write_output; name = resource._source._resources_inverse[resource]; KeyError: __RESOURCE_FILE__11; ```. Checking that line of _batch.py_, it is failing while trying to print an error message because `_resources_inverse` is not set up for the JobResourceFiles within ResourceGroups. PR #13192 is a suggested fix for this. With that PR applied, this results in a more useful hail error message exception:. ```; hailtop.batch.exceptions.BatchException: undefined resource 'counts[""tsv.gz.tbi""]'; Hint: resources must be defined within the job methods 'command' or 'declare_resource_group'; ```. This can be worked around by mentioning the filename in the commands to be run — in a comment, because none of the commands actually need to specify the `.tbi` output filename:. ```python; …; j.command(f""""""; gatk SubCommand … --output {j.counts['tsv']}; bgzip {j.counts['tsv']}; gatk IndexFeatureFile --input {j.counts['tsv.gz']}; : {j.counts['tsv.gz.tbi']}; """"""); …; ```. This produces the desired two files — compressed data and the associated index — written to the final bucket. Is it kosher to use `write_output` on the individual items within a ResourceGroup like this?. However this resource **was** defined ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13191:1652,message,message,1652,https://hail.is,https://github.com/hail-is/hail/issues/13191,1,['message'],['message']
Integrability,"( WrappedArray(Map(null -> Map(WrappedArray() -> null))); , WrappedArray(); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> Map()), Map(null -> Map(WrappedArray() -> 2)))); , Set(WrappedArray()); , Set( WrappedArray(); , WrappedArray(Map(null -> Map()))); , Set(); , Set( WrappedArray(Map(null -> null)); , WrappedArray(Map(null -> Map()))); , Set( WrappedArray(Map(null -> Map(WrappedArray(null) -> 1)), Map(null -> Map(WrappedArray(5) -> 2))); , WrappedArray(Map())); , Set(); , Set(); , Set(WrappedArray(); , WrappedArray(Map(null -> Map()))); , Set(); , Set( null; , WrappedArray()); , Set( WrappedArray(Map(null -> Map(WrappedArray(1) -> 19))); , WrappedArray(Map(null -> Map(WrappedArray(0) -> 2)), Map(null -> Map())); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> Map(WrappedArray(2) -> null)), Map(null -> Map(WrappedArray() -> 17)), Map(null -> Map(WrappedArray() -> 1)))); , Set(WrappedArray(Map(null -> Map(WrappedArray(null) -> 1)), Map(null -> Map(WrappedArray(2) -> 0, WrappedArray() -> null)), Map(), Map())); , Set(WrappedArray(Map(null -> Map()), Map(null -> Map()), Map(null -> Map(WrappedArray(0) -> 0)))); , Set( WrappedArray(); , WrappedArray(Map(null -> Map(WrappedArray(0) -> null)))); , Set(WrappedArray(Map())); , Set( WrappedArray(Map()); , WrappedArray(Map(null -> Map(WrappedArray() -> 0))); , WrappedArray(Map(null -> Map()))); , Set(); , Set( WrappedArray(); , WrappedArray(Map(null -> Map(WrappedArray(null) -> 2))); , WrappedArray(Map(null -> Map()))); , Set( WrappedArray(Map(null -> Map(WrappedArray() -> 0))); , WrappedArray(Map(), Map(null -> Map()), Map(), Map(null -> Map(WrappedArray(0) -> null)))); ); , Set(null); , WrappedArray( WrappedArray(null, [null,false,1], [null,true,6]); , WrappedArray(); , WrappedArray([null,false,0], [null,true,1]); , WrappedArray(); , null; , WrappedArray(); , null; , WrappedArray(null, [null,false,0], null); , WrappedArray(null, null, null, [null,false,null]); , WrappedArray(null, [null,true,",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1902:2681,Wrap,WrappedArray,2681,https://hail.is,https://github.com/hail-is/hail/pull/1902,1,['Wrap'],['WrappedArray']
Integrability,"() done, defined at <ipython-input-7-ccfd397235b8>:2> exception=ValueError('unretrieved case')>, True, False); Task exception was never retrieved; future: <Task finished name='Task-579' coro=<foo.<locals>.raises() done, defined at <ipython-input-7-ccfd397235b8>:2> exception=ValueError('unretrieved case')>; Traceback (most recent call last):; File ""<ipython-input-7-ccfd397235b8>"", line 4, in raises; await asyncio.sleep(100); File ""/Users/dking/miniconda3/lib/python3.10/asyncio/tasks.py"", line 605, in sleep; return await future; asyncio.exceptions.CancelledError. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<ipython-input-7-ccfd397235b8>"", line 6, in raises; raise ValueError(message); ValueError: unretrieved case; ```. 5. And here is an example of ""retrieving"" the exception (by calling `Task.exception`). Notice we do not get the ""Task exception was never retrieved"" message. ```; In [8]: async def foo():; ...: async def raises(message):; ...: try:; ...: await asyncio.sleep(100); ...: finally:; ...: raise ValueError(message); ...:; ...: t = asyncio.create_task(raises('retrieved case')); ...: await asyncio.sleep(0) # let the other task run for a moment; ...: t.cancel(); ...: await asyncio.wait([t]); ...: print((t, t.done(), t.cancelled(), t.exception())); ...:; ...: asyncio.run(foo()); ...:; (<Task finished name='Task-599' coro=<foo.<locals>.raises() done, defined at <ipython-input-8-5fa396151822>:2> exception=ValueError('retrieved case')>, True, False, ValueError('retrieved case')); ```. ---. One more thing of interest, I confirmed that the ExitStack throws the first exception it encountered *after* performing all callbacks. ```ipython; In [6]: with ExitStack() as exit:; ...: def foo(i):; ...: print(str(i)); ...: raise ValueError(i); ...: exit.callback(foo, 1); ...: exit.callback(foo, 2); 2; 1; ---------------------------------------------------------------------------; ValueError Traceback (most recent ca",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13876:4152,message,message,4152,https://hail.is,https://github.com/hail-is/hail/pull/13876,1,['message'],['message']
Integrability,"(2022-01-12)</h2>; <h3>⚠ BREAKING CHANGES</h3>; <ul>; <li>Remove Python 2 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/657"">#657</a>)</li>; </ul>; <h3>Features</h3>; <ul>; <li>Remove Python 2 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/657"">#657</a>) (<a href=""https://github.com/googleapis/python-storage/commit/b6116700a4a32d28404c39018138e545f3f7910e"">b611670</a>)</li>; </ul>; <h2><a href=""https://www.github.com/googleapis/python-storage/compare/v1.43.0...v1.44.0"">1.44.0</a> (2022-01-05)</h2>; <h3>Features</h3>; <ul>; <li>add raw_download kwarg to BlobReader (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/668"">#668</a>) (<a href=""https://www.github.com/googleapis/python-storage/commit/10cdad630739a324ae0b16a3d14a67ca4c8a23c2"">10cdad6</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Describe code sample more specifically (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/660"">#660</a>) (<a href=""https://www.github.com/googleapis/python-storage/commit/0459cb4e866696c46385a5ad72e2a85db810a36b"">0459cb4</a>)</li>; <li>refresh readme instructions (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/667"">#667</a>) (<a href=""https://www.github.com/googleapis/python-storage/commit/ceb931403a755f2a0bdc20144287dbc4700c3360"">ceb9314</a>)</li>; <li>This is just a simple PR to better describe what the code is doing in the comments. (<a href=""https://www.github.com/googleapis/python-storage/commit/0459cb4e866696c46385a5ad72e2a85db810a36b"">0459cb4</a>)</li>; <li>use writeable streamin example for 'download_blob_to_file' (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/676"">#676</a>) (<a href=""https://www.github.com/googleapis/python-storage/commit/96092d4be36be478f9671e8940de4fd09cc6f7f0"">96092d4</a>)</li>; </ul>; <h2><a href=""https://www.github.com/googleapis/pyth",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11520:3506,depend,dependabot,3506,https://hail.is,https://github.com/hail-is/hail/pull/11520,1,['depend'],['dependabot']
Integrability,"(<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25011"">#25011</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/030141734a239fa6fb1aa7a8c43d322c82753510""><code>0301417</code></a> [Storage] Add argument to perf tests to use client-side encryption (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/24978"">#24978</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-storage-blob_12.11.0...azure-storage-blob_12.13.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=azure-storage-blob&package-manager=pip&previous-version=12.11.0&new-version=12.13.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12109:4985,Depend,Dependabot,4985,https://hail.is,https://github.com/hail-is/hail/pull/12109,1,['Depend'],['Dependabot']
Integrability,"(<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1703"">#1703</a>) (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1767"">#1767</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/java-storage/compare/v1.106.0...v2.15.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.cloud:google-cloud-storage&package-manager=gradle&previous-version=1.106.0&new-version=2.15.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12529:14712,Depend,Dependabot,14712,https://hail.is,https://github.com/hail-is/hail/pull/12529,1,['Depend'],['Dependabot']
Integrability,"(<a href=""https://github-redirect.dependabot.com/hagenw/sphinxcontrib-katex/issues/61"">#61</a>)</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/5ef309a8c9c7f9f12c3c17693adef49f593eb5de""><code>5ef309a</code></a> TST: re-enable link checks (<a href=""https://github-redirect.dependabot.com/hagenw/sphinxcontrib-katex/issues/60"">#60</a>)</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/e29e793911d2d71bd50a9ecb7248f51832ad8ea6""><code>e29e793</code></a> DOC: update copyright year (<a href=""https://github-redirect.dependabot.com/hagenw/sphinxcontrib-katex/issues/59"">#59</a>)</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/3ea5d66cc6985f4aa021c845ceeadd9a26f39a37""><code>3ea5d66</code></a> Release 0.8.3</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/d7636e1c52f3cc9a586171f5c9318b338acfbaaf""><code>d7636e1</code></a> Readd manifest to fix compilation of latest docs (<a href=""https://github-redirect.dependabot.com/hagenw/sphinxcontrib-katex/issues/58"">#58</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/hagenw/sphinxcontrib-katex/compare/0.5.1...v0.8.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinxcontrib-katex&package-manager=pip&previous-version=0.5.1&new-version=0.8.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recre",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11458:5709,depend,dependabot,5709,https://hail.is,https://github.com/hail-is/hail/pull/11458,2,['depend'],['dependabot']
Integrability,"(<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/924"">#924</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/666eab0b8cd7991697a9957001cf78401a76c52d""><code>666eab0</code></a> Add papermill downstream check and fix kernel client replies (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/925"">#925</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/fac9c3a890599ca8d7ee73206f98d75574cf4ca8""><code>fac9c3a</code></a> Prefer print in kernelspecapp (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/923"">#923</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/9904c4163a60c5e98737c7934b9a876c806c58fa""><code>9904c41</code></a> Publish 8.0.1</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/dc6113c360e05122430b8e130374e9f4e4b701d7""><code>dc6113c</code></a> Fix json_output in kernelspec app (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/921"">#921</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/dac3cc2caa83dde06a69012e610717019026aa4e""><code>dac3cc2</code></a> Publish 8.0.0</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/760a7835d8b20a9daea3737759b1751d5e55dad8""><code>760a783</code></a> MAINT: Don't format log in log call. (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/919"">#919</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/0ab0feb42fcdfe1a2528f630ca269c9fda6a2675""><code>0ab0feb</code></a> Reflect current protocol version in documentation (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/918"">#918</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/eded331c9f292a1838602414b6c05928917d13e8""><code>eded331</code></a> Add full api docs (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/908"">#908</a>)</li>;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12656:7637,depend,dependabot,7637,https://hail.is,https://github.com/hail-is/hail/pull/12656,1,['depend'],['dependabot']
Integrability,"(<a href=""https://redirect.github.com/GoogleCloudPlatform/google-auth-library-python-oauthlib/issues/317"">#317</a>)</li>; <li><a href=""https://github.com/googleapis/google-auth-library-python-oauthlib/commit/b303c66305a8dd17b375aa719a87dd3f619cccaa""><code>b303c66</code></a> chore: update docfx minimum Python version (<a href=""https://redirect.github.com/GoogleCloudPlatform/google-auth-library-python-oauthlib/issues/316"">#316</a>)</li>; <li><a href=""https://github.com/googleapis/google-auth-library-python-oauthlib/commit/fc1fad5d7b9b7774273b379d52022a9b294f7619""><code>fc1fad5</code></a> chore: rename rst files to avoid conflict with service names (<a href=""https://redirect.github.com/GoogleCloudPlatform/google-auth-library-python-oauthlib/issues/315"">#315</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/GoogleCloudPlatform/google-auth-library-python-oauthlib/compare/v0.8.0...v1.2.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=google-auth-oauthlib&package-manager=pip&previous-version=0.8.0&new-version=1.2.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot can",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14510:10607,Depend,Dependabot,10607,https://hail.is,https://github.com/hail-is/hail/pull/14510,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"(<a href=""https://redirect.github.com/pallets/jinja/issues/1918"">#1918</a>)</li>; <li><a href=""https://github.com/pallets/jinja/commit/19a55db3b411343309f2faaffaedbb089e841895""><code>19a55db</code></a> Make nested-trans-block exceptions nicer</li>; <li><a href=""https://github.com/pallets/jinja/commit/716795349a41d4983a9a4771f7d883c96ea17be7""><code>7167953</code></a> Merge pull request from GHSA-h5c8-rqwp-cp95</li>; <li><a href=""https://github.com/pallets/jinja/commit/7dd3680e6eea0d77fde024763657aa4d884ddb23""><code>7dd3680</code></a> xmlattr filter disallows keys with spaces</li>; <li>Additional commits viewable in <a href=""https://github.com/pallets/jinja/compare/3.1.2...3.1.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jinja2&package-manager=pip&previous-version=3.1.2&new-version=3.1.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14144:3580,depend,dependabot-security-updates,3580,https://hail.is,https://github.com/hail-is/hail/pull/14144,3,['depend'],['dependabot-security-updates']
Integrability,"(If you want to take a look at a live instance, I've deployed to my namespace and you can look at the batch logs here: https://ci.hail.is/batches/634 ). ignore all the log messages that have to do with `/wang/blog/healthcheck/`---since it's logging to persistent storage, it's also printing all the old logs from a few days ago to the batch logs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7381#issuecomment-548103287:172,message,messages,172,https://hail.is,https://github.com/hail-is/hail/pull/7381#issuecomment-548103287,1,['message'],['messages']
Integrability,"(Map(CallStats() -> AggSignature(CallStats(),ArrayBuffer(int32),ArrayBuffer(call))),CallStats(),None))),ApplyBinaryPrimOp(Add(),GetField(Ref(__iruid_400,struct{x: call, y: int32}),y),GetField(GetTupleElement(Ref(__iruid_401,tuple(struct{AC: array<int32>, AF: array<float64>, AN: int32, homozygote_count: array<int32>})),0),AN))),WrappedArray(AggStateSignature(Map(CallStats() -> AggSignature(CallStats(),ArrayBuffer(int32),ArrayBuffer(call))),CallStats(),None)))))). After lower: ; MakeTuple(ArrayBuffer((0,RunAggScan(GetTupleElement(In(0,PCTuple[0:PCArray[PCStruct{x:PCCall,y:PInt32}]]),0),__iruid_400,Begin(ArrayBuffer(InitOp(0,ArrayBuffer(I32(2)),AggStateSignature(Map(CallStats() -> AggSignature(CallStats(),ArrayBuffer(int32),ArrayBuffer(call))),CallStats(),None),CallStats()))),Begin(ArrayBuffer(SeqOp(0,ArrayBuffer(GetField(Ref(__iruid_400,struct{x: call, y: int32}),x)),AggStateSignature(Map(CallStats() -> AggSignature(CallStats(),ArrayBuffer(int32),ArrayBuffer(call))),CallStats(),None),CallStats()))),Let(__iruid_401,ResultOp(0,WrappedArray(AggStateSignature(Map(CallStats() -> AggSignature(CallStats(),ArrayBuffer(int32),ArrayBuffer(call))),CallStats(),None))),ApplyBinaryPrimOp(Add(),GetField(Ref(__iruid_400,struct{x: call, y: int32}),y),GetField(GetTupleElement(Ref(__iruid_401,tuple(struct{AC: array<int32>, AF: array<float64>, AN: int32, homozygote_count: array<int32>})),0),AN))),WrappedArray(AggStateSignature(Map(CallStats() -> AggSignature(CallStats(),ArrayBuffer(int32),ArrayBuffer(call))),CallStats(),None)))))). is.hail.utils.HailException: not a streamable IR: (GetTupleElement 0; (In PCTuple[0:PCArray[PCStruct{x:PCCall,y:PInt32}]] 0)); ...; at is.hail.expr.ir.EmitStream$.is$hail$expr$ir$EmitStream$$emitStream$1(EmitStream.scala:850). ```scala; private def toStream(node: IR): IR = {; node match {; case _: ToStream => node; case _ => {; if(node.typ.isInstanceOf[TContainer]) {; ToStream(node); } else {; node; }; }; }; }; ````. with . ```scala; private def toStream(node: ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8063#issuecomment-586602113:5629,Wrap,WrappedArray,5629,https://hail.is,https://github.com/hail-is/hail/pull/8063#issuecomment-586602113,2,['Wrap'],['WrappedArray']
Integrability,(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:363); at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:968); at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$2.apply$mcV$sp(RDD.scala:1517); at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$2.apply(RDD.scala:1505); at org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$2.apply(RDD.scala:1505); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:363); at org.apache.spark.rdd.RDD.saveAsTextFile(RDD.scala:1505); at is.hail.utils.richUtils.RichRDD$.writeTable$extension(RichRDD.scala:66); at is.hail.io.vcf.ExportVCF$.apply(ExportVCF.scala:474); at is.hail.expr.ir.MatrixVCFWriter.apply(MatrixWriter.scala:48); at is.hail.expr.ir.WrappedMatrixWriter.apply(MatrixWriter.scala:24); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:743); at is.hail.expr.ir.Interpret$.apply(Interpret.scala:91); at is.hail.expr.ir.CompileAndEvaluate$$anonfun$1.apply(CompileAndEvaluate.scala:33); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:24); at is.hail.expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:33); at is.hail.backend.Backend$$anonfun$execute$1.apply(Backend.scala:86); at is.hail.backend.Backend$$anonfun$execute$1.apply(Backend.scala:86); at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:8); at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:7); at is.hail.utils.package$.using(package.scala:596); at is.hail.annotations.Region$.scoped(Region.scala:18); at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:7); at is.hail.backend.Backend.execute(Backend.scala:86); at is.hail.backend.Backend.executeJSON(Backend.scala:92); at sun.reflect.NativeMethod,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8106:14466,Wrap,WrappedMatrixWriter,14466,https://hail.is,https://github.com/hail-is/hail/issues/8106,2,['Wrap'],['WrappedMatrixWriter']
Integrability,"(This definitely feels like a problem. Took three minutes to serialize an array with 10 million ints and with 40 million ints, this happens:). ```; >>> def serialize_test(n):; ... t = [i for i in range(n)]; ... t1 = datetime.now(); ... print(len(t)); ... print(hl.eval(hl.len(hl.array(t)))); ... t2 = datetime.now(); ... print(t2 - t1); ... ; >>> serialize_test(40000000); 40000000; Exception in thread ""Thread-2"" java.lang.OutOfMemoryError: Java heap space; 	at java.util.Arrays.copyOf(Arrays.java:3332); 	at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:124); 	at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:649); 	at java.lang.StringBuilder.append(StringBuilder.java:202); 	at py4j.StringUtil.unescape(StringUtil.java:57); 	at py4j.Protocol.getString(Protocol.java:475); 	at py4j.Protocol.getObject(Protocol.java:302); 	at py4j.commands.AbstractCommand.getArguments(AbstractCommand.java:82); 	at py4j.commands.CallCommand.execute(CallCommand.java:77); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748); ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/Users/wang/spark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1035, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/Users/wang/spark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 883, in send_command; response = connection.send_command(command); File ""/Users/wang/spark-2.2.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1040, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; Traceback (most recent call last):; File ""<stdi",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5407#issuecomment-474983184:793,Protocol,Protocol,793,https://hail.is,https://github.com/hail-is/hail/issues/5407#issuecomment-474983184,4,['Protocol'],['Protocol']
Integrability,(TransportContext.java:331) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:274) ~[?:1.8.0_392]; 	at sun.security.ssl.TransportContext.fatal(TransportContext.java:269) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:119) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1404) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1372) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl.access$300(SSLSocketImpl.java:73) ~[?:1.8.0_392]; 	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:966) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[?:1.8.0_392]; 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[?:1.8.0_392]; 	at sun.net.www.MeteredStream.read(MeteredStream.java:134) ~[?:1.8.0_392]; 	at java.io.FilterInputStream.read(FilterInputStream.java:133) ~[?:1.8.0_392]; 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3460) ~[?:1.8.0_392]; 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385) ~[?:1.8.0_392]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:242) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:113) ~[gs:__hail-query-ger0g_jars_dking_3xzj5v1p7z3y_38ae919f8ce5c699083a8effa13127b0ba0c41ad.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.UnbufferedReadableByteChannelSession$Unbuffered,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352:1206,protocol,protocol,1206,https://hail.is,https://github.com/hail-is/hail/pull/14094#issuecomment-1852957352,1,['protocol'],['protocol']
Integrability,"(We've added `if messages: …` to the code in question to prevent this, but it would be good to fix the issue from the Hail end as well.)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14700#issuecomment-2372549348:17,message,messages,17,https://hail.is,https://github.com/hail-is/hail/pull/14700#issuecomment-2372549348,1,['message'],['messages']
Integrability,"(WrappedArray() -> null)))); , Set(); , Set( WrappedArray(Map(null -> Map(WrappedArray() -> null))); , WrappedArray(); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> Map()), Map(null -> Map(WrappedArray() -> 2)))); , Set(WrappedArray()); , Set( WrappedArray(); , WrappedArray(Map(null -> Map()))); , Set(); , Set( WrappedArray(Map(null -> null)); , WrappedArray(Map(null -> Map()))); , Set( WrappedArray(Map(null -> Map(WrappedArray(null) -> 1)), Map(null -> Map(WrappedArray(5) -> 2))); , WrappedArray(Map())); , Set(); , Set(); , Set(WrappedArray(); , WrappedArray(Map(null -> Map()))); , Set(); , Set( null; , WrappedArray()); , Set( WrappedArray(Map(null -> Map(WrappedArray(1) -> 19))); , WrappedArray(Map(null -> Map(WrappedArray(0) -> 2)), Map(null -> Map())); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> Map(WrappedArray(2) -> null)), Map(null -> Map(WrappedArray() -> 17)), Map(null -> Map(WrappedArray() -> 1)))); , Set(WrappedArray(Map(null -> Map(WrappedArray(null) -> 1)), Map(null -> Map(WrappedArray(2) -> 0, WrappedArray() -> null)), Map(), Map())); , Set(WrappedArray(Map(null -> Map()), Map(null -> Map()), Map(null -> Map(WrappedArray(0) -> 0)))); , Set( WrappedArray(); , WrappedArray(Map(null -> Map(WrappedArray(0) -> null)))); , Set(WrappedArray(Map())); , Set( WrappedArray(Map()); , WrappedArray(Map(null -> Map(WrappedArray() -> 0))); , WrappedArray(Map(null -> Map()))); , Set(); , Set( WrappedArray(); , WrappedArray(Map(null -> Map(WrappedArray(null) -> 2))); , WrappedArray(Map(null -> Map()))); , Set( WrappedArray(Map(null -> Map(WrappedArray() -> 0))); , WrappedArray(Map(), Map(null -> Map()), Map(), Map(null -> Map(WrappedArray(0) -> null)))); ); , Set(null); , WrappedArray( WrappedArray(null, [null,false,1], [null,true,6]); , WrappedArray(); , WrappedArray([null,false,0], [null,true,1]); , WrappedArray(); , null; , WrappedArray(); , null; , WrappedArray(null, [null,false,0], null); , WrappedArray(null, null, null, [null,fal",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1902:2638,Wrap,WrappedArray,2638,https://hail.is,https://github.com/hail-is/hail/pull/1902,1,['Wrap'],['WrappedArray']
Integrability,"(WrappedArray(2) -> 2)), Map(null -> Map(WrappedArray() -> 1)), Map(null -> Map(WrappedArray(1) -> 2))); ); , Set(WrappedArray(Map(null -> null), Map(null -> Map(WrappedArray(2) -> 31, WrappedArray(0) -> 0)))); , Set(WrappedArray(Map(null -> Map()), Map(null -> null))); , Set( WrappedArray(Map()); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> null)); , WrappedArray(); , WrappedArray(null, Map(null -> Map(WrappedArray() -> null)))); , Set(); , Set( WrappedArray(Map(null -> Map(WrappedArray() -> null))); , WrappedArray(); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> Map()), Map(null -> Map(WrappedArray() -> 2)))); , Set(WrappedArray()); , Set( WrappedArray(); , WrappedArray(Map(null -> Map()))); , Set(); , Set( WrappedArray(Map(null -> null)); , WrappedArray(Map(null -> Map()))); , Set( WrappedArray(Map(null -> Map(WrappedArray(null) -> 1)), Map(null -> Map(WrappedArray(5) -> 2))); , WrappedArray(Map())); , Set(); , Set(); , Set(WrappedArray(); , WrappedArray(Map(null -> Map()))); , Set(); , Set( null; , WrappedArray()); , Set( WrappedArray(Map(null -> Map(WrappedArray(1) -> 19))); , WrappedArray(Map(null -> Map(WrappedArray(0) -> 2)), Map(null -> Map())); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> Map(WrappedArray(2) -> null)), Map(null -> Map(WrappedArray() -> 17)), Map(null -> Map(WrappedArray() -> 1)))); , Set(WrappedArray(Map(null -> Map(WrappedArray(null) -> 1)), Map(null -> Map(WrappedArray(2) -> 0, WrappedArray() -> null)), Map(), Map())); , Set(WrappedArray(Map(null -> Map()), Map(null -> Map()), Map(null -> Map(WrappedArray(0) -> 0)))); , Set( WrappedArray(); , WrappedArray(Map(null -> Map(WrappedArray(0) -> null)))); , Set(WrappedArray(Map())); , Set( WrappedArray(Map()); , WrappedArray(Map(null -> Map(WrappedArray() -> 0))); , WrappedArray(Map(null -> Map()))); , Set(); , Set( WrappedArray(); , WrappedArray(Map(null -> Map(WrappedArray(null) -> 2))); , WrappedArray(Map(null -> Map()))); , Set( WrappedAr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1902:2214,Wrap,WrappedArray,2214,https://hail.is,https://github.com/hail-is/hail/pull/1902,1,['Wrap'],['WrappedArray']
Integrability,"(WrappedArray(Map(null -> Map()), Map(null -> null))); , Set( WrappedArray(Map()); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> null)); , WrappedArray(); , WrappedArray(null, Map(null -> Map(WrappedArray() -> null)))); , Set(); , Set( WrappedArray(Map(null -> Map(WrappedArray() -> null))); , WrappedArray(); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> Map()), Map(null -> Map(WrappedArray() -> 2)))); , Set(WrappedArray()); , Set( WrappedArray(); , WrappedArray(Map(null -> Map()))); , Set(); , Set( WrappedArray(Map(null -> null)); , WrappedArray(Map(null -> Map()))); , Set( WrappedArray(Map(null -> Map(WrappedArray(null) -> 1)), Map(null -> Map(WrappedArray(5) -> 2))); , WrappedArray(Map())); , Set(); , Set(); , Set(WrappedArray(); , WrappedArray(Map(null -> Map()))); , Set(); , Set( null; , WrappedArray()); , Set( WrappedArray(Map(null -> Map(WrappedArray(1) -> 19))); , WrappedArray(Map(null -> Map(WrappedArray(0) -> 2)), Map(null -> Map())); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> Map(WrappedArray(2) -> null)), Map(null -> Map(WrappedArray() -> 17)), Map(null -> Map(WrappedArray() -> 1)))); , Set(WrappedArray(Map(null -> Map(WrappedArray(null) -> 1)), Map(null -> Map(WrappedArray(2) -> 0, WrappedArray() -> null)), Map(), Map())); , Set(WrappedArray(Map(null -> Map()), Map(null -> Map()), Map(null -> Map(WrappedArray(0) -> 0)))); , Set( WrappedArray(); , WrappedArray(Map(null -> Map(WrappedArray(0) -> null)))); , Set(WrappedArray(Map())); , Set( WrappedArray(Map()); , WrappedArray(Map(null -> Map(WrappedArray() -> 0))); , WrappedArray(Map(null -> Map()))); , Set(); , Set( WrappedArray(); , WrappedArray(Map(null -> Map(WrappedArray(null) -> 2))); , WrappedArray(Map(null -> Map()))); , Set( WrappedArray(Map(null -> Map(WrappedArray() -> 0))); , WrappedArray(Map(), Map(null -> Map()), Map(), Map(null -> Map(WrappedArray(0) -> null)))); ); , Set(null); , WrappedArray( WrappedArray(null, [null,false,1], [null,true,",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1902:2430,Wrap,WrappedArray,2430,https://hail.is,https://github.com/hail-is/hail/pull/1902,1,['Wrap'],['WrappedArray']
Integrability,"(gh issue <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/992"">#992</a>, pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/994"">#994</a>).</li>; <li>Updated <code>parser.parse</code> documentation to reflect the switch from; <code>ValueError</code> to <code>ParserError</code>. (gh issue <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/992"">#992</a>, pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/994"">#994</a>).</li>; <li>Fixed methods in the <code>rrule</code> module not being displayed in the docs. (gh pr; <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1025"">#1025</a>)</li>; <li>Changed some relative links in the exercise documentation to refer to the; document locations in the input tree, rather than the generated HTML files in; the HTML output tree (which presumably will not exist in non-HTML output; formats). (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1078"">#1078</a>).</li>; </ul>; <h2>Misc</h2>; <ul>; <li>Moved <code>test_imports.py</code>, <code>test_internals.py</code> and <code>test_utils.py</code> to; pytest. Reported and fixed by <a href=""https://github.com/jpurviance""><code>@​jpurviance</code></a> (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/978"">#978</a>)</li>; <li>Added project_urls for documentation and source. Patch by <a href=""https://github.com/andriyor""><code>@​andriyor</code></a> (gh pr; <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/975"">#975</a>).</li>; <li>Simplified handling of bytes and bytearray in <code>_parser._timelex</code>. Reported; and fixed by <a href=""https://github.com/frenzymadness""><code>@​frenzymadness</code></a> (gh issue <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1060"">#1060</a>).</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <det",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11518:7926,depend,dependabot,7926,https://hail.is,https://github.com/hail-is/hail/pull/11518,1,['depend'],['dependabot']
Integrability,"(gh issue <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/992"">#992</a>, pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/994"">#994</a>).</li>; <li>Updated <code>parser.parse</code> documentation to reflect the switch from; <code>ValueError</code> to <code>ParserError</code>. (gh issue <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/992"">#992</a>, pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/994"">#994</a>).</li>; <li>Fixed methods in the <code>rrule</code> module not being displayed in the docs. (gh pr; <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1025"">#1025</a>)</li>; <li>Changed some relative links in the exercise documentation to refer to the; document locations in the input tree, rather than the generated HTML files in; the HTML output tree (which presumably will not exist in non-HTML output; formats). (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1078"">#1078</a>).</li>; </ul>; <h2>Misc</h2>; <ul>; <li>Moved <code>test_imports.py</code>, <code>test_internals.py</code> and <code>test_utils.py</code> to; pytest. Reported and fixed by <a href=""https://github.com/jpurviance""><code>@​jpurviance</code></a> (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/978"">#978</a>)</li>; <li>Added project_urls for documentation and source. Patch by <a href=""https://github.com/andriyor""><code>@​andriyor</code></a> (gh pr; <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/975"">#975</a>).</li>; <li>Simplified handling of bytes and bytearray in <code>_parser._timelex</code>. Reported</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/dateutil/dateutil/blob/master/NEWS"">python-dateutil's changelog</a>.</em></p>; <blockquote>; <h1>Version 2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11518:3605,depend,dependabot,3605,https://hail.is,https://github.com/hail-is/hail/pull/11518,1,['depend'],['dependabot']
Integrability,"(https://github.com/jupyter/jupyter_client) from 7.4.8 to 8.0.2.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/jupyter/jupyter_client/releases"">jupyter-client's releases</a>.</em></p>; <blockquote>; <h2>v8.0.2</h2>; <h2>8.0.2</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v8.0.1...717d36edcd9ce595f727d8b5a27e270c2a6e2c46"">Full Changelog</a>)</p>; <h3>Bugs fixed</h3>; <ul>; <li>Add papermill downstream check and fix kernel client replies <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/925"">#925</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; </ul>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Adopt more ruff rules <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/924"">#924</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; <li>Prefer print in kernelspecapp <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/923"">#923</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_client/graphs/contributors?from=2023-01-26&amp;to=2023-01-30&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Ablink1073+updated%3A2023-01-26..2023-01-30&amp;type=Issues""><code>@​blink1073</code></a></p>; <h2>v8.0.1</h2>; <h2>8.0.1</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v8.0.0...dc6113c360e05122430b8e130374e9f4e4b701d7"">Full Changelog</a>)</p>; <h3>Bugs fixed</h3>; <ul>; <li>Fix json_output in kernelspec app <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/921"">#921</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12656:1017,depend,dependabot,1017,https://hail.is,https://github.com/hail-is/hail/pull/12656,1,['depend'],['dependabot']
Integrability,"(https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6050294](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6050294) | `cryptography:` <br> `41.0.7 -> 42.0.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Information Exposure <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6126975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6126975) | `cryptography:` <br> `41.0.7 -> 42.0.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxNjVmNDVkMi00ZDM3LTRmNzAtOGU1OC00OGIxOGJhNmVlOTgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjE2NWY0NWQyLTRkMzctNGY3MC04ZTU4LTQ4YjE4YmE2ZWU5OCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14203:1969,depend,dependency,1969,https://hail.is,https://github.com/hail-is/hail/pull/14203,2,['depend'],"['dependencies', 'dependency']"
Integrability,"(https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **479/1000** <br/> **Why?** Has a fix available, CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6050294](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6050294) | `cryptography:` <br> `41.0.7 -> 42.0.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | Information Exposure <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6126975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6126975) | `cryptography:` <br> `41.0.7 -> 42.0.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyMTAxMzNhYS03MjA2LTRmMzQtYTQ2OC1iYjY5YWJmYTUzZjEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjIxMDEzM2FhLTcyMDYtNGYzNC1hNDY4LWJiNjlhYmZhNTNmMSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14200:1695,depend,dependency,1695,https://hail.is,https://github.com/hail-is/hail/pull/14200,2,['depend'],"['dependencies', 'dependency']"
Integrability,"(i) -> O(i, i)` makes a square matrix whose diagonal is T. * `T(i) -> O(i, j)` and `T(i) -> O(j, i)` broadcast T over a matrix in the two possible directions. Now let T be a 2-tensor. * `T(i, j) -> O(i)` is the vector of row-sums of T. * `T(i, i) -> O(i)` is the diagonal of T. * `T(i, i) -> O()` is the trace of T. * `T(i, j) -> O(j, i)` is transposition. How do we represent matrix multiplication? Let T1 and T2 be 2-tensors. Then letting `T = Out(T1, T2, ""and"").map((x, y) => x * y)`, the matrix product is given by. * `T(i, j, j, k) -> O(i, k)`. In general, an index operation on T requires specifying an output tensor O (including its shape, though you can deduce that in non-broadcasting cases), a set of index variables (eg. ""i, j, k""), and an assignment of a variable to each dimension of T and O. . More abstractly, let DT and DO be the sets of dimensions of T and O. An index operation consists of a set I and two functions DT -> I <- DO, a ""cospan"". These operations compose by cospan composition, which involves a pushout (a disjoint union and a quotient). Let i: DT -> I and o: DO -> I be the two maps assigning index variables. It helps to consider some special cases (compare to the examples above):. * If i is surjective, and o is identity, this is extracting a diagonal from T. * If i is injective, and o is identity, this is a broadcast. * If i is identity, and o is surjective, this embeds T as a diagonal of a higher-dimensional output tensor. * If i is identity, and o is injective, this is a pure aggregation, summing out some dimensions of T. To make composition easy to compute, we could represent an index operation using a union-find structure for I. In other words, an index operation consists of a union-find structure I, and two arrays of points of I, encoding the two functions above. Then the composition of (T, I1, M) and (M, I2, O) is (T, I', O), where I' is computed by taking the union I1+I2, then for each dimension of M, unioning the assigned points of I1 and I2.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5190#issuecomment-457598772:3583,inject,injective,3583,https://hail.is,https://github.com/hail-is/hail/pull/5190#issuecomment-457598772,4,['inject'],['injective']
Integrability,"(mt, mt.project_id). <ipython-input-16-30f700382b6e> in add_popmax_expr(freq, freq_meta, populations); 57 """"""; 58 pops_to_use = hl.literal(populations); ---> 59 freq = hl.map(lambda x: x[0].annotate(**x[1]), hl.zip(freq, freq_meta)); 60 freq_filtered = hl.filter(lambda f: (f.meta.size() == 2) & (f.meta.get('group') == 'adj') &; 61 pops_to_use.contains(f.meta.get('pop')) & (f.AC[1] > 0), freq). /home/hail/hail.zip/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). /home/hail/hail.zip/hail/expr/functions.py in map(f, collection); 2641 Collection where each element has been transformed by `f`.; 2642 """"""; -> 2643 return collection.map(f); 2644 ; 2645 . /home/hail/hail.zip/hail/typecheck/check.py in wrapper(*args, **kwargs); 545 def wrapper(*args, **kwargs):; 546 args_, kwargs_ = check_all(f, args, kwargs, checkers, is_method=is_method); --> 547 return f(*args_, **kwargs_); 548 ; 549 update_wrapper(wrapper, f). /home/hail/hail.zip/hail/expr/expressions/typed_expressions.py in map(self, f); 296 return a; 297 ; --> 298 array_map = hl.array(self)._ir_lambda_method(transform_ir, f, self._type.element_type, lambda t: self._type.__class__(t)); 299 ; 300 if isinstance(self._type, tset):. /home/hail/hail.zip/hail/expr/expressions/base_expression.py in _ir_lambda_method(self, irf, f, input_type, ret_type_f, *args); 473 new_id = Env.get_uid(); 474 lambda_result = to_expr(; --> 475 f(expressions.construct_variable(new_id, input_type, self._indices, self._aggregations))); 476 ; 477 indices, aggregations = unify_all(self, lambda_result). /home/hail/hail.zip/hail/typecheck/check.py in f(*args); 303 ; 304 def f(*args):; --> 305 ret = x(*args); 306 try:; 307 return self.ret_checker.check(ret, caller, param). /home/hail/hail.zip/hail/typecheck/check.py in f(*args); 303 ; 304 def f(*args):; --> 305 re",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4081:2470,wrap,wrapper,2470,https://hail.is,https://github.com/hail-is/hail/issues/4081,3,['wrap'],['wrapper']
Integrability,"(pulling out bits from #6480). This defines the StagedRegionValueAggregator and RVAState interfaces, implementing ArrayElementsAggregator and PrevNonNullAggregator as examples. Builds on #6500 and #6499. (for clarity, I've put all the changes from those PRs into the first commit.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6501:89,interface,interfaces,89,https://hail.is,https://github.com/hail-is/hail/pull/6501,1,['interface'],['interfaces']
Integrability,"(that's not to say we shouldn't do dependency audits every few months, bumping the pinned version to latest)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7299#issuecomment-542205189:35,depend,dependency,35,https://hail.is,https://github.com/hail-is/hail/issues/7299#issuecomment-542205189,1,['depend'],['dependency']
Integrability,(vague) sort out python and R integration story,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/21:30,integrat,integration,30,https://hail.is,https://github.com/hail-is/hail/issues/21,1,['integrat'],['integration']
Integrability,"(x).; 0, 0); ```; but I'm not sure I really like any of them.; * the scoping for `Recur` is difficult to check and enforce.; * It's difficult to check if a TailLoop is invalidly attempting to recur a function from a different loop (in a nested environment), except by the type signature. I think I could give each loop a name so that `Recur` unambiguously refers to a loop defined in the surrounding scope, mostly treating `Recur` as something of a function reference.; * The code generation is rather inconsistent, since the `Recur` node technically has the same type as the return type of the function, but the code generated needs to be a jump node with no actual value (which makes the generated EmitTriplet look a lot like it has type TVoid!); * @patrick-schultz proposed a similar design, but with two additional types to make the difference between the type of the `Recur` concept and the actual return type more explicit. I have not yet implemented it because I think it might make this python interface more difficult to support, and I rather like its simplicity.; * @patrick-schultz and I were talking about rewriting loops in the stream interface.; * We can only emit calls to recur in the same method that the original loop is defined in, because we are using jumps to implement them. This means we need to know that we are not going to wrap any calls that contain `Recur` in a method. I don't believe there are any cases where we wrap `If` conditions or `Let` bodies in methods, so this is fine for now, but we're not enforcing it in any way. I believe that the iteration for the stream codegen stuff will always be in the same method, so we wouldn't have to deal with this specially there.; * I've implemented a pretty simple version of here, as part of the `Streamify` pass. I believe it should handle all the valid tail-recursive cases, but I don't think we want to use it right now since it'll always allocate (as opposed to not allocating if all state is primitive). We could potenti",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7614:2071,interface,interface,2071,https://hail.is,https://github.com/hail-is/hail/pull/7614,1,['interface'],['interface']
Integrability,") (<a href=""https://www.github.com/googleapis/google-auth-library-python/commit/8e95c1e458793593972b6b05a355aaeaecd31670"">8e95c1e</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/google-auth-library-python/blob/main/CHANGELOG.md"">google-auth's changelog</a>.</em></p>; <blockquote>; <h2><a href=""https://github.com/googleapis/google-auth-library-python/compare/v2.5.0...v2.6.0"">2.6.0</a> (2022-01-31)</h2>; <h3>Features</h3>; <ul>; <li>ADC can load an impersonated service account credentials. (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/962"">#962</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/52c8ef90058120d7d04d3d201adc111664be526c"">52c8ef9</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <ul>; <li>revert &quot;feat: add api key support (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/826"">#826</a>)&quot; (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/964"">#964</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/f9f23f4370f2a7a5b2c66ee56a5e700ef03b5b06"">f9f23f4</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/google-auth-library-python/compare/v2.4.1...v2.5.0"">2.5.0</a> (2022-01-25)</h2>; <h3>Features</h3>; <ul>; <li>ADC can load an impersonated service account credentials. (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/956"">#956</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/a8eb4c8693055a3420cfe9c3420aae2bc8cd465a"">a8eb4c8</a>)</li>; </ul>; <h3><a href=""https://github.com/googleapis/google-auth-library-python/compare/v2.4.0...v2.4.1"">2.4.1</a> (2022-01-21)</h3>; <h3>Bug Fixes</h3>; <ul>; <li>urllib3 import (<a href=""https://github-redirect.dependabo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11546:5726,depend,dependabot,5726,https://hail.is,https://github.com/hail-is/hail/pull/11546,1,['depend'],['dependabot']
Integrability,") <a href=""https://github.com/BeyondEvil""><code>@​BeyondEvil</code></a></li>; <li>Fix min-width which produced horizontal scrolls (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/237"">#237</a>) <a href=""https://github.com/ssbarnea""><code>@​ssbarnea</code></a></li>; <li>Support utf8 display (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/244"">#244</a>) <a href=""https://github.com/lzhu666""><code>@​lzhu666</code></a></li>; <li>Trigger sorting for initial sort column (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/248"">#248</a>) <a href=""https://github.com/wanam""><code>@​wanam</code></a></li>; <li>Close opened resource. (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/235"">#235</a>) <a href=""https://github.com/krzysztof-pawlik-gat""><code>@​krzysztof-pawlik-gat</code></a></li>; <li>Keep sort preference for previously sorted columns (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/220"">#220</a>) <a href=""https://github.com/wanam""><code>@​wanam</code></a></li>; <li>Fix assets file naming to work across both *nix and windows (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/223"">#223</a>) <a href=""https://github.com/BeyondEvil""><code>@​BeyondEvil</code></a></li>; <li>Remove unused and undocumented markers (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/224"">#224</a>) <a href=""https://github.com/BeyondEvil""><code>@​BeyondEvil</code></a></li>; <li>Append a line break after captured log sections (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/217"">#217</a>) <a href=""https://github.com/borntyping""><code>@​borntyping</code></a></li>; <li>Handle when report title is stored as an environment variable (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/203"">#203</a>) <a href=""https://github.com/BeyondEvil""><code>@​Bey",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11524:6376,depend,dependabot,6376,https://hail.is,https://github.com/hail-is/hail/pull/11524,1,['depend'],['dependabot']
Integrability,") [""{\""path\"":\""gs://aou_analysis/250k/data/utils/aou_mt_sample_qc_250k.ht\""}""] ; !191 = MakeStruct(); !192 = WriteMetadata(!191) [""{\""path\"":\""gs://aou_analysis/250k/data/utils/aou_mt_sample_qc_250k.ht/globals\""}""] ; !193 = MakeStruct(); !194 = WriteMetadata(!193) [""{\""path\"":\""gs://aou_analysis/250k/data/utils/aou_mt_sample_qc_250k.ht/cols\""}""] ; !195 = MakeStruct(); !196 = WriteMetadata(!195) [""{\""path\"":\""gs://aou_analysis/250k/data/utils/aou_mt_sample_qc_250k.ht/rows\""}""] ; !197 = MakeStruct(); !198 = WriteMetadata(!197) [""{\""path\"":\""gs://aou_analysis/250k/data/utils/aou_mt_sample_qc_250k.ht/entries\""}""]; !199 = Begin(!154, !160, !166, !169, !172, !176, !188, !190, !192, !194, !196, !198); Begin(!11, !199); ```. </details>. Notice that, after lowering to CDAIR, the `WriteMetadata` for; `gs://aou_analysis/250k/data/utils/aou_mt_sample_qc_250k.ht`, `....ht/globals`, `....ht/cols`,; `...ht/rows`, and `...ht/entries` all appear thrice. The error message is clearly coming from; `WriteMetadata` writing into the root of the Hail Table. ```; !1 = MakeStruct(); !2 = WriteMetadata(!1) [""{\""path\"":\""gs://aou_analysis/250k/data/utils/aou_mt_sample_qc_250k.ht\"",\""overwrite\"":false,\""refs\"":{\""rowType\"":\""Struct{locus:Locus(GRCh38),alleles:Array[String],filters:Set[String],a_index:Int32,was_split:Boolean,variant_qc:Struct{gq_stats:Struct{mean:Float64,stdev:Float64,min:Float64,max:Float64},call_rate:Float64,n_called:Int64,n_not_called:Int64,n_filtered:Int64,n_het:Int64,n_non_ref:Int64,het_freq_hwe:Float64,p_value_hwe:Float64,p_value_excess_het:Float64},info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,homozygote_count:Array[Int32]},`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{GT:Call,GQ:Int32,RGQ:Int32,FT:String,AD:Array[Int32]}]}\"",\""key\"":[\""locus\"",\""alleles\""],\""globalType\"":\""Struct{__cols:Array[Struct{s:String,mt_sample_qc:Struct{gq_stats:Struct{mean:Float64,stdev:Float64,min:Float64,max:Float64},call_rate:Float64,n_called:Int64,n_not_called:Int64",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13809:42435,message,message,42435,https://hail.is,https://github.com/hail-is/hail/issues/13809,1,['message'],['message']
Integrability,) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.Abstracead(DefaultChannelPipeline.java:935) at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:138) at ed(NioEventLoop.java:580) at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:497) at io.netty.channel.nio.Nio at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:138) at java.lang.Thread.run(Thrpark.network.server.TransportChannelHandler.channelRead(TransportChannelHandler.java:120) at io.netty.channel.AbstractChannelHandlerContext.innelHandlerContext.java:348) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) at eChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerCetty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102) at io.netty.channel.AbstractChannelHandlerContext.innelHandlerContext.java:348) at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340) at lerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362) at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(Abstrac0) at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1359) at io.netty.channel.AbstractChannelRead(AbstractChannelHandlerContext.java:348) at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:935) at ocessSelectedKey(NioEventLoop.java:645) at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:580) at ava:459) at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858) at io.netty.util.concurrent. Java stack trace:; org.apache.spark.SparkException: Job aborted.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8106:10102,Message,MessageToMessageDecoder,10102,https://hail.is,https://github.com/hail-is/hail/issues/8106,1,['Message'],['MessageToMessageDecoder']
Integrability,") fast and slow paths depending on page boundary</li>; <li><a href=""https://github.com/ijl/orjson/commit/29884e617d35c6774f60b8fedf6de47d74edcd2f""><code>29884e6</code></a> Fix buffer overread in format_escaped_str</li>; <li><a href=""https://github.com/ijl/orjson/commit/c825472198c20f40064af63d7ef7b21eb2e3aaef""><code>c825472</code></a> cargo update</li>; <li><a href=""https://github.com/ijl/orjson/commit/4eb4f005a6f1b71609051770612a055b584b73d2""><code>4eb4f00</code></a> 3.9.13</li>; <li>Additional commits viewable in <a href=""https://github.com/ijl/orjson/compare/3.9.10...3.9.15"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=orjson&package-manager=pip&previous-version=3.9.10&new-version=3.9.15)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ign",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14357:4995,Depend,Dependabot,4995,https://hail.is,https://github.com/hail-is/hail/pull/14357,1,['Depend'],['Dependabot']
Integrability,") from 5.0.3 to 6.0.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/docker/docker-py/releases"">docker's releases</a>.</em></p>; <blockquote>; <h2>6.0.1</h2>; <h2>🐛 Bugfixes</h2>; <ul>; <li>Fix for <code>The pipe has been ended</code> errors on Windows (<a href=""https://github-redirect.dependabot.com/docker/docker-py/issues/3056"">#3056</a>)</li>; <li>Support floats for timestamps in Docker logs (<code>since</code> / <code>until</code>) (<a href=""https://github-redirect.dependabot.com/docker/docker-py/issues/3031"">#3031</a>)</li>; </ul>; <h2>What's Changed</h2>; <ul>; <li>docs: install package in ReadTheDocs build by <a href=""https://github.com/milas""><code>@​milas</code></a> in <a href=""https://github-redirect.dependabot.com/docker/docker-py/pull/3032"">docker/docker-py#3032</a></li>; <li>Use latest stable syntax for Dockerfiles by <a href=""https://github.com/thaJeztah""><code>@​thaJeztah</code></a> in <a href=""https://github-redirect.dependabot.com/docker/docker-py/pull/3035"">docker/docker-py#3035</a></li>; <li>feat: add support for floats to docker logs params since / until sinc… by <a href=""https://github.com/ArchiMoebius""><code>@​ArchiMoebius</code></a> in <a href=""https://github-redirect.dependabot.com/docker/docker-py/pull/3031"">docker/docker-py#3031</a></li>; <li>Change prune test to use anonymous volumes by <a href=""https://github.com/cpuguy83""><code>@​cpuguy83</code></a> in <a href=""https://github-redirect.dependabot.com/docker/docker-py/pull/3051"">docker/docker-py#3051</a></li>; <li>socket: handle npipe close by <a href=""https://github.com/nicks""><code>@​nicks</code></a> in <a href=""https://github-redirect.dependabot.com/docker/docker-py/pull/3056"">docker/docker-py#3056</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/ArchiMoebius""><code>@​ArchiMoebius</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/docker/docker-py/pull/3031"">docker/do",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12475:1045,depend,dependabot,1045,https://hail.is,https://github.com/hail-is/hail/pull/12475,1,['depend'],['dependabot']
Integrability,") from 7.3.1 to 7.3.4.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/jupyter/jupyter_client/releases"">jupyter-client's releases</a>.</em></p>; <blockquote>; <h2>v7.3.4</h2>; <h2>7.3.4</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v7.3.3...ca4cb2d6a4b95a6925de85a47b323d2235032c74"">Full Changelog</a>)</p>; <h3>Bugs fixed</h3>; <ul>; <li>Revert latest changes to <code>ThreadedZMQSocketChannel</code> because they break Qtconsole <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/803"">#803</a> (<a href=""https://github.com/ccordoba12""><code>@​ccordoba12</code></a>)</li>; </ul>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Fix sphinx 5.0 support <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/804"">#804</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; <li>[pre-commit.ci] pre-commit autoupdate <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/799"">#799</a> (<a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_client/graphs/contributors?from=2022-06-07&amp;to=2022-06-08&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Ablink1073+updated%3A2022-06-07..2022-06-08&amp;type=Issues""><code>@​blink1073</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Accordoba12+updated%3A2022-06-07..2022-06-08&amp;type=Issues""><code>@​ccordoba12</code></a> | <a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Apre-commit-ci+updated%3A2022-06-07..2022-06-08&amp;type=Issues""><code>@​pre-commit-ci</code></a></p>; <h2>v7.3.3</h2>; <h2>7.3.3</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v7.3.2...37ca37d865db",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12110:1059,depend,dependabot,1059,https://hail.is,https://github.com/hail-is/hail/pull/12110,1,['depend'],['dependabot']
Integrability,"). A Certificate Authority (like; letsencypt or VeriSign) digitally signs the certificate of a user that has; proven they own the domain name mentioned in the certificate (see above; discussion of `CN` and `subjectAltName`). Web browsers have a file of the ""root""; certificates of the public Certificate Authorities. They establish a ""chain of; trust"" from a root certificate to the server's certificate. Our system is simpler. We have no root certificate. Each principal has a; certificate which is given to all the principals to which it might; communicate. ### Encryption. TLS has many encryption schemes. I will focus on encryption using a *symmetric*; key because asymmetric schemes do not enable *forward secrecy* [2]. Under; forward secret schemes, the two parties share a private key unknown to all; adversaries. TLS 1.3 makes forward secrecy mandatory. I intend to eventually; require all our services to refuse to speak anything other than TLS 1.3. The shared private key is used to encrypt and decrypt messages sent over a; socket. This poses a problem: how do two parties who have never met each other; agree on a private key without revealing the key to the public? This is a; classic cryptography problem called [key; exchange](https://en.wikipedia.org/wiki/Key_exchange). The classic solution to; this problem is [Diffie-Hellman key; exchange](https://en.wikipedia.org/wiki/Diffie–Hellman_key_exchange). The; Wikipedia article has ""General overview"" which is quite clear. In addition to a key, the parties must agree on a cipher. There are many old,; insecure ciphers available. In the future I intend all our servers to refuse to; use insecure ciphers. Mozilla; [has a list of secure cipher suites](https://wiki.mozilla.org/Security/Server_Side_TLS#Recommended_configurations). ## New Hail Concepts. Every principal in our system has a secret: `ssl-config-NAME`. These secrets are; automatically created for a particular namespace by `tls/create_certs.py`. Who; trusts who (i.e. who i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:5463,message,messages,5463,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['message'],['messages']
Integrability,"). File /usr/local/lib/python3.11/dist-packages/hail/table.py:2180, in Table._Show._ascii_str(self); 2177 return s[: truncate - 3] + ""...""; 2178 return s; -> 2180 rows, has_more, dtype = self.data(); 2181 fields = list(dtype); 2182 trunc_fields = [trunc(f) for f in fields]. File /usr/local/lib/python3.11/dist-packages/hail/table.py:2164, in Table._Show.data(self); 2162 row_dtype = t.row.dtype; 2163 t = t.select(**{k: hl._showstr(v) for (k, v) in t.row.items()}); -> 2164 rows, has_more = t._take_n(self.n); 2165 self._data = (rows, has_more, row_dtype); 2166 return self._data. File /usr/local/lib/python3.11/dist-packages/hail/table.py:2310, in Table._take_n(self, n); 2308 has_more = False; 2309 else:; -> 2310 rows = self.take(n + 1); 2311 has_more = len(rows) > n; 2312 rows = rows[:n]. File <decorator-gen-1250>:2, in take(self, n, _localize). File /usr/local/lib/python3.11/dist-packages/hail/typecheck/check.py:585, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 582 @decorator; 583 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 584 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 585 return __original_func(*args_, **kwargs_). File /usr/local/lib/python3.11/dist-packages/hail/table.py:3027, in Table.take(self, n, _localize); 2993 @typecheck_method(n=int, _localize=bool); 2994 def take(self, n, _localize=True):; 2995 """"""Collect the first `n` rows of the table into a local list.; 2996 ; 2997 Examples; (...); 3024 List of row structs.; 3025 """"""; -> 3027 return self.head(n).collect(_localize). File <decorator-gen-1244>:2, in collect(self, _localize, _timed). File /usr/local/lib/python3.11/dist-packages/hail/typecheck/check.py:585, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 582 @decorator; 583 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 584 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 585 retu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14529:3206,wrap,wrapper,3206,https://hail.is,https://github.com/hail-is/hail/issues/14529,2,['wrap'],['wrapper']
Integrability,); 	at java.io.FilterInputStream.read(FilterInputStream.java:133); 	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3456); 	at com.google.api.client.http.javanet.NetHttpResponse$SizeValidatingInputStream.read(NetHttpResponse.java:164); 	at java.nio.channels.Channels$ReadableByteChannelImpl.read(Channels.java:385); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$ScatteringByteChannelFacade.read(StorageByteChannels.java:226); 	at is.hail.relocated.com.google.cloud.storage.ApiaryUnbufferedReadableByteChannel.read(ApiaryUnbufferedReadableByteChannel.java:104); 	at is.hail.relocated.com.google.cloud.storage.UnbufferedReadableByteChannelSession$UnbufferedReadableByteChannel.read(UnbufferedReadableByteChannelSession.java:31); 	at is.hail.relocated.com.google.cloud.storage.DefaultBufferedReadableByteChannel.read(DefaultBufferedReadableByteChannel.java:81); 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$SynchronizedBufferedReadableByteChannel.read(StorageByteChannels.java:84); 	at is.hail.relocated.com.google.cloud.storage.BaseStorageReadChannel.read(BaseStorageReadChannel.java:91); 	at is.hail.io.fs.GoogleStorageFS$$anon$1.readHandlingRequesterPays(GoogleStorageFS.scala:201); 	at is.hail.io.fs.GoogleStorageFS$$anon$1.fill(GoogleStorageFS.scala:238); 	at is.hail.io.fs.FSSeekableInputStream.read(FS.scala:164); 	at java.io.DataInputStream.read(DataInputStream.java:149); 	at is.hail.utils.richUtils.RichInputStream$.readRepeatedly$extension0(RichInputStream.scala:21); 	at is.hail.utils.richUtils.RichInputStream$.readFully$extension1(RichInputStream.scala:12); 	at is.hail.io.StreamBlockInputBuffer.readBlock(InputBuffers.scala:550); 	at is.hail.io.LZ4InputBlockBuffer.readBlock(InputBuffers.scala:584); 	at is.hail.io.BlockingInputBuffer.readBlock(InputBuffers.scala:382); 	at is.hail.io.BlockingInputBuffer.readBytes(InputBuffers.scala:446); 	at is.hail.io.LEB128InputBuffer.readBytes(InputBuffers.scala:,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12982:4578,Synchroniz,SynchronizedBufferedReadableByteChannel,4578,https://hail.is,https://github.com/hail-is/hail/issues/12982,2,['Synchroniz'],['SynchronizedBufferedReadableByteChannel']
Integrability,); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:344); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745); Caused by: is.hail.utils.HailException: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.io.LoadMatrixParser.parseLine(LoadMatrix.scala:33); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:383); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:377); 	at is.hail.utils.WithContext.wrap(Context.scala:41); 	... 30 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1575); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1563); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1562); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1562); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:803); 	at scala.Option.foreach(Option.scala:257); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:803); 	at org.apache.spark.scheduler.D,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:5899,wrap,wrap,5899,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['wrap'],['wrap']
Integrability,"); 115 def deco(*a, **kw):; 116 try:; --> 117 return f(*a, **kw); 118 except py4j.protocol.Py4JJavaError as e:; 119 converted = convert_exception(e.java_exception). /databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 324 value = OUTPUT_CONVERTER[type](answer[2:], gateway_client); 325 if answer[1] == REFERENCE_TYPE:; --> 326 raise Py4JJavaError(; 327 ""An error occurred while calling {0}{1}{2}.\n"".; 328 format(target_id, ""."", name), value). Py4JJavaError: An error occurred while calling o504.pyPersistTable.; : is.hail.utils.HailException: 1 samples and 12 covariates (including x) implies -11 degrees of freedom.; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:11); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:11); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.methods.LinearRegressionRowsSingle.execute(LinearRegression.scala:51); 	at is.hail.expr.ir.functions.WrappedMatrixToTableFunction.execute(RelationalFunctions.scala:51); 	at is.hail.expr.ir.TableToTableApply.execute(TableIR.scala:2936); 	at is.hail.expr.ir.TableIR.analyzeAndExecute(TableIR.scala:57); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:27); 	at is.hail.backend.spark.SparkBackend.$anonfun$pyPersistTable$2(SparkBackend.scala:502); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:47); 	at is.hail.utils.package$.using(package.scala:638); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:47); 	at is.hail.utils.package$.using(package.scala:638); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:46); 	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:275); 	at is.hail.backend.spark.SparkBackend.$anonfun$pyPersistTable$1(SparkBackend.scala:501); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); 	at is.hail.utils.ExecutionTi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11413:4062,Wrap,WrappedMatrixToTableFunction,4062,https://hail.is,https://github.com/hail-is/hail/issues/11413,1,['Wrap'],['WrappedMatrixToTableFunction']
Integrability,"); File ""/tmp/c38a09976d3c40abbc33f88f4fd39639/pyscripts_Zf07i2.zip/gnomad_hail/utils/slack.py"", line 112, in try_slack; File ""/tmp/c38a09976d3c40abbc33f88f4fd39639/pyscripts_Zf07i2.zip/gnomad_hail/utils/slack.py"", line 95, in try_slack; File ""/tmp/c38a09976d3c40abbc33f88f4fd39639/constraint.py"", line 36, in main; recalculate_all_possible_summary=True, remove_common_downsampled=False, remove_common_ordinary=True); File ""/tmp/c38a09976d3c40abbc33f88f4fd39639/pyscripts_Zf07i2.zip/constraint_utils/constraint_basics.py"", line 263, in calculate_mu_by_downsampling; File ""/tmp/c38a09976d3c40abbc33f88f4fd39639/pyscripts_Zf07i2.zip/constraint_utils/constraint_basics.py"", line 41, in get_old_mu_data; File ""/tmp/c38a09976d3c40abbc33f88f4fd39639/hail-devel-17a988f2a628.zip/hail/table.py"", line 772, in transmute; File ""<decorator-gen-648>"", line 2, in _select; File ""/tmp/c38a09976d3c40abbc33f88f4fd39639/hail-devel-17a988f2a628.zip/hail/typecheck/check.py"", line 546, in wrapper; File ""/tmp/c38a09976d3c40abbc33f88f4fd39639/hail-devel-17a988f2a628.zip/hail/table.py"", line 438, in _select; File ""/tmp/c38a09976d3c40abbc33f88f4fd39639/hail-devel-17a988f2a628.zip/hail/table.py"", line 447, in _select_scala; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/tmp/c38a09976d3c40abbc33f88f4fd39639/hail-devel-17a988f2a628.zip/hail/utils/java.py"", line 210, in deco; hail.utils.java.FatalError: NullPointerException: null. Java stack trace:; java.lang.NullPointerException: null; 	at scala.collection.convert.Wrappers$JListWrapper.length(Wrappers.scala:86); 	at scala.collection.SeqLike$class.size(SeqLike.scala:106); 	at scala.collection.AbstractSeq.size(Seq.scala:41); 	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:285); 	at scala.collection.AbstractTraversable.toArray(Traversable.scala:104); 	at is.hail.utils.richUtils.RichIterable.toFastIndexedSeq(RichIterable.scala:83); 	at is.hail.table.Table.select(Table.scala:436",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4314#issuecomment-420405267:1158,wrap,wrapper,1158,https://hail.is,https://github.com/hail-is/hail/issues/4314#issuecomment-420405267,1,['wrap'],['wrapper']
Integrability,"); mt_hwe = mt_filtered.group_cols_by(mt_filtered.ancestry).aggregate(hwe = hl.agg.hardy_weinberg_test(mt_filtered.GT)); hwe_bucket = os.path.join(bucket, ""hwe_vals.tsv""); mt_hwe.hwe.p_value.export(hwe_bucket). vcf_bucket = os.path.join(bucket, ""variants.vcf""); variant_call_rate_bucket = os.path.join(bucket, ""variant_call_rate.tsv""); mt_filtered.variant_qc.call_rate.export(variant_call_rate_bucket); hl.export_vcf(mt_filtered, vcf_bucket). ```. ### Version. 0.2.107-2387bb00ceee. ### Relevant log output. ```shell; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); /tmp/ipykernel_109/3358609846.py in <module>; ----> 1 mt_hwe.hwe.p_value.export(hwe_bucket). <decorator-gen-637> in export(self, path, delimiter, missing, header). /opt/conda/lib/python3.7/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 575 def wrapper(__original_func, *args, **kwargs):; 576 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 577 return __original_func(*args_, **kwargs_); 578 ; 579 return wrapper. /opt/conda/lib/python3.7/site-packages/hail/expr/expressions/base_expression.py in export(self, path, delimiter, missing, header); 1068 **{output_col_name: hl.delimit(column_names, delimiter)}); 1069 file_contents = header_table.union(file_contents); -> 1070 file_contents.export(path, delimiter=delimiter, header=False); 1071 ; 1072 @typecheck_method(n=int, _localize=bool). <decorator-gen-1193> in export(self, output, types_file, header, parallel, delimiter). /opt/conda/lib/python3.7/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 575 def wrapper(__original_func, *args, **kwargs):; 576 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 577 return __original_func(*args_, **kwargs_); 578 ; 579 return wrapper. /opt/conda/lib/python3.7/site-packages/hail/table.py in export(self, ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287:2206,wrap,wrapper,2206,https://hail.is,https://github.com/hail-is/hail/issues/13287,3,['wrap'],['wrapper']
Integrability,")</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/af0560812d3dc2043565de1108ac41b65caac7d0""><code>af05608</code></a> Release 2.11 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/673"">#673</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/16aa24292125aa59fed1ab4292c6576d800295f1""><code>16aa242</code></a> Bump pytest-mock from 3.6.1 to 3.7.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/674"">#674</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/72d199d40689cb0a83f2b911044ab0ed9f6cc08e""><code>72d199d</code></a> Fix error in example</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/44e60f51bdb1ecfc22fa8bc87e8d025f2f17cd90""><code>44e60f5</code></a> Minor changes to typing. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/672"">#672</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/bf9a5f0b87470dd145cff326b0b05f898f775d94""><code>bf9a5f0</code></a> Fix session resetting before expiry. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/671"">#671</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/36b8a0a5ed2caaaba9d5d3ece8aaf03ca45b6c34""><code>36b8a0a</code></a> Allow passing Fernet to Encrypted Cookie Storage (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/448"">#448</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/984decc496fe92e053c14949c8d3a60bacd62426""><code>984decc</code></a> Test on Python up to 3.10 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/634"">#634</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/936f76351450066903002d60286110007310a44f""><code>936f763</code><",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11577:3557,depend,dependabot,3557,https://hail.is,https://github.com/hail-is/hail/pull/11577,1,['depend'],['dependabot']
Integrability,")</li>; </ul>; <h2>3.46.5</h2>; <ul>; <li>Add TypeScript interfaces for typing actions (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/6538"">#6538</a>)</li>; <li>Do not generate <code>unused-export-let</code> warning inside <code>&lt;script context=&quot;module&quot;&gt;</code> blocks (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7055"">#7055</a>)</li>; <li>Do not collapse whitespace-only CSS vars (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7152"">#7152</a>)</li>; <li>Add <code>aria-description</code> to the list of allowed ARIA attributes (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7301"">#7301</a>)</li>; <li>Fix attribute escaping during SSR (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7327"">#7327</a>)</li>; <li>Prevent <code>.innerHTML</code> optimization from being used when <code>style:</code> directive is present (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7386"">#7386</a>)</li>; </ul>; <h2>3.46.4</h2>; <ul>; <li>Avoid <code>maximum call stack size exceeded</code> errors on large components (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/4694"">#4694</a>)</li>; <li>Preserve leading space with <code>preserveWhitespace: true</code> (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/4731"">#4731</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/sveltejs/svelte/commit/52153dbce0237f0c36e4ff36377398d7f95276ef""><code>52153db</code></a> -&gt; v3.49.0</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/3798808e7484b7eeee6acb2860c45bb2e59d84bd""><code>3798808</code></a> update changelog</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/0fa0a38d5168a1767843fdb0a43c00aa30b8670f""><code>0fa0a38</code></a> [fix] export CompileOptions (<a h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12032:5736,depend,dependabot,5736,https://hail.is,https://github.com/hail-is/hail/pull/12032,3,['depend'],['dependabot']
Integrability,")</li>; </ul>; <h2>Fixes</h2>; <ul>; <li>Updated Google analytics integration (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1129"">#1129</a>)</li>; <li>Add classifier separation on Sphinx 2+ HTML4 writer (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1192"">#1192</a>)</li>; <li>Added missing space char in footer (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1188"">#1188</a>)</li>; <li>Fix navigation right padding on level2+ elements (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1068"">#1068</a>)</li>; <li>Fix navigation expansion button sizes (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1067"">#1067</a>)</li>; <li>Wrap inline literals (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1050"">#1050</a>)</li>; <li>Fix aria labels (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1056"">#1056</a>)</li>; <li>Don't toggle navigation terminal nodes (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1049"">#1049</a>)</li>; <li>Fix <code>&lt;pre&gt;</code> overflow (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1220"">#1220</a>)</li>; <li>Fix literal/ref style inside <code>&lt;dl&gt;</code> (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1088"">#1088</a>)</li>; </ul>; <p>Other Changes</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/readthedocs/sphinx_rtd_theme/commit/c9b1bde560d8ee31400e4e4f92f2e8d7a42265ce""><code>c9b1bde</code></a> Replace sphinx reST with native reST</li>; <li><a href=""https://github.com/readthedocs/sphinx_rtd_theme/commit/15e4a9029194083d34e0dffa9b3f297a7692164e""><code>15e4a90</code></a> U",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11464:3947,depend,dependabot,3947,https://hail.is,https://github.com/hail-is/hail/pull/11464,2,['depend'],['dependabot']
Integrability,")</li>; </ul>; <h3>Configuration</h3>; <ul>; <li>Do not format <code>__pypackages__</code> directories by default (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2836"">#2836</a>)</li>; <li>Add support for specifying stable version with <code>--required-version</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2832"">#2832</a>).</li>; <li>Avoid crashing when the user has no homedir (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2814"">#2814</a>)</li>; <li>Avoid crashing when md5 is not available (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2905"">#2905</a>)</li>; <li>Fix handling of directory junctions on Windows (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2904"">#2904</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Update pylint config documentation (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2931"">#2931</a>)</li>; </ul>; <h3>Integrations</h3>; <ul>; <li>Move test to disable plugin in Vim/Neovim, which speeds up loading (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2896"">#2896</a>)</li>; </ul>; <h3>Output</h3>; <ul>; <li>In verbose, mode, log when <em>Black</em> is using user-level config (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2861"">#2861</a>)</li>; </ul>; <h3>Packaging</h3>; <ul>; <li>Fix Black to work with Click 8.1.0 (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2966"">#2966</a>)</li>; <li>On Python 3.11 and newer, use the standard library's <code>tomllib</code> instead of <code>tomli</code>; (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2903"">#2903</a>)</li>; <li><code>black-primer</code>, the deprecated internal devtool, has been removed and copied to a; <a href=""https://github.com/cooperlees/black-primer"">separate repository</a> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2924"">#2924</a>)</li>; </ul>; <h3>Parser</h3>; <ul>; <li>Blac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11696:1882,Integrat,Integrations,1882,https://hail.is,https://github.com/hail-is/hail/pull/11696,2,['Integrat'],['Integrations']
Integrability,")</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/69d2f672399502021a8f8918a7d5962c3005f687""><code>69d2f67</code></a> [Automation] Generate Fluent Lite from appcomplianceautomation#package-2022-1...</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/20a07b197d8afa5f0f5f65b9e448c938ffad354e""><code>20a07b1</code></a> November 2022 release (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32153"">#32153</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/17da0b33c07ee121d68a957879e314fb2bceba5e""><code>17da0b3</code></a> mgmt, update codegen for dependency conflict (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32150"">#32150</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-java/compare/azure-storage-blob_12.13.0...azure-storage-blob_12.20.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.azure:azure-storage-blob&package-manager=gradle&previous-version=12.13.0&new-version=12.20.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12477:5709,Depend,Dependabot,5709,https://hail.is,https://github.com/hail-is/hail/pull/12477,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,")</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/437ac47fe332106a07a2d5335bb89619f1bc23f7""><code>437ac47</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7995"">#7995</a>/43a5bc50 backport][3.9] Fix examples of <code>fallback_charset_resolver</code>...</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/034e5e34ee11c6138c773d85123490e691e1b708""><code>034e5e3</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8042"">#8042</a>/4b91b530 backport][3.9] Tightening the runtime type check for ssl (...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.9.1...v3.9.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.9.1&new-version=3.9.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14212:7044,depend,dependabot-security-updates,7044,https://hail.is,https://github.com/hail-is/hail/pull/14212,6,['depend'],['dependabot-security-updates']
Integrability,")</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/45dc983a4af8e7feb937263ce611bd34eda37e03""><code>45dc983</code></a> feat: update GrpcBlobReadChannel to allow seek/limit after read (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1834"">#1834</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/b8f43169a504080c55eadc3428d0d7966efdc3d4""><code>b8f4316</code></a> build(deps): update dependency org.apache.maven.plugins:maven-dependency-plug...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/e532a590fd351bb2020b571d21662fbee629038e""><code>e532a59</code></a> build(deps): update dependency org.apache.maven.plugins:maven-surefire-plugin...</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/java-storage/compare/v1.106.0...v2.17.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.cloud:google-cloud-storage&package-manager=gradle&previous-version=1.106.0&new-version=2.17.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requeste",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12598:16286,depend,dependency-name,16286,https://hail.is,https://github.com/hail-is/hail/pull/12598,1,['depend'],['dependency-name']
Integrability,")</li>; <li>Additional commits viewable in <a href=""https://github.com/Textualize/rich/compare/v12.6.0...v13.7.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=rich&package-manager=pip&previous-version=12.6.0&new-version=13.7.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14376:7182,Depend,Dependabot,7182,https://hail.is,https://github.com/hail-is/hail/pull/14376,18,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,")</li>; <li>Additional commits viewable in <a href=""https://github.com/hagenw/sphinxcontrib-katex/compare/0.5.1...v0.8.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinxcontrib-katex&package-manager=pip&previous-version=0.5.1&new-version=0.8.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11458:6605,Depend,Dependabot,6605,https://hail.is,https://github.com/hail-is/hail/pull/11458,34,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,")</li>; <li>Additional commits viewable in <a href=""https://github.com/hagenw/sphinxcontrib-katex/compare/0.5.1...v0.9.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinxcontrib-katex&package-manager=pip&previous-version=0.5.1&new-version=0.9.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12241:7042,Depend,Dependabot,7042,https://hail.is,https://github.com/hail-is/hail/pull/12241,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,")</li>; <li>Additional commits viewable in <a href=""https://github.com/samtools/htsjdk/compare/2.24.1...3.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.github.samtools:htsjdk&package-manager=gradle&previous-version=2.24.1&new-version=3.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12229:9602,Depend,Dependabot,9602,https://hail.is,https://github.com/hail-is/hail/pull/12229,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,")</li>; <li>Additional commits viewable in <a href=""https://github.com/samtools/htsjdk/compare/2.24.1...3.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.github.samtools:htsjdk&package-manager=gradle&previous-version=2.24.1&new-version=3.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12310:9427,Depend,Dependabot,9427,https://hail.is,https://github.com/hail-is/hail/pull/12310,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,")</li>; <li>adds support for audience in client_options. (<a href=""https://github.com/googleapis/python-api-core/commit/c97c4980125a86f384cdf12720df7bb1a2adf9d2"">c97c498</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/python-api-core/compare/v2.7.2...v2.7.3"">2.7.3</a> (2022-04-29)</h2>; <h3>Bug Fixes</h3>; <ul>; <li>Avoid AttributeError if grpcio-status is not installed (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/370"">#370</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/022add16266f9c07f0f88eea13472cc2e0bfc991"">022add1</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/python-api-core/compare/v2.7.1...v2.7.2"">2.7.2</a> (2022-04-13)</h2>; <h3>Bug Fixes</h3>; <ul>; <li>allow grpc without grpcio-status (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/355"">#355</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/112049e79f5a5b0a989d85d438a1bd29485f46f7"">112049e</a>)</li>; <li>remove dependency on pkg_resources (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/361"">#361</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/523dbd0b10d37ffcf83fa751f0bad313f162abf1"">523dbd0</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/python-api-core/compare/v2.7.0...v2.7.1"">2.7.1</a> (2022-03-09)</h2>; <h3>Bug Fixes</h3>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/googleapis/python-api-core/commit/5b5e77563229687c901d77b5fdecc18168b535e6""><code>5b5e775</code></a> chore(main): release 2.8.2 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/396"">#396</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-core/commit/8f73d2ee2d3af2201f877aa7e2f7361147759dc7""><code>8f73d2e</code></a> fix(deps): allow protobuf &lt; 5.0.0 (<a href=""https://github-redi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11970:7527,depend,dependency,7527,https://hail.is,https://github.com/hail-is/hail/pull/11970,1,['depend'],['dependency']
Integrability,"* **#14451** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14451?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @patrick-schultz and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14451#issuecomment-2045755749:654,depend,dependencies,654,https://hail.is,https://github.com/hail-is/hail/pull/14451#issuecomment-2045755749,1,['depend'],['dependencies']
Integrability,"* **#14455** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14455?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @patrick-schultz and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14455#issuecomment-2046054784:654,depend,dependencies,654,https://hail.is,https://github.com/hail-is/hail/pull/14455#issuecomment-2046054784,1,['depend'],['dependencies']
Integrability,"* **#14496** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14496?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 2 dependent PRs ([#14509](https://github.com/hail-is/hail/pull/14509) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14509?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>, [#14514](https://github.com/hail-is/hail/pull/14514) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14514?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>) 👈; * **#14495** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14495?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14475** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14475?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @patrick-schultz and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14496#issuecomment-2070873404:238,depend,dependent,238,https://hail.is,https://github.com/hail-is/hail/pull/14496#issuecomment-2070873404,2,['depend'],"['dependencies', 'dependent']"
Integrability,"* **#14496** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14496?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 2 dependent PRs ([#14509](https://github.com/hail-is/hail/pull/14509) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14509?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>, [#14514](https://github.com/hail-is/hail/pull/14514) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14514?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14495** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14495?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * **#14475** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14475?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @patrick-schultz and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14495#issuecomment-2070873392:238,depend,dependent,238,https://hail.is,https://github.com/hail-is/hail/pull/14495#issuecomment-2070873392,2,['depend'],"['dependencies', 'dependent']"
Integrability,"* **#14496** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14496?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 2 dependent PRs ([#14509](https://github.com/hail-is/hail/pull/14509) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14509?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>, [#14514](https://github.com/hail-is/hail/pull/14514) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14514?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14495** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14495?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14475** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14475?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @patrick-schultz and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14475#issuecomment-2059793128:238,depend,dependent,238,https://hail.is,https://github.com/hail-is/hail/pull/14475#issuecomment-2059793128,2,['depend'],"['dependencies', 'dependent']"
Integrability,"* **#14514** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14514?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 2 dependent PRs ([#14509](https://github.com/hail-is/hail/pull/14509) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14509?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>, [#14554](https://github.com/hail-is/hail/pull/14554) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14554?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>) 👈; * **#14517** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14517?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @patrick-schultz and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14514#issuecomment-2086536884:238,depend,dependent,238,https://hail.is,https://github.com/hail-is/hail/pull/14514#issuecomment-2086536884,2,['depend'],"['dependencies', 'dependent']"
Integrability,"* **#14514** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14514?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 2 dependent PRs ([#14509](https://github.com/hail-is/hail/pull/14509) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14509?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>, [#14554](https://github.com/hail-is/hail/pull/14554) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14554?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14517** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14517?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @patrick-schultz and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14517#issuecomment-2091504683:238,depend,dependent,238,https://hail.is,https://github.com/hail-is/hail/pull/14517#issuecomment-2091504683,2,['depend'],"['dependencies', 'dependent']"
Integrability,"* **#14533** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14533?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14509** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14509?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * **#14514** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14514?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 1 other dependent PR ([#14554](https://github.com/hail-is/hail/pull/14554) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14554?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14517** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14517?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @patrick-schultz and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14509#issuecomment-2080036916:718,depend,dependent,718,https://hail.is,https://github.com/hail-is/hail/pull/14509#issuecomment-2080036916,2,['depend'],"['dependencies', 'dependent']"
Integrability,"* **#14547** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14547?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @patrick-schultz and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14547#issuecomment-2105153451:654,depend,dependencies,654,https://hail.is,https://github.com/hail-is/hail/pull/14547#issuecomment-2105153451,1,['depend'],['dependencies']
Integrability,"* **#14551** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14551?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * **#14550** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14550?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @patrick-schultz and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14551#issuecomment-2108604092:890,depend,dependencies,890,https://hail.is,https://github.com/hail-is/hail/pull/14551#issuecomment-2108604092,1,['depend'],['dependencies']
Integrability,"* **#14551** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14551?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14550** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14550?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @patrick-schultz and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14550#issuecomment-2108442266:890,depend,dependencies,890,https://hail.is,https://github.com/hail-is/hail/pull/14550#issuecomment-2108442266,1,['depend'],['dependencies']
Integrability,"* **#14553** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14553?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @patrick-schultz and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14553#issuecomment-2110596841:654,depend,dependencies,654,https://hail.is,https://github.com/hail-is/hail/pull/14553#issuecomment-2110596841,1,['depend'],['dependencies']
Integrability,"* **#14554** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14554?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * **#14514** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14514?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 1 other dependent PR ([#14509](https://github.com/hail-is/hail/pull/14509) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14509?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14517** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14517?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @patrick-schultz and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14554#issuecomment-2110766283:482,depend,dependent,482,https://hail.is,https://github.com/hail-is/hail/pull/14554#issuecomment-2110766283,2,['depend'],"['dependencies', 'dependent']"
Integrability,"* **#14578** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14578?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @patrick-schultz and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14578#issuecomment-2163445582:654,depend,dependencies,654,https://hail.is,https://github.com/hail-is/hail/pull/14578#issuecomment-2163445582,1,['depend'],['dependencies']
Integrability,"* **#14582** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14582?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @patrick-schultz and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14582#issuecomment-2166604877:654,depend,dependencies,654,https://hail.is,https://github.com/hail-is/hail/pull/14582#issuecomment-2166604877,1,['depend'],['dependencies']
Integrability,"* **#14638** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14638?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @patrick-schultz and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14638#issuecomment-2252777195:654,depend,dependencies,654,https://hail.is,https://github.com/hail-is/hail/pull/14638#issuecomment-2252777195,1,['depend'],['dependencies']
Integrability,"* **#14663** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14663?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * **#14662** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14662?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @patrick-schultz and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14662#issuecomment-2302524285:890,depend,dependencies,890,https://hail.is,https://github.com/hail-is/hail/pull/14662#issuecomment-2302524285,1,['depend'],['dependencies']
Integrability,"* **#14673** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14673?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @patrick-schultz and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14673#issuecomment-2334696866:654,depend,dependencies,654,https://hail.is,https://github.com/hail-is/hail/pull/14673#issuecomment-2334696866,1,['depend'],['dependencies']
Integrability,"* **#14684** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14684?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 2 dependent PRs ([#14686](https://github.com/hail-is/hail/pull/14686) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14686?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>, [#14747](https://github.com/hail-is/hail/pull/14747) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14747?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>) 👈; * **#14683** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14683?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @ehigham and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14684#issuecomment-2349934247:238,depend,dependent,238,https://hail.is,https://github.com/hail-is/hail/pull/14684#issuecomment-2349934247,2,['depend'],"['dependencies', 'dependent']"
Integrability,"* **#14684** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14684?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>: 2 dependent PRs ([#14686](https://github.com/hail-is/hail/pull/14686) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14686?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>, [#14747](https://github.com/hail-is/hail/pull/14747) <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14747?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a>); * **#14683** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14683?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @ehigham and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14683#issuecomment-2349934211:238,depend,dependent,238,https://hail.is,https://github.com/hail-is/hail/pull/14683#issuecomment-2349934211,2,['depend'],"['dependencies', 'dependent']"
Integrability,"* **#14745** <a href=""https://app.graphite.dev/github/pr/hail-is/hail/14745?utm_source=stack-comment-icon"" target=""_blank""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""10px"" height=""10px""/></a> 👈; * `main`. This stack of pull requests is managed by Graphite. <a href=""https://stacking.dev/?utm_source=stack-comment"">Learn more about stacking.</a>; <h2></h2>. Join @patrick-schultz and the rest of your teammates on <a href=""https://graphite.dev?utm-source=stack-comment""><img src=""https://static.graphite.dev/graphite-32x32-black.png"" alt=""Graphite"" width=""11px"" height=""11px""/> <b>Graphite</b></a>; <!-- Current dependencies on/for this PR: -->",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14745#issuecomment-2435880729:654,depend,dependencies,654,https://hail.is,https://github.com/hail-is/hail/pull/14745#issuecomment-2435880729,1,['depend'],['dependencies']
Integrability,* CamelCased minRep (was inconsistent globally and more importantly camelcased in python interface!); * Added `isStar` to `AltAllele` and made sure that `*` alleles aren't counted as `SNP`s anymore; * Modified minRep to ignore `*` alleles and correctly minrep in their presence; * FilterAlleles now filters sites where only a `*` allele is left by default (keepStar option allows overriding this behavior),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1644:89,interface,interface,89,https://hail.is,https://github.com/hail-is/hail/pull/1644,1,['interface'],['interface']
Integrability,"* Reworked logging to route log output through Python stderr. - Removed SLF4J, everything goes directly through log4j now.; - Removed the explicitly System.err.write calls inside info / warn.; - Separated console logging and log file logging; - Stripped the huge stack traces out of python errors; they are logged; to the screen / cell through log4j. * Fix info for truncatables. * Address comments",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2109:22,rout,route,22,https://hail.is,https://github.com/hail-is/hail/pull/2109,1,['rout'],['route']
Integrability,* `approx_quantiles` aggregator wrapping `approx_cdf`; * cdf and pdf plots; * Allow the histogram plot to take the result of the `approx_cdf` aggregator; * Add interactivity to the histogram and pdf plots,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5732:32,wrap,wrapping,32,https://hail.is,https://github.com/hail-is/hail/pull/5732,1,['wrap'],['wrapping']
Integrability,"* `mill reformat` - runs scalafmt on all sources in the root module (currently that's all scala sources, but hopefully not for long). `mill __.reformat` runs scalaformat on all sources in all modules. `mill __.checkFormat` only checks for rule failures (we run this in ci); * `mill fix` - runs scalafix on all sources in the root module (currently that's all scala sources, but hopefully not for long). `mill __.fix` runs scalafix on all sources in all modules. `mill __.fix --check` only checks for rule failures (we run this in ci). You can pass any options to scalafix, e.g. `mill fix --help`.; * `mill inspect` - see the docstring and dependencies for any target, e.g. `mill inspect compile`; * `mill ivyDepsTree` - show the tree of external dependencies of the root module, highlighting potential incompatibilities in transitive dependencies. `mill ivyDepsTree --withCompile --withRuntime` includes compile-only and runtime-only dependencies. Use `--whatDependsOn` to see an inverted tree showing how a transitive dependency is getting pulled in, e.g. `mill ivyDepsTree --withCompile --withRuntime --whatDependsOn org.slf4j:slf4j-api`; * `mill mill.scalalib.Dependency/showUpdates` - show outdated dependencies (we have a lot!). See [here](https://mill-build.com/mill/Intro_to_Mill.html) and [here](https://mill-build.com/mill/Builtin_Commands.html) for more details. ## IntelliJ setup. To import from scratch:; * delete any `.idea` directories in the hail root, or `hail/` subdirectory (you could try skipping this, but you're on your own); * in the `hail/` subdirectory, you can also delete `.classpath`, `.gradle`, `.project`, `.settings/`, `build/` (we still use this for a few things, but most of it is dead gradle output, and it's safe to delete it all and start clean), `build.gradle`, `gradle/`, `gradlew`, `gradlew.bat`, `pgradle`, `settings.gradle`; * run `mill mill.bsp.BSP/install` to generate the `.bsp` config directory (bsp is the Build Server Protocol); * In IntelliJ, go to File-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14147:2874,depend,dependency,2874,https://hail.is,https://github.com/hail-is/hail/pull/14147,1,['depend'],['dependency']
Integrability,"* add simulated BGEN file based on distributions in real data; * add import, info score, filter benchmarks; * fix bad error message in `export_bgen`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6976:124,message,message,124,https://hail.is,https://github.com/hail-is/hail/pull/6976,1,['message'],['message']
Integrability,"* construct doesn't take structs, takes IndexedSeq[Value[Long]]; * Implement the nested loops in one place; * Delete some methods from type interface, insert PCanonical casts",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9960:140,interface,interface,140,https://hail.is,https://github.com/hail-is/hail/pull/9960,1,['interface'],['interface']
Integrability,"* fixed finally. * evict Spark BlockMatrix and friends. * remove old test suite. * a bunch more cleanups. * simplify grid partitioner. * fix test. * remove unneeded try-catches. * organization. * add a test suite for HBM. * help closure serializer. * use correct aggregation method, add test. * test+fix bug grid partitioner. * wip zippartitions. * teach tests to tolerate NaNs. * fix test. * kinda works again. * remove unnecessary trys. * handle transposition in map*. * clean up imports. * standardize langauge. * bunch of comments addressed. * improve error message. * fix python. * rename HailBlockMatrix -> BlockMatrix. * a bunch of comments addressed. * more comments addressed. * make test comment not confusing. * fix rebase error. * fixes. * fix. * fix bug in rirm. * gotta get that transpose right. * test fixes. * dan is a dummy. * commits got lost for sure. * realize transpose when writing. * add indexed tests for map2?WithIndex when transposed. * use Gen.denseMatrix. * use Gen.denseMatrix. * final fixes. * toLocalMatrix returns Spark matrix for backwards compatibility. * avoid an array copy. the BDMs produced by BlockMatrix.toLocalMatrix are in a; ""normal form"", i.e. offset 0, column-major stride, non-; transposed. Given this assumption we can quickly produce a; Spark-style local matrix. * dan is a dummy. * collect-in-order. collect doesn't guarantee order. * do not use BDM.data naively. This was the true root casue: an incorrect test. * fix python interface. * in python, java fields are methods. note the addition of parentheses",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2329:562,message,message,562,https://hail.is,https://github.com/hail-is/hail/pull/2329,2,"['interface', 'message']","['interface', 'message']"
Integrability,* works. * use hadoop. * fix inputstream reader and uris. * fix bug. * using existing interfaces. * fix comments,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2122:86,interface,interfaces,86,https://hail.is,https://github.com/hail-is/hail/pull/2122,1,['interface'],['interfaces']
Integrability,* works?. * address PR comments. * optimize imports. * use existing interfaces. * fix imports. * fix syntax error. * remove bad import. * add LDMatrix import. * fix tests for ldmatrix. * fix tests. * clean paths before writing,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2124:68,interface,interfaces,68,https://hail.is,https://github.com/hail-is/hail/pull/2124,1,['interface'],['interfaces']
Integrability,"** Actually used python stdlib package `difflib`. This PR improves error messages for things like:. ```text; In [3]: ds.INFO; AttributeError: MatrixTable instance has no field, method, or property 'INFO'; Did you mean:; Data field: 'info' [row]; ```; ```text; In [4]: ds['INFO']; LookupError: MatrixTable instance has no field 'INFO'; Did you mean:; 'info' [row field]; Hint: use 'describe()' to show the names of all data fields.; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2735:73,message,messages,73,https://hail.is,https://github.com/hail-is/hail/pull/2735,1,['message'],['messages']
Integrability,"**Hail version: 0.2.74**; **Spark version: 3.1.1 (Hadoop 3.2)**. --. Hello, and thanks for putting your time and effort into the development of Hail. I'm trying to create a low-level R interface providing methods for interacting with Hail data structures. So far I've been able to import an example VCF file as a `TableValue`/`RDD` object, but - due to a type mismatch caused by its `locus` field - I'm not able to convert it any further (to a Spark data frame, for example). Reproducible example (but please replace paths):. ```{scala}; val backend = is.hail.backend.spark.SparkBackend(sc, ""Hail"", ""local"", ""local[*]"", false, 1, ""/tmp"", ""/tmp""); val hc = is.hail.HailContext(backend, ""/path/to/hail.log"", true, false, 50, false, 3); val hadoop_conf = sc.hadoopConfiguration; val shconf = new is.hail.utils.SerializableHadoopConfiguration(hadoop_conf); val fs = new is.hail.io.fs.HadoopFS(shconf); val pool = is.hail.annotations.RegionPool(false); val reg = is.hail.annotations.Region(0, pool); val timer = new is.hail.utils.ExecutionTimer(""timer""); val ec = new is.hail.expr.ir.ExecuteContext(""/tmp"", ""/tmp"", backend, fs, reg, timer, null); val text_input = is.hail.utils.TextInputFilterAndReplace(); val reader_params = is.hail.io.vcf.MatrixVCFReaderParameters(Seq(""/path/to/tdt_tiny.vcf""), Set(), ""Float64"", Option(""/path/to/tdt_tiny.vcf""), Some(1), Some(1), Some(1), Option(""GRCh37""), Map(), true, false, false, false, text_input, """"); val reader = is.hail.io.vcf.MatrixVCFReader.apply(ec, reader_params); val ttyp = reader.fullType; val tread = is.hail.expr.ir.TableRead(ttyp, false, reader); val tval = reader.apply(tread, ec); val rdd = tval.rdd; ```. Now, it should be possible to run `tval.toDF()`, but it throws:. > scala.MatchError: locus<GRCh37> (of class is.hail.types.virtual.TLocus); > at is.hail.expr.SparkAnnotationImpex$.exportType(AnnotationImpex.scala:42); > at is.hail.types.virtual.Type.schema(Type.scala:168). That's because `SparkAnnotationImpex.exportType()` doesn't support `",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10882:185,interface,interface,185,https://hail.is,https://github.com/hail-is/hail/issues/10882,1,['interface'],['interface']
Integrability,"**Work in progress**; _worried the merging and rebasing was done poorly due to the message about merge conflicts at the bottom of this PR - would be useful if someone could let me know or walk me through resolving it_. **Additions:**. - adds method for Blanczos SVD, not yet following the exact interface of the current PCA call; - adds test for Blanczos SVD method; - adds multiple jupyter notebooks where this algorithm was implemented; - adds first version of benchmarking script; - update to requirements.txt regarding gcsfs version should probably be moved to separate PR. **Needs:**; - larger benchmarking; - better test; - hail method for Blanczos PCA to use exact interface and return eigenvalues, scores, and optional loadings as if it were the hail PCA method instead of the current non-centered SVD; - fix the norm(A - QQtA) computation - maybe make it blocked; - possibly block the error bound computation; - possibly replace the numpy library calls to SVD and QR decomposition with distributed hail versions, or at least the SVD call at a minimum since it is easier",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9222:83,message,message,83,https://hail.is,https://github.com/hail-is/hail/pull/9222,3,"['interface', 'message']","['interface', 'message']"
Integrability,"**c++ -v**; Using built-in specs.; COLLECT_GCC=c++; COLLECT_LTO_WRAPPER=/opt/local/libexec/gcc/x86_64-apple-darwin15/4.9.3/lto-wrapper; Target: x86_64-apple-darwin15; Configured with: /opt/local/var/macports/build/_opt_mports_dports_lang_gcc49/gcc49/work/gcc-4.9.3/configure --prefix=/opt/local --build=x86_64-apple-darwin15 --enable-languages=c,c++,objc,obj-c++,lto,fortran,java --libdir=/opt/local/lib/gcc49 --includedir=/opt/local/include/gcc49 --infodir=/opt/local/share/info --mandir=/opt/local/share/man --datarootdir=/opt/local/share/gcc-4.9 --with-local-prefix=/opt/local --with-system-zlib --disable-nls --program-suffix=-mp-4.9 --with-gxx-include-dir=/opt/local/include/gcc49/c++/ --with-gmp=/opt/local --with-mpfr=/opt/local --with-mpc=/opt/local --with-isl=/opt/local --disable-isl-version-check --with-cloog=/opt/local --disable-cloog-version-check --enable-stage1-checking --disable-multilib --enable-lto --enable-libstdcxx-time --with-as=/opt/local/bin/as --with-ld=/opt/local/bin/ld --with-ar=/opt/local/bin/ar --with-bugurl=https://trac.macports.org/newticket --with-pkgversion='MacPorts gcc49 4.9.3_0' --with-build-config=bootstrap-debug; Thread model: posix; gcc version 4.9.3 (MacPorts gcc49 4.9.3_0) . **sysctl -a | grep machdep.cpu**; machdep.cpu.tsc_ccc.denominator: 0; machdep.cpu.tsc_ccc.numerator: 0; machdep.cpu.thread_count: 8; machdep.cpu.core_count: 4; machdep.cpu.address_bits.virtual: 48; machdep.cpu.address_bits.physical: 36; machdep.cpu.tlb.shared: 512; machdep.cpu.tlb.data.large: 32; machdep.cpu.tlb.data.small: 64; machdep.cpu.tlb.inst.large: 8; machdep.cpu.tlb.inst.small: 64; machdep.cpu.cache.size: 256; machdep.cpu.cache.L2_associativity: 8; machdep.cpu.cache.linesize: 64; machdep.cpu.arch_perf.fixed_width: 48; machdep.cpu.arch_perf.fixed_number: 3; machdep.cpu.arch_perf.events: 0; machdep.cpu.arch_perf.events_number: 7; machdep.cpu.arch_perf.width: 48; machdep.cpu.arch_perf.number: 4; machdep.cpu.arch_perf.version: 3; machdep.cpu.xsave.extended_state1:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1274#issuecomment-274242543:127,wrap,wrapper,127,https://hail.is,https://github.com/hail-is/hail/issues/1274#issuecomment-274242543,1,['wrap'],['wrapper']
Integrability,*sigh*. ```; E java.lang.RuntimeException: Stream is already closed.; E 	at com.azure.storage.common.StorageOutputStream.checkStreamState(StorageOutputStream.java:79); E 	at com.azure.storage.common.StorageOutputStream.flush(StorageOutputStream.java:89); E 	at is.hail.io.fs.AzureStorageFS$$anon$3.close(AzureStorageFS.scala:291); E 	at java.io.FilterOutputStream.close(FilterOutputStream.java:159); E 	at is.hail.utils.package$.using(package.scala:640); E 	at is.hail.io.fs.FS.writePDOS(FS.scala:428); E 	at is.hail.io.fs.FS.writePDOS$(FS.scala:427); E 	at is.hail.io.fs.RouterFS.writePDOS(RouterFS.scala:3); E 	at is.hail.backend.service.ServiceBackend.$anonfun$parallelizeAndComputeWithIndex$3(ServiceBackend.scala:114); E 	at is.hail.backend.service.ServiceBackend.$anonfun$parallelizeAndComputeWithIndex$3$adapted(ServiceBackend.scala:114); E 	at is.hail.backend.service.ServiceBackend$$anon$2.$anonfun$call$1(ServiceBackend.scala:122); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.services.package$.retryTransientErrors(package.scala:124); E 	at is.hail.backend.service.ServiceBackend$$anon$2.call(ServiceBackend.scala:122); E 	at is.hail.backend.service.ServiceBackend$$anon$2.call(ServiceBackend.scala:119); E 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); E 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); E 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); E 	at java.lang.Thread.run(Thread.java:750); ```. Azure's `StorageOutputStream.close` method is not idempotent in the version that we use. It has been made idempotent in `12.18.0`. I would be surprised if spark let us upgrade to a version that recent,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12968#issuecomment-1532328901:572,Rout,RouterFS,572,https://hail.is,https://github.com/hail-is/hail/pull/12968#issuecomment-1532328901,2,['Rout'],['RouterFS']
Integrability,"+ CI total time speedups</li>; <li>See full diff in <a href=""https://github.com/saghul/pycares/compare/pycares-4.2.2...pycares-4.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pycares&package-manager=pip&previous-version=4.2.2&new-version=4.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12559:4114,Depend,Dependabot,4114,https://hail.is,https://github.com/hail-is/hail/pull/12559,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,", ""first_request_line"": ""POST /api/v1alpha/batches/9/jobs/create HTTP/1.1"", ""response_status"": 200, ""response_size"": 158, ""request_header"": {""Referer"": ""-"", ""User-Agent"": ""Python/3.6 aiohttp/3.5.4""}}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:34,945"", ""filename"": ""web_log.py"", ""funcNameAndLine"": ""log:233"", ""message"": ""10.32.4.199 [11/Jul/2019:14:19:34 +0000] \""PATCH /api/v1alpha/batches/9/close HTTP/1.1\"" 200 158 \""-\"" \""Python/3.6 aiohttp/3.5.4\"""", ""remote_address"": ""10.32.4.199"", ""request_start_time"": ""[11/Jul/2019:14:19:34 +0000]"", ""first_request_line"": ""PATCH /api/v1alpha/batches/9/close HTTP/1.1"", ""response_status"": 200, ""response_size"": 158, ""request_header"": {""Referer"": ""-"", ""User-Agent"": ""Python/3.6 aiohttp/3.5.4""}}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:34,957"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""cancel:862"", ""message"": ""batch 9 cancelled""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:34,958"", ""filename"": ""web_log.py"", ""funcNameAndLine"": ""log:233"", ""message"": ""10.32.4.199 [11/Jul/2019:14:19:34 +0000] \""PATCH /api/v1alpha/batches/9/cancel HTTP/1.1\"" 200 158 \""-\"" \""Python/3.6 aiohttp/3.5.4\"""", ""remote_address"": ""10.32.4.199"", ""request_start_time"": ""[11/Jul/2019:14:19:34 +0000]"", ""first_request_line"": ""PATCH /api/v1alpha/batches/9/cancel HTTP/1.1"", ""response_status"": 200, ""response_size"": 158, ""request_header"": {""Referer"": ""-"", ""User-Agent"": ""Python/3.6 aiohttp/3.5.4""}}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:34,967"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1145"", ""message"": ""update job (9, 1, 'main') with pod batch-9-job-1-c8b9b2""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:34,969"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""set_state:501"", ""message"": ""job (9, 1, 'main') changed state: Ready -> Cancelled""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:34,974"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""_delete_pvc:251"", ""message"": ""deleting persistent volume claim batc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6617:2157,message,message,2157,https://hail.is,https://github.com/hail-is/hail/issues/6617,1,['message'],['message']
Integrability,", and tests: <code>naturaltime</code> can also accept a <code>timedelta</code> (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/31"">#31</a>) <a href=""https://github.com/nuztalgia""><code>@​nuztalgia</code></a></li>; </ul>; <h2>4.2.2</h2>; <h2>Fixed</h2>; <ul>; <li>Update annotations: <code>naturadelta</code> and <code>naturaltime</code> can also accept a <code>float</code> (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/29"">#29</a>) <a href=""https://github.com/hugovk""><code>@​hugovk</code></a></li>; </ul>; <h2>4.2.1</h2>; <h2>Fixed</h2>; <ul>; <li>Rename Arabic locale from <code>ar_SA</code> to <code>ar</code> to enable fallbacks (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/27"">#27</a>) <a href=""https://github.com/hugovk""><code>@​hugovk</code></a></li>; <li>Use <code>%d</code> for year translations, convert to string for <code>intcomma</code> after (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/23"">#23</a>) <a href=""https://github.com/carterbox""><code>@​carterbox</code></a></li>; <li>Fix <code>intcomma</code> with <code>ndigits=0</code> (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/26"">#26</a>) <a href=""https://github.com/hugovk""><code>@​hugovk</code></a></li>; </ul>; <h2>4.2.0</h2>; <h2>Added</h2>; <ul>; <li>Add <code>humanize.metric()</code> for converting big/small numbers to SI units (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/22"">#22</a>) <a href=""https://github.com/bwoodsend""><code>@​bwoodsend</code></a></li>; <li>Add type hints (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/15"">#15</a>) <a href=""https://github.com/hugovk""><code>@​hugovk</code></a></li>; </ul>; <h2>Fixed</h2>; <ul>; <li>Fix <code>scientific()</code> on small positive numbers (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/22"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12329:3662,depend,dependabot,3662,https://hail.is,https://github.com/hail-is/hail/pull/12329,1,['depend'],['dependabot']
Integrability,", and verify (proxied) servers. For Hail principals, we only generate a json configuration; file containing the ssl mode and some named paths. The new `hailtop/ssl.py`; module defines the mapping from configuration to Python's; [`SSLContext`](https://docs.python.org/3.6/library/ssl.html#ssl.SSLContext). There is also one ""curl"" principal: the admin-pod. REQUIRED and DISABLED are; mostly the same because required passes the `insecure` flag. As curl is; client-only, there is no notion of ""incoming connection"". ---. FAQ. Does this recreate certs on each deploy?. Yes. How do services speak to each other while a deploy is happening? Newly deployed; services will only trust newly deployed clients?. `create_certs.py` includes the previous deploy's certificates in the trust; chain, so we can always accept clients from one deploy backwards. Old services; will not trust the new clients, but the `build.yaml` ensures things are deployed; in dependency order. Deploy would never work if a client could depend on; a not-yet-deployed server. ---. Things for you to verify:; - does every service load *its own unqiue* ssl-config secret?; - does every service use an SSL context for serving?; - does everyone who makes http requests to internal services use an SSL client; session?; - do all TLS-secured nginx instances include their http.conf in the `http`; section and the `proxy.conf` file in any proxying sections?; - Do the SSLContext's from `ssl.py` and the nginx configurations generated by; `create_certs.py` obey the aforementioned matrix?. Post-merge actions:; - deploy gateway; - deploy internal-gateway; - deploy router-resolver. Anticipated outages:. - Before a service is redeployed it will be inaccessible from the outside; because the router will try to speak to it on HTTPS. Services that speak to; one another (ci<->batch, everyone<->auth) will lose connections while the; deploy is happening. Deploy should move smoothly because CI will completely; transmit the deploy batch to batch ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8513:5812,depend,depend,5812,https://hail.is,https://github.com/hail-is/hail/pull/8513,1,['depend'],['depend']
Integrability,", in export_bgen; Env.hail().utils.ExportType.getExportType(parallel)))); File ""/opt/conda/default/lib/python3.6/site-packages/hail/backend/backend.py"", line 109, in execute; result = json.loads(Env.hc()._jhc.backend().executeJSON(self._to_java_ir(ir))); File ""/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; File ""/opt/conda/default/lib/python3.6/site-packages/hail/utils/java.py"", line 225, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.RuntimeException: error while applying lowering 'InterpretNonCompilable'; at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:26); at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:18); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:18); at is.hail.expr.ir.CompileAndEvaluate$$anonfun$apply$1.apply(CompileAndEvaluate.scala:16); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); at is.hail.expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:14); at is.hail.backend.Backend$$anonfun$execute$1.apply(Backend.scala:56); at is.hail.backend.Backend$$anonfun$execute$1.apply(Backend.scala:56); at is.hail.utils.package$.using(package.scala:596); at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:10); at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:9); at is.hail.utils.package$.using(package.scala:596); at is.hail.annotations.Region$.scoped(Region.scala:18); at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:9); at is.hail.backend.Backend.execute(Backend.scala:56); at is.hail.backend.Backend.executeJSON(Backend.scala:62); at sun",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8161:1579,Wrap,WrappedArray,1579,https://hail.is,https://github.com/hail-is/hail/issues/8161,1,['Wrap'],['WrappedArray']
Integrability,", in rare cases, make changes that affect code that was not previously formatted by <em>Black</em> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3155"">#3155</a>)</li>; </ul>; <h3>Stable style</h3>; <ul>; <li>Fix an infinite loop when using <code># fmt: on/off</code> in the middle of an expression or code block (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3158"">#3158</a>)</li>; <li>Fix incorrect handling of <code># fmt: skip</code> on colon (<code>:</code>) lines (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3148"">#3148</a>)</li>; <li>Comments are no longer deleted when a line had spaces removed around power operators (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2874"">#2874</a>)</li>; </ul>; <h3>Preview style</h3>; <ul>; <li>Single-character closing docstring quotes are no longer moved to their own line as this is invalid. This was a bug introduced in version 22.6.0. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3166"">#3166</a>)</li>; <li><code>--skip-string-normalization</code> / <code>-S</code> now prevents docstring prefixes from being normalized as expected (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3168"">#3168</a>)</li>; <li>When using <code>--skip-magic-trailing-comma</code> or <code>-C</code>, trailing commas are stripped from subscript expressions with more than 1 element (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3209"">#3209</a>)</li>; <li>Implicitly concatenated strings inside a list, set, or tuple are now wrapped inside parentheses (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3162"">#3162</a>)</li>; <li>Fix a string merging/split issue when a comment is present in the middle of implicitly concatenated strings on its own line (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3227"">#3227</a>)</li>; </ul>; <h3><em>Blackd</em></h3>; <ul>; <li><code>blackd</code> now supports enabl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12174:1675,depend,dependabot,1675,https://hail.is,https://github.com/hail-is/hail/pull/12174,1,['depend'],['dependabot']
Integrability,", or <code>$u</code> global objects, you need to update your; JavaScript or use the mitigation below.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/953002e6261bdd9314ee0a3314aae19479a88c7e""><code>953002e</code></a> Bump to 5.0.0 final</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/3d3e93290bbddede9ce5824119120330b3800e5e""><code>3d3e932</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10463"">#10463</a> from AA-Turner/fix-css-docutils-0-18</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/9298b3e142d48420a8c1edbb353c5d9be3e69348""><code>9298b3e</code></a> Update message catalogs</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/bdeb627c14174d53e0eeaf51ff8d69eb5b296565""><code>bdeb627</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10486"">#10486</a> from tk0miya/fix_babel_extract_message</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/16ca3237bdcdc1b45b6c839af201802aeaf937c2""><code>16ca323</code></a> Fix imgconverter: Failed to extract translation messages</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/dc30920db0a8159da2a4e94cfa107322b83f7cda""><code>dc30920</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10481"">#10481</a> from AA-Turner/lang-none-en</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/200414982c768c213ca66f41fa331a5b4d129d94""><code>2004149</code></a> Update test</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/78c478a579b9d3f57091544d1717ee7f1c507ff1""><code>78c478a</code></a> Merge remote-tracking branch 'upstream/5.0.x' into lang-none-en</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/479e48266c025c99025787a8004a82b2afda8e6c""><code>479e482",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11871:4920,depend,dependabot,4920,https://hail.is,https://github.com/hail-is/hail/pull/11871,1,['depend'],['dependabot']
Integrability,", writer)); File ""/share/pkg.7/hail/0.2.46/install/lib/python3.7/site-packages/hail/backend/spark_backend.py"", line 296, in execute; result = json.loads(self._jhc.backend().executeJSON(jir)); File ""/share/pkg.7/spark/2.4.3/install/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; File ""/share/pkg.7/hail/0.2.46/install/lib/python3.7/site-packages/hail/backend/spark_backend.py"", line 41, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: SocketException: Too many open files. Java stack trace:; java.lang.RuntimeException: error while applying lowering 'InterpretNonCompilable'; at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:26); at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:18); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:18); at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:28); at is.hail.backend.spark.SparkBackend.is$hail$backend$spark$SparkBackend$$_execute(SparkBackend.scala:317); at is.hail.backend.spark.SparkBackend$$anonfun$execute$1.apply(SparkBackend.scala:304); at is.hail.backend.spark.SparkBackend$$anonfun$execute$1.apply(SparkBackend.scala:303); at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:20); at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:18); at is.hail.utils.package$.using(package.scala:601); at is.hail.annotations.Region$.scoped(Region.scala:18); at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:18); at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:229); at is.hail.backend.spark.SparkBackend.execute(SparkBackend.scala:303); at is.hail.backend.spark.SparkBackend.execu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293:3348,Wrap,WrappedArray,3348,https://hail.is,https://github.com/hail-is/hail/issues/9293,1,['Wrap'],['WrappedArray']
Integrability,",; L3Ol_: Call,; Bmt: Variant,; EExpF_H: Struct{; DyAZQ1pL: Empty; },; JSc3FhxVxoM: Array[Dict[String, Empty]],; Iuu: Dict[Variant, Double],; qXBGmKS: Long,; QQfQtf3ct: Call,; bSsLYsTDI: Array[Array[Call]],; ad1iBzwaFZf: Dict[String, Locus],; Z2cD2KmFIkG: Call,; VSqH: AltAllele,; XVZqCYGf3_: Double,; NBdmoAaGkoL: Boolean,; r: Array[AltAllele],; W_NOSJIvTd: Double,; s3B8QiAqQ: Long,; lk: Float,; S1Fo: Float,; PEcTjU8vomh: Empty,; REgY: Double,; ZUB: Variant,; b9UtO: Set[Float],; sT8o_aQ: Array[Call],; Igr1: Call,; A6ditFSwmRK: Call,; EmxV: Boolean,; a7: Struct{; JtHJhnfateR: Empty; }; }; v [ 14:1955123271-18:1272376844; , [false,null]; , 14:1256937813-17:1583114455; , 3:4546980; , 2; , Set(null, 15:1947873743, 13:866526696, 6:1573282210, 19:891774512); , GCaO16Nsy8:77911856:ATA:TG; , Set(72); , false; , [null]; , Set(F&S~b); , 7:472895707; , null; , true; , Infinity; , ./.:22,28:75:108:PL=167,0,83; , Infinity; , rdQ:630981228:T:CTA; , Map(); , -28; , 11:810964873; , RFJrknBvIH:1425413812:TAT:GC; , [[GCCAC/A]]; , 1; , qxomnU6Nqr:1347703197:G:A; , [null]; , WrappedArray(); , Map(m:190688303:C:AG -> -1.7976931348623157E308, lcg7p:2050711280:G:GATC -> 4.9E-324, DBeo6xuPH:1588993816:T:CTA -> 8.537643765112484E307); , -5599614078518791215; , 1; , null; , Map(y -> 17:750270934); , 0; , G/CATG; , -1.4729264086204403E307; , false; , WrappedArray(); , null; , -9223372036854775808; , 12.945546; , -Infinity; , null; , null; , QWxPKk:173048886:GTC:TCTT; , null; , WrappedArray(); , null; , 2; , false; , [null]; ]; ```; ```scala; t Struct{; CKkepccXC: Float,; Np: Locus,; fP8kTXty9: Double,; Qp6uH: Set[Set[Double]],; K7wSG1F3: Variant,; lLo85q: AltAllele,; v1du: Genotype; }; v [ -Infinity; , 5:2134996951; , 0.0; , Set( Set(7.482063689522203E307, -4.3155177478799624E305, -1.428773456444566E308, 9.332975286117578E307); , Set(); , null; , Set(49.15738854346134, 1.5361471805543802E308); , Set(-7.448920624629132E306, 13.921804085458959, 4.9E-324, -40.02694783286595, -54.20909301114429); ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1903:2999,Wrap,WrappedArray,2999,https://hail.is,https://github.com/hail-is/hail/pull/1903,1,['Wrap'],['WrappedArray']
Integrability,",>=0.14, but you have docutils 0.20.1.; sphinx-rtd-theme 1.3.0 has requirement docutils<0.19, but you have docutils 0.20.1.; notebook 6.5.6 has requirement pyzmq<25,>=17, but you have pyzmq 25.1.1.; matplotlib 3.5.3 requires pillow, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Heap-based Buffer Overflow <br/>[SNYK-PYTHON-PILLOW-5918878](https://snyk.io/vuln/SNYK-PYTHON-PILLOW-5918878) | `pillow:` <br> `9.5.0 -> 10.0.1` <br> | No | Mature . Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzNTM4YWIwOC03Yzk4LTRjMDUtOTQ0Ny0yMjYwYjliNjhmY2IiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjM1MzhhYjA4LTdjOTgtNGMwNS05NDQ3LTIyNjBiOWI2OGZjYiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13708:1470,depend,dependency,1470,https://hail.is,https://github.com/hail-is/hail/pull/13708,2,['depend'],"['dependencies', 'dependency']"
Integrability,",A]]| 1:11155_C_A|; +--------+-------+--------------------+--------------------+--------------------+; only showing top 10 rows. Struct {; v: Variant,; `va.varid`: String; }; [u'va.varid']; +--------+-------+--------------------+--------------------+--------------------+; |v.contig|v.start| v.ref| v.altAlleles| va.varid|; +--------+-------+--------------------+--------------------+--------------------+; | 01| 10013| A| [[A,C]]| 1:10013_A_C|; | 01| 10179| G| [[G,T]]| 1:10179_G_T|; | 01| 10259| C| [[C,A]]| 1:10259_C_A|; | 01| 10292| C| [[C,T]]| 1:10292_C_T|; | 01| 10402| G| [[G,A]]| 1:10402_G_A|; | 01| 10527| T| [[T,A]]| 1:10527_T_A|; | 01| 10611| G| [[G,A]]| 1:10611_G_A|; | 01| 10754| G| [[G,C]]| 1:10754_G_C|; | 01| 11099| T| [[T,G]]| 1:11099_T_G|; | 01| 11115| C| [[C,A]]| 1:11155_C_A|; +--------+-------+--------------------+--------------------+--------------------+; only showing top 10 rows. Struct {; v: Variant,; `va.varid`: String,; C1: Double,; C2: Double; }; [u'va.varid']; [Stage 6:====================================================>(1640 + 1) / 1641]Traceback (most recent call last):; File ""/tmp/ec5f6e42-0ea7-404d-8311-f97f7ec26ad6/kt_troubleshooting_issue_042617.py"", line 31, in <module>; kt2.to_dataframe().show(10); File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py"", line 287, in show; File ""/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py"", line 63, in deco; File ""/usr/lib/spark/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py"", line 319, in get_return_value; py4j.protocol.Py4JJavaError: An error occurred while calling o448.showString.; : org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 8.0 failed 20 times, most recent failure: Lost task 0.19 in stage 8.0 (TID 3406, cluster-mh-sw-xn3h.c.practice.internal): java.lang.ClassCastException: java.lang.String cannot be cast to is.hail.variant.Variant; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1725:2811,protocol,protocol,2811,https://hail.is,https://github.com/hail-is/hail/issues/1725,2,['protocol'],['protocol']
Integrability,",ArrayBuffer(call))),CallStats(),None),CallStats()))),Begin(ArrayBuffer(SeqOp(0,ArrayBuffer(GetField(Ref(__iruid_400,struct{x: call, y: int32}),x)),AggStateSignature(Map(CallStats() -> AggSignature(CallStats(),ArrayBuffer(int32),ArrayBuffer(call))),CallStats(),None),CallStats()))),Let(__iruid_401,ResultOp(0,WrappedArray(AggStateSignature(Map(CallStats() -> AggSignature(CallStats(),ArrayBuffer(int32),ArrayBuffer(call))),CallStats(),None))),ApplyBinaryPrimOp(Add(),GetField(Ref(__iruid_400,struct{x: call, y: int32}),y),GetField(GetTupleElement(Ref(__iruid_401,tuple(struct{AC: array<int32>, AF: array<float64>, AN: int32, homozygote_count: array<int32>})),0),AN))),WrappedArray(AggStateSignature(Map(CallStats() -> AggSignature(CallStats(),ArrayBuffer(int32),ArrayBuffer(call))),CallStats(),None)))))). After lower: ; MakeTuple(ArrayBuffer((0,RunAggScan(GetTupleElement(In(0,PCTuple[0:PCArray[PCStruct{x:PCCall,y:PInt32}]]),0),__iruid_400,Begin(ArrayBuffer(InitOp(0,ArrayBuffer(I32(2)),AggStateSignature(Map(CallStats() -> AggSignature(CallStats(),ArrayBuffer(int32),ArrayBuffer(call))),CallStats(),None),CallStats()))),Begin(ArrayBuffer(SeqOp(0,ArrayBuffer(GetField(Ref(__iruid_400,struct{x: call, y: int32}),x)),AggStateSignature(Map(CallStats() -> AggSignature(CallStats(),ArrayBuffer(int32),ArrayBuffer(call))),CallStats(),None),CallStats()))),Let(__iruid_401,ResultOp(0,WrappedArray(AggStateSignature(Map(CallStats() -> AggSignature(CallStats(),ArrayBuffer(int32),ArrayBuffer(call))),CallStats(),None))),ApplyBinaryPrimOp(Add(),GetField(Ref(__iruid_400,struct{x: call, y: int32}),y),GetField(GetTupleElement(Ref(__iruid_401,tuple(struct{AC: array<int32>, AF: array<float64>, AN: int32, homozygote_count: array<int32>})),0),AN))),WrappedArray(AggStateSignature(Map(CallStats() -> AggSignature(CallStats(),ArrayBuffer(int32),ArrayBuffer(call))),CallStats(),None)))))). is.hail.utils.HailException: not a streamable IR: (GetTupleElement 0; (In PCTuple[0:PCArray[PCStruct{x:PCCall,y:PInt32}]] 0))",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8063#issuecomment-586602113:8432,Wrap,WrappedArray,8432,https://hail.is,https://github.com/hail-is/hail/pull/8063#issuecomment-586602113,2,['Wrap'],['WrappedArray']
Integrability,",rsid:EBinary,qual:EFloat64,filters:EArray[+EBinary],info:+EBaseStruct{AC:EArray[EInt32],AF:EArray[EFloat64],AN:EInt32,BaseQRankSum:EFloat64,ClippingRankSum:EFloat64,DP:EInt32,DS:+EBoolean,FS:EFloat64,HaplotypeScore:EFloat64,InbreedingCoeff:EFloat64,MLEAC:EArray[EInt32],MLEAF:EArray[EFloat64],MQ:EFloat64,MQ0:EInt32,MQRankSum:EFloat64,QD:EFloat64,ReadPosRankSum:EFloat64,set:EBinary}}"",""_vType"":""Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Float64,InbreedingCoeff:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(locus, alleles),JArray(List(JObject(List((start,JObject(List((locus,JObject(List((contig,JString(1)), (position,JInt(904165))))), (alleles,JArray(List(JString(G), JString(A))))))), (end,JObject(List((locus,JObject(List((contig,JString(4)), (position,JInt(70592790))))), (alleles,JArray(List(JString(G), JString(T))))))), (includeStart,JBool(true)), (includeEnd,JBool(true)))), JObject(List((start,JObject(List((locus,JObject(List((contig,JString(4)), (position,JInt(70899111))))), (alleles,JArray(List(JString(G), JString(A))))))), (end,JObject(List((locus,JObject(List((contig,JString(8)), (position,JInt(126013303))))), (alleles,JArray(List(JString(G), JString(A))))))), (includeStart,JBool(true)), (includeEnd,JBool(true)))), JObject(List((start,JObject(List((locus,JObject(List((contig,JString(8)), (position,JInt(126888589))))), (alleles,JArray(List(JString(G), JString(A))))))), (end,JObject(List((locus,JObject(List((contig,JString(14)), (position,JInt(75037676))))), (alleles,JArray(Lis",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9856:14034,Wrap,WrappedArray,14034,https://hail.is,https://github.com/hail-is/hail/issues/9856,1,['Wrap'],['WrappedArray']
Integrability,"- (1.0 / (n - 2.0)); starts_and_stops = hl.linalg.utils.locus_windows(ht.locus, args.radius, _localize=False); r2_adj = r2_adj._sparsify_row_intervals_expr(starts_and_stops, blocks_only=False); r2_adj = r2_adj.sparsify_triangle(); r2_adj = r2_adj.checkpoint(f'{tmp}/adj', overwrite=args.overwrite). if __name__ == '__main__':; main(); ```. ### Version. 0.2.128. ### Relevant log output. ```shell; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.128-17247d8990c6; LOGGING: writing to /home/edmund/.local/src/hail/hail-20240508-1553-0.2.128-17247d8990c6.log; Traceback (most recent call last):; File ""/home/edmund/.local/share/pyenv/versions/3.9.18/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.local/share/pyenv/versions/3.9.18/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/__main__.py"", line 39, in <module>; cli.main(); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py"", line 430, in main; run(); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py"", line 284, in run_file; runpy.run_path(target, run_name=""__main__""); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 321, in run_path; return _run_module_code(code, init_globals, run_name,; File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 135, in _run_module_code; _run_code(code, mod_globals, init_globals,; File ""/home/edmund/.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14537:1934,adapter,adapter,1934,https://hail.is,https://github.com/hail-is/hail/issues/14537,1,['adapter'],['adapter']
Integrability,"- Add Hadoop config as additional parameter to c++ compiled function; - Add C++ `HadoopConfig` wrapper and method to create an output stream; - Implement `NDArrayWrite` node and emit on backend. ### Notes; - `RichHadoopConfiguration` is an `AnyVal`, which is not implemented as a Java `Object`. In order to use it with JNI (and our `ObjectArray` pattern), I had to cast it to an `AnyRef` and allocate it as an object. There might be a way to call `AnyVal` methods and not do the allocation but haven't found one yet.; - Our current system doesn't support compiled functions that don't return values. I made it support void-type IRs but for now enforced that they will return an int (returned 0 after a successful write).; - All our bufferspecs are blocking which won't work for a numpy-compatible encoding. Going to follow-up on this PR with a simple non-blocking spec. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5837:95,wrap,wrapper,95,https://hail.is,https://github.com/hail-is/hail/pull/5837,1,['wrap'],['wrapper']
Integrability,- Added Scala infrastructure to aggregate to new row fields (current is only entry fields). To Do:; - Expose in Python interface (currently just passing an empty struct); - Write tests in Python,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4131:119,interface,interface,119,https://hail.is,https://github.com/hail-is/hail/pull/4131,1,['interface'],['interface']
Integrability,"- Added a new build step `test_pipeline_docs` that runs doctest for the pipeline module; - Added pipeline docs to the hail/Makefile with a new target `pipeline-docs`. I also changed the `make-docs` target to be `base-docs` and `hail-docs`. `pipeline-docs` and `hail-docs` depend on `base-docs` and `upload-docs` depends on `hail-docs` and `pipeline-docs`; - Fixed a bunch of places in the documentation for clarity and to make the doctests work.; - Note, some examples are skipped because we can't run docker within docker in local mode. We can consider at another time point running all of the examples with the BatchBackend; - There's a bunch of Sphinx stuff I had to do to get the docs to render how I wanted them to with regards to inherited members (it was including all string methods by default even though). It's possible I can clean that up a bit, but I think it's fine for now.; - Added a link to the docs to the batch dropdown menu.; - Docs will appear at hail.is/docs/pipeline for now. Eventually everything will be renamed to batch, but I elected not to do that now.; - I checked the dropdown works correctly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8086:272,depend,depend,272,https://hail.is,https://github.com/hail-is/hail/pull/8086,2,['depend'],"['depend', 'depends']"
Integrability,- Also changed VARCHAR fields back to TEXT where it was VARCHAR(65535).; - Added names to containers for ease in identifying when debugging; - Got rid of the google sdk dependency in the docker worker image (saves 400MB),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7365:169,depend,dependency,169,https://hail.is,https://github.com/hail-is/hail/pull/7365,1,['depend'],['dependency']
Integrability,"- Basic JSON format for NGINX access logs; - `message`, `remote_address`, `request_duration`, `response_status` and `x_real_ip` should match the Python Access logger so we should be able to query these fields all at once; - Unfortunately the NGINX `error_log` does not allow the same custom formatter, but we can create multiple, [custom access logs](https://www.nginx.com/blog/diagnostic-logging-nginx-javascript-module/#proxy_next_upstream) based on arbitrary failure criteria if there's a particular class of error logs we want to get in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9928:46,message,message,46,https://hail.is,https://github.com/hail-is/hail/pull/9928,1,['message'],['message']
Integrability,"- Delete the Python ir.Value class (no longer used); - Set up infrastructure for Scala interface changes, but don't; do that here. I think we should add a `hl.parallelize(<array<struct> expr>)` method; that returns a table.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4214:87,interface,interface,87,https://hail.is,https://github.com/hail-is/hail/pull/4214,1,['interface'],['interface']
Integrability,- Depends on #1780,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1789:2,Depend,Depends,2,https://hail.is,https://github.com/hail-is/hail/pull/1789,1,['Depend'],['Depends']
Integrability,- Depends on #2086 and #2090,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2096:2,Depend,Depends,2,https://hail.is,https://github.com/hail-is/hail/pull/2096,1,['Depend'],['Depends']
Integrability,"- Expose init_local.; - Fix formatting of some error messages (stray }).; - Fix index paths, they don't have a ""parts"" component, have "".idx"" suffix. This showed up as an issue interopreating between Spark and local modes. FYI @tpoterba rather than just testing them independently, it might be worthwhile to have write/read interop tests between the various backends. Spark to local is partially tested by the pre-existing (matrix)tables tests, but not the other way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9596:53,message,messages,53,https://hail.is,https://github.com/hail-is/hail/pull/9596,1,['message'],['messages']
Integrability,- Fixed VEP not annotating any allele when a `*` allele present at the site; now annotates the other alleles.; - Fixed VEP crash when returning no results; now issues a warn message.; - Changed annotation type with `csq` option from `String` to `Array[String]` (was wrong),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1531:174,message,message,174,https://hail.is,https://github.com/hail-is/hail/pull/1531,1,['message'],['message']
Integrability,"- HAIL_QUERY_BACKEND selects the backend: spark or service; - remove Spark from default initializing message; - Add HAIL_DONT_RETRY_500=1 to disable retrying 500. This is necessary to see the faction of passing tests against the partially-functioning query service. Otherwise the tests hang.; - normalize paths in GoogleStorageFS. Various code uses .., and normalizing removes them.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8585:101,message,message,101,https://hail.is,https://github.com/hail-is/hail/pull/8585,1,['message'],['message']
Integrability,"- I ported over the parallel write changes from 0.2 to 0.1. However, I left the interface of parallel being a Boolean where False = concatenate and True = parallel with a header per shard.; - This is a combination of previous PRs: #2265, #2263, #2354, #2587, #2630 ; - Addresses #2245 for @maryhaas",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2746:80,interface,interface,80,https://hail.is,https://github.com/hail-is/hail/pull/2746,1,['interface'],['interface']
Integrability,- Implemented support for blockmatrix types in the service backend; - All BlockMatrix tests except those for `sparsify` methods and `svd` (which uses `sparsify`) succeed locally on the service backend; - Removed test decorators for tests that succeeded locally; - Added a single test out of the `BlockMatrix` suite to `test-apiserver.sh`. ### Dependencies on BlockMatrix; - `Statgen` doesn't seem to have any `BlockMatrix`-based Java dependencies; - `linear-mixed-model` uses `svd` and `RowMatrix`,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5522:343,Depend,Dependencies,343,https://hail.is,https://github.com/hail-is/hail/pull/5522,2,"['Depend', 'depend']","['Dependencies', 'dependencies']"
Integrability,"- In the `combOp`, the `TakeByAggregator` was calling the `seqOp` which recomputes the sort-key. Since the evaluation context was not set correctly for the keys, the expression that evaluates the sort-key obviously produced the wrong value for the given key. - `TakeByAggregator.result` used `PriorityQueue.toArray`, which is not guaranteed to produce the elements in sorted order, according to [the PriorityQueue docs](http://www.scala-lang.org/api/current/scala/collection/mutable/PriorityQueue.html). Instead, we must `clone` the `PriorityQueue` and then `dequeueAll` the elements. I'm not certain the `clone` is necessary. @cseed, does the Aggregator interface permit multiple calls to `result`?. > Only the dequeue and dequeueAll methods will return elements in priority order (while removing elements from the heap). Standard collection methods including drop, iterator, and toString will remove or traverse the heap in whichever order seems most convenient. I also added some fairly robust tests that compare `takeBy(f, 10)` to `collect().sortBy(f)`. In particular: ; - the `takeBy` should be a prefix of `sortBy` when lensing by `f`,; - for every sort-key except last one, the elements should be the same as in `sortBy`, and; - for the last sort-key, the elements should be a subset of those in `sortBy`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1761:655,interface,interface,655,https://hail.is,https://github.com/hail-is/hail/pull/1761,1,['interface'],['interface']
Integrability,"- KeyTable interface -- RDD[(Annotation, Annotation)]; - Python bindings; - Aggregator serialization fix!!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1103:11,interface,interface,11,https://hail.is,https://github.com/hail-is/hail/pull/1103,1,['interface'],['interface']
Integrability,- List of str inputs for condition are modified such that each condition is wrapped in parentheses and multiple conditions are separated by `&&`. Previous was conditions were comma separated.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1208:76,wrap,wrapped,76,https://hail.is,https://github.com/hail-is/hail/pull/1208,1,['wrap'],['wrapped']
Integrability,- Needed for new BGEN interface,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4253:22,interface,interface,22,https://hail.is,https://github.com/hail-is/hail/pull/4253,1,['interface'],['interface']
Integrability,"- Nested arrays appear to be supported in the current code, and I don't think this is intended.; - Why do exportFormat and exportInfo differ?; - Number is accessed from the field attrs without being checked. There could be something silly in there.; - Bad error messages (don't say which field was the problem)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1820:262,message,messages,262,https://hail.is,https://github.com/hail-is/hail/issues/1820,1,['message'],['messages']
Integrability,"- On *deploys*, makes sure that whatever is in our third-party images is in our private registry before starting builds like hail-ubuntu that might depend on those images. This means that we can update our ubuntu base image without the australians needing to deploy any images by hand. However, this does not run in PRs because I 1) didn't want to add that kind of latency for PRs and 2) we don't do any kind of namespacing for our images so if we did include this for a PR that ultimately wasn't merged we would have to manually remove the image anyway so why not manually add it if you're going to PR it… I think point 2 is a little weak but I recall this being what we agreed on a couple months back when we discussed this. I'm wondering if we should just eat the minute or so latency at the beginning of PRs to be safe but it also feels like a shame for something that changes so infrequently. . - Again on deploys, upload the hailgenetics/* images to the private registry if they don't already exist there. This way any deployments that aren't hail team's GCP deployment can get these images automatically when they deploy a new SHA instead of uploading them manually. It won't backfill skipped versions, but we decided that was ok. This seems less relevant for testing on PRs as it will get triggered on releases and we can easily dev deploy to rectify the image if this breaks.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12818:148,depend,depend,148,https://hail.is,https://github.com/hail-is/hail/pull/12818,1,['depend'],['depend']
Integrability,"- Removed `export_samples`, `export_variants`, `export_genotypes`. To perform same functionality, need to convert to KeyTable and then use `select` and `export`. - Changed Python interface for `select`, `drop`, and `key_by` to take varargs rather than a String or List of String. - Select is not backwards compatible with 0.1. To select a column name with periods in it, must use backticks now. - Not certain whether left hand side of named expression should be treated as an identifier or an annotationIdentifier. Right now, it's treated as an identifier. If it's an identifier, than `A.B = 5` will have a signature of `(""A.B"", TInt)`. If it's an annotationIdentifier path, than the signature would be `(""A"", TStruct((""B"", TInt)))`. Thoughts?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2279:179,interface,interface,179,https://hail.is,https://github.com/hail-is/hail/pull/2279,1,['interface'],['interface']
Integrability,"- Resolves #1105, #196; - For VDS and KT writes, writes history to `<output_path>/history.txt`; - For all other file types, writes history to `<output>.history.txt`; - Requires new Python dependency: `pip install autopep8`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2060:188,depend,dependency,188,https://hail.is,https://github.com/hail-is/hail/pull/2060,1,['depend'],['dependency']
Integrability,"- Signup page with web socket and spinner while waiting for account to create; - Upon account creation, a billing project named `{username}-trial` is created with $10 limit and a user `{username}`; - When deleting an account, the billing project is reopened if it's closed, then remove the user, and finally close the billing project. This behavior might be debatable. We may not need to remove the user from the billing project. I think it's better to be safe in case the billing project is reopened. Auth-driver is implicitly dependent on the batch front end, but this dependency isn't stated in build.yaml. An event queue is a future solution. I can get rid of my personal email being whitelisted, but I think it will be useful if we need to debug later and for a possible demo on Monday (although I'll probably just use some screenshots). If you want to test it in your namespace, make sure to comment out all the create and delete steps that are not related to billing projects.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9658:528,depend,dependent,528,https://hail.is,https://github.com/hail-is/hail/pull/9658,2,['depend'],"['dependency', 'dependent']"
Integrability,"- TableMapRows IR (takes a Struct IR as an argument); - Removed TableAnnotate; - select can output an IR; - Rewrote annotate and rename in Python to utilize select; - Removed annotate, rename, and drop from the Scala Table interface; - Moved annotate and rename to RichTable for Scala tests; - added some additional python tests",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3161:223,interface,interface,223,https://hail.is,https://github.com/hail-is/hail/pull/3161,1,['interface'],['interface']
Integrability,"- Using the full domain name instead of the shorthand `<service>.<namespace>` isn't strictly necessary but just made me nervous and I opted for the full unambiguous domain for in-cluster services (what if we had a namespace named `com`?? I feel like that would break some things); - I got the configuration wrong on how to tell envoy *not* to worry about certs of internal namespaces (I'd recommend using the `split` view for the diff because otherwise it's pretty hard to read); - For internal namespaces, using the `prefix` parameter for matching a route allowed `/foo/batch` to match a route like `/foo/batch-driver` which is obviously not great. the `path_separated_prefix` parameter actually does what we want; - Fixed the batch tests not to look at the HTTP 1.1 reason phrase and instead look at the response body to determine the error",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12392:551,rout,route,551,https://hail.is,https://github.com/hail-is/hail/pull/12392,2,['rout'],['route']
Integrability,"- Values of types other than `Array` and `Boolean` get output in VCF format (e.g. `.` instead of `NA` for missing values); - `NaN` values are converted to missing (`.`) when exporting VCF since VCF doesn't handle `NaN`; - Changes to handling of filters:; - `.` <=> `NA:Set[String]`; - `PASS` <=> `{}:Set[String]`; - `other` <=> `{""other""}:Set[String]""`; - Removed `va.pass` entirely (redundant with `va.filters` and needs constant synchronization)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1517:431,synchroniz,synchronization,431,https://hail.is,https://github.com/hail-is/hail/pull/1517,1,['synchroniz'],['synchronization']
Integrability,"- Write new index file to *.idx2; - Removed file_row_idx. Now take a list of variants to filter to. Future Plans:; - Have import_bgen get reference_genome, contig_recoding, and skip_invalid_loci from index file instead of from user; - Change index_bgen and import_bgen interface with more flexibility on where to read/write index files from; - Filtering variants from a Table -- User specifies expression from an existing table or a list of variants to filter from.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4243:269,interface,interface,269,https://hail.is,https://github.com/hail-is/hail/pull/4243,1,['interface'],['interface']
Integrability,"- [ ] use make dry-runs w/ git to ensure that CI executes exactly those tests whose dependencies have changed since the last commit. - [ ] banish `archiveZip`. create `whl` files without spark dependencies, install those on the leader node (do we need to specify the jar separately still?). - [ ] download plink, qctool, and R packages in hail/Makefile and make dependencies for `test`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5199:84,depend,dependencies,84,https://hail.is,https://github.com/hail-is/hail/issues/5199,3,['depend'],['dependencies']
Integrability,"- [dependabot/pip/hail/python/decorator-lt-6](/hail-is/hail/tree/dependabot/pip/hail/python/decorator-lt-6); - [dependabot/pip/hail/python/pytest-xdist-2.5.0](/hail-is/hail/tree/dependabot/pip/hail/python/pytest-xdist-2.5.0); - [dependabot/pip/hail/python/sphinx-rtd-theme-1.0.0](/hail-is/hail/tree/dependabot/pip/hail/python/sphinx-rtd-theme-1.0.0); - [dependabot/pip/hail/python/azure-identity-1.8.0](/hail-is/hail/tree/dependabot/pip/hail/python/azure-identity-1.8.0); - [dependabot/pip/hail/python/curlylint-0.13.0](/hail-is/hail/tree/dependabot/pip/hail/python/curlylint-0.13.0); - [dependabot/pip/hail/python/dev/pre-commit-2.17.0](/hail-is/hail/tree/dependabot/pip/hail/python/dev/pre-commit-2.17.0); - [dependabot/pip/hail/python/dev/curlylint-0.13.0](/hail-is/hail/tree/dependabot/pip/hail/python/dev/curlylint-0.13.0); - [dependabot/pip/hail/python/dev/pytest-xdist-2.5.0](/hail-is/hail/tree/dependabot/pip/hail/python/dev/pytest-xdist-2.5.0); - [dependabot/pip/hail/python/dev/mypy-0.931](/hail-is/hail/tree/dependabot/pip/hail/python/dev/mypy-0.931). Merge remote-tracking branches 'hi/dependabot/pip/hail/python/decorator-lt-6', 'hi/dependabot/pip/hail/python/pytest-xdist-2.5.0', 'hi/dependabot/pip/hail/python/sphinx-rtd-theme-1.0.0', 'hi/dependabot/pip/hail/python/azure-identity-1.8.0', 'hi/dependabot/pip/hail/python/curlylint-0.13.0', 'hi/dependabot/pip/hail/python/dev/pre-commit-2.17.0', 'hi/dependabot/pip/hail/python/dev/curlylint-0.13.0', 'hi/dependabot/pip/hail/python/dev/pytest-xdist-2.5.0' and 'hi/dependabot/pip/hail/python/dev/mypy-0.931' into HEAD",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11502:3,depend,dependabot,3,https://hail.is,https://github.com/hail-is/hail/pull/11502,27,['depend'],['dependabot']
Integrability,"- [x] There should be a test in the tests that verify that the account is operational, so if it disabled, we get an informative error message. (see issue #4533). - [x] There should be documentation/a playbook about how to get Github unstuck when this happens. (see [here](; https://github.com/hail-is/hail/issues/4517#issuecomment-429135514)). - [ ] We should mock Github so we don't rely on it during the tests, which makes me sad because yay integration tests, and what do we do when the Github API changes/breaks/doesn't behave the way we expect?. Assigning to @danking since he's been through the first two, but maybe someone else can handle the third.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4517:134,message,message,134,https://hail.is,https://github.com/hail-is/hail/issues/4517,2,"['integrat', 'message']","['integration', 'message']"
Integrability,"- [x] ~~Stacked on #7207 (needed for `MakeArray`)~~. Implements a new interface `EmitStream` for staged ""pull"" based streams. This design differs significantly from the current `ArrayIteratorTriplet` design; such ""push"" based streams are incapable of deforested operations that operate on multiple sub-streams, notably joins or zips. A (pull) stream has an internal state, which can be used to generate new elements by a `step` operation. This state is initialized by passing an initial parameter to an `init` operation, which will determine the initial state. You can think of a stream as allowing elements to be computed ""on-demand"", as opposed to the old design where the entire stream is consumed at once. This PR just contains the most simple streams (`ArrayRange`, `MakeArray`, `ArrayMap`, `ArrayFilter`). I'd like to get comments on it before merging my other stream implementations. So far I have all of the other streams implemented, except for `ReadPartition` and `If` (it turns out that `If` is tricky). **Interface**. `init` can return in two possible ways:; - `Missing` - the stream is actually entirely missing; this usually happens if one of the parameters to a stream is missing (e.g. `ArrayRange(0, NA, 1) = NA`); - `State(s0)` - the stream has started; its initial state is `s0`. `step` can return in three possible ways as well:; - `EOS` - we've reached the End Of Stream, there are no more elements left.; - `Skip(s1)` - this iteration didn't produce an element, you must try stepping again with state `s1` (see ""design notes"").; - `Yield(elt, s1)` - the stream computed an element `elt`; the following stream state will be `s1`. **Design Notes**. - The `Skip` return is very useful for simplifying the implementation of `ArrayFilter`. There is basically no nice way to implement filter otherwise without introducing some significant code duplication.; - ~~The stream ""parameter"", as well as the `Empty` return, are not very useful for the basic streams in this PR. However, they s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7228:70,interface,interface,70,https://hail.is,https://github.com/hail-is/hail/pull/7228,1,['interface'],['interface']
Integrability,- `stat -c` doesn't work on Mac; - I have a bloop directory now (related to metals which is a Scala Emacs IDE); - I had a rogue x in the definition of gateway's deployment; - I had missing semicolons in gateway's deployment; - the router resolver *is* TLS enabled; - the internal-gateway is *not* TLS enabled,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8686:231,rout,router,231,https://hail.is,https://github.com/hail-is/hail/pull/8686,1,['rout'],['router']
Integrability,"- add PIndexableValue. This represents canonical array, set and dict values.; - use in ArrayRef; - newP{Local, FIeld} now has a `PV <: PValue` type parameter to eliminate some casting. Where I'm going:. There will be a abstract PValue with the interface for each virtual type (container/indexable, base struct, etc.) Each concrete PType will have a corresponding PValue implementation (in this case, PCanonicalArray is implemented by PCanonicalIndexableValue.) I think this will allow us to get rid of PArrayBackedContainer. Only primitive PValues will have a code method (since other types might be compound). The code generator should then dispatch through downcasts of PValues get access to the relevant methods.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8213:244,interface,interface,244,https://hail.is,https://github.com/hail-is/hail/pull/8213,1,['interface'],['interface']
Integrability,- add priority class infrastructure throughout; - all pod specs have resource requests and limits; - make es tolerate preemptibles; - make monitoring router tolerate preemptibles. Deployed.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7425:150,rout,router,150,https://hail.is,https://github.com/hail-is/hail/pull/7425,1,['rout'],['router']
Integrability,- aggregate intervals (easy to implement with key tables); - annotate samples list (easy to implement with annotate_samples_table); - annotate global list and annotate global table (easy to implement with key table and annotate_global (renamed from annotate_global_py). Also cleaned up VSM interface (removed annotateSamplesList),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1796:290,interface,interface,290,https://hail.is,https://github.com/hail-is/hail/pull/1796,1,['interface'],['interface']
Integrability,- also add batch2 to the router,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6808:25,rout,router,25,https://hail.is,https://github.com/hail-is/hail/pull/6808,1,['rout'],['router']
Integrability,- annotateRowsExpr and dropRows(**exprs) have been removed from the Scala interface (annotateRowsExpr has been moved to testUtils); - annotate_rows and drop_rows are rewritten in terms of select_rows in Python (following Table.select and MatrixTable.select_entries).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3230:74,interface,interface,74,https://hail.is,https://github.com/hail-is/hail/pull/3230,1,['interface'],['interface']
Integrability,"- automatically download catch.hpp from GitHub if it's missing; - remove builtin rules and suffix based rules to improve performance and ease debugging; - change Makefile variable definitions to match our standard `FOO OP VAL` (note: two spaces); - rely on `clang -MM` (see: [Clang command line reference](https://clang.llvm.org/docs/ClangCommandLineReference.html) and below explanation) to generate precise dependencies for object files (including source and header files); - explicitly specify which files depend on `NUMBER_OF_GENOTYPES_PER_ROW` to be set (namely the dependency file and the object file associated with `ibs.cpp`); - break `TEST_OBJECTS` into two steps so that we can have `_test.cpp` files which do not have corresponding `.cpp` files (consider, for example, a header-only file, which ApproximateQuantiles will be); - eliminate `$(BUILD)/headers` in favor of precise dependency tracking described above; - remove the target `$(BUILD)`, directories don't work the way you think in Make, it's better to have individual rules create the containing directories when necessary; - remove `wget` nonsense, standardize on `curl -sSL` (which produces useful error messages). ---. # clang -MM. This argument to clang allows us to generate ""depfile"" or ""dependency files"" which are valid `Makefile`s describing how object files depend on `c`, `cpp`, `h`, and `hpp` files. `clang -MM foo.cpp` writes to stdout a Makefile that indicates how `foo.o` depends on preprocessor includes of other *user* files. For example,. ```; # cat foo.cpp; #include<stdio.h>; #include ""bar.h""; # clang -MM foo.cpp; foo.o: foo.cpp bar.h; ```. The `-MT target` allows us to specify the target's name:; ```; # clang -MM foo.cpp -MT fiddle; fiddle: foo.cpp bar.h; ```. The `-MQ` argument asks `clang` to quote the variable before make sees it, so (nb, I first quote it for the shell so it doesn't get seen as an env var):; ```; # clang -MM foo.cpp -MQ '$fiddle'; $$fiddle: foo.cpp bar.h; ```. The `-MG` argument tel",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5331:409,depend,dependencies,409,https://hail.is,https://github.com/hail-is/hail/pull/5331,5,"['depend', 'message']","['depend', 'dependencies', 'dependency', 'messages']"
Integrability,- better error message for invalid export type; - don't support nested collections (bugfix),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1821:15,message,message,15,https://hail.is,https://github.com/hail-is/hail/pull/1821,1,['message'],['message']
Integrability,"- changed behavior of `linear_regression` to parallel that of the other stats method when an expression is passed for `y`. When `y` is a list of expressions (even a list of one expression), the the five phenotype-dependent annotations are still array of float64.; - expanded `test_linreg` to test that all the interfaces work as expected; - changed `n_complete_samples` to just `n` since we may introduce an option to subset rather than impute per variant (which would cause n to change per variant) and I don't want to overload the notion of complete_sample to depend on the mode. I also think `n` is clear in linear regression context as the number of data points used, and in any case it's documented as the number of columns used.; - fixed a bug whereby `sum_x` was still `AC` on the Scala side.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3295:213,depend,dependent,213,https://hail.is,https://github.com/hail-is/hail/pull/3295,3,"['depend', 'interface']","['depend', 'dependent', 'interfaces']"
Integrability,"- conda environments are always up to date and enabled (important for developers); - flake8 and pylint are test (and, ergo, CI) dependencies; - use pytest with `--first-failure` so that re-runs run the failing tests first (important for developers)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4924:128,depend,dependencies,128,https://hail.is,https://github.com/hail-is/hail/pull/4924,1,['depend'],['dependencies']
Integrability,"- create KeyTable from DataFrame; - to make above useful, we need a way to ""contract"" native types (opposite of expand_types), that, convert Struct with the appropriate fields to Variant, etc. One alternative is to use SparkAnnotationImpex and have the user specify the Hail type. (Also means we need a way to build Hail types in python.); - annotate variants or samples with keytable; - load fam file as keytable; - remove annotevariants table, vcf, vds and annotatesamples fam, table, list, vds. They can all be implemented with annotate with keytable.; - same with filter list",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1158:76,contract,contract,76,https://hail.is,https://github.com/hail-is/hail/issues/1158,1,['contract'],['contract']
Integrability,- emit streams for `If` and `ReadPartition` IR. ; - delete `Emit.emitOldArrayIterator()` because all streamable IR's can be emitted with the new interface. before this is merged we probably want to make sure there are no significant performance regressions or anything of that sort,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7736:145,interface,interface,145,https://hail.is,https://github.com/hail-is/hail/pull/7736,1,['interface'],['interface']
Integrability,"- first cut C++ value IR compiler; - followed existing design, e.g. cxx.EmitTriplet, but carry physical type,; - added cxx.Compile, compiles a function takes and returns a single non-missing tuple,; - throws CXXUnsupportedOperation if it can't compile,; - integrate with assertEvalsTo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4663:256,integrat,integrate,256,https://hail.is,https://github.com/hail-is/hail/pull/4663,1,['integrat'],['integrate']
Integrability,"- front_end returns 200 OK if a bunch is already inserted for an open batch; - add a test that inserts failures on every third http request made by a batch builder; - add `MultipleExceptions` which can be raised and have many causes; - set minimum log level of aioclient to WARNING, so users see `log.warn` messages; - increase bunch byte size to 8MiB (was 8MB), increase bunch size to 8 * 1024 (was 1000, which, for typical Konrad jobs (1kB) prevents fully filling the HTTP request); - make the previous two parameters configurable (primarily for testing purposes); - souped up AsyncThrottledGather to bail out after a configurable number of exceptions. For the restartable client we:; 1. create the batch, if that succeeds we never try to create again; 2. create the json-encoded job_spec bunches, this only fails on user error; 3. submit 50-way parallel bunch, with a maximum of (by default) 10 individual request failures; 4. if any request fails, raise an exception, which is caught by outer `submit`, which retries a configurable number of times, logging a configurable number of errors",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7875:307,message,messages,307,https://hail.is,https://github.com/hail-is/hail/pull/7875,1,['message'],['messages']
Integrability,- generate appropriate error message; - don't test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8637:29,message,message,29,https://hail.is,https://github.com/hail-is/hail/pull/8637,1,['message'],['message']
Integrability,"- implements ""Block Lanczos"" / Blanczos algorithm for randomized SVD in Hail with HailTables; - adds method for Blanczos PCA following the exact interface of the current PCA method in Hail; - adds tests comparing Blanczos PCA with numpy and with Hail's current PCA",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9228:145,interface,interface,145,https://hail.is,https://github.com/hail-is/hail/pull/9228,1,['interface'],['interface']
Integrability,"- improved and fleshed out documentation of current BlockMatrix python functionality. Note`from_matrix_table` renamed to `from_entry_expr`, `from_numpy_matrix(numpy_matrix, ...)` renamed to `from_numpy(ndarray, ...)`, and similarly for `to_numpy_matrix`.; - renamed `matrix.py` as `blockmatrix.py`; - renamed `toLocalMatrix` to the more specific `toBreezeMatrix` on BlockMatrix and RowMatrix. This is prep for filling out the BlockMatrix interface w/ NumPy broadcast rules (model is LocalMatrix) and speeding up `to_numpy` and `from_numpy` (for now, by passing bytes via temp files rather than trough py4j) so that NumPy ndarrays serve as local matrix on Python side and interact predictably with BlockMatrices.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3072:438,interface,interface,438,https://hail.is,https://github.com/hail-is/hail/pull/3072,1,['interface'],['interface']
Integrability,"- ir for chisq, fet, ctt, hwe; - using nan instead of missing; - direct implementation of chisq. This is first half of closed #3825, leaving all python docs and interface as is. To cross-check, I used R and https://www.cog-genomics.org/software/stats",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3833:161,interface,interface,161,https://hail.is,https://github.com/hail-is/hail/pull/3833,1,['interface'],['interface']
Integrability,"- move environment.yml files out of the packaged directory so they don't get shipped to end users. - add `make test-pip-deploy` which pip deploys to the next available `devN` version (you have to wait a bit before you can `pip install` it, so I didn't include that in the test, but you can do that manually, or a motivated person can write a polling script). - add `build/dev-conda` which ensures that if the dev-environment file changes since you last ran `make build/dev-conda`, your conda environment is updated. - pedantically use the correct conda environment _everywhere_. - use python to determine cpu count instead of fixing it at 2. - add `jq` as an `env-setup.sh` dependency. - add `make build/credentials.json` which `scp`s a new JSON file containing credentials to the local machine, moreover there are two rules for automatically extracting the credentials for PYPI from this JSON file. - use `ENV_VAR`, a make macro, to ensure we rebuild the appropriate targets (but no more) when a relevant environment variable is changed since last build. - added several missing breeze versions, now we can easily test against new spark versions, just run `SPARK_VERSION=4.0.0 make test`. - fold doctests in with regular tests under `test-python` which uses pytest, no more unnecessary copying as well. - fix build-info. - delete two unused python files in hail root. - correct LIBSIMDPP dependency in C makefile. # Not Doing Yet. - incorporate native lib into this Makefile. Instead, if anything changed in src/main/c since we last built, we rebuild. - fix the directory structure to be compliant with pytests recommended structure",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5194:674,depend,dependency,674,https://hail.is,https://github.com/hail-is/hail/pull/5194,2,['depend'],['dependency']
Integrability,"- remove shadowJar dependency of makeDocsNoTest; - cleanup markdown conversion, make general: any pair of .md and .xslt file defines a new top-level page; - harmonize naming to enable the above, landing.md becomes index.md; - ctrl-c actually kills the site docker container now; - `(cd site && make test)` tests the site image with the contents of `hail/build/www` (we need a top-level makefile to manage that dependency properly); - added a 404 page; ![screen shot 2018-12-07 at 3 33 13 pm](https://user-images.githubusercontent.com/106194/49671603-72713580-fa36-11e8-91cf-b24936257628.png); - fixed redirect rules for /docs and /hail see note below. Resolves #4919 . ---; ### On NGINX Redirects; The internet seems to think that `rewrite` for redirects is ""bad"", ergo, I ignore the deleted rule and explain the additions. ```; location = /docs/ {; return 307 $scheme://$http_host/docs/0.2;; }; location ~ ^/hail(|/.*)$ {; return 301 $scheme://$http_host/docs/0.1$1;; }; ```. The [location](http://nginx.org/en/docs/http/ngx_http_core_module.html#location) directive can match `=` exactly, `~` by regex, `~*` by case insensitive regex, and `^~` which I do not understand. Question one: does this redirect `hail.is/docs` to `/docs/0.2`? Yes, the last paragraph of the location docs:. > If a location is defined by a prefix string that ends with the slash character, and requests are processed by one of proxy_pass, fastcgi_pass, uwsgi_pass, scgi_pass, memcached_pass, or grpc_pass, then the special processing is performed. In response to a request with URI equal to this string, but without the trailing slash, a permanent redirect with the code 301 will be returned to the requested URI with the slash appended. The docs appear incomplete, though, because this is a `return` rule, but it gets the 301. Question two: does this redirect `hail.is/docs/foo` to `/docs/0.2/foo`. No, the docs redirect is an `=` or exact match so `hail.is/docs/foo` is a 404. Question three: does this redirect `/hail/over",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4929:19,depend,dependency,19,https://hail.is,https://github.com/hail-is/hail/pull/4929,2,['depend'],['dependency']
Integrability,"- removed dependencies of lmm tests on linear_mixed_regression; - added test against fast_lmm; - added h_sq_standard_error feature from linear_mixed_regression. Toward goal of deleting linear_mixed_regression and its Scala / suites ASAP, as well as the KinshipMatrix class",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3931:10,depend,dependencies,10,https://hail.is,https://github.com/hail-is/hail/pull/3931,1,['depend'],['dependencies']
Integrability,"- set up tests that evaluate performance tradeoffs; - build interface for controlling compression levels in import / write; - also test parquet LZ4 / snappy on write with Mitja pipeline, with size",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/293:60,interface,interface,60,https://hail.is,https://github.com/hail-is/hail/issues/293,1,['interface'],['interface']
Integrability,- track last 10 instance.create operations per zone; - weight probability by the success rate; - fixed bug where mark = None wouldn't return any messages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9317:145,message,messages,145,https://hail.is,https://github.com/hail-is/hail/pull/9317,1,['message'],['messages']
Integrability,"- version `devel-6ee2919`; - source: git@github.com/hail-is/hail.git ; compiled with `gradle shadowJar`. Desired behavior:. When reading an old version of a VDS, hail should print a message such as:. ```; The vds ""/users/dking/projects/hail-data/profile225.vds"" cannot be read by this version of hail. It must be regenerated from the VCF source using this version of hail.; ```. Actual behavior:. ```; dking@wmb16-359 # python; >>> from hail import *; >>> hc = HailContext(); hc.reaUsing Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; d9""/projecRunning on Apache Spark version 2.0.2; SparkUI available at http://10.10.99.215:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version devel-6ee2919; WARNING: This is an unstable development build.; >>> hc.read(""/users/dking/projects/hail-data/profile225.vds""); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-606>"", line 2, in read; File ""/Users/dking/projects/hail/python/hail/java.py"", line 121, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: MappingException: Did not find value which can be converted into java.lang.String. Java stack trace:; org.json4s.package$MappingException: No usable value for sample_schema; Did not find value which can be converted into java.lang.String; 	at org.json4s.reflect.package$.fail(package.scala:96); 	at org.json4s.Extraction$ClassInstanceBuilder.org$json4s$Extraction$ClassInstanceBuilder$$buildCtorArg(Extraction.scala:462); 	at org.json4s.Extraction$ClassInstanceBuilder$$anonfun$14.apply(Extraction.scala:482); 	at org.json4s.Extraction$ClassInstanceBuilder$$anonfun$14.apply(Extraction.scala:482); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(Traversab",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2159:182,message,message,182,https://hail.is,https://github.com/hail-is/hail/issues/2159,1,['message'],['message']
Integrability,"- web_common/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **658/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.3 | HTTP Request Smuggling <br/>[SNYK-PYTHON-AIOHTTP-5798483](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-5798483) | `aiohttp:` <br> `3.8.4 -> 3.8.5` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjZmU2NDEwYi1jYjQ3LTQ2YzgtOTYwYy1kOWRlY2UxMjI5ZTIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImNmZTY0MTBiLWNiNDctNDZjOC05NjBjLWQ5ZGVjZTEyMjllMiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13286:1338,depend,dependency,1338,https://hail.is,https://github.com/hail-is/hail/pull/13286,2,['depend'],"['dependencies', 'dependency']"
Integrability,-- | ----------- | ------- | ------- | -------- | ------------------------------------------------------------------------------------- |; | 1 | PRIMARY | job_groups | NULL | range | PRIMARY | 8 | 5420371 | 10.00 | Using where; Using index; Using temporary; Using filesort; Rematerialize (<derived3>) |; | 1 | PRIMARY | batches | NULL | eq_ref | PRIMARY | 8 | 1 | 50.00 | Using where |; | 1 | PRIMARY | billing_projects | NULL | eq_ref | PRIMARY | 302 | 1 | 100.00 | Using index |; | 1 | PRIMARY | job_groups_n_jobs_in_complete_states | NULL | eq_ref | PRIMARY | 12 | 1 | 100.00 | NULL |; | 1 | PRIMARY | job_groups_cancelled | NULL | ref | PRIMARY | 8 | 1 | 100.00 | Using index |; | 1 | PRIMARY | job_group_self_and_ancestors | NULL | eq_ref | PRIMARY | 16 | 1 | 100.00 | Using index |; | 1 | PRIMARY | billing_project_users | NULL | eq_ref | PRIMARY | 604 | 1 | 100.00 | Using index |; | 1 | PRIMARY | <derived3> | NULL | ALL | NULL | NULL | 2 | 100.00 | Using where |; | 3 | DEPENDENT DERIVED | <derived4> | NULL | ALL | NULL | NULL | 35 | 100.00 | NULL |; | 3 | DEPENDENT DERIVED | resources | NULL | eq_ref | resource_id | 4 | 1 | 100.00 | NULL |; | 4 | DEPENDENT DERIVED | aggregated_job_group_resources_v3 | NULL | ref | PRIMARY | 12 | 35 | 100.00 | Using temporary |. If I replace `ORDER BY batches.id DESC` with `ORDER BY job_groups.batch_id DESC` the query plan excludes a filesort. | id | select_type | table | partitions | type | key | key_len | rows | filtered | Extra |; | -- | ----------------- | ------------------------------------ | ---------- | ------ | ----------- | ------- | ------- | -------- | ------------------------------------------------------------------------- |; | 1 | PRIMARY | job_groups | NULL | range | PRIMARY | 8 | 5420371 | 10.00 | Using where; Backward index scan; Using index; Rematerialize (<derived3>) |; | 1 | PRIMARY | batches | NULL | eq_ref | PRIMARY | 8 | 1 | 50.00 | Using where |; | 1 | PRIMARY | billing_projects | NULL | eq_ref | PRIMARY | 302 | 1 ,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14377:3875,DEPEND,DEPENDENT,3875,https://hail.is,https://github.com/hail-is/hail/pull/14377,1,['DEPEND'],['DEPENDENT']
Integrability,----------------------------------------- |; | 1 | PRIMARY | job_groups | NULL | range | PRIMARY | 8 | 5420371 | 10.00 | Using where; Using index; Using temporary; Using filesort; Rematerialize (<derived3>) |; | 1 | PRIMARY | batches | NULL | eq_ref | PRIMARY | 8 | 1 | 50.00 | Using where |; | 1 | PRIMARY | billing_projects | NULL | eq_ref | PRIMARY | 302 | 1 | 100.00 | Using index |; | 1 | PRIMARY | job_groups_n_jobs_in_complete_states | NULL | eq_ref | PRIMARY | 12 | 1 | 100.00 | NULL |; | 1 | PRIMARY | job_groups_cancelled | NULL | ref | PRIMARY | 8 | 1 | 100.00 | Using index |; | 1 | PRIMARY | job_group_self_and_ancestors | NULL | eq_ref | PRIMARY | 16 | 1 | 100.00 | Using index |; | 1 | PRIMARY | billing_project_users | NULL | eq_ref | PRIMARY | 604 | 1 | 100.00 | Using index |; | 1 | PRIMARY | <derived3> | NULL | ALL | NULL | NULL | 2 | 100.00 | Using where |; | 3 | DEPENDENT DERIVED | <derived4> | NULL | ALL | NULL | NULL | 35 | 100.00 | NULL |; | 3 | DEPENDENT DERIVED | resources | NULL | eq_ref | resource_id | 4 | 1 | 100.00 | NULL |; | 4 | DEPENDENT DERIVED | aggregated_job_group_resources_v3 | NULL | ref | PRIMARY | 12 | 35 | 100.00 | Using temporary |. If I replace `ORDER BY batches.id DESC` with `ORDER BY job_groups.batch_id DESC` the query plan excludes a filesort. | id | select_type | table | partitions | type | key | key_len | rows | filtered | Extra |; | -- | ----------------- | ------------------------------------ | ---------- | ------ | ----------- | ------- | ------- | -------- | ------------------------------------------------------------------------- |; | 1 | PRIMARY | job_groups | NULL | range | PRIMARY | 8 | 5420371 | 10.00 | Using where; Backward index scan; Using index; Rematerialize (<derived3>) |; | 1 | PRIMARY | batches | NULL | eq_ref | PRIMARY | 8 | 1 | 50.00 | Using where |; | 1 | PRIMARY | billing_projects | NULL | eq_ref | PRIMARY | 302 | 1 | 100.00 | Using index |; | 1 | PRIMARY | job_groups_n_jobs_in_complete_states | NULL | eq_ref,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14377:3963,DEPEND,DEPENDENT,3963,https://hail.is,https://github.com/hail-is/hail/pull/14377,1,['DEPEND'],['DEPENDENT']
Integrability,"-----------------------------------------------------------------. ### Hail version:; 0.2-a2eaf89baa0c; ### What you did:; Executed first four lines in https://github.com/hail-is/hail/blob/master/hail/python/hail/docs/tutorials/01-genome-wide-association-study.ipynb; ### What went wrong (all error messages here, including the full java stack trace):. ```; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-4-758eefccad3d> in <module>; ----> 1 hl.import_vcf('data/1kg.vcf.bgz').write('data/1kg.mt', overwrite=True). <decorator-gen-1074> in import_vcf(path, force, force_bgz, header_file, min_partitions, drop_samples, call_fields, reference_genome, contig_recoding, array_elements_required, skip_invalid_loci). ~/bin/anaconda3/lib/python3.6/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 558 def wrapper(__original_func, *args, **kwargs):; 559 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 560 return __original_func(*args_, **kwargs_); 561 ; 562 return wrapper. ~/bin/anaconda3/lib/python3.6/site-packages/hail/methods/impex.py in import_vcf(path, force, force_bgz, header_file, min_partitions, drop_samples, call_fields, reference_genome, contig_recoding, array_elements_required, skip_invalid_loci); 1893 skip_invalid_loci,; 1894 force_bgz,; -> 1895 force; 1896 ); 1897 return MatrixTable(jmt). ~/bin/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. ~/bin/anaconda3/lib/python3.6/site-packages/hail/utils/java.py in deco(*args, **kwargs); 208 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 209 'Hail version: %s\n'; --> 210 'Error summary: %s' % (deepest, full, hail.__version__, deep",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4775:1039,wrap,wrapper,1039,https://hail.is,https://github.com/hail-is/hail/issues/4775,3,['wrap'],['wrapper']
Integrability,"----------------------------------------------------------------. ### Hail version:. devel-406fc7f6af42. ### What you did:. Calling `export_elasticsearch` without a `config` argument works fine.; ```python; hl.export_elasticsearch(table, ""host"", 9200, ""someindex"", ""sometype"", 1000, config=None); ```. However, attempting to pass `config`, for example:; ```python; es_config = {""es.write.operation"": ""index""}; hl.export_elasticsearch(table, ""host"", 9200, ""someindex"", ""sometype"", 1000, config=es_config); ```; causes the following error:. ### What went wrong (all error messages here, including the full java stack trace):. ```; Traceback (most recent call last):; File ""/tmp/0ba8fc2c770d4b2ba96dc23c50fd6eab/load_clinvar_to_es.py"", line 105, in <module>; verbose=True,; File ""/tmp/0ba8fc2c770d4b2ba96dc23c50fd6eab/hail_v02_scripts.zip/hail_v02_scripts/utils/elasticsearch/client.py"", line 234, in export_table_to_elasticsearch; File ""/home/hail/hail.zip/hail/typecheck/check.py"", line 547, in wrapper; File ""/home/hail/hail.zip/hail/methods/impex.py"", line 1885, in export_elasticsearch; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/home/hail/hail.zip/hail/utils/java.py"", line 188, in deco; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py"", line 323, in get_return_value; py4j.protocol.Py4JError: An error occurred while calling z:is.hail.io.ElasticsearchConnector.export. Trace:; py4j.Py4JException: Method export([class is.hail.table.Table, class java.lang.String, class java.lang.Integer, class java.lang.String, class java.lang.String, class java.lang.Integer, class java.util.HashMap, class java.lang.Boolean]) does not exist; 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318); 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:339); 	at py4j.Gateway.invoke(Gateway.java:274); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4063:1163,wrap,wrapper,1163,https://hail.is,https://github.com/hail-is/hail/issues/4063,1,['wrap'],['wrapper']
Integrability,"------------------------------------------------------; RuntimeError Traceback (most recent call last); File ~/miniconda3/lib/python3.10/site-packages/hailtop/hail_event_loop.py:12, in hail_event_loop(); 11 try:; ---> 12 asyncio.get_running_loop(); 13 nest_asyncio.apply(). RuntimeError: no running event loop. During handling of the above exception, another exception occurred:. RuntimeError Traceback (most recent call last); Cell In[2], line 1; ----> 1 hl.init(). File <decorator-gen-1760>:2, in init(sc, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmp_dir, default_reference, idempotent, global_seed, spark_conf, skip_logging_configuration, local_tmpdir, _optimizer_iterations, backend, driver_cores, driver_memory, worker_cores, worker_memory, gcs_requester_pays_configuration, regions, gcs_bucket_allow_list). File ~/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py:587, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 584 @decorator; 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_). File ~/miniconda3/lib/python3.10/site-packages/hail/context.py:357, in init(sc, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmp_dir, default_reference, idempotent, global_seed, spark_conf, skip_logging_configuration, local_tmpdir, _optimizer_iterations, backend, driver_cores, driver_memory, worker_cores, worker_memory, gcs_requester_pays_configuration, regions, gcs_bucket_allow_list); 354 backend = 'batch'; 356 if backend == 'batch':; --> 357 return hail_event_loop().run_until_complete(init_batch(; 358 log=log,; 359 quiet=quiet,; 360 append=append,; 361 tmpdir=tmp_dir,; 362 local_tmpdir=local_tmpdir,; 363 default_reference=default_reference,; 364 global_seed=global_seed,; 365 driver_cores=driver_cores,; 366 driver_memory=driver",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14099:1627,wrap,wrapper,1627,https://hail.is,https://github.com/hail-is/hail/issues/14099,2,['wrap'],['wrapper']
Integrability,"--------------------------------; IncompleteParseError Traceback (most recent call last); <ipython-input-2-ebe253e83367> in <module>(); 1 phesant_still_more1 = hl.import_table('gs://ukb31063-mega-gwas/phenotype-files/still-more-phesant/neale_lab_parsed_and_restricted_to_QCed_samples_cat_variables_both_sexes.1.tsv',; ----> 2 missing='',impute=True,types={'all_sexes$userId':hl.tstr}).rename({'all_sexes$userId':'s'}); 3 # phesant_still_more2 = hl.import_table('gs://ukb31063-mega-gwas/phenotype-files/still-more-phesant/neale_lab_parsed_and_restricted_to_QCed_samples_cat_variables_both_sexes.2.tsv',; 4 # missing='',impute=True,types={'all_sexes$userId':hl.tstr}). <decorator-gen-1108> in import_table(paths, key, min_partitions, impute, no_header, comment, delimiter, missing, types, quote, skip_blank_lines, force_bgz). /home/hail/hail.zip/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 558 def wrapper(__original_func, *args, **kwargs):; 559 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 560 return __original_func(*args_, **kwargs_); 561; 562 return wrapper. /home/hail/hail.zip/hail/methods/impex.py in import_table(paths, key, min_partitions, impute, no_header, comment, delimiter, missing, types, quote, skip_blank_lines, force_bgz); 1327 delimiter, missing, no_header, impute, quote,; 1328 skip_blank_lines, force_bgz); -> 1329 return Table._from_java(jt); 1330; 1331. /home/hail/hail.zip/hail/table.py in _from_java(jt); 319 @staticmethod; 320 def _from_java(jt):; --> 321 return Table(JavaTable(jt.tir())); 322; 323 def __init__(self, tir):. /home/hail/hail.zip/hail/table.py in __init__(self, tir); 328 Env.hc()._jhc, Env.hc()._backend._to_java_ir(self._tir)); 329; --> 330 self._type = self._tir.typ; 331; 332 self._row_axis = 'row'. /home/hail/hail.zip/hail/ir/base_ir.py in typ(self); 78 def typ(self):; 79 jtir = Env.hc()._backend._to_java_ir(self); ---> 80 return ttable._from_java(jtir.typ()); 81; 82 def parse",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5119:1518,wrap,wrapper,1518,https://hail.is,https://github.com/hail-is/hail/issues/5119,3,['wrap'],['wrapper']
Integrability,"--------------------------; FatalError Traceback (most recent call last); Cell In[10], [line 5](vscode-notebook-cell:?execution_count=10&line=5); [1](vscode-notebook-cell:?execution_count=10&line=1) (; [2](vscode-notebook-cell:?execution_count=10&line=2) mt.filter_rows(selected_variants.contains(mt.rsid)); [3](vscode-notebook-cell:?execution_count=10&line=3) .select_rows('rsid'); [4](vscode-notebook-cell:?execution_count=10&line=4) .select_entries('GT'); ----> [5](vscode-notebook-cell:?execution_count=10&line=5) ).make_table().take(1). File .../python3.10/site-packages/decorator.py:232, in decorate.<locals>.fun(*args, **kw); [230](.../python3.10/site-packages/decorator.py:230) if not kwsyntax:; [231](.../python3.10/site-packages/decorator.py:231) args, kw = fix(args, kw, sig); --> [232](.../python3.10/site-packages/decorator.py:232) return caller(func, *(extras + args), **kw). File .../python3.10/site-packages/hail/typecheck/check.py:584, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); [581](.../python3.10/site-packages/hail/typecheck/check.py:581) @decorator; [582](.../python3.10/site-packages/hail/typecheck/check.py:582) def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; [583](.../python3.10/site-packages/hail/typecheck/check.py:583) args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> [584](.../python3.10/site-packages/hail/typecheck/check.py:584) return __original_func(*args_, **kwargs_). File .../python3.10/site-packages/hail/table.py:2426, in Table.take(self, n, _localize); [2392](.../python3.10/site-packages/hail/table.py:2392) @typecheck_method(n=int, _localize=bool); [2393](.../python3.10/site-packages/hail/table.py:2393) def take(self, n, _localize=True):; [2394](.../python3.10/site-packages/hail/table.py:2394) """"""Collect the first `n` rows of the table into a local list.; [2395](.../python3.10/site-packages/hail/table.py:2395) ; [2396](.../python3.10/site-packages/hail/table.py:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14362:2426,wrap,wrapper,2426,https://hail.is,https://github.com/hail-is/hail/issues/14362,1,['wrap'],['wrapper']
Integrability,"----------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **265/1000** <br/> **Why?** CVSS 5.3 | Denial of Service (DoS) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6050294](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6050294) | `cryptography:` <br> `41.0.7 -> 42.0.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **402/1000** <br/> **Why?** Proof of Concept exploit, CVSS 5.9 | Information Exposure <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6126975](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6126975) | `cryptography:` <br> `41.0.7 -> 42.0.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJkYWIzNjU3Mi1hNTUwLTQwY2EtYThjZi0zN2ZjODljOWI1OGEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImRhYjM2NTcyLWE1NTAtNDBjYS1hOGNmLTM3ZmM4OWM5YjU4YSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14201:1919,depend,dependency,1919,https://hail.is,https://github.com/hail-is/hail/pull/14201,2,['depend'],"['dependencies', 'dependency']"
Integrability,"----------------; Key: ['i', 'j']; ----------------------------------------; ```. and tie_breaker is :. ```; def tie_breaker(l, r):; return hl.or_else(l.rank, max_rank + 1) - hl.or_else(r.rank, max_rank + 1); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; FatalError Traceback (most recent call last); <ipython-input-220-88e7ce1066ed> in <module>; 11 return hl.or_else(l.rank, max_rank + 1) - hl.or_else(r.rank, max_rank + 1); 12 ; ---> 13 related_samples_to_drop_ranked = hl.maximal_independent_set(related_pairs.id1_rank, related_pairs.id2_rank,keep=False, tie_breaker=tie_breaker); 14 #return related_samples_to_drop_ranked.select(**related_samples_to_drop_ranked.node.id).key_by('data_type', 's'). <decorator-gen-1024> in maximal_independent_set(i, j, keep, tie_breaker). /home/hail/hail.zip/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 558 def wrapper(__original_func, *args, **kwargs):; 559 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 560 return __original_func(*args_, **kwargs_); 561 ; 562 return wrapper. /home/hail/hail.zip/hail/methods/misc.py in maximal_independent_set(i, j, keep, tie_breaker); 142 ; 143 edges = t.key_by().select('i', 'j'); --> 144 nodes_in_set = Env.hail().utils.Graph.maximalIndependentSet(edges._jt.collect(), node_t._jtype, joption(tie_breaker_str)); 145 ; 146 nt = Table._from_java(nodes._jt.annotateGlobal(nodes_in_set, hl.tset(node_t)._jtype, 'nodes_in_set')). /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134 ; 1135 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 208 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 209 'Hail version: %s\n'; --> 210 'Error summary: %s' % (deepest, ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4857:1597,wrap,wrapper,1597,https://hail.is,https://github.com/hail-is/hail/issues/4857,3,['wrap'],['wrapper']
Integrability,"-------------; Row fields:; 'locus': locus<GRCh38>; 'alleles': array<str>; 'rsid': str; ----------------------------------------; Entry fields:; 'LA': array<int32>; 'LGT': call; 'LAD': array<int32>; 'LPGT': str # BROKEN, should be ""call""; 'LPL': array<int32>; 'RGQ': int32; 'gvcf_info': struct {; […etc…]; ```. Hence the problem appears to be in the combining and I suspect may have been caused by PR #13206. Any hints on where this field may have been reverted to a `StringExpression` in the new combiner code? I can try to debug this further, or is this enough to go on for those familiar with this code?. ### Version. 0.2.120 (worked as expected in 0.2.119 and prior). ### Relevant log output. ```shell; cpg_workflows/large_cohort/dense_subset.py:24: in run; vds = hl.vds.split_multi(vds, filter_changed_loci=True); <decorator-gen-1858>:2: in split_multi; ???; /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/typecheck/check.py:584: in wrapper; return __original_func(*args_, **kwargs_); /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/vds/methods.py:766: in split_multi; variant_data = hl.experimental.sparse_split_multi(vds.variant_data, filter_changed_loci=filter_changed_loci); /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/experimental/sparse_mt/sparse_split_multi.py:206: in sparse_split_multi; entries: ds[entries].map(transform_entries); <decorator-gen-564>:2: in map; ???; /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/typecheck/check.py:584: in wrapper; return __original_func(*args_, **kwargs_); /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/expr/expressions/typed_expressions.py:309: in map; array_map = hl.array(self)._ir_lambda_method(transform_ir, f, self._type.element_type, lambda t: self._type.__class__(t)); /opt/hostedtoolcache/Python/3.10.12/x64/lib/python3.10/site-packages/hail/expr/expressions/base_expression.py:706: in _ir_lambda_method",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13337:2040,wrap,wrapper,2040,https://hail.is,https://github.com/hail-is/hail/issues/13337,1,['wrap'],['wrapper']
Integrability,"---. ### Hail version:; 0.2; ### What you did:; users = hl.read_table('data/users.ht'); hl.export_elasticsearch(users, 'XX.XXX.XXX.XXX', 32565, 'users', 'movies', 200,config=None, verbose=True ). ### What went wrong (all error messages here, including the full java stack trace):; Gotten this error even though the elasticsearch IP and port number 32565 is correct. The IP mentioned in the error 192.168.185.157:9200 was not found anywhere in our EMR or elasticsearch cluster. ; >>> hl.export_elasticsearch(users, 'XX.XXX.XXX.XXX', 32565, 'users', 'movies', 200,config=None, verbose=True ); Config Map(es.nodes -> XX.XXX.XXX.XXX, es.port -> 32565, es.batch.size.entries -> 200, es.index.auto.create -> true); [Stage 0:> (0 + 32) / 65]Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""</usr/local/lib/python3.6/site-packages/decorator.py:decorator-gen-1122>"", line 2, in export_elasticsearch; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/typecheck/check.py"", line 561, in wrapper; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/methods/impex.py"", line 2106, in export_elasticsearch; File ""/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 227, in deco; hail.utils.java.FatalError: EsHadoopNoNodesLeftException: Connection error (check network and/or proxy settings)- all nodes failed; tried [[192.168.185.157:9200, 192.168.81.209:9200]] . Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 73, ip-172-31-10-234.ap-southeast-1.compute.internal, executor 3): org.elasticsearch.hadoop.rest.EsHadoopNoNodesLeftException: Connection error (check network and/or proxy settings)- all nodes failed; tried [[192.168.185.157:9200, 192.168.81.209:9200]]",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5643:1263,wrap,wrapper,1263,https://hail.is,https://github.com/hail-is/hail/issues/5643,1,['wrap'],['wrapper']
Integrability,"-05-04)<!-- raw HTML omitted --></h2>; <ul>; <li>fix: inline js and css paths for virtual html (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/7993"">#7993</a>) (<a href=""https://github.com/vitejs/vite/commit/d49e3fb"">d49e3fb</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/7993"">#7993</a></li>; <li>fix: only handle merge ssr.noExternal (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8003"">#8003</a>) (<a href=""https://github.com/vitejs/vite/commit/642d65b"">642d65b</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8003"">#8003</a></li>; <li>fix: optimized processing folder renaming in win (fix <a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/7939"">#7939</a>) (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8019"">#8019</a>) (<a href=""https://github.com/vitejs/vite/commit/e5fe1c6"">e5fe1c6</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/7939"">#7939</a> <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8019"">#8019</a></li>; <li>fix(css): do not clean id when passing to postcss (fix <a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/7822"">#7822</a>) (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/7827"">#7827</a>) (<a href=""https://github.com/vitejs/vite/commit/72f17f8"">72f17f8</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/7822"">#7822</a> <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/7827"">#7827</a></li>; <li>fix(css): var in image-set (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/7921"">#7921</a>) (<a href=""https://github.com/vitejs/vite/commit/e96b908"">e96b908</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/7921"">#7921</a></li>; <li>fix(ssr): allow ssrTransform to parse hashbang (<a href=""https://github.com/vitejs/vite/tr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12142:9477,depend,dependabot,9477,https://hail.is,https://github.com/hail-is/hail/pull/12142,2,['depend'],['dependabot']
Integrability,"-22)</p>; <ul>; <li>Changes order of items for REMOVE section of generated patches when; <code>swap</code> is called so the list items are removed from the end. (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/85"">#85</a>)</li>; <li>Improves API documentation for <code>ignore</code> argument in <code>diff</code> function.; (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/79"">#79</a>)</li>; <li>Executes doctests during PyTest invocation.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/inveniosoftware/dictdiffer/commit/36506e4046e07e4d43e0b5af6f76c75ff7b2b6a3""><code>36506e4</code></a> ci: remove compilie_catalog</li>; <li><a href=""https://github.com/inveniosoftware/dictdiffer/commit/2cc6ff223bdc2f2fa6b3a1842c68fc12d9555645""><code>2cc6ff2</code></a> release: v0.9.0 (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/161"">#161</a>)</li>; <li><a href=""https://github.com/inveniosoftware/dictdiffer/commit/d2f84b7dbe5e2ea871c25f7cb013d36e3be221e8""><code>d2f84b7</code></a> diff: add support for absolute tolerance of floats (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/152"">#152</a>)</li>; <li><a href=""https://github.com/inveniosoftware/dictdiffer/commit/fb2064ad9400c3b1c46a9c5cc58a0d509b1c99fd""><code>fb2064a</code></a> global: drop support for Python&lt;3.5 (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/160"">#160</a>)</li>; <li><a href=""https://github.com/inveniosoftware/dictdiffer/commit/02446475a71a22de6f7ee3d1aba2655e625c8e31""><code>0244647</code></a> testing: add <code>assert_no_diff</code> helper to assist pytest users (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/153"">#153</a>)</li>; <li><a href=""https://github.com/inveniosoftware/dictdiffer/commi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11485:6145,depend,dependabot,6145,https://hail.is,https://github.com/hail-is/hail/pull/11485,1,['depend'],['dependabot']
Integrability,"-27)</h2>; <h3>⚠ BREAKING CHANGES</h3>; <ul>; <li>make logging API more friendly to use (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/422"">#422</a>)</li>; <li>api consistency between HTTP and Gapic layers (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/375"">#375</a>)</li>; <li>support string-encoded json (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/339"">#339</a>)</li>; <li>Infer default resource in logger (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/315"">#315</a>)</li>; <li>support json logs (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/316"">#316</a>)</li>; <li>deprecate AppEngineHandler and ContainerEngineHandler (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/310"">#310</a>)</li>; </ul>; <h3>Features</h3>; <ul>; <li>add api key support (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/472"">#472</a>) (<a href=""https://github.com/googleapis/python-logging/commit/81ca8c616acb988be1fbecfc2a0b1a5b39280149"">81ca8c6</a>)</li>; <li>add json_fields extras argument for adding to jsonPayload (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/447"">#447</a>) (<a href=""https://github.com/googleapis/python-logging/commit/a760e02371a55d6262e42de9e0222fffa2c7192b"">a760e02</a>)</li>; <li>avoid importing grpc when explicitly disabled (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/416"">#416</a>) (<a href=""https://github.com/googleapis/python-logging/commit/818213e143d6a1941211a48e0b23069a426ac300"">818213e</a>)</li>; <li>Infer default resource in logger (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/315"">#315</a>) (<a href=""https://github.com/googleapis/python-logging/commit/c63250399fcd6e1317d341e98fab11095c443e5e"">c632503</a>)</li>; <li>make lo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11574:1401,depend,dependabot,1401,https://hail.is,https://github.com/hail-is/hail/pull/11574,2,['depend'],['dependabot']
Integrability,"-398>:2: in export_vcf; ???; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _. func = <function export_vcf at 0x7fa13c4d9938>, args = (<hail.dataset.VariantDataset object at 0x7fa13c3c9390>, 'file:///scratch/test_vcf_export.vcf.bgz', None, False, False), kwargs = {}; e = Py4JJavaError(u'An error occurred while calling o160.exportVCF.\n', JavaObject id=o162), tpl = JavaObject id=o210; deepest = 'ClassNotFoundException: Class org.apache.hadoop.mapred.DirectFileOutputCommitter not found'; full = 'java.lang.RuntimeException: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.map...mmand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748). '. @decorator; def handle_py4j(func, *args, **kwargs):; try:; r = func(*args, **kwargs); except py4j.protocol.Py4JJavaError as e:; tpl = Env.jutils().handleForPython(e.java_exception); deepest, full = tpl._1(), tpl._2(); raise FatalError('%s\n\nJava stack trace:\n%s\n'; 'Hail version: %s\n'; > 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); E FatalError: ClassNotFoundException: Class org.apache.hadoop.mapred.DirectFileOutputCommitter not found; E; E Java stack trace:; E java.lang.RuntimeException: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.mapred.DirectFileOutputCommitter not found; E at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2227); E at org.apache.hadoop.mapred.JobConf.getOutputCommitter(JobConf.java:726); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1051); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1035); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(Pai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3946:3179,protocol,protocol,3179,https://hail.is,https://github.com/hail-is/hail/issues/3946,1,['protocol'],['protocol']
Integrability,"-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/da4f3c3f209aea47d69c4faf90029a6933bd3a60""><code>da4f3c3</code></a> [DOCS] Add 8.5.3 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2045"">#2045</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2050"">#2050</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/79d592abdce1cd90845d153afab8b66069e2a172""><code>79d592a</code></a> [DOCS] Add 8.5.2 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2042"">#2042</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2049"">#2049</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/712f518822ff281abdd6f83c2e0ea97857dbf6ba""><code>712f518</code></a> [DOCS] Add 8.5.1 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2040"">#2040</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/0a8e0bca839408ba7cdd4e1e4ef669894f29e96f""><code>0a8e0bc</code></a> [DOCS] Add 8.5.0 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2032"">#2032</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/4d09926f840998a20d4f45380723d2d77b46544a""><code>4d09926</code></a> [DOCS] Add 8.4.3 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2028"">#2028</a>)</li>; <li><a h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12601:2585,depend,dependabot,2585,https://hail.is,https://github.com/hail-is/hail/pull/12601,1,['depend'],['dependabot']
Integrability,"-api-core/commit/8f73d2ee2d3af2201f877aa7e2f7361147759dc7""><code>8f73d2e</code></a> fix(deps): allow protobuf &lt; 5.0.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/400"">#400</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-core/commit/5da6733a475c436efc11b14889af73b3a0e20379""><code>5da6733</code></a> fix: drop support for grpc-gcp (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/401"">#401</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-core/commit/e92045b7a34b8d0a6374d6b1f67c1c6095ad33c6""><code>e92045b</code></a> chore: test minimum dependencies in python 3.7 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/397"">#397</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-core/commit/0eb727f92314db3c4383754514f75a49ba02e27b""><code>0eb727f</code></a> docs: Fix typo in the BackgroundConsumer docstring (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/395"">#395</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-core/commit/ac266e935bc4e7c6dff250384407e7a60d8dba90""><code>ac266e9</code></a> docs: fix changelog header to consistent size (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/394"">#394</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-core/commit/0c4668df73ac3989170ea5677f906f147a9560d0""><code>0c4668d</code></a> chore: allow releases from older version branches (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/388"">#388</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-core/commit/9be727df7fb19d7264c81eab9cc8b6de63f6117e""><code>9be727d</code></a> chore(main): release 2.8.1 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/386"">#386</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-core/commit/d84d66c2a4107f5f9a20c53e870a27fb1250",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11970:9348,depend,dependabot,9348,https://hail.is,https://github.com/hail-is/hail/pull/11970,1,['depend'],['dependabot']
Integrability,"-asyncio/commit/ef3b3477070d6a270e1bb2c1d438c64dba42724c""><code>ef3b347</code></a> Build(deps): Bump packaging from 23.2 to 24.0 in /dependencies/default</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/b22d84e1f0d53920352be4c66d1b6c7f7a9ce005""><code>b22d84e</code></a> [docs] Fixes the example showing how to run all tests in a session-scoped loop.</li>; <li>Additional commits viewable in <a href=""https://github.com/pytest-dev/pytest-asyncio/compare/v0.21.1...v0.23.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest-asyncio&package-manager=pip&previous-version=0.21.1&new-version=0.23.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major versio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14507:9672,depend,dependabot,9672,https://hail.is,https://github.com/hail-is/hail/pull/14507,1,['depend'],['dependabot']
Integrability,"-ci-update-config</li>; <li>Additional commits viewable in <a href=""https://github.com/sass/libsass-python/compare/0.19.2...0.21.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=libsass&package-manager=pip&previous-version=0.19.2&new-version=0.21.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11508:6368,Depend,Dependabot,6368,https://hail.is,https://github.com/hail-is/hail/pull/11508,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"-cloud-core/commit/2dd10a7b737efc6b45cd9ff0d13efeaaa6cbdc88""><code>2dd10a7</code></a> chore(deps): update actions/setup-python action to v4 (<a href=""https://github-redirect.dependabot.com/googleapis/python-cloud-core/issues/197"">#197</a>)</li>; <li><a href=""https://github.com/googleapis/python-cloud-core/commit/3277c60102803deaae17f665b3f2f80087dd1e0f""><code>3277c60</code></a> fix: require python 3.7+ (<a href=""https://github-redirect.dependabot.com/googleapis/python-cloud-core/issues/201"">#201</a>)</li>; <li><a href=""https://github.com/googleapis/python-cloud-core/commit/1bc7354261e2fcb8426d269d0083d2d993fafe66""><code>1bc7354</code></a> chore(main): release 2.3.1 (<a href=""https://github-redirect.dependabot.com/googleapis/python-cloud-core/issues/195"">#195</a>)</li>; <li><a href=""https://github.com/googleapis/python-cloud-core/commit/1b79d69cdb156ae21dddb5ab7579f6c08fd701b8""><code>1b79d69</code></a> docs: fix changelog header to consistent size (<a href=""https://github-redirect.dependabot.com/googleapis/python-cloud-core/issues/194"">#194</a>)</li>; <li><a href=""https://github.com/googleapis/python-cloud-core/commit/66d0e8692123021ae76d5d0802c130ba05cce181""><code>66d0e86</code></a> chore(python): auto approve template changes (<a href=""https://github-redirect.dependabot.com/googleapis/python-cloud-core/issues/193"">#193</a>)</li>; <li><a href=""https://github.com/googleapis/python-cloud-core/commit/a41c3a78fd6611a4e0e0044f25b1af36bcf3ca6b""><code>a41c3a7</code></a> chore: [autoapprove] update readme_gen.py to include autoescape True (<a href=""https://github-redirect.dependabot.com/googleapis/python-cloud-core/issues/191"">#191</a>)</li>; <li><a href=""https://github.com/googleapis/python-cloud-core/commit/3f64dde56a5ebd3941cac91f68c2be250978a9c6""><code>3f64dde</code></a> chore(python): use ubuntu 22.04 in docs image (<a href=""https://github-redirect.dependabot.com/googleapis/python-cloud-core/issues/190"">#190</a>)</li>; <li><a href=""https://github.com/googleapis/python-c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12175:8365,depend,dependabot,8365,https://hail.is,https://github.com/hail-is/hail/pull/12175,1,['depend'],['dependabot']
Integrability,"-commit autoupdate</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/0414bb9f81cc1856ea021504eecd22d202462f1d""><code>0414bb9</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-metadata/issues/46"">#46</a> from pytest-dev/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/025be8999a22ae395b0e2b8ae4e7c9fa2334f874""><code>025be89</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/429840f4de26276560961929f21aab79ed305875""><code>429840f</code></a> Avoid running nightly on forks</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/c1968f39609978ec9c6a4bcf91c37c6164483f04""><code>c1968f3</code></a> Fix nightly</li>; <li>See full diff in <a href=""https://github.com/pytest-dev/pytest-metadata/compare/v2.0.1...v2.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest-metadata&package-manager=pip&previous-version=2.0.1&new-version=2.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel m",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12188:2309,Depend,Dependabot,2309,https://hail.is,https://github.com/hail-is/hail/pull/12188,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/sass/libsass-python/commit/e836a7e7c3778ac34a8bd117c2ce701209097cd5""><code>e836a7e</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sass/libsass-python/issues/339"">#339</a> from sass/pre-commit-ci-update-config</li>; <li>Additional commits viewable in <a href=""https://github.com/sass/libsass-python/compare/0.19.2...0.21.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=libsass&package-manager=pip&previous-version=0.19.2&new-version=0.21.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11508:6211,depend,dependabot-automerge-start,6211,https://hail.is,https://github.com/hail-is/hail/pull/11508,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,-dev/pytest-html/issues/282&amp;gt;`_). * Thanks to `@ssbarnea &amp;lt;https://github.com/ssbarnea&amp;gt;`_ for reporting and `@christiansandberg &amp;lt;https://github.com/christiansandberg&amp;gt;`_ for the fix. 2.1.0 (2020-03-09); &lt;/code&gt;&lt;/pre&gt;; &lt;!-- raw HTML omitted --&gt;; &lt;/blockquote&gt;; &lt;p&gt;... (truncated)&lt;/p&gt;; &lt;/details&gt;; &lt;details&gt;; &lt;summary&gt;Commits&lt;/summary&gt;. &lt;ul&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/a1639ef4d9bdc89daa037fd0bfc003bdf2e99865&quot;&gt;&lt;code&gt;a1639ef&lt;/code&gt;&lt;/a&gt; Update CHANGES.rst (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/411&quot;&gt;#411&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/727b305a5707a937b427894360eba11c402b1755&quot;&gt;&lt;code&gt;727b305&lt;/code&gt;&lt;/a&gt; Enable camelcase eslint rule (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/410&quot;&gt;#410&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/dade11a7a1281ca3060bf1149fdc1d6d0763c97e&quot;&gt;&lt;code&gt;dade11a&lt;/code&gt;&lt;/a&gt; fixed css sort tringles (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/409&quot;&gt;#409&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/e00532d9c8a598fb848d16b0ce23665789e3517a&quot;&gt;&lt;code&gt;e00532d&lt;/code&gt;&lt;/a&gt; Use scss nesting &amp;amp; variables (&lt;a href=&quot;https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/393&quot;&gt;#393&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/pytest-dev/pytest-html/commit/9bd4907682f10849dde1fe866b5a71402c74e551&quot;&gt;&lt;code&gt;9bd4907&lt;/code&gt;&lt;/a&gt; remove all read the doc documentation from the repo (&lt;a href=&quot;https://github-redirect.de,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11524:13979,depend,dependabot,13979,https://hail.is,https://github.com/hail-is/hail/pull/11524,1,['depend'],['dependabot']
Integrability,"-dev/sphinx-autodoc-typehints/issues/208"">#208</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/d770c69c1e6c7e4a809a145140cfc1033eac57dd""><code>d770c69</code></a> Fix fully_qualified should be typehints_fully_qualified (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/204"">#204</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/compare/1.11.1...1.17.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx-autodoc-typehints&package-manager=pip&previous-version=1.11.1&new-version=1.17.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11503:6283,depend,dependabot,6283,https://hail.is,https://github.com/hail-is/hail/pull/11503,2,['depend'],['dependabot']
Integrability,"-download-task/commit/34e2dd41477f18b1ae3d6d5a71dca5449d6cd1e0""><code>34e2dd4</code></a> Downgrade slf4j to fix warning on console about missing slf4j provider</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/b3fa29f9ffb4d4544e13ef84601e371fb2778ddf""><code>b3fa29f</code></a> Revert &quot;Update Apache HttpClient to 5.2.1&quot;</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/01f05e046be0dca18f506723c79e88f208336e71""><code>01f05e0</code></a> Add integration tests for Gradle 6.9.3 and 7.6</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a998a544908a8b39f713f4526f717fcb328c06eb""><code>a998a54</code></a> Upgrade Gradle to 7.6</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/5.3.0...5.3.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=5.3.0&new-version=5.3.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12707:3372,depend,dependency-name,3372,https://hail.is,https://github.com/hail-is/hail/pull/12707,1,['depend'],['dependency-name']
Integrability,"-for-python/commit/5166ee94acdb80f2217a1ce694e169ea2b33219d""><code>5166ee9</code></a> [Storage] Fix <code>upload_blob()</code> from an OS pipe on Linux (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23211"">#23211</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-storage-blob_12.8.1...azure-storage-blob_12.11.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=azure-storage-blob&package-manager=pip&previous-version=12.8.1&new-version=12.11.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11703:6813,depend,dependabot-automerge-start,6813,https://hail.is,https://github.com/hail-is/hail/pull/11703,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"-input-7-5fec92db8e26> in <module>; ----> 1 mt = hl.experimental.load_dataset(name='1000_Genomes_chrMT',; 2 version='phase_3',; 3 reference_genome='GRCh37',; 4 region='us',; 5 cloud='gcp'). ~/miniconda3/envs/hail-env/lib/python3.9/site-packages/hail/experimental/datasets.py in load_dataset(name, version, reference_genome, region, cloud); 109 return hl.read_table(path); 110 elif path.endswith('.mt'):; --> 111 return hl.read_matrix_table(path); 112 elif path.endswith('.bm'):; 113 return hl.linalg.BlockMatrix.read(path). ~/miniconda3/envs/hail-env/lib/python3.9/site-packages/decorator.py in fun(*args, **kw); 230 if not kwsyntax:; 231 args, kw = fix(args, kw, sig); --> 232 return caller(func, *(extras + args), **kw); 233 fun.__name__ = func.__name__; 234 fun.__doc__ = func.__doc__. ~/miniconda3/envs/hail-env/lib/python3.9/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 575 def wrapper(__original_func, *args, **kwargs):; 576 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 577 return __original_func(*args_, **kwargs_); 578 ; 579 return wrapper. ~/miniconda3/envs/hail-env/lib/python3.9/site-packages/hail/methods/impex.py in read_matrix_table(path, _intervals, _filter_intervals, _drop_cols, _drop_rows, _n_partitions); 2009 :class:`.MatrixTable`; 2010 """"""; -> 2011 for rg_config in Env.backend().load_references_from_dataset(path):; 2012 hl.ReferenceGenome._from_config(rg_config); 2013 . ~/miniconda3/envs/hail-env/lib/python3.9/site-packages/hail/backend/spark_backend.py in load_references_from_dataset(self, path); 321 ; 322 def load_references_from_dataset(self, path):; --> 323 return json.loads(Env.hail().variant.ReferenceGenome.fromHailDataset(self.fs._jfs, path)); 324 ; 325 def from_fasta_file(self, name, fasta_file, index_file, x_contigs, y_contigs, mt_contigs, par):. ~/miniconda3/envs/hail-env/lib/python3.9/site-packages/py4j/java_gateway.py in __call__(self, *args); 1302 ; 1303 answer = sel",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10530:1544,wrap,wrapper,1544,https://hail.is,https://github.com/hail-is/hail/issues/10530,3,['wrap'],['wrapper']
Integrability,"-java/commit/47e36b651e9abc80f8d711cbff69c821539851c2""><code>47e36b6</code></a> Updating CODEOWNERS for Communication Identity &amp; Common Packages (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32222"">#32222</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/c051757b394000308e0a79bcb93da05875892401""><code>c051757</code></a> Increment package versions for cosmos releases (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32209"">#32209</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-java/compare/v1.2.1...azure-identity_1.7.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.azure:azure-identity&package-manager=gradle&previous-version=1.2.1&new-version=1.7.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12508:4658,depend,dependabot-security-updates,4658,https://hail.is,https://github.com/hail-is/hail/pull/12508,1,['depend'],['dependabot-security-updates']
Integrability,"-libs/aiodocker/commit/e2ed71db8f29012899e115ba9a3082bb76142173""><code>e2ed71d</code></a> Upgrade to GitHub-native Dependabot (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/577"">#577</a>)</li>; <li><a href=""https://github.com/aio-libs/aiodocker/commit/a6644f3fa00222f4d8df1cc9bc4eb3de025486b6""><code>a6644f3</code></a> Bump mypy from 0.902 to 0.910 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/595"">#595</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiodocker/compare/v0.17.0...v0.21.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiodocker&package-manager=pip&previous-version=0.17.0&new-version=0.21.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11537:6103,Depend,Dependabot,6103,https://hail.is,https://github.com/hail-is/hail/pull/11537,1,['Depend'],['Dependabot']
Integrability,"-libs/aiohttp/commit/034e5e34ee11c6138c773d85123490e691e1b708""><code>034e5e3</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/8042"">#8042</a>/4b91b530 backport][3.9] Tightening the runtime type check for ssl (...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.9.1...v3.9.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.9.1&new-version=3.9.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14212:7366,Depend,Dependabot,7366,https://hail.is,https://github.com/hail-is/hail/pull/14212,6,['Depend'],['Dependabot']
Integrability,"-libs/aiohttp/commit/0d945d1be08f2ba8475513216a66411f053c3217""><code>0d945d1</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7916"">#7916</a>/822fbc74 backport][3.9] Add more information to contributing page (...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.9.1...v3.9.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.9.1&new-version=3.9.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14219:6575,Depend,Dependabot,6575,https://hail.is,https://github.com/hail-is/hail/pull/14219,2,['Depend'],['Dependabot']
Integrability,"-libs/async-timeout/issues/269"">#269</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c71bbb5b5d7330f6dabfde7a1adec30a4611c0be""><code>c71bbb5</code></a> Bump docutils from 0.18 to 0.18.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/266"">#266</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/async-timeout/compare/v3.0.1...v4.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=async-timeout&package-manager=pip&previous-version=3.0.1&new-version=4.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:6852,depend,dependabot-automerge-start,6852,https://hail.is,https://github.com/hail-is/hail/pull/11465,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"-metadata/issues/46"">#46</a> from pytest-dev/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/025be8999a22ae395b0e2b8ae4e7c9fa2334f874""><code>025be89</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/429840f4de26276560961929f21aab79ed305875""><code>429840f</code></a> Avoid running nightly on forks</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/c1968f39609978ec9c6a4bcf91c37c6164483f04""><code>c1968f3</code></a> Fix nightly</li>; <li>See full diff in <a href=""https://github.com/pytest-dev/pytest-metadata/compare/v2.0.1...v2.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest-metadata&package-manager=pip&previous-version=2.0.1&new-version=2.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12188:2577,depend,dependabot-security-updates,2577,https://hail.is,https://github.com/hail-is/hail/pull/12188,1,['depend'],['dependabot-security-updates']
Integrability,"-of-python-branches"">end-of-life</a> at 2021-12-23.</p>; </li>; </ul>; <h2>Improvements</h2>; <ul>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/5192"">#5192</a>: Fixed test output for some data types where <code>-v</code> would show less information.</p>; <p>Also, when showing diffs for sequences, <code>-q</code> would produce full diffs instead of the expected diff.</p>; </li>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9362"">#9362</a>: pytest now avoids specialized assert formatting when it is detected that the default <code>__eq__</code> is overridden in <code>attrs</code> or <code>dataclasses</code>.</p>; </li>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9536"">#9536</a>: When <code>-vv</code> is given on command line, show skipping and xfail reasons in full instead of truncating them to fit the terminal width.</p>; </li>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9644"">#9644</a>: More information about the location of resources that led Python to raise <code>ResourceWarning</code>{.interpreted-text role=&quot;class&quot;} can now; be obtained by enabling <code>tracemalloc</code>{.interpreted-text role=&quot;mod&quot;}.</p>; <p>See <code>resource-warnings</code>{.interpreted-text role=&quot;ref&quot;} for more information.</p>; </li>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9678"">#9678</a>: More types are now accepted in the <code>ids</code> argument to <code>@pytest.mark.parametrize</code>.; Previously only [str]{.title-ref}, [float]{.title-ref}, [int]{.title-ref} and [bool]{.title-ref} were accepted;; now [bytes]{.title-ref}, [complex]{.title-ref}, [re.Pattern]{.title-ref}, [Enum]{.title-ref} and anything with a [__name__]{.title-ref} are also accepted.</p>; </li>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9692"">#9692</a>: <code>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11571:2256,depend,dependabot,2256,https://hail.is,https://github.com/hail-is/hail/pull/11571,3,['depend'],['dependabot']
Integrability,"-pillow/Pillow/commit/7c945f5131cf8596084b32af582f90a43b090540""><code>7c945f5</code></a> Merge pull request <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7243"">#7243</a> from radarhere/releasenotes</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/0fb69fa821155c1b213f3f3488d3057b6ba7c154""><code>0fb69fa</code></a> Added release notes for <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7123"">#7123</a></li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/b7f1af77fd6ec9468438e25f72b003c16a9e6661""><code>b7f1af7</code></a> Merge pull request <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7230"">#7230</a> from nulano/add-pyproject.toml</li>; <li>Additional commits viewable in <a href=""https://github.com/python-pillow/Pillow/compare/9.5.0...10.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pillow&package-manager=pip&previous-version=9.5.0&new-version=10.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` wil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13321:14840,depend,dependency-name,14840,https://hail.is,https://github.com/hail-is/hail/pull/13321,1,['depend'],['dependency-name']
Integrability,"-pillow/imagemath</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/f5eeeacf7539eaa0d93a677d7666bc7c142c8d1c""><code>f5eeeac</code></a> Name as 'options' in lambda_eval and unsafe_eval, but '_dict' in deprecated eval</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/facf3af93dabcbdd8cdbda8c3b50eefafa3bb04c""><code>facf3af</code></a> Added release notes</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/2a93aba5cfcf6e241ab4f9392c13e3b74032c061""><code>2a93aba</code></a> Use strncpy to avoid buffer overflow</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/a670597bc30e9d489656fc9d807170b8f3d7ca57""><code>a670597</code></a> Update CHANGES.rst [ci skip]</li>; <li>Additional commits viewable in <a href=""https://github.com/python-pillow/Pillow/compare/10.2.0...10.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pillow&package-manager=pip&previous-version=10.2.0&new-version=10.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` wi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14439:15335,depend,dependency-name,15335,https://hail.is,https://github.com/hail-is/hail/pull/14439,3,['depend'],['dependency-name']
Integrability,"-preview</code> header from :meth:<code>gidgethub.apps.get_installation_access_token</code>; because it is out of preview. The <code>machine-man-preview</code> is <code>no longer required &lt;https://developer.github.com/changes/#--machine-man-and-sailor-v-previews-graduate&gt;</code>_; as of August 20, 2020.</li>; </ul>; <h2>5.0.0</h2>; <ul>; <li>Add :meth:<code>gidgethub.routing.Router.fetch</code> for obtaining a frozenset of functions; registered to the router that the event would be called on.; (<code>Issue [#74](https://github.com/brettcannon/gidgethub/issues/74) &lt;https://github.com/brettcannon/gidgethub/issues/74&gt;</code>_).</li>; <li>Add support for GitHub Actions Environment Files with :meth:<code>gidgethub.actions.setenv</code>; and :meth:<code>gidgethub.actions.addpath</code>.; (<code>Issue [#137](https://github.com/brettcannon/gidgethub/issues/137) &lt;https://github.com/brettcannon/gidgethub/issues/132&gt;</code>_).</li>; <li>Make router callback execution order non-deterministic to avoid relying on; registration order.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/brettcannon/gidgethub/commit/9660d1e1c0187d9def32c473c8ceefcd130fe26f""><code>9660d1e</code></a> Add .DS_Store to .gitignore file</li>; <li><a href=""https://github.com/brettcannon/gidgethub/commit/ef0368998fe40769f4f20a6c4b6ccfea27fe8ca9""><code>ef03689</code></a> Bump the version number</li>; <li><a href=""https://github.com/brettcannon/gidgethub/commit/1f80a51670555acda0db0e42189d00bb58bb3b45""><code>1f80a51</code></a> Release 5.2.1</li>; <li><a href=""https://github.com/brettcannon/gidgethub/commit/89ade8859539212e0663e91f0777ad8a39ecf323""><code>89ade88</code></a> Fix cgi and importlib_resources deprecations (<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/185"">#185</a>)</li>; <li><a href=""https://github.com/brettcannon/gidgethub/commit/6488",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12328:6858,rout,router,6858,https://hail.is,https://github.com/hail-is/hail/pull/12328,1,['rout'],['router']
Integrability,"-python/issues/25522"">#25522</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/e90af4374bfd7c139737ad2888fcd269b3023520""><code>e90af43</code></a> DataLake funny dependency (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25129"">#25129</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/cbec3383039ffeb46760268d1a8f81cf1b4d2219""><code>cbec338</code></a> [AutoRelease] t2-storagecache-2022-07-06-35884(Do not merge) (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25089"">#25089</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/dc7c5a16d39df8a8d4b838a7240e58f64fc824f2""><code>dc7c5a1</code></a> [Storage] API View Feedback For STG84 GA (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25085"">#25085</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/9f66f6bce7d777b34c03dc9a633148acd0c4f238""><code>9f66f6b</code></a> [Storage] Revert removing aiohttp dependency for storage.blob.aio (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25084"">#25084</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/e40d3e1d985cee13a2e0d070fb8e04958905f468""><code>e40d3e1</code></a> [storage.blob] Remove aiohttp as dependency for storage.blob.aio (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/24965"">#24965</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/7915719f211cc1217dfca6f3973a2b1f04c2e3f5""><code>7915719</code></a> [Storage] Prepare for STG83 GA release (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/25040"">#25040</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/155eb8b69b3cd2f8ef992cf1436bf2751769ac42""><code>155eb8b</code></a> [Storage] Add <code>progress_hook</code> to file-share upload/download (<a href=""ht",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12109:2821,depend,dependency,2821,https://hail.is,https://github.com/hail-is/hail/pull/12109,1,['depend'],['dependency']
Integrability,"-python/issues/953"">#953</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/c8b5cae3da5eb9d40067d38dac51a4a8c1e0763e"">c8b5cae</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/google-auth-library-python/compare/v2.3.3...v2.4.0"">2.4.0</a> (2022-01-20)</h2>; <h3>Features</h3>; <ul>; <li>add 'py.typed' declaration (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/919"">#919</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/c99350455d0f7fd3aab950ac47b43000c73dd312"">c993504</a>)</li>; <li>add api key support (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/826"">#826</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/3b15092b3461278400e4683060f64a96d50587c4"">3b15092</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <ul>; <li><strong>deps:</strong> allow cachetools 5.0 for python 3.7+ (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/937"">#937</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/1eae37db7f6fceb32d6ef0041962ce1755d2116c"">1eae37d</a>)</li>; <li>fix the message format for metadata server exception (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/916"">#916</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/e756f08dc78616040ab8fbd7db20903137ccf0c7"">e756f08</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>fix intersphinx link for 'requests-oauthlib' (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/921"">#921</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/967be4f4e2a43ba7e240d7acb01b6b992d40e6ec"">967be4f</a>)</li>; <li>note ValueError in <code>verify_oauth2_token</code> (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/928"">#928</a>) ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11546:7763,depend,dependabot,7763,https://hail.is,https://github.com/hail-is/hail/pull/11546,1,['depend'],['dependabot']
Integrability,"-python/issues/965"">#965</a>)</li>; <li><a href=""https://github.com/googleapis/google-auth-library-python/commit/f9f23f4370f2a7a5b2c66ee56a5e700ef03b5b06""><code>f9f23f4</code></a> fix: revert &quot;feat: add api key support (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/826"">#826</a>)&quot; (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/964"">#964</a>)</li>; <li><a href=""https://github.com/googleapis/google-auth-library-python/commit/3c72365d8407bb097568919123cd7232c1a49f4f""><code>3c72365</code></a> chore: update user cred for system test (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/966"">#966</a>)</li>; <li><a href=""https://github.com/googleapis/google-auth-library-python/commit/52c8ef90058120d7d04d3d201adc111664be526c""><code>52c8ef9</code></a> feat: ADC can load an impersonated service account credentials. (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/962"">#962</a>)</li>; <li><a href=""https://github.com/googleapis/google-auth-library-python/commit/83b20f0b4d32b2ff1183a9c2926afd37f3baf92b""><code>83b20f0</code></a> chore: update user creds for system test (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/963"">#963</a>)</li>; <li><a href=""https://github.com/googleapis/google-auth-library-python/commit/3c9feff3e9037a15bf07496623e3a810f117adcf""><code>3c9feff</code></a> chore(main): release 2.5.0 (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/960"">#960</a>)</li>; <li><a href=""https://github.com/googleapis/google-auth-library-python/commit/a8eb4c8693055a3420cfe9c3420aae2bc8cd465a""><code>a8eb4c8</code></a> feat: ADC can load an impersonated service account credentials. (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/956"">#956</a>)</li>; <li><a href=""htt",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11546:10427,depend,dependabot,10427,https://hail.is,https://github.com/hail-is/hail/pull/11546,1,['depend'],['dependabot']
Integrability,"-redirect.dependabot.com/PyCQA/pylint/issues/5679"">PyCQA/pylint#5679</a></p>; </li>; <li>; <p>Inlcude names of keyword-only arguments in <code>astroid.scoped_nodes.Lambda.argnames</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5771"">PyCQA/pylint#5771</a></p>; </li>; <li>; <p>Fixed a crash inferring on a <code>NewType</code> named with an f-string.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5770"">PyCQA/pylint#5770</a></p>; </li>; <li>; <p>Add support for <a href=""https://github.com/python-attrs/attrs/releases/tag/21.3.0"">attrs v21.3.0</a> which; added a new <code>attrs</code> module alongside the existing <code>attr</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1330"">#1330</a></p>; </li>; <li>; <p>Use the <code>end_lineno</code> attribute for the <code>NodeNG.tolineno</code> property; when it is available.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1350"">#1350</a></p>; </li>; <li>; <p>Add <code>is_dataclass</code> attribute to <code>ClassDef</code> nodes.</p>; </li>; <li>; <p>Use <code>sysconfig</code> instead of <code>distutils</code> to determine the location of; python stdlib files and packages.</p>; <p>Related pull requests: <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1322"">#1322</a>, <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1323"">#1323</a>, <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1324"">#1324</a>; Closes <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1282"">#1282</a>; Ref <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1103"">#1103</a></p>; </li>; <li>; <p>Fixed crash with recursion error for inference of class attributes that referenced; the class itself.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5408"">PyCQA/pylint#5408</a></p>; </li>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11463:2087,depend,dependabot,2087,https://hail.is,https://github.com/hail-is/hail/pull/11463,2,['depend'],['dependabot']
Integrability,"-redirect.dependabot.com/bokeh/bokeh/issues/11781"">#11781</a> [component: examples] fix transform jitter example</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11786"">#11786</a> bokeh 2.4.2 backports</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11790"">#11790</a> [component: build] Bryanv/pin sphinx 42</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11797"">#11797</a> Add OS to bokeh info</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11805"">#11805</a> More 3.0 -&gt; 2.4.2 backports</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11810"">#11810</a> [component: docs] Update docs for new issue forms</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11824"">#11824</a> Updates for release</li>; </ul>; </li>; </ul>; <h2>2021-10-13 2.4.1:</h2>; <ul>; <li>; <p>bugfixes:</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11119"">#11119</a> [component: bokehjs] [BUG] varea_stack() and vline_stack() fails to update correctly when new source data is different length</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11625"">#11625</a> [component: tests] [BUG] Codebase test failures in Windows</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11627"">#11627</a> [BUG] mypy tests fail in Windows</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11629"">#11629</a> [BUG] Hover tool takes long time to render</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11633"">#11633</a> [component: bokehjs] [BUG] RangesUpdate not emitted when using xwheel_pan</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11645"">#11645</a> [component: bokehjs] [BUG] <code>bokeh init</code> creates a <code>package.json</code> which refers to the deprecated Bokeh JS node package</li>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11540:3072,depend,dependabot,3072,https://hail.is,https://github.com/hail-is/hail/pull/11540,1,['depend'],['dependabot']
Integrability,"-redirect.dependabot.com/chardet/chardet/issues/239"">#239</a>)</li>; <li><a href=""https://github.com/chardet/chardet/commit/5c73bfcdf819251d1a1d0de672e34480ebafbe1f""><code>5c73bfc</code></a> Run all pre-commit hooks on pull requests (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/236"">#236</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/chardet/chardet/compare/4.0.0...5.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=chardet&package-manager=pip&previous-version=4.0.0&new-version=5.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12107:6054,depend,dependabot-automerge-start,6054,https://hail.is,https://github.com/hail-is/hail/pull/12107,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2028"">#2028</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/d498aa068ef552aef9de3325e9d105611e5adbba""><code>d498aa0</code></a> Update index.adoc (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2000"">#2000</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/elastic/elasticsearch-hadoop/compare/v8.4.3...v8.6.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.elasticsearch:elasticsearch-spark-20_2.12&package-manager=gradle&previous-version=8.4.3&new-version=8.6.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12623:5939,depend,dependabot,5939,https://hail.is,https://github.com/hail-is/hail/pull/12623,1,['depend'],['dependabot']
Integrability,"-redirect.dependabot.com/googleapis/java-storage/issues/1838"">#1838</a>) (<a href=""https://github.com/googleapis/java-storage/commit/372521ba80b12e52c74fae5ac766dbe6610ff0b2"">372521b</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.15.1...v2.16.0"">2.16.0</a> (2022-12-06)</h2>; <h3>Features</h3>; <ul>; <li>Add {Compose,Rewrite,StartResumableWrite}Request.object_checksums and Bucket.RetentionPolicy.retention_duration (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1790"">#1790</a>) (<a href=""https://github.com/googleapis/java-storage/commit/31c1b18acc3c118e39eb613a82ee292f3e246b8f"">31c1b18</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/googleapis/java-storage/commit/28bd2bbe07eeb014ba63c62125371286163fbbdc""><code>28bd2bb</code></a> chore(main): release 2.17.1 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1854"">#1854</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/1425dd97cb7d4a58f0bbededeca543f1a89c7d5d""><code>1425dd9</code></a> fix: update BaseStorageReadChannel to be left open unless explicitly closed (...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/4491f73e1fe4baed1ace132cba9f8cc1557ffa33""><code>4491f73</code></a> chore(main): release 2.17.1-SNAPSHOT (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1849"">#1849</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/fb3ae9c172f6176a52815cc7ffc09175f23d0df8""><code>fb3ae9c</code></a> chore(main): release 2.17.0 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1804"">#1804</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/3ab745207badbd4971f2fb62ed92e1703625214a""><code>3ab7452</code></a> chore(test): increase debug logging for failure cases in Ga",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12598:13728,depend,dependabot,13728,https://hail.is,https://github.com/hail-is/hail/pull/12598,1,['depend'],['dependabot']
Integrability,"-redirect.dependabot.com/java-native-access/jna/pull/1398"">#1398</a>: Increase <code>c.s.j.p.win32.Sspi#MAX_TOKEN_SIZE</code> on Windows 8/Server 2012 and later - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1403"">#1403</a>: Rebuild AIX binaries with libffi 3.4.2 (other architectures were part of 5.10) - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1404"">#1404</a>: Added Solaris Kstat2 library - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1416"">#1416</a>: Add <code>CFDictionaryGetCount</code> to <code>c.s.j.p.mac.CoreFoundation</code> - <a href=""https://github.com/shalupov""><code>@​shalupov</code></a></li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1418"">#1418</a>: Add <code>CertOpenStore</code> to <code>c.s.j.p.win32.Crypt32</code> - <a href=""https://github.com/shalupov""><code>@​shalupov</code></a></li>; </ul>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1411"">#1411</a>: Do not throw <code>Win32Exception</code> on success for empty section in <code>Kernel32Util#getPrivateProfileSection</code> - <a href=""https://github.com/mkarg""><code>@​mkarg</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1414"">#1414</a>: Fix definition of <code>c.s.j.p.unix.X11.XK_Shift_R</code> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1323"">#1323</a>. Fix crashes in direct callbacks on mac OS aarch64 - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:3717,depend,dependabot,3717,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['depend'],['dependabot']
Integrability,"-redirect.dependabot.com/psf/black/issues/2919"">#2919</a>)</li>; <li>Remove unnecessary parentheses from <code>except</code> statements (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2939"">#2939</a>)</li>; <li>Remove unnecessary parentheses from tuple unpacking in <code>for</code> loops (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2945"">#2945</a>)</li>; <li>Avoid magic-trailing-comma in single-element subscripts (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2942"">#2942</a>)</li>; </ul>; <h3>Configuration</h3>; <ul>; <li>Do not format <code>__pypackages__</code> directories by default (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2836"">#2836</a>)</li>; <li>Add support for specifying stable version with <code>--required-version</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2832"">#2832</a>).</li>; <li>Avoid crashing when the user has no homedir (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2814"">#2814</a>)</li>; <li>Avoid crashing when md5 is not available (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2905"">#2905</a>)</li>; <li>Fix handling of directory junctions on Windows (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2904"">#2904</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Update pylint config documentation (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2931"">#2931</a>)</li>; </ul>; <h3>Integrations</h3>; <ul>; <li>Move test to disable plugin in Vim/Neovim, which speeds up loading (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2896"">#2896</a>)</li>; </ul>; <h3>Output</h3>; <ul>; <li>In verbose, mode, log when <em>Black</em> is using user-level config (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2861"">#2861</a>)</li>; </ul>; <h3>Packaging</h3>; <ul>; <li>Fix Black to work with Click 8.1.0 (<a href=""https://github-redirect.dependabot.com/psf",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11696:1377,depend,dependabot,1377,https://hail.is,https://github.com/hail-is/hail/pull/11696,2,['depend'],['dependabot']
Integrability,"-redirect.dependabot.com/sphinx-doc/sphinx/issues/9856"">#9856</a>: Deprecated <code>sphinx.ext.napoleon.iterators</code>.</li>; </ul>; <h2>Features added</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10444"">#10444</a>: html theme: Allow specifying multiple CSS files through the <code>stylesheet</code>; setting in <code>theme.conf</code> or by setting <code>html_style</code> to an iterable of strings.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10366"">#10366</a>: std domain: Add support for emphasising placeholders in :rst:dir:<code>option</code>; directives through a new :confval:<code>option_emphasise_placeholders</code> configuration; option.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10439"">#10439</a>: std domain: Use the repr of some variables when displaying warnings,; making whitespace issues easier to identify.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10571"">#10571</a>: quickstart: Reduce content in the generated <code>conf.py</code> file. Patch by; Pradyun Gedam.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10648"">#10648</a>: LaTeX: CSS-named-alike additional :ref:<code>'sphinxsetup' &lt;latexsphinxsetup&gt;</code>; keys allow to configure four separate border-widths, four paddings, four; corner radii, a shadow (possibly inset), colours for border, background, shadow; for each of the code-block, topic, attention, caution, danger, error and warning; directives.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10655"">#10655</a>: LaTeX: Explain non-standard encoding in LatinRules.xdy</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10599"">#10599</a>: HTML Theme: Wrap consecutive footnotes in an <code>&lt;aside&gt;</code> element when; using Docutils 0.18 or later, to allow for easier styling. This",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12165:3741,depend,dependabot,3741,https://hail.is,https://github.com/hail-is/hail/pull/12165,1,['depend'],['dependabot']
Integrability,"-redirect.dependabot.com/sveltejs/svelte/issues/5950"">#5950</a>)</li>; <li>Support svg namespace for <code>{@html}</code> (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7002"">#7002</a>, <a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7450"">#7450</a>)</li>; <li>Fix <code>{@const}</code> tag not working inside a component when there's no <code>let:</code> <a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7189"">#7189</a></li>; <li>Remove extraneous leading newline inside <code>&lt;pre&gt;</code> and <code>&lt;textarea&gt;</code> (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7264"">#7264</a>)</li>; <li>Fix erroneous setting of <code>textContent</code> for <code>\&lt;template&gt;</code> elements (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/pull/7297"">#7297</a>)</li>; <li>Fix value of <code>let:</code> bindings not updating in certain cases (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7440"">#7440</a>)</li>; <li>Fix handling of void tags in <code>&lt;svelte:element&gt;</code> (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7449"">#7449</a>)</li>; <li>Fix handling of boolean attributes in <code>&lt;svelte:element&gt;</code> (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7478"">#7478</a>)</li>; <li>Add special style scoping handling of <code>[open]</code> selectors on <code>&lt;dialog&gt;</code> elements (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7494"">#7495</a>)</li>; </ul>; <h2>3.47.0</h2>; <ul>; <li>Add support for dynamic elements through <code>&lt;svelte:element&gt;</code> (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/2324"">#2324</a>)</li>; <li>Miscellaneous variable context fixes in <code>{@const}</code> (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/pull/7222"">#7222</a>)</li>; <li>Fix <code>{#key}</code> block no",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12032:3253,depend,dependabot,3253,https://hail.is,https://github.com/hail-is/hail/pull/12032,3,['depend'],['dependabot']
Integrability,"-redirect.dependabot.com/tox-dev/py-filelock/pull/155"">tox-dev/py-filelock#155</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/156"">tox-dev/py-filelock#156</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/157"">tox-dev/py-filelock#157</a></li>; <li>Check 3.11 support by <a href=""https://github.com/gaborbernat""><code>@​gaborbernat</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/158"">tox-dev/py-filelock#158</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/159"">tox-dev/py-filelock#159</a></li>; <li>Bump dependencies by <a href=""https://github.com/gaborbernat""><code>@​gaborbernat</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/160"">tox-dev/py-filelock#160</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/162"">tox-dev/py-filelock#162</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/dependabot""><code>@​dependabot</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/154"">tox-dev/py-filelock#154</a></li>; <li><a href=""https://github.com/jnordberg""><code>@​jnordberg</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/148"">tox-dev/py-filelock#148</a></li>; <li><a href=""https://github.com/DeadNews""><code>@​DeadNews</code></",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12157:3051,depend,dependencies,3051,https://hail.is,https://github.com/hail-is/hail/pull/12157,1,['depend'],['dependencies']
Integrability,"-sdk-for-java/commit/a651fcc7c0026641717465f8bbae64de808df187""><code>a651fcc</code></a> Doc consistenty review updates (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/31332"">#31332</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/6b1aef8c5c09239d6e4534a116fba195891e3d57""><code>6b1aef8</code></a> target version with fixes (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/31310"">#31310</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/b17fed8df6b512691656673a6c5b7e8033ff31c2""><code>b17fed8</code></a> Prepare release for Schema Registry (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/31375"">#31375</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/1c2a0d90d42432387794daa3c03469fc0fcd1060""><code>1c2a0d9</code></a> [Perf] Call configureClientBuilder() in DataLake and FileShare tests (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/31324"">#31324</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/c85090e334e4ff77a3b3178a57b8b6d24518859d""><code>c85090e</code></a> Create Media Streaming package parser with updated contracts (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/31309"">#31309</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/6f7b2986b03ae7c4ab67f52452c5af7f260a3880""><code>6f7b298</code></a> Add Merge-Branch script eng/scripts (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/31222"">#31222</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/02fdc27bc10fa3e1bda08f3125059e95be8a4bb0""><code>02fdc27</code></a> Release/azure communication common/1.2.2 (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/31377"">#31377</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-ja",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12450:2044,depend,dependabot,2044,https://hail.is,https://github.com/hail-is/hail/pull/12450,1,['depend'],['dependabot']
Integrability,"-src.zip; /share/pkg/spark/1.6.1/install/python/lib/py4j-0.9-src.zip; /share/pkg/spark/2.0.0/install/python/lib/py4j-0.10.1-src.zip; /share/pkg/spark/2.1.0/install/python/lib/py4j-0.10.4-src.zip. So I got the following error since I was using Spark 2.1.0 which has; py4j-0.10.4-src.zip instead of py4j-0.10.3-src.zip in the alias. >>> import pyhail; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File; ""/restricted/projectnb/genpro/github/hail/python/pyhail/__init__.py"", line; 1, in <module>; from pyhail.context import HailContext; File ""/restricted/projectnb/genpro/github/hail/python/pyhail/context.py"",; line 1, in <module>; from pyspark.java_gateway import launch_gateway; File ""/share/pkg/spark/2.1.0/install/python/pyspark/__init__.py"", line; 44, in <module>; from pyspark.context import SparkContext; File ""/share/pkg/spark/2.1.0/install/python/pyspark/context.py"", line 29,; in <module>; from py4j.protocol import Py4JError; ImportError: No module named py4j.protocol. The following will fix the issue. Essentially it sets PYJ4 to the py4j zip; file found in SPARK_HOME. Then uses that to set the PYTHONPATH. *PYJ4*=`ls $SPARK_HOME/python/lib/py4j*.zip`; alias hail=""PYTHONPATH=$SPARK_HOME/python:*$PYJ4*:$HAIL_HOME/python; SPARK_CLASSPATH=$HAIL_HOME/build/libs/hail-all-spark.jar python"". On Thu, Jan 12, 2017 at 11:21 PM, cseed <notifications@github.com> wrote:. > We now have a Getting Started the python API:; >; > https://hail.is/pyhail/getting_started.html; >; > Please give it a spin and let us know if you run into any problems. The; > documentation for the python API is nearly complete, but the Tutorial and; > General Reference section are still being ported to python and will need; > another week or so. Thanks for your patience!; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/hail-is/hail/issues/1218#issuecomment-272357689>, or mute; > the thread; > <http",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1218#issuecomment-272537799:1549,protocol,protocol,1549,https://hail.is,https://github.com/hail-is/hail/issues/1218#issuecomment-272537799,1,['protocol'],['protocol']
Integrability,"-storage/commit/4dafc815470480ce9de7f0357e331d3fbd0ae9b7""><code>4dafc81</code></a> feat: add turbo replication support and samples (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/622"">#622</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/8aa4130ee068a1922161c8ca54a53a4a51d65ce0""><code>8aa4130</code></a> feat: remove python 3.6 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/689"">#689</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/fe1855a5f23dd49f5d2f830d9ae39b8f2f0a4aaf""><code>fe1855a</code></a> chore(python): update release.sh to use keystore (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/692"">#692</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/b53feaaaf0af92ea9e1d16abd317f798f2b6e17a""><code>b53feaa</code></a> build: switch to release-please for tagging (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/691"">#691</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/7f771077511d6b446686724f48514d5b903ec036""><code>7f77107</code></a> chore(deps): update dependency google-cloud-storage to v2 (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/690"">#690</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/7891dcc6c0bd90da192691025c910cf30c98407b""><code>7891dcc</code></a> chore(main): release 2.0.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/687"">#687</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/python-storage/compare/v1.25.0...v2.1.0"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (depe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11520:7781,depend,dependabot,7781,https://hail.is,https://github.com/hail-is/hail/pull/11520,1,['depend'],['dependabot']
Integrability,"-storage/issues/1853"">#1853</a>) (<a href=""https://github.com/googleapis/java-storage/commit/1425dd97cb7d4a58f0bbededeca543f1a89c7d5d"">1425dd9</a>)</li>; </ul>; <h2>v2.17.0</h2>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.16.0...v2.17.0"">2.17.0</a> (2023-01-12)</h2>; <h3>Features</h3>; <ul>; <li>Implement GrpcStorageImpl BucketAccessControl operations (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1816"">#1816</a>) (<a href=""https://github.com/googleapis/java-storage/commit/5c52079fb5f52caf39a49ccb96df6251a9c728d3"">5c52079</a>)</li>; <li>Implement GrpcStorageImpl ObjectAccessControl operations (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1818"">#1818</a>) (<a href=""https://github.com/googleapis/java-storage/commit/2eec791122bb1bb28a1ffb14beb7ce8776c5b5ec"">2eec791</a>)</li>; <li>Implement GrpcStorageImpl#createDefaultAcl &amp; GrpcStorageImpl#updateDefaultAcl (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1806"">#1806</a>) (<a href=""https://github.com/googleapis/java-storage/commit/0f24a11c5289a4c07f27d8a3c29fab34520b036f"">0f24a11</a>)</li>; <li>Implement GrpcStorageImpl#deleteDefaultAcl (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1807"">#1807</a>) (<a href=""https://github.com/googleapis/java-storage/commit/c78327717a7936492161ddcc64c86374db72c48c"">c783277</a>)</li>; <li>Implement GrpcStorageImpl#getDefaultAcl (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1802"">#1802</a>) (<a href=""https://github.com/googleapis/java-storage/commit/b9b7c49fcfcab285da156b34b186a007150e876f"">b9b7c49</a>)</li>; <li>Implement GrpcStorageImpl#listDefaultAcl (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1805"">#1805</a>) (<a href=""https://github.com/googleapis/java-storage/commit/03c2e6660721b4a8bfc09b241ef44f3e4e08865b"">03c2e66</a>)</li>; <li>Improve throughput of http b",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12598:1577,depend,dependabot,1577,https://hail.is,https://github.com/hail-is/hail/pull/12598,1,['depend'],['dependabot']
Integrability,"-strings to detect target version (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3215"">#3215</a>)</li>; <li>Fix misdetection of project root and verbose logging of sources in cases involving <code>--stdin-filename</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3216"">#3216</a>)</li>; <li>Immediate <code>.gitignore</code> files in source directories given on the command line are now also respected, previously only <code>.gitignore</code> files in the project root and automatically discovered directories were respected (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3237"">#3237</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Recommend using BlackConnect in IntelliJ IDEs (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3150"">#3150</a>)</li>; </ul>; <h3>Integrations</h3>; <ul>; <li>Vim plugin: prefix messages with <code>Black: </code> so it's clear they come from Black (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3194"">#3194</a>)</li>; <li>Docker: changed to a /opt/venv installation + added to PATH to be available to non-root users (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3202"">#3202</a>)</li>; </ul>; <h3>Output</h3>; <ul>; <li>Change from deprecated <code>asyncio.get_event_loop()</code> to create our event loop which removes DeprecationWarning (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3164"">#3164</a>)</li>; <li>Remove logging from internal <code>blib2to3</code> library since it regularly emits error logs about failed caching that can and should be ignored (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3193"">#3193</a>)</li>; </ul>; <h3>Parser</h3>; <ul>; <li>Type comments are now included in the AST equivalence check consistently so accidental deletion raises an error. Though type comments can't be tracked when running on PyPy 3.7 due to standard library limitations. (<a href=""https://github-redirect.d",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12174:3904,depend,dependabot,3904,https://hail.is,https://github.com/hail-is/hail/pull/12174,1,['depend'],['dependabot']
Integrability,"-typehints/commit/bff0765fbaf628a314e210bb2903b2f0b4ed6ff6""><code>bff0765</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/230"">#230</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/73aa9b6aea40720ca270b1107c1980b909943cb3""><code>73aa9b6</code></a> Fix mock imports on guarded imports (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/225"">#225</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/4d5867d5a235040b3e7d3373a56c5b2b580db7b7""><code>4d5867d</code></a> Handle UnionType (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/221"">#221</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/13ca2b458b0ee9c8d1c980b6a5e97a6ee78f46c7""><code>13ca2b4</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/226"">#226</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/def37f75a11237a3889c9179d17a6635f8062604""><code>def37f7</code></a> Support and require nptyping 2</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/ede082a858e1f7353cc502fd89a80736b718902f""><code>ede082a</code></a> Require nptyping&lt;2 (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/227"">#227</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/f9219b21ef8807150dbbcbaf45d6118387ff9a32""><code>f9219b2</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/222"">#222</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/a9b90238f74f1c5f69d7dcafb83c9775504f9b3b""><code>a9b9023</code></a> Fix typos (<a href=""https://github-redirect.dependabot.co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11893:5522,depend,dependabot,5522,https://hail.is,https://github.com/hail-is/hail/pull/11893,2,['depend'],['dependabot']
Integrability,"-uniform continuous and; discrete distributions</li>; <li>All namespaces that were private but happened to miss underscores in; their names have been deprecated.</li>; </ul>; <h1>New features</h1>; <h1><code>scipy.fft</code> improvements</h1>; <p>Added an <code>orthogonalize=None</code> parameter to the real transforms in <code>scipy.fft</code>; which controls whether the modified definition of DCT/DST is used without; changing the overall scaling.</p>; <p><code>scipy.fft</code> backend registration is now smoother, operating with a single</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/scipy/scipy/commit/b5d8bab88af61d61de09641243848df63380a67f""><code>b5d8bab</code></a> REL: 1.8.0 release commit.</li>; <li><a href=""https://github.com/scipy/scipy/commit/d84f731d4df03915ce3dd8013a86eab0db5ec60e""><code>d84f731</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/scipy/scipy/issues/15521"">#15521</a> from tylerjereddy/treddy_prep_180_final</li>; <li><a href=""https://github.com/scipy/scipy/commit/315dd5340cd2825682087f195663d2f63deb3f24""><code>315dd53</code></a> DOC: update 1.8.0 relnotes.</li>; <li><a href=""https://github.com/scipy/scipy/commit/b54b7ae0240cad126a1a9baf2ed71c97c15ddc15""><code>b54b7ae</code></a> MAINT: fix broken link and remove CI badges</li>; <li><a href=""https://github.com/scipy/scipy/commit/920e27b282583531cbf5b5ad348845f0c4bddeed""><code>920e27b</code></a> REL: 1.8.0 unreleased.</li>; <li><a href=""https://github.com/scipy/scipy/commit/ea004bd338738183ff4761427246198f84071ba1""><code>ea004bd</code></a> REL: 1.8.0rc4 released.</li>; <li><a href=""https://github.com/scipy/scipy/commit/4f3969d70fd5cd8f7fcc7ffb207879c4d482b642""><code>4f3969d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/scipy/scipy/issues/15479"">#15479</a> from tylerjereddy/treddy_180rc4</li>; <li><a href=""https://github.com/s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11538:2986,depend,dependabot,2986,https://hail.is,https://github.com/hail-is/hail/pull/11538,1,['depend'],['dependabot']
Integrability,"-version</code> and <code>--audit-webhook-version</code> now only support the default value of <code>audit.k8s.io/v1</code>. The v1alpha1 and v1beta1 audit log versions, deprecated since 1.13, have been removed. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108092"">kubernetes/kubernetes#108092</a>, <a href=""https://github.com/carlory""><code>@​carlory</code></a>)</li>; <li>Kube-apiserver: the <code>metadata.selfLink</code> field can no longer be populated by kube-apiserver; it was deprecated in 1.16 and has not been populated by default since 1.20+. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107527"">kubernetes/kubernetes#107527</a>, <a href=""https://github.com/wojtek-t""><code>@​wojtek-t</code></a>)</li>; <li>Kubelet external Credential Provider feature is moved to Beta. Credential Provider Plugin and Credential Provider Config API's updated from v1alpha1 to v1beta1 with no API changes. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108847"">kubernetes/kubernetes#108847</a>, <a href=""https://github.com/adisky""><code>@​adisky</code></a>)</li>; <li>Make STS available replicas optional again. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/109241"">kubernetes/kubernetes#109241</a>, <a href=""https://github.com/ravisantoshgudimetla""><code>@​ravisantoshgudimetla</code></a>)</li>; <li>MaxUnavailable for StatefulSets, allows faster RollingUpdate by taking down more than 1 pod at a time. The number of pods you want to take down during a RollingUpdate is configurable using maxUnavailable parameter. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/82162"">kubernetes/kubernetes#82162</a>, <a href=""https://github.com/krmayankk""><code>@​krmayankk</code></a>)</li>; <li>Non-graceful node shutdown handling is enabled for stateful workload failovers (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108486"">kubernetes/ku",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:9313,depend,dependabot,9313,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['depend'],['dependabot']
Integrability,". (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/206"">#206</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/308f153f91b7942476f2d4ddda3dc8c99933d598""><code>308f153</code></a> ci: add workflow to publish sdist/wheel to PyPI (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/202"">#202</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/961624063383cbcdc78a61b1d18448429a61a489""><code>9616240</code></a> [chore] update changelog</li>; <li>Additional commits viewable in <a href=""https://github.com/tomplus/kubernetes_asyncio/compare/v19.15.1...23.6.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=kubernetes-asyncio&package-manager=pip&previous-version=19.15.1&new-version=23.6.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:15842,depend,dependabot-security-updates,15842,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['depend'],['dependabot-security-updates']
Integrability,". (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/java-native-access/jna/commit/3705b849892aa3c37e5608e640eff19047811a5c""><code>3705b84</code></a> Release 5.12.1</li>; <li><a href=""https://github.com/java-native-access/jna/commit/2f919e56bad203494fe9589206d6d23f27ef4f26""><code>2f919e5</code></a> Null-check cleanable in Memory#close (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1447"">#1447</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/1eec7dd76830af97ed64ecb2d8d39a56db104dcd""><code>1eec7dd</code></a> Prepare next development iteration</li>; <li><a href=""https://github.com/java-native-access/jna/commit/0d7499f105e4495bdea15fc21f5b1046e81ca822""><code>0d7499f</code></a> Release 5.12.0</li>; <li><a href=""https://github.com/java-native-access/jna/commit/fa86166d4f75ef4478de7ad9d7d6c0b6b6933ee0""><code>fa86166</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1445"">#1445</a> from matthiasblaesing/aix</li>; <li><a href=""https://github.com/java-native-access/jna/commit/4cca4405f7f6bc32d2a08495efb81c081b065279""><code>4cca440</code></a> Fix name mapping difference between AIX JDK 8 and Semeru JDK 18</li>; <li><a href=""https://github.com/java-native-access/jna/commit/f58b0f8f6b5c013adfe44a2cfb018ccb6ef6a688""><code>f58b0f8</code></a> Improve test stability on AIX (exclude tests that are expected to fail)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/c1565fb89469cbcba67b1cc305e16d520779b270""><code>c1565fb</code></a> Handle race condition in PdhUtil#PdhEnumObjectItems (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1442"">#1442</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/99fcfa822db86b1f2ba5823dbf17efeb3d246ad5""><code>99fcfa8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issue",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:6492,depend,dependabot,6492,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['depend'],['dependabot']
Integrability,". The exceptions are:; - from batch-driver to batch workers; - from batch workers to internal-gateway; - to ukbb-rg; - from router to notebook workers; - letsencrypt (oh the irony). The major new build step is `create_certs` which creates a certificate, key, and; list of trusted ""principals"" for each ""principal"". ""Principal"" is a computer; security term referring to an authenticatable identity. In our system, the; services are each unique principals and every client (e.g. the test_batch CI; step) is also a principal. A principal's certificate is a unforgeable proof of; their identity. A principal's ""key"", in our system, is actually a public-private; (i.e. asymmetric) key pair which the client and server use to establish a; symmetric key for each new connection. A list of trusted principals is a list of; certificates. Every incoming connection must provide a certificate in the; trusted list or the server will drop the connection. Every service depends on the `create_certs` step because their deployment's load; secrets created by `create_certs`. The blog service is implemented by Ghost. Ghost only supports HTTP. As a result; we cannot make all network traffic in our cluster TLS-secured. However, we can; use an nginx sidecar on the blog pod which terminates TLS connections and sends; plaintext traffic on the loopback interface to Ghost. Thus, our goal is: no; plaintext traffic on non-loopback interfaces. Readiness and liveness probes cannot use HTTP. Although k8s supports HTTPS, it; does not support so-called ""mTLS"" or ""mutual TLS."" This is fancy verbiage for; servers that require clients to send trusted certificates. We require; this. There is a lot of information in GitHub issues and the Istio web pages; about this, but at the end of the day, kubernetes does not support this. TCP; probes are the best we can do. There [was a; PR](https://github.com/kubernetes/kubernetes/pull/61231) to allow httpGet probes; to send the kubelet certificate, but it was closed because, app",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8513:1040,depend,depends,1040,https://hail.is,https://github.com/hail-is/hail/pull/8513,1,['depend'],['depends']
Integrability,". [:issue:<code>313</code> by Anthony Sottile]</li>; </ul>; <p>__ <a href=""https://github.com/sass/libsass/releases/tag/3.6.4"">https://github.com/sass/libsass/releases/tag/3.6.4</a></p>; <h2>Version 0.19.4</h2>; <p>Released on November 3, 2019.</p>; <ul>; <li>Follow up the libsass upstream: 3.6.3 --- See the release notes of LibSass; 3.6.3__. [:issue:<code>304</code> by Anthony Sottile]</li>; </ul>; <p>__ <a href=""https://github.com/sass/libsass/releases/tag/3.6.3"">https://github.com/sass/libsass/releases/tag/3.6.3</a></p>; <h2>Version 0.19.3</h2>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/sass/libsass-python/commit/13c0d60e244c694dec88d8ac8370d7aae6dce4d0""><code>13c0d60</code></a> 0.21.0</li>; <li><a href=""https://github.com/sass/libsass-python/commit/5c94c2a72dab34367758e229c487de50f1430283""><code>5c94c2a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sass/libsass-python/issues/344"">#344</a> from sass/3_6_5</li>; <li><a href=""https://github.com/sass/libsass-python/commit/ad69f6e023a6d8fdde4428b7a497b60fb5515215""><code>ad69f6e</code></a> update libsass to 3.6.5</li>; <li><a href=""https://github.com/sass/libsass-python/commit/38735e2fdc30ecb21f6eebb253c1b7a9a45dc757""><code>38735e2</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sass/libsass-python/issues/343"">#343</a> from sass/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/sass/libsass-python/commit/7f01591fdbca66375a61d70e505a286550a1c1b1""><code>7f01591</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/sass/libsass-python/commit/814d42df9787494f01474116940782ab67da083f""><code>814d42d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sass/libsass-python/issues/342"">#342</a> from sass/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/sass/libsass-p",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11508:3700,depend,dependabot,3700,https://hail.is,https://github.com/hail-is/hail/pull/11508,1,['depend'],['dependabot']
Integrability,". _v41-0-5:; </code></pre></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pyca/cryptography/commit/f09c261ca10a31fe41b1262306db7f8f1da0e48a""><code>f09c261</code></a> 41.0.6 release (<a href=""https://redirect.github.com/pyca/cryptography/issues/9927"">#9927</a>)</li>; <li>See full diff in <a href=""https://github.com/pyca/cryptography/compare/41.0.5...41.0.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=41.0.5&new-version=41.0.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14046:1468,depend,dependabot-automerge-start,1468,https://hail.is,https://github.com/hail-is/hail/pull/14046,6,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,". debian8), and systems; based on g++-5.x and later with new-ABI std::string by default (e.g. debian9). That; incompatibility is the problem. >Not having access to the standard library seems problematic. You absolutely have access to the full C++11 standard library in dynamically-generated code -; you're compiling with the master node's default compiler, and header files, and using; the default libstdc++.o (libc++.dylib), and it's all fine. And you'll be using whichever flavor; of std::string is the default for that system, which will presumably also be interoperable with any; third-party library packages on that system. The issues we're getting round are:. a) If libhail.so is prebuilt on a new-ABI system *and* uses std::string, then it can't run against; the libstdc++ on an old-ABI system. b) If libhail.so is prebuilt on an old-ABI system, then it can run against either old-ABI or new-ABI; libstdc++, but if it then gets linked against third-party libraries compiled against new-ABI; headers, you'll have two different flavors of std::string floating around in the same program,; which causes confusion at any interfaceswhich pass std::string around. Now if you want to go further in shipping more of the system, then the question of whether to; ship your own libstdc++ (or libc++) is independent of the choice of compiler version. *If* you ; ship your own libstdc++, then you potentially introduce the problems of interoperability with; other libraries on the system). And there's a slight question about whether your libstdc++ will; work against the other systems libc.so, though I think the ABI at that level has been stable enough for long enough that it probably doesn't cause trouble.; ; In short, it's a can of worms. Avoiding std::string in libhail.so keeps the can closed for now.; And I believe dataproc will move to using debian9 images as the default in November, so at; some point the need to support old-ABI systems (debian8) will diminish and possibly go away completely.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4422#issuecomment-424787941:1743,interoperab,interoperability,1743,https://hail.is,https://github.com/hail-is/hail/pull/4422#issuecomment-424787941,1,['interoperab'],['interoperability']
Integrability,".. and I hand-deployed the router and it looks good. Most of our existing services can't handle being located at internal.hail.is/ns/svc, so I'm going to make a series of changes to fix that, possibly folded into my auth changes.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6928#issuecomment-524334117:27,rout,router,27,https://hail.is,https://github.com/hail-is/hail/pull/6928#issuecomment-524334117,1,['rout'],['router']
Integrability,"....</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/e726483d70938f3bff67e95358841a1f6271b149""><code>e726483</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48619"">#48619</a> on branch 1.5.x (REGR: Loc.setitem with enlargement raises...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/f83e2fe3327ad85ae2e8c4ba469fe98383243dbf""><code>f83e2fe</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48623"">#48623</a> on branch 1.5.x (REGR/DOC: Docs left navbar broke) (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48625"">#48625</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/4fbb05591979055708162994e96fb4c61cf2a8ab""><code>4fbb055</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48601"">#48601</a> on branch 1.5.x (CI: Fix matplolib release issues) (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48617"">#48617</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/aabf6597f45436e9ada915ac15d3708f9d4948ca""><code>aabf659</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48587"">#48587</a> on branch 1.5.x (Fix <code>series.str.startswith(tuple)</code>) (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48593"">#48593</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/dfc00bfc5d98f8e2c63356e6a415da8ab7a7b436""><code>dfc00bf</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48397"">#48397</a> on branch 1.5.x (WARN: Remove false positive warning for i...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/3f91207dca8971c723605243f6bc113c739ba637""><code>3f91207</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48572"">#48572</a> on branch 1.5.x (DOC: Fixing ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12292:3948,depend,dependabot,3948,https://hail.is,https://github.com/hail-is/hail/pull/12292,1,['depend'],['dependabot']
Integrability,"...2.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx-rtd-theme&package-manager=pip&previous-version=1.3.0&new-version=2.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14502:4597,Depend,Dependabot,4597,https://hail.is,https://github.com/hail-is/hail/pull/14502,9,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"...3.2.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=nanoid&package-manager=npm_and_yarn&previous-version=3.1.23&new-version=3.2.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11284:4012,Depend,Dependabot,4012,https://hail.is,https://github.com/hail-is/hail/pull/11284,18,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"...v2.15.0"">2.15.0</a> (2022-11-07)</h2>; <h3>Features</h3>; <ul>; <li>Add Autoclass support and sample (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1697"">#1697</a>) (<a href=""https://github.com/googleapis/java-storage/commit/82aacd7922573d6f4779f21cdc83de10616d7a08"">82aacd7</a>)</li>; <li>Update retries for Notifications (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1734"">#1734</a>) (<a href=""https://github.com/googleapis/java-storage/commit/0fb2f1823f9eff8534f15240321003f120fed3f4"">0fb2f18</a>)</li>; </ul>; <h3>Dependencies</h3>; <ul>; <li>Update dependency com.google.cloud:google-cloud-shared-dependencies to v3.0.6 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1761"">#1761</a>) (<a href=""https://github.com/googleapis/java-storage/commit/803a90b7747b8972f51d1407616c51084d97c589"">803a90b</a>)</li>; <li>Update dependency net.jqwik:jqwik to v1.7.1 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1758"">#1758</a>) (<a href=""https://github.com/googleapis/java-storage/commit/140e90911229c876de7b674dd1e61b278e8b07fd"">140e909</a>)</li>; <li>Update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.17 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1759"">#1759</a>) (<a href=""https://github.com/googleapis/java-storage/commit/7e3175a56a06dac0aa0841f221a486bb69b5c9bf"">7e3175a</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.13.1...v2.14.0"">2.14.0</a> (2022-10-26)</h2>; <h3>Google Cloud Storage gRPC API Preview</h3>; <p>The first release of <code>google-cloud-storage</code> with support for a subset of the Google Cloud Storage gRPC API which is in private preview. The most common operations have all been implemented and are available for experimentation.</p>; <p>Given not all public api surface of <code>google-cloud-storage</code> classes are supported for gRPC a new ann",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12456:6882,depend,dependabot,6882,https://hail.is,https://github.com/hail-is/hail/pull/12456,2,['depend'],['dependabot']
Integrability,"...v2.15.0"">2.15.0</a> (2022-11-07)</h2>; <h3>Features</h3>; <ul>; <li>Add Autoclass support and sample (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1697"">#1697</a>) (<a href=""https://github.com/googleapis/java-storage/commit/82aacd7922573d6f4779f21cdc83de10616d7a08"">82aacd7</a>)</li>; <li>Update retries for Notifications (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1734"">#1734</a>) (<a href=""https://github.com/googleapis/java-storage/commit/0fb2f1823f9eff8534f15240321003f120fed3f4"">0fb2f18</a>)</li>; </ul>; <h3>Dependencies</h3>; <ul>; <li>Update dependency com.google.cloud:google-cloud-shared-dependencies to v3.0.6 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1761"">#1761</a>) (<a href=""https://github.com/googleapis/java-storage/commit/803a90b7747b8972f51d1407616c51084d97c589"">803a90b</a>)</li>; <li>Update dependency net.jqwik:jqwik to v1.7.1 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1758"">#1758</a>) (<a href=""https://github.com/googleapis/java-storage/commit/140e90911229c876de7b674dd1e61b278e8b07fd"">140e909</a>)</li>; <li>Update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.17 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1759"">#1759</a>) (<a href=""https://github.com/googleapis/java-storage/commit/7e3175a56a06dac0aa0841f221a486bb69b5c9bf"">7e3175a</a>)</li>; </ul>; <h2>v2.14.0</h2>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.13.1...v2.14.0"">2.14.0</a> (2022-10-26)</h2>; <h3>Google Cloud Storage gRPC API Preview</h3>; <p>The first release of <code>google-cloud-storage</code> with support for a subset of the Google Cloud Storage gRPC API which is in private preview. The most common operations have all been implemented and are available for experimentation.</p>; <p>Given not all public api surface of <code>google-cloud-storage</code> classes are supported ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12456:1370,depend,dependabot,1370,https://hail.is,https://github.com/hail-is/hail/pull/12456,2,['depend'],['dependabot']
Integrability,"..1.2.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=minimist&package-manager=npm_and_yarn&previous-version=1.2.5&new-version=1.2.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/netw",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11653:1577,Depend,Dependabot,1577,https://hail.is,https://github.com/hail-is/hail/pull/11653,9,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"..</li>; <li><a href=""https://github.com/apache/spark/commit/be891ad99083564a7bf7f421e00b2cc4759a679f""><code>be891ad</code></a> [SPARK-39551][SQL][3.2] Add AQE invalid plan check</li>; <li><a href=""https://github.com/apache/spark/commit/1c0bd4c15a28d7c6a2dca846a5b8d0eb1d152aae""><code>1c0bd4c</code></a> [SPARK-39656][SQL][3.2] Fix wrong namespace in DescribeNamespaceExec</li>; <li><a href=""https://github.com/apache/spark/commit/3d084fe3217bea9af4c544f10ead8a2e5b97dad4""><code>3d084fe</code></a> [SPARK-39677][SQL][DOCS][3.2] Fix args formatting of the regexp and like func...</li>; <li>Additional commits viewable in <a href=""https://github.com/apache/spark/compare/v3.1.3...v3.2.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyspark&package-manager=pip&previous-version=3.1.3&new-version=3.2.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12452:2495,depend,dependabot-security-updates,2495,https://hail.is,https://github.com/hail-is/hail/pull/12452,1,['depend'],['dependabot-security-updates']
Integrability,"..</li>; <li><a href=""https://github.com/jaraco/zipp/commit/2ec3ed8567d0842675c38fd8ef0a28db668e602d""><code>2ec3ed8</code></a> Add another test at another magnitude.</li>; <li><a href=""https://github.com/jaraco/zipp/commit/d9bf5aab8b39c6a124d9499ae0315d3bf2ac2f46""><code>d9bf5aa</code></a> Fix name generator for width=1</li>; <li>Additional commits viewable in <a href=""https://github.com/jaraco/zipp/compare/v3.17.0...v3.18.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=zipp&package-manager=pip&previous-version=3.17.0&new-version=3.18.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14473:3346,depend,dependabot-automerge-start,3346,https://hail.is,https://github.com/hail-is/hail/pull/14473,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"..</li>; <li><a href=""https://github.com/lepture/authlib/commit/fca7f8523042cd9eadc68a1be091af9bc4ecab8b""><code>fca7f85</code></a> fix assertion client for httpx</li>; <li><a href=""https://github.com/lepture/authlib/commit/4d8a6ef7775dbe7033bb6d3efbc1919ff13579aa""><code>4d8a6ef</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/lepture/authlib/issues/390"">#390</a> from minddistrict/parameterize-signing-algoritm-for-r...</li>; <li><a href=""https://github.com/lepture/authlib/commit/1e511edf07afcf14b4ad6704a7333eb5e78ef99a""><code>1e511ed</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/lepture/authlib/issues/393"">#393</a> from nam3less/maintain-0.15-bugfix-377</li>; <li>Additional commits viewable in <a href=""https://github.com/lepture/authlib/compare/v0.11...v0.15.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=authlib&package-manager=pip&previous-version=0.11&new-version=0.15.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` wil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11483:6360,depend,dependency-name,6360,https://hail.is,https://github.com/hail-is/hail/pull/11483,1,['depend'],['dependency-name']
Integrability,"..v2.26.0"">2.26.0</a> (2023-08-03)</h2>; <h3>Features</h3>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/java-storage/blob/main/CHANGELOG.md"">com.google.cloud:google-cloud-storage's changelog</a>.</em></p>; <blockquote>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.26.1...v2.27.0"">2.27.0</a> (2023-09-12)</h2>; <h3>Features</h3>; <ul>; <li>Add new JournalingBlobWriteSessionConfig usable with gRPC transport (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2194"">#2194</a>) (<a href=""https://github.com/googleapis/java-storage/commit/8880d94c3d1a737dd4492cf66a16ba5e08633a70"">8880d94</a>)</li>; <li>Follow-up CLI Improvements (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2184"">#2184</a>) (<a href=""https://github.com/googleapis/java-storage/commit/d9859768081ea6f872097851d3e318b5bad384d9"">d985976</a>)</li>; <li>Initial CLI for SSB integration and Workload 1 (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2166"">#2166</a>) (<a href=""https://github.com/googleapis/java-storage/commit/a349735e7fe108e623a330afec0c8cd608ebeef9"">a349735</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <ul>; <li>A resumable session without a Range header should be interpreted as 0 length (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2182"">#2182</a>) (<a href=""https://github.com/googleapis/java-storage/commit/53022011d83e6a8515a5ba008fc45fc2dae39cea"">5302201</a>)</li>; <li>Update User-Agent handling for resumable uploads (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2168"">#2168</a>) (<a href=""https://github.com/googleapis/java-storage/commit/665b714f421d3c13b557d0ff71460c328c010856"">665b714</a>)</li>; <li>Update version resolution logic to be more resilient (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2169"">#2169</a>) (<a href=",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13624:6978,integrat,integration,6978,https://hail.is,https://github.com/hail-is/hail/pull/13624,1,['integrat'],['integration']
Integrability,".0 to 3.7.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/272"">#272</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/e5c813173b8811b30f4a30eeba56fa8808ab15bb""><code>e5c8131</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/271"">#271</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c7e10db3d0965422122bef263fb36f6fd7572330""><code>c7e10db</code></a> Fix linter configs</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/6af8bf421a799208b27d57c6bf69de0d998fedec""><code>6af8bf4</code></a> Bump pre-commit from 2.15 to 2.16.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/269"">#269</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c71bbb5b5d7330f6dabfde7a1adec30a4611c0be""><code>c71bbb5</code></a> Bump docutils from 0.18 to 0.18.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/266"">#266</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/async-timeout/compare/v3.0.1...v4.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=async-timeout&package-manager=pip&previous-version=3.0.1&new-version=4.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:6124,depend,dependabot,6124,https://hail.is,https://github.com/hail-is/hail/pull/11465,1,['depend'],['dependabot']
Integrability,".0.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-requests&package-manager=pip&previous-version=2.27.30&new-version=2.28.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11967:915,Depend,Dependabot,915,https://hail.is,https://github.com/hail-is/hail/pull/11967,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,".1 - 2022-04-02</h1>; <h3>Fixes</h3>; <ul>; <li>Fix regression for <code>repo: local</code> hooks running <code>python&lt;3.7</code>; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2324"">#2324</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; </ul>; <h1>2.18.0 - 2022-04-02</h1>; <h3>Features</h3>; <ul>; <li>Keep <code>GIT_HTTP_PROXY_AUTHMETHOD</code> in git environ.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2272"">#2272</a> PR by <a href=""https://github.com/VincentBerthier""><code>@​VincentBerthier</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2271"">#2271</a> issue by <a href=""https://github.com/VincentBerthier""><code>@​VincentBerthier</code></a>.</li>; </ul>; </li>; <li>Support both <code>cs</code> and <code>coursier</code> executables for coursier hooks.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2293"">#2293</a> PR by <a href=""https://github.com/Holzhaus""><code>@​Holzhaus</code></a>.</li>; </ul>; </li>; <li>Include more information in errors for <code>language_version</code> /; <code>additional_dependencies</code> for languages which do not support them.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2315"">#2315</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>Have autoupdate preferentially pick tags which look like versions when; there are multiple equivalent tags.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2312"">#2312</a> PR by <a href=""https://github.com/mblayman""><code>@​mblayman</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2311"">#2311</a> issue by <a href=""https://github.com/mblayman""><code>@​mblayman</code></a>.</li>; </ul>; </li>; <li>Upgrade <c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11731:6438,depend,dependabot,6438,https://hail.is,https://github.com/hail-is/hail/pull/11731,1,['depend'],['dependabot']
Integrability,".1 in /dependencies/default</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/ef3b3477070d6a270e1bb2c1d438c64dba42724c""><code>ef3b347</code></a> Build(deps): Bump packaging from 23.2 to 24.0 in /dependencies/default</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/b22d84e1f0d53920352be4c66d1b6c7f7a9ce005""><code>b22d84e</code></a> [docs] Fixes the example showing how to run all tests in a session-scoped loop.</li>; <li>Additional commits viewable in <a href=""https://github.com/pytest-dev/pytest-asyncio/compare/v0.21.1...v0.23.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest-asyncio&package-manager=pip&previous-version=0.21.1&new-version=0.23.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ign",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14507:9526,Depend,Dependabot,9526,https://hail.is,https://github.com/hail-is/hail/pull/14507,1,['Depend'],['Dependabot']
Integrability,".11 (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3052"">fonttools/fonttools#3052</a>).</li>; </ul>; <h2>4.39.2</h2>; <ul>; <li>[varLib] Fixed regression introduced in 4.39.1 whereby an incomplete 'STAT' table would be built even though a DesignSpace v5 did contain 'STAT' definitions (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3045"">#3045</a>, <a href=""https://redirect.github.com/fonttools/fonttools/issues/3046"">#3046</a>).</li>; </ul>; <p><strong>NOTE</strong>: The 4.39.1 distribution was &quot;yanked&quot; from PyPI to prevent users from accidentally upgrading to it.</p>; <h2>4.39.1</h2>; <ul>; <li>[avar2] Added experimental support for reading/writing avar version 2 as specified in this draft proposal:; <a href=""https://github.com/harfbuzz/boring-expansion-spec/blob/main/avar2.md"">https://github.com/harfbuzz/boring-expansion-spec/blob/main/avar2.md</a></li>; <li>[glifLib] Wrap underlying XML library exceptions with GlifLibError when parsing GLIFs, and also print the name and path of the glyph that fails to be parsed (<a href=""https://redirect.github.com/fonttools/fonttools/pull/3029"">fonttools/fonttools#3029</a>).</li>; <li>[feaLib] Consult avar for normalizing user-space values in ConditionSets and in VariableScalars (<a href=""https://redirect.github.com/fonttools/fonttools/pull/3042"">fonttools/fonttools#3042</a>, <a href=""https://redirect.github.com/fonttools/fonttools/pull/3043"">fonttools/fonttools#3043</a>).</li>; <li>[ttProgram] Handle string input to Program.fromAssembly() (<a href=""https://redirect.github.com/fonttools/fonttools/pull/3038"">fonttools/fonttools#3038</a>).</li>; <li>[otlLib] Added a config option to emit GPOS 7 lookups, currently disabled by default because of a macOS bug (<a href=""https://redirect.github.com/fonttools/fonttools/pull/3034"">fonttools/fonttools#3034</a>).</li>; <li>[COLRv1] Added method to automatically compute ClipBoxes (<a href=""https://redirect.github.com/fonttools/fonttools/pull/3027"">f",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12910:1598,Wrap,Wrap,1598,https://hail.is,https://github.com/hail-is/hail/pull/12910,1,['Wrap'],['Wrap']
Integrability,".11b1 to 21.12b0 (<a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/383"">#383</a>)</li>; <li><a href=""https://github.com/aio-libs/janus/commit/883e82bea0af1d12a68e92148b75b3344b31227a""><code>883e82b</code></a> Update README.rst</li>; <li><a href=""https://github.com/aio-libs/janus/commit/2e30d8a0f3c77c383a39da9b5c233a5c93a049fb""><code>2e30d8a</code></a> Bump coverage from 6.1.2 to 6.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/382"">#382</a>)</li>; <li>See full diff in <a href=""https://github.com/aio-libs/janus/compare/v0.7.0...v1.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=janus&package-manager=pip&previous-version=0.7.0&new-version=1.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12436:2805,Depend,Dependabot,2805,https://hail.is,https://github.com/hail-is/hail/pull/12436,1,['Depend'],['Dependabot']
Integrability,".12"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jupyterlab&package-manager=pip&previous-version=4.0.9&new-version=4.0.12)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14218:15877,depend,dependabot,15877,https://hail.is,https://github.com/hail-is/hail/pull/14218,11,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,".12.1...v4.13.0"">https://github.com/python-jsonschema/jsonschema/compare/v4.12.1...v4.13.0</a></p>; <h2>v4.12.1</h2>; <h2>What's Changed</h2>; <ul>; <li>Use rST markers in README by <a href=""https://github.com/hynek""><code>@​hynek</code></a> in <a href=""https://github-redirect.dependabot.com/python-jsonschema/jsonschema/pull/987"">python-jsonschema/jsonschema#987</a></li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.12.0...v4.12.1"">https://github.com/python-jsonschema/jsonschema/compare/v4.12.0...v4.12.1</a></p>; <h2>v4.12.0</h2>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.11.0...v4.12.0"">https://github.com/python-jsonschema/jsonschema/compare/v4.11.0...v4.12.0</a></p>; <h2>v4.11.0</h2>; <h2>What's Changed</h2>; <ul>; <li>jsonschema deserves a ✨fancy✨ readme by <a href=""https://github.com/hynek""><code>@​hynek</code></a> in <a href=""https://github-redirect.dependabot.com/python-jsonschema/jsonschema/pull/983"">python-jsonschema/jsonschema#983</a></li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.10.3...v4.11.0"">https://github.com/python-jsonschema/jsonschema/compare/v4.10.3...v4.11.0</a></p>; <h2>v4.10.3</h2>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.10.2...v4.10.3"">https://github.com/python-jsonschema/jsonschema/compare/v4.10.2...v4.10.3</a></p>; <h2>v4.10.2</h2>; <ul>; <li>Fix a second place where subclasses may have added attrs attributes (<a href=""https://github-redirect.dependabot.com/python-jsonschema/jsonschema/issues/982"">#982</a>).</li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.10.1...v4.10.2"">https://github.com/python-jsonschema/jsonschema/compare/v4.10.1...v4.10.2</a></p>; <h2>v4.10.1</h2>; <ul>; <li>Fix Validator.evolve (and APIs like <",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12163:2115,depend,dependabot,2115,https://hail.is,https://github.com/hail-is/hail/pull/12163,1,['depend'],['dependabot']
Integrability,".13.1, update changelog</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/v2.12.2...v2.13.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pylint&package-manager=pip&previous-version=2.12.2&new-version=2.13.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11702:5394,Depend,Dependabot,5394,https://hail.is,https://github.com/hail-is/hail/pull/11702,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,".16...1.26.17"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.16&new-version=1.26.17)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13762:3160,Depend,Dependabot,3160,https://hail.is,https://github.com/hail-is/hail/pull/13762,45,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,".16.18.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-six&package-manager=pip&previous-version=1.16.15&new-version=1.16.18)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12114:907,Depend,Dependabot,907,https://hail.is,https://github.com/hail-is/hail/pull/12114,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,".16.19.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-six&package-manager=pip&previous-version=1.16.15&new-version=1.16.19)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12131:907,Depend,Dependabot,907,https://hail.is,https://github.com/hail-is/hail/pull/12131,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,".17...1.26.18"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.17&new-version=1.26.18)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13842:2277,Depend,Dependabot,2277,https://hail.is,https://github.com/hail-is/hail/pull/13842,45,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,".19</code>_. Patch by Adam Turner.</li>; </ul>; <p>.. _Docutils 0.19: <a href=""https://docutils.sourceforge.io/RELEASE-NOTES.html#release-0-19-2022-07-05"">https://docutils.sourceforge.io/RELEASE-NOTES.html#release-0-19-2022-07-05</a></p>; <h2>Deprecated</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10467"">#10467</a>: Deprecated <code>sphinx.util.stemmer</code> in favour of <code>snowballstemmer</code>.; Patch by Adam Turner.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9856"">#9856</a>: Deprecated <code>sphinx.ext.napoleon.iterators</code>.</li>; </ul>; <h2>Features added</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10444"">#10444</a>: html theme: Allow specifying multiple CSS files through the <code>stylesheet</code>; setting in <code>theme.conf</code> or by setting <code>html_style</code> to an iterable of strings.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10366"">#10366</a>: std domain: Add support for emphasising placeholders in :rst:dir:<code>option</code>; directives through a new :confval:<code>option_emphasise_placeholders</code> configuration; option.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10439"">#10439</a>: std domain: Use the repr of some variables when displaying warnings,; making whitespace issues easier to identify.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10571"">#10571</a>: quickstart: Reduce content in the generated <code>conf.py</code> file. Patch by; Pradyun Gedam.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10648"">#10648</a>: LaTeX: CSS-named-alike additional :ref:<code>'sphinxsetup' &lt;latexsphinxsetup&gt;</code>; keys allow to configure four separate border-widths, four paddings, four; corner radii, a shadow (possibly inset), colours for border, background, shado",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12165:3236,depend,dependabot,3236,https://hail.is,https://github.com/hail-is/hail/pull/12165,1,['depend'],['dependabot']
Integrability,".1</li>; <li><a href=""https://github.com/pallets/click/commit/e4aceee8d2bf7fe9461915b0a21c4359ddcb8dc2""><code>e4aceee</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2224"">#2224</a> from pallets/release-8.1.0</li>; <li><a href=""https://github.com/pallets/click/commit/f8d811e5d5644aca8d32eebff196bf7c659ebf45""><code>f8d811e</code></a> release version 8.1.0</li>; <li><a href=""https://github.com/pallets/click/commit/20c88f02788586a80e6d867854c8313eaba5ad6e""><code>20c88f0</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2223"">#2223</a> from pallets/env-var</li>; <li><a href=""https://github.com/pallets/click/commit/8d7f03dac8739afed890af0c0921965786c5e83c""><code>8d7f03d</code></a> treat empty auto_envvar as None</li>; <li><a href=""https://github.com/pallets/click/commit/ef11be6e49e19a055fe7e5a89f0f1f4062c68dba""><code>ef11be6</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2041"">#2041</a> from spanglerco/shell-completion-option-values</li>; <li>Additional commits viewable in <a href=""https://github.com/pallets/click/compare/8.0.4...8.1.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=click&package-manager=pip&previous-version=8.0.4&new-version=8.1.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11721:6619,depend,dependabot,6619,https://hail.is,https://github.com/hail-is/hail/pull/11721,1,['depend'],['dependabot']
Integrability,".2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jupyter-core&package-manager=pip&previous-version=5.7.1&new-version=5.7.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14484:5538,depend,dependabot,5538,https://hail.is,https://github.com/hail-is/hail/pull/14484,11,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,".2.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=google-auth-oauthlib&package-manager=pip&previous-version=0.8.0&new-version=1.2.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14510:11269,Depend,Dependabot,11269,https://hail.is,https://github.com/hail-is/hail/pull/14510,9,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,".2.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/python-api-core/releases"">google-api-core[grpc]'s releases</a>.</em></p>; <blockquote>; <h2>v2.8.2</h2>; <h2><a href=""https://github.com/googleapis/python-api-core/compare/v2.8.1...v2.8.2"">2.8.2</a> (2022-06-13)</h2>; <h3>Bug Fixes</h3>; <ul>; <li><strong>deps:</strong> allow protobuf &lt; 5.0.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/400"">#400</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/8f73d2ee2d3af2201f877aa7e2f7361147759dc7"">8f73d2e</a>)</li>; <li>drop support for grpc-gcp (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/401"">#401</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/5da6733a475c436efc11b14889af73b3a0e20379"">5da6733</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>fix changelog header to consistent size (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/394"">#394</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/ac266e935bc4e7c6dff250384407e7a60d8dba90"">ac266e9</a>)</li>; <li>Fix typo in the BackgroundConsumer docstring (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/395"">#395</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/0eb727f92314db3c4383754514f75a49ba02e27b"">0eb727f</a>)</li>; </ul>; <h2>v2.8.1</h2>; <h3><a href=""https://github.com/googleapis/python-api-core/compare/v2.8.0...v2.8.1"">2.8.1</a> (2022-05-26)</h3>; <h3>Bug Fixes</h3>; <ul>; <li><strong>deps:</strong> require googleapis-common-protos &gt;= 1.56.2 (<a href=""https://github.com/googleapis/python-api-core/commit/d84d66c2a4107f5f9a20c53e870a27fb1250ea3d"">d84d66c</a>)</li>; <li><strong>deps:</strong> require protobuf&gt;= 3.15.0, &lt;4.0.0dev (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/385"">#385</a>) (<a href=""https://g",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11970:1090,depend,dependabot,1090,https://hail.is,https://github.com/hail-is/hail/pull/11970,1,['depend'],['dependabot']
Integrability,".2022-06-07&amp;type=Issues""><code>@​utkonos</code></a></p>; <h2>7.3.2</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v7.3.1...c81771416d9e09e0e92be799f3e8549d0db57e43"">Full Changelog</a>)</p>; <h3>Enhancements made</h3>; <ul>; <li>Correct <code>Any</code> type annotations. <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/791"">#791</a> (<a href=""https://github.com/joouha""><code>@​joouha</code></a>)</li>; </ul>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>[pre-commit.ci] pre-commit autoupdate <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/792"">#792</a> (<a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a>)</li>; <li>Use hatch backend <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/789"">#789</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; <li>[pre-commit.ci] pre-commit autoupdate <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/788"">#788</a> (<a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a>)</li>; <li>Use flit build backend <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/781"">#781</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/c26ce9f8f9c5b697a3f78afeee60ab23e94c3fca""><code>c26ce9f</code></a> Publish 7.3.4</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/fd7525dcace2313d25e89ae9511078efc11b7499""><code>fd7525d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/805"">#805</a> from jupyter/changelog-c21f25fee76511ec8f3ae1e2b5040e36</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/51e071a973b232deaefd4cbf11f00",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12110:7058,depend,dependabot,7058,https://hail.is,https://github.com/hail-is/hail/pull/12110,1,['depend'],['dependabot']
Integrability,".24.14</li>; <li><a href=""https://github.com/boto/botocore/commit/ba0d095eeb62a2a293abadb54111df5fc0e2f0c8""><code>ba0d095</code></a> Update to latest models</li>; <li><a href=""https://github.com/boto/botocore/commit/a8c5cc855ecb91f5f64d73f2a15dfebc9e5e20e0""><code>a8c5cc8</code></a> Merge branch 'release-1.24.13' into develop</li>; <li>See full diff in <a href=""https://github.com/boto/botocore/compare/1.24.13...1.24.14"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=botocore&package-manager=pip&previous-version=1.24.13&new-version=1.24.14)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11534:2082,depend,dependabot-automerge-start,2082,https://hail.is,https://github.com/hail-is/hail/pull/11534,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,".26.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jupyterlab-server&package-manager=pip&previous-version=2.25.3&new-version=2.26.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14483:9273,Depend,Dependabot,9273,https://hail.is,https://github.com/hail-is/hail/pull/14483,9,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,".2</h2>; <h1>C++</h1>; <ul>; <li>Reduce memory consumption of MessageSet parsing</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf"">Security Advisory for C++ and Python users</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/protocolbuffers/protobuf/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.1&new-version=4.21.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12227:1262,depend,dependabot-automerge-start,1262,https://hail.is,https://github.com/hail-is/hail/pull/12227,4,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,".3-patch</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/c9ee3ca8820531cd709bb8f8a58a736813346861""><code>c9ee3ca</code></a> deps: update dependency org.apache.httpcomponents:httpmime to v4.5.14 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1796"">#1796</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/cf900f4139f30f89e3c0784467ddc12cc00cf81c""><code>cf900f4</code></a> deps: update dependency org.apache.httpcomponents:httpclient to v4.5.14 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1795"">#1795</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/099a6165722464b46d37206af274a637d3f0461a""><code>099a616</code></a> test(deps): update cross product test dependencies (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1792"">#1792</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/3184d65cce1368c2f39ff85a6ed02cf536902244""><code>3184d65</code></a> deps: update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.19...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/7d6742115bcea6b848a289fdf5c4e4bbafc4cf18""><code>7d67421</code></a> build(deps): update dependency com.google.cloud:google-cloud-shared-config to...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/3bf403e94c035e6cf936e062a1ced2b5221b3912""><code>3bf403e</code></a> deps: update dependency org.apache.httpcomponents:httpcore to v4.4.16 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1786"">#1786</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/java-storage/compare/v1.106.0...v2.16.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.cloud:google-cloud-storage&package-manager=gradle&previous-ver",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12545:12046,depend,dependency,12046,https://hail.is,https://github.com/hail-is/hail/pull/12545,1,['depend'],['dependency']
Integrability,".3.0 to 22.8.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/psf/black/releases"">black's releases</a>.</em></p>; <blockquote>; <h2>22.8.0</h2>; <h3>Highlights</h3>; <ul>; <li>Python 3.11 is now supported, except for <em>blackd</em> as aiohttp does not support 3.11 as of publishing (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3234"">#3234</a>)</li>; <li>This is the last release that supports running <em>Black</em> on Python 3.6 (formatting 3.6 code will continue to be supported until further notice)</li>; <li>Reword the stability policy to say that we may, in rare cases, make changes that affect code that was not previously formatted by <em>Black</em> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3155"">#3155</a>)</li>; </ul>; <h3>Stable style</h3>; <ul>; <li>Fix an infinite loop when using <code># fmt: on/off</code> in the middle of an expression or code block (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3158"">#3158</a>)</li>; <li>Fix incorrect handling of <code># fmt: skip</code> on colon (<code>:</code>) lines (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3148"">#3148</a>)</li>; <li>Comments are no longer deleted when a line had spaces removed around power operators (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2874"">#2874</a>)</li>; </ul>; <h3>Preview style</h3>; <ul>; <li>Single-character closing docstring quotes are no longer moved to their own line as this is invalid. This was a bug introduced in version 22.6.0. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3166"">#3166</a>)</li>; <li><code>--skip-string-normalization</code> / <code>-S</code> now prevents docstring prefixes from being normalized as expected (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3168"">#3168</a>)</li>; <li>When using <code>--skip-magic-trailing-comma</code> or <code>-C</code>, trailing commas are stripped",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12174:1046,depend,dependabot,1046,https://hail.is,https://github.com/hail-is/hail/pull/12174,1,['depend'],['dependabot']
Integrability,".3.2</h2>; <h2>7.3.2</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v7.3.1...c81771416d9e09e0e92be799f3e8549d0db57e43"">Full Changelog</a>)</p>; <h3>Enhancements made</h3>; <ul>; <li>Correct <code>Any</code> type annotations. <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/791"">#791</a> (<a href=""https://github.com/joouha""><code>@​joouha</code></a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jupyter/jupyter_client/blob/main/CHANGELOG.md"">jupyter-client's changelog</a>.</em></p>; <blockquote>; <h2>7.3.4</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v7.3.3...ca4cb2d6a4b95a6925de85a47b323d2235032c74"">Full Changelog</a>)</p>; <h3>Bugs fixed</h3>; <ul>; <li>Revert latest changes to <code>ThreadedZMQSocketChannel</code> because they break Qtconsole <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/803"">#803</a> (<a href=""https://github.com/ccordoba12""><code>@​ccordoba12</code></a>)</li>; </ul>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Fix sphinx 5.0 support <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/804"">#804</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; <li>[pre-commit.ci] pre-commit autoupdate <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/799"">#799</a> (<a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_client/graphs/contributors?from=2022-06-07&amp;to=2022-06-08&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Ablink1073+updated%3A2022-06-07..2022-06-08&amp;type=Issues""><code>@​blink1073</code></a> | <a href=""h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12110:3856,depend,dependabot,3856,https://hail.is,https://github.com/hail-is/hail/pull/12110,1,['depend'],['dependabot']
Integrability,".34.0 to 8.10.0.; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/ipython/ipython/commit/15ea1ed5a886d6c19c1cc4856f2cf04a2a547c57""><code>15ea1ed</code></a> release 8.10.0</li>; <li><a href=""https://github.com/ipython/ipython/commit/560ad109197c0f8373865896af369bb3b36fd229""><code>560ad10</code></a> DOC: Update what's new for 8.10 (<a href=""https://github-redirect.dependabot.com/ipython/ipython/issues/13939"">#13939</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/7557ade0ed927475d5ab5b573d0ea4febfb22683""><code>7557ade</code></a> DOC: Update what's new for 8.10</li>; <li><a href=""https://github.com/ipython/ipython/commit/385d69325319a5972ee9b5983638e3617f21cb1f""><code>385d693</code></a> Merge pull request from GHSA-29gw-9793-fvw7</li>; <li><a href=""https://github.com/ipython/ipython/commit/e548ee23ac460a99901f1cd43b94ae84a35ec393""><code>e548ee2</code></a> Swallow potential exceptions from showtraceback() (<a href=""https://github-redirect.dependabot.com/ipython/ipython/issues/13934"">#13934</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/0694b08b436203817059ec7e7136cf8561a6f013""><code>0694b08</code></a> MAINT: mock slowest test. (<a href=""https://github-redirect.dependabot.com/ipython/ipython/issues/13885"">#13885</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/865591252a67c6907fe03228b4053305715286e6""><code>8655912</code></a> MAINT: mock slowest test.</li>; <li><a href=""https://github.com/ipython/ipython/commit/a011765b44febfb11bae122d2ed7db763621ac8f""><code>a011765</code></a> Isolate the attack tests with setUp and tearDown methods</li>; <li><a href=""https://github.com/ipython/ipython/commit/c7a9470e540392c575aac46c3ee5cf4fe5123eb1""><code>c7a9470</code></a> Add some regression tests for this change</li>; <li><a href=""https://github.com/ipython/ipython/commit/fd34cf5f1f6e243243c738c6e0cf62eb682c4d68""><code>fd34cf5</code></a> Swallow potential exceptions from showtraceback()</li>; <li>Additio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12683:1053,depend,dependabot,1053,https://hail.is,https://github.com/hail-is/hail/pull/12683,1,['depend'],['dependabot']
Integrability,".4.1.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-chardet&package-manager=pip&previous-version=5.0.4&new-version=5.0.4.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12537:911,Depend,Dependabot,911,https://hail.is,https://github.com/hail-is/hail/pull/12537,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,".6.0</strong></p>; <ul>; <li>; <p>Fixed <code>TypeError</code> in <code>get_current_task()</code> on asyncio when using a custom <code>Task</code> factory</p>; </li>; <li>; <p>Updated type annotations on <code>run_process()</code> and <code>open_process()</code>:</p>; <ul>; <li><code>command</code> now accepts accepts bytes and sequences of bytes</li>; <li><code>stdin</code>, <code>stdout</code> and <code>stderr</code> now accept file-like objects; (PR by John T. Wodder II)</li>; </ul>; </li>; <li>; <p>Changed the pytest plugin to run both the setup and teardown phases of asynchronous; generator fixtures within a single task to enable use cases such as cancel scopes and; task groups where a context manager straddles the <code>yield</code></p>; </li>; </ul>; <p><strong>3.5.0</strong></p>; <ul>; <li>Added <code>start_new_session</code> keyword argument to <code>run_process()</code> and <code>open_process()</code>; (PR by Jordan Speicher)</li>; <li>Fixed deadlock in synchronization primitives on asyncio which can happen if a task acquiring a; primitive is hit with a native (not AnyIO) cancellation with just the right timing, leaving the; next acquiring task waiting forever (<code>[#398](https://github.com/agronholm/anyio/issues/398) &lt;https://github.com/agronholm/anyio/issues/398&gt;</code>_)</li>; <li>Added workaround for bpo-46313_ to enable compatibility with OpenSSL 3.0</li>; </ul>; <p>.. _bpo-46313: <a href=""https://bugs.python.org/issue46313"">https://bugs.python.org/issue46313</a></p>; <p><strong>3.4.0</strong></p>; <ul>; <li>; <p>Added context propagation to/from worker threads in <code>to_thread.run_sync()</code>,; <code>from_thread.run()</code> and <code>from_thread.run_sync()</code>; (<code>[#363](https://github.com/agronholm/anyio/issues/363) &lt;https://github.com/agronholm/anyio/issues/363&gt;</code>_; partially based on a PR by Sebastián; Ramírez)</p>; <p><strong>NOTE</strong>: Requires Python 3.7 to work properly on asyncio!</p>; </li>; <li>; <p>Fixed r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12362:1837,synchroniz,synchronization,1837,https://hail.is,https://github.com/hail-is/hail/pull/12362,1,['synchroniz'],['synchronization']
Integrability,".6.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-chardet&package-manager=pip&previous-version=5.0.4.5&new-version=5.0.4.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13034:915,Depend,Dependabot,915,https://hail.is,https://github.com/hail-is/hail/pull/13034,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,".7', 'isodate==0.6.1', 'janus==1.0.0', 'jinja2==3.1.4', 'jmespath==1.0.1', 'jproperties==2.1.1', 'markupsafe==2.1.5', 'msal==1.29.0', 'msal-extensions==1.2.0', 'msrest==0.7.1', 'multidict==6.0.5', 'nest-asyncio==1.6.0', 'numpy==1.26.4', 'oauthlib==3.2.2', 'orjson==3.10.6', 'packaging==24.1', 'pandas==2.2.2', 'parsimonious==0.10.0', 'pillow==10.4.0', 'plotly==5.22.0', 'portalocker==2.10.0', 'protobuf==3.20.2', 'py4j==0.10.9.7', 'pyasn1==0.6.0', 'pyasn1-modules==0.4.0', 'pycares==4.4.0', 'pycparser==2.22', 'pygments==2.18.0', 'pyjwt==2.8.0', 'python-dateutil==2.9.0.post0', 'python-json-logger==2.0.7', 'pytz==2024.1', 'pyyaml==6.0.1', 'regex==2024.5.15', 'requests==2.32.3', 'requests-oauthlib==2.0.0', 'rich==12.6.0', 'rsa==4.9', 's3transfer==0.10.2', 'scipy==1.11.4', 'shellingham==1.5.4', 'six==1.16.0', 'sortedcontainers==2.4.0', 'tabulate==0.9.0', 'tenacity==8.4.2', 'tornado==6.4.1', 'typer==0.12.3', 'typing-extensions==4.12.2', 'tzdata==2024.1', 'urllib3==1.26.19', 'uvloop==0.19.0', 'wrapt==1.16.0', 'xyzservices==2024.6.0', 'yarl==1.9.4']; Collecting https://github.com/hail-is/jgscm/archive/v0.1.13+hail.zip; WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fef979a53d0>, 'Connection to github.com timed out. (connect timeout=15)')': /hail-is/jgscm/archive/v0.1.13+hail.zip; WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fef9797e050>, 'Connection to github.com timed out. (connect timeout=15)')': /hail-is/jgscm/archive/v0.1.13+hail.zip; WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fef979ba910>, 'Connection to github.com timed out.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14652:2543,wrap,wrapt,2543,https://hail.is,https://github.com/hail-is/hail/issues/14652,1,['wrap'],['wrapt']
Integrability,".7.1.; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/Azure/msrest-for-python/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=msrest&package-manager=pip&previous-version=0.6.21&new-version=0.7.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11965:911,Depend,Dependabot,911,https://hail.is,https://github.com/hail-is/hail/pull/11965,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,".7.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/Azure/azure-sdk-for-java/releases"">azure-identity's releases</a>.</em></p>; <blockquote>; <h2>azure-identity_1.7.1</h2>; <h2>1.7.1 (2022-11-17)</h2>; <h3>Features Added</h3>; <ul>; <li>Added user-agent header to Identity requests</li>; </ul>; <h2>azure-data-appconfiguration_1.3.9</h2>; <h2>1.3.9 (2022-11-09)</h2>; <h3>Other Changes</h3>; <h4>Dependency Updates</h4>; <ul>; <li>Updated <code>azure-core</code> to <code>1.34.0</code>.</li>; <li>Updated <code>azure-core-http-netty</code> to <code>1.12.7</code>.</li>; </ul>; <h2>azure-communication-chat_1.3.3</h2>; <h2>1.3.3 (2022-11-10)</h2>; <h3>Other Changes</h3>; <h4>Dependency Updates</h4>; <ul>; <li>Upgraded <code>azure-communication-common</code> to 1.2.3</li>; <li>Upgraded <code>azure-core</code> to 1.34.0</li>; </ul>; <h2>azure-data-schemaregistry_1.3.1</h2>; <h2>1.3.1 (2022-11-16)</h2>; <h3>Other Changes</h3>; <h4>Dependency Updates</h4>; <ul>; <li>Update <code>azure-core</code> dependency to <code>1.34.0</code>.</li>; <li>Update <code>azure-core-http-netty</code> dependency to <code>1.12.7</code>.</li>; </ul>; <h2>azure-sdk-bom_1.2.8</h2>; <p>No release notes provided.</p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/89123194fe6a4a2f2cdc58535abea9d75d753a79""><code>8912319</code></a> Identity 1.7.1 patch (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32140"">#32140</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/fe0a0dad4771fb7c6105cc412cf9cc8d10722e59""><code>fe0a0da</code></a> Updated versions after patch release. (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32231"">#32231</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/4fc24620f120643d18f85aca1bf3ee53daf7f124""><code>4fc2462</code></a> Increment versions",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12508:1064,Depend,Dependency,1064,https://hail.is,https://github.com/hail-is/hail/pull/12508,2,"['Depend', 'depend']","['Dependency', 'dependency']"
Integrability,".9.19...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/7d6742115bcea6b848a289fdf5c4e4bbafc4cf18""><code>7d67421</code></a> build(deps): update dependency com.google.cloud:google-cloud-shared-config to...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/3bf403e94c035e6cf936e062a1ced2b5221b3912""><code>3bf403e</code></a> deps: update dependency org.apache.httpcomponents:httpcore to v4.4.16 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1786"">#1786</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/java-storage/compare/v1.106.0...v2.16.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.cloud:google-cloud-storage&package-manager=gradle&previous-version=1.106.0&new-version=2.16.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12545:13104,depend,dependabot-security-updates,13104,https://hail.is,https://github.com/hail-is/hail/pull/12545,1,['depend'],['dependabot-security-updates']
Integrability,".910 to 0.920 (<a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/384"">#384</a>)</li>; <li><a href=""https://github.com/aio-libs/janus/commit/56b2d1d8dbd10cce28302a4e1c4224ce219c6246""><code>56b2d1d</code></a> Bump black from 21.11b1 to 21.12b0 (<a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/383"">#383</a>)</li>; <li><a href=""https://github.com/aio-libs/janus/commit/883e82bea0af1d12a68e92148b75b3344b31227a""><code>883e82b</code></a> Update README.rst</li>; <li><a href=""https://github.com/aio-libs/janus/commit/2e30d8a0f3c77c383a39da9b5c233a5c93a049fb""><code>2e30d8a</code></a> Bump coverage from 6.1.2 to 6.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/382"">#382</a>)</li>; <li>See full diff in <a href=""https://github.com/aio-libs/janus/compare/v0.7.0...v1.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=janus&package-manager=pip&previous-version=0.7.0&new-version=1.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12436:2589,depend,dependency-name,2589,https://hail.is,https://github.com/hail-is/hail/pull/12436,1,['depend'],['dependency-name']
Integrability,".942</li>; <li><a href=""https://github.com/python/mypy/commit/1c836685da13f11287ae6d6931c04337f881ec40""><code>1c83668</code></a> Let overload item have a wider return type than implementation (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/12435"">#12435</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/67088e558dc24a2c6c231db542a367923dfdc049""><code>67088e5</code></a> Pin the version of bugbear (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/12436"">#12436</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/367b29d4aac16fc7493abffe2df0d8f477c23923""><code>367b29d</code></a> Make order of processing the builtins SCC predictable (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/12431"">#12431</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/f81b228e66d8a95cc39247f189e7be7e894f7f92""><code>f81b228</code></a> Fix inheritance false positives with dataclasses/attrs (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/12411"">#12411</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/7e09c2a100209072429e290d2f7b9b8007b8629c""><code>7e09c2a</code></a> Support overriding dunder attributes in Enum subclass (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/12138"">#12138</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/837543efb616b14e2f800db6962d216621dee4d7""><code>837543e</code></a> Fix crash in match statement if class name is undefined (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/12417"">#12417</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/6606dbe98d09170d3ad810bc791a16d99ceb2281""><code>6606dbe</code></a> Allow non-final <strong>match_args</strong> and overriding (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/12415"">#12415</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/626147a761891362dbf6e845c99031e2e043d0f4""><code>626147a</code></a> Fix small conditional overl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11667:1244,depend,dependabot,1244,https://hail.is,https://github.com/hail-is/hail/pull/11667,2,['depend'],['dependabot']
Integrability,".: asyncio.run(foo()); ...:; (<Task finished name='Task-579' coro=<foo.<locals>.raises() done, defined at <ipython-input-7-ccfd397235b8>:2> exception=ValueError('unretrieved case')>, True, False); Task exception was never retrieved; future: <Task finished name='Task-579' coro=<foo.<locals>.raises() done, defined at <ipython-input-7-ccfd397235b8>:2> exception=ValueError('unretrieved case')>; Traceback (most recent call last):; File ""<ipython-input-7-ccfd397235b8>"", line 4, in raises; await asyncio.sleep(100); File ""/Users/dking/miniconda3/lib/python3.10/asyncio/tasks.py"", line 605, in sleep; return await future; asyncio.exceptions.CancelledError. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<ipython-input-7-ccfd397235b8>"", line 6, in raises; raise ValueError(message); ValueError: unretrieved case; ```. 5. And here is an example of ""retrieving"" the exception (by calling `Task.exception`). Notice we do not get the ""Task exception was never retrieved"" message. ```; In [8]: async def foo():; ...: async def raises(message):; ...: try:; ...: await asyncio.sleep(100); ...: finally:; ...: raise ValueError(message); ...:; ...: t = asyncio.create_task(raises('retrieved case')); ...: await asyncio.sleep(0) # let the other task run for a moment; ...: t.cancel(); ...: await asyncio.wait([t]); ...: print((t, t.done(), t.cancelled(), t.exception())); ...:; ...: asyncio.run(foo()); ...:; (<Task finished name='Task-599' coro=<foo.<locals>.raises() done, defined at <ipython-input-8-5fa396151822>:2> exception=ValueError('retrieved case')>, True, False, ValueError('retrieved case')); ```. ---. One more thing of interest, I confirmed that the ExitStack throws the first exception it encountered *after* performing all callbacks. ```ipython; In [6]: with ExitStack() as exit:; ...: def foo(i):; ...: print(str(i)); ...: raise ValueError(i); ...: exit.callback(foo, 1); ...: exit.callback(foo, 2); 2; 1; ---------------------------",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13876:4090,message,message,4090,https://hail.is,https://github.com/hail-is/hail/pull/13876,1,['message'],['message']
Integrability,".; 1921 """"""; -> 1922 return Env.backend().persist_table(self, storage_level); 1923 ; 1924 def unpersist(self) -> 'Table':. /databricks/python/lib/python3.8/site-packages/hail/backend/spark_backend.py in persist_table(self, t, storage_level); 294 ; 295 def persist_table(self, t, storage_level):; --> 296 return Table._from_java(self._jbackend.pyPersistTable(storage_level, self._to_java_table_ir(t._tir))); 297 ; 298 def unpersist_table(self, t):. /databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py in __call__(self, *args); 1302 ; 1303 answer = self.gateway_client.send_command(command); -> 1304 return_value = get_return_value(; 1305 answer, self.gateway_client, self.target_id, self.name); 1306 . /databricks/spark/python/pyspark/sql/utils.py in deco(*a, **kw); 115 def deco(*a, **kw):; 116 try:; --> 117 return f(*a, **kw); 118 except py4j.protocol.Py4JJavaError as e:; 119 converted = convert_exception(e.java_exception). /databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 324 value = OUTPUT_CONVERTER[type](answer[2:], gateway_client); 325 if answer[1] == REFERENCE_TYPE:; --> 326 raise Py4JJavaError(; 327 ""An error occurred while calling {0}{1}{2}.\n"".; 328 format(target_id, ""."", name), value). Py4JJavaError: An error occurred while calling o504.pyPersistTable.; : is.hail.utils.HailException: 1 samples and 12 covariates (including x) implies -11 degrees of freedom.; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:11); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:11); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.methods.LinearRegressionRowsSingle.execute(LinearRegression.scala:51); 	at is.hail.expr.ir.functions.WrappedMatrixToTableFunction.execute(RelationalFunctions.scala:51); 	at is.hail.expr.ir.TableToTableApply.execute(TableIR.scala:2936); 	at is.hail.expr.ir.TableIR.analyzeAndExecute(TableIR.scala:57); 	at is.hail.expr.ir.Interpret$.ap",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11413:3295,protocol,protocol,3295,https://hail.is,https://github.com/hail-is/hail/issues/11413,1,['protocol'],['protocol']
Integrability,".; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/protocolbuffers/protobuf/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.1&new-version=4.21.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12082:919,Depend,Dependabot,919,https://hail.is,https://github.com/hail-is/hail/pull/12082,34,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,".; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/python/typeshed/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=types-setuptools&package-manager=pip&previous-version=57.4.17&new-version=65.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12181:919,Depend,Dependabot,919,https://hail.is,https://github.com/hail-is/hail/pull/12181,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,".; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2170"">#2170</a> PR by <a href=""https://github.com/lorenzwalthert""><code>@​lorenzwalthert</code></a>.</li>; </ul>; </li>; <li>forbid overriding <code>entry</code> in <code>language: meta</code> hooks which breaks them.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2180"">#2180</a> issue by <a href=""https://github.com/DanKaplanSES""><code>@​DanKaplanSES</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2181"">#2181</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>always use <code>#!/bin/sh</code> on windows for hook script.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2182"">#2182</a> issue by <a href=""https://github.com/hushigome-visco""><code>@​hushigome-visco</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2187"">#2187</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; </ul>; <h1>2.16.0 - 2021-11-30</h1>; <h3>Features</h3>; <ul>; <li>add warning for regexes containing <code>[\/]</code> or <code>[/\\]</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2053"">#2053</a> PR by <a href=""https://github.com/radek-sprta""><code>@​radek-sprta</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2043"">#2043</a> issue by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>move hook template back to <code>bash</code> resolving shebang-portability issues.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2065"">#2065</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>add support for <code>fail_fast</code> at",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11460:10291,depend,dependabot,10291,https://hail.is,https://github.com/hail-is/hail/pull/11460,2,['depend'],['dependabot']
Integrability,".; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2170"">#2170</a> PR by <a href=""https://github.com/lorenzwalthert""><code>@​lorenzwalthert</code></a>.</li>; </ul>; </li>; <li>forbid overriding <code>entry</code> in <code>language: meta</code> hooks which breaks them.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2180"">#2180</a> issue by <a href=""https://github.com/DanKaplanSES""><code>@​DanKaplanSES</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2181"">#2181</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>always use <code>#!/bin/sh</code> on windows for hook script.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2182"">#2182</a> issue by <a href=""https://github.com/hushigome-visco""><code>@​hushigome-visco</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2187"">#2187</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; </ul>; <h2>pre-commit v2.16.0</h2>; <h3>Features</h3>; <ul>; <li>add warning for regexes containing <code>[\/]</code> or <code>[/\\]</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2053"">#2053</a> PR by <a href=""https://github.com/radek-sprta""><code>@​radek-sprta</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2043"">#2043</a> issue by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>move hook template back to <code>bash</code> resolving shebang-portability issues.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2065"">#2065</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>add support for <code>fail_fast</code> at ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11460:3810,depend,dependabot,3810,https://hail.is,https://github.com/hail-is/hail/pull/11460,2,['depend'],['dependabot']
Integrability,".; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2277"">#2277</a> PR by <a href=""https://github.com/lorenzwalthert""><code>@​lorenzwalthert</code></a>.</li>; </ul>; </li>; <li>Fix handling of git worktrees.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2252"">#2252</a> PR by <a href=""https://github.com/daschuer""><code>@​daschuer</code></a>.</li>; </ul>; </li>; <li>Fix handling of <code>$R_HOME</code> for R hooks.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2301"">#2301</a> PR by <a href=""https://github.com/jeff-m-sullivan""><code>@​jeff-m-sullivan</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2300"">#2300</a> issue by <a href=""https://github.com/jeff-m-sullivan""><code>@​jeff-m-sullivan</code></a>.</li>; </ul>; </li>; <li>Fix a rare race condition in change stashing.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2323"">#2323</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2287"">#2287</a> issue by <a href=""https://github.com/ian-h-chamberlain""><code>@​ian-h-chamberlain</code></a>.</li>; </ul>; </li>; </ul>; <h3>Updating</h3>; <ul>; <li>Remove python3.6 support. Note that pre-commit still supports running hooks written in older versions, but pre-commit itself requires python 3.7+.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2215"">#2215</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>pre-commit has migrated from the <code>master</code> branch to <code>main</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2302"">#2302</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11731:4201,depend,dependabot,4201,https://hail.is,https://github.com/hail-is/hail/pull/11731,1,['depend'],['dependabot']
Integrability,".; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2277"">#2277</a> PR by <a href=""https://github.com/lorenzwalthert""><code>@​lorenzwalthert</code></a>.</li>; </ul>; </li>; <li>Fix handling of git worktrees.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2252"">#2252</a> PR by <a href=""https://github.com/daschuer""><code>@​daschuer</code></a>.</li>; </ul>; </li>; <li>Fix handling of <code>$R_HOME</code> for R hooks.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2301"">#2301</a> PR by <a href=""https://github.com/jeff-m-sullivan""><code>@​jeff-m-sullivan</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2300"">#2300</a> issue by <a href=""https://github.com/jeff-m-sullivan""><code>@​jeff-m-sullivan</code></a>.</li>; </ul>; </li>; <li>Fix a rare race condition in change stashing.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2323"">#2323</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2287"">#2287</a> issue by <a href=""https://github.com/ian-h-chamberlain""><code>@​ian-h-chamberlain</code></a>.</li>; </ul>; </li>; </ul>; <h3>Updating</h3>; <ul>; <li>Remove python3.6 support. Note that pre-commit still supports running hooks; written in older versions, but pre-commit itself requires python 3.7+.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2215"">#2215</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>pre-commit has migrated from the <code>master</code> branch to <code>main</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2302"">#2302</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11731:9380,depend,dependabot,9380,https://hail.is,https://github.com/hail-is/hail/pull/11731,1,['depend'],['dependabot']
Integrability,".; It's just one step short of using containers - but since it doesn't require; a containerized OS, I think it works; for laptops etc. I believe the package could have all the stuff we currently manage my; manual install, viz JDK, Spark, Python-3.6,; R, R packages, as well as Hail and a friendly-C++17-capable compiler. All; without perturbing anything else; on the system. See https://bitnami.com. I took a similar approach at PhysicsSpeed, though without using any bitnami; tools because we had less than; zero dollars :-(. I don't know if this adds any value in the containerized/cloud environment,; where custom machine images; are presumably the way to go. But it makes setup easy for standalone use. Regards; Richard. On Thu, Aug 2, 2018 at 10:44 PM Richard Cownie <rcownie@broadinstitute.org>; wrote:. > We have a difference of opinion about the risks involved in using whatever; > compiler happens to show up as $(CXX); > to try to compile arbitrarily large auto-generated C++ files, and maybe; > about what happens when that fails; > and gives an error message about something in the middle of 12000 lines of; > code that bears no obvious relationship; > to what the user is doing. Or when that compiler takes 15 minutes to; > compile it. It's the C++ equivalent of; > the JVM ""no, that's just too much bytecode"". Or worst of all, it compiles; > it but the code gives the wrong answers; > because that particular compiler has a bug, and we never tested the; > combination of our codegen with *that*; > compiler/version.; >; > A couple of years ago I was seeing g++ take 40-60 seconds to compile; > something that clang did in 2 seconds; > (fairly heavily templated code generated for an SQL query, so very much in; > the same ballpark as parts of Hail),; > which contributes to my concern about this, especially on linux where g++; > is the default.; >; > So in the long run I expect we'll ship a compiler, or specify a compiler.; > But that becomes a problem in itself; > if we want the sh",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3973#issuecomment-410235287:1386,message,message,1386,https://hail.is,https://github.com/hail-is/hail/pull/3973#issuecomment-410235287,1,['message'],['message']
Integrability,".</em></p>; <blockquote>; <h1>2.12.0 (2022-10-28)</h1>; <ul>; <li>Migrated from <code>aioredis</code> to <code>redis</code> (if using redis without installing; <code>aiohttp-session[aioredis]</code> then it will be necessary to manually install <code>redis</code>).</li>; </ul>; <h1>2.11.0 (2021-01-31)</h1>; <ul>; <li>Support initialising <code>EncryptedCookieStorage</code> with <code>Fernet</code> object directly.</li>; <li>Fix an issue where the session would get reset before the cookie expiry.</li>; </ul>; <h1>2.10.0 (2021-12-30)</h1>; <ul>; <li>Typing support</li>; <li>Add samesite cookie option</li>; <li>Support aioredis 2</li>; </ul>; <h1>2.9.0 (2019-11-04)</h1>; <ul>; <li>Fix memcached expiring time (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/398"">#398</a>)</li>; </ul>; <h1>2.8.0 (2019-09-17)</h1>; <ul>; <li>Make this compatible with Python 3.7+. Import from collections.abc, instead; of from collections. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/373"">#373</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/4cedef7c62419de606aca7464a2e3247fdb0dd3c""><code>4cedef7</code></a> Release 2.12 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/763"">#763</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/dc5650045c358190677372cb1b66ddfbc2a98521""><code>dc56500</code></a> Bump flake8-requirements from 1.7.2 to 1.7.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/768"">#768</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/45a614ccf31aa7b2bf353a3d08d07566879875cf""><code>45a614c</code></a> Bump flake8-bugbear from 22.10.25 to 22.10.27 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/767"">#767</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12499:2054,depend,dependabot,2054,https://hail.is,https://github.com/hail-is/hail/pull/12499,1,['depend'],['dependabot']
Integrability,".</li>; </ul>; <p>These are in addition to the ongoing work to provide SIMD support for; commonly used functions, improvements to F2PY, and better documentation.</p>; <p>The Python versions supported in this release are 3.8-3.10, Python 3.7; has been dropped. Note that 32 bit wheels are only provided for Python; 3.8 and 3.9 on Windows, all other wheels are 64 bits on account of; Ubuntu, Fedora, and other Linux distributions dropping 32 bit support.; All 64 bit wheels are also linked with 64 bit integer OpenBLAS, which should fix; the occasional problems encountered by folks using truly huge arrays.</p>; <h2>Expired deprecations</h2>; <h3>Deprecated numeric style dtype strings have been removed</h3>; <p>Using the strings <code>&quot;Bytes0&quot;</code>, <code>&quot;Datetime64&quot;</code>, <code>&quot;Str0&quot;</code>, <code>&quot;Uint32&quot;</code>,; and <code>&quot;Uint64&quot;</code> as a dtype will now raise a <code>TypeError</code>.</p>; <p>(<a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/19539"">gh-19539</a>)</p>; <h3>Expired deprecations for <code>loads</code>, <code>ndfromtxt</code>, and <code>mafromtxt</code> in npyio</h3>; <p><code>numpy.loads</code> was deprecated in v1.15, with the recommendation that; users use <code>pickle.loads</code> instead. <code>ndfromtxt</code> and <code>mafromtxt</code> were both; deprecated in v1.17 - users should use <code>numpy.genfromtxt</code> instead with; the appropriate value for the <code>usemask</code> parameter.</p>; <p>(<a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/19615"">gh-19615</a>)</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/numpy/numpy/commit/4adc87dff15a247e417d50f10cc4def8e1c17a03""><code>4adc87d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/20685"">#20685</a> from charris/prepare-for-1.22.0-release</li>; <li><a h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11939:2247,depend,dependabot,2247,https://hail.is,https://github.com/hail-is/hail/pull/11939,2,['depend'],['dependabot']
Integrability,".apache.spark.SparkException: Job aborted due to stage failure: Task 9 in stage 10.0 failed 20 times, most recent failure: Lost task 9.19 in stage 10.0 (TID 1997, exomes-w-1.c.broad-mpg-gnomad.internal, executor 15): is.hail.utils.HailException: invalid allele ""GN""; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.variant.AltAlleleMethods$.validate(AltAlleleMethods.scala:24); 	at is.hail.variant.AltAlleleMethods$.altAlleleType(AltAlleleMethods.scala:28); 	at is.hail.variant.AltAlleleMethods$.isStar(AltAlleleMethods.scala:73); 	at is.hail.variant.VariantMethods$$anonfun$minRep$1.apply(VariantMethods.scala:43); 	at is.hail.variant.VariantMethods$$anonfun$minRep$1.apply(VariantMethods.scala:43); 	at scala.collection.IndexedSeqOptimized$class.prefixLengthImpl(IndexedSeqOptimized.scala:38); 	at scala.collection.IndexedSeqOptimized$class.forall(IndexedSeqOptimized.scala:43); 	at scala.collection.mutable.WrappedArray.forall(WrappedArray.scala:35); 	at is.hail.variant.VariantMethods$.minRep(VariantMethods.scala:43); 	at is.hail.methods.SplitMultiPartitionContext$$anonfun$2.apply(SplitMulti.scala:196); 	at is.hail.methods.SplitMultiPartitionContext$$anonfun$2.apply(SplitMulti.scala:192); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); 	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); 	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); 	at scala.collection.AbstractIterator.to(Iterator.scala:1336); 	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); 	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1336); 	",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3480:1120,Wrap,WrappedArray,1120,https://hail.is,https://github.com/hail-is/hail/issues/3480,1,['Wrap'],['WrappedArray']
Integrability,".ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/271"">#271</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c7e10db3d0965422122bef263fb36f6fd7572330""><code>c7e10db</code></a> Fix linter configs</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/6af8bf421a799208b27d57c6bf69de0d998fedec""><code>6af8bf4</code></a> Bump pre-commit from 2.15 to 2.16.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/269"">#269</a>)</li>; <li><a href=""https://github.com/aio-libs/async-timeout/commit/c71bbb5b5d7330f6dabfde7a1adec30a4611c0be""><code>c71bbb5</code></a> Bump docutils from 0.18 to 0.18.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/async-timeout/issues/266"">#266</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/async-timeout/compare/v3.0.1...v4.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=async-timeout&package-manager=pip&previous-version=3.0.1&new-version=4.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel mer",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11465:6354,Depend,Dependabot,6354,https://hail.is,https://github.com/hail-is/hail/pull/11465,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,".com/Azure/azure-sdk-for-java/commit/24a912a7b9f5cede6bc6007904a98b7a69c4e349""><code>24a912a</code></a> SyncPollingStrategy Compliment to PollingStrategy (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/31923"">#31923</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/46759562feb14a16da80295135ce79556639e460""><code>4675956</code></a> target newest version of proxy tool (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/31925"">#31925</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/2c6ab741fa96a78c8b6dd607986cdbe645860747""><code>2c6ab74</code></a> updated CHANGELOG.md (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/31922"">#31922</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/117395c4d526151c7c5faf7059285de6cd9f1c1b""><code>117395c</code></a> healthCheckImprovement[transitTimeout] (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/31544"">#31544</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-java/compare/azure-core_1.10.0...azure-core-http-netty_1.12.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.azure:azure-core-http-netty&package-manager=gradle&previous-version=1.10.0&new-version=1.12.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12460:3476,depend,dependabot,3476,https://hail.is,https://github.com/hail-is/hail/pull/12460,1,['depend'],['dependabot']
Integrability,".com/GrahamDumpleton/wrapt/commit/f2f1a680113d500f525de78da91ae19235efef16""><code>f2f1a68</code></a> Merge branch 'release/1.14.1'</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/97b72d49a8cda771c6006571486530ca84f3a834""><code>97b72d4</code></a> Update version of cibuildwheel for recent Python versions.</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/337072730beddd653f19c8b1a1157ecbb9d62790""><code>3370727</code></a> Only test Python 3.10 on aarch64 linux due to unreliability of GitHub runners...</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/982ddecf52013ce9bbdf8b48b76ae054844ba31b""><code>982ddec</code></a> Python 3.6 no longer available on aarch64 linux for testing.</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/240fea86df0357f3642db040f912031e4ecdfcb1""><code>240fea8</code></a> Update copyright notice year.</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/9668bbd7c7314d81b7cf8ce4293d04212ae1edee""><code>9668bbd</code></a> Update version in preparation for 1.14.1 release.</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/c86a4d37fa61494957153f76b1d6bbdacfd83205""><code>c86a4d3</code></a> Add classifier for Python 3.11.</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/07239ac21a68ced86860cf3bb52ee0c60faf0915""><code>07239ac</code></a> Document fix for module importers using deprecated APIs.</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/df0e62c2740143cceb6cafea4c306dae1c559ef8""><code>df0e62c</code></a> Deal with module importers that don't implement newer API.</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/72627592324bee1a197925d0e600142bc8719a3e""><code>7262759</code></a> Fix change notes formatting.</li>; <li>Additional commits viewable in <a href=""https://github.com/GrahamDumpleton/wrapt/compare/1.13.3...1.14.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](http",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12102:3167,wrap,wrapt,3167,https://hail.is,https://github.com/hail-is/hail/pull/12102,1,['wrap'],['wrapt']
Integrability,".com/ai/nanoid/issues/335"">#335</a>)</li>; <li><a href=""https://github.com/ai/nanoid/commit/90a446fef3ecaac78e5af2ea01025c4f40182e2b""><code>90a446f</code></a> Update benchmark results</li>; <li><a href=""https://github.com/ai/nanoid/commit/8ba2319b579895cc1f9060b9946a44852f97c509""><code>8ba2319</code></a> bench: add <code>@​napi-rs/uuid</code> v4 (<a href=""https://github-redirect.dependabot.com/ai/nanoid/issues/333"">#333</a>)</li>; <li><a href=""https://github.com/ai/nanoid/commit/f4257780ece488734a65c176e80c2fd8ab6aab8e""><code>f425778</code></a> Release 3.1.32 version</li>; <li>Additional commits viewable in <a href=""https://github.com/ai/nanoid/compare/3.1.23...3.2.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=nanoid&package-manager=npm_and_yarn&previous-version=3.1.23&new-version=3.2.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11284:3623,depend,dependabot-security-updates,3623,https://hail.is,https://github.com/hail-is/hail/pull/11284,2,['depend'],['dependabot-security-updates']
Integrability,".com/aio-libs/aiohttp/issues/7355"">#7355</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/40874103ebfaa1007d47c25ecc4288af873a07cf""><code>4087410</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7346"">#7346</a>/346fd202 backport][3.8]  Bump vendored llhttp to v8.1.1 (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7352"">#7352</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.8.4...v3.8.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.8.4&new-version=3.8.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13270:6761,depend,dependabot,6761,https://hail.is,https://github.com/hail-is/hail/pull/13270,5,['depend'],['dependabot']
Integrability,".com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>Have autoupdate preferentially pick tags which look like versions when there are multiple equivalent tags.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2312"">#2312</a> PR by <a href=""https://github.com/mblayman""><code>@​mblayman</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2311"">#2311</a> issue by <a href=""https://github.com/mblayman""><code>@​mblayman</code></a>.</li>; </ul>; </li>; <li>Upgrade <code>ruby-build</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2319"">#2319</a> PR by <a href=""https://github.com/jalessio""><code>@​jalessio</code></a>.</li>; </ul>; </li>; <li>Add top level <code>default_install_hook_types</code> which will be installed when <code>--hook-types</code> is not specified in <code>pre-commit install</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2322"">#2322</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; </ul>; <h3>Fixes</h3>; <ul>; <li>Fix typo in help message for <code>--from-ref</code> and <code>--to-ref</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2266"">#2266</a> PR by <a href=""https://github.com/leetrout""><code>@​leetrout</code></a>.</li>; </ul>; </li>; <li>Prioritize binary builds for R dependencies.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2277"">#2277</a> PR by <a href=""https://github.com/lorenzwalthert""><code>@​lorenzwalthert</code></a>.</li>; </ul>; </li>; <li>Fix handling of git worktrees.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2252"">#2252</a> PR by <a href=""https://github.com/daschuer""><code>@​daschuer</code></a>.</li>; </ul>; </li>; <li>Fix handling of <code>$R_HOME</code> for R hooks.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11731:2696,depend,dependabot,2696,https://hail.is,https://github.com/hail-is/hail/pull/11731,1,['depend'],['dependabot']
Integrability,".com/axios/axios/pull/3377"">#3377</a>)</li>; <li>Adding ability to omit User-Agent header (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3703"">#3703</a>)</li>; <li>Adding multiple JSON improvements (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3688"">#3688</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3763"">#3763</a>)</li>; <li>Fixing quadratic runtime and extra memory usage when setting a maxContentLength (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3738"">#3738</a>)</li>; <li>Adding parseInt to config.timeout (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3781"">#3781</a>)</li>; <li>Adding custom return type support to interceptor (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3783"">#3783</a>)</li>; <li>Adding security fix for ReDoS vulnerability (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3980"">#3980</a>)</li>; </ul>; <p>Internal and Tests:</p>; <ul>; <li>Updating build dev dependancies (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3401"">#3401</a>)</li>; <li>Fixing builds running on Travis CI (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3538"">#3538</a>)</li>; <li>Updating follow rediect version (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3694"">#3694</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3771"">#3771</a>)</li>; <li>Updating karma sauce launcher to fix failing sauce tests (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3712"">#3712</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3717"">#3717</a>)</li>; <li>Updating content-type header for application/json to not contain charset field, according do RFC 8259 (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2154"">#2154</a>)</li>; <li>Fixing tests by bumping karma-sauce-launcher version (<a href=""https://github-redirect.dependabot.com/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:1773,depend,dependancies,1773,https://hail.is,https://github.com/hail-is/hail/pull/11080,4,['depend'],['dependancies']
Integrability,".com/chardet/chardet/issues/244"">#244</a>)</li>; <li><a href=""https://github.com/chardet/chardet/commit/49b8341f507bed68f7d3ff7138bb97047a0e04f0""><code>49b8341</code></a> Configure setuptools using the declarative syntax in setup.cfg (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/239"">#239</a>)</li>; <li><a href=""https://github.com/chardet/chardet/commit/5c73bfcdf819251d1a1d0de672e34480ebafbe1f""><code>5c73bfc</code></a> Run all pre-commit hooks on pull requests (<a href=""https://github-redirect.dependabot.com/chardet/chardet/issues/236"">#236</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/chardet/chardet/compare/4.0.0...5.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=chardet&package-manager=pip&previous-version=4.0.0&new-version=5.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12107:5822,depend,dependabot-security-updates,5822,https://hail.is,https://github.com/hail-is/hail/pull/12107,1,['depend'],['dependabot-security-updates']
Integrability,".com/dependabot""><code>@​dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/152"">tox-dev/py-filelock#152</a></li>; <li>Bump pre-commit/action from 2.0.3 to 3.0.0 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/151"">tox-dev/py-filelock#151</a></li>; <li>Bump actions/checkout from 2 to 3 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/153"">tox-dev/py-filelock#153</a></li>; <li>Bump actions/setup-python from 2 to 4 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/150"">tox-dev/py-filelock#150</a></li>; <li>Add timeout unit to docstrings by <a href=""https://github.com/jnordberg""><code>@​jnordberg</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/148"">tox-dev/py-filelock#148</a></li>; <li>Unify badges style by <a href=""https://github.com/DeadNews""><code>@​DeadNews</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/155"">tox-dev/py-filelock#155</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/156"">tox-dev/py-filelock#156</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/157"">tox-dev/py-filelock#157</a></li>; <li>Check 3.11 support by <a href=""https://github.com/gaborbernat""><code>@​gaborbernat</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/158"">tox-dev/py-filelock#158</a></li>; <li>[pre-commit.ci] pre-commit auto",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12157:1835,depend,dependabot,1835,https://hail.is,https://github.com/hail-is/hail/pull/12157,1,['depend'],['dependabot']
Integrability,".com/googleapis/java-storage) from 1.106.0 to 2.15.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/java-storage/releases"">google-cloud-storage's releases</a>.</em></p>; <blockquote>; <h2>v2.15.0</h2>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.14.0...v2.15.0"">2.15.0</a> (2022-11-07)</h2>; <h3>Features</h3>; <ul>; <li>Add Autoclass support and sample (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1697"">#1697</a>) (<a href=""https://github.com/googleapis/java-storage/commit/82aacd7922573d6f4779f21cdc83de10616d7a08"">82aacd7</a>)</li>; <li>Update retries for Notifications (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1734"">#1734</a>) (<a href=""https://github.com/googleapis/java-storage/commit/0fb2f1823f9eff8534f15240321003f120fed3f4"">0fb2f18</a>)</li>; </ul>; <h3>Dependencies</h3>; <ul>; <li>Update dependency com.google.cloud:google-cloud-shared-dependencies to v3.0.6 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1761"">#1761</a>) (<a href=""https://github.com/googleapis/java-storage/commit/803a90b7747b8972f51d1407616c51084d97c589"">803a90b</a>)</li>; <li>Update dependency net.jqwik:jqwik to v1.7.1 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1758"">#1758</a>) (<a href=""https://github.com/googleapis/java-storage/commit/140e90911229c876de7b674dd1e61b278e8b07fd"">140e909</a>)</li>; <li>Update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.17 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1759"">#1759</a>) (<a href=""https://github.com/googleapis/java-storage/commit/7e3175a56a06dac0aa0841f221a486bb69b5c9bf"">7e3175a</a>)</li>; </ul>; <h2>v2.14.0</h2>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.13.1...v2.14.0"">2.14.0</a> (2022-10-26)</h2>; <h3>Google Cloud Storage gRPC API Preview</h3>; <p>The fir",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12456:1047,depend,dependencies,1047,https://hail.is,https://github.com/hail-is/hail/pull/12456,1,['depend'],['dependencies']
Integrability,".com/googleapis/java-storage/commit/c8bf3c70cca81ed87a52939fe7da58889c8f55ce"">c8bf3c7</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Document differing behavior of {get,list}{,default}Acl between HTTP and gRPC (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1820"">#1820</a>) (<a href=""https://github.com/googleapis/java-storage/commit/9511b173e84d2b28ab1a1625b16e3e648c3856fb"">9511b17</a>)</li>; </ul>; <h3>Dependencies</h3>; <ul>; <li>Update dependency com.google.cloud:google-cloud-shared-dependencies to v3.1.1 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1836"">#1836</a>) (<a href=""https://github.com/googleapis/java-storage/commit/3b71fab11ac71039c2a9983821ce02ce25ce311d"">3b71fab</a>)</li>; <li>Update dependency net.jqwik:jqwik to v1.7.2 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1833"">#1833</a>) (<a href=""https://github.com/googleapis/java-storage/commit/83bc261130e89e5994f21e32422054ef6ea2fe8e"">83bc261</a>)</li>; <li>Update dependency org.junit.vintage:junit-vintage-engine to v5.9.2 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1837"">#1837</a>) (<a href=""https://github.com/googleapis/java-storage/commit/5b381845b4f48a691aa3f0cb96599ddefc7e463f"">5b38184</a>)</li>; <li>Update junit-platform.version to v5.9.2 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1838"">#1838</a>) (<a href=""https://github.com/googleapis/java-storage/commit/372521ba80b12e52c74fae5ac766dbe6610ff0b2"">372521b</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.15.1...v2.16.0"">2.16.0</a> (2022-12-06)</h2>; <h3>Features</h3>; <ul>; <li>Add {Compose,Rewrite,StartResumableWrite}Request.object_checksums and Bucket.RetentionPolicy.retention_duration (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1790"">#1790</a>) (<a href=""https://github.com/googleapis/java-storage/com",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12598:12387,depend,dependency,12387,https://hail.is,https://github.com/hail-is/hail/pull/12598,1,['depend'],['dependency']
Integrability,".com/googleapis/java-storage/commit/c8bf3c70cca81ed87a52939fe7da58889c8f55ce"">c8bf3c7</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Document differing behavior of {get,list}{,default}Acl between HTTP and gRPC (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1820"">#1820</a>) (<a href=""https://github.com/googleapis/java-storage/commit/9511b173e84d2b28ab1a1625b16e3e648c3856fb"">9511b17</a>)</li>; </ul>; <h3>Dependencies</h3>; <ul>; <li>Update dependency com.google.cloud:google-cloud-shared-dependencies to v3.1.1 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1836"">#1836</a>) (<a href=""https://github.com/googleapis/java-storage/commit/3b71fab11ac71039c2a9983821ce02ce25ce311d"">3b71fab</a>)</li>; <li>Update dependency net.jqwik:jqwik to v1.7.2 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1833"">#1833</a>) (<a href=""https://github.com/googleapis/java-storage/commit/83bc261130e89e5994f21e32422054ef6ea2fe8e"">83bc261</a>)</li>; <li>Update dependency org.junit.vintage:junit-vintage-engine to v5.9.2 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1837"">#1837</a>) (<a href=""https://github.com/googleapis/java-storage/commit/5b381845b4f48a691aa3f0cb96599ddefc7e463f"">5b38184</a>)</li>; <li>Update junit-platform.version to v5.9.2 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1838"">#1838</a>) (<a href=""https://github.com/googleapis/java-storage/commit/372521ba80b12e52c74fae5ac766dbe6610ff0b2"">372521b</a>)</li>; </ul>; <h2>v2.16.0</h2>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.15.1...v2.16.0"">2.16.0</a> (2022-12-06)</h2>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/java-storage/blob/main/CHANGELOG.md"">google-cloud-storage's changelog</a>.</em></p>; <blockquote>;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12598:5877,depend,dependency,5877,https://hail.is,https://github.com/hail-is/hail/pull/12598,1,['depend'],['dependency']
Integrability,".com/googleapis/python-api-core/issues/379"">#379</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/c97c4980125a86f384cdf12720df7bb1a2adf9d2"">c97c498</a>)</li>; <li>adds support for audience in client_options. (<a href=""https://github.com/googleapis/python-api-core/commit/c97c4980125a86f384cdf12720df7bb1a2adf9d2"">c97c498</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/python-api-core/compare/v2.7.2...v2.7.3"">2.7.3</a> (2022-04-29)</h2>; <h3>Bug Fixes</h3>; <ul>; <li>Avoid AttributeError if grpcio-status is not installed (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/370"">#370</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/022add16266f9c07f0f88eea13472cc2e0bfc991"">022add1</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/python-api-core/compare/v2.7.1...v2.7.2"">2.7.2</a> (2022-04-13)</h2>; <h3>Bug Fixes</h3>; <ul>; <li>allow grpc without grpcio-status (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/355"">#355</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/112049e79f5a5b0a989d85d438a1bd29485f46f7"">112049e</a>)</li>; <li>remove dependency on pkg_resources (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/361"">#361</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/523dbd0b10d37ffcf83fa751f0bad313f162abf1"">523dbd0</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/python-api-core/compare/v2.7.0...v2.7.1"">2.7.1</a> (2022-03-09)</h2>; <h3>Bug Fixes</h3>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/googleapis/python-api-core/commit/5b5e77563229687c901d77b5fdecc18168b535e6""><code>5b5e775</code></a> chore(main): release 2.8.2 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/396"">#396</a>)</li>; <li><a href=""https://github.co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11970:7328,depend,dependabot,7328,https://hail.is,https://github.com/hail-is/hail/pull/11970,1,['depend'],['dependabot']
Integrability,".com/ijl/orjson/commit/a348f59f0b55d92a1364523560f52f5b3cf9c12a""><code>a348f59</code></a> 3.9.15</li>; <li><a href=""https://github.com/ijl/orjson/commit/b0e4d2c06ce06c6e63981bf0276e4b7c74e5845e""><code>b0e4d2c</code></a> yyjson 0eca326, recursion limit</li>; <li><a href=""https://github.com/ijl/orjson/commit/5067eadc84cf516e4eb33bcb09ad756bb59dc42e""><code>5067ead</code></a> impl_escape_unchecked() byte exact read</li>; <li><a href=""https://github.com/ijl/orjson/commit/e04ea735b087742b6cee738aa295d8b835c3a195""><code>e04ea73</code></a> cargo update, build misc</li>; <li><a href=""https://github.com/ijl/orjson/commit/ba8c701292e4720b4e10210b266be5666d098fb6""><code>ba8c701</code></a> 3.9.14</li>; <li><a href=""https://github.com/ijl/orjson/commit/a2f7b7bfa4987c102892793ab7c7483fcb8050a0""><code>a2f7b7b</code></a> impl_format_simd!() lift create from loop, rotate left</li>; <li><a href=""https://github.com/ijl/orjson/commit/528220fb0d18bbf0212de7f0ce5c7aec209bc6e7""><code>528220f</code></a> format_escaped_str() fast and slow paths depending on page boundary</li>; <li><a href=""https://github.com/ijl/orjson/commit/29884e617d35c6774f60b8fedf6de47d74edcd2f""><code>29884e6</code></a> Fix buffer overread in format_escaped_str</li>; <li><a href=""https://github.com/ijl/orjson/commit/c825472198c20f40064af63d7ef7b21eb2e3aaef""><code>c825472</code></a> cargo update</li>; <li><a href=""https://github.com/ijl/orjson/commit/4eb4f005a6f1b71609051770612a055b584b73d2""><code>4eb4f00</code></a> 3.9.13</li>; <li>Additional commits viewable in <a href=""https://github.com/ijl/orjson/compare/3.9.10...3.9.15"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=orjson&package-manager=pip&previous-version=3.9.10&new-version=3.9.15)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conf",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14357:4061,depend,depending,4061,https://hail.is,https://github.com/hail-is/hail/pull/14357,1,['depend'],['depending']
Integrability,".com/ijl/orjson/commit/a348f59f0b55d92a1364523560f52f5b3cf9c12a""><code>a348f59</code></a> 3.9.15</li>; <li><a href=""https://github.com/ijl/orjson/commit/b0e4d2c06ce06c6e63981bf0276e4b7c74e5845e""><code>b0e4d2c</code></a> yyjson 0eca326, recursion limit</li>; <li><a href=""https://github.com/ijl/orjson/commit/5067eadc84cf516e4eb33bcb09ad756bb59dc42e""><code>5067ead</code></a> impl_escape_unchecked() byte exact read</li>; <li><a href=""https://github.com/ijl/orjson/commit/e04ea735b087742b6cee738aa295d8b835c3a195""><code>e04ea73</code></a> cargo update, build misc</li>; <li><a href=""https://github.com/ijl/orjson/commit/ba8c701292e4720b4e10210b266be5666d098fb6""><code>ba8c701</code></a> 3.9.14</li>; <li><a href=""https://github.com/ijl/orjson/commit/a2f7b7bfa4987c102892793ab7c7483fcb8050a0""><code>a2f7b7b</code></a> impl_format_simd!() lift create from loop, rotate left</li>; <li><a href=""https://github.com/ijl/orjson/commit/528220fb0d18bbf0212de7f0ce5c7aec209bc6e7""><code>528220f</code></a> format_escaped_str() fast and slow paths depending on page boundary</li>; <li><a href=""https://github.com/ijl/orjson/commit/29884e617d35c6774f60b8fedf6de47d74edcd2f""><code>29884e6</code></a> Fix buffer overread in format_escaped_str</li>; <li><a href=""https://github.com/ijl/orjson/commit/c825472198c20f40064af63d7ef7b21eb2e3aaef""><code>c825472</code></a> cargo update</li>; <li><a href=""https://github.com/ijl/orjson/commit/4eb4f005a6f1b71609051770612a055b584b73d2""><code>4eb4f00</code></a> 3.9.13</li>; <li>Additional commits viewable in <a href=""https://github.com/ijl/orjson/compare/3.9.10...3.9.15"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=orjson&package-manager=pip&previous-version=3.9.10&new-version=3.9.15)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14358:4061,depend,depending,4061,https://hail.is,https://github.com/hail-is/hail/pull/14358,2,['depend'],['depending']
Integrability,".com/ipython/comm/commit/76149e7ee0f331772c964ae86cdb8bafebe6dfa2""><code>76149e7</code></a> Update Release Scripts (<a href=""https://redirect.github.com/ipython/comm/issues/27"">#27</a>)</li>; <li><a href=""https://github.com/ipython/comm/commit/915898ddeddd0d1c8a1b87c5dcfbe6392fd225b7""><code>915898d</code></a> chore: update pre-commit hooks (<a href=""https://redirect.github.com/ipython/comm/issues/26"">#26</a>)</li>; <li>See full diff in <a href=""https://github.com/ipython/comm/compare/v0.2.1...v0.2.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=comm&package-manager=pip&previous-version=0.2.1&new-version=0.2.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major versio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14492:4005,depend,dependabot,4005,https://hail.is,https://github.com/hail-is/hail/pull/14492,1,['depend'],['dependabot']
Integrability,".com/ipython/ipython/commit/3edbe3bd10c434af6458bdbe02269880b10b9adf""><code>3edbe3b</code></a> Resurrect fast (non-highlighted) traceback code for long files. (<a href=""https://redirect.github.com/ipython/ipython/issues/13947"">#13947</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/7.34.0...8.11.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ipython&package-manager=pip&previous-version=7.34.0&new-version=8.11.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12807:2747,Depend,Dependabot,2747,https://hail.is,https://github.com/hail-is/hail/pull/12807,1,['Depend'],['Dependabot']
Integrability,".com/jaraco/keyrings.alt/commit/f36ec65595bc6b59243adc0cb9e5a1a367f1e50b""><code>f36ec65</code></a> Consolidate logic for resolving crypto lib.</li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/3de7f4007c4cf749b97dd3acba4b00d7cf0b55a1""><code>3de7f40</code></a> Remove dependency on deprecated keyring.util.properties. Fixes <a href=""https://github-redirect.dependabot.com/jaraco/keyrings.alt/issues/47"">#47</a>.</li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/010fe59c64ffacbc0f97405d3bf21072d811baf1""><code>010fe59</code></a> Merge <a href=""https://github.com/jaraco/skeleton"">https://github.com/jaraco/skeleton</a></li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/47c2cb324e20f784289496ef3a7b19a1cd23d196""><code>47c2cb3</code></a> Also update release to v4</li>; <li>Additional commits viewable in <a href=""https://github.com/jaraco/keyrings.alt/compare/v3.5.2...v4.2.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=keyrings-alt&package-manager=pip&previous-version=3.5.2&new-version=4.2.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merg",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12448:3413,Depend,Dependabot,3413,https://hail.is,https://github.com/hail-is/hail/pull/12448,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,".com/jaraco/tidelift</a></li>; <li><a href=""https://github.com/jaraco/zipp/commit/25e46d7fd2b20f50267ae96cf632d8ab3cccb671""><code>25e46d7</code></a> Merge <a href=""https://github.com/jaraco/skeleton"">https://github.com/jaraco/skeleton</a></li>; <li><a href=""https://github.com/jaraco/zipp/commit/fea1e7cdd57d330f22ac54512ae2df19083c6ec7""><code>fea1e7c</code></a> Ran pre-commit autoupdate</li>; <li><a href=""https://github.com/jaraco/zipp/commit/2678a7e82d581c07691575d90cd255b64ee63a27""><code>2678a7e</code></a> Honor PEP 518 with pytest-enabler.</li>; <li><a href=""https://github.com/jaraco/zipp/commit/6dcd157a7057ec8e1f1f6afebe2115f55df4aaed""><code>6dcd157</code></a> Prefer spaces for rst. Fixes <a href=""https://github-redirect.dependabot.com/jaraco/skeleton/issues/64"">jaraco/skeleton#64</a>.</li>; <li><a href=""https://github.com/jaraco/zipp/commit/e719f86c138a750f0c4599cd01cb8067b1ca95c8""><code>e719f86</code></a> exclude build env from cov reporting (<a href=""https://github-redirect.dependabot.com/jaraco/zipp/issues/60"">#60</a>)</li>; <li><a href=""https://github.com/jaraco/zipp/commit/74f337fec4c233b3a6750fa64b61d03c189d9416""><code>74f337f</code></a> Update Github actions to v3 (<a href=""https://github-redirect.dependabot.com/jaraco/zipp/issues/62"">#62</a>)</li>; <li><a href=""https://github.com/jaraco/zipp/commit/a4f5b769793af19f7b858816889c1bf026f55f5c""><code>a4f5b76</code></a> Update base URL for PEPs (<a href=""https://github-redirect.dependabot.com/jaraco/zipp/issues/61"">#61</a>)</li>; <li><a href=""https://github.com/jaraco/zipp/commit/10bf1b1fb9e09e9836bea9e2edec620cd9eea7f9""><code>10bf1b1</code></a> Add Python 3.11 into the matrix using workaround from <a href=""https://github-redirect.dependabot.com/actions/setup-python/issues/21"">actions/setup-python#21</a>...</li>; <li>Additional commits viewable in <a href=""https://github.com/jaraco/zipp/compare/v3.8.0...v3.8.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependab",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12108:1707,depend,dependabot,1707,https://hail.is,https://github.com/hail-is/hail/pull/12108,1,['depend'],['dependabot']
Integrability,".com/jpadilla/pyjwt/issues/700"">#700</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/6223ba13780a941a3f4c9dec62f282bdd9b5afb0""><code>6223ba1</code></a> Bump up version to v2.2.0 (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/697"">#697</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/258d7bab0ecb86be91738ac1e23744429280acd1""><code>258d7ba</code></a> Use timezone package as Python 3.5+ is required (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/694"">#694</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/a988e1a11e5abb5869dd641f3f4f6a5bb4e70fdf""><code>a988e1a</code></a> Chore: inline Variables that immediately Returned (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/690"">#690</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/e7a6c022f3f2e5ba329cbadd242c788014926a7e""><code>e7a6c02</code></a> Add support for Ed448/EdDSA. (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/675"">#675</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/19ce9c5ec7947428d35aaffd302eb2629210a697""><code>19ce9c5</code></a> Remove upper bound on cryptography version (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/693"">#693</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/9249fc70b5aede04c3dcb86e4b6560ab7e032563""><code>9249fc7</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/689"">#689</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/jpadilla/pyjwt/compare/1.7.1...2.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyjwt&package-manager=pip&previous-version=1.7.1&new-version=2.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11457:13021,depend,dependabot,13021,https://hail.is,https://github.com/hail-is/hail/pull/11457,1,['depend'],['dependabot']
Integrability,".com/jupyterlab/jupyterlab/issues/15262"">#15262</a> on branch 4.0.x (Fix connection loop issue with standalone...</li>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/8a5acf284b1e6defc6b15f22ec11c3cae67eaba1""><code>8a5acf2</code></a> Backport PR <a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15695"">#15695</a>: Fix shortcut UI failing on filtering when empty command i...</li>; <li><a href=""https://github.com/jupyterlab/jupyterlab/commit/9d4a3611bae6868f7de7584f8c0b16b8a7535e70""><code>9d4a361</code></a> Automated Changelog Entry - Remove 1 placeholder entries. (<a href=""https://redirect.github.com/jupyterlab/jupyterlab/issues/15667"">#15667</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/jupyterlab/jupyterlab/compare/@jupyterlab/lsp@4.0.9...@jupyterlab/lsp@4.0.12"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jupyterlab&package-manager=pip&previous-version=4.0.9&new-version=4.0.12)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` w",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14218:14687,depend,dependency-name,14687,https://hail.is,https://github.com/hail-is/hail/pull/14218,1,['depend'],['dependency-name']
Integrability,".com/kubernetes/kubernetes/pull/107859"">kubernetes/kubernetes#107859</a>, <a href=""https://github.com/ravisantoshgudimetla""><code>@​ravisantoshgudimetla</code></a>)</li>; <li>Remove a v1alpha1 networking API for ClusterCIDRConfig (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/109436"">kubernetes/kubernetes#109436</a>, <a href=""https://github.com/JamesLaverack""><code>@​JamesLaverack</code></a>)</li>; <li>Renamed metrics <code>evictions_number</code> to <code>evictions_total</code> and mark it as stable. The original <code>evictions_number</code> metrics name is marked as &quot;Deprecated&quot; and has been removed in kubernetes 1.23 . (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/106366"">kubernetes/kubernetes#106366</a>, <a href=""https://github.com/cyclinder""><code>@​cyclinder</code></a>)</li>; <li>Skip x-kubernetes-validations rules if having fundamental error against the OpenAPIv3 schema. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108859"">kubernetes/kubernetes#108859</a>, <a href=""https://github.com/cici37""><code>@​cici37</code></a>)</li>; <li>Support for gRPC probes is now in beta. GRPCContainerProbe feature gate is enabled by default. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108522"">kubernetes/kubernetes#108522</a>, <a href=""https://github.com/SergeyKanzhelev""><code>@​SergeyKanzhelev</code></a>)</li>; <li>Suspend job to GA. The feature gate <code>SuspendJob</code> is locked and will be removed in 1.26. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108129"">kubernetes/kubernetes#108129</a>, <a href=""https://github.com/ahg-g""><code>@​ahg-g</code></a>)</li>; <li>The AnyVolumeDataSource feature is now beta, and the feature gate is enabled by default. In order to provide user feedback on PVCs with data sources, deployers must install the VolumePopulators CRD and the data-source-validator controller. (<a href=""https:/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:12734,depend,dependabot,12734,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['depend'],['dependabot']
Integrability,".com/milas""><code>@​milas</code></a> in <a href=""https://github-redirect.dependabot.com/docker/docker-py/pull/3032"">docker/docker-py#3032</a></li>; <li>Use latest stable syntax for Dockerfiles by <a href=""https://github.com/thaJeztah""><code>@​thaJeztah</code></a> in <a href=""https://github-redirect.dependabot.com/docker/docker-py/pull/3035"">docker/docker-py#3035</a></li>; <li>feat: add support for floats to docker logs params since / until sinc… by <a href=""https://github.com/ArchiMoebius""><code>@​ArchiMoebius</code></a> in <a href=""https://github-redirect.dependabot.com/docker/docker-py/pull/3031"">docker/docker-py#3031</a></li>; <li>Change prune test to use anonymous volumes by <a href=""https://github.com/cpuguy83""><code>@​cpuguy83</code></a> in <a href=""https://github-redirect.dependabot.com/docker/docker-py/pull/3051"">docker/docker-py#3051</a></li>; <li>socket: handle npipe close by <a href=""https://github.com/nicks""><code>@​nicks</code></a> in <a href=""https://github-redirect.dependabot.com/docker/docker-py/pull/3056"">docker/docker-py#3056</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/ArchiMoebius""><code>@​ArchiMoebius</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/docker/docker-py/pull/3031"">docker/docker-py#3031</a></li>; <li><a href=""https://github.com/nicks""><code>@​nicks</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/docker/docker-py/pull/3056"">docker/docker-py#3056</a></li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/docker/docker-py/compare/6.0.0...6.0.1"">https://github.com/docker/docker-py/compare/6.0.0...6.0.1</a></p>; <h2>6.0.0</h2>; <h3>ℹ️ Upgrade Notes</h3>; <ul>; <li>Minimum supported Python version is 3.7+</li>; <li>When installing with pip, the <code>docker[tls]</code> extra is deprecated and a no-op,; use <code>docker</code> for same functionality (TLS support is always available now)</li>; <li>N",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12475:1740,depend,dependabot,1740,https://hail.is,https://github.com/hail-is/hail/pull/12475,1,['depend'],['dependabot']
Integrability,".com/mypyc/mypyc"">mypyc</a> for an overall 2x; speed-up. 64-bit Windows, MacOS, and Linux (not including musl) are supported. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/1009"">#1009</a>,; <a href=""https://github-redirect.dependabot.com/psf/black/issues/2431"">#2431</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/psf/black/commits/22.1.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=black&package-manager=pip&previous-version=20.8b1&new-version=22.1.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11468:12326,depend,dependabot,12326,https://hail.is,https://github.com/hail-is/hail/pull/11468,1,['depend'],['dependabot']
Integrability,".com/numpy/numpy/commit/f9c45f8ebf31340b1a5a0371bfca25afcfc4794e""><code>f9c45f8</code></a> Merge pull request <a href=""https://redirect.github.com/numpy/numpy/issues/20680"">#20680</a> from charris/backport-20663</li>; <li><a href=""https://github.com/numpy/numpy/commit/794b36f7e1bf2a8c42774ab0db86a74bd32f674b""><code>794b36f</code></a> Update armccompiler.py</li>; <li><a href=""https://github.com/numpy/numpy/commit/d93b14e3d7abaa1d837825e51671f817788e120f""><code>d93b14e</code></a> Update test_public_api.py</li>; <li><a href=""https://github.com/numpy/numpy/commit/7662c0789cc6a70d5ad4d950ee2e95f3afef7df6""><code>7662c07</code></a> Update <strong>init</strong>.py</li>; <li><a href=""https://github.com/numpy/numpy/commit/311ab52488a7d096ac3bc4c2de0fdae17ecd13ef""><code>311ab52</code></a> Update armccompiler.py</li>; <li>Additional commits viewable in <a href=""https://github.com/numpy/numpy/compare/v1.21.6...v1.22.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.6&new-version=1.22.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` wi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12894:4997,Depend,Dependabot,4997,https://hail.is,https://github.com/hail-is/hail/pull/12894,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,".com/numpy/numpy/commit/f9c45f8ebf31340b1a5a0371bfca25afcfc4794e""><code>f9c45f8</code></a> Merge pull request <a href=""https://redirect.github.com/numpy/numpy/issues/20680"">#20680</a> from charris/backport-20663</li>; <li><a href=""https://github.com/numpy/numpy/commit/794b36f7e1bf2a8c42774ab0db86a74bd32f674b""><code>794b36f</code></a> Update armccompiler.py</li>; <li><a href=""https://github.com/numpy/numpy/commit/d93b14e3d7abaa1d837825e51671f817788e120f""><code>d93b14e</code></a> Update test_public_api.py</li>; <li><a href=""https://github.com/numpy/numpy/commit/7662c0789cc6a70d5ad4d950ee2e95f3afef7df6""><code>7662c07</code></a> Update <strong>init</strong>.py</li>; <li><a href=""https://github.com/numpy/numpy/commit/311ab52488a7d096ac3bc4c2de0fdae17ecd13ef""><code>311ab52</code></a> Update armccompiler.py</li>; <li>Additional commits viewable in <a href=""https://github.com/numpy/numpy/compare/v1.21.6...v1.22.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.6&new-version=1.22.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reop",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12809:4997,Depend,Dependabot,4997,https://hail.is,https://github.com/hail-is/hail/pull/12809,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,".com/pallets/werkzeug/commit/15fcb87d36f4ed45b127692d2d739266b918503c""><code>15fcb87</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/werkzeug/issues/2499"">#2499</a> from pallets/release-2.2.2</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/87b082a02373aa2feba5750f5768efd6013f701d""><code>87b082a</code></a> release version 2.2.2</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/110b4cdbc1c86125065e56c8d64d0c560883b42b""><code>110b4cd</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/werkzeug/issues/2498"">#2498</a> from pallets/socket-warning</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/b484e5497d12a11766544d79d320d5953d3a753d""><code>b484e54</code></a> handle unclosed socket resource warning</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/bebf46d336782e70510f00e3a08db1e1453ce68a""><code>bebf46d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/werkzeug/issues/2497"">#2497</a> from pallets/local-wrapped</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/82d3fba4e7955e00833eff123fd11564fc96cdae""><code>82d3fba</code></a> LocalProxy.<strong>wrapped</strong> is always set when unbound</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/fe8a56e9e348e8ae97ce826368301becea8a3d74""><code>fe8a56e</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/werkzeug/issues/2496"">#2496</a> from pallets/deploy-docs</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/1c656e17fa82028f722bf36f458f772a2a54e8e8""><code>1c656e1</code></a> modernize deployment docs</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/67dc99d60ceed66b089b23e18f5c9727bf60890e""><code>67dc99d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/werkzeug/issues/2495"">#2495</a> from pallets/dev-server-warning</li>; <li><a href=""https://github.com/pallets/we",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12119:5540,depend,dependabot,5540,https://hail.is,https://github.com/hail-is/hail/pull/12119,1,['depend'],['dependabot']
Integrability,".com/pallets/werkzeug/commit/fe8a56e9e348e8ae97ce826368301becea8a3d74""><code>fe8a56e</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/werkzeug/issues/2496"">#2496</a> from pallets/deploy-docs</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/1c656e17fa82028f722bf36f458f772a2a54e8e8""><code>1c656e1</code></a> modernize deployment docs</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/67dc99d60ceed66b089b23e18f5c9727bf60890e""><code>67dc99d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/werkzeug/issues/2495"">#2495</a> from pallets/dev-server-warning</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/09a30668d9cda3fc5d85c1152044fdbf5863c43e""><code>09a3066</code></a> always show dev server warning</li>; <li>Additional commits viewable in <a href=""https://github.com/pallets/werkzeug/compare/2.1.2...2.2.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=werkzeug&package-manager=pip&previous-version=2.1.2&new-version=2.2.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` w",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12119:6820,Depend,Dependabot,6820,https://hail.is,https://github.com/hail-is/hail/pull/12119,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,".com/protocolbuffers/protobuf) from 3.20.1 to 4.21.6.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/protocolbuffers/protobuf/releases"">protobuf's releases</a>.</em></p>; <blockquote>; <h2>Protocol Buffers v3.20.2</h2>; <h1>C++</h1>; <ul>; <li>Reduce memory consumption of MessageSet parsing</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf"">Security Advisory for C++ and Python users</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/protocolbuffers/protobuf/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.1&new-version=4.21.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12227:1030,depend,dependabot-security-updates,1030,https://hail.is,https://github.com/hail-is/hail/pull/12227,2,['depend'],['dependabot-security-updates']
Integrability,".com/psf/black/issues/3194"">#3194</a>)</li>; <li>Docker: changed to a /opt/venv installation + added to PATH to be available to non-root users (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3202"">#3202</a>)</li>; </ul>; <h3>Output</h3>; <ul>; <li>Change from deprecated <code>asyncio.get_event_loop()</code> to create our event loop which removes DeprecationWarning (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3164"">#3164</a>)</li>; <li>Remove logging from internal <code>blib2to3</code> library since it regularly emits error logs about failed caching that can and should be ignored (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3193"">#3193</a>)</li>; </ul>; <h3>Parser</h3>; <ul>; <li>Type comments are now included in the AST equivalence check consistently so accidental deletion raises an error. Though type comments can't be tracked when running on PyPy 3.7 due to standard library limitations. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2874"">#2874</a>)</li>; </ul>; <h3>Performance</h3>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/psf/black/blob/main/CHANGES.md"">black's changelog</a>.</em></p>; <blockquote>; <h2>22.8.0</h2>; <h3>Highlights</h3>; <ul>; <li>Python 3.11 is now supported, except for <em>blackd</em> as aiohttp does not support 3.11 as; of publishing (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3234"">#3234</a>)</li>; <li>This is the last release that supports running <em>Black</em> on Python 3.6 (formatting 3.6; code will continue to be supported until further notice)</li>; <li>Reword the stability policy to say that we may, in rare cases, make changes that; affect code that was not previously formatted by <em>Black</em> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3155"">#3155</a>)</li>; </ul>; <h3>Stable style</h3>; <u",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12174:4909,depend,dependabot,4909,https://hail.is,https://github.com/hail-is/hail/pull/12174,1,['depend'],['dependabot']
Integrability,".com/pyca/cryptography/commit/f302d28b81607aab28d22b653da78d564824f267""><code>f302d28</code></a> Update CI for new LibreSSL releases (<a href=""https://redirect.github.com/pyca/cryptography/issues/8975"">#8975</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/851d8ccb340bfc93c827b9e80af939a216b34925""><code>851d8cc</code></a> Bump openssl from 0.10.52 to 0.10.53 in /src/rust (<a href=""https://redirect.github.com/pyca/cryptography/issues/8986"">#8986</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/0918c7236c94c29272e0790ba0227cfa9401943b""><code>0918c72</code></a> Bump coverage from 7.2.6 to 7.2.7 (<a href=""https://redirect.github.com/pyca/cryptography/issues/8985"">#8985</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pyca/cryptography/compare/40.0.2...41.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=40.0.2&new-version=41.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13146:4905,depend,dependency-name,4905,https://hail.is,https://github.com/hail-is/hail/pull/13146,1,['depend'],['dependency-name']
Integrability,".com/pyca/cryptography/issues/10395"">#10395</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/0e0e46f5f73f477b8ee9682738c42129d5d60177""><code>0e0e46f</code></a> backport: initialize openssl's legacy provider in rust (<a href=""https://redirect.github.com/pyca/cryptography/issues/10323"">#10323</a>) (<a href=""https://redirect.github.com/pyca/cryptography/issues/10333"">#10333</a>)</li>; <li>See full diff in <a href=""https://github.com/pyca/cryptography/compare/42.0.2...42.0.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=42.0.2&new-version=42.0.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major versio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14332:3688,depend,dependabot,3688,https://hail.is,https://github.com/hail-is/hail/pull/14332,3,['depend'],['dependabot']
Integrability,".com/python-parsy/parsy/commit/18df37a479f1bc4170999866433ca19f92f19f63""><code>18df37a</code></a> Dropped Python 3.4 from tox</li>; <li><a href=""https://github.com/python-parsy/parsy/commit/1d7189b5bf78bd0d8d6e4bb2170dfeabba659c5c""><code>1d7189b</code></a> Merge branch 'master' of github.com:python-parsy/parsy</li>; <li><a href=""https://github.com/python-parsy/parsy/commit/8ec01153ccf6c58e2811c0e4c760b98125aeebca""><code>8ec0115</code></a> Link to SQL example from README</li>; <li>Additional commits viewable in <a href=""https://github.com/python-parsy/parsy/compare/v1.1.0...v1.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=parsy&package-manager=pip&previous-version=1.1.0&new-version=1.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12007:3549,Depend,Dependabot,3549,https://hail.is,https://github.com/hail-is/hail/pull/12007,1,['Depend'],['Dependabot']
Integrability,".com/python/typing_extensions/issues/43"">#43</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/abe4390fe2456c6052c868731eb4b225b5a2f529""><code>abe4390</code></a> dataclass_transform will be in 3.11 (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/42"">#42</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/e9d09b5bb998693c3565a276a27f424b327b0f7b""><code>e9d09b5</code></a> Remove obsolete README.rst (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/41"">#41</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/447b62c4816efbd85727a12191a310bac5c416cc""><code>447b62c</code></a> fix CI (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/4"">#4</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/47600f62c354ca028c29762fa6ff0b007716ef88""><code>47600f6</code></a> update links (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/3"">#3</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/bc9317ef90a629f27f1ab706bfce99da873044b4""><code>bc9317e</code></a> Change home URL to tree instead of README (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/1157"">#1157</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/c10296f15f92277ed1d3ed0c83103ae3818d3669""><code>c10296f</code></a> Add a README.rst file back temporarily. (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/1156"">#1156</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/python/typing_extensions/compare/4.2.0...4.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=typing-extensions&package-manager=pip&previous-version=4.2.0&new-version=4.3.0)](https://docs.github.com/en/git",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12200:3195,depend,dependabot,3195,https://hail.is,https://github.com/hail-is/hail/pull/12200,1,['depend'],['dependabot']
Integrability,".com/samtools/htsjdk/commit/d15a5bacbb5ed54f1a474aede9a2c3cb9d8832fb""><code>d15a5ba</code></a> Added ULTIMA and ELEMENT as valid value for RG-PL according to SAM spec. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1619"">#1619</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/489c4192dd9682a9d1e53f4c8f6f7bb826e33589""><code>489c419</code></a> Support CRAM reference regions. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1605"">#1605</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/f461401e38fe95362a6d3c5afd8b592964b4bd29""><code>f461401</code></a> Silence AsciiLineReader warning when creating a FASTA sequence index (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1559"">#1559</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/1449dec45b4e95293db14595ec0d11a3839bac23""><code>1449dec</code></a> Support loading of CSI from URLs/streams. <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1507"">#1507</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1595"">#1595</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/22aec6782b33f8d169a5d1cf63e952126a3f09e0""><code>22aec67</code></a> Fix decoding of CRAM Scores read feature during normalization. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1592"">#1592</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/70e42597ee8e2db6241f7b147f1356a1f8a846bc""><code>70e4259</code></a> Remove unnecessary println in test (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1602"">#1602</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/6507249a4422d021b984e710e8f031816f6d8da2""><code>6507249</code></a> Make the CRAM MD5 failure message more user friendly. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1607"">#1607</a>)</li>; <li>Additional commits viewable in <a href=""https://gi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12229:7822,depend,dependabot,7822,https://hail.is,https://github.com/hail-is/hail/pull/12229,1,['depend'],['dependabot']
Integrability,".com/samtools/htsjdk/commit/d15a5bacbb5ed54f1a474aede9a2c3cb9d8832fb""><code>d15a5ba</code></a> Added ULTIMA and ELEMENT as valid value for RG-PL according to SAM spec. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1619"">#1619</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/489c4192dd9682a9d1e53f4c8f6f7bb826e33589""><code>489c419</code></a> Support CRAM reference regions. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1605"">#1605</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/f461401e38fe95362a6d3c5afd8b592964b4bd29""><code>f461401</code></a> Silence AsciiLineReader warning when creating a FASTA sequence index (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1559"">#1559</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/1449dec45b4e95293db14595ec0d11a3839bac23""><code>1449dec</code></a> Support loading of CSI from URLs/streams. <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1507"">#1507</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1595"">#1595</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/22aec6782b33f8d169a5d1cf63e952126a3f09e0""><code>22aec67</code></a> Fix decoding of CRAM Scores read feature during normalization. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1592"">#1592</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/samtools/htsjdk/compare/2.24.1...3.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.github.samtools:htsjdk&package-manager=gradle&previous-version=2.24.1&new-version=3.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12310:8170,depend,dependabot,8170,https://hail.is,https://github.com/hail-is/hail/pull/12310,1,['depend'],['dependabot']
Integrability,".com/samtools/htsjdk/issues/1565"">#1565</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1566"">#1566</a>); 8466c82dc Respect genotype filtering when calculating AC/AN/AF (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1554"">#1554</a>)</p>; <p>User API:; a4f1f04c8 Allow fluent chaining setters for SAMSequenceRecord (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1563"">#1563</a>)</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/samtools/htsjdk/commit/4a4024a97ee3e87096df6ad9b22c8260bd527772""><code>4a4024a</code></a> Fix temporary directory hijacking or temporary directory information disclosu...</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/9fd0ecf212219d252ab273db0f7b845a59073d64""><code>9fd0ecf</code></a> Disable codecov until we can fix the uploader (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1622"">#1622</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/347c0ac571be29d7aa59fea3090947d9dcc9f8f0""><code>347c0ac</code></a> Fix EdgeReadIterator (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1616"">#1616</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/d15a5bacbb5ed54f1a474aede9a2c3cb9d8832fb""><code>d15a5ba</code></a> Added ULTIMA and ELEMENT as valid value for RG-PL according to SAM spec. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1619"">#1619</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/489c4192dd9682a9d1e53f4c8f6f7bb826e33589""><code>489c419</code></a> Support CRAM reference regions. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1605"">#1605</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/f461401e38fe95362a6d3c5afd8b592964b4bd29""><code>f461401</code></a> Silence AsciiLineReader warning when creating ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12229:6501,depend,dependabot,6501,https://hail.is,https://github.com/hail-is/hail/pull/12229,1,['depend'],['dependabot']
Integrability,".com/search?q=repo%3Aipython%2Fcomm+involves%3Apre-commit-ci+updated%3A2024-01-02..2024-03-12&amp;type=Issues""><code>@​pre-commit-ci</code></a></p>; <!-- raw HTML omitted -->; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/ipython/comm/commit/d119118d950f2c64f184c37e7e42b4c968701668""><code>d119118</code></a> Publish 0.2.2</li>; <li><a href=""https://github.com/ipython/comm/commit/76149e7ee0f331772c964ae86cdb8bafebe6dfa2""><code>76149e7</code></a> Update Release Scripts (<a href=""https://redirect.github.com/ipython/comm/issues/27"">#27</a>)</li>; <li><a href=""https://github.com/ipython/comm/commit/915898ddeddd0d1c8a1b87c5dcfbe6392fd225b7""><code>915898d</code></a> chore: update pre-commit hooks (<a href=""https://redirect.github.com/ipython/comm/issues/26"">#26</a>)</li>; <li>See full diff in <a href=""https://github.com/ipython/comm/compare/v0.2.1...v0.2.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=comm&package-manager=pip&previous-version=0.2.1&new-version=0.2.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14492:3545,Depend,Dependabot,3545,https://hail.is,https://github.com/hail-is/hail/pull/14492,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,".com/tomplus/kubernetes_asyncio/issues/210"">#210</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/8b54424920fd58174d7b215489d4f74c7656ed3d""><code>8b54424</code></a> [chore] update changelog</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/50fc5f8758a3f0c0da723ae766f48345e2108ce9""><code>50fc5f8</code></a> Periodically refresh ServiceAccount tokens (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/205"">#205</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/af050bb8b129a6648030ec11c1b0625cfd7a29dd""><code>af050bb</code></a> chore(deps): update sphinx requirement (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/204"">#204</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/7e7999c19300d32c04f90cc0b56f0c5488e9d787""><code>7e7999c</code></a> [chore] pin k8s version to 1.23.6 in e2e tests. (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/206"">#206</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/308f153f91b7942476f2d4ddda3dc8c99933d598""><code>308f153</code></a> ci: add workflow to publish sdist/wheel to PyPI (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/202"">#202</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/961624063383cbcdc78a61b1d18448429a61a489""><code>9616240</code></a> [chore] update changelog</li>; <li>Additional commits viewable in <a href=""https://github.com/tomplus/kubernetes_asyncio/compare/v19.15.1...23.6.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=kubernetes-asyncio&package-manager=pip&previous-version=19.15.1&new-version=23.6.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:14879,depend,dependabot,14879,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['depend'],['dependabot']
Integrability,".com/urllib3/urllib3/commit/b594c5ceaca38e1ac215f916538fb128e3526a36""><code>b594c5c</code></a> Merge pull request from GHSA-g4mx-q9vg-27p4</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/944f0eb134485f41bc531be52de12ba5a37bca73""><code>944f0eb</code></a> [1.26] Use vendored six in urllib3.contrib.securetransport</li>; <li>See full diff in <a href=""https://github.com/urllib3/urllib3/compare/1.26.17...1.26.18"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.17&new-version=1.26.18)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13842:2120,depend,dependabot-automerge-start,2120,https://hail.is,https://github.com/hail-is/hail/pull/13842,10,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,".dependabot.com/PyCQA/pylint/issues/5770"">PyCQA/pylint#5770</a></p>; </li>; <li>; <p>Add support for <a href=""https://github.com/python-attrs/attrs/releases/tag/21.3.0"">attrs v21.3.0</a> which; added a new <code>attrs</code> module alongside the existing <code>attr</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1330"">#1330</a></p>; </li>; <li>; <p>Use the <code>end_lineno</code> attribute for the <code>NodeNG.tolineno</code> property; when it is available.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1350"">#1350</a></p>; </li>; <li>; <p>Add <code>is_dataclass</code> attribute to <code>ClassDef</code> nodes.</p>; </li>; <li>; <p>Use <code>sysconfig</code> instead of <code>distutils</code> to determine the location of; python stdlib files and packages.</p>; <p>Related pull requests: <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1322"">#1322</a>, <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1323"">#1323</a>, <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1324"">#1324</a>; Closes <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1282"">#1282</a>; Ref <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1103"">#1103</a></p>; </li>; <li>; <p>Fixed crash with recursion error for inference of class attributes that referenced; the class itself.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5408"">PyCQA/pylint#5408</a></p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/astroid/commit/07c0f60ffc1017d0a9a2bb605a5c645781a8c088""><code>07c0f60</code></a> Bump astroid to 2.10.0, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/e6dc5ef0f8c2d28bc9d2ffa226fbb5e4e58d88f3""><code>e6dc5ef</code></a> Fix some typoes in the",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11463:2528,depend,dependabot,2528,https://hail.is,https://github.com/hail-is/hail/pull/11463,2,['depend'],['dependabot']
Integrability,".dependabot.com/aio-libs/aiodocker/issues/466"">#466</a>)</li>; <li>Add <code>container.rename()</code> method. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/458"">#458</a>)</li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>Changed DockerNetwork.delete() to return True if successful (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/464"">#464</a>)</li>; </ul>; <h1>0.18.9 (2020-07-07)</h1>; <p>Bugfixes</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiodocker/commit/234522e191d208bab11175e2684b02ed9caedc43""><code>234522e</code></a> Bump to 0.21.0</li>; <li><a href=""https://github.com/aio-libs/aiodocker/commit/9b459934c3b1fde2fb9f0fa4e692be2403994cda""><code>9b45993</code></a> Fix <a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/536"">#536</a>: ssl_context not used (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/607"">#607</a>)</li>; <li><a href=""https://github.com/aio-libs/aiodocker/commit/72c157378490cfd4ef463759169c8be2bdfbfd19""><code>72c1573</code></a> Fix error when Stream is closed after container stopped (<a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/608"">#608</a>)</li>; <li><a href=""https://github.com/aio-libs/aiodocker/commit/e35e9698c93d5e9df59e81267a65ff355109af5c""><code>e35e969</code></a> Bump to 0.20.0</li>; <li><a href=""https://github.com/aio-libs/aiodocker/commit/d85e607f2c3d100b6415273665e75bc1fd75657c""><code>d85e607</code></a> Fix <a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/295"">#295</a>: allow passing credentials into run() call to pulling absent image f...</li>; <li><a href=""https://github.com/aio-libs/aiodocker/commit/2ad735b17d4ee7c1b1617373d2858ae776672ef3""><code>2ad735b</code></a> Fix <a href=""https://github-redirect.dependabot.com/aio-libs/aiodocker/issues/295"">#295</a>: allow pa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11537:3514,depend,dependabot,3514,https://hail.is,https://github.com/hail-is/hail/pull/11537,1,['depend'],['dependabot']
Integrability,".dependabot.com/elastic/elasticsearch-hadoop/issues/1997"">#1997</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/2fcae131824c8221231f5f9331c2a5c677376237""><code>2fcae13</code></a> [DOCS] Added RNs for 8.4.1 (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1995"">#1995</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/elastic/elasticsearch-hadoop/compare/v8.4.3...v8.6.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.elasticsearch:elasticsearch-spark-20_2.12&package-manager=gradle&previous-version=8.4.3&new-version=8.6.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12601:5535,depend,dependabot,5535,https://hail.is,https://github.com/hail-is/hail/pull/12601,1,['depend'],['dependabot']
Integrability,".dependabot.com/pandas-dev/pandas/issues/50"">#50</a>...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/54b40379e3fe6825f676cf02767ee81adb6ffeb5""><code>54b4037</code></a> Backport PR on Branch 1.5.x (REV: revert deprecation of Series.<strong>getitem</strong> sl...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/71db310a328a0dfa194ef0fe2b95238817b4f419""><code>71db310</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/50396"">#50396</a> on branch 1.5.x (BUG/COMPAT: fix assert_* functions for ne...</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.5...v1.5.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pandas&package-manager=pip&previous-version=1.3.5&new-version=1.5.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Depe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12610:5680,depend,dependabot-security-updates,5680,https://hail.is,https://github.com/hail-is/hail/pull/12610,1,['depend'],['dependabot-security-updates']
Integrability,".dependabot.com/plotly/plotly.py/pull/3775"">#3775</a></li>; </ul>; <h3>Performance</h3>; <ul>; <li><code>px</code> methods no longer call <code>groupby</code> on the input dataframe when the result would be a single group, and no longer groups by a lambda, for significant speedups <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3765"">#3765</a> with thanks to <a href=""https://github.com/jvdd""><code>@​jvdd</code></a></li>; </ul>; <h3>Updated</h3>; <ul>; <li>Allow non-string extras in <code>flaglist</code> attributes, to support upcoming changes to <code>ax.automargin</code> in plotly.js <a href=""https://github-redirect.dependabot.com/plotly/plotly.js/pull/6193"">plotly.js#6193</a>, <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3749"">#3749</a></li>; </ul>; <h2>[5.8.2] - 2022-06-10</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed a syntax error that caused rendering issues in Databricks notebooks and likely elsewhere. <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3763"">#3763</a> with thanks to <a href=""https://github.com/fwetdb""><code>@​fwetdb</code></a></li>; </ul>; <h2>[5.8.1] - 2022-06-08</h2>; <p>(no changes, due to a mixup with the build process!)</p>; <h2>[5.8.0] - 2022-05-09</h2>; <h3>Fixed</h3>; <ul>; <li>Improve support for type checking and IDE auto-completion by bypassing lazy-loading when type checking. <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3425"">#3425</a> with thanks to <a href=""https://github.com/JP-Ellis""><code>@​JP-Ellis</code></a></li>; <li>line dash-style validators are now correctly used everywhere so that values like <code>10px 2px</code> are accepted <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/pull/3722"">#3722</a></li>; <li>Resolved various deprecation warning messages and compatibility issues with upstream dependencies and Python 3.11, plus removed dependency on <code>six</code>, with thanks to <a href=""https://github.com/maresb""><code>@​ma",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12113:3307,depend,dependabot,3307,https://hail.is,https://github.com/hail-is/hail/pull/12113,1,['depend'],['dependabot']
Integrability,".dependabot.com/pycqa/flake8/issues/1404"">#1404</a> from PyCQA/drop-xdg-config</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/807904aebc20814ac595b0004ab526fffb5ef681""><code>807904a</code></a> Drop support for Home and XDG config files</li>; <li>Additional commits viewable in <a href=""https://github.com/pycqa/flake8/compare/3.8.3...4.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=flake8&package-manager=pip&previous-version=3.8.3&new-version=4.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11456:2817,Depend,Dependabot,2817,https://hail.is,https://github.com/hail-is/hail/pull/11456,2,['Depend'],['Dependabot']
Integrability,".dependabot.com/pytest-dev/pytest/issues/9362"">#9362</a>: pytest now avoids specialized assert formatting when it is detected that the default <code>__eq__</code> is overridden in <code>attrs</code> or <code>dataclasses</code>.</p>; </li>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9536"">#9536</a>: When <code>-vv</code> is given on command line, show skipping and xfail reasons in full instead of truncating them to fit the terminal width.</p>; </li>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9644"">#9644</a>: More information about the location of resources that led Python to raise <code>ResourceWarning</code>{.interpreted-text role=&quot;class&quot;} can now; be obtained by enabling <code>tracemalloc</code>{.interpreted-text role=&quot;mod&quot;}.</p>; <p>See <code>resource-warnings</code>{.interpreted-text role=&quot;ref&quot;} for more information.</p>; </li>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9678"">#9678</a>: More types are now accepted in the <code>ids</code> argument to <code>@pytest.mark.parametrize</code>.; Previously only [str]{.title-ref}, [float]{.title-ref}, [int]{.title-ref} and [bool]{.title-ref} were accepted;; now [bytes]{.title-ref}, [complex]{.title-ref}, [re.Pattern]{.title-ref}, [Enum]{.title-ref} and anything with a [__name__]{.title-ref} are also accepted.</p>; </li>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9692"">#9692</a>: <code>pytest.approx</code>{.interpreted-text role=&quot;func&quot;} now raises a <code>TypeError</code>{.interpreted-text role=&quot;class&quot;} when given an unordered sequence (such as <code>set</code>{.interpreted-text role=&quot;class&quot;}).</p>; <p>Note that this implies that custom classes which only implement <code>__iter__</code> and <code>__len__</code> are no longer supported as they don't guarantee order.</p>; </li>; </ul>; <!-- raw HTML omitted --",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11619:3064,depend,dependabot,3064,https://hail.is,https://github.com/hail-is/hail/pull/11619,1,['depend'],['dependabot']
Integrability,".dependabot.com/pytest-dev/pytest/issues/9362"">#9362</a>: pytest now avoids specialized assert formatting when it is detected that the default <code>__eq__</code> is overridden in <code>attrs</code> or <code>dataclasses</code>.</p>; </li>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9536"">#9536</a>: When <code>-vv</code> is given on command line, show skipping and xfail reasons in full instead of truncating them to fit the terminal width.</p>; </li>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9644"">#9644</a>: More information about the location of resources that led Python to raise <code>ResourceWarning</code>{.interpreted-text role=&quot;class&quot;} can now; be obtained by enabling <code>tracemalloc</code>{.interpreted-text role=&quot;mod&quot;}.</p>; <p>See <code>resource-warnings</code>{.interpreted-text role=&quot;ref&quot;} for more information.</p>; </li>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9678"">#9678</a>: More types are now accepted in the <code>ids</code> argument to <code>@pytest.mark.parametrize</code>.; Previously only [str]{.title-ref}, [float]{.title-ref}, [int]{.title-ref} and [bool]{.title-ref} were accepted;; now [bytes]{.title-ref}, [complex]{.title-ref}, [re.Pattern]{.title-ref}, [Enum]{.title-ref} and anything with a [__name__]{.title-ref} are also accepted.</p>; </li>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9692"">#9692</a>: <code>pytest.approx</code>{.interpreted-text role=&quot;func&quot;} now raises a <code>TypeError</code>{.interpreted-text role=&quot;class&quot;} when given an unordered sequence (such as <code>set</code>{.interpreted-text role=&quot;class&quot;}).</p>; <p>Note that this implies that custom classes which only implement <code>__iter__</code> and <code>__len__</code> are no longer supported as they don't guarantee order.</p>; </li>; </ul>; <h2>Bug Fixes</h2>; <ul>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11571:2716,depend,dependabot,2716,https://hail.is,https://github.com/hail-is/hail/pull/11571,2,['depend'],['dependabot']
Integrability,".dependabot.com/samtools/htsjdk/issues/1552"">#1552</a>); d5f7e106b Adding PL Tag 'DNBSEQ' as the Platform/Technology for BGI/MGI (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1547"">#1547</a>)</p>; <p>Misc Improvements; f461401e3 Silence AsciiLineReader warning when creating a FASTA sequence index (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1559"">#1559</a>); 8f82871c1 Update explain samflags script to python3 (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1585"">#1585</a>); 4ba4c0678 Update to new version of the snappy library which will work with M1 macs (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1580"">#1580</a>); e92706452 add predicate to GFF3Codec to give a chance to filter out some unused attributes (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1575"">#1575</a>); c647764b0 Some long reads tests using PacBio data. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1564"">#1564</a>); 57c3f03eb remove hardcoded .idx (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1568"">#1568</a>); a94a32512 Add file extension to missing index error message <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1512"">#1512</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1567"">#1567</a>); 74b827b67 Improve error message in IntervalTree (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1545"">#1545</a>); 7719274fe Htsget POST request support (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1529"">#1529</a>)</p>; <p>VCF:; aac46ee6d Added GVCF mode for VariantContext type determination (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1544"">#1544</a>); d72d73b01 Add context to exception when the vcf file is invalid <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1565"">#1565</a> (<a hre",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12229:4551,depend,dependabot,4551,https://hail.is,https://github.com/hail-is/hail/pull/12229,1,['depend'],['dependabot']
Integrability,".dependabot.com/samtools/htsjdk/issues/1552"">#1552</a>); d5f7e106b Adding PL Tag 'DNBSEQ' as the Platform/Technology for BGI/MGI (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1547"">#1547</a>)</p>; <p>Misc Improvements; f461401e3 Silence AsciiLineReader warning when creating a FASTA sequence index (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1559"">#1559</a>); 8f82871c1 Update explain samflags script to python3 (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1585"">#1585</a>); 4ba4c0678 Update to new version of the snappy library which will work with M1 macs (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1580"">#1580</a>); e92706452 add predicate to GFF3Codec to give a chance to filter out some unused attributes (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1575"">#1575</a>); c647764b0 Some long reads tests using PacBio data. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1564"">#1564</a>)</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/samtools/htsjdk/commit/02942a97ef6e7e14019efa502b0b03fea3c68c1f""><code>02942a9</code></a> Remove deprecation from Allele.acceptableAlleleBases <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1623"">#1623</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1625"">#1625</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/e490a97ae465abe3ccaf24bc116cd9e80909764e""><code>e490a97</code></a> Minor improvements to AbstractLocusIterator (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1624"">#1624</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/4a4024a97ee3e87096df6ad9b22c8260bd527772""><code>4a4024a</code></a> Fix temporary directory hijacking or temporary directory information disclosu...</l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12310:5637,depend,dependabot,5637,https://hail.is,https://github.com/hail-is/hail/pull/12310,1,['depend'],['dependabot']
Integrability,".dependabot.com/tox-dev/py-filelock/pull/155"">tox-dev/py-filelock#155</a></li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/tox-dev/py-filelock/compare/3.7.1...3.8.0"">https://github.com/tox-dev/py-filelock/compare/3.7.1...3.8.0</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/24b26b6be356de80d7212a9f7621d81c6d3eec8d""><code>24b26b6</code></a> Delete main.pdf</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/f7e72dd59b230b2751b10023851b01655d60bac6""><code>f7e72dd</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/issues/162"">#162</a>)</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/81bd5a3666c863c665acfdaf9ace6c6c964e0ad5""><code>81bd5a3</code></a> Update check.yml</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/558c67f85a6f23b22831e81d792bb21471c12393""><code>558c67f</code></a> Bump build dependencies</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/fc2edee8ecf5d4eae99e6e7502671a094e9d60d2""><code>fc2edee</code></a> Bump dependencies</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/3b3f562be03ae963dadd1360a04b430e37b4bfd9""><code>3b3f562</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/issues/159"">#159</a>)</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/e3894f669319c4371cd398f39fe99c57c8395212""><code>e3894f6</code></a> Check 3.11 support (<a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/issues/158"">#158</a>)</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/1957538dea683fda4cca8650efd35b97ccab04ab""><code>1957538</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/issues/157"">#157</a>)</li>; <li><a href=""https://github.com/tox-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12157:5132,depend,dependencies,5132,https://hail.is,https://github.com/hail-is/hail/pull/12157,1,['depend'],['dependencies']
Integrability,.execution.datasources.parquet.ParquetRelation$MetadataCache.refresh(ParquetRelation.scala:404); at org.apache.spark.sql.execution.datasources.parquet.ParquetRelation.org$apache$spark$sql$execution$datasources$parquet$ParquetRelation$$metadataCache$lzycompute(ParquetRelation.scala:145); at org.apache.spark.sql.execution.datasources.parquet.ParquetRelation.org$apache$spark$sql$execution$datasources$parquet$ParquetRelation$$metadataCache(ParquetRelation.scala:143); at org.apache.spark.sql.execution.datasources.parquet.ParquetRelation$$anonfun$6.apply(ParquetRelation.scala:196); at org.apache.spark.sql.execution.datasources.parquet.ParquetRelation$$anonfun$6.apply(ParquetRelation.scala:196); at scala.Option.getOrElse(Option.scala:120); at org.apache.spark.sql.execution.datasources.parquet.ParquetRelation.dataSchema(ParquetRelation.scala:196); at org.apache.spark.sql.sources.HadoopFsRelation.schema$lzycompute(interfaces.scala:561); at org.apache.spark.sql.sources.HadoopFsRelation.schema(interfaces.scala:560); at org.apache.spark.sql.execution.datasources.LogicalRelation.<init>(LogicalRelation.scala:31); at org.apache.spark.sql.SQLContext.baseRelationToDataFrame(SQLContext.scala:389); at org.apache.spark.sql.DataFrameReader.parquet(DataFrameReader.scala:267); at org.broadinstitute.hail.variant.VariantSampleMatrix$.read(VariantSampleMatrix.scala:132); at org.broadinstitute.hail.driver.Read$.run(Read.scala:29); at org.broadinstitute.hail.driver.Read$.run(Read.scala:6); at org.broadinstitute.hail.driver.Command.runCommand(Command.scala:238); at org.broadinstitute.hail.driver.Main$.runCommand(Main.scala:86); at org.broadinstitute.hail.driver.Main$$anonfun$runCommands$1$$anonfun$1.apply(Main.scala:111); at org.broadinstitute.hail.driver.Main$$anonfun$runCommands$1$$anonfun$1.apply(Main.scala:111); at org.broadinstitute.hail.Utils$.time(Utils.scala:1185); at org.broadinstitute.hail.driver.Main$$anonfun$runCommands$1.apply(Main.scala:110); at org.broadinstitute.hail.driver.Main,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/621:2068,interface,interfaces,2068,https://hail.is,https://github.com/hail-is/hail/issues/621,1,['interface'],['interfaces']
Integrability,".g. MethodBuilder support the ClassBuilder interface: this is what the Wrapped traits are for: MethodBuilder extends WrappedClassBuilder and ClassBuilder extends WrappedModuleBuilder. So MethodBuilder has the ClassBuilder interface, but is not actually a ClassBuilder. I tried a bunch of variants for the design of this, and while I don't think this is quite perfect, it seems workable.; - EmitMethodBuilder extends WrappedMethodBuilder, etc. Rather than overloading, the two interfaces are distinct: genMethod vs genEmitMethod, etc.; - Pushed ""new vs gen"" into more places e.g. newMethod vs genMethod. newMethod takes a name and creates a method of that name (e.g. apply). genMethod takes a baseName and creates a unique name based on the baseName.; - MethodBuilder newField => genFieldThisRef to distinguish it from ClassBuilder.newField. The former returns a Settable[T] referencing `this.<field>`, the latter just returns a Field.; - All methods supporting code generation for IR take EmitMethodBuilder rather than MethodBuilder (PType routines, aggregators, etc.). Summarizing the new class structure:. ```; class ModuleBuilder; trait WrappedModuleBuilder; def modb: ModuleBuilder; class ClassBuilder[C] extends WrappedModuleBuilder; trait WrappedClassBuilder[C]; def cb: ClassBuilder[C]; class MethodBuilder[C] extends WrappedClassBuilder[C]; trait WrappedMethodBuilder[C]; def mb: MethodBuilder; class FunctionBuilder[F] extends WrappedMethodBuilder[F]; def apply_method: MethodBuilder[F]. class EmitModuleBuilder extends WrappedModuleBuilder; trait WrappedEmitModuleBuilder extends WrappedModuleBuilder; def emodb: EmitModuleBuilder; class EmitClassBuilder[C] extends WrappedEmitModuleBuilder with WrappedClassBuilder[C]; trait WrappedEmitClassBuilder[C] extends WrappedModuleBuilder with WrappedClassBuilder[C]; def ecb: EmitClassBuilder; class EmitMethodBuilder[C] extends WrappedClassBuilder[C] with WrappedMethodBuilder[C]; trait WrappedEmitMethodBuilder[C] extends WrappedClassBuilder[C] ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8335:1892,rout,routines,1892,https://hail.is,https://github.com/hail-is/hail/pull/8335,1,['rout'],['routines']
Integrability,".hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": ""https GET /michaelfranklin/query/api/v1alpha/wait done in 50.029999999998836s: 200"", ""remote_address"": ""10.28.127.3"", ""request_start_time"": ""[24/Feb/2021:23:22:35 +0000]"", ""request_duration"": 50.029999999998836, ""response_status"": 200, ""x_real_ip"": ""124.170.20.28"", ""hail_log"": 1}; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,005"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:255"", ""message"": ""Tasks have all completed."", ""hail_log"": 1}; ```. Test duration endpoint; ```python; @routes.get('/api/v1alpha/wait'); async def wait_seconds(request):; """"""; Wait query.duration seconds before returning the request.; """"""; duration = request.query.get('duration'); try:; duration = int(duration); except Exception as e:; return web.json_response({; 'error': f'In",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10106:1682,message,message,1682,https://hail.is,https://github.com/hail-is/hail/pull/10106,1,['message'],['message']
Integrability,.ir.Optimize$.apply(Optimize.scala:45); at is.hail.expr.ir.lowering.OptimizePass.transform(LoweringPass.scala:30); at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); at is.hail.expr.ir.lowering.OptimizePass.apply(LoweringPass.scala:26); at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:15); at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:13); at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:13); at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:47); at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:450); at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:486); at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:70); at is.hail.utils.package$.using(package.scala:635); at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:70); at is.hail.utils.package$.using(package.scala:635); at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:59); at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:339); at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$1(SparkBackend.scala:483); at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); at is.hail.backend.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13046:3743,Wrap,WrappedArray,3743,https://hail.is,https://github.com/hail-is/hail/issues/13046,1,['Wrap'],['WrappedArray']
Integrability,.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.co,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:9139,Wrap,WrappedArray,9139,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Wrap'],['WrappedArray']
Integrability,.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at is.hail.expr.ir.BaseIR.mapChildren(BaseIR.scala:17); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:30); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:11); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyValue$1.apply(Simplify.scala:36); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.Wra,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:10107,Wrap,WrappedArray,10107,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['Wrap'],['WrappedArray']
Integrability,".org/en/master/changes.html"">https://www.sphinx-doc.org/en/master/changes.html</a></p>; <h2>v4.4.0</h2>; <p>Changelog: <a href=""https://www.sphinx-doc.org/en/master/changes.html"">https://www.sphinx-doc.org/en/master/changes.html</a></p>; <h2>v4.3.1</h2>; <p>No release notes provided.</p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/sphinx-doc/sphinx/blob/5.x/CHANGES"">sphinx's changelog</a>.</em></p>; <blockquote>; <h1>Release 5.1.1 (released Jul 26, 2022)</h1>; <h2>Bugs fixed</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10701"">#10701</a>: Fix ValueError in the new <code>deque</code> based <code>sphinx.ext.napolean</code>; iterator implementation.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10702"">#10702</a>: Restore compatability with third-party builders.</li>; </ul>; <h1>Release 5.1.0 (released Jul 24, 2022)</h1>; <h2>Dependencies</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10656"">#10656</a>: Support <code>Docutils 0.19</code>_. Patch by Adam Turner.</li>; </ul>; <p>.. _Docutils 0.19: <a href=""https://docutils.sourceforge.io/RELEASE-NOTES.html#release-0-19-2022-07-05"">https://docutils.sourceforge.io/RELEASE-NOTES.html#release-0-19-2022-07-05</a></p>; <h2>Deprecated</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10467"">#10467</a>: Deprecated <code>sphinx.util.stemmer</code> in favour of <code>snowballstemmer</code>.; Patch by Adam Turner.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9856"">#9856</a>: Deprecated <code>sphinx.ext.napoleon.iterators</code>.</li>; </ul>; <h2>Features added</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10444"">#10444</a>: html theme: Allow specifying multiple CSS files through the <code>stylesheet</code>; setting in <code",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12165:2096,Depend,Dependencies,2096,https://hail.is,https://github.com/hail-is/hail/pull/12165,1,['Depend'],['Dependencies']
Integrability,".primitives.asymmetric.rsa.RSAPrivateNumbers.private_key</code>.; This speeds up key loading but is :term:<code>unsafe</code> if you are loading potentially; attacker supplied keys.</li>; <li>Significantly improved performance for; :class:<code>~cryptography.hazmat.primitives.ciphers.aead.ChaCha20Poly1305</code></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pyca/cryptography/commit/d6951dca25de45abd52da51b608055371fbcde4e""><code>d6951dc</code></a> changelog + security fix backport (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/8231"">#8231</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/138da90c8450446b19619e3faa77b9da54c34be3""><code>138da90</code></a> workaround scapy bug in downstream tests (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/8218"">#8218</a>) (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/8228"">#8228</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/69527bc79095c9646d7e839121f0783477892ecc""><code>69527bc</code></a> bookworm is py311 now (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/8200"">#8200</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/111deefb659b8d73c56d3ce89458f2df973d60e4""><code>111deef</code></a> backport main branch CI to 39.0.x (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/8153"">#8153</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/338a65a7df74e189f6b5d1d3a6315ffa911b21c2""><code>338a65a</code></a> 39.0.0 version bump (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7954"">#7954</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/84a3cd7abb16f594d8c315e8aedb4be02583bf6a""><code>84a3cd7</code></a> automatically download and upload circleci wheels (<a href=""https://github-redir",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12668:3897,depend,dependabot,3897,https://hail.is,https://github.com/hail-is/hail/pull/12668,4,['depend'],['dependabot']
Integrability,.put(IdentityObjectIntMap.java:162); at com.esotericsoftware.kryo.util.IdentityObjectIntMap.putStash(IdentityObjectIntMap.java:307); at com.esotericsoftware.kryo.util.IdentityObjectIntMap.push(IdentityObjectIntMap.java:300); at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:162); at com.esotericsoftware.kryo.util.MapReferenceResolver.addWrittenObject(MapReferenceResolver.java:41); at com.esotericsoftware.kryo.Kryo.writeReferenceOrNull(Kryo.java:681); at com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:616); at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$StringArraySerializer.write(DefaultArraySerializers.java:272); at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$StringArraySerializer.write(DefaultArraySerializers.java:258); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651); at com.twitter.chill.WrappedArraySerializer.write(WrappedArraySerializer.scala:28); at com.twitter.chill.WrappedArraySerializer.write(WrappedArraySerializer.scala:23); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651); at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:361); at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:302); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651); at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14168:2536,Wrap,WrappedArraySerializer,2536,https://hail.is,https://github.com/hail-is/hail/issues/14168,2,['Wrap'],['WrappedArraySerializer']
Integrability,".py"", line 8, in <module>; from hailtop.fs.fs import FS; File ""/Users/srinivas/test/.pixi/envs/default/lib/python3.12/site-packages/hailtop/fs/__init__.py"", line 1, in <module>; from .fs_utils import (; File ""/Users/srinivas/test/.pixi/envs/default/lib/python3.12/site-packages/hailtop/fs/fs_utils.py"", line 4, in <module>; from hailtop.aiocloud.aiogoogle import GCSRequesterPaysConfiguration; File ""/Users/srinivas/test/.pixi/envs/default/lib/python3.12/site-packages/hailtop/aiocloud/aiogoogle/__init__.py"", line 1, in <module>; from .client import (; File ""/Users/srinivas/test/.pixi/envs/default/lib/python3.12/site-packages/hailtop/aiocloud/aiogoogle/client/__init__.py"", line 8, in <module>; from .storage_client import (; File ""/Users/srinivas/test/.pixi/envs/default/lib/python3.12/site-packages/hailtop/aiocloud/aiogoogle/client/storage_client.py"", line 14, in <module>; from hailtop.aiotools import FeedableAsyncIterable, WriteBuffer; File ""/Users/srinivas/test/.pixi/envs/default/lib/python3.12/site-packages/hailtop/aiotools/__init__.py"", line 1, in <module>; from .fs import (; File ""/Users/srinivas/test/.pixi/envs/default/lib/python3.12/site-packages/hailtop/aiotools/fs/__init__.py"", line 1, in <module>; from .copier import Copier, CopyReport, SourceCopier, SourceReport, Transfer, TransferReport; File ""/Users/srinivas/test/.pixi/envs/default/lib/python3.12/site-packages/hailtop/aiotools/fs/copier.py"", line 7, in <module>; import humanize; File ""/Users/srinivas/test/.pixi/envs/default/lib/python3.12/site-packages/humanize/__init__.py"", line 1, in <module>; import pkg_resources; ModuleNotFoundError: No module named 'pkg_resources'. ```. I think this is largely because hail requires an ancient version of humanize (v1 vs v4). In any case, the wheel on PyPI is broken and un-importable. . There are other issues stemming from the underlying issue that there is no clear description of requirements and dependencies. . ### Version. 0.2.132. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14630:2777,depend,dependencies,2777,https://hail.is,https://github.com/hail-is/hail/issues/14630,1,['depend'],['dependencies']
Integrability,".py:76: in execute; result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); ../../.venv/lib/python3.10/site-packages/py4j/java_gateway.py:1321: in __call__; return_value = get_return_value(; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . args = ('xro549', <py4j.clientserver.JavaClient object at 0x7fd0d58f6fb0>, 'o1', 'executeEncode'); kwargs = {}; pyspark = <module 'pyspark' from '/home/edmund/.local/src/hail/.venv/lib/python3.10/site-packages/pyspark/__init__.py'>; s = 'java.lang.AssertionError: assertion failed', tpl = JavaObject id=o550; deepest = 'AssertionError: assertion failed'; full = 'java.lang.AssertionError: assertion failed\n\tat scala.Predef$.assert(Predef.scala:208)\n\tat is.hail.expr.ir.BlockMa...lientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:834)\n\n\n'; error_id = -1. def deco(*args, **kwargs):; import pyspark; try:; return f(*args, **kwargs); except py4j.protocol.Py4JJavaError as e:; s = e.java_exception.toString(); ; # py4j catches NoSuchElementExceptions to stop array iteration; if s.startswith('java.util.NoSuchElementException'):; raise; ; tpl = Env.jutils().handleForPython(e.java_exception); deepest, full, error_id = tpl._1(), tpl._2(), tpl._3(); > raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; E hail.utils.java.FatalError: AssertionError: assertion failed; E ; E Java stack trace:; E java.lang.AssertionError: assertion failed; E 	at scala.Predef$.assert(Predef.scala:208); E 	at is.hail.expr.ir.BlockMatrixMap.execute(BlockMatrixIR.scala:269); E 	at is.hail.expr.ir.BlockMatrixMap2.execute(BlockMatrixIR.scala:393); E 	at is.hail.expr.ir.Interpret$.run(Interpret.scala:875); E 	at is.hail.expr.ir.Interpret$.alreadyLowered(Interpret.scala:59); E 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.evaluate$1(LowerOrInterpretNonCompilable.scala:20); E 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(Low",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12754#issuecomment-1456467229:2313,protocol,protocol,2313,https://hail.is,https://github.com/hail-is/hail/pull/12754#issuecomment-1456467229,1,['protocol'],['protocol']
Integrability,".reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:745)is.hail.utils.HailException: gcad.sv.delly.5k.vcf.bgz: caught java.lang.NumberFormatException: For input string: ""-66.2667,0,-25.4754""; offending line: chr2 130824417 DEL00068296 AGAACAGGACATCCCAGGCAGCTACAGCCCATC...; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:17); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.utils.Context.wrapException(Context.scala:23); at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:741); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); at is.hail.rvd.OrderedRVD$$anon$2.hasNext(OrderedRVD.scala:412); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.hasNext(OrderedRVD.scala:750); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at is.hail.io.RichRDDRegionValue$$anonfun$5$$anonfun$apply$1$$anonfun$apply$2$$anonfun$apply$3$$anonfun$apply$4.apply(RowStore.scala:774); at is.hail.io.RichRDDRegionValue$$anonfun$5$$anonfun$apply$1$$anonfun$apply$2$$anonfun$apply$3$$anonfun$apply$4.apply(RowStore.scala:767); at is.hail.utils.package$.using(package.scala:576); at is.hail.io.Ric",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3361:9531,wrap,wrapException,9531,https://hail.is,https://github.com/hail-is/hail/issues/3361,1,['wrap'],['wrapException']
Integrability,.relocated.com.google.cloud.storage.spi.v1.HttpStorageRpc.load(HttpStorageRpc.java:726); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.lambda$readAllBytes$24(StorageImpl.java:574); 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:103); 	at is.hail.relocated.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at is.hail.relocated.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at is.hail.relocated.com.google.cloud.storage.Retrying.run(Retrying.java:60); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.run(StorageImpl.java:1476); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.readAllBytes(StorageImpl.java:574); 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.readAllBytes(StorageImpl.java:563); 	at is.hail.io.fs.GoogleStorageFS.$anonfun$readNoCompression$1(GoogleStorageFS.scala:288); 	at is.hail.services.package$.retryTransientErrors(package.scala:163); 	at is.hail.io.fs.GoogleStorageFS.readNoCompression(GoogleStorageFS.scala:286); 	at is.hail.io.fs.RouterFS.readNoCompression(RouterFS.scala:26); 	at is.hail.backend.service.ServiceBackend$$anon$4.call(ServiceBackend.scala:239); 	at is.hail.backend.service.ServiceBackend$$anon$4.call(ServiceBackend.scala:235); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750). Hail version: 0.2.120-f00f916faf78; Error summary: GoogleJsonResponseException: 404 Not Found; GET https://storage.googleapis.com/download/storage/v1/b/wes-bipolar-tmp-4day/o/bge-wave-1-VQSR%2FparallelizeAndComputeWithIndex%2FgCyfD7XOt_MQrrCGc4Q-RrrWPb3cTAbhhcV28BCntiU=%2Fresult.2706?alt=media; No such object: wes-bipolar-tmp-4day/bge-wave-1-VQSR/parallelizeAndComputeWithIndex/gCyfD7XOt_MQrrCGc4Q-RrrWPb3cTAbhhcV28BCntiU=/result.2706; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13409:9485,Rout,RouterFS,9485,https://hail.is,https://github.com/hail-is/hail/issues/13409,2,['Rout'],['RouterFS']
Integrability,.scala:2125); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); 	at org.apache.spark.scheduler.Task.run(Task.scala:109); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:344); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); 	at java.lang.Thread.run(Thread.java:745). is.hail.utils.HailException: Error parsing row fields in row 0:; expected 5 fields but only 5 found.; File: foo; Line:; 7	75216143	75216143	C/T	+; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:28); 	at is.hail.io.LoadMatrixParser.parseLine(LoadMatrix.scala:33); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:383); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6$$anonfun$apply$7.apply(LoadMatrix.scala:377); 	at is.hail.utils.WithContext.wrap(Context.scala:41); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:377); 	at is.hail.io.LoadMatrix$$anonfun$16$$anonfun$apply$6.apply(LoadMatrix.scala:375); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:409); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:575); 	at is.hail.rvd.RVD$$anonfun$count$2.apply(RVD.scala:573); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$28.apply(ContextRDD.scala:405); 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$28.apply(ContextRDD.scala:405); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$8.apply(ContextRDD.scala:192); 	at is.hail.sparkextras.ContextRDD$$anonfun$run$1$$anonfun$apply$8.apply(ContextRDD.scala:192); 	at scala.collection.Itera,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5718:13221,wrap,wrap,13221,https://hail.is,https://github.com/hail-is/hail/issues/5718,1,['wrap'],['wrap']
Integrability,.scala:27); 	at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3$$anonfun$1.apply(LoweringPass.scala:15); 	at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3$$anonfun$1.apply(LoweringPass.scala:15); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); 	at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3.apply(LoweringPass.scala:15); 	at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3.apply(LoweringPass.scala:13); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); 	at is.hail.expr.ir.lowering.LoweringPass$class.apply(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.OptimizePass.apply(LoweringPass.scala:24); 	at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:14); 	at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:12); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:12); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:28); 	at is.hail.backend.spark.SparkBackend.is$hail$backend$spark$SparkBackend$$_execute(SparkBackend.scala:318); 	at is.hail.backend.spark.SparkBackend$$anonfun$execute$1.apply(SparkBackend.scala:305); 	at is.hail.backend.spark.SparkBackend$$anonfun$execute$1.apply(SparkBackend.scala:304); 	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:20); 	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:18); 	at is.hail.utils.package$.using(package.scala:602); 	at is.hail.annotations.Region$.scoped(Region.scala:18); 	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:18); 	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:230); 	at is.hail.backend.spark.SparkBackend.execute(SparkBackend.scala:304); 	at is.hail.backend.spark.Spark,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9128:7281,Wrap,WrappedArray,7281,https://hail.is,https://github.com/hail-is/hail/issues/9128,1,['Wrap'],['WrappedArray']
Integrability,".serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:185); at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32); at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37); at org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:199); at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:103); at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:105); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323); at org.apache.spark.rdd.RDD.iterator(RDD.scala:287); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38). Hail version: 0.2-721af83bc30a; Error summary: OutOfMemoryError: GC overhead limit exceeded; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1035, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 883, in send_command; response = connection.send_command(command); File ""/share/pkg/spark/2.2.1/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1040, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780:15399,protocol,protocol,15399,https://hail.is,https://github.com/hail-is/hail/issues/4780,2,['protocol'],['protocol']
Integrability,".ss.nt1) &; (mt.alleles[1] == mt.ss.nt2)) |; ((flip_text(mt.alleles[0]) == mt.ss.nt1) &; (flip_text(mt.alleles[1]) == mt.ss.nt2)),; (-1*mt.ss.ldpred_inf_beta)); .when(((mt.alleles[0] == mt.ss.nt2) &; (mt.alleles[1] == mt.ss.nt1)) |; ((flip_text(mt.alleles[0]) == mt.ss.nt2) &; (flip_text(mt.alleles[1]) == mt.ss.nt1)),; mt.ss.ldpred_inf_beta); .or_missing()). # filter bgen matrixtable down to only SNPs with betas; mt = mt.filter_rows(hl.is_defined(mt.beta)). # filter bgen matrixtable to only include people in scoring sample; mt = mt.filter_cols(hl.is_defined(sampleids[mt.s])). # score sample; mt = mt.annotate_cols(prs=hl.agg.sum(mt.beta * mt.dosage)). # write out table with sample IDs and PRS scores; mt.cols().export('gs://ukbb_prs/prs/UKB_'+pheno+'_PRS_22.txt'). parser = argparse.ArgumentParser(); parser.add_argument(""--phenotype"", help=""name of the sumstat phenotype""); args = parser.parse_args(). try:; start = time.time(); main(args.phenotype); end = time.time(); message = ""Success! Job was completed in %s"" % time.strftime(""%H:%M:%S"", time.gmtime(end - start)); send_message(message); except Exception as e:; send_message(""Fail.""); ```. ""Failure Reason"":; ```; Job aborted due to stage failure: Task 98 in stage 13.0 failed 20 times, most recent failure: Lost task 98.19 in stage 13.0 (TID 22699, ccarey-sw-xt4j.c.ukbb-robinson.internal, executor 68): java.lang.NegativeArraySizeException; 	at java.util.Arrays.copyOf(Arrays.java:3236); 	at is.hail.annotations.Region.ensure(Region.scala:139); 	at is.hail.annotations.Region.allocate(Region.scala:152); 	at is.hail.annotations.Region.allocate(Region.scala:159); 	at is.hail.expr.types.TContainer.allocate(TContainer.scala:127); 	at is.hail.annotations.RegionValueBuilder.fixupArray(RegionValueBuilder.scala:278); 	at is.hail.annotations.RegionValueBuilder.addRegionValue(RegionValueBuilder.scala:432); 	at is.hail.expr.MatrixMapRows$$anonfun$25$$anonfun$apply$19.apply(Relational.scala:815); 	at is.hail.expr.MatrixMapRows$$anonfun$25",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681:2623,message,message,2623,https://hail.is,https://github.com/hail-is/hail/issues/3508#issuecomment-387563681,1,['message'],['message']
Integrability,".txt (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/131"">#131</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/6026462f3b63b4df442a7f3e9214ee8ebfd7ffdb""><code>6026462</code></a> chore: fix path to requirements.txt in release script [autoapprove] (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/130"">#130</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/python-api-common-protos/compare/v1.56.4...v1.57.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=googleapis-common-protos&package-manager=pip&previous-version=1.56.4&new-version=1.57.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12514:8012,Depend,Dependabot,8012,https://hail.is,https://github.com/hail-is/hail/pull/12514,1,['Depend'],['Dependabot']
Integrability,".v0.23.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest-asyncio&package-manager=pip&previous-version=0.21.1&new-version=0.23.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14507:9858,Depend,Dependabot,9858,https://hail.is,https://github.com/hail-is/hail/pull/14507,9,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,".v1.11.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=scipy&package-manager=pip&previous-version=1.9.3&new-version=1.11.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13461:4853,depend,dependabot,4853,https://hail.is,https://github.com/hail-is/hail/pull/13461,11,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,".v13.5.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=rich&package-manager=pip&previous-version=12.6.0&new-version=13.5.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13575:8062,depend,dependabot,8062,https://hail.is,https://github.com/hail-is/hail/pull/13575,11,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,".v13.5.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=rich&package-manager=pip&previous-version=12.6.0&new-version=13.5.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13651:8200,depend,dependabot,8200,https://hail.is,https://github.com/hail-is/hail/pull/13651,22,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,".v3.18.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=zipp&package-manager=pip&previous-version=3.17.0&new-version=3.18.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14473:4139,depend,dependabot,4139,https://hail.is,https://github.com/hail-is/hail/pull/14473,11,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,".v3.9.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.9.1&new-version=3.9.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14219:7278,depend,dependabot,7278,https://hail.is,https://github.com/hail-is/hail/pull/14219,22,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"/ 2021-10-29</h2>; <p>[FEATURE] Exemplar support (excludes multiprocess) <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/669"">#669</a>; [ENHANCEMENT] Add support for Python 3.10 <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/706"">#706</a>; [ENHANCEMENT] Restricted Registry will handle metrics added after restricting <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/675"">#675</a>, <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/680"">#680</a><br />; [ENHANCEMENT] Raise a more helpful error if a metric is not observable <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/666"">#666</a>; [BUGFIX] Fix instance_ip_grouping_key not working on MacOS <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/687"">#687</a>; [BUGFIX] Fix assertion error from favicion.ico with Python 2.7 <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/715"">#715</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/prometheus/client_python/commit/a234283a853238dc73fa22651532590330fd72a1""><code>a234283</code></a> Release 0.13.1</li>; <li><a href=""https://github.com/prometheus/client_python/commit/557d123b349f3881cd6475a29ff4c79088a85a26""><code>557d123</code></a> Relax type constraints Timestamp</li>; <li><a href=""https://github.com/prometheus/client_python/commit/b44b63e59b168c6a8498ca31ddcce3ea5e46dcdc""><code>b44b63e</code></a> Declare <code>registry</code> on <code>MetricWrapperBase</code> as <code>Optional</code> (<a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/754"">#754</a>)</li>; <li><a href=""https://github.com/prometheus/client_python/commit/b3271a3f1842dbbddeab822063a3f08911f3c190""><code>b3271a3</code></a> Add missing functions/classes to <strong>all</strong> (<a href=""https://github-redirect.depen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11515:2873,depend,dependabot,2873,https://hail.is,https://github.com/hail-is/hail/pull/11515,1,['depend'],['dependabot']
Integrability,"/.conda/envs/hail/lib/python3.7/site-packages/hail/table.py in persist(self, storage_level); 1677 Persisted table.; 1678 """"""; -> 1679 return Env.backend().persist_table(self, storage_level); 1680 ; 1681 def unpersist(self) -> 'Table':. ~/.conda/envs/hail/lib/python3.7/site-packages/hail/backend/backend.py in persist_table(self, t, storage_level); 107 ; 108 def persist_table(self, t, storage_level):; --> 109 return Table._from_java(self._to_java_ir(t._tir).pyPersist(storage_level)); 110 ; 111 def unpersist_table(self, t):. ~/.conda/envs/hail/lib/python3.7/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. ~/.conda/envs/hail/lib/python3.7/site-packages/hail/utils/java.py in deco(*args, **kwargs); 213 import pyspark; 214 try:; --> 215 return f(*args, **kwargs); 216 except py4j.protocol.Py4JJavaError as e:; 217 s = e.java_exception.toString(). ~/.conda/envs/hail/lib/python3.7/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; --> 336 format(target_id, ""."", name)); 337 else:; 338 type = answer[1]. Py4JError: An error occurred while calling o51.pyPersist; ```. ```; (hail) -bash:uger-r7-c001:~ 1037 $ find /lib /lib64/ -regex '.*blas.*' -exec ls -al \{\} \;; lrwxrwxrwx. 1 root root 16 Dec 13 2017 /lib64/libblas.so.3.4 -> libblas.so.3.4.2; lrwxrwxrwx. 1 root root 16 Dec 13 2017 /lib64/libblas.so.3 -> libblas.so.3.4.2; lrwxrwxrwx. 1 root root 16 Dec 13 2017 /lib64/libblas.so -> libblas.so.3.4.2; -rwxr-xr-x. 1 root root 364808 Mar 2 2017 /lib64/libblas.so.3.4.2; ```. ```; (hail) -bash:uger-r7-c001:~ 1034 $ objdump -T /lib64/liblapack.so.3 | grep dgemm; 0000000000000000 DF *UND*	0000000000000000 dgemm_; (hail) -bash:uger-r7-c001:~ 1035 $ objdump -T /lib64/libb",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5559:4789,protocol,protocol,4789,https://hail.is,https://github.com/hail-is/hail/issues/5559,1,['protocol'],['protocol']
Integrability,"//github-redirect.dependabot.com/bartdag/py4j/issues/487"">#487</a>)</li>; <li><a href=""https://github.com/py4j/py4j/commit/1c622faa81e983f5ceface5290859d6a49974849""><code>1c622fa</code></a> Migrate nosetest to pytest (<a href=""https://github-redirect.dependabot.com/bartdag/py4j/issues/481"">#481</a>)</li>; <li><a href=""https://github.com/py4j/py4j/commit/64ba89c5a680218d682161a4a6d952a969d1299b""><code>64ba89c</code></a> Add explanations for releasing Py4J for eclipse. Convert .txt to .md (<a href=""https://github-redirect.dependabot.com/bartdag/py4j/issues/479"">#479</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/bartdag/py4j/compare/0.10.9...0.10.9.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=py4j&package-manager=pip&previous-version=0.10.9&new-version=0.10.9.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12298:2780,depend,dependabot-security-updates,2780,https://hail.is,https://github.com/hail-is/hail/pull/12298,1,['depend'],['dependabot-security-updates']
Integrability,"//github-redirect.dependabot.com/bokeh/bokeh/issues/11679"">#11679</a> [BUG] Parallel Plot example with output_backend=&quot;webgl&quot; not working</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11713"">#11713</a> [component: docs] Documentation builds are failing in CI</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11644"">#11644</a> [component: bokehjs] Actually fix clipping in SVG <code>&lt;text&gt;</code> nodes</li>; </ul>; </li>; <li>; <p>tasks:</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11617"">#11617</a> [component: docs] Update Team link in footer</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11658"">#11658</a> [component: build] Support &quot;pip install&quot; from sdist</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11618"">#11618</a> [component: tests] Reduce Tornado imports</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11628"">#11628</a> [component: docs] Correct path in dev guide server instructions</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11652"">#11652</a> [component: build] Update bokehjs' dependencies</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11668"">#11668</a> [component: docs] Add information about mathjax bundle</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11681"">#11681</a> [NO SQUASH] Batch of 3.0 -&gt; 2.4 backports</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11712"">#11712</a> [component: tests] Upgrade baselines to Chrome 94</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11722"">#11722</a> [component: tests] Update visual baselines on MacOS</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11724"">#11724</a> [NO SQUASH] More 3.0 -&gt; 2.4 backports</li>; </ul>; </li>; </ul>; <!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11540:5606,depend,dependabot,5606,https://hail.is,https://github.com/hail-is/hail/pull/11540,1,['depend'],['dependabot']
Integrability,"//github-redirect.dependabot.com/brettcannon/gidgethub/issues/180"">#180</a>)</li>; <li><a href=""https://github.com/brettcannon/gidgethub/commit/cf2cb85551a8aa36536dc828e830e13032e594d4""><code>cf2cb85</code></a> Bump min PyJWT v2.4.0 (<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/179"">#179</a>)</li>; <li><a href=""https://github.com/brettcannon/gidgethub/commit/9096d1b79447a3ef81b331457ea39c43f43e2f2d""><code>9096d1b</code></a> Release v5.1.0 (<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/175"">#175</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/brettcannon/gidgethub/compare/v4.2.0...v5.2.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=gidgethub&package-manager=pip&previous-version=4.2.0&new-version=5.2.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12328:9666,depend,dependabot-security-updates,9666,https://hail.is,https://github.com/hail-is/hail/pull/12328,1,['depend'],['dependabot-security-updates']
Integrability,"//github-redirect.dependabot.com/follow-redirects/follow-redirects/issues/172"">#172</a>)</li>; <li><a href=""https://github.com/follow-redirects/follow-redirects/commit/77e2a581e1d1811674b7b74745a9c20a5b939488""><code>77e2a58</code></a> Release version 1.14.4 of the npm package.</li>; <li>Additional commits viewable in <a href=""https://github.com/follow-redirects/follow-redirects/compare/v1.14.1...v1.14.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=follow-redirects&package-manager=npm_and_yarn&previous-version=1.14.1&new-version=1.14.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11283:2815,depend,dependabot-automerge-start,2815,https://hail.is,https://github.com/hail-is/hail/pull/11283,4,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"//github-redirect.dependabot.com/giampaolo/psutil/issues/2033"">#2033</a>)</li>; <li><a href=""https://github.com/giampaolo/psutil/commit/b490b5d51af6ed29709c357a00fcdb6bda26df78""><code>b490b5d</code></a> fix missing arg passed to C psutil_debug()</li>; <li><a href=""https://github.com/giampaolo/psutil/commit/eb2f74c153987b4e0d03aa16931d97e8137d9257""><code>eb2f74c</code></a> Fix CI tests / wheels / workflow (<a href=""https://github-redirect.dependabot.com/giampaolo/psutil/issues/2024"">#2024</a>)</li>; <li><a href=""https://github.com/giampaolo/psutil/commit/a1ae994cabff37eb86c6ca4564b4f193a73a7b0d""><code>a1ae994</code></a> fix <a href=""https://github-redirect.dependabot.com/giampaolo/psutil/issues/2023"">#2023</a> [Linux] cpu_freq() return order is wrong on systems with &gt; 9 CPUs.</li>; <li><a href=""https://github.com/giampaolo/psutil/commit/875d2195fc8efa642c7bca714d468551d1805c6c""><code>875d219</code></a> Handle missing dependencies on MidnightBSD (<a href=""https://github-redirect.dependabot.com/giampaolo/psutil/issues/2019"">#2019</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/giampaolo/psutil/compare/release-5.8.0...release-5.9.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=psutil&package-manager=pip&previous-version=5.8.0&new-version=5.9.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11459:6007,depend,dependabot,6007,https://hail.is,https://github.com/hail-is/hail/pull/11459,1,['depend'],['dependabot']
Integrability,"//github-redirect.dependabot.com/googleapis/python-cloud-core/issues/178"">#178</a>) (<a href=""https://github.com/googleapis/python-cloud-core/commit/c65ad44df0b058120aea0686eddeaffbe9bbdda7"">c65ad44</a>)</li>; <li><strong>deps:</strong> require google-auth 1.25.0 (<a href=""https://github.com/googleapis/python-cloud-core/commit/c65ad44df0b058120aea0686eddeaffbe9bbdda7"">c65ad44</a>)</li>; </ul>; <h2>v2.2.2</h2>; <h3><a href=""https://github.com/googleapis/python-cloud-core/compare/v2.2.1...v2.2.2"">2.2.2</a> (2022-01-17)</h3>; <h3>Bug Fixes</h3>; <ul>; <li>correct param type of _ClientFactoryMixin.from_service_account_info method (<a href=""https://github-redirect.dependabot.com/googleapis/python-cloud-core/issues/161"">#161</a>) (<a href=""https://github.com/googleapis/python-cloud-core/commit/24b7de49943a49e8235f9dbee6b32693deed8c1f"">24b7de4</a>)</li>; </ul>; <h2>v2.2.1</h2>; <h3>Bug Fixes</h3>; <ul>; <li>correct Client and Connection type annotations (<a href=""https://github-redirect.dependabot.com/googleapis/python-cloud-core/issues/156"">#156</a>) (<a href=""https://www.github.com/googleapis/python-cloud-core/commit/a427681913ab76379e007a8c3ae519b41e8cee62"">a427681</a>)</li>; </ul>; <h2>v2.2.0</h2>; <h3>Features</h3>; <ul>; <li>add mypy checking + 'py.typed' files (<a href=""https://github-redirect.dependabot.com/googleapis/python-cloud-core/issues/149"">#149</a>) (<a href=""https://www.github.com/googleapis/python-cloud-core/commit/f20ef60abaff13520d2e7b9719741746bd0d1c7b"">f20ef60</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/python-cloud-core/blob/main/CHANGELOG.md"">google-cloud-core's changelog</a>.</em></p>; <blockquote>; <h2><a href=""https://github.com/googleapis/python-cloud-core/compare/v2.3.1...v2.3.2"">2.3.2</a> (2022-07-15)</h2>; <h3>Bug Fixes</h3>; <ul>; <li>require python 3.7+ (<a href=""https://github-redirect.depen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12175:2827,depend,dependabot,2827,https://hail.is,https://github.com/hail-is/hail/pull/12175,1,['depend'],['dependabot']
Integrability,"//github-redirect.dependabot.com/pre-commit/pre-commit/issues/2181"">#2181</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>always use <code>#!/bin/sh</code> on windows for hook script.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2182"">#2182</a> issue by <a href=""https://github.com/hushigome-visco""><code>@​hushigome-visco</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2187"">#2187</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; </ul>; <h1>2.16.0 - 2021-11-30</h1>; <h3>Features</h3>; <ul>; <li>add warning for regexes containing <code>[\/]</code> or <code>[/\\]</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2053"">#2053</a> PR by <a href=""https://github.com/radek-sprta""><code>@​radek-sprta</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2043"">#2043</a> issue by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>move hook template back to <code>bash</code> resolving shebang-portability issues.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2065"">#2065</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>add support for <code>fail_fast</code> at the individual hook level.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2097"">#2097</a> PR by <a href=""https://github.com/colens3""><code>@​colens3</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/1143"">#1143</a> issue by <a href=""https://github.com/potiuk""><code>@​potiuk</code></a>.</li>; </ul>; </li>; <li>allow passthrough of <code>GIT_CONFIG_KEY_*</code>, <code>GIT_CONFIG_VALUE_*</code>, and; <code>GIT_CONFIG_COUNT</code>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11460:10812,depend,dependabot,10812,https://hail.is,https://github.com/hail-is/hail/pull/11460,2,['depend'],['dependabot']
Integrability,"//github-redirect.dependabot.com/psf/requests/issues/5239"">#5239</a>)</p>; </li>; <li>; <p>Fixed urllib3 exception leak, wrapping <code>urllib3.exceptions.InvalidHeader</code> with; <code>requests.exceptions.InvalidHeader</code>. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5914"">#5914</a>)</p>; </li>; <li>; <p>Fixed bug where two Host headers were sent for chunked requests. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5391"">#5391</a>)</p>; </li>; <li>; <p>Fixed regression in Requests 2.26.0 where <code>Proxy-Authorization</code> was; incorrectly stripped from all requests sent with <code>Session.send</code>. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5924"">#5924</a>)</p>; </li>; <li>; <p>Fixed performance regression in 2.26.0 for hosts with a large number of; proxies available in the environment. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5924"">#5924</a>)</p>; </li>; <li>; <p>Fixed idna exception leak, wrapping <code>UnicodeError</code> with; <code>requests.exceptions.InvalidURL</code> for URLs with a leading dot (.) in the; domain. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5414"">#5414</a>)</p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/psf/requests/commit/31a89d9c8463c3394ca00f408f4b86d814421a09""><code>31a89d9</code></a> v2.27.1</li>; <li><a href=""https://github.com/psf/requests/commit/8fa9724398c4f44090997ff430a1dd3e935a9057""><code>8fa9724</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/psf/requests/issues/6028"">#6028</a> from nateprewitt/prox_auth_fix</li>; <li><a href=""https://github.com/psf/requests/commit/38f3f8ecb93cadfac03a6b7b3173018ac829d0cf""><code>38f3f8e</code></a> Fix auth parsing for proxies</li>; <li><a href=""https://github.com/psf/requests/commit/0192aac24123735b3eaf9b08d",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11528:6473,wrap,wrapping,6473,https://hail.is,https://github.com/hail-is/hail/pull/11528,2,['wrap'],['wrapping']
Integrability,"//github-redirect.dependabot.com/samtools/htsjdk/issues/1616"">#1616</a>); d15a5bacb Added ULTIMA and ELEMENT as valid value for RG-PL according to SAM spec. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1619"">#1619</a>)</p>; <h2>3.0.0</h2>; <p>Htsjdk 3.0.0: Revenge of the Simple Allele</p>; <p>This is the first htsjdk with a major version increase in a long time. We bumped it to indicate there are some breaking changes that will potentially require downstream code changes. Notably, <code>Allele</code> became an interface instead of a concrete class. <code>SimpleAllele</code> may be used as a replacement if you have classes which previously subclassed allele.</p>; <p>New Plugin Infrastructure:; 6a60de7c2 Move API marker annotations into new annotation package. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1558"">#1558</a>); 7ac95d5f7 Plugin framework and interfaces for versioned file format codecs (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1525"">#1525</a>); d40fe5412 Beta implementation of Bundles. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1546"">#1546</a>)</p>; <p>CRAM; 489c4192d Support CRAM reference regions. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1605"">#1605</a>); 22aec6782 Fix decoding of CRAM Scores read feature during normalization. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1592"">#1592</a>); 6507249a4 Make the CRAM MD5 failure message more user friendly. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1607"">#1607</a>); b5af659e6 Fix restoration of read base feature code. <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1379"">#1379</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1590"">#1590</a>); e63c34a92 Ignore TC, TN on CRAM read (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1578"">#1578</a>)<",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12229:1896,depend,dependabot,1896,https://hail.is,https://github.com/hail-is/hail/pull/12229,2,['depend'],['dependabot']
Integrability,"//github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10539"">#10539</a>)</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/3956cf2249d27ed63e8381c07dfde36f6c96f78f""><code>3956cf2</code></a> Fix documenting inherited attributes</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/27f05328d0369ad0db85c27935d52fdadf020f6b""><code>27f0532</code></a> Move <code>aside.topic</code> into the conditional blocks</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/5806f0af2788db40661d62e5e88c2c1560ae46b6""><code>5806f0a</code></a> Add <code>nav.contents</code> everywhere that <code>div.topic</code> is used</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/8da2efb1d71ab2d384ddc90cf4fdebe5d18e91cd""><code>8da2efb</code></a> Rename CSS files to CSS template files</li>; <li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v3.5.4...v5.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx&package-manager=pip&previous-version=3.5.4&new-version=5.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` wil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11925:6302,Depend,Dependabot,6302,https://hail.is,https://github.com/hail-is/hail/pull/11925,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"//github.com/Infinisil</a>) contributed a patch to; some doctests that were breaking on NixOS.; John Vandenberg (<a href=""https://github.com/jayvdb"">https://github.com/jayvdb</a>) made a case for removing the usage</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/micheles/decorator/commits/5.1.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=decorator&package-manager=pip&previous-version=4.4.0&new-version=5.1.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11799:3237,depend,dependabot-automerge-start,3237,https://hail.is,https://github.com/hail-is/hail/pull/11799,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"//github.com/aio-libs/aiohttp-session/commit/36b8a0a5ed2caaaba9d5d3ece8aaf03ca45b6c34""><code>36b8a0a</code></a> Allow passing Fernet to Encrypted Cookie Storage (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/448"">#448</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/984decc496fe92e053c14949c8d3a60bacd62426""><code>984decc</code></a> Test on Python up to 3.10 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/634"">#634</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/936f76351450066903002d60286110007310a44f""><code>936f763</code></a> Bump aiomcache from 0.6.0 to 0.7.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/665"">#665</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/29ddff39290f4e2fbc7b9feb94eb622763e156e2""><code>29ddff3</code></a> Bump pytest-aiohttp from 0.3.0 to 1.0.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/668"">#668</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/3bc517092aff39330f2f96315e6f542e23415831""><code>3bc5170</code></a> Bump multidict from 5.2.0 to 6.0.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/670"">#670</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp_session/compare/v2.7.0...v2.11.0"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11577:4909,depend,dependabot,4909,https://hail.is,https://github.com/hail-is/hail/pull/11577,1,['depend'],['dependabot']
Integrability,"//github.com/aio-libs/aiohttp-session/commit/36b8a0a5ed2caaaba9d5d3ece8aaf03ca45b6c34""><code>36b8a0a</code></a> Allow passing Fernet to Encrypted Cookie Storage (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/448"">#448</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/984decc496fe92e053c14949c8d3a60bacd62426""><code>984decc</code></a> Test on Python up to 3.10 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/634"">#634</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/936f76351450066903002d60286110007310a44f""><code>936f763</code></a> Bump aiomcache from 0.6.0 to 0.7.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/665"">#665</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/29ddff39290f4e2fbc7b9feb94eb622763e156e2""><code>29ddff3</code></a> Bump pytest-aiohttp from 0.3.0 to 1.0.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/668"">#668</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/3bc517092aff39330f2f96315e6f542e23415831""><code>3bc5170</code></a> Bump multidict from 5.2.0 to 6.0.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/670"">#670</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp_session/compare/v2.7.0...v2.11.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp-session&package-manager=pip&previous-version=2.7.0&new-version=2.11.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11544:3923,depend,dependabot,3923,https://hail.is,https://github.com/hail-is/hail/pull/11544,1,['depend'],['dependabot']
Integrability,"//github.com/anatolyuzhakov""><code>@​anatolyuzhakov</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2793"">cbeust/testng#2793</a></li>; <li>Fix issue 2801 - Only resolve hostname once by <a href=""https://github.com/spkrka""><code>@​spkrka</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2802"">cbeust/testng#2802</a></li>; <li>[SECURITY] Fix Zip Slip Vulnerability; by <a href=""https://github.com/JLLeitschuh""><code>@​JLLeitschuh</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2806"">cbeust/testng#2806</a></li>; <li>GITHUB-2807 - Failsafe buildStackTrace by <a href=""https://github.com/seregamorph""><code>@​seregamorph</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2808"">cbeust/testng#2808</a></li>; <li>Prevent overlogging of debug msgs in Graph impl by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2813"">cbeust/testng#2813</a></li>; <li>Streamline dataprovider invoking in abstract classes by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2814"">cbeust/testng#2814</a></li>; <li>Streamline TestResult due to expectedExceptions by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2815"">cbeust/testng#2815</a></li>; <li>Unexpected test runs count with retry analyzer by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2816"">cbeust/testng#2816</a></li>; <li>Make PackageUtils compliant with JPMS by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2817"">cbeust/testng#2817</a></li>; <li>Ability to ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:2295,depend,dependabot,2295,https://hail.is,https://github.com/hail-is/hail/pull/12665,1,['depend'],['dependabot']
Integrability,"//github.com/apache/commons-codec/commit/f39003c953df152ff737474d2d2f27b611963a1c""><code>f39003c</code></a> Test isInAlphabet</li>; <li><a href=""https://github.com/apache/commons-codec/commit/9ac33a12a500bbc3ea40685aac61c95169443957""><code>9ac33a1</code></a> Test all constructors</li>; <li><a href=""https://github.com/apache/commons-codec/commit/3535c17eccb2251fc518aa545a800b4922c8dc35""><code>3535c17</code></a> Test encode of null and empty array with an offset</li>; <li><a href=""https://github.com/apache/commons-codec/commit/e42dfe1ff2f273926fd759abea82b1c7b3021985""><code>e42dfe1</code></a> Fix test names</li>; <li><a href=""https://github.com/apache/commons-codec/commit/536587931cb77538709c57455165379a74e2f04f""><code>5365879</code></a> Test the codec policy property</li>; <li>Additional commits viewable in <a href=""https://github.com/apache/commons-codec/compare/commons-codec-1.11...rel/commons-codec-1.15"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=commons-codec:commons-codec&package-manager=gradle&previous-version=1.11&new-version=1.15)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@depend",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12385:4690,Depend,Dependabot,4690,https://hail.is,https://github.com/hail-is/hail/pull/12385,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"//github.com/boto/botocore/commit/a7e153d9c822fae5c55d30ef476bdf4f55a4d027""><code>a7e153d</code></a> Merge branch 'release-1.29.15'</li>; <li><a href=""https://github.com/boto/botocore/commit/a942b57854dd35a37766d7973c3fb980a2de4068""><code>a942b57</code></a> Merge branch 'release-1.29.15' into develop</li>; <li><a href=""https://github.com/boto/botocore/commit/4d972ecc0b008bc6e8d9dbacc285524a5fa82e3f""><code>4d972ec</code></a> Bumping version to 1.29.15</li>; <li><a href=""https://github.com/boto/botocore/commit/4e5ec200284b1bbce09a973de61de159888dd657""><code>4e5ec20</code></a> Update to latest partitions and endpoints</li>; <li><a href=""https://github.com/boto/botocore/commit/238d938b4f519a5efce58403848fd480cf99d331""><code>238d938</code></a> Update to latest models</li>; <li><a href=""https://github.com/boto/botocore/commit/7b4b3bbb13a5d59097e6d5f178de58e280fdb553""><code>7b4b3bb</code></a> Resolve endpoint with default partition when no region is set (<a href=""https://github-redirect.dependabot.com/boto/botocore/issues/2818"">#2818</a>)</li>; <li><a href=""https://github.com/boto/botocore/commit/cc3f1c22f55ba50ca792eb73e7a6f721abdcc5ee""><code>cc3f1c2</code></a> Fix: S3 Object Lambda requests miss x-amz-content-sha256 headers (<a href=""https://github-redirect.dependabot.com/boto/botocore/issues/2819"">#2819</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/boto/botocore/compare/1.29.13...1.29.16"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=botocore&package-manager=pip&previous-version=1.29.13&new-version=1.29.16)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-auto",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12503:3111,depend,dependabot,3111,https://hail.is,https://github.com/hail-is/hail/pull/12503,1,['depend'],['dependabot']
Integrability,"//github.com/hynek/prometheus-async/commit/02b12bebcaa97574f0e202057c0658c5137a4324""><code>02b12be</code></a> Ignore compare URLs</li>; <li><a href=""https://github.com/hynek/prometheus-async/commit/f3c9d75160cb75cd8b4ddd2353b06f37bde0555e""><code>f3c9d75</code></a> Use proper way to determine package version</li>; <li><a href=""https://github.com/hynek/prometheus-async/commit/8af33182b5a0f8e2b6a5735cffff3b1f973e25d2""><code>8af3318</code></a> Block github from linkcheck</li>; <li><a href=""https://github.com/hynek/prometheus-async/commit/356ab35846a8a408b75c37697261238d3660382a""><code>356ab35</code></a> Remove stray whitespace</li>; <li><a href=""https://github.com/hynek/prometheus-async/commit/fc873f4b4351b6428375eb35e8dc1d471f4185a3""><code>fc873f4</code></a> Port changelog to Keep a Changelog</li>; <li><a href=""https://github.com/hynek/prometheus-async/commit/c021ce58432b27ac9035fc53c23273bff6ea4f70""><code>c021ce5</code></a> Port from rST to md/MyST (<a href=""https://github-redirect.dependabot.com/hynek/prometheus-async/issues/27"">#27</a>)</li>; <li><a href=""https://github.com/hynek/prometheus-async/commit/36bfe3f427c4206828d2d99f5aeefac2ec8d8226""><code>36bfe3f</code></a> count_exceptions only needs an Incrementer</li>; <li><a href=""https://github.com/hynek/prometheus-async/commit/82766062e8d64b56999d150dd2b4f60d4b6dd33d""><code>8276606</code></a> Expand regression test to signatures</li>; <li>Additional commits viewable in <a href=""https://github.com/hynek/prometheus-async/compare/19.2.0...22.1.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=prometheus-async&package-manager=pip&previous-version=19.2.0&new-version=22.1.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11536:3604,depend,dependabot,3604,https://hail.is,https://github.com/hail-is/hail/pull/11536,1,['depend'],['dependabot']
Integrability,"//github.com/ipython/ipython/commit/1b5674ca8bbac62daa42eb460848173c0542cf2e""><code>1b5674c</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/ipython/ipython/issues/13778"">#13778</a> from zhizheng1/fix-mpl-webagg</li>; <li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/7.34.0...8.6.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ipython&package-manager=pip&previous-version=7.34.0&new-version=8.6.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12442:2812,Depend,Dependabot,2812,https://hail.is,https://github.com/hail-is/hail/pull/12442,1,['Depend'],['Dependabot']
Integrability,"//github.com/jalessio""><code>@​jalessio</code></a>.</li>; </ul>; </li>; <li>allow <code>language: conda</code> to use <code>mamba</code> or <code>micromamba</code> via <code>PRE_COMMIT_USE_MAMBA=1</code> or <code>PRE_COMMIT_USE_MICROMAMBA=1</code> respectively.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2204"">#2204</a> issue by <a href=""https://github.com/janjagusch""><code>@​janjagusch</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2207"">#2207</a> PR by <a href=""https://github.com/xhochy""><code>@​xhochy</code></a>.</li>; </ul>; </li>; <li>display <code>git --version</code> in error report.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2210"">#2210</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>add <code>language: lua</code> as a supported language.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2158"">#2158</a> PR by <a href=""https://github.com/mblayman""><code>@​mblayman</code></a>.</li>; </ul>; </li>; </ul>; <h3>Fixes</h3>; <ul>; <li>temporarily add <code>setuptools</code> to the zipapp.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2122"">#2122</a> issue by <a href=""https://github.com/andreoliwa""><code>@​andreoliwa</code></a>.</li>; <li>a737d5f commit by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>use <code>go install</code> instead of <code>go get</code> for go 1.18+ support.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2161"">#2161</a> PR by <a href=""https://github.com/schmir""><code>@​schmir</code></a>.</li>; </ul>; </li>; <li>fix <code>language: r</code> with a local renv and <code>RENV_PROJECT</code> set.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2170"">#2170</a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11460:1913,depend,dependabot,1913,https://hail.is,https://github.com/hail-is/hail/pull/11460,2,['depend'],['dependabot']
Integrability,"//github.com/pandas-dev/pandas/commit/27fd6c6c5141c5946470f4810858eb903491d651""><code>27fd6c6</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48285"">#48285</a> on branch 1.5.x (WEB: Unpin pydata sphinx theme) (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48585"">#48585</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/9e8d859f46abe33896ed9df8d82587f915cc2529""><code>9e8d859</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48557"">#48557</a> on branch 1.5.x (WEB: Add new footer to web) (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48571"">#48571</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.5...v1.5.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pandas&package-manager=pip&previous-version=1.3.5&new-version=1.5.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12292:5997,depend,dependency-name,5997,https://hail.is,https://github.com/hail-is/hail/pull/12292,1,['depend'],['dependency-name']
Integrability,"//github.com/python/typing_extensions/commit/7198c63522f3f435f8610c88ed0f5d0cf9d26091""><code>7198c63</code></a> Add <code>.gitignore</code>, <code>.editorconfig</code>, <code>CONTRIBUTING.md</code> (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/43"">#43</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/abe4390fe2456c6052c868731eb4b225b5a2f529""><code>abe4390</code></a> dataclass_transform will be in 3.11 (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/42"">#42</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/e9d09b5bb998693c3565a276a27f424b327b0f7b""><code>e9d09b5</code></a> Remove obsolete README.rst (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/41"">#41</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/447b62c4816efbd85727a12191a310bac5c416cc""><code>447b62c</code></a> fix CI (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/4"">#4</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/47600f62c354ca028c29762fa6ff0b007716ef88""><code>47600f6</code></a> update links (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/3"">#3</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/bc9317ef90a629f27f1ab706bfce99da873044b4""><code>bc9317e</code></a> Change home URL to tree instead of README (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/1157"">#1157</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/c10296f15f92277ed1d3ed0c83103ae3818d3669""><code>c10296f</code></a> Add a README.rst file back temporarily. (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/1156"">#1156</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/python/typing_extensions/compare/4.2.0...4.3.0"">compare view</a></li>; </ul>; </detai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12200:2953,depend,dependabot,2953,https://hail.is,https://github.com/hail-is/hail/pull/12200,1,['depend'],['dependabot']
Integrability,"//github.com/rekyungmin""><code>@​rekyungmin</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/705"">jpadilla/pyjwt#705</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/708"">jpadilla/pyjwt#708</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/710"">jpadilla/pyjwt#710</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/711"">jpadilla/pyjwt#711</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/712"">jpadilla/pyjwt#712</a></li>; <li>documentation fix: show correct scope for decode_complete() by <a href=""https://github.com/sseering""><code>@​sseering</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/661"">jpadilla/pyjwt#661</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/716"">jpadilla/pyjwt#716</a></li>; <li>Explicit check the key for ECAlgorithm by <a href=""https://github.com/estin""><code>@​estin</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/713"">jpadilla/pyjwt#713</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/720"">jpadilla/pyjwt#720</a></li>; <li>api_jwk: Add PyJWKSet.<strong>ge",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11866:1817,depend,dependabot,1817,https://hail.is,https://github.com/hail-is/hail/pull/11866,1,['depend'],['dependabot']
Integrability,"//github.com/sveltejs/svelte/commit/0fa0a38d5168a1767843fdb0a43c00aa30b8670f""><code>0fa0a38</code></a> [fix] export CompileOptions (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7658"">#7658</a>)</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/a3ecb44b5346dbf116c5bec5dcf47cd7f459784d""><code>a3ecb44</code></a> update changelog</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/7e1691cd62df0593882480d00eb7e9a7616bb029""><code>7e1691c</code></a> [fix] support <a href=""https://github.com/layer""><code>@​layer</code></a> (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7514"">#7514</a>)</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/4583b170842208bcafcbb095221c8ac12689f739""><code>4583b17</code></a> Update CHANGELOG.md</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/02f60fbebf7cdb036472d1aec8dc9d9f8215cd7a""><code>02f60fb</code></a> [fix]destroy empty component (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7492"">#7492</a>)</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/31e5f8b5de24e2e058cb1a70467c0092e422ee5d""><code>31e5f8b</code></a> [docs] &quot;What's new in Svelte&quot; July newsletter (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7637"">#7637</a>)</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/6f575715073f4a1eb1abdd7a2d22a75ae6017cf7""><code>6f57571</code></a> [feat] add convenience types ComponentType and ComponentProps (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/6770"">#6770</a>)</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/2f562d9e2817d911d0eec437d2b0e45074ec8291""><code>2f562d9</code></a> [docs] use npm create instead of npm init (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7641"">#7641</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/sveltejs/svelte/compare/v3.38.2...v3.49.0"">compare view</a></li>; </ul>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12032:7601,depend,dependabot,7601,https://hail.is,https://github.com/hail-is/hail/pull/12032,3,['depend'],['dependabot']
Integrability,"//jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-2"">https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-2</a></li>; <li>Milestone: <a href=""https://github.com/pallets/jinja/milestone/13?closed=1"">https://github.com/pallets/jinja/milestone/13?closed=1</a></li>; </ul>; <h2>3.1.1</h2>; <ul>; <li>Changes: <a href=""https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-1"">https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-1</a></li>; <li>Milestone: <a href=""https://github.com/pallets/jinja/milestone/12?closed=1"">https://github.com/pallets/jinja/milestone/12?closed=1</a></li>; </ul>; <h2>3.1.0</h2>; <p>This is a feature release, which includes new features and removes previously deprecated features. The 3.1.x branch is now the supported bugfix branch, the 3.0.x branch has become a tag marking the end of support for that branch. We encourage everyone to upgrade, and to use a tool such as <a href=""https://pypi.org/project/pip-tools/"">pip-tools</a> to pin all dependencies and control upgrades. We also encourage upgrading to MarkupSafe 2.1.1, the latest version at this time.</p>; <ul>; <li>Changes: <a href=""https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-0"">https://jinja.palletsprojects.com/en/3.1.x/changes/#version-3-1-0</a></li>; <li>Milestone: <a href=""https://github.com/pallets/jinja/milestone/8?closed=1"">https://github.com/pallets/jinja/milestone/8?closed=1</a></li>; <li>MarkupSafe changes: <a href=""https://markupsafe.palletsprojects.com/en/2.1.x/changes/#version-2-1-1"">https://markupsafe.palletsprojects.com/en/2.1.x/changes/#version-2-1-1</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/jinja/blob/main/CHANGES.rst"">jinja2's changelog</a>.</em></p>; <blockquote>; <h2>Version 3.1.2</h2>; <p>Released 2022-04-28</p>; <ul>; <li>Add parameters to <code>Environment.overlay</code> to match <code>__init__</code>.; :issue:<code>1645",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12173:1420,depend,dependencies,1420,https://hail.is,https://github.com/hail-is/hail/pull/12173,1,['depend'],['dependencies']
Integrability,"//redirect.github.com/jaraco/zipp/issues/106"">#106</a>.</li>; <li><a href=""https://github.com/jaraco/zipp/commit/4cceb497c278ad0ecb11a9472e58f4130f5ff16b""><code>4cceb49</code></a> Add special accounting for pypy when computing the stack level for text encod...</li>; <li><a href=""https://github.com/jaraco/zipp/commit/2ec3ed8567d0842675c38fd8ef0a28db668e602d""><code>2ec3ed8</code></a> Add another test at another magnitude.</li>; <li><a href=""https://github.com/jaraco/zipp/commit/d9bf5aab8b39c6a124d9499ae0315d3bf2ac2f46""><code>d9bf5aa</code></a> Fix name generator for width=1</li>; <li>Additional commits viewable in <a href=""https://github.com/jaraco/zipp/compare/v3.17.0...v3.18.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=zipp&package-manager=pip&previous-version=3.17.0&new-version=3.18.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14473:3114,depend,dependabot-security-updates,3114,https://hail.is,https://github.com/hail-is/hail/pull/14473,1,['depend'],['dependabot-security-updates']
Integrability,"//www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.2.html</a></p>; <h2>Elasticsearch Hadoop 8.5.1</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/e665cd918aa8d0ba7806b92e16881edb96180d48""><code>e665cd9</code></a> Update Spark to 3.2.3 (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2056"">#2056</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2057"">#2057</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/07380b0e17c7d908d50d59fc69ac2953adfa5a0d""><code>07380b0</code></a> Use DRA repository for build-tools dependencies</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/77bce30bfefb39c39bd34a6f147b17fb0df4701c""><code>77bce30</code></a> Bump to version 8.6.1</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/92ac2d5e61b7b8cc16b6a9f29ad1454497f604ba""><code>92ac2d5</code></a> [DOCS] Add 8.6.0 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2053"">#2053</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2054"">#2054</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/da4f3c3f209aea47d69c4faf90029a6933",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12623:2526,depend,dependabot,2526,https://hail.is,https://github.com/hail-is/hail/pull/12623,1,['depend'],['dependabot']
Integrability,"//www.sphinx-doc.org/en/master/changes.html</a></p>; <h2>v4.3.1</h2>; <p>No release notes provided.</p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/sphinx-doc/sphinx/blob/5.x/CHANGES"">sphinx's changelog</a>.</em></p>; <blockquote>; <h1>Release 5.0.1 (released Jun 03, 2022)</h1>; <h2>Bugs fixed</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10498"">#10498</a>: gettext: TypeError is raised when sorting warning messages if a node; has no line number</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10493"">#10493</a>: html theme: :rst:dir:<code>topic</code> directive is rendered incorrectly with; docutils-0.18</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10495"">#10495</a>: IndexError is raised for a :rst:role:<code>kbd</code> role having a separator</li>; </ul>; <h1>Release 5.0.0 (released May 30, 2022)</h1>; <h2>Dependencies</h2>; <p>5.0.0 b1</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10164"">#10164</a>: Support <code>Docutils 0.18</code>_. Patch by Adam Turner.</li>; </ul>; <p>.. _Docutils 0.18: <a href=""https://docutils.sourceforge.io/RELEASE-NOTES.html#release-0-18-2021-10-26"">https://docutils.sourceforge.io/RELEASE-NOTES.html#release-0-18-2021-10-26</a></p>; <h2>Incompatible changes</h2>; <p>5.0.0 b1</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10031"">#10031</a>: autosummary: <code>sphinx.ext.autosummary.import_by_name()</code> now raises; <code>ImportExceptionGroup</code> instead of <code>ImportError</code> when it failed to import; target object. Please handle the exception if your extension uses the; function to import Python object. As a workaround, you can disable the; behavior via <code>grouped_exception=False</code> keyword argument until v7.0.</li>; <li><a href=""https://github-redirect.depe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11885:1798,Depend,Dependencies,1798,https://hail.is,https://github.com/hail-is/hail/pull/11885,1,['Depend'],['Dependencies']
Integrability,"/10.1.0...10.2.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pillow&package-manager=pip&previous-version=10.1.0&new-version=10.2.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14191:15910,Depend,Dependabot,15910,https://hail.is,https://github.com/hail-is/hail/pull/14191,27,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"/10.2.0...10.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pillow&package-manager=pip&previous-version=10.2.0&new-version=10.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14439:15886,Depend,Dependabot,15886,https://hail.is,https://github.com/hail-is/hail/pull/14439,27,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"/135"">#135</a> from arthurzam/master</li>; <li><a href=""https://github.com/micheles/decorator/commit/a3a8c1d573cc4abc4c05c2b6ccbaa6ba0153b909""><code>a3a8c1d</code></a> setup.cfg: Replace dashes with underscores</li>; <li><a href=""https://github.com/micheles/decorator/commit/d37eebca8c7b094d65c696aec6bc89a9df50324f""><code>d37eebc</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/micheles/decorator/issues/134"">#134</a> from hugovk/master</li>; <li><a href=""https://github.com/micheles/decorator/commit/7002507b86f90a79777d65129e39c4cce96587e2""><code>7002507</code></a> Add support for Python 3.10</li>; <li>Additional commits viewable in <a href=""https://github.com/micheles/decorator/compare/decorator-3.4.0...5.1.1"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11490:4937,depend,dependabot-automerge-start,4937,https://hail.is,https://github.com/hail-is/hail/pull/11490,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"/13989"">#13989</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/92027083ab69186db3f104fe38651086bcf4e760""><code>9202708</code></a> Handle OSError cases where traceback frames occur from built files (<a href=""https://redirect.github.com/ipython/ipython/issues/13964"">#13964</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/fc872d6cfab48d861c43c766d583edde73370836""><code>fc872d6</code></a> Allow to dispatch getting documentation on objects</li>; <li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/7.34.0...8.12.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ipython&package-manager=pip&previous-version=7.34.0&new-version=8.12.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12832:2906,Depend,Dependabot,2906,https://hail.is,https://github.com/hail-is/hail/pull/12832,2,['Depend'],['Dependabot']
Integrability,"/1593"">#1593</a>)</li>; <li>See full diff in <a href=""https://github.com/samtools/htsjdk/compare/3.0.2...3.0.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.github.samtools:htsjdk&package-manager=gradle&previous-version=3.0.2&new-version=3.0.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12700:3807,Depend,Dependabot,3807,https://hail.is,https://github.com/hail-is/hail/pull/12700,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"/175"">#175</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/brettcannon/gidgethub/compare/v4.2.0...v5.2.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=gidgethub&package-manager=pip&previous-version=4.2.0&new-version=5.2.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12328:10055,Depend,Dependabot,10055,https://hail.is,https://github.com/hail-is/hail/pull/12328,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"/1804"">#1804</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/3ab745207badbd4971f2fb62ed92e1703625214a""><code>3ab7452</code></a> chore(test): increase debug logging for failure cases in GapicUnbufferedWrita...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/c8bf3c70cca81ed87a52939fe7da58889c8f55ce""><code>c8bf3c7</code></a> fix: update GrpcStorageImpl#update to support fine-grained update of BucketIn...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/3345ac9eec286ee3108c08bdbe263eba59085ad3""><code>3345ac9</code></a> test: add test to verify <code>lifecycle.rule.condition.age_days = 0</code> (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1846"">#1846</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/45dc983a4af8e7feb937263ce611bd34eda37e03""><code>45dc983</code></a> feat: update GrpcBlobReadChannel to allow seek/limit after read (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1834"">#1834</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/b8f43169a504080c55eadc3428d0d7966efdc3d4""><code>b8f4316</code></a> build(deps): update dependency org.apache.maven.plugins:maven-dependency-plug...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/e532a590fd351bb2020b571d21662fbee629038e""><code>e532a59</code></a> build(deps): update dependency org.apache.maven.plugins:maven-surefire-plugin...</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/java-storage/compare/v1.106.0...v2.17.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.cloud:google-cloud-storage&package-manager=gradle&previous-version=1.106.0&new-version=2.17.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12598:15516,depend,dependabot,15516,https://hail.is,https://github.com/hail-is/hail/pull/12598,1,['depend'],['dependabot']
Integrability,"/1b1b22e999541e8ce7ac3147eb468e0cde6c157a""><code>1b1b22e</code></a> Patch Release 11/15/2022 (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32171"">#32171</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/68d7b8992d77ad00cdd985bfd764b81f42085fe3""><code>68d7b89</code></a> Eagerly Convert Headers Always in Download (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32173"">#32173</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/c10e612d913b03f044ddd58aa591850615b61ecd""><code>c10e612</code></a> Sync eng/common directory with azure-sdk-tools for PR 4701 (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32168"">#32168</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/44682b71c0216aae1530af287e745803feeec2fc""><code>44682b7</code></a> Regenerate Storage Blobs with Fix for Download to File (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32163"">#32163</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/11f065d4d592d14977d178ddd58f6a6ec6b16276""><code>11f065d</code></a> Increment package versions for keyvault releases (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32151"">#32151</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/44d679faee209611bee14fcea08207f9753bb466""><code>44d679f</code></a> Increment versions for appcomplianceautomation releases (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32155"">#32155</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/020145e20dff874555f4e610bc9b5b39213b1740""><code>020145e</code></a> move processor-lifecycle-manager from messaging to service module (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32152"">#32152</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12477:3790,depend,dependabot,3790,https://hail.is,https://github.com/hail-is/hail/pull/12477,1,['depend'],['dependabot']
Integrability,"/1f0b7856de4008e7e4c1e8c1b215d5d4dfaecd1a""><code>1f0b785</code></a> chore(deps): update codecov/codecov-action action to v4 (<a href=""https://redirect.github.com/PyMySQL/PyMySQL/issues/1158"">#1158</a>)</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/1e28be81c24dde66f8acbf4c5e24f60d6b5e72e7""><code>1e28be8</code></a> chore(deps): update github/codeql-action action to v3 (<a href=""https://redirect.github.com/PyMySQL/PyMySQL/issues/1154"">#1154</a>)</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/f13f054abcc18b39855a760a84be0a517f0da658""><code>f13f054</code></a> chore(deps): update actions/setup-python action to v5 (<a href=""https://redirect.github.com/PyMySQL/PyMySQL/issues/1152"">#1152</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/PyMySQL/PyMySQL/compare/v1.1.0...v1.1.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pymysql&package-manager=pip&previous-version=1.1.0&new-version=1.1.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` wil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14556:7520,depend,dependency-name,7520,https://hail.is,https://github.com/hail-is/hail/pull/14556,1,['depend'],['dependency-name']
Integrability,"/2.10.1...2.11.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jinja2&package-manager=pip&previous-version=2.10.1&new-version=2.11.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10209:7855,Depend,Dependabot,7855,https://hail.is,https://github.com/hail-is/hail/pull/10209,9,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"/22"">#22</a>) <a href=""https://github.com/bwoodsend""><code>@​bwoodsend</code></a></li>; <li>Add type hints (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/15"">#15</a>) <a href=""https://github.com/hugovk""><code>@​hugovk</code></a></li>; </ul>; <h2>Fixed</h2>; <ul>; <li>Fix <code>scientific()</code> on small positive numbers (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/22"">#22</a>) <a href=""https://github.com/bwoodsend""><code>@​bwoodsend</code></a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/python-humanize/humanize/commit/5553ff5308c363aeaa923362b11b7a8e299129f5""><code>5553ff5</code></a> Update FUNDING.yml</li>; <li><a href=""https://github.com/python-humanize/humanize/commit/694a2d616ff72796acdd1830a1fa3f91a1e03448""><code>694a2d6</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/56"">#56</a> from python-humanize/add-installation-instructions</li>; <li><a href=""https://github.com/python-humanize/humanize/commit/c0591aeb25a067fcfb3419e5e524f4ebd72c1380""><code>c0591ae</code></a> Add installation instructions</li>; <li><a href=""https://github.com/python-humanize/humanize/commit/e0e82da1eb41ed89b448062c058da3ae43ebd07c""><code>e0e82da</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/54"">#54</a> from mjmikulski/pl-short-scale</li>; <li><a href=""https://github.com/python-humanize/humanize/commit/a52beedd9ec52a40797b86e6624ba8a194cbcacc""><code>a52beed</code></a> Add author notice</li>; <li><a href=""https://github.com/python-humanize/humanize/commit/7b0d9be9e472b5e99e4db2ed15dc5716639c2121""><code>7b0d9be</code></a> Fix wrong declinations of googol and a year</li>; <li><a href=""https://github.com/python-humanize/humanize/commit/d0dde8f2e4ab13de51c6920f6ed523eadd2d4d3c""><c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12329:5220,depend,dependabot,5220,https://hail.is,https://github.com/hail-is/hail/pull/12329,1,['depend'],['dependabot']
Integrability,"/22625"">#22625</a> from charris/backport-22561</li>; <li><a href=""https://github.com/numpy/numpy/commit/dcd9404456e4af37041ee740045e95b10aaa46ad""><code>dcd9404</code></a> BUG: Histogramdd breaks on big arrays in Windows (<a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22561"">#22561</a>)</li>; <li><a href=""https://github.com/numpy/numpy/commit/bb5e3a671f1fab8bf39346c760cf65009f91bea2""><code>bb5e3a6</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22597"">#22597</a> from charris/backport-22557</li>; <li><a href=""https://github.com/numpy/numpy/commit/0d3d50045fdb4012e51d47ab95e9fbbbbd08ca00""><code>0d3d500</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22596"">#22596</a> from charris/backport-22503</li>; <li><a href=""https://github.com/numpy/numpy/commit/38fe21f6cae59326a4b35c5337c78052df153d41""><code>38fe21f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22595"">#22595</a> from charris/backport-22452</li>; <li><a href=""https://github.com/numpy/numpy/commit/45329c1ee92d00959d11cdfa0a2c5a25a6867933""><code>45329c1</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22593"">#22593</a> from charris/backport-22447</li>; <li><a href=""https://github.com/numpy/numpy/commit/3ca02ce5b1a4ec2412cad839d42452a4200a5270""><code>3ca02ce</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22594"">#22594</a> from charris/backport-22450</li>; <li><a href=""https://github.com/numpy/numpy/commit/8cededdf4eeebd4f1985bd74c11fbf44f367937f""><code>8cededd</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22592"">#22592</a> from charris/backport-22393</li>; <li>Additional commits viewable in <a href=""https://github.com/numpy/numpy/compare/v1.21.6...v1.23.5"">compare view</a></li>; </ul>; </details>; <br />. ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12515:5260,depend,dependabot,5260,https://hail.is,https://github.com/hail-is/hail/pull/12515,1,['depend'],['dependabot']
Integrability,"/23b5134dee481632775b09a2d37d183a646026a8""><code>23b5134</code></a> Provide complete model context for deserialization of instances (<a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11469"">#11469</a>)</li>; <li><a href=""https://github.com/bokeh/bokeh/commit/64fa0759bab7e2cc48663a2359093dc3e0b58df5""><code>64fa075</code></a> Add OS to bokeh info (<a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11797"">#11797</a>)</li>; <li><a href=""https://github.com/bokeh/bokeh/commit/da7d07ab6cc9fc9e88df7b5ecd39bc5da0b47cd9""><code>da7d07a</code></a> Don't unnecessarily update node/edge renderers in graphs (<a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11808"">#11808</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/bokeh/bokeh/compare/1.3.1...2.4.2"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11540:9019,depend,dependabot,9019,https://hail.is,https://github.com/hail-is/hail/pull/11540,1,['depend'],['dependabot']
Integrability,"/276162426. Running the `prepare_gtex_v7_expression_data` step of the https://github.com/broadinstitute/gnomad-browser pipeline using Hail 0.2.105 results in the following error:. ```; Traceback (most recent call last):; File ""/tmp/dc052bbb66544877a73c723ac0a0dc46/genes.py"", line 327, in <module>; run_pipeline(pipeline); File ""/tmp/dc052bbb66544877a73c723ac0a0dc46/pyfiles_h7wv4zl3.zip/data_pipeline/pipeline.py"", line 200, in run_pipeline; File ""/tmp/dc052bbb66544877a73c723ac0a0dc46/pyfiles_h7wv4zl3.zip/data_pipeline/pipeline.py"", line 167, in run; File ""/tmp/dc052bbb66544877a73c723ac0a0dc46/pyfiles_h7wv4zl3.zip/data_pipeline/pipeline.py"", line 132, in run; File ""/tmp/dc052bbb66544877a73c723ac0a0dc46/pyfiles_h7wv4zl3.zip/data_pipeline/data_types/gtex_tissue_expression.py"", line 14, in prepare_gtex_expression_data; File ""<decorator-gen-1060>"", line 2, in export; File ""/opt/conda/default/lib/python3.8/site-packages/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/opt/conda/default/lib/python3.8/site-packages/hail/table.py"", line 1098, in export; Env.backend().execute(; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 105, in execute; raise e.maybe_user_error(ir) from None; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 99, in execute; result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); File ""/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py"", line 1304, in __call__; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 31, in deco; raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; hail.utils.java.FatalError: MethodTooLargeException: Method too large: __C444collect_distributed_array_table_text_writer.__m512split_InsertFields ()V. Java stack trace:; is.hail.relocated.org.objectweb.asm.MethodTooLargeException: Method too large: __C444collect_distr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12531:1148,wrap,wrapper,1148,https://hail.is,https://github.com/hail-is/hail/issues/12531,1,['wrap'],['wrapper']
Integrability,"/295"">#295</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/c1e212c0fb41b3ea9185a9ea463fb1ea7142f748""><code>c1e212c</code></a> Add integration tests for Gradle 8.0 and 8.0.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/304f68e25f53633a92a4d2d6ce003a4986929503""><code>304f68e</code></a> Fix type inference issue</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/5.3.1...5.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=5.3.1&new-version=5.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12893:3134,Depend,Dependabot,3134,https://hail.is,https://github.com/hail-is/hail/pull/12893,1,['Depend'],['Dependabot']
Integrability,"/3.0.8...3.0.9"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=flask-cors&package-manager=pip&previous-version=3.0.8&new-version=3.0.9)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10464:3636,Depend,Dependabot,3636,https://hail.is,https://github.com/hail-is/hail/pull/10464,9,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"/3.9.10...3.10.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=orjson&package-manager=pip&previous-version=3.9.10&new-version=3.10.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14427:5577,Depend,Dependabot,5577,https://hail.is,https://github.com/hail-is/hail/pull/14427,9,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"/3.9.10...3.9.15"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=orjson&package-manager=pip&previous-version=3.9.10&new-version=3.9.15)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14357:5327,Depend,Dependabot,5327,https://hail.is,https://github.com/hail-is/hail/pull/14357,9,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"/3125"">#3125</a>)</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/da69d4f4f95bc7ef9307fc8e0499c2121f1e4791""><code>da69d4f</code></a> Fix docs build (<a href=""https://redirect.github.com/urllib3/urllib3/issues/3123"">#3123</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/urllib3/urllib3/compare/1.26.16...2.0.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.16&new-version=2.0.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13768:14731,Depend,Dependabot,14731,https://hail.is,https://github.com/hail-is/hail/pull/13768,2,['Depend'],['Dependabot']
Integrability,"/32aff86477ac001b0ee047db08591d89e90c6eb8""><code>32aff86</code></a> [SPARK-39447][SQL][3.2] Avoid AssertionError in AdaptiveSparkPlanExec.doExecu...</li>; <li><a href=""https://github.com/apache/spark/commit/be891ad99083564a7bf7f421e00b2cc4759a679f""><code>be891ad</code></a> [SPARK-39551][SQL][3.2] Add AQE invalid plan check</li>; <li><a href=""https://github.com/apache/spark/commit/1c0bd4c15a28d7c6a2dca846a5b8d0eb1d152aae""><code>1c0bd4c</code></a> [SPARK-39656][SQL][3.2] Fix wrong namespace in DescribeNamespaceExec</li>; <li><a href=""https://github.com/apache/spark/commit/3d084fe3217bea9af4c544f10ead8a2e5b97dad4""><code>3d084fe</code></a> [SPARK-39677][SQL][DOCS][3.2] Fix args formatting of the regexp and like func...</li>; <li>Additional commits viewable in <a href=""https://github.com/apache/spark/compare/v3.1.3...v3.2.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyspark&package-manager=pip&previous-version=3.1.3&new-version=3.2.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` wil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12452:2334,depend,dependency-name,2334,https://hail.is,https://github.com/hail-is/hail/pull/12452,1,['depend'],['dependency-name']
Integrability,"/354"">#354</a>: Removed <code>Distribution._local</code> factory. This; functionality was created as a demonstration of the; possible implementation. Now, the; <code>pep517 &lt;https://pypi.org/project/pep517&gt;</code>_ package; provides this functionality directly through; <code>pep517.meta.load &lt;https://github.com/pypa/pep517/blob/a942316305395f8f757f210e2b16f738af73f8b8/pep517/meta.py#L63-L73&gt;</code>_.</li>; </ul>; <h1>v4.9.0</h1>; <ul>; <li>Require Python 3.7 or later.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/python/importlib_metadata/commit/99a2ec4489da45407d8224be2804ff323a164ac0""><code>99a2ec4</code></a> Update changelog.</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/dbe114cbdc49ff42026974e48ca7178a091e7530""><code>dbe114c</code></a> Add docstring with tests for EntryPoint.matches. Ref <a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/373"">#373</a>.</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/ee566d048c0061b4f846f100ebfd93eefbcbf608""><code>ee566d0</code></a> Remove cast of path items to strings. Ref <a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/372"">#372</a>.</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/14cce75299645467adcd17352cb07caada32c444""><code>14cce75</code></a> Prefer re.findall, which returns materialized results. Fixes <a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/369"">#369</a>.</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/b4661fd8988b4101d4042e4cc4a8ed74423ec410""><code>b4661fd</code></a> Add test capturing missed expectation on extras. Ref <a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/369"">#369</a>.</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/590e31dad1afce",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11596:2653,depend,dependabot,2653,https://hail.is,https://github.com/hail-is/hail/pull/11596,1,['depend'],['dependabot']
Integrability,"/665"">#665</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/29ddff39290f4e2fbc7b9feb94eb622763e156e2""><code>29ddff3</code></a> Bump pytest-aiohttp from 0.3.0 to 1.0.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/668"">#668</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/3bc517092aff39330f2f96315e6f542e23415831""><code>3bc5170</code></a> Bump multidict from 5.2.0 to 6.0.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/670"">#670</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp_session/compare/v2.7.0...v2.11.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp-session&package-manager=pip&previous-version=2.7.0&new-version=2.11.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11544:4695,depend,dependabot-security-updates,4695,https://hail.is,https://github.com/hail-is/hail/pull/11544,1,['depend'],['dependabot-security-updates']
Integrability,"/699"">jpadilla/pyjwt#699</a></li>; <li><a href=""https://github.com/rekyungmin""><code>@​rekyungmin</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/705"">jpadilla/pyjwt#705</a></li>; <li><a href=""https://github.com/sseering""><code>@​sseering</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/661"">jpadilla/pyjwt#661</a></li>; <li><a href=""https://github.com/estin""><code>@​estin</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/713"">jpadilla/pyjwt#713</a></li>; <li><a href=""https://github.com/woodruffw""><code>@​woodruffw</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/725"">jpadilla/pyjwt#725</a></li>; <li><a href=""https://github.com/guneybilen""><code>@​guneybilen</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/727"">jpadilla/pyjwt#727</a></li>; <li><a href=""https://github.com/dmahr1""><code>@​dmahr1</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/734"">jpadilla/pyjwt#734</a></li>; <li><a href=""https://github.com/israelabraham""><code>@​israelabraham</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/738"">jpadilla/pyjwt#738</a></li>; <li><a href=""https://github.com/fviard""><code>@​fviard</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/723"">jpadilla/pyjwt#723</a></li>; <li><a href=""https://github.com/akx""><code>@​akx</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/742"">jpadilla/pyjwt#742</a></li>; <li><a href=""https://github.com/hipertracker""><code>@​hipertracker</code></a> made their first contribution in <a href=""https",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11866:6867,depend,dependabot,6867,https://hail.is,https://github.com/hail-is/hail/pull/11866,1,['depend'],['dependabot']
Integrability,"/7183"">#7183</a>)</li>; <li><a href=""https://github.com/jupyter/notebook/commit/e73d410074e6dbf97273f761d1513ff61db2965c""><code>e73d410</code></a> Updated ui-tests Configuration in Contributing.md (<a href=""https://redirect.github.com/jupyter/notebook/issues/7124"">#7124</a>)</li>; <li><a href=""https://github.com/jupyter/notebook/commit/ea1a1538ef56084654b7486e1d0b96f06b33acbe""><code>ea1a153</code></a> Set <code>navigation_with_keys</code> to <code>False</code> (<a href=""https://redirect.github.com/jupyter/notebook/issues/7129"">#7129</a>)</li>; <li><a href=""https://github.com/jupyter/notebook/commit/d717c6b3613f3609139bc2b9fe8d0a126aaeeae2""><code>d717c6b</code></a> Add Python 3.12 classifier (<a href=""https://redirect.github.com/jupyter/notebook/issues/7111"">#7111</a>)</li>; <li>See full diff in <a href=""https://github.com/jupyter/notebook/compare/@jupyter-notebook/tree@7.0.6...@jupyter-notebook/tree@7.0.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=notebook&package-manager=pip&previous-version=7.0.6&new-version=7.0.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` w",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14182:8680,Depend,Dependabot,8680,https://hail.is,https://github.com/hail-is/hail/pull/14182,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"/77"">#77</a>)</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/258a8832d9518340386e584206d7b5116185b182""><code>258a883</code></a> DOC: adjust test badge to point to Github Actions (<a href=""https://github-redirect.dependabot.com/hagenw/sphinxcontrib-katex/issues/76"">#76</a>)</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/ef894b2bf6ae4b1eaa0c5adec7ab5c1540da97cd""><code>ef894b2</code></a> Support Python 3.10 (<a href=""https://github-redirect.dependabot.com/hagenw/sphinxcontrib-katex/issues/74"">#74</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/hagenw/sphinxcontrib-katex/compare/0.5.1...v0.9.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinxcontrib-katex&package-manager=pip&previous-version=0.5.1&new-version=0.9.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12241:6653,depend,dependabot-security-updates,6653,https://hail.is,https://github.com/hail-is/hail/pull/12241,1,['depend'],['dependabot-security-updates']
Integrability,"/797b57a4ac8da86c13e52bf60586cd2432864400""><code>797b57a</code></a> Fixed pyproject.toml and setup.py.</li>; <li><a href=""https://github.com/mrabarnett/mrab-regex/commit/16bcce0d56e84367f61c24b369e23e73a3e9ad9e""><code>16bcce0</code></a> Add changelog.txt.</li>; <li><a href=""https://github.com/mrabarnett/mrab-regex/commit/d235c2c17f2335dd7699f3c29a6ae6db6dbe6dab""><code>d235c2c</code></a> pyproject.toml was missing.</li>; <li><a href=""https://github.com/mrabarnett/mrab-regex/commit/78460dc755b09966ee6e87d04c8dcfca7212256b""><code>78460dc</code></a> Added pyproject.toml.</li>; <li>See full diff in <a href=""https://github.com/mrabarnett/mrab-regex/compare/2023.3.23...2023.5.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=regex&package-manager=pip&previous-version=2023.3.23&new-version=2023.5.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12989:3212,depend,dependabot-security-updates,3212,https://hail.is,https://github.com/hail-is/hail/pull/12989,1,['depend'],['dependabot-security-updates']
Integrability,"/7c28357e412cef215a7d66c0ef69b568b316678b""><code>7c28357</code></a> Add a backport of generic <code>NamedTuple</code>s (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/44"">#44</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/7198c63522f3f435f8610c88ed0f5d0cf9d26091""><code>7198c63</code></a> Add <code>.gitignore</code>, <code>.editorconfig</code>, <code>CONTRIBUTING.md</code> (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/43"">#43</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/abe4390fe2456c6052c868731eb4b225b5a2f529""><code>abe4390</code></a> dataclass_transform will be in 3.11 (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/42"">#42</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/e9d09b5bb998693c3565a276a27f424b327b0f7b""><code>e9d09b5</code></a> Remove obsolete README.rst (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/41"">#41</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/447b62c4816efbd85727a12191a310bac5c416cc""><code>447b62c</code></a> fix CI (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/4"">#4</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/47600f62c354ca028c29762fa6ff0b007716ef88""><code>47600f6</code></a> update links (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/3"">#3</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/bc9317ef90a629f27f1ab706bfce99da873044b4""><code>bc9317e</code></a> Change home URL to tree instead of README (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/1157"">#1157</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/c10296f15f92277ed1d3ed0c83103ae3818d3669""><code>c10296f</code></a> Add a README.rst file back temporarily. (<a href=""http",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12200:2715,depend,dependabot,2715,https://hail.is,https://github.com/hail-is/hail/pull/12200,1,['depend'],['dependabot']
Integrability,"/7f924b13a50a05b8dc894418fa7faf779201e129""><code>7f924b1</code></a> Fix typo in deprecation documentation</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/4a8f8ada431974f2837260af3ed36299fd382814""><code>4a8f8ad</code></a> build(deps): Bump django from 4.0.2 to 4.0.3 in /testing/plugins_integration ...</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/c0fd2d883940f1292d5e8234803beaacd08315e6""><code>c0fd2d8</code></a> build(deps): Bump pytest-asyncio from 0.18.1 to 0.18.2 in /testing/plugins_in...</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/843e01824c257c3190792a9df430289c3abe349d""><code>843e018</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9732"">#9732</a> from nicoddemus/9730-toml-failure</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/bc43d66b47b917d43a22e0c703ecfe4eea342263""><code>bc43d66</code></a> [automated] Update plugin list (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9733"">#9733</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/e38d1cac489e42f4bdbecbb50f9f25dc9c36c19f""><code>e38d1ca</code></a> Improve error message for malformed pyproject.toml files</li>; <li>Additional commits viewable in <a href=""https://github.com/pytest-dev/pytest/compare/6.2.5...7.1.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest&package-manager=pip&previous-version=6.2.5&new-version=7.1.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot command",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11571:6347,depend,dependabot,6347,https://hail.is,https://github.com/hail-is/hail/pull/11571,2,['depend'],['dependabot']
Integrability,"/9319"">#9319</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/bfa4d95f0f356f2d535efd5c775e0fb3efe90ef2""><code>bfa4d95</code></a> changelog for 41.0.3 (<a href=""https://redirect.github.com/pyca/cryptography/issues/9320"">#9320</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/0da7165aa73c0a4865b0a4d9e019db3c16eea55a""><code>0da7165</code></a> backport fix the memory leak in fixedpool (<a href=""https://redirect.github.com/pyca/cryptography/issues/9272"">#9272</a>) (<a href=""https://redirect.github.com/pyca/cryptography/issues/9309"">#9309</a>)</li>; <li>See full diff in <a href=""https://github.com/pyca/cryptography/compare/41.0.2...41.0.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=41.0.2&new-version=41.0.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13357:2206,depend,dependabot-security-updates,2206,https://hail.is,https://github.com/hail-is/hail/pull/13357,3,['depend'],['dependabot-security-updates']
Integrability,"/99fcfa822db86b1f2ba5823dbf17efeb3d246ad5""><code>99fcfa8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1444"">#1444</a> from matthiasblaesing/update_libffi</li>; <li><a href=""https://github.com/java-native-access/jna/commit/9e473350a5ad5e04aab8b01e4018f973976e19f8""><code>9e47335</code></a> Update CHANGES.md</li>; <li>Additional commits viewable in <a href=""https://github.com/java-native-access/jna/compare/5.6.0...5.12.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=net.java.dev.jna:jna&package-manager=gradle&previous-version=5.6.0&new-version=5.12.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:8354,depend,dependabot,8354,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['depend'],['dependabot']
Integrability,"/9c0759a260fe126210a1e2026720000a3c40a919""><code>9c0759a</code></a> Prepare release 4.3.0 (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/52"">#52</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/1baf0a58b2b4c5327871d06801187cba47aa6975""><code>1baf0a5</code></a> Backport generic <code>TypedDict</code>s (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/46"">#46</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/7c28357e412cef215a7d66c0ef69b568b316678b""><code>7c28357</code></a> Add a backport of generic <code>NamedTuple</code>s (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/44"">#44</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/7198c63522f3f435f8610c88ed0f5d0cf9d26091""><code>7198c63</code></a> Add <code>.gitignore</code>, <code>.editorconfig</code>, <code>CONTRIBUTING.md</code> (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/43"">#43</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/abe4390fe2456c6052c868731eb4b225b5a2f529""><code>abe4390</code></a> dataclass_transform will be in 3.11 (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/42"">#42</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/e9d09b5bb998693c3565a276a27f424b327b0f7b""><code>e9d09b5</code></a> Remove obsolete README.rst (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/41"">#41</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/447b62c4816efbd85727a12191a310bac5c416cc""><code>447b62c</code></a> fix CI (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/4"">#4</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/47600f62c354ca028c29762fa6ff0b007716ef88""><code>47600f6</code></a> update links (<a href=""https://github-redirect.d",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12200:2190,depend,dependabot,2190,https://hail.is,https://github.com/hail-is/hail/pull/12200,1,['depend'],['dependabot']
Integrability,"/Azure/azure-sdk-for-java/commit/02fdc27bc10fa3e1bda08f3125059e95be8a4bb0""><code>02fdc27</code></a> Release/azure communication common/1.2.2 (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/31377"">#31377</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-java/compare/azure-storage-blob_12.13.0...azure-storage-blob_12.20.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.azure:azure-storage-blob&package-manager=gradle&previous-version=12.13.0&new-version=12.20.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12450:3691,depend,dependabot-automerge-start,3691,https://hail.is,https://github.com/hail-is/hail/pull/12450,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"/Azure/azure-sdk-for-java/commit/4fc24620f120643d18f85aca1bf3ee53daf7f124""><code>4fc2462</code></a> Increment versions for eventgrid releases (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32230"">#32230</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/de48207d7f57407cebfa549c843135dadeeab15c""><code>de48207</code></a> Nikoudsi/batch data plane sdk release for 2022 10 01 API Change (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32162"">#32162</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/11f08f973490521552c80e876f23ecc1bde99ed7""><code>11f08f9</code></a> Update live test (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32229"">#32229</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/82717614085eea8d521bf4b040a3791c9de63aa8""><code>8271761</code></a> Use the new audience field (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32225"">#32225</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/056f7e87e3b6af7c5efb1f18b24c51b7fd8d505c""><code>056f7e8</code></a> Increment versions for eventhubs releases (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32226"">#32226</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/d75b6a864c4428feaee8e6474fd2f074ac1541eb""><code>d75b6a8</code></a> Sync eng/common directory with azure-sdk-tools for PR 4628 (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32105"">#32105</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/47e36b651e9abc80f8d711cbff69c821539851c2""><code>47e36b6</code></a> Updating CODEOWNERS for Communication Identity &amp; Common Packages (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32222"">#32222</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-j",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12508:2961,depend,dependabot,2961,https://hail.is,https://github.com/hail-is/hail/pull/12508,1,['depend'],['dependabot']
Integrability,"/Azure/azure-sdk-for-java/commit/de48207d7f57407cebfa549c843135dadeeab15c""><code>de48207</code></a> Nikoudsi/batch data plane sdk release for 2022 10 01 API Change (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32162"">#32162</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/11f08f973490521552c80e876f23ecc1bde99ed7""><code>11f08f9</code></a> Update live test (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32229"">#32229</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/82717614085eea8d521bf4b040a3791c9de63aa8""><code>8271761</code></a> Use the new audience field (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32225"">#32225</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/056f7e87e3b6af7c5efb1f18b24c51b7fd8d505c""><code>056f7e8</code></a> Increment versions for eventhubs releases (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32226"">#32226</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/d75b6a864c4428feaee8e6474fd2f074ac1541eb""><code>d75b6a8</code></a> Sync eng/common directory with azure-sdk-tools for PR 4628 (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32105"">#32105</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/47e36b651e9abc80f8d711cbff69c821539851c2""><code>47e36b6</code></a> Updating CODEOWNERS for Communication Identity &amp; Common Packages (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32222"">#32222</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/c051757b394000308e0a79bcb93da05875892401""><code>c051757</code></a> Increment package versions for cosmos releases (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/32209"">#32209</a>)</li>; <li>Additional commits viewable in <a href=""http",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12508:3240,depend,dependabot,3240,https://hail.is,https://github.com/hail-is/hail/pull/12508,1,['depend'],['dependabot']
Integrability,"/PyCQA/pylint/commit/05990167978b3acbb1fbf37b079602a057ee4774""><code>0599016</code></a> <code>redefined-slots-in-subclass</code> crash when slot type is neither a string or c...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c48c45a88c74c0429f184c48334a513806c6a16c""><code>c48c45a</code></a> Fix E1102 / <code>not-callable</code> false positive for property that returns a lambd...</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/v2.13.4...v2.13.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pylint&package-manager=pip&previous-version=2.13.4&new-version=2.13.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11739:5381,depend,dependabot,5381,https://hail.is,https://github.com/hail-is/hail/pull/11739,1,['depend'],['dependabot']
Integrability,"/PyCQA/pylint/commit/680edebc686cad664bbed934a490aeafa775f163""><code>680edeb</code></a> Bump pylint to 2.14.3, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/b05ac51ad2e3785b6b9b071b8cb241993c914105""><code>b05ac51</code></a> Pin <code>colorama</code> to lowest supported version (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6970"">#6970</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/v2.13.5...v2.14.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pylint&package-manager=pip&previous-version=2.13.5&new-version=2.14.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11980:3283,depend,dependabot,3283,https://hail.is,https://github.com/hail-is/hail/pull/11980,1,['depend'],['dependabot']
Integrability,"/PyCQA/pylint/issues/5452"">#5452</a>: Fix false positive missing-doc-param from multi-line Google-st… (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5459"">#5459</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/35813de38ed58855f1b89fb492dc141d24bf2661""><code>35813de</code></a> Move various tests from <code>TestTypeChecker</code> to functional tests (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5455"">#5455</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/pylint-2.6.0...v2.12.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pylint&package-manager=pip&previous-version=2.6.0&new-version=2.12.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11461:8783,Depend,Dependabot,8783,https://hail.is,https://github.com/hail-is/hail/pull/11461,2,['Depend'],['Dependabot']
Integrability,"/PyCQA/pylint/issues/6029"">#6029</a>)</li>; <li>See full diff in <a href=""https://github.com/PyCQA/pylint/compare/v2.13.3...v2.13.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pylint&package-manager=pip&previous-version=2.13.3&new-version=2.13.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11723:3819,Depend,Dependabot,3819,https://hail.is,https://github.com/hail-is/hail/pull/11723,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/aiocloud/common/base_client.py"", line 21, in request; async with await self._session.request(method, url, **kwargs) as resp:; File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/aiocloud/common/session.py"", line 103, in request; return await retry_transient_errors(self._request_with_valid_authn, method, url, **kwargs); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/utils/utils.py"", line 769, in retry_transient_errors; return await retry_transient_errors_with_debug_string('', 0, f, *args, **kwargs); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/utils/utils.py"", line 785, in retry_transient_errors_with_debug_string; return await f(*args, **kwargs); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/aiocloud/common/session.py"", line 115, in _request_with_valid_authn; return await self._http_session.request(method, url, **kwargs); File ""/Users/mkanai/.anyenv/envs/pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages/hailtop/httpx.py"", line 138, in request_and_raise_for_status; raise ClientResponseError(; hailtop.httpx.ClientResponseError: 403, message='Forbidden', url=URL('https://storage.googleapis.com/storage/v1/b/hail-common?userProject=finngen-xavier') body='{\n ""error"": {\n ""code"": 403,\n ""message"": ""mkanai@broadinstitute.org does not have storage.buckets.get access to the Google Cloud Storage bucket. Permission \'storage.buckets.get\' denied on resource (or it may not exist)."",\n ""errors"": [\n {\n ""message"": ""mkanai@broadinstitute.org does not have storage.buckets.get access to the Google Cloud Storage bucket. Permission \'storage.buckets.get\' denied on resource (or it may not exist)."",\n ""domain"": ""global"",\n ""reason"": ""forbidden""\n }\n ]\n }\n}\n'; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14291:5020,message,message,5020,https://hail.is,https://github.com/hail-is/hail/issues/14291,3,['message'],['message']
Integrability,/a&gt; [pre-commit.ci] pre-commit autoupdate (&lt;a href=&quot;https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/748&quot;&gt;#748&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/jpadilla/pyjwt/commit/3d4d82248f1120c87f1f4e0e8793eaa1d54843a6&quot;&gt;&lt;code&gt;3d4d822&lt;/code&gt;&lt;/a&gt; Don't mutate options dictionary in .decode_complete() (&lt;a href=&quot;https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/743&quot;&gt;#743&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/jpadilla/pyjwt/commit/1f1fe15bb41846c602b3e106176b2c692b93a613&quot;&gt;&lt;code&gt;1f1fe15&lt;/code&gt;&lt;/a&gt; Add a deprecation warning when jwt.decode() is called with the legacy verify=...&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/jpadilla/pyjwt/commit/35fa28e59d99b99c6a780d2a029a74d6bbba8b1e&quot;&gt;&lt;code&gt;35fa28e&lt;/code&gt;&lt;/a&gt; [pre-commit.ci] pre-commit autoupdate (&lt;a href=&quot;https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/740&quot;&gt;#740&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;Additional commits viewable in &lt;a href=&quot;https://github.com/jpadilla/pyjwt/compare/1.7.1...2.4.0&quot;&gt;compare view&lt;/a&gt;&lt;/li&gt;; &lt;/ul&gt;; &lt;/details&gt;. &lt;br /&gt;; </code></pre>. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyjwt&package-manager=pip&previous-version=1.7.1&new-version=2.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11866:14335,depend,dependabot,14335,https://hail.is,https://github.com/hail-is/hail/pull/11866,1,['depend'],['dependabot']
Integrability,"/a153aeed8df60f4190e6114f77cd254d1493e411""><code>a153aee</code></a> remove special handling of pypy offsets since modern pypy gets it right (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/717"">#717</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/d875b02835fb9b1480a95c5245040eb31a384357""><code>d875b02</code></a> fix syntax error reporting from stdin (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/357"">#357</a>) (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/716"">#716</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/44ef321b0e608c61182ecf5d88f9edeececa5403""><code>44ef321</code></a> Fix pylint URL in README (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/714"">#714</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/2246217295dc8cb30ef4a7b9d8dc449ce32e603a""><code>2246217</code></a> burn the bridges with python 2.x (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/707"">#707</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/becbab65bae84e3e19fc388a42dfabcff0c323c8""><code>becbab6</code></a> upgrade flake8 to 4.0.1 (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/706"">#706</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/f736615f32a4bab27c9efeb5b8f8c31702efc4ab""><code>f736615</code></a> remove backported unittest methods (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/705"">#705</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/5959216f67837f3ddf5b959c21e097c7a3758d48""><code>5959216</code></a> remove checking of node.docstring (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/704"">#704</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/405a0906c8debafaae419472d3f51b84b7ba5c49""><code>405a090</code></a> simplify PYPY check (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/703""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12149:2187,depend,dependabot,2187,https://hail.is,https://github.com/hail-is/hail/pull/12149,1,['depend'],['dependabot']
Integrability,"/a> (2022-01-25)</h2>; <h3>Features</h3>; <ul>; <li>ADC can load an impersonated service account credentials. (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/956"">#956</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/a8eb4c8693055a3420cfe9c3420aae2bc8cd465a"">a8eb4c8</a>)</li>; </ul>; <h3><a href=""https://github.com/googleapis/google-auth-library-python/compare/v2.4.0...v2.4.1"">2.4.1</a> (2022-01-21)</h3>; <h3>Bug Fixes</h3>; <ul>; <li>urllib3 import (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/953"">#953</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/c8b5cae3da5eb9d40067d38dac51a4a8c1e0763e"">c8b5cae</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/google-auth-library-python/compare/v2.3.3...v2.4.0"">2.4.0</a> (2022-01-20)</h2>; <h3>Features</h3>; <ul>; <li>add 'py.typed' declaration (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/919"">#919</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/c99350455d0f7fd3aab950ac47b43000c73dd312"">c993504</a>)</li>; <li>add api key support (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/826"">#826</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/3b15092b3461278400e4683060f64a96d50587c4"">3b15092</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <ul>; <li><strong>deps:</strong> allow cachetools 5.0 for python 3.7+ (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/937"">#937</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/1eae37db7f6fceb32d6ef0041962ce1755d2116c"">1eae37d</a>)</li>; <li>fix the message format for metadata server exception (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/916"">#916</a>) (<a href=""https://git",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11546:7154,depend,dependabot,7154,https://hail.is,https://github.com/hail-is/hail/pull/11546,1,['depend'],['dependabot']
Integrability,"/a> (<a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/issues/61"">61</a>)</li>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/354"">PR 354</a> - PR: Add wrapper around sip/shiboken isdeleted/isvalid (compat.py), by <a href=""https://github.com/zjp""><code>@​zjp</code></a> (<a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/issues/302"">302</a>)</li>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/353"">PR 353</a> - PR: Add note to readme about use with Pyright, by <a href=""https://github.com/CAM-Gerlach""><code>@​CAM-Gerlach</code></a> (<a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/issues/352"">352</a>)</li>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/350"">PR 350</a> - PR: Restore <code>WEBENGINE</code> constant in <code>QtWebEngineWidgets</code>, by <a href=""https://github.com/ccordoba12""><code>@​ccordoba12</code></a></li>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/346"">PR 346</a> - PR: Add workaround for <code>mode</code> argument in QTextCursor.movePosition (PySide6), by <a href=""https://github.com/rear1019""><code>@​rear1019</code></a></li>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/344"">PR 344</a> - PR: Add missing imports and modules, by <a href=""https://github.com/DaelonSuzuka""><code>@​DaelonSuzuka</code></a></li>; </ul>; <p>In this release 7 pull requests were closed.</p>; <hr />; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/spyder-ide/qtpy/commit/7841f4d398c9dbdc3b479a1df9f997dc14101088""><code>7841f4d</code></a> Release 2.2.0</li>; <li><a href=""https://github.com/spyder-ide/qtpy/commit/78ee3de13b7eba94cffa5ccc508a6da07cb693aa""><code>78ee3de</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/issues/357"">#357</a> from dalthviz/fixes_issue_61</li>; <li><a href=""https://github.com/sp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12194:5847,depend,dependabot,5847,https://hail.is,https://github.com/hail-is/hail/pull/12194,1,['depend'],['dependabot']
Integrability,"/a> Bump pylint to 2.15.3, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/38e278401a66218fba26308fbce56740761a2003""><code>38e2784</code></a> Bump astroid to 2.12.10</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/f5e168e867799013fb380aa9fe8a0c1516a651c8""><code>f5e168e</code></a> Fix <code>undefined-loop-variable</code> with <code>NoReturn</code> and <code>Never</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7476"">#7476</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/fbc9e663473fa0416779f1d71109b4123f6c3365""><code>fbc9e66</code></a> Accept a comma-separated list of messages IDs in <code>--help-msg</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7490"">#7490</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/fe3436efb0ec10677ba1539ac02e26cb3f852cbb""><code>fe3436e</code></a> False positive <code>global-variable-not-assigned</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7479"">#7479</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/52cf631d732f7b39a879adf7e617e0aa7059a83a""><code>52cf631</code></a> [invalid-class-object] Fix crash when <strong>class</strong> is defined with a tuple</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/8e05ff6acf30deae5d83ea3847ec47ed0bf049a4""><code>8e05ff6</code></a> Fix a crash in the <code>modified-iterating-dict</code> checker involving instance attri...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/9b359ad676dff97a35321976c19ca0f6c4fc44ad""><code>9b359ad</code></a> Fix <code>unhashable-member</code> crash when <code>lambda</code> used as a dict key (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7454"">#7454</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/5716ad10104a9553ef9d64404b044c04947889b2""><code>5716ad1</code></a> Bump pylint to 2.15.2, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/49b5d5da",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12240:1227,depend,dependabot,1227,https://hail.is,https://github.com/hail-is/hail/pull/12240,1,['depend'],['dependabot']
Integrability,"/a> DOC: update 1.11.2 relnotes</li>; <li><a href=""https://github.com/scipy/scipy/commit/0641a73ae4fbb1ee377518d3054ef7123b1c0f88""><code>0641a73</code></a> LINT</li>; <li><a href=""https://github.com/scipy/scipy/commit/a8b825af44d7ad2187d3cafb2247c17acf0ae709""><code>a8b825a</code></a> MAINT: ensure cobyla objective returns scalar</li>; <li><a href=""https://github.com/scipy/scipy/commit/4dd233372f30327a101331af8dab4a8a9b9c2659""><code>4dd2333</code></a> MAINT: fixup dep warning</li>; <li>Additional commits viewable in <a href=""https://github.com/scipy/scipy/compare/v1.9.3...v1.11.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=scipy&package-manager=pip&previous-version=1.9.3&new-version=1.11.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ign",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13461:3885,Depend,Dependabot,3885,https://hail.is,https://github.com/hail-is/hail/pull/13461,1,['Depend'],['Dependabot']
Integrability,"/a> Handle ForwardRef, expand TypeVar and link Ellipsis (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/214"">#214</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/f75d19be9275b25d2f6caa23392a6072f49c3d56""><code>f75d19b</code></a> Add handling of tuples in type subscriptions (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/212"">#212</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/7b8c357be15d7b7b4ec4ad272f554f7ab3e0e197""><code>7b8c357</code></a> ADMIN: Update pepy.tech link in badge (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/213"">#213</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/3492d491fe09701a035715bb1dbaba13734ad69c""><code>3492d49</code></a> Prevents reaching inner blocks that contains <code>if TYPE_CHECKING</code> (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/211"">#211</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/01b3a1abeac063a5530b96b78252aa17a93f040c""><code>01b3a1a</code></a> More robust handling of type guard imports (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/208"">#208</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/d770c69c1e6c7e4a809a145140cfc1033eac57dd""><code>d770c69</code></a> Fix fully_qualified should be typehints_fully_qualified (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/204"">#204</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/compare/1.11.1...1.17.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx-autodoc-typehints&package-manager=pip",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11503:4954,depend,dependabot,4954,https://hail.is,https://github.com/hail-is/hail/pull/11503,2,['depend'],['dependabot']
Integrability,"/a> Merge <a href=""https://github.com/jaraco/skeleton"">https://github.com/jaraco/skeleton</a></li>; <li><a href=""https://github.com/python/importlib_metadata/commit/04fe68a96ee8e3d3ca521b4abbfe53203063f9d9""><code>04fe68a</code></a> Ran pre-commit autoupdate</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/2ef893a85f0ad023827d0720307695214a2245b2""><code>2ef893a</code></a> Merge <a href=""https://github.com/jaraco/skeleton"">https://github.com/jaraco/skeleton</a></li>; <li><a href=""https://github.com/python/importlib_metadata/commit/97e0293b8bf317b54f49c25add7d44830f9180fe""><code>97e0293</code></a> In _read_egg_info_reqs, when requires.txt exists but is empty, return an empt...</li>; <li>Additional commits viewable in <a href=""https://github.com/python/importlib_metadata/compare/0.1...v4.11.3"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11596:4995,depend,dependabot,4995,https://hail.is,https://github.com/hail-is/hail/pull/11596,1,['depend'],['dependabot']
Integrability,"/a> Merge pull request <a href=""https://redirect.github.com/numpy/numpy/issues/20680"">#20680</a> from charris/backport-20663</li>; <li><a href=""https://github.com/numpy/numpy/commit/794b36f7e1bf2a8c42774ab0db86a74bd32f674b""><code>794b36f</code></a> Update armccompiler.py</li>; <li><a href=""https://github.com/numpy/numpy/commit/d93b14e3d7abaa1d837825e51671f817788e120f""><code>d93b14e</code></a> Update test_public_api.py</li>; <li><a href=""https://github.com/numpy/numpy/commit/7662c0789cc6a70d5ad4d950ee2e95f3afef7df6""><code>7662c07</code></a> Update <strong>init</strong>.py</li>; <li><a href=""https://github.com/numpy/numpy/commit/311ab52488a7d096ac3bc4c2de0fdae17ecd13ef""><code>311ab52</code></a> Update armccompiler.py</li>; <li>Additional commits viewable in <a href=""https://github.com/numpy/numpy/compare/v1.21.6...v1.22.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.6&new-version=1.22.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` wi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12894:5096,depend,dependency-name,5096,https://hail.is,https://github.com/hail-is/hail/pull/12894,1,['depend'],['dependency-name']
Integrability,"/a> Merge pull request <a href=""https://redirect.github.com/numpy/numpy/issues/20680"">#20680</a> from charris/backport-20663</li>; <li><a href=""https://github.com/numpy/numpy/commit/794b36f7e1bf2a8c42774ab0db86a74bd32f674b""><code>794b36f</code></a> Update armccompiler.py</li>; <li><a href=""https://github.com/numpy/numpy/commit/d93b14e3d7abaa1d837825e51671f817788e120f""><code>d93b14e</code></a> Update test_public_api.py</li>; <li><a href=""https://github.com/numpy/numpy/commit/7662c0789cc6a70d5ad4d950ee2e95f3afef7df6""><code>7662c07</code></a> Update <strong>init</strong>.py</li>; <li><a href=""https://github.com/numpy/numpy/commit/311ab52488a7d096ac3bc4c2de0fdae17ecd13ef""><code>311ab52</code></a> Update armccompiler.py</li>; <li>Additional commits viewable in <a href=""https://github.com/numpy/numpy/compare/v1.21.6...v1.22.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.6&new-version=1.22.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12809:5096,depend,dependency-name,5096,https://hail.is,https://github.com/hail-is/hail/pull/12809,1,['depend'],['dependency-name']
Integrability,"/a> Merge remote-tracking branch 'upstream/5.0.x' into lang-none-en</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/479e48266c025c99025787a8004a82b2afda8e6c""><code>479e482</code></a> Update warning, revert my original warning patch</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/fb6db30c1024ce5838dcf330f275cdf2adbd94b6""><code>fb6db30</code></a> Update comment</li>; <li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v3.5.4...v5.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx&package-manager=pip&previous-version=3.5.4&new-version=5.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11871:6759,depend,dependabot,6759,https://hail.is,https://github.com/hail-is/hail/pull/11871,1,['depend'],['dependabot']
Integrability,"/a> Name as 'options' in lambda_eval and unsafe_eval, but '_dict' in deprecated eval</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/facf3af93dabcbdd8cdbda8c3b50eefafa3bb04c""><code>facf3af</code></a> Added release notes</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/2a93aba5cfcf6e241ab4f9392c13e3b74032c061""><code>2a93aba</code></a> Use strncpy to avoid buffer overflow</li>; <li><a href=""https://github.com/python-pillow/Pillow/commit/a670597bc30e9d489656fc9d807170b8f3d7ca57""><code>a670597</code></a> Update CHANGES.rst [ci skip]</li>; <li>Additional commits viewable in <a href=""https://github.com/python-pillow/Pillow/compare/10.2.0...10.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pillow&package-manager=pip&previous-version=10.2.0&new-version=10.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14439:15497,depend,dependabot-security-updates,15497,https://hail.is,https://github.com/hail-is/hail/pull/14439,3,['depend'],['dependabot-security-updates']
Integrability,"/a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; </ul>; <h3>Fixes</h3>; <ul>; <li>Fix typo in help message for <code>--from-ref</code> and <code>--to-ref</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2266"">#2266</a> PR by <a href=""https://github.com/leetrout""><code>@​leetrout</code></a>.</li>; </ul>; </li>; <li>Prioritize binary builds for R dependencies.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2277"">#2277</a> PR by <a href=""https://github.com/lorenzwalthert""><code>@​lorenzwalthert</code></a>.</li>; </ul>; </li>; <li>Fix handling of git worktrees.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2252"">#2252</a> PR by <a href=""https://github.com/daschuer""><code>@​daschuer</code></a>.</li>; </ul>; </li>; <li>Fix handling of <code>$R_HOME</code> for R hooks.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2301"">#2301</a> PR by <a href=""https://github.com/jeff-m-sullivan""><code>@​jeff-m-sullivan</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2300"">#2300</a> issue by <a href=""https://github.com/jeff-m-sullivan""><code>@​jeff-m-sullivan</code></a>.</li>; </ul>; </li>; <li>Fix a rare race condition in change stashing.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2323"">#2323</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2287"">#2287</a> issue by <a href=""https://github.com/ian-h-chamberlain""><code>@​ian-h-chamberlain</code></a>.</li>; </ul>; </li>; </ul>; <h3>Updating</h3>; <ul>; <li>Remove python3.6 support. Note that pre-commit still supports running hooks written in older versions, but pre-commit itself requires python 3.7+.; <ul>; <li><a href=",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11731:3747,depend,dependabot,3747,https://hail.is,https://github.com/hail-is/hail/pull/11731,1,['depend'],['dependabot']
Integrability,"/a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; </ul>; <h3>Fixes</h3>; <ul>; <li>Fix typo in help message for <code>--from-ref</code> and <code>--to-ref</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2266"">#2266</a> PR by <a href=""https://github.com/leetrout""><code>@​leetrout</code></a>.</li>; </ul>; </li>; <li>Prioritize binary builds for R dependencies.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2277"">#2277</a> PR by <a href=""https://github.com/lorenzwalthert""><code>@​lorenzwalthert</code></a>.</li>; </ul>; </li>; <li>Fix handling of git worktrees.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2252"">#2252</a> PR by <a href=""https://github.com/daschuer""><code>@​daschuer</code></a>.</li>; </ul>; </li>; <li>Fix handling of <code>$R_HOME</code> for R hooks.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2301"">#2301</a> PR by <a href=""https://github.com/jeff-m-sullivan""><code>@​jeff-m-sullivan</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2300"">#2300</a> issue by <a href=""https://github.com/jeff-m-sullivan""><code>@​jeff-m-sullivan</code></a>.</li>; </ul>; </li>; <li>Fix a rare race condition in change stashing.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2323"">#2323</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2287"">#2287</a> issue by <a href=""https://github.com/ian-h-chamberlain""><code>@​ian-h-chamberlain</code></a>.</li>; </ul>; </li>; </ul>; <h3>Updating</h3>; <ul>; <li>Remove python3.6 support. Note that pre-commit still supports running hooks; written in older versions, but pre-commit itself requires python 3.7+.; <ul>; <li><a href",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11731:8926,depend,dependabot,8926,https://hail.is,https://github.com/hail-is/hail/pull/11731,1,['depend'],['dependabot']
Integrability,"/a> REL: Prepare for the NumPy 1.23.5 Release.</li>; <li><a href=""https://github.com/numpy/numpy/commit/2c4cf9a3c4cff914e3f9d190f42546d3e7c9ff82""><code>2c4cf9a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22625"">#22625</a> from charris/backport-22561</li>; <li><a href=""https://github.com/numpy/numpy/commit/dcd9404456e4af37041ee740045e95b10aaa46ad""><code>dcd9404</code></a> BUG: Histogramdd breaks on big arrays in Windows (<a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22561"">#22561</a>)</li>; <li><a href=""https://github.com/numpy/numpy/commit/bb5e3a671f1fab8bf39346c760cf65009f91bea2""><code>bb5e3a6</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22597"">#22597</a> from charris/backport-22557</li>; <li><a href=""https://github.com/numpy/numpy/commit/0d3d50045fdb4012e51d47ab95e9fbbbbd08ca00""><code>0d3d500</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22596"">#22596</a> from charris/backport-22503</li>; <li><a href=""https://github.com/numpy/numpy/commit/38fe21f6cae59326a4b35c5337c78052df153d41""><code>38fe21f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22595"">#22595</a> from charris/backport-22452</li>; <li><a href=""https://github.com/numpy/numpy/commit/45329c1ee92d00959d11cdfa0a2c5a25a6867933""><code>45329c1</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22593"">#22593</a> from charris/backport-22447</li>; <li><a href=""https://github.com/numpy/numpy/commit/3ca02ce5b1a4ec2412cad839d42452a4200a5270""><code>3ca02ce</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22594"">#22594</a> from charris/backport-22450</li>; <li><a href=""https://github.com/numpy/numpy/commit/8cededdf4eeebd4f1985bd74c11fbf44f367937f""><code>8cededd</code></a> Merge pull request <a href=""https:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12515:5004,depend,dependabot,5004,https://hail.is,https://github.com/hail-is/hail/pull/12515,1,['depend'],['dependabot']
Integrability,"/a> Slight perf enhancement in Empty</li>; <li><a href=""https://github.com/pyparsing/pyparsing/commit/801863aa4582a8ce5e6a7408d4966afcd247ea90""><code>801863a</code></a> Make htmlStripper.py and html_table_parser examples use PEP-8 names, add comm...</li>; <li><a href=""https://github.com/pyparsing/pyparsing/commit/7d4da80b2bca8a2767134f4a181ea9aac4bbb230""><code>7d4da80</code></a> Prep for release</li>; <li><a href=""https://github.com/pyparsing/pyparsing/commit/be0310a83436bb4893d0068bb5da3059199e4c0b""><code>be0310a</code></a> Add bf parser/executor example</li>; <li>Additional commits viewable in <a href=""https://github.com/pyparsing/pyparsing/compare/pyparsing_3.0.9...3.1.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyparsing&package-manager=pip&previous-version=3.0.9&new-version=3.1.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13334:9142,depend,dependabot-security-updates,9142,https://hail.is,https://github.com/hail-is/hail/pull/13334,1,['depend'],['dependabot-security-updates']
Integrability,"/a> Test all constructors</li>; <li><a href=""https://github.com/apache/commons-codec/commit/3535c17eccb2251fc518aa545a800b4922c8dc35""><code>3535c17</code></a> Test encode of null and empty array with an offset</li>; <li><a href=""https://github.com/apache/commons-codec/commit/e42dfe1ff2f273926fd759abea82b1c7b3021985""><code>e42dfe1</code></a> Fix test names</li>; <li><a href=""https://github.com/apache/commons-codec/commit/536587931cb77538709c57455165379a74e2f04f""><code>5365879</code></a> Test the codec policy property</li>; <li>Additional commits viewable in <a href=""https://github.com/apache/commons-codec/compare/commons-codec-1.11...rel/commons-codec-1.15"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=commons-codec:commons-codec&package-manager=gradle&previous-version=1.11&new-version=1.15)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12385:4971,depend,dependabot-security-updates,4971,https://hail.is,https://github.com/hail-is/hail/pull/12385,1,['depend'],['dependabot-security-updates']
Integrability,"/a> Update CHANGES for PR <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10107"">#10107</a></li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/b20e04968e73234da9fff7d19b12dfbeebebe944""><code>b20e049</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10107"">#10107</a> from Jean-Abou-Samra/intl-warnings</li>; <li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v3.5.4...v4.5.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx&package-manager=pip&previous-version=3.5.4&new-version=4.5.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11714:8013,depend,dependabot,8013,https://hail.is,https://github.com/hail-is/hail/pull/11714,2,['depend'],['dependabot']
Integrability,"/a> fix: add user agent in python-storage when calling resumable media (WIP) (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/715"">#715</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/4fbbf02d3d2fb7e16c3db32eee0474655247c3bc""><code>4fbbf02</code></a> chore: Adding support for pytest-xdist and pytest-parallel (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/723"">#723</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/dbfe520008a25c4e6f5b94e332129affa0f0d869""><code>dbfe520</code></a> chore(deps): update dependency google-cloud-pubsub to v2.10.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/724"">#724</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/e9aab389f868799d4425133954bad4f1cbb85786""><code>e9aab38</code></a> fix(deps): require google-api-core&gt;=1.31.5, &gt;=2.3.2 (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/722"">#722</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/python-storage/compare/v1.25.0...v2.2.0"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11578:8996,depend,dependabot,8996,https://hail.is,https://github.com/hail-is/hail/pull/11578,1,['depend'],['dependabot']
Integrability,"/a> from nicoddemus/9730-toml-failure</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/bc43d66b47b917d43a22e0c703ecfe4eea342263""><code>bc43d66</code></a> [automated] Update plugin list (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9733"">#9733</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/e38d1cac489e42f4bdbecbb50f9f25dc9c36c19f""><code>e38d1ca</code></a> Improve error message for malformed pyproject.toml files</li>; <li>Additional commits viewable in <a href=""https://github.com/pytest-dev/pytest/compare/6.2.5...7.1.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest&package-manager=pip&previous-version=6.2.5&new-version=7.1.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11571:7070,Depend,Dependabot,7070,https://hail.is,https://github.com/hail-is/hail/pull/11571,2,['Depend'],['Dependabot']
Integrability,"/a> from pre-commit/move-try-slightly</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/a138c85e64cb9ba7703565650504cff0bb339505""><code>a138c85</code></a> move patch discarding inside <code>try</code> for staged_files_only</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/7602abc3cfa054bcec49e982fd3a90e026430dae""><code>7602abc</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2322"">#2322</a> from pre-commit/default-install-hook-types</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/e11163d010447ce83aae996cf5a76038aa975fe4""><code>e11163d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2301"">#2301</a> from jeff-m-sullivan/rscript-path</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/d65016042b67d09139876e1903e839a168dfa7c3""><code>d650160</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2252"">#2252</a> from daschuer/worktree_fix</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/fd0177ae3ae5f94b36aafb54ab496f76fcead7b9""><code>fd0177a</code></a> implement default_install_hook_types</li>; <li>Additional commits viewable in <a href=""https://github.com/pre-commit/pre-commit/compare/v2.17.0...v2.18.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pre-commit&package-manager=pip&previous-version=2.17.0&new-version=2.18.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11731:12447,depend,dependabot,12447,https://hail.is,https://github.com/hail-is/hail/pull/11731,1,['depend'],['dependabot']
Integrability,"/a> in <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/346"">spyder-ide/qtpy#346</a></li>; <li>PR: Add missing imports and modules by <a href=""https://github.com/DaelonSuzuka""><code>@​DaelonSuzuka</code></a> in <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/344"">spyder-ide/qtpy#344</a></li>; <li>PR: Restore <code>WEBENGINE</code> constant in <code>QtWebEngineWidgets</code> by <a href=""https://github.com/ccordoba12""><code>@​ccordoba12</code></a> in <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/350"">spyder-ide/qtpy#350</a></li>; <li>PR: Add note to readme about use with Pyright by <a href=""https://github.com/CAM-Gerlach""><code>@​CAM-Gerlach</code></a> in <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/353"">spyder-ide/qtpy#353</a></li>; <li>PR: Add wrapper around sip/shiboken isdeleted/isvalid (compat.py) by <a href=""https://github.com/zjp""><code>@​zjp</code></a> in <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/354"">spyder-ide/qtpy#354</a></li>; <li>PR: Fix PyQt6 typing import for Qt by <a href=""https://github.com/tlambert03""><code>@​tlambert03</code></a> in <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/358"">spyder-ide/qtpy#358</a></li>; <li>PR: Add initial <code>Methods, helpers and QtPy namespace specifics</code> section to the README by <a href=""https://github.com/dalthviz""><code>@​dalthviz</code></a> in <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/357"">spyder-ide/qtpy#357</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/DaelonSuzuka""><code>@​DaelonSuzuka</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/344"">spyder-ide/qtpy#344</a></li>; <li><a href=""https://github.com/zjp""><code>@​zjp</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/354"">spyder-ide/qtpy#3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12194:1439,depend,dependabot,1439,https://hail.is,https://github.com/hail-is/hail/pull/12194,1,['depend'],['dependabot']
Integrability,"/a> issue by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>move hook template back to <code>bash</code> resolving shebang-portability issues.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2065"">#2065</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>add support for <code>fail_fast</code> at the individual hook level.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2097"">#2097</a> PR by <a href=""https://github.com/colens3""><code>@​colens3</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/1143"">#1143</a> issue by <a href=""https://github.com/potiuk""><code>@​potiuk</code></a>.</li>; </ul>; </li>; <li>allow passthrough of <code>GIT_CONFIG_KEY_*</code>, <code>GIT_CONFIG_VALUE_*</code>, and <code>GIT_CONFIG_COUNT</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2136"">#2136</a> PR by <a href=""https://github.com/emzeat""><code>@​emzeat</code></a>.</li>; </ul>; </li>; </ul>; <h3>Fixes</h3>; <ul>; <li>fix pre-commit autoupdate for <code>core.useBuiltinFSMonitor=true</code> on windows.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2047"">#2047</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2046"">#2046</a> issue by <a href=""https://github.com/lcnittl""><code>@​lcnittl</code></a>.</li>; </ul>; </li>; <li>fix temporary file stashing with for <code>submodule.recurse=1</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2071"">#2071</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2063"">#2063</a> issue by <",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11460:5381,depend,dependabot,5381,https://hail.is,https://github.com/hail-is/hail/pull/11460,2,['depend'],['dependabot']
Integrability,"/a> on branch 1.5.x (REGR: Loc.setitem with enlargement raises...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/f83e2fe3327ad85ae2e8c4ba469fe98383243dbf""><code>f83e2fe</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48623"">#48623</a> on branch 1.5.x (REGR/DOC: Docs left navbar broke) (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48625"">#48625</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/4fbb05591979055708162994e96fb4c61cf2a8ab""><code>4fbb055</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48601"">#48601</a> on branch 1.5.x (CI: Fix matplolib release issues) (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48617"">#48617</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/aabf6597f45436e9ada915ac15d3708f9d4948ca""><code>aabf659</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48587"">#48587</a> on branch 1.5.x (Fix <code>series.str.startswith(tuple)</code>) (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48593"">#48593</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/dfc00bfc5d98f8e2c63356e6a415da8ab7a7b436""><code>dfc00bf</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48397"">#48397</a> on branch 1.5.x (WARN: Remove false positive warning for i...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/3f91207dca8971c723605243f6bc113c739ba637""><code>3f91207</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48572"">#48572</a> on branch 1.5.x (DOC: Fixing styles for the dark theme) (#...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/27fd6c6c5141c5946470f4810858eb903491d651""><code>27fd6c6</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12292:4182,depend,dependabot,4182,https://hail.is,https://github.com/hail-is/hail/pull/12292,1,['depend'],['dependabot']
Integrability,"/a> remove unneeded variable</li>; <li>Additional commits viewable in <a href=""https://github.com/tqdm/tqdm/compare/v4.42.1...v4.64.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=tqdm&package-manager=pip&previous-version=4.42.1&new-version=4.64.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12260:6384,Depend,Dependabot,6384,https://hail.is,https://github.com/hail-is/hail/pull/12260,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"/a>) <a href=""https://github.com/BeyondEvil""><code>@​BeyondEvil</code></a></li>; <li>Update link to Tox (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/301"">#301</a>) <a href=""https://github.com/gnikonorov""><code>@​gnikonorov</code></a></li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>Add ESLint to project (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/367"">#367</a>) <a href=""https://github.com/gnikonorov""><code>@​gnikonorov</code></a></li>; <li>Assure scm versioning is pypa compatible (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/364"">#364</a>) <a href=""https://github.com/ssbarnea""><code>@​ssbarnea</code></a></li>; <li>Move release from travis to github actions (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/360"">#360</a>) <a href=""https://github.com/ssbarnea""><code>@​ssbarnea</code></a></li>; <li>Respect --show-capture=no flag (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/359"">#359</a>) <a href=""https://github.com/gnikonorov""><code>@​gnikonorov</code></a></li>; <li>Respect pytest --capture=no and -s flags (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/353"">#353</a>) <a href=""https://github.com/gnikonorov""><code>@​gnikonorov</code></a></li>; <li>Stop shadowing the 'format' builtin (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/347"">#347</a>) <a href=""https://github.com/gnikonorov""><code>@​gnikonorov</code></a></li>; <li>Post process html to include teardown in log (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/271"">#271</a>) <a href=""https://github.com/csm10495""><code>@​csm10495</code></a></li>; <li>Avoid pytest 6.0.0 (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/319"">#319</a>) <a href=""https://github.com/ssbarnea""><code>@​ssbarnea</code></a></li>; <li>Rename &quot;slave&quot; -&gt; &quot;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11524:3413,depend,dependabot,3413,https://hail.is,https://github.com/hail-is/hail/pull/11524,1,['depend'],['dependabot']
Integrability,"/a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/python-storage/blob/main/CHANGELOG.md"">google-cloud-storage's changelog</a>.</em></p>; <blockquote>; <h2><a href=""https://github.com/googleapis/python-storage/compare/v2.1.0...v2.2.0"">2.2.0</a> (2022-03-14)</h2>; <h3>Features</h3>; <ul>; <li>allow no project in client methods using storage emulator (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/703"">#703</a>) (<a href=""https://github.com/googleapis/python-storage/commit/bcde0ec619d7d303892bcc0863b7f977c79f7649"">bcde0ec</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <ul>; <li>add user agent in python-storage when calling resumable media (<a href=""https://github.com/googleapis/python-storage/commit/c7bf615909a04f3bab3efb1047a9f4ba659bba19"">c7bf615</a>)</li>; <li><strong>deps:</strong> require google-api-core&gt;=1.31.5, &gt;=2.3.2 (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/722"">#722</a>) (<a href=""https://github.com/googleapis/python-storage/commit/e9aab389f868799d4425133954bad4f1cbb85786"">e9aab38</a>)</li>; <li>Fix BlobReader handling of interleaved reads and seeks (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/721"">#721</a>) (<a href=""https://github.com/googleapis/python-storage/commit/5d1cfd2050321481a3bc4acbe80537ea666506fa"">5d1cfd2</a>)</li>; <li>retry client side requests timeout (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/727"">#727</a>) (<a href=""https://github.com/googleapis/python-storage/commit/e0b3b354d51e4be7c563d7f2f628a7139df842c0"">e0b3b35</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>fixed download_blob_to_file example (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/704"">#704</a>) (<a href=""https://github.com/googleapis/python-storage/commit/2c94d98ed21cc768cfa54fac3d734254fc4d8480"">2c94",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11578:3089,depend,dependabot,3089,https://hail.is,https://github.com/hail-is/hail/pull/11578,1,['depend'],['dependabot']
Integrability,"/a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/9683c1a82add3182be967050d164349da426a20f""><code>9683c1a</code></a> Backport test case from #python/cpython/96358 (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/71"">#71</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/db79268673ac10412b4aad19efea03948869b7db""><code>db79268</code></a> Silence a <code>flake8-bugbear</code> warning (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/72"">#72</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/python/typing_extensions/compare/4.3.0...4.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=typing-extensions&package-manager=pip&previous-version=4.3.0&new-version=4.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12288:4434,depend,dependabot-security-updates,4434,https://hail.is,https://github.com/hail-is/hail/pull/12288,1,['depend'],['dependabot-security-updates']
Integrability,"/a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp_session/compare/v2.7.0...v2.11.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp-session&package-manager=pip&previous-version=2.7.0&new-version=2.11.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11544:5084,Depend,Dependabot,5084,https://hail.is,https://github.com/hail-is/hail/pull/11544,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"/a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp_session/compare/v2.7.0...v2.12.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp-session&package-manager=pip&previous-version=2.7.0&new-version=2.12.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12499:5651,Depend,Dependabot,5651,https://hail.is,https://github.com/hail-is/hail/pull/12499,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"/a>)</li>; <li>Clean up 7.x workflows <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/865"">#865</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_client/graphs/contributors?from=2022-10-25&amp;to=2022-11-10&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Ablink1073+updated%3A2022-10-25..2022-11-10&amp;type=Issues""><code>@​blink1073</code></a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/f71daff259071f3077810d9a4256876b441f5ab5""><code>f71daff</code></a> Publish 7.4.6</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/3394591f161be4a19f9e61c66ba510d7e29afd59""><code>3394591</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/879"">#879</a> on branch 7.x (Reconcile connection information) (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/881"">#881</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/763ff5f8c1132d3da913bf05e19b87efa8e35bf6""><code>763ff5f</code></a> Publish 7.4.5</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/d27c8a497c6cbb1a232fbbe75cb1fd0f53faa9b0""><code>d27c8a4</code></a> [7.x] Handle Jupyter Core Warning (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/875"">#875</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/46f3f8c34f272629c45beba9884053680f213cfd""><code>46f3f8c</code></a> Clean up 7.x workflows (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/865"">#865</a>)</li>; <li>See full diff in <a href=""https://github.com/jupyter/jupyter_client/compare/v7.4.4...v7.4.6"">compare view</a></li>; </ul>; </detai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12467:4540,depend,dependabot,4540,https://hail.is,https://github.com/hail-is/hail/pull/12467,1,['depend'],['dependabot']
Integrability,"/a>.</em></p>; <blockquote>; <h1>2.17.0 - 2022-01-18</h1>; <h3>Features</h3>; <ul>; <li>add warnings for regexes containing <code>[\\/]</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2151"">#2151</a> issue by <a href=""https://github.com/sanjioh""><code>@​sanjioh</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2154"">#2154</a> PR by <a href=""https://github.com/kuviokelluja""><code>@​kuviokelluja</code></a>.</li>; </ul>; </li>; <li>upgrade supported ruby versions.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2205"">#2205</a> PR by <a href=""https://github.com/jalessio""><code>@​jalessio</code></a>.</li>; </ul>; </li>; <li>allow <code>language: conda</code> to use <code>mamba</code> or <code>micromamba</code> via; <code>PRE_COMMIT_USE_MAMBA=1</code> or <code>PRE_COMMIT_USE_MICROMAMBA=1</code> respectively.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2204"">#2204</a> issue by <a href=""https://github.com/janjagusch""><code>@​janjagusch</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2207"">#2207</a> PR by <a href=""https://github.com/xhochy""><code>@​xhochy</code></a>.</li>; </ul>; </li>; <li>display <code>git --version</code> in error report.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2210"">#2210</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>add <code>language: lua</code> as a supported language.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2158"">#2158</a> PR by <a href=""https://github.com/mblayman""><code>@​mblayman</code></a>.</li>; </ul>; </li>; </ul>; <h3>Fixes</h3>; <ul>; <li>temporarily add <code>setuptools</code> to the zipapp.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11460:7705,depend,dependabot,7705,https://hail.is,https://github.com/hail-is/hail/pull/11460,2,['depend'],['dependabot']
Integrability,"/a>.</em></p>; <blockquote>; <h2>v5.0.1</h2>; <p>Changelog: <a href=""https://www.sphinx-doc.org/en/master/changes.html"">https://www.sphinx-doc.org/en/master/changes.html</a></p>; <h2>v5.0.0b1</h2>; <p>Changelog: <a href=""https://www.sphinx-doc.org/en/master/changes.html"">https://www.sphinx-doc.org/en/master/changes.html</a></p>; <h2>v4.5.0</h2>; <p>Changelog: <a href=""https://www.sphinx-doc.org/en/master/changes.html"">https://www.sphinx-doc.org/en/master/changes.html</a></p>; <h2>v4.4.0</h2>; <p>Changelog: <a href=""https://www.sphinx-doc.org/en/master/changes.html"">https://www.sphinx-doc.org/en/master/changes.html</a></p>; <h2>v4.3.1</h2>; <p>No release notes provided.</p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/sphinx-doc/sphinx/blob/5.x/CHANGES"">sphinx's changelog</a>.</em></p>; <blockquote>; <h1>Release 5.0.1 (released Jun 03, 2022)</h1>; <h2>Bugs fixed</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10498"">#10498</a>: gettext: TypeError is raised when sorting warning messages if a node; has no line number</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10493"">#10493</a>: html theme: :rst:dir:<code>topic</code> directive is rendered incorrectly with; docutils-0.18</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10495"">#10495</a>: IndexError is raised for a :rst:role:<code>kbd</code> role having a separator</li>; </ul>; <h1>Release 5.0.0 (released May 30, 2022)</h1>; <h2>Dependencies</h2>; <p>5.0.0 b1</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10164"">#10164</a>: Support <code>Docutils 0.18</code>_. Patch by Adam Turner.</li>; </ul>; <p>.. _Docutils 0.18: <a href=""https://docutils.sourceforge.io/RELEASE-NOTES.html#release-0-18-2021-10-26"">https://docutils.sourceforge.io/RELEASE-NOTES.html#release-0-18-2021-10-26</a></p>; <h2>Incompatible",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11885:1209,depend,dependabot,1209,https://hail.is,https://github.com/hail-is/hail/pull/11885,1,['depend'],['dependabot']
Integrability,"/a>.</p>; <h3>Highlights</h3>; <ul>; <li><strong>Remove Python 2 support</strong> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2740"">#2740</a>)</li>; <li>Introduce the <code>--preview</code> flag (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2752"">#2752</a>)</li>; </ul>; <h3>Style</h3>; <ul>; <li>Deprecate <code>--experimental-string-processing</code> and move the functionality under; <code>--preview</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2789"">#2789</a>)</li>; <li>For stubs, one blank line between class attributes and methods is now kept if there's; at least one pre-existing blank line (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2736"">#2736</a>)</li>; <li>Black now normalizes string prefix order (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2297"">#2297</a>)</li>; <li>Remove spaces around power operators if both operands are simple (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2726"">#2726</a>)</li>; <li>Work around bug that causes unstable formatting in some cases in the presence of the; magic trailing comma (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2807"">#2807</a>)</li>; <li>Use parentheses for attribute access on decimal float and int literals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2799"">#2799</a>)</li>; <li>Don't add whitespace for attribute access on hexadecimal, binary, octal, and complex; literals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2799"">#2799</a>)</li>; <li>Treat blank lines in stubs the same inside top-level <code>if</code> statements (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2820"">#2820</a>)</li>; <li>Fix unstable formatting with semicolons and arithmetic expressions (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2817"">#2817</a>)</li>; <li>Fix unstable formatting around magic trailing comma (<a href=""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11468:8464,depend,dependabot,8464,https://hail.is,https://github.com/hail-is/hail/pull/11468,1,['depend'],['dependabot']
Integrability,"/a>: Add <code>CertOpenStore</code> to <code>c.s.j.p.win32.Crypt32</code> - <a href=""https://github.com/shalupov""><code>@​shalupov</code></a></li>; </ul>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1411"">#1411</a>: Do not throw <code>Win32Exception</code> on success for empty section in <code>Kernel32Util#getPrivateProfileSection</code> - <a href=""https://github.com/mkarg""><code>@​mkarg</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1414"">#1414</a>: Fix definition of <code>c.s.j.p.unix.X11.XK_Shift_R</code> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1323"">#1323</a>. Fix crashes in direct callbacks on mac OS aarch64 - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1422"">#1422</a>: Load jawt library relative to <code>sun.boot.library.path</code> system on unix OSes - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1427"">#1427</a>: Rebuild all binaries with fix from <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1422"">#1422</a> and <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1323"">#1323</a> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; </ul>; <h1>Release 5.10.0</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/java-native-access/jna/commit/3705b849892aa3c37e5608e640eff19047811a5c""><code>3705b84</code></a> Release 5.12.1</li>; <li><a href=""https://github.com/java-native-access",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:4767,depend,dependabot,4767,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['depend'],['dependabot']
Integrability,"/a>: Do not throw <code>Win32Exception</code> on success for empty section in <code>Kernel32Util#getPrivateProfileSection</code> - <a href=""https://github.com/mkarg""><code>@​mkarg</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1414"">#1414</a>: Fix definition of <code>c.s.j.p.unix.X11.XK_Shift_R</code> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1323"">#1323</a>. Fix crashes in direct callbacks on mac OS aarch64 - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1422"">#1422</a>: Load jawt library relative to <code>sun.boot.library.path</code> system on unix OSes - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1427"">#1427</a>: Rebuild all binaries with fix from <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1422"">#1422</a> and <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1323"">#1323</a> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; </ul>; <h1>Release 5.10.0</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/java-native-access/jna/commit/3705b849892aa3c37e5608e640eff19047811a5c""><code>3705b84</code></a> Release 5.12.1</li>; <li><a href=""https://github.com/java-native-access/jna/commit/2f919e56bad203494fe9589206d6d23f27ef4f26""><code>2f919e5</code></a> Null-check cleanable in Memory#close (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1447"">#1447</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:5040,depend,dependabot,5040,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['depend'],['dependabot']
Integrability,"/a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.github.samtools:htsjdk&package-manager=gradle&previous-version=3.0.4&new-version=4.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13576:9506,depend,dependabot,9506,https://hail.is,https://github.com/hail-is/hail/pull/13576,11,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"/a></li>; <li><a href=""https://github.com/python/importlib_resources/commit/99f5d8f95488a2bd18a053509b168084b8ff10a7""><code>99f5d8f</code></a> Merge <a href=""https://github.com/jaraco/skeleton"">https://github.com/jaraco/skeleton</a></li>; <li><a href=""https://github.com/python/importlib_resources/commit/fea1e7cdd57d330f22ac54512ae2df19083c6ec7""><code>fea1e7c</code></a> Ran pre-commit autoupdate</li>; <li><a href=""https://github.com/python/importlib_resources/commit/ccbb0d396b0057ee70a3e8f36b7e8418c211c826""><code>ccbb0d3</code></a> Docs: Change isdir() to is_dir()</li>; <li><a href=""https://github.com/python/importlib_resources/commit/79d452444f9d83d01bd76bb8bbba5138de06521e""><code>79d4524</code></a> Merge <a href=""https://github.com/jaraco/skeleton"">https://github.com/jaraco/skeleton</a></li>; <li>Additional commits viewable in <a href=""https://github.com/python/importlib_resources/compare/v5.7.1...v5.9.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=importlib-resources&package-manager=pip&previous-version=5.7.1&new-version=5.9.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot canc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12141:3717,Depend,Dependabot,3717,https://hail.is,https://github.com/hail-is/hail/pull/12141,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"/a></p>; <ul>; <li>Deprecated the <code>urllib3.contrib.ntlmpool</code> module. urllib3 is not able to support it properly due to <a href=""https://github-redirect.dependabot.com/urllib3/urllib3/issues/2282"">reasons listed in this issue</a>. If you are a user of this module please leave a comment.</li>; <li>Changed <code>HTTPConnection.request_chunked()</code> to not erroneously emit multiple <code>Transfer-Encoding</code> headers in the case that one is already specified.</li>; <li>Fixed typo in deprecation message to recommend <code>Retry.DEFAULT_ALLOWED_METHODS</code>.</li>; </ul>; <p><strong>If you or your organization rely on urllib3 consider supporting us via <a href=""https://github.com/sponsors/urllib3"">GitHub Sponsors</a></strong></p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/urllib3/urllib3/blob/main/CHANGES.rst"">urllib3's changelog</a>.</em></p>; <blockquote>; <h2>1.26.8 (2022-01-07)</h2>; <ul>; <li>Added extra message to <code>urllib3.exceptions.ProxyError</code> when urllib3 detects that; a proxy is configured to use HTTPS but the proxy itself appears to only use HTTP.</li>; <li>Added a mention of the size of the connection pool when discarding a connection due to the pool being full.</li>; <li>Added explicit support for Python 3.11.</li>; <li>Deprecated the <code>Retry.MAX_BACKOFF</code> class property in favor of <code>Retry.DEFAULT_MAX_BACKOFF</code>; to better match the rest of the default parameter names. <code>Retry.MAX_BACKOFF</code> is removed in v2.0.</li>; <li>Changed location of the vendored <code>ssl.match_hostname</code> function from <code>urllib3.packages.ssl_match_hostname</code>; to <code>urllib3.util.ssl_match_hostname</code> to ensure Python 3.10+ compatibility after being repackaged; by downstream distributors.</li>; <li>Fixed absolute imports, all imports are now relative.</li>; </ul>; <h1>1.26.7 (2021-09-22)</h1>; <ul>; <li>Fixed a bug with HTTPS hostname veri",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11532:3457,message,message,3457,https://hail.is,https://github.com/hail-is/hail/pull/11532,1,['message'],['message']
Integrability,"/add-pyproject.toml</li>; <li>Additional commits viewable in <a href=""https://github.com/python-pillow/Pillow/compare/9.5.0...10.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pillow&package-manager=pip&previous-version=9.5.0&new-version=10.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13321:15390,Depend,Dependabot,15390,https://hail.is,https://github.com/hail-is/hail/pull/13321,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"/aio-libs/aiomysql/issues/418"">#418</a> <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/437"">#437</a></p>; </li>; <li>; <p>Ignore pyenv's .python-version file <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/424"">#424</a></p>; </li>; <li>; <p>Replace asyncio.streams.IncompleteReadError with asyncio.IncompleteReadError <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/460"">#460</a> <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/454"">#454</a></p>; </li>; <li>; <p>Add support for SQLAlchemy default parameters <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/455"">#455</a> <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/466"">#466</a></p>; </li>; <li>; <p>Update dependencies <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/485"">#485</a></p>; </li>; <li>; <p>Support Python 3.7 &amp; 3.8 <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/493"">#493</a></p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiomysql/blob/master/CHANGES.txt"">aiomysql's changelog</a>.</em></p>; <blockquote>; <p>0.0.22 (2021-11-14); ^^^^^^^^^^^^^^^^^^^</p>; <ul>; <li>Support python 3.10 <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/505"">#505</a></li>; </ul>; <p>0.0.21 (2020-11-26); ^^^^^^^^^^^^^^^^^^^</p>; <ul>; <li>; <p>Allow to use custom Cursor subclasses <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/374"">#374</a></p>; </li>; <li>; <p>Fill Connection class with actual client version <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/388"">#388</a></p>; </li>; <li>; <p>Fix legacy <strong>aiter</strong> methods <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/403"">#403</a></p>; </li>; <li>; <p>Fix &amp; update docs <a hre",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11543:1824,depend,dependabot,1824,https://hail.is,https://github.com/hail-is/hail/pull/11543,1,['depend'],['dependabot']
Integrability,"/aio-libs/aiomysql/issues/418"">#418</a> <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/437"">#437</a></p>; </li>; <li>; <p>Ignore pyenv's .python-version file <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/424"">#424</a></p>; </li>; <li>; <p>Replace asyncio.streams.IncompleteReadError with asyncio.IncompleteReadError <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/460"">#460</a> <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/454"">#454</a></p>; </li>; <li>; <p>Add support for SQLAlchemy default parameters <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/455"">#455</a> <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/466"">#466</a></p>; </li>; <li>; <p>Update dependencies <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/485"">#485</a></p>; </li>; <li>; <p>Support Python 3.7 &amp; 3.8 <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/493"">#493</a></p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiomysql/commit/81aadb22ba0222570e96037d47caaa2c41dfe4de""><code>81aadb2</code></a> Bump to 0.22.0</li>; <li><a href=""https://github.com/aio-libs/aiomysql/commit/87e1fdd13c7230da1f03805395546ca0620687bb""><code>87e1fdd</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/631"">#631</a> from albertyw/python-3-10</li>; <li><a href=""https://github.com/aio-libs/aiomysql/commit/0c12aa37c6b9fe152d1fc86d0998fbbf22b1edd5""><code>0c12aa3</code></a> Update changelog</li>; <li><a href=""https://github.com/aio-libs/aiomysql/commit/f053640dc7766af8a1d472b0765fd33710faf4d6""><code>f053640</code></a> Remove broken loop argument</li>; <li><a href=""https://github.com/aio-libs/aiomysql/commit/0a8af2355562ea961477738d66b3334332447186""><code>0a8af23</code></a> Bump version and tweak se",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11543:3866,depend,dependabot,3866,https://hail.is,https://github.com/hail-is/hail/pull/11543,1,['depend'],['dependabot']
Integrability,"/aio-libs/aioredis-py/commit/33b2dbd0a40ac148e6a36ba2fc7ab5d438a9a71d""><code>33b2dbd</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1201"">#1201</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/a708bd14b1a8bec0a1f3d469bf5384eb2726b5fa""><code>a708bd1</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1162"">#1162</a> from aio-libs/dependabot/pip/flake8-4.0.1</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/5d51d8d9675bce935e3a0373875a6a9b52f7be0c""><code>5d51d8d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1198"">#1198</a> from aio-libs/dependabot/pip/docs/mkdocs-1.2.3</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aioredis-py/compare/v1.3.1...v2.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aioredis&package-manager=pip&previous-version=1.3.1&new-version=2.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` w",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11569:6674,Depend,Dependabot,6674,https://hail.is,https://github.com/hail-is/hail/pull/11569,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"/aio-libs/aiorwlock/issues/250"">#250</a>)</li>; <li><a href=""https://github.com/aio-libs/aiorwlock/commit/63f68eb11d293a5e15133ef933304eddf61753e7""><code>63f68eb</code></a> Bump pytest-asyncio from 0.16.0 to 0.17.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiorwlock/issues/249"">#249</a>)</li>; <li><a href=""https://github.com/aio-libs/aiorwlock/commit/34092ffd1f8927d68dc3e3e9f2a0bfddbdc3a382""><code>34092ff</code></a> Bump flake8-bugbear from 21.11.29 to 22.1.11 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiorwlock/issues/248"">#248</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiorwlock/compare/v1.0.0...v1.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiorwlock&package-manager=pip&previous-version=1.0.0&new-version=1.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11514:3835,depend,dependabot-security-updates,3835,https://hail.is,https://github.com/hail-is/hail/pull/11514,1,['depend'],['dependabot-security-updates']
Integrability,"/aiohttp-session/commit/3bc517092aff39330f2f96315e6f542e23415831""><code>3bc5170</code></a> Bump multidict from 5.2.0 to 6.0.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/670"">#670</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp_session/compare/v2.7.0...v2.11.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp-session&package-manager=pip&previous-version=2.7.0&new-version=2.11.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11544:5017,Depend,Dependabot,5017,https://hail.is,https://github.com/hail-is/hail/pull/11544,1,['Depend'],['Dependabot']
Integrability,"/aiohttp/commit/c0f9017a9a34a7823e1ea9b9abb393bd6c10777b""><code>c0f9017</code></a> [PR <a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7821"">#7821</a>/366ba40f backport][3.9] Only check origin if insecure scheme and th...</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/9d498ca1e632fe1976ea1dae0ea083b29b0cc4c0""><code>9d498ca</code></a> Bump sphinx from 7.1.1 to 7.2.6 (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7606"">#7606</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.8.6...v3.9.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.8.6&new-version=3.9.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ign",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14027:9985,Depend,Dependabot,9985,https://hail.is,https://github.com/hail-is/hail/pull/14027,6,['Depend'],['Dependabot']
Integrability,"/aiohttp_session/issues/768"">#768</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/45a614ccf31aa7b2bf353a3d08d07566879875cf""><code>45a614c</code></a> Bump flake8-bugbear from 22.10.25 to 22.10.27 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/767"">#767</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/c24376e53a167156915bdf931f6e92def20bf0fd""><code>c24376e</code></a> Allow partial backward-compatibility with aioredis, with warning (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/766"">#766</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/5695c127b78bd38ec80eba89779488962d1d3493""><code>5695c12</code></a> Update <strong>init</strong>.py</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/5e532eb909cbc0ab344d1fe0409de8f87cf7cdc9""><code>5e532eb</code></a> Updated documentation for redis module (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/761"">#761</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/f25b7508b4ba0cdfef2f99888bd40f1beb2ae0a7""><code>f25b750</code></a> Bump pytest from 7.1.3 to 7.2.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/765"">#765</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/970cd31ce41162d9893c975f05e7082d32a4cece""><code>970cd31</code></a> Bump flake8-bugbear from 22.9.23 to 22.10.25 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/764"">#764</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/bf16648feca6571649849bca65ca1d9b36f8b417""><code>bf16648</code></a> Bump types-redis from 4.3.21.2 to 4.3.21.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/762"">#762</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/07a709a0f408e54b294b28b81968d2b79f188290""><code>07a709a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12499:3675,depend,dependabot,3675,https://hail.is,https://github.com/hail-is/hail/pull/12499,1,['depend'],['dependabot']
Integrability,"/aiomysql/commit/0a8af2355562ea961477738d66b3334332447186""><code>0a8af23</code></a> Bump version and tweak setup.py (<a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/540"">#540</a>)</li>; <li><a href=""https://github.com/aio-libs/aiomysql/commit/0fc109d16c939a7dd06ef2abf078632f7b336c39""><code>0fc109d</code></a> Fill changelog for 0.0.21 release (<a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/538"">#538</a>)</li>; <li><a href=""https://github.com/aio-libs/aiomysql/commit/d842ec3f95614a2042a9107d7b65edfcf661d614""><code>d842ec3</code></a> Fix tests to pass under Python 3.7 and 3.8</li>; <li><a href=""https://github.com/aio-libs/aiomysql/commit/e4cba8f07c95b5f655b01cacc3103626db9eba11""><code>e4cba8f</code></a> Support python 3.7 and 3.8 in tests and travis CI</li>; <li><a href=""https://github.com/aio-libs/aiomysql/commit/f9b86aa08576c677afe16caf41aa2ab685b0f995""><code>f9b86aa</code></a> Update dependencies (<a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/485"">#485</a>)</li>; <li><a href=""https://github.com/aio-libs/aiomysql/commit/e3c1bb808d0af308e21d2488be75a40dfd054b78""><code>e3c1bb8</code></a> chore(flake8): fixed flake8 errors (<a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/484"">#484</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiomysql/compare/v0.0.20...v0.0.22"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiomysql&package-manager=pip&previous-version=0.0.20&new-version=0.0.22)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11543:5758,depend,dependabot,5758,https://hail.is,https://github.com/hail-is/hail/pull/11543,1,['depend'],['dependabot']
Integrability,"/aiomysql/issues/466"">#466</a></p>; </li>; <li>; <p>Update dependencies <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/485"">#485</a></p>; </li>; <li>; <p>Support Python 3.7 &amp; 3.8 <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/493"">#493</a></p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiomysql/blob/master/CHANGES.txt"">aiomysql's changelog</a>.</em></p>; <blockquote>; <p>0.0.22 (2021-11-14); ^^^^^^^^^^^^^^^^^^^</p>; <ul>; <li>Support python 3.10 <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/505"">#505</a></li>; </ul>; <p>0.0.21 (2020-11-26); ^^^^^^^^^^^^^^^^^^^</p>; <ul>; <li>; <p>Allow to use custom Cursor subclasses <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/374"">#374</a></p>; </li>; <li>; <p>Fill Connection class with actual client version <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/388"">#388</a></p>; </li>; <li>; <p>Fix legacy <strong>aiter</strong> methods <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/403"">#403</a></p>; </li>; <li>; <p>Fix &amp; update docs <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/418"">#418</a> <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/437"">#437</a></p>; </li>; <li>; <p>Ignore pyenv's .python-version file <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/424"">#424</a></p>; </li>; <li>; <p>Replace asyncio.streams.IncompleteReadError with asyncio.IncompleteReadError <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/460"">#460</a> <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/454"">#454</a></p>; </li>; <li>; <p>Add support for SQLAlchemy default parameters <a href=""https://github-redirect.dependabot.com/aio-libs/aiomysql/issues/455"">#455</a> <a href=""https:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11543:2577,depend,dependabot,2577,https://hail.is,https://github.com/hail-is/hail/pull/11543,1,['depend'],['dependabot']
Integrability,"/astroid/commit/1f5dc457729d7219178ace9705d8445e89513472""><code>1f5dc45</code></a> Handle <code>dataclass</code> <code>kw_only</code> keyword correctly (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1764"">#1764</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/astroid/compare/v2.11.5...v2.12.9"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=astroid&package-manager=pip&previous-version=2.11.5&new-version=2.12.9)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12161:5379,Depend,Dependabot,5379,https://hail.is,https://github.com/hail-is/hail/pull/12161,1,['Depend'],['Dependabot']
Integrability,"/azure-sdk-for-java/issues/31922"">#31922</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/117395c4d526151c7c5faf7059285de6cd9f1c1b""><code>117395c</code></a> healthCheckImprovement[transitTimeout] (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/31544"">#31544</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-java/compare/azure-core_1.10.0...azure-core-http-netty_1.12.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.azure:azure-core-http-netty&package-manager=gradle&previous-version=1.10.0&new-version=1.12.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12460:4239,depend,dependabot,4239,https://hail.is,https://github.com/hail-is/hail/pull/12460,1,['depend'],['dependabot']
Integrability,"/b64ec22effafffc6a1371e544c560e6bfc24b56e""><code>b64ec22</code></a> Add explicit name in setup.py</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/4f8ef056177513ea599597d4089fed4275ae5d12""><code>4f8ef05</code></a> chore(deps): update actions/checkout action to v3 (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/121"">#121</a>)</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/6389c5acb15153df43b0681cb1333bbd892c3a16""><code>6389c5a</code></a> chore: allow automerge for official GitHub Actions</li>; <li>Additional commits viewable in <a href=""https://github.com/thibaudcolas/curlylint/compare/v0.12.0...v0.13.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=curlylint&package-manager=pip&previous-version=0.12.0&new-version=0.13.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11713:9381,depend,dependabot-security-updates,9381,https://hail.is,https://github.com/hail-is/hail/pull/11713,1,['depend'],['dependabot-security-updates']
Integrability,"/backport-10217-to-7.1.x</li>; <li>Additional commits viewable in <a href=""https://github.com/pytest-dev/pytest/compare/7.1.1...7.1.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest&package-manager=pip&previous-version=7.1.1&new-version=7.1.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12187:6602,Depend,Dependabot,6602,https://hail.is,https://github.com/hail-is/hail/pull/12187,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"/black/issues/2716"">#2716</a>)</li>; <li>Fix call patterns that contain as-expressions with keyword arguments, like <code>case Foo(bar=baz as quux)</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2749"">#2749</a>)</li>; <li>Tuple unpacking on <code>return</code> and <code>yield</code> constructs now implies 3.8+ (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2700"">#2700</a>)</li>; <li>Unparenthesized tuples on annotated assignments (e.g <code>values: Tuple[int, ...] = 1, 2, 3</code>) now implies 3.8+ (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2708"">#2708</a>)</li>; <li>Fix handling of standalone <code>match()</code> or <code>case()</code> when there is a trailing newline or a comment inside of the parentheses. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2760"">#2760</a>)</li>; <li><code>from __future__ import annotations</code> statement now implies Python 3.7+ (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2690"">#2690</a>)</li>; </ul>; <h3>Performance</h3>; <ul>; <li>Speed-up the new backtracking parser about 4X in general (enabled when <code>--target-version</code> is set to 3.10 and higher). (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2728"">#2728</a>)</li>; <li>Black is now compiled with mypyc for an overall 2x speed-up. 64-bit Windows, MacOS, and Linux (not including musl) are supported. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/1009"">#1009</a>, <a href=""https://github-redirect.dependabot.com/psf/black/issues/2431"">#2431</a>)</li>; </ul>; <h3>Configuration</h3>; <ul>; <li>Do not accept bare carriage return line endings in pyproject.toml (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2408"">#2408</a>)</li>; <li>Add configuration option (<code>python-cell-magics</code>) to format cells with custom magics in Jupyter Notebooks (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2744"">#2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11468:3910,depend,dependabot,3910,https://hail.is,https://github.com/hail-is/hail/pull/11468,1,['depend'],['dependabot']
Integrability,"/blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pandas-dev/pandas/commit/87cfe4e38bafe7300a6003a1d18bd80f3f77c763""><code>87cfe4e</code></a> RLS: 1.5.0</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/ecc700c8be8e4af2799dc18ce5f7e6328c80e976""><code>ecc700c</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48627"">#48627</a> on branch 1.5.x (DOC: Last changes to release notes for 1....</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/e726483d70938f3bff67e95358841a1f6271b149""><code>e726483</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48619"">#48619</a> on branch 1.5.x (REGR: Loc.setitem with enlargement raises...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/f83e2fe3327ad85ae2e8c4ba469fe98383243dbf""><code>f83e2fe</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48623"">#48623</a> on branch 1.5.x (REGR/DOC: Docs left navbar broke) (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48625"">#48625</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/4fbb05591979055708162994e96fb4c61cf2a8ab""><code>4fbb055</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48601"">#48601</a> on branch 1.5.x (CI: Fix matplolib release issues) (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48617"">#48617</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/aabf6597f45436e9ada915ac15d3708f9d4948ca""><code>aabf659</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48587"">#48587</a> on branch 1.5.x (Fix <code>series.str.startswith(tuple)</code>) (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/48593"">#48593</a>)</li>; <li><a href=""https://github.com",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12292:3428,depend,dependabot,3428,https://hail.is,https://github.com/hail-is/hail/pull/12292,1,['depend'],['dependabot']
Integrability,"/bokeh/bokeh/issues/11670"">#11670</a> [component: bokehjs] [BUG] Duplicate change events for autocomplete_input</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11679"">#11679</a> [BUG] Parallel Plot example with output_backend=&quot;webgl&quot; not working</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11713"">#11713</a> [component: docs] Documentation builds are failing in CI</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11644"">#11644</a> [component: bokehjs] Actually fix clipping in SVG <code>&lt;text&gt;</code> nodes</li>; </ul>; </li>; <li>; <p>tasks:</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11617"">#11617</a> [component: docs] Update Team link in footer</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11658"">#11658</a> [component: build] Support &quot;pip install&quot; from sdist</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11618"">#11618</a> [component: tests] Reduce Tornado imports</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11628"">#11628</a> [component: docs] Correct path in dev guide server instructions</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11652"">#11652</a> [component: build] Update bokehjs' dependencies</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11668"">#11668</a> [component: docs] Add information about mathjax bundle</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11681"">#11681</a> [NO SQUASH] Batch of 3.0 -&gt; 2.4 backports</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11712"">#11712</a> [component: tests] Upgrade baselines to Chrome 94</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11722"">#11722</a> [component: tests] Update visual baselines on MacOS</li>; <li><a href=""https://g",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11540:5469,depend,dependabot,5469,https://hail.is,https://github.com/hail-is/hail/pull/11540,1,['depend'],['dependabot']
Integrability,"/botocore/commit/cc3f1c22f55ba50ca792eb73e7a6f721abdcc5ee""><code>cc3f1c2</code></a> Fix: S3 Object Lambda requests miss x-amz-content-sha256 headers (<a href=""https://github-redirect.dependabot.com/boto/botocore/issues/2819"">#2819</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/boto/botocore/compare/1.29.13...1.29.16"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=botocore&package-manager=pip&previous-version=1.29.13&new-version=1.29.16)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12503:4192,Depend,Dependabot,4192,https://hail.is,https://github.com/hail-is/hail/pull/12503,1,['Depend'],['Dependabot']
Integrability,"/c14bd2aac8e370bc84048a97f17a1ed906523bf9""><code>c14bd2a</code></a> Revert &quot;Merge pull request <a href=""https://github-redirect.dependabot.com/PyCQA/pycodestyle/issues/1041"">#1041</a> from asfaltboy/issue-830-e721-types-regex-in...</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pycodestyle/compare/2.8.0...2.9.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pycodestyle&package-manager=pip&previous-version=2.8.0&new-version=2.9.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12476:4323,Depend,Dependabot,4323,https://hail.is,https://github.com/hail-is/hail/pull/12476,1,['Depend'],['Dependabot']
Integrability,"/check.py"", line 481, in _typecheck; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/matrixtable.py"", line 1956, in write; File ""/share/pkg/spark/2.2.0/install/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/restricted/projectnb/genpro/github/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 196, in deco; hail.utils.java.FatalError: NumberFormatException: For input string: ""-66.2667,0,-25.4754"". Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 48 in stage 2.0 failed 4 times, most recent failure: Lost task 48.3 in stage 2.0 (TID 536, scc-q14.scc.bu.edu, executor 1): is.hail.utils.HailExcput string: ""-66.2667,0,-25.4754""; offending line: chr2 130824417 DEL00068296 AGAACAGGACATCCCAGGCAGCTACAGCCCATC...; at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:17); at is.hail.utils.package$.fatal(package.scala:26); at is.hail.utils.Context.wrapException(Context.scala:23); at is.hail.io.vcf.LoadVCF$$anonfun$parseLines$1$$anon$1.hasNext(LoadVCF.scala:741); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$$anon$1.hasNext(Iterator.scala:1004); at is.hail.rvd.OrderedRVD$$anon$2.hasNext(OrderedRVD.scala:412); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at is.hail.rvd.OrderedRVD$$anonfun$apply$10$$anon$3.hasNext(OrderedRVD.scala:750); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:438); at scala.collection.Iterator$class.foreach(Iterator.scala:893); at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); at is.hail.io.RichRDDRegionValue$$anonfun$5$$anonfun$apply$1$$anonfun$apply$2$$anonfun$apply$3$$anonfun$apply$4.apply(RowStore.scala:774); at is.hail.io.RichRDDRegionValue$$anonfun$5$$anonfun$apply$1$$anonfun$apply$2$$anonfun$apply$3$$anonfun$apply$4.apply(RowStore.scala:767); at is.hail.utils.package$.using(package.scala:576); at is.hail.io.Ric",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3361:2435,wrap,wrapException,2435,https://hail.is,https://github.com/hail-is/hail/issues/3361,1,['wrap'],['wrapException']
Integrability,"/code>).</li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Fix Python 3.10 deprecation warning by importing Iterable from collections.abc (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; </ul>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.12.2"">v0.12.2</a> 2021-03-06</h2>; <h3>Fixed</h3>; <ul>; <li>The <code>image_alt</code> rule no longer crashes when encountering template conditionals in img attributes (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/57"">#57</a>). Thanks to <a href=""https://github.com/adrien-delhorme""><code>@​adrien-delhorme</code></a>.</li>; </ul>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.12.1"">v0.12.1</a> 2021-03-06</h2>; <h3>Fixed</h3>; <ul>; <li>The project’s sdist now includes all needed files to run the test suite (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/49"">#49</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/50"">#50</a>). Thanks to <a href=""https://github.com/jayvdb""><code>@​jayvdb</code></a>.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/20d279d3cba11d64529ee88c5a2092c5c09919b6""><code>20d279d</code></a> Release v0.13.1</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/5bd2922633791277f3073135f779fee3e6684bb4""><code>5bd2922</code></a> Update <code>patch_click</code> to fix compatibility issue with click 8.1.0. Fix <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/132"">#132</a> (#...</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/e16056828523d9af3e13b67243d62830ff03d89d""><code>e160568</code></a> chore(deps): update actions/cache action to v3</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/bce95021c33e9206104512c412751ee435a6606b""><code>bce9502</code></a> chore(deps): up",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11713:6635,depend,dependabot,6635,https://hail.is,https://github.com/hail-is/hail/pull/11713,1,['depend'],['dependabot']
Integrability,"/code>).</li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Fix Python 3.10 deprecation warning by importing Iterable from collections.abc (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; </ul>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.12.2"">v0.12.2</a> 2021-03-06</h2>; <h3>Fixed</h3>; <ul>; <li>The <code>image_alt</code> rule no longer crashes when encountering template conditionals in img attributes (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/57"">#57</a>). Thanks to <a href=""https://github.com/adrien-delhorme""><code>@​adrien-delhorme</code></a>.</li>; </ul>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.12.1"">v0.12.1</a> 2021-03-06</h2>; <h3>Fixed</h3>; <ul>; <li>The project’s sdist now includes all needed files to run the test suite (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/49"">#49</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/50"">#50</a>). Thanks to <a href=""https://github.com/jayvdb""><code>@​jayvdb</code></a>.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/e6f6869fddbf307e3267ac164561c669039d557a""><code>e6f6869</code></a> Release v0.13.0 (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/78"">#78</a>)</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/2afa4b2934c3b61b96259d548c26cd49e03daf24""><code>2afa4b2</code></a> Implement --template-tags CLI flag</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/28316eea40acb6f67f267a0fa1545d81fb3ed59a""><code>28316ee</code></a> Re-add repo token</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/27b6bf942a0e9205d918efff1c6bab87ed80a460""><code>27b6bf9</code></a> Add website .nvmrc for Netlify</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/comm",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11494:5015,depend,dependabot,5015,https://hail.is,https://github.com/hail-is/hail/pull/11494,2,['depend'],['dependabot']
Integrability,"/code>, and for optionally overriding the default deprecation warning with a <code>spec.versions[*].deprecationWarning</code> field. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92329"">kubernetes/kubernetes#92329</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>) [SIG API Machinery]</li>; <li>EnvVarSource api doc bug fixes (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91194"">kubernetes/kubernetes#91194</a>, <a href=""https://github.com/wawa0210""><code>@​wawa0210</code></a>) [SIG Apps]</li>; <li>Fix bug in reflector that couldn't recover from &quot;Too large resource version&quot; errors (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92537"">kubernetes/kubernetes#92537</a>, <a href=""https://github.com/wojtek-t""><code>@​wojtek-t</code></a>) [SIG API Machinery]</li>; <li>Fixed: log timestamps now include trailing zeros to maintain a fixed width (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91207"">kubernetes/kubernetes#91207</a>, <a href=""https://github.com/iamchuckss""><code>@​iamchuckss</code></a>) [SIG Apps and Node]</li>; <li>Generic ephemeral volumes, a new alpha feature under the <code>GenericEphemeralVolume</code> feature gate, provide a more flexible alternative to <code>EmptyDir</code> volumes: as with <code>EmptyDir</code>, volumes are created and deleted for each pod automatically by Kubernetes. But because the normal provisioning process is used (<code>PersistentVolumeClaim</code>), storage can be provided by third-party storage vendors and all of the usual volume features work. Volumes don't need to be empt; for example, restoring from snapshot is supported. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92784"">kubernetes/kubernetes#92784</a>, <a href=""https://github.com/pohly""><code>@​pohly</code></a>) [SIG API Machinery, Apps, Auth, CLI, Instrumentation, Node, Scheduling, Storage and Testing]</",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:7009,depend,dependabot,7009,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['depend'],['dependabot']
Integrability,"/code></a> Bump astroid to 2.12.7, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/fbe7859ec56ab64cc4d1b2604082878fdfdc8a14""><code>fbe7859</code></a> Fix crash in <code>dataclass</code> brain (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1768"">#1768</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/e194631088aee587140c029a0404f8d40c6765b5""><code>e194631</code></a> Bump astroid to 2.12.6, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/1f5dc457729d7219178ace9705d8445e89513472""><code>1f5dc45</code></a> Handle <code>dataclass</code> <code>kw_only</code> keyword correctly (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1764"">#1764</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/8f8448ee70d968784c3e2b9d622f2b1e8fe61f5d""><code>8f8448e</code></a> Fix a crash involving <code>Uninferable</code> args to <code>namedtuple</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1763"">#1763</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/c313631bca83f7b6eb7dd8990aa702b85eb22d64""><code>c313631</code></a> Bump astroid to 2.12.5, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/8852ecda407598636fcd760877e5a093148e8e67""><code>8852ecd</code></a> Prevent first-party imports from being resolved to <code>site-packages</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1756"">#1756</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/astroid/compare/v2.11.5...v2.12.8"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=astroid&package-manager=pip&previous-version=2.11.5&new-version=2.12.8)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot wi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12158:4131,depend,dependabot,4131,https://hail.is,https://github.com/hail-is/hail/pull/12158,1,['depend'],['dependabot']
Integrability,"/code></a> Fixed implementation of decorator_apply</li>; <li><a href=""https://github.com/micheles/decorator/commit/9cf8151de8fd26551cb43288b2010965ad346839""><code>9cf8151</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/micheles/decorator/issues/137"">#137</a> from borishim/master</li>; <li><a href=""https://github.com/micheles/decorator/commit/5478aa30cfb407684ea111867c3fd4ca829dd54d""><code>5478aa3</code></a> Check with inspect.routine()</li>; <li><a href=""https://github.com/micheles/decorator/commit/d5d65ada05723b3d4999a3aa419aac2f5f02012b""><code>d5d65ad</code></a> Merge branch 'master' of github.com:micheles/decorator</li>; <li><a href=""https://github.com/micheles/decorator/commit/baf129705a56ead40a71b1813003439e06fd1538""><code>baf1297</code></a> Fixed the ContextManager</li>; <li><a href=""https://github.com/micheles/decorator/commit/f3daf42a7928e157e1e0b8ec6840f68af5d20a83""><code>f3daf42</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/micheles/decorator/issues/135"">#135</a> from arthurzam/master</li>; <li><a href=""https://github.com/micheles/decorator/commit/a3a8c1d573cc4abc4c05c2b6ccbaa6ba0153b909""><code>a3a8c1d</code></a> setup.cfg: Replace dashes with underscores</li>; <li><a href=""https://github.com/micheles/decorator/commit/d37eebca8c7b094d65c696aec6bc89a9df50324f""><code>d37eebc</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/micheles/decorator/issues/134"">#134</a> from hugovk/master</li>; <li><a href=""https://github.com/micheles/decorator/commit/7002507b86f90a79777d65129e39c4cce96587e2""><code>7002507</code></a> Add support for Python 3.10</li>; <li>Additional commits viewable in <a href=""https://github.com/micheles/decorator/compare/decorator-3.4.0...5.1.1"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11490:3924,depend,dependabot,3924,https://hail.is,https://github.com/hail-is/hail/pull/11490,1,['depend'],['dependabot']
Integrability,"/code></a> Release v0.13.1</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/5bd2922633791277f3073135f779fee3e6684bb4""><code>5bd2922</code></a> Update <code>patch_click</code> to fix compatibility issue with click 8.1.0. Fix <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/132"">#132</a> (#...</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/e16056828523d9af3e13b67243d62830ff03d89d""><code>e160568</code></a> chore(deps): update actions/cache action to v3</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/bce95021c33e9206104512c412751ee435a6606b""><code>bce9502</code></a> chore(deps): update dependency prettier to v2.6.1</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/c7ebbaedf5bc6a8c562a46941681d7bc8598497b""><code>c7ebbae</code></a> chore(deps): update dependency prettier to v2.6.0</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/efd710b42cf0982582bb8a4f345ccfa967866b97""><code>efd710b</code></a> chore(deps): update dependency coverage to v6.3.2</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/438cf6131c1784de8bc9b34970beace1ec7c52af""><code>438cf61</code></a> Update tested Python versions on GitHub (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/122"">#122</a>)</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/b64ec22effafffc6a1371e544c560e6bfc24b56e""><code>b64ec22</code></a> Add explicit name in setup.py</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/4f8ef056177513ea599597d4089fed4275ae5d12""><code>4f8ef05</code></a> chore(deps): update actions/checkout action to v3 (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/121"">#121</a>)</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/6389c5acb15153df43b0681cb1333bbd892c3a16""><code>6389c5a</code></a> chore: allow automerge for official GitHub Actions</li>; <li>Additional com",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11713:8016,depend,dependency,8016,https://hail.is,https://github.com/hail-is/hail/pull/11713,1,['depend'],['dependency']
Integrability,"/code></a> Security fix for ReDoS (<a href=""https://github-redirect.dependabot.com/axios/axios/issues/3980"">#3980</a>)</li>; <li><a href=""https://github.com/axios/axios/commit/5bc9ea24dda14e74def0b8ae9cdb3fa1a0c77773""><code>5bc9ea2</code></a> Update ECOSYSTEM.md (<a href=""https://github-redirect.dependabot.com/axios/axios/issues/3817"">#3817</a>)</li>; <li><a href=""https://github.com/axios/axios/commit/e72813a385c32e4c3eeaeb4fcc4437dd124bbbcf""><code>e72813a</code></a> Fixing README.md (<a href=""https://github-redirect.dependabot.com/axios/axios/issues/3818"">#3818</a>)</li>; <li><a href=""https://github.com/axios/axios/commit/e10a0270e988a641ba0f01509c4c3ba657afe5a5""><code>e10a027</code></a> Fix README typo under Request Config (<a href=""https://github-redirect.dependabot.com/axios/axios/issues/3825"">#3825</a>)</li>; <li><a href=""https://github.com/axios/axios/commit/e091491127893a476b0223ab72f788c3b30fc082""><code>e091491</code></a> Update README.md (<a href=""https://github-redirect.dependabot.com/axios/axios/issues/3936"">#3936</a>)</li>; <li><a href=""https://github.com/axios/axios/commit/b42fbad57b093bb7214991161c5355bd46b864d0""><code>b42fbad</code></a> Removed un-needed bracket</li>; <li><a href=""https://github.com/axios/axios/commit/520c8dccdef92cccbe51ea7cd96ad464c6401914""><code>520c8dc</code></a> Updating CI status badge (<a href=""https://github-redirect.dependabot.com/axios/axios/issues/3953"">#3953</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/axios/axios/compare/v0.21.1...v0.21.2"">compare view</a></li>; </ul>; </details>; <details>; <summary>Maintainer changes</summary>; <p>This version was pushed to npm by <a href=""https://www.npmjs.com/~jasonsaayman"">jasonsaayman</a>, a new releaser for axios since your current version.</p>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=axios&package-manager=npm_and_yarn&previous-version=0.21.1&new-version=0.2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:12934,depend,dependabot,12934,https://hail.is,https://github.com/hail-is/hail/pull/11080,2,['depend'],['dependabot']
Integrability,"/code></a> Update armccompiler.py</li>; <li><a href=""https://github.com/numpy/numpy/commit/d93b14e3d7abaa1d837825e51671f817788e120f""><code>d93b14e</code></a> Update test_public_api.py</li>; <li><a href=""https://github.com/numpy/numpy/commit/7662c0789cc6a70d5ad4d950ee2e95f3afef7df6""><code>7662c07</code></a> Update <strong>init</strong>.py</li>; <li><a href=""https://github.com/numpy/numpy/commit/311ab52488a7d096ac3bc4c2de0fdae17ecd13ef""><code>311ab52</code></a> Update armccompiler.py</li>; <li>Additional commits viewable in <a href=""https://github.com/numpy/numpy/compare/v1.21.6...v1.22.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.6&new-version=1.22.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12809:5366,depend,dependabot,5366,https://hail.is,https://github.com/hail-is/hail/pull/12809,1,['depend'],['dependabot']
Integrability,"/code></a> [pipeline] update existing README.md to drop py2 (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23332"">#23332</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/f7136780995ccd504770976549d603b7e6187ced""><code>f713678</code></a> [Storage] Remove batch delete files feature for GA release (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23320"">#23320</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/8479758cd6b1daf4360cf3de19bea70bcb6895dd""><code>8479758</code></a> [Storage] Address comments from API Review for March release (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23294"">#23294</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/eeb2f3b8c7c115337f9d71166aca91db732c931e""><code>eeb2f3b</code></a> [Storage] Add missing SAS permissions to Storage packages (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23179"">#23179</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/038b35f890d2363edc1254ac2ee61918b2b84b66""><code>038b35f</code></a> [Storage] Fix bug with <code>ignore_read_only</code> in <code>start_copy_from_url()</code> (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23141"">#23141</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/5166ee94acdb80f2217a1ce694e169ea2b33219d""><code>5166ee9</code></a> [Storage] Fix <code>upload_blob()</code> from an OS pipe on Linux (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23211"">#23211</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/84cbec033ed8e4df87f44a82dcebb96aa19deac0""><code>84cbec0</code></a> [Storage] Adjust some file-datalake test recordings (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23147"">#23147</a>)</li>; ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11610:4616,depend,dependabot,4616,https://hail.is,https://github.com/hail-is/hail/pull/11610,1,['depend'],['dependabot']
Integrability,"/code></a> [pipeline] update existing README.md to drop py2 (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23332"">#23332</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/f7136780995ccd504770976549d603b7e6187ced""><code>f713678</code></a> [Storage] Remove batch delete files feature for GA release (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23320"">#23320</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/8479758cd6b1daf4360cf3de19bea70bcb6895dd""><code>8479758</code></a> [Storage] Address comments from API Review for March release (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23294"">#23294</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/eeb2f3b8c7c115337f9d71166aca91db732c931e""><code>eeb2f3b</code></a> [Storage] Add missing SAS permissions to Storage packages (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23179"">#23179</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/038b35f890d2363edc1254ac2ee61918b2b84b66""><code>038b35f</code></a> [Storage] Fix bug with <code>ignore_read_only</code> in <code>start_copy_from_url()</code> (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23141"">#23141</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/5166ee94acdb80f2217a1ce694e169ea2b33219d""><code>5166ee9</code></a> [Storage] Fix <code>upload_blob()</code> from an OS pipe on Linux (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23211"">#23211</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-storage-blob_12.8.1...azure-storage-blob_12.11.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compati",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11703:5387,depend,dependabot,5387,https://hail.is,https://github.com/hail-is/hail/pull/11703,1,['depend'],['dependabot']
Integrability,"/code></a> chore: rename rst files to avoid conflict with service names (<a href=""https://redirect.github.com/GoogleCloudPlatform/google-auth-library-python-oauthlib/issues/315"">#315</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/GoogleCloudPlatform/google-auth-library-python-oauthlib/compare/v0.8.0...v1.2.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=google-auth-oauthlib&package-manager=pip&previous-version=0.8.0&new-version=1.2.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14510:11202,Depend,Dependabot,11202,https://hail.is,https://github.com/hail-is/hail/pull/14510,1,['Depend'],['Dependabot']
Integrability,"/code></a> fix typo: 'are specified the' should be 'are specified in the' (<a href=""https://github-redirect.dependabot.com/boto/boto3/issues/3499"">#3499</a>)</li>; <li><a href=""https://github.com/boto/boto3/commit/47f20744b3c57223da5e14e185120586f8212af8""><code>47f2074</code></a> Merge branch 'release-1.26.13'</li>; <li><a href=""https://github.com/boto/boto3/commit/3d4081ccb7c350538ba3d6a5073c59575a812eb0""><code>3d4081c</code></a> Merge branch 'release-1.26.13' into develop</li>; <li>Additional commits viewable in <a href=""https://github.com/boto/boto3/compare/1.26.7...1.26.15"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=boto3&package-manager=pip&previous-version=1.26.7&new-version=1.26.15)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12498:9646,Depend,Dependabot,9646,https://hail.is,https://github.com/hail-is/hail/pull/12498,1,['Depend'],['Dependabot']
Integrability,"/code></a> in <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/354"">spyder-ide/qtpy#354</a></li>; <li>PR: Fix PyQt6 typing import for Qt by <a href=""https://github.com/tlambert03""><code>@​tlambert03</code></a> in <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/358"">spyder-ide/qtpy#358</a></li>; <li>PR: Add initial <code>Methods, helpers and QtPy namespace specifics</code> section to the README by <a href=""https://github.com/dalthviz""><code>@​dalthviz</code></a> in <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/357"">spyder-ide/qtpy#357</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/DaelonSuzuka""><code>@​DaelonSuzuka</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/344"">spyder-ide/qtpy#344</a></li>; <li><a href=""https://github.com/zjp""><code>@​zjp</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/354"">spyder-ide/qtpy#354</a></li>; </ul>; <p><strong>Full commits list between this release and the previous one</strong>: <a href=""https://github.com/spyder-ide/qtpy/compare/v2.1.0...v2.2.0"">https://github.com/spyder-ide/qtpy/compare/v2.1.0...v2.2.0</a>; <strong>Full Changelog</strong>: <a href=""https://github.com/spyder-ide/qtpy/blob/master/CHANGELOG.md#version-220-2022-08-10"">CHANGELOG.md - Version 2.2.0 (2022-08-10)</a></p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/spyder-ide/qtpy/blob/master/CHANGELOG.md"">qtpy's changelog</a>.</em></p>; <blockquote>; <h2>Version 2.2.0 (2022-08-10)</h2>; <h3>Issues Closed</h3>; <ul>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/issues/359"">Issue 359</a> - Release QtPy 2.2.0</li>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/issues/352"">Issue 352</a> - Deprecation Warning for Enum Access (<a href=""htt",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12194:2387,depend,dependabot,2387,https://hail.is,https://github.com/hail-is/hail/pull/12194,1,['depend'],['dependabot']
Integrability,"/code></a> remove badges</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/f65351b1bd6c02eab07f20cbedada6ebfbf6d56d""><code>f65351b</code></a> Do not create universal wheel</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/6e5d5bd94af056c66a1ed05de754a83f8628faea""><code>6e5d5bd</code></a> v1.0.0</li>; <li>Additional commits viewable in <a href=""https://github.com/PyMySQL/PyMySQL/compare/v0.9.2...v1.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pymysql&package-manager=pip&previous-version=0.9.2&new-version=1.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11595:5247,depend,dependabot-automerge-start,5247,https://hail.is,https://github.com/hail-is/hail/pull/11595,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"/code></a>)</li>; <li>Fix kube-proxy regression on UDP services because the logic to detect stale connections was not considering if the endpoint was ready. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/106163"">kubernetes/kubernetes#106163</a>, <a href=""https://github.com/aojea""><code>@​aojea</code></a>) [SIG API Machinery, Apps, Architecture, Auth, Autoscaling, CLI, Cloud Provider, Contributor Experience, Instrumentation, Network, Node, Release, Scalability, Scheduling, Storage, Testing and Windows]</li>; <li>If a conflict occurs when creating an object with <code>generateName</code>, the server now returns an &quot;AlreadyExists&quot; error with a retry option. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104699"">kubernetes/kubernetes#104699</a>, <a href=""https://github.com/vincepri""><code>@​vincepri</code></a>)</li>; <li>Implement support for recovering from volume expansion failures (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/106154"">kubernetes/kubernetes#106154</a>, <a href=""https://github.com/gnufied""><code>@​gnufied</code></a>) [SIG API Machinery, Apps and Storage]</li>; <li>In kubelet, log verbosity and flush frequency can also be configured via the configuration file and not just via command line flags. In other commands (kube-apiserver, kube-controller-manager), the flags are listed in the &quot;Logs flags&quot; group and not under &quot;Global&quot; or &quot;Misc&quot;. The type for <code>-vmodule</code> was made a bit more descriptive (<code>pattern=N,...</code> instead of <code>moduleSpec</code>). (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/106090"">kubernetes/kubernetes#106090</a>, <a href=""https://github.com/pohly""><code>@​pohly</code></a>) [SIG API Machinery, Architecture, CLI, Cluster Lifecycle, Instrumentation, Node and Scheduling]</li>; <li>Introduce <code>OS</code> field in the PodSpec (<a href=""https://github-redirect.depend",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:4657,depend,dependabot,4657,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['depend'],['dependabot']
Integrability,"/code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1442"">#1442</a>: Handle race condition in <code>c.s.j.p.win32.PdhUtil#PdhEnumObjectItems</code> - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; </ul>; <h2>Important Changes</h2>; <ul>; <li><code>Memory#dispose</code>, <code>CallbackReference#dispose</code> and <code>NativeLibrary#dispose</code>; were called by the <code>Object#finalize</code> override. These calls were replaced by; the use of a cleaner. It is not guaranteed anymore, that <code>dispose</code> is called; on subclasses on finalization.</li>; </ul>; <h1>Release 5.11.0</h1>; <h2>Features</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1398"">#1398</a>: Increase <code>c.s.j.p.win32.Sspi#MAX_TOKEN_SIZE</code> on Windows 8/Server 2012 and later - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1403"">#1403</a>: Rebuild AIX binaries with libffi 3.4.2 (other architectures were part of 5.10) - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1404"">#1404</a>: Added Solaris Kstat2 library - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1416"">#1416</a>: Add <code>CFDictionaryGetCount</code> to <code>c.s.j.p.mac.CoreFoundation</code> - <a href=""https://github.com/shalupov""><code>@​shalupov</code></a></li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1418"">#1418</a>: Add <code>CertOpenStore</code> to <code>c.s.j.p.win32.Crypt32</code> - <a href=""https://github.com/shalupov""><code>@​shalupov</code></a></li>; </ul>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:2995,depend,dependabot,2995,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['depend'],['dependabot']
Integrability,"/commit/01bfdd18c2eb8ea34cbb9915cb2bc7d9806f81a4""><code>01bfdd1</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/799"">#799</a> from jupyter/pre-commit-ci-update-config</li>; <li>Additional commits viewable in <a href=""https://github.com/jupyter/jupyter_client/compare/v7.3.1...v7.3.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jupyter-client&package-manager=pip&previous-version=7.3.1&new-version=7.3.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12110:10455,Depend,Dependabot,10455,https://hail.is,https://github.com/hail-is/hail/pull/12110,1,['Depend'],['Dependabot']
Integrability,"/commit/5c52079fb5f52caf39a49ccb96df6251a9c728d3"">5c52079</a>)</li>; <li>Implement GrpcStorageImpl ObjectAccessControl operations (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1818"">#1818</a>) (<a href=""https://github.com/googleapis/java-storage/commit/2eec791122bb1bb28a1ffb14beb7ce8776c5b5ec"">2eec791</a>)</li>; <li>Implement GrpcStorageImpl#createDefaultAcl &amp; GrpcStorageImpl#updateDefaultAcl (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1806"">#1806</a>) (<a href=""https://github.com/googleapis/java-storage/commit/0f24a11c5289a4c07f27d8a3c29fab34520b036f"">0f24a11</a>)</li>; <li>Implement GrpcStorageImpl#deleteDefaultAcl (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1807"">#1807</a>) (<a href=""https://github.com/googleapis/java-storage/commit/c78327717a7936492161ddcc64c86374db72c48c"">c783277</a>)</li>; <li>Implement GrpcStorageImpl#getDefaultAcl (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1802"">#1802</a>) (<a href=""https://github.com/googleapis/java-storage/commit/b9b7c49fcfcab285da156b34b186a007150e876f"">b9b7c49</a>)</li>; <li>Implement GrpcStorageImpl#listDefaultAcl (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1805"">#1805</a>) (<a href=""https://github.com/googleapis/java-storage/commit/03c2e6660721b4a8bfc09b241ef44f3e4e08865b"">03c2e66</a>)</li>; <li>Improve throughput of http based storage#reader between 100 MiB/s and 200 MiB/s (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1799"">#1799</a>) (<a href=""https://github.com/googleapis/java-storage/commit/94cd2887f22f6d1bb82f9929b388c27c63353d77"">94cd288</a>)</li>; <li>Update GrpcBlobReadChannel to allow seek/limit after read (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1834"">#1834</a>) (<a href=""https://github.com/googleapis/java-storage/commit/45dc983a4af8e7feb937263ce611bd34eda37e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12598:2104,depend,dependabot,2104,https://hail.is,https://github.com/hail-is/hail/pull/12598,2,['depend'],['dependabot']
Integrability,"/commit/5da6733a475c436efc11b14889af73b3a0e20379""><code>5da6733</code></a> fix: drop support for grpc-gcp (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/401"">#401</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-core/commit/e92045b7a34b8d0a6374d6b1f67c1c6095ad33c6""><code>e92045b</code></a> chore: test minimum dependencies in python 3.7 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/397"">#397</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-core/commit/0eb727f92314db3c4383754514f75a49ba02e27b""><code>0eb727f</code></a> docs: Fix typo in the BackgroundConsumer docstring (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/395"">#395</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-core/commit/ac266e935bc4e7c6dff250384407e7a60d8dba90""><code>ac266e9</code></a> docs: fix changelog header to consistent size (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/394"">#394</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-core/commit/0c4668df73ac3989170ea5677f906f147a9560d0""><code>0c4668d</code></a> chore: allow releases from older version branches (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/388"">#388</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-core/commit/9be727df7fb19d7264c81eab9cc8b6de63f6117e""><code>9be727d</code></a> chore(main): release 2.8.1 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/386"">#386</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-core/commit/d84d66c2a4107f5f9a20c53e870a27fb1250ea3d""><code>d84d66c</code></a> fix(deps): require protobuf&gt;= 3.15.0, &lt;4.0.0dev (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/385"">#385</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-core/commit/eed844f211ad8c6ab2c4cb0d6f08",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11970:9631,depend,dependabot,9631,https://hail.is,https://github.com/hail-is/hail/pull/11970,1,['depend'],['dependabot']
Integrability,"/commit/6b276e339cd850c5f8c93ff4bdbd305dd963d7bb""><code>6b276e3</code></a> Step in/step over support for IPython. Fixes <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/869"">#869</a></li>; <li><a href=""https://github.com/microsoft/debugpy/commit/a294092d9c6d8459126ecb8f537b6012fb7e7d28""><code>a294092</code></a> Properly stop at line 1 in frame eval mode. Fixes <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/995"">#995</a></li>; <li>Additional commits viewable in <a href=""https://github.com/microsoft/debugpy/compare/v1.6.0...v1.6.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=debugpy&package-manager=pip&previous-version=1.6.0&new-version=1.6.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12103:5739,Depend,Dependabot,5739,https://hail.is,https://github.com/hail-is/hail/pull/12103,2,['Depend'],['Dependabot']
Integrability,"/commit/772054c9cf24e860cf08563ac33caab50e904dd5""><code>772054c</code></a> drop py27 support (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22531"">#22531</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-identity_1.6.0...azure-identity_1.8.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=azure-identity&package-manager=pip&previous-version=1.6.0&new-version=1.8.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11493:5491,Depend,Dependabot,5491,https://hail.is,https://github.com/hail-is/hail/pull/11493,2,['Depend'],['Dependabot']
Integrability,"/commit/894a5c591fa4b56f6e1dfa369948c3b6d25e4178""><code>894a5c5</code></a> Bumping version to 1.26.8</li>; <li><a href=""https://github.com/boto/boto3/commit/dde20184baf312a4f5ca7df08a0d7ce2c5c6e697""><code>dde2018</code></a> Add changelog entries from botocore</li>; <li><a href=""https://github.com/boto/boto3/commit/2d82a0c13d4510a5950dd24b4664e23584a5a364""><code>2d82a0c</code></a> Merge branch 'release-1.26.7'</li>; <li><a href=""https://github.com/boto/boto3/commit/b35796f0522b13bc2f9f293ec93697afe09873e2""><code>b35796f</code></a> Merge branch 'release-1.26.7' into develop</li>; <li><a href=""https://github.com/boto/boto3/commit/b0e241282f308cee430d340dee119af9100325ff""><code>b0e2412</code></a> Bumping version to 1.26.7</li>; <li>Additional commits viewable in <a href=""https://github.com/boto/boto3/compare/1.26.6...1.26.9"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=boto3&package-manager=pip&previous-version=1.26.6&new-version=1.26.9)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` wi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12466:6899,depend,dependency-name,6899,https://hail.is,https://github.com/hail-is/hail/pull/12466,1,['depend'],['dependency-name']
Integrability,"/commit/8c2b4b82d0cade0d37e6a88e2cd2413878e8ebd4""><code>8c2b4b8</code></a> don't strip leading = when parsing cookie</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/7c7ce5cb73f3f7d3b9c09340e4f322aeb583dbc5""><code>7c7ce5c</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/pallets/werkzeug/issues/2585"">#2585</a>)</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/19ae03e6a39b3f63fd08fef4fddae4385cdddf25""><code>19ae03e</code></a> [pre-commit.ci] auto fixes from pre-commit.com hooks</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/a83d3b8bf070810874c8e8d03dcce270666e10fe""><code>a83d3b8</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li>Additional commits viewable in <a href=""https://github.com/pallets/werkzeug/compare/2.2.2...2.2.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=werkzeug&package-manager=pip&previous-version=2.2.2&new-version=2.2.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` wil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12703:5021,depend,dependency-name,5021,https://hail.is,https://github.com/hail-is/hail/pull/12703,1,['depend'],['dependency-name']
Integrability,"/commit/a3ecb44b5346dbf116c5bec5dcf47cd7f459784d""><code>a3ecb44</code></a> update changelog</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/7e1691cd62df0593882480d00eb7e9a7616bb029""><code>7e1691c</code></a> [fix] support <a href=""https://github.com/layer""><code>@​layer</code></a> (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7514"">#7514</a>)</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/4583b170842208bcafcbb095221c8ac12689f739""><code>4583b17</code></a> Update CHANGELOG.md</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/02f60fbebf7cdb036472d1aec8dc9d9f8215cd7a""><code>02f60fb</code></a> [fix]destroy empty component (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7492"">#7492</a>)</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/31e5f8b5de24e2e058cb1a70467c0092e422ee5d""><code>31e5f8b</code></a> [docs] &quot;What's new in Svelte&quot; July newsletter (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7637"">#7637</a>)</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/6f575715073f4a1eb1abdd7a2d22a75ae6017cf7""><code>6f57571</code></a> [feat] add convenience types ComponentType and ComponentProps (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/6770"">#6770</a>)</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/2f562d9e2817d911d0eec437d2b0e45074ec8291""><code>2f562d9</code></a> [docs] use npm create instead of npm init (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7641"">#7641</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/sveltejs/svelte/compare/v3.38.2...v3.49.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=svelte&package-manager=npm_and_yarn&previous-version=3.38.2&new-version=3.49.0)](https://docs.github.com/en/github/managing-security-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12032:7874,depend,dependabot,7874,https://hail.is,https://github.com/hail-is/hail/pull/12032,3,['depend'],['dependabot']
Integrability,"/commit/b08cd4bc64bb980df86ed2876978ae5735572280""><code>b08cd4b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/jinja/issues/1660"">#1660</a> from pallets/release-3.1.2</li>; <li><a href=""https://github.com/pallets/jinja/commit/1e68ba86177504bb6404288610608b855eab93fa""><code>1e68ba8</code></a> release version 3.1.2</li>; <li><a href=""https://github.com/pallets/jinja/commit/8efee35092404ba67ede8316566be4f430e7b61d""><code>8efee35</code></a> pre-commit updates latest release branch</li>; <li><a href=""https://github.com/pallets/jinja/commit/a24df26d54fa2ccbe9bdaa0bb9419075a00e2699""><code>a24df26</code></a> ignore new mypy finding</li>; <li><a href=""https://github.com/pallets/jinja/commit/9faee281ea75694e28c33e2878879b322359d411""><code>9faee28</code></a> update requirements</li>; <li><a href=""https://github.com/pallets/jinja/commit/b802b5a6ad9deea082c16d9adb6417eda1a184d8""><code>b802b5a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/jinja/issues/1655"">#1655</a> from dvitek/dvitek/issue1654</li>; <li><a href=""https://github.com/pallets/jinja/commit/746bb95780c17687b27b6d1bf4df1216f0da972c""><code>746bb95</code></a> Fix race conditions in FileSystemBytecodeCache</li>; <li><a href=""https://github.com/pallets/jinja/commit/466a200ea40642b674db77588d13889abbad55f5""><code>466a200</code></a> update requirements</li>; <li><a href=""https://github.com/pallets/jinja/commit/990602f719b4086540287e95f601baefd830d790""><code>990602f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/jinja/issues/1647"">#1647</a> from Tom-Brouwer/202204/add-missing-overlay-options</li>; <li><a href=""https://github.com/pallets/jinja/commit/5d3d2414710c1439105d84efc58e4aba8e453cb3""><code>5d3d241</code></a> fix flake8-bugbear finding</li>; <li>Additional commits viewable in <a href=""https://github.com/pallets/jinja/compare/3.0.3...3.1.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12173:5584,depend,dependabot,5584,https://hail.is,https://github.com/hail-is/hail/pull/12173,1,['depend'],['dependabot']
Integrability,"/commit/c9252cfd111fab8f8361613a8ca518de1207d51a""><code>c9252cf</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/49614"">#49614</a> on branch 1.5.x (CI: Updating website sync to new server) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.5...v1.5.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pandas&package-manager=pip&previous-version=1.3.5&new-version=1.5.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12564:6291,Depend,Dependabot,6291,https://hail.is,https://github.com/hail-is/hail/pull/12564,1,['Depend'],['Dependabot']
Integrability,"/commit/d8e27393dbf4ed3645ffc3464c9c44f4d8e47534""><code>d8e2739</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/52"">#52</a> from Luflosi/fix-intcomma-with-str-and-ndigits</li>; <li>Additional commits viewable in <a href=""https://github.com/python-humanize/humanize/compare/1.1.0...4.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=humanize&package-manager=pip&previous-version=1.1.0&new-version=4.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12329:7822,Depend,Dependabot,7822,https://hail.is,https://github.com/hail-is/hail/pull/12329,1,['Depend'],['Dependabot']
Integrability,"/commit/e0c5fc02160ae87faf4ba5c2b62be86de6b02cf3""><code>e0c5fc0</code></a> feat: trace improvements (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/450"">#450</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/97e32b67603553fe350b6327455fc9f80b8aa6ce""><code>97e32b6</code></a> fix: allow reading logs from non-project paths (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/444"">#444</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/a760e02371a55d6262e42de9e0222fffa2c7192b""><code>a760e02</code></a> feat: add json_fields extras argument for adding to jsonPayload (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/447"">#447</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/83d9ca8521fe7c470bb6755a48a97496515d7abc""><code>83d9ca8</code></a> feat!: make logging API more friendly to use (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/422"">#422</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/818213e143d6a1941211a48e0b23069a426ac300""><code>818213e</code></a> feat: avoid importing grpc when explicitly disabled (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/416"">#416</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/e1506fa9030776353878048ce562c53bf6ccf7bf""><code>e1506fa</code></a> fix!: api consistency between HTTP and Gapic layers (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/375"">#375</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/6fa17735fe3edb45483ec5e3abd1f53c24ffa881""><code>6fa1773</code></a> feat!: support string-encoded json (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/339"">#339</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/python-logging/comp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11574:12996,depend,dependabot,12996,https://hail.is,https://github.com/hail-is/hail/pull/11574,1,['depend'],['dependabot']
Integrability,"/dateutil/issues/1143"">#1143</a> from mariocj89/pu/2.8.2</li>; <li><a href=""https://github.com/dateutil/dateutil/commit/cf44dd0c66827070cf9dd7b30f126b3ab2e110b5""><code>cf44dd0</code></a> Manual cleanup for 2.8.2 NEWS</li>; <li><a href=""https://github.com/dateutil/dateutil/commit/561167183d4cad190059975e5c0826e3587d3c97""><code>5611671</code></a> Automatic generation of NEWS entries for 2.8.2</li>; <li><a href=""https://github.com/dateutil/dateutil/commit/584b58d58abc7c23aa3c5177f465464cf90d10d7""><code>584b58d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1142"">#1142</a> from mariocj89/pu/typo</li>; <li><a href=""https://github.com/dateutil/dateutil/commit/e960effe35d8cdcf66f5c496fa393bd6692acf60""><code>e960eff</code></a> Fix typo in RELEASING steps</li>; <li><a href=""https://github.com/dateutil/dateutil/commit/1682d23f16b8bdc9ae88d26defdb6b839e97b90d""><code>1682d23</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1141"">#1141</a> from mariocj89/pu/auto-relase</li>; <li><a href=""https://github.com/dateutil/dateutil/commit/b9b8eea6b3a8c0cb6b9ad8f6cd56d10a69fafe97""><code>b9b8eea</code></a> Update information about release signatures</li>; <li><a href=""https://github.com/dateutil/dateutil/commit/ee85831cc25d34ff597cfb3f2d90ce5904dbc561""><code>ee85831</code></a> Build releases with Python 3.9</li>; <li><a href=""https://github.com/dateutil/dateutil/commit/6b337ea412d399fb48771c544b1a6880763b46c6""><code>6b337ea</code></a> Automate cutting new releases</li>; <li><a href=""https://github.com/dateutil/dateutil/commit/9c2ad8f981ece1bdb3d52527f1cb39523b11d862""><code>9c2ad8f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1056"">#1056</a> from ffe4/issue_1029</li>; <li>Additional commits viewable in <a href=""https://github.com/dateutil/dateutil/compare/2.8.1...2.8.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dep",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11518:10167,depend,dependabot,10167,https://hail.is,https://github.com/hail-is/hail/pull/11518,1,['depend'],['dependabot']
Integrability,"/details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **461/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.5 | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3MThjYjgyZC1jNGU3LTRlNWEtODgzZi02NjQ0NjlmYzA4MGEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjcxOGNiODJkLWM0ZTctNGU1YS04ODNmLTY2NDQ2OWZjMDgwYSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14070:1754,depend,dependency,1754,https://hail.is,https://github.com/hail-is/hail/pull/14070,2,['depend'],"['dependencies', 'dependency']"
Integrability,"/details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/python-api-core/blob/main/CHANGELOG.md"">google-api-core[grpc]'s changelog</a>.</em></p>; <blockquote>; <h2><a href=""https://github.com/googleapis/python-api-core/compare/v2.8.1...v2.8.2"">2.8.2</a> (2022-06-13)</h2>; <h3>Bug Fixes</h3>; <ul>; <li><strong>deps:</strong> allow protobuf &lt; 5.0.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/400"">#400</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/8f73d2ee2d3af2201f877aa7e2f7361147759dc7"">8f73d2e</a>)</li>; <li>drop support for grpc-gcp (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/401"">#401</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/5da6733a475c436efc11b14889af73b3a0e20379"">5da6733</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>fix changelog header to consistent size (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/394"">#394</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/ac266e935bc4e7c6dff250384407e7a60d8dba90"">ac266e9</a>)</li>; <li>Fix typo in the BackgroundConsumer docstring (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/395"">#395</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/0eb727f92314db3c4383754514f75a49ba02e27b"">0eb727f</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/python-api-core/compare/v2.8.0...v2.8.1"">2.8.1</a> (2022-05-26)</h2>; <h3>Bug Fixes</h3>; <ul>; <li><strong>deps:</strong> require googleapis-common-protos &gt;= 1.56.2 (<a href=""https://github.com/googleapis/python-api-core/commit/d84d66c2a4107f5f9a20c53e870a27fb1250ea3d"">d84d66c</a>)</li>; <li><strong>deps:</strong> require protobuf&gt;= 3.15.0, &lt;4.0.0dev (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/385"">#385</a>) (<a href=""https://github.com/googlea",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11970:5002,depend,dependabot,5002,https://hail.is,https://github.com/hail-is/hail/pull/11970,1,['depend'],['dependabot']
Integrability,"/details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/samtools/htsjdk/commit/4a4024a97ee3e87096df6ad9b22c8260bd527772""><code>4a4024a</code></a> Fix temporary directory hijacking or temporary directory information disclosu...</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/9fd0ecf212219d252ab273db0f7b845a59073d64""><code>9fd0ecf</code></a> Disable codecov until we can fix the uploader (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1622"">#1622</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/347c0ac571be29d7aa59fea3090947d9dcc9f8f0""><code>347c0ac</code></a> Fix EdgeReadIterator (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1616"">#1616</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/d15a5bacbb5ed54f1a474aede9a2c3cb9d8832fb""><code>d15a5ba</code></a> Added ULTIMA and ELEMENT as valid value for RG-PL according to SAM spec. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1619"">#1619</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/489c4192dd9682a9d1e53f4c8f6f7bb826e33589""><code>489c419</code></a> Support CRAM reference regions. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1605"">#1605</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/f461401e38fe95362a6d3c5afd8b592964b4bd29""><code>f461401</code></a> Silence AsciiLineReader warning when creating a FASTA sequence index (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1559"">#1559</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/1449dec45b4e95293db14595ec0d11a3839bac23""><code>1449dec</code></a> Support loading of CSI from URLs/streams. <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1507"">#1507</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1595"">#1595</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/22aec6782",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12229:7029,depend,dependabot,7029,https://hail.is,https://github.com/hail-is/hail/pull/12229,1,['depend'],['dependabot']
Integrability,"/driver/main.py"", line 1288, in monitor_billing_limits; records = await query_billing_projects_with_cost(db); File ""/usr/local/lib/python3.9/dist-packages/batch/utils.py"", line 165, in query_billing_projects_with_cost; async for record in db.select_and_fetchall(sql, tuple(args)):; File ""/usr/local/lib/python3.9/dist-packages/gear/database.py"", line 339, in select_and_fetchall; async for row in tx.execute_and_fetchall(sql, args, query_name):; File ""/usr/local/lib/python3.9/dist-packages/gear/database.py"", line 254, in execute_and_fetchall; await cursor.execute(sql, args); File ""/usr/local/lib/python3.9/dist-packages/aiomysql/cursors.py"", line 239, in execute; await self._query(query); File ""/usr/local/lib/python3.9/dist-packages/aiomysql/cursors.py"", line 457, in _query; await conn.query(q); File ""/usr/local/lib/python3.9/dist-packages/aiomysql/connection.py"", line 469, in query; await self._read_query_result(unbuffered=unbuffered); File ""/usr/local/lib/python3.9/dist-packages/aiomysql/connection.py"", line 683, in _read_query_result; await result.read(); File ""/usr/local/lib/python3.9/dist-packages/aiomysql/connection.py"", line 1172, in read; await self._read_result_packet(first_packet); File ""/usr/local/lib/python3.9/dist-packages/aiomysql/connection.py"", line 1232, in _read_result_packet; await self._read_rowdata_packet(); File ""/usr/local/lib/python3.9/dist-packages/aiomysql/connection.py"", line 1282, in _read_rowdata_packet; packet = await self.connection._read_packet(); File ""/usr/local/lib/python3.9/dist-packages/aiomysql/connection.py"", line 652, in _read_packet; packet.raise_for_error(); File ""/usr/local/lib/python3.9/dist-packages/pymysql/protocol.py"", line 221, in raise_for_error; err.raise_mysql_exception(self._data); File ""/usr/local/lib/python3.9/dist-packages/pymysql/err.py"", line 143, in raise_mysql_exception; raise errorclass(errno, errval); pymysql.err.OperationalError: (1213, 'Deadlock found when trying to get lock; try restarting transaction'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14423:2716,protocol,protocol,2716,https://hail.is,https://github.com/hail-is/hail/issues/14423,1,['protocol'],['protocol']
Integrability,"/e194631088aee587140c029a0404f8d40c6765b5""><code>e194631</code></a> Bump astroid to 2.12.6, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/1f5dc457729d7219178ace9705d8445e89513472""><code>1f5dc45</code></a> Handle <code>dataclass</code> <code>kw_only</code> keyword correctly (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1764"">#1764</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/astroid/compare/v2.11.5...v2.12.9"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=astroid&package-manager=pip&previous-version=2.11.5&new-version=2.12.9)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12161:5260,depend,dependabot,5260,https://hail.is,https://github.com/hail-is/hail/pull/12161,1,['depend'],['dependabot']
Integrability,"/e5b7d8759214feedd0c49a7859ebb124473bcfc3""><code>e5b7d87</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/390"">#390</a> from python/bugfix/noisy-coverage</li>; <li>Additional commits viewable in <a href=""https://github.com/python/importlib_metadata/compare/v3.10.1...v4.12.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=importlib-metadata&package-manager=pip&previous-version=3.10.1&new-version=4.12.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12000:5182,Depend,Dependabot,5182,https://hail.is,https://github.com/hail-is/hail/pull/12000,1,['Depend'],['Dependabot']
Integrability,"/e6f6869fddbf307e3267ac164561c669039d557a""><code>e6f6869</code></a> Release v0.13.0 (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/78"">#78</a>)</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/2afa4b2934c3b61b96259d548c26cd49e03daf24""><code>2afa4b2</code></a> Implement --template-tags CLI flag</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/28316eea40acb6f67f267a0fa1545d81fb3ed59a""><code>28316ee</code></a> Re-add repo token</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/27b6bf942a0e9205d918efff1c6bab87ed80a460""><code>27b6bf9</code></a> Add website .nvmrc for Netlify</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/fd8964ab2ecc7662c6b88575f5b89de7a2fbde3d""><code>fd8964a</code></a> Revert &quot;Switch to official GitHub Actions coveralls integration&quot;</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/bc4ec76844853c0fe57b595b18116b2ca33b10bd""><code>bc4ec76</code></a> Use correct lcov path for Coveralls integration</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/7a081706e70480e23ea27c567cbc25121489938e""><code>7a08170</code></a> Add more basic CLI tests</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/08bdb0ce9e044e008eb487f32162865740c25232""><code>08bdb0c</code></a> Switch to official GitHub Actions coveralls integration</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/3a92cc4b4e6f5951bea72234f57b32bef133ab75""><code>3a92cc4</code></a> Tentatively declare support for Python 3.10</li>; <li><a href=""https://github.com/thibaudcolas/curlylint/commit/145983f7a3764743a653ef61595dd3ea33f24620""><code>145983f</code></a> Declare support for Python 3.9</li>; <li>Additional commits viewable in <a href=""https://github.com/thibaudcolas/curlylint/compare/v0.12.0...v0.13.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/bad",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11494:6337,integrat,integration,6337,https://hail.is,https://github.com/hail-is/hail/pull/11494,2,['integrat'],['integration']
Integrability,"/e76f3c3ea78481342e21a7b3328075462ab69c2b""><code>e76f3c3</code></a> Update pre-commit hooks (<a href=""https://redirect.github.com/Textualize/rich/issues/3113"">#3113</a>)</li>; <li><a href=""https://github.com/Textualize/rich/commit/92e7164773ab1a0dd438ba43fee5d3b76b28ba1a""><code>92e7164</code></a> Fix <a href=""https://redirect.github.com/Textualize/rich/issues/3104"">#3104</a> (<a href=""https://redirect.github.com/Textualize/rich/issues/3105"">#3105</a>)</li>; <li><a href=""https://github.com/Textualize/rich/commit/9f620dc50c0008c35e9f8493f198e6e593574a70""><code>9f620dc</code></a> Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3191"">#3191</a> from Textualize/assorted-docs-and-tidying</li>; <li>Additional commits viewable in <a href=""https://github.com/Textualize/rich/compare/v12.6.0...v13.7.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=rich&package-manager=pip&previous-version=12.6.0&new-version=13.7.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14012:7666,depend,dependency-name,7666,https://hail.is,https://github.com/hail-is/hail/pull/14012,2,['depend'],['dependency-name']
Integrability,"/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 321, in run_path; return _run_module_code(code, init_globals, run_name,; File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 135, in _run_module_code; _run_code(code, mod_globals, init_globals,; File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 124, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/test.py"", line 34, in <module>; main(); File ""/home/edmund/.local/src/hail/test.py"", line 28, in main; r2_adj = r2_adj.checkpoint(f'{tmp}/adj', overwrite=args.overwrite); File ""<decorator-gen-1508>"", line 2, in checkpoint; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/hail/python/hail/linalg/blockmatrix.py"", line 679, in checkpoint; self.write(path, overwrite, force_row_major, stage_locally); File ""<decorator-gen-1506>"", line 2, in write; File ""/home/edmund/.local/src/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/home/edmund/.local/src/hail/hail/python/hail/linalg/blockmatrix.py"", line 656, in write; Env.backend().execute(BlockMatrixWrite(self._bmir, writer)); File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 190, in execute; raise e.maybe_user_error(ir) from None; File ""/home/edmund/.local/src/hail/hail/python/hail/backend/backend.py"", line 188, in execute; result, timings = self._rpc(ActionTag.EXECUTE, payload); File ""/home/edmund/.local/src/hail/hail/python/hail/backend/service_backend.py"", line 498, in _rpc; return self._cancel_on_ctrl_c(self._async_rpc(action, payload)); File ""/home/edmund/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14537:3441,wrap,wrapper,3441,https://hail.is,https://github.com/hail-is/hail/issues/14537,1,['wrap'],['wrapper']
Integrability,"/elastic/elasticsearch-hadoop/issues/1989"">#1989</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1990"">#1990</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/71f288bf1b473d0ed34b9dd4284bf33aa98a0ccf""><code>71f288b</code></a> [DOCS] Add 8.3.3 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1983"">#1983</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1985"">#1985</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/712679f88772fb15184ad7c87dea220a87803f44""><code>712679f</code></a> Upgrade to Gradle 7.5 (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1980"">#1980</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/a4d14077a58ba3272469d48500ce007c725f1c73""><code>a4d1407</code></a> [DOCS] Added 8.3.2 RNs (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1978"">#1978</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/elastic/elasticsearch-hadoop/compare/v7.17.1...v8.4.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.elasticsearch:elasticsearch-spark-20_2.12&package-manager=gradle&previous-version=7.17.1&new-version=8.4.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` w",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12358:7192,depend,dependabot,7192,https://hail.is,https://github.com/hail-is/hail/pull/12358,1,['depend'],['dependabot']
Integrability,"/elastic/elasticsearch-hadoop/issues/1989"">#1989</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1990"">#1990</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/71f288bf1b473d0ed34b9dd4284bf33aa98a0ccf""><code>71f288b</code></a> [DOCS] Add 8.3.3 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1983"">#1983</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1985"">#1985</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/712679f88772fb15184ad7c87dea220a87803f44""><code>712679f</code></a> Upgrade to Gradle 7.5 (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1980"">#1980</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/a4d14077a58ba3272469d48500ce007c725f1c73""><code>a4d1407</code></a> [DOCS] Added 8.3.2 RNs (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1978"">#1978</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/elastic/elasticsearch-hadoop/compare/v8.0.0...v8.4.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.elasticsearch:elasticsearch-spark-30_2.12&package-manager=gradle&previous-version=8.0.0&new-version=8.4.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` wil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12319:7191,depend,dependabot,7191,https://hail.is,https://github.com/hail-is/hail/pull/12319,1,['depend'],['dependabot']
Integrability,"/elasticsearch-hadoop/issues/2000"">#2000</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/e90ae30e6977b43eea3e08c8a2d35ba2ef43a2e4""><code>e90ae30</code></a> Bump to version 8.6.0</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/b8fec87ab612f9ca25091e9314fb5be7a697d260""><code>b8fec87</code></a> [DOCS] Add 8.4.2 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1998"">#1998</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/069c07b47da2f9bce703968c56308a58e6855895""><code>069c07b</code></a> Ignoring missing indices if es.index.read.missing.as.empty is true (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1997"">#1997</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/2fcae131824c8221231f5f9331c2a5c677376237""><code>2fcae13</code></a> [DOCS] Added RNs for 8.4.1 (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/1995"">#1995</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/elastic/elasticsearch-hadoop/compare/v8.4.3...v8.6.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.elasticsearch:elasticsearch-spark-20_2.12&package-manager=gradle&previous-version=8.4.3&new-version=8.6.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` wil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12601:4787,depend,dependabot,4787,https://hail.is,https://github.com/hail-is/hail/pull/12601,1,['depend'],['dependabot']
Integrability,"/gatk.hc/gcad.5k.snv.vqsr.pass.common'); print(""Pruning LD Variants""); pruned =hl.ld_prune(common,30,r2=0.1, memory_per_core=2048); pruned.write('/project/casa/hail.ds/gatk.hc/gcad.5k.snv.vqsr.pruned'); print(""Sample 20% of variants for running PC-Relate""); pruned_subsample = pruned.sample_rows(0.2).persist(); print(""Running PC_Relate""); rel = hl.pc_relate(pruned_subsample.GT, 0.01, k=10); rel_df = rel.to_pandas(); rel_df.describe(); pprint(rel_df); rel_df.to_csv('gcad_5k.snv.rel.csv'); ```. ### What went wrong (all error messages here, including the full java stack trace):. Got a memory error. but not sure what memory needs to be increased. The job seems to restart but does not progress and need to kill. . java.lang.OutOfMemoryError: Java heap spaceop. Running on Apache Spark version 2.2.0; SparkUI available at http://10.48.225.55:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version devel-63d60cc; NOTE: This is a beta version. Interfaces may change; during the beta period. We also recommend pulling; the latest changes weekly.; Read in PASS SNVs; Filtering Common Variants; [Stage 0:==================================================>(96600 + 1) / 96601]2018-04-27 20:54:43 Hail: INFO: wrote 11341822 items in 96601 partitions; Pruning LD Variants; [Stage 1:==================================================>(96598 + 3) / 96601]2018-04-27 21:19:04 Hail: INFO: Running LD prune with nSamples=4795, nVariants=11341822, nPartitions=96601, and maxQueueSize=429841.; [Stage 2:=========================================> (79823 + 18) / 96601]java.lang.OutOfMemoryError: Java heap spaceop""; at java.util.Arrays.copyOf(Arrays.java:3181); at java.util.ArrayList.toArray(ArrayList.java:376); at java.util.Collections$SynchronizedCollection.toArray(Collections.java:2024); at java.util.ArrayList.<init>(ArrayList.java:177); at org.apache.spark.util.CollectionAccumulator.value(AccumulatorV2.scala:470); at org.apache.spark.util.CollectionAccumulator.value(Accu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3463:2386,Interface,Interfaces,2386,https://hail.is,https://github.com/hail-is/hail/issues/3463,1,['Interface'],['Interfaces']
Integrability,"/gidgethub/discussions/155"">https://github.com/brettcannon/gidgethub/discussions/155</a>)</li>; </ul>; <h2>5.0.0</h2>; <ul>; <li>Add <code>gidgethub.routing.Router.fetch</code> for obtaining a frozenset of functions; registered to the router that the event would be called on.; [Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/74"">#74</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/74"">brettcannon/gidgethub#74</a>).</li>; <li>Add support for GitHub Actions Environment Files with <code>gidgethub.actions.setenv</code>; and <code>gidgethub.actions.addpath</code>.; [Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/137"">#137</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/132"">brettcannon/gidgethub#132</a>).</li>; <li>Make router callback execution order non-deterministic to avoid relying on; registration order.; [Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/74"">#74</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/74"">brettcannon/gidgethub#74</a>).</li>; <li>Fix mypy errors in <code>gidgethub.httpx.GitHubAPI._request</code>[Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/133"">#133</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/133"">brettcannon/gidgethub#133</a>).</li>; <li>Make the minimum version of PyJWT be v2.0.0.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/brettcannon/gidgethub/blob/main/docs/changelog.rst"">gidgethub's changelog</a>.</em></p>; <blockquote>; <h2>5.2.1</h2>; <ul>; <li>; <p>Fix cgi and importlib_resources deprecations.; (<code>PR [#185](https://github.com/brettcannon/gidgethub/issues/185) &lt;https://github.com/brettcannon/gidgethub/pull/185&gt;_</code>)</p>; </li>; <li>; <p>Add support for Python 3.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12328:3576,depend,dependabot,3576,https://hail.is,https://github.com/hail-is/hail/pull/12328,1,['depend'],['dependabot']
Integrability,"/github-redirect.dependabot.com/PyCQA/astroid/issues/1753"">#1753</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/060cefa51884d176fdacf1b8ea18cee3ae0b0948""><code>060cefa</code></a> Bump astroid to 2.12.3, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/d0ecb2a58df1eae6c78c3dd39b5399d7f7a59ea3""><code>d0ecb2a</code></a> Remove str instance in model of BaseException.attrs (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1749"">#1749</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/823e802de81350e7aa57807b450faa21d6d25de1""><code>823e802</code></a> Fix false positive with inference of <code>http</code> module (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1742"">#1742</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/e1d1783ff6a2a24699a5dc13fc87d5baac0b6630""><code>e1d1783</code></a> Don't add <code>KW_ONLY</code> fields to dataclass fields (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1746"">#1746</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/astroid/compare/v2.11.5...v2.12.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=astroid&package-manager=pip&previous-version=2.11.5&new-version=2.12.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, o",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12151:4945,depend,dependabot,4945,https://hail.is,https://github.com/hail-is/hail/pull/12151,1,['depend'],['dependabot']
Integrability,"/github-redirect.dependabot.com/PyCQA/pyflakes/issues/714"">#714</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/2246217295dc8cb30ef4a7b9d8dc449ce32e603a""><code>2246217</code></a> burn the bridges with python 2.x (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/707"">#707</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/becbab65bae84e3e19fc388a42dfabcff0c323c8""><code>becbab6</code></a> upgrade flake8 to 4.0.1 (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/706"">#706</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/f736615f32a4bab27c9efeb5b8f8c31702efc4ab""><code>f736615</code></a> remove backported unittest methods (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/705"">#705</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/5959216f67837f3ddf5b959c21e097c7a3758d48""><code>5959216</code></a> remove checking of node.docstring (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/704"">#704</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/405a0906c8debafaae419472d3f51b84b7ba5c49""><code>405a090</code></a> simplify PYPY check (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/703"">#703</a>)</li>; <li><a href=""https://github.com/PyCQA/pyflakes/commit/30ec8589e183f76f40764a8dd78591719f521943""><code>30ec858</code></a> remove unused WIN (<a href=""https://github-redirect.dependabot.com/PyCQA/pyflakes/issues/702"">#702</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pyflakes/compare/2.4.0...2.5.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyflakes&package-manager=pip&previous-version=2.4.0&new-version=2.5.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot w",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12149:2919,depend,dependabot,2919,https://hail.is,https://github.com/hail-is/hail/pull/12149,1,['depend'],['dependabot']
Integrability,"/github-redirect.dependabot.com/brettcannon/gidgethub/issues/174"">#174</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/pull/174"">brettcannon/gidgethub#174</a>))</p>; </li>; </ul>; <h2>5.0.1</h2>; <ul>; <li>Drop the <code>machine-man-preview</code> header from <code>gidgethub.apps.get_installation_access_token</code> because it is out of preview. The machine-man-preview is no longer required as of August 20, 2020. [Discussion <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/155"">#155</a>](<a href=""https://github.com/brettcannon/gidgethub/discussions/155"">https://github.com/brettcannon/gidgethub/discussions/155</a>)</li>; </ul>; <h2>5.0.0</h2>; <ul>; <li>Add <code>gidgethub.routing.Router.fetch</code> for obtaining a frozenset of functions; registered to the router that the event would be called on.; [Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/74"">#74</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/74"">brettcannon/gidgethub#74</a>).</li>; <li>Add support for GitHub Actions Environment Files with <code>gidgethub.actions.setenv</code>; and <code>gidgethub.actions.addpath</code>.; [Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/137"">#137</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/132"">brettcannon/gidgethub#132</a>).</li>; <li>Make router callback execution order non-deterministic to avoid relying on; registration order.; [Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/74"">#74</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/74"">brettcannon/gidgethub#74</a>).</li>; <li>Fix mypy errors in <code>gidgethub.httpx.GitHubAPI._request</code>[Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/133"">#133</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issue",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12328:2989,depend,dependabot,2989,https://hail.is,https://github.com/hail-is/hail/pull/12328,1,['depend'],['dependabot']
Integrability,"/github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/141"">#141</a>) (<a href=""https://github.com/googleapis/python-api-common-protos/commit/9ea3530b459269e964fcc98db1c5025e05d6495f"">9ea3530</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>minor updates to comments (<a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac"">6af2132</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/0ee8d805e9061b52a210d69d46e433c718ad18ff""><code>0ee8d80</code></a> chore(main): release 1.57.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/139"">#139</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/b9dbb219ea46abd9851af1fc41ea37f9d5631c0b""><code>b9dbb21</code></a> feat: add support for Python 3.11 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/145"">#145</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/63ca888512be84508fcf95e4d5d40df036a85e18""><code>63ca888</code></a> feat: add support for Python 3.10 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/143"">#143</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/6af21322879cba158e0a5992c9799e68c1744fac""><code>6af2132</code></a> chore(python): update dependencies in .kokoro/requirements.txt [autoapprove] ...</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/9ea3530b459269e964fcc98db1c5025e05d6495f""><code>9ea3530</code></a> fix(deps): require protobuf &gt;=3.19.5 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/141"">#141</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/5cf4e0bbfed23d061600d64099f21fcf92ef0cf",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12514:5078,depend,dependabot,5078,https://hail.is,https://github.com/hail-is/hail/pull/12514,1,['depend'],['dependabot']
Integrability,"/github-redirect.dependabot.com/googleapis/python-storage/issues/689"">#689</a>) (<a href=""https://github.com/googleapis/python-storage/commit/8aa4130ee068a1922161c8ca54a53a4a51d65ce0"">8aa4130</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/python-storage/compare/v1.44.0...v2.0.0"">2.0.0</a> (2022-01-12)</h2>; <h3>⚠ BREAKING CHANGES</h3>; <ul>; <li>Remove Python 2 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/657"">#657</a>)</li>; </ul>; <h3>Features</h3>; <ul>; <li>Remove Python 2 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/657"">#657</a>) (<a href=""https://github.com/googleapis/python-storage/commit/b6116700a4a32d28404c39018138e545f3f7910e"">b611670</a>)</li>; </ul>; <h2><a href=""https://www.github.com/googleapis/python-storage/compare/v1.43.0...v1.44.0"">1.44.0</a> (2022-01-05)</h2>; <h3>Features</h3>; <ul>; <li>add raw_download kwarg to BlobReader (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/668"">#668</a>) (<a href=""https://www.github.com/googleapis/python-storage/commit/10cdad630739a324ae0b16a3d14a67ca4c8a23c2"">10cdad6</a>)</li>; </ul>; <h3>Documentation</h3>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/googleapis/python-storage/commit/f80f69516b0eaa6ebef6a28d1fd12c9d78f362ce""><code>f80f695</code></a> chore(main): release 2.2.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/705"">#705</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/eae1df0f4526eefb21f14eb3f5a319b9395b90c7""><code>eae1df0</code></a> chore(deps): update dependency pytest to v7.1.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/732"">#732</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/5d1cfd2050321481a3bc4acbe80537ea666506fa""><code>5d1c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11578:5829,depend,dependabot,5829,https://hail.is,https://github.com/hail-is/hail/pull/11578,1,['depend'],['dependabot']
Integrability,"/github-redirect.dependabot.com/googleapis/python-storage/issues/689"">#689</a>) (<a href=""https://github.com/googleapis/python-storage/commit/8aa4130ee068a1922161c8ca54a53a4a51d65ce0"">8aa4130</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/python-storage/compare/v1.44.0...v2.0.0"">2.0.0</a> (2022-01-12)</h2>; <h3>⚠ BREAKING CHANGES</h3>; <ul>; <li>Remove Python 2 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/657"">#657</a>)</li>; </ul>; <h3>Features</h3>; <ul>; <li>Remove Python 2 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/657"">#657</a>) (<a href=""https://github.com/googleapis/python-storage/commit/b6116700a4a32d28404c39018138e545f3f7910e"">b611670</a>)</li>; </ul>; <h2><a href=""https://www.github.com/googleapis/python-storage/compare/v1.43.0...v1.44.0"">1.44.0</a> (2022-01-05)</h2>; <h3>Features</h3>; <ul>; <li>add raw_download kwarg to BlobReader (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/668"">#668</a>) (<a href=""https://www.github.com/googleapis/python-storage/commit/10cdad630739a324ae0b16a3d14a67ca4c8a23c2"">10cdad6</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Describe code sample more specifically (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/660"">#660</a>) (<a href=""https://www.github.com/googleapis/python-storage/commit/0459cb4e866696c46385a5ad72e2a85db810a36b"">0459cb4</a>)</li>; <li>refresh readme instructions (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/667"">#667</a>) (<a href=""https://www.github.com/googleapis/python-storage/commit/ceb931403a755f2a0bdc20144287dbc4700c3360"">ceb9314</a>)</li>; <li>This is just a simple PR to better describe what the code is doing in the comments. (<a href=""https://www.github.com/googleapis/python-storage/commit/0459cb4e866696c46385a5ad72e2a85db810a36b"">0459cb4</a>)</li>; <li>use writeable streamin example for 'd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11520:3202,depend,dependabot,3202,https://hail.is,https://github.com/hail-is/hail/pull/11520,1,['depend'],['dependabot']
Integrability,"/github-redirect.dependabot.com/grpc/grpc/issues/30326"">#30326</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/4c51abf12053e3c43a62059c693322ea992b35ce""><code>4c51abf</code></a> Bump version to 1.48.0-pre1 (on v1.48.x branch) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30194"">#30194</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/46bd0be2c99aa8228ec5d93d8a27f20ab0c61956""><code>46bd0be</code></a> Bump core version to 26.0.0 for upcoming release (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30163"">#30163</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/grpc/grpc/compare/v1.47.0...v1.48.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=grpcio&package-manager=pip&previous-version=1.47.0&new-version=1.48.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12201:6386,depend,dependabot-security-updates,6386,https://hail.is,https://github.com/hail-is/hail/pull/12201,1,['depend'],['dependabot-security-updates']
Integrability,"/github-redirect.dependabot.com/jaraco/zipp/issues/62"">#62</a>)</li>; <li><a href=""https://github.com/jaraco/zipp/commit/a4f5b769793af19f7b858816889c1bf026f55f5c""><code>a4f5b76</code></a> Update base URL for PEPs (<a href=""https://github-redirect.dependabot.com/jaraco/zipp/issues/61"">#61</a>)</li>; <li><a href=""https://github.com/jaraco/zipp/commit/10bf1b1fb9e09e9836bea9e2edec620cd9eea7f9""><code>10bf1b1</code></a> Add Python 3.11 into the matrix using workaround from <a href=""https://github-redirect.dependabot.com/actions/setup-python/issues/21"">actions/setup-python#21</a>...</li>; <li>Additional commits viewable in <a href=""https://github.com/jaraco/zipp/compare/v3.8.0...v3.8.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=zipp&package-manager=pip&previous-version=3.8.0&new-version=3.8.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12108:2922,depend,dependabot-security-updates,2922,https://hail.is,https://github.com/hail-is/hail/pull/12108,1,['depend'],['dependabot-security-updates']
Integrability,"/github-redirect.dependabot.com/psf/black/issues/2903"">#2903</a>)</li>; <li><code>black-primer</code>, the deprecated internal devtool, has been removed and copied to a; <a href=""https://github.com/cooperlees/black-primer"">separate repository</a> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2924"">#2924</a>)</li>; </ul>; <h3>Parser</h3>; <ul>; <li>Black can now parse starred expressions in the target of <code>for</code> and <code>async for</code>; statements, e.g <code>for item in *items_1, *items_2: pass</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2879"">#2879</a>).</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/psf/black/blob/main/CHANGES.md"">black's changelog</a>.</em></p>; <blockquote>; <h2>22.3.0</h2>; <h3>Preview style</h3>; <ul>; <li>Code cell separators <code>#%%</code> are now standardised to <code># %%</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2919"">#2919</a>)</li>; <li>Remove unnecessary parentheses from <code>except</code> statements (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2939"">#2939</a>)</li>; <li>Remove unnecessary parentheses from tuple unpacking in <code>for</code> loops (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2945"">#2945</a>)</li>; <li>Avoid magic-trailing-comma in single-element subscripts (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2942"">#2942</a>)</li>; </ul>; <h3>Configuration</h3>; <ul>; <li>Do not format <code>__pypackages__</code> directories by default (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2836"">#2836</a>)</li>; <li>Add support for specifying stable version with <code>--required-version</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2832"">#2832</a>).</li>; <li>Avoid crashing when the user has no homedir (<a href=""https://github-redirect.dependabot.com/psf/bl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11696:3541,depend,dependabot,3541,https://hail.is,https://github.com/hail-is/hail/pull/11696,1,['depend'],['dependabot']
Integrability,"/github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/227"">#227</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/f9219b21ef8807150dbbcbaf45d6118387ff9a32""><code>f9219b2</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/222"">#222</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/a9b90238f74f1c5f69d7dcafb83c9775504f9b3b""><code>a9b9023</code></a> Fix typos (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/224"">#224</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/1ef84886873b80ff62ed1ea76e111dd9e96dbf18""><code>1ef8488</code></a> Release 1.17.0</li>; <li>Additional commits viewable in <a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/compare/1.11.1...1.18.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx-autodoc-typehints&package-manager=pip&previous-version=1.11.1&new-version=1.18.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependab",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11893:6925,Depend,Dependabot,6925,https://hail.is,https://github.com/hail-is/hail/pull/11893,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"/github-redirect.dependabot.com/tqdm/tqdm/issues/1246"">#1246</a>)</li>; <li>misc tidying &amp; refactoring</li>; <li>misc build/dev framework updates; <ul>; <li>update dependencies</li>; <li>update linters</li>; <li>update docs deployment branches</li>; </ul>; </li>; <li>misc test/ci updates; <ul>; <li>test forks</li>; <li>tidy OS &amp; Python version tests</li>; <li>bump primary python version 3.7 =&gt; 3.8</li>; <li>beta py3.10 testing</li>; <li>fix py2.7 tests</li>; <li>better timeout handling</li>; </ul>; </li>; </ul>; <h2>tqdm v4.62.2 stable</h2>; <ul>; <li>fix notebook memory leak (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1216"">#1216</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/tqdm/tqdm/commit/6791e8c5b3d6c30bdd2060c346996bfb5a6f10d1""><code>6791e8c</code></a> bump version, merge pull request <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1366"">#1366</a> from tqdm/devel</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/754186291e6b4e28ea8b56c9493adc03bf14c404""><code>7541862</code></a> tests: hotfix skip windows errors</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/8fb3d91f561e2a286a7fda13291eda16613dac39""><code>8fb3d91</code></a> fix ipywidgets&gt;=8 display</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/05e3d32a5fc8559e133e6d627d44afda93018637""><code>05e3d32</code></a> fix jupyterlab display</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/4f208e72552c4d916aa4fe6a955349ee8b2ed353""><code>4f208e7</code></a> bump version, merge branch 'slack'</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/1d29dec4b07de3dab34d3557baa9520cd9d46e38""><code>1d29dec</code></a> add <code>[slack]</code> extra dependency</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/4a1d10e19fdca00db47fd50725715dc5e4aa68e6""><code>4a1d10e</code></a> consistent ordering</li>; <li><a href=""https://",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12260:4177,depend,dependabot,4177,https://hail.is,https://github.com/hail-is/hail/pull/12260,1,['depend'],['dependabot']
Integrability,"/github.com/PyCQA/flake8/commit/84d56a8c25106b5e0a41cdf63b5de261f8da5c99""><code>84d56a8</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/ff6569b87db8ae28c41b548071454de620ad14d5""><code>ff6569b</code></a> Release 5.0.3</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/e76b59ae44f46f7958d13b28bd2d7d9bdc0f5962""><code>e76b59a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pycqa/flake8/issues/1648"">#1648</a> from PyCQA/invalid-syntax-partial-parse</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/25e8ff18b30b58f1dabc1d20546ebc20fd775560""><code>25e8ff1</code></a> ignore config files that partially parse as flake8 configs</li>; <li>Additional commits viewable in <a href=""https://github.com/pycqa/flake8/compare/4.0.1...5.0.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=flake8&package-manager=pip&previous-version=4.0.1&new-version=5.0.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12105:2365,depend,dependency-name,2365,https://hail.is,https://github.com/hail-is/hail/pull/12105,1,['depend'],['dependency-name']
Integrability,"/github.com/aio-libs/aiohttp-session/commit/f25b7508b4ba0cdfef2f99888bd40f1beb2ae0a7""><code>f25b750</code></a> Bump pytest from 7.1.3 to 7.2.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/765"">#765</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/970cd31ce41162d9893c975f05e7082d32a4cece""><code>970cd31</code></a> Bump flake8-bugbear from 22.9.23 to 22.10.25 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/764"">#764</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/bf16648feca6571649849bca65ca1d9b36f8b417""><code>bf16648</code></a> Bump types-redis from 4.3.21.2 to 4.3.21.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/762"">#762</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/07a709a0f408e54b294b28b81968d2b79f188290""><code>07a709a</code></a> Bump redis from 4.3.3 to 4.3.4 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/759"">#759</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp_session/compare/v2.7.0...v2.12.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp-session&package-manager=pip&previous-version=2.7.0&new-version=2.12.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12499:4758,depend,dependabot,4758,https://hail.is,https://github.com/hail-is/hail/pull/12499,1,['depend'],['dependabot']
Integrability,"/github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; </ul>; <h2>pre-commit v2.16.0</h2>; <h3>Features</h3>; <ul>; <li>add warning for regexes containing <code>[\/]</code> or <code>[/\\]</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2053"">#2053</a> PR by <a href=""https://github.com/radek-sprta""><code>@​radek-sprta</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2043"">#2043</a> issue by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>move hook template back to <code>bash</code> resolving shebang-portability issues.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2065"">#2065</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>add support for <code>fail_fast</code> at the individual hook level.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2097"">#2097</a> PR by <a href=""https://github.com/colens3""><code>@​colens3</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/1143"">#1143</a> issue by <a href=""https://github.com/potiuk""><code>@​potiuk</code></a>.</li>; </ul>; </li>; <li>allow passthrough of <code>GIT_CONFIG_KEY_*</code>, <code>GIT_CONFIG_VALUE_*</code>, and <code>GIT_CONFIG_COUNT</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2136"">#2136</a> PR by <a href=""https://github.com/emzeat""><code>@​emzeat</code></a>.</li>; </ul>; </li>; </ul>; <h3>Fixes</h3>; <ul>; <li>fix pre-commit autoupdate for <code>core.useBuiltinFSMonitor=true</code> on windows.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2047"">#2047</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11460:4887,depend,dependabot,4887,https://hail.is,https://github.com/hail-is/hail/pull/11460,2,['depend'],['dependabot']
Integrability,"/github.com/dateutil/dateutil/commit/9c2ad8f981ece1bdb3d52527f1cb39523b11d862""><code>9c2ad8f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1056"">#1056</a> from ffe4/issue_1029</li>; <li>Additional commits viewable in <a href=""https://github.com/dateutil/dateutil/compare/2.8.1...2.8.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=python-dateutil&package-manager=pip&previous-version=2.8.1&new-version=2.8.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11518:11760,Depend,Dependabot,11760,https://hail.is,https://github.com/hail-is/hail/pull/11518,1,['Depend'],['Dependabot']
Integrability,"/github.com/giampaolo/psutil/commit/ebbaae8d1f42f051282af79d60f19cb1161088a5""><code>ebbaae8</code></a> git pre commit hook: use shlex.split()</li>; <li><a href=""https://github.com/giampaolo/psutil/commit/39dc44bfa5fbb9500166b3480295379602e5bbc5""><code>39dc44b</code></a> Automatically sort imports (isort CLI tool) (<a href=""https://github-redirect.dependabot.com/giampaolo/psutil/issues/2033"">#2033</a>)</li>; <li><a href=""https://github.com/giampaolo/psutil/commit/b490b5d51af6ed29709c357a00fcdb6bda26df78""><code>b490b5d</code></a> fix missing arg passed to C psutil_debug()</li>; <li><a href=""https://github.com/giampaolo/psutil/commit/eb2f74c153987b4e0d03aa16931d97e8137d9257""><code>eb2f74c</code></a> Fix CI tests / wheels / workflow (<a href=""https://github-redirect.dependabot.com/giampaolo/psutil/issues/2024"">#2024</a>)</li>; <li><a href=""https://github.com/giampaolo/psutil/commit/a1ae994cabff37eb86c6ca4564b4f193a73a7b0d""><code>a1ae994</code></a> fix <a href=""https://github-redirect.dependabot.com/giampaolo/psutil/issues/2023"">#2023</a> [Linux] cpu_freq() return order is wrong on systems with &gt; 9 CPUs.</li>; <li><a href=""https://github.com/giampaolo/psutil/commit/875d2195fc8efa642c7bca714d468551d1805c6c""><code>875d219</code></a> Handle missing dependencies on MidnightBSD (<a href=""https://github-redirect.dependabot.com/giampaolo/psutil/issues/2019"">#2019</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/giampaolo/psutil/compare/release-5.8.0...release-5.9.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=psutil&package-manager=pip&previous-version=5.8.0&new-version=5.9.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11459:5676,depend,dependabot,5676,https://hail.is,https://github.com/hail-is/hail/pull/11459,1,['depend'],['dependabot']
Integrability,"/github.com/hugovk""><code>@​hugovk</code></a></li>; </ul>; <h2>4.2.1</h2>; <h2>Fixed</h2>; <ul>; <li>Rename Arabic locale from <code>ar_SA</code> to <code>ar</code> to enable fallbacks (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/27"">#27</a>) <a href=""https://github.com/hugovk""><code>@​hugovk</code></a></li>; <li>Use <code>%d</code> for year translations, convert to string for <code>intcomma</code> after (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/23"">#23</a>) <a href=""https://github.com/carterbox""><code>@​carterbox</code></a></li>; <li>Fix <code>intcomma</code> with <code>ndigits=0</code> (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/26"">#26</a>) <a href=""https://github.com/hugovk""><code>@​hugovk</code></a></li>; </ul>; <h2>4.2.0</h2>; <h2>Added</h2>; <ul>; <li>Add <code>humanize.metric()</code> for converting big/small numbers to SI units (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/22"">#22</a>) <a href=""https://github.com/bwoodsend""><code>@​bwoodsend</code></a></li>; <li>Add type hints (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/15"">#15</a>) <a href=""https://github.com/hugovk""><code>@​hugovk</code></a></li>; </ul>; <h2>Fixed</h2>; <ul>; <li>Fix <code>scientific()</code> on small positive numbers (<a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/22"">#22</a>) <a href=""https://github.com/bwoodsend""><code>@​bwoodsend</code></a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/python-humanize/humanize/commit/5553ff5308c363aeaa923362b11b7a8e299129f5""><code>5553ff5</code></a> Update FUNDING.yml</li>; <li><a href=""https://github.com/python-humanize/humanize/commit/694a2d616ff72796acdd1830a1fa3f91a1e03448""><code>694a2d6</code></a> Merge pull reques",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12329:4179,depend,dependabot,4179,https://hail.is,https://github.com/hail-is/hail/pull/12329,1,['depend'],['dependabot']
Integrability,"/github.com/jalessio""><code>@​jalessio</code></a>.</li>; </ul>; </li>; <li>allow <code>language: conda</code> to use <code>mamba</code> or <code>micromamba</code> via; <code>PRE_COMMIT_USE_MAMBA=1</code> or <code>PRE_COMMIT_USE_MICROMAMBA=1</code> respectively.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2204"">#2204</a> issue by <a href=""https://github.com/janjagusch""><code>@​janjagusch</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2207"">#2207</a> PR by <a href=""https://github.com/xhochy""><code>@​xhochy</code></a>.</li>; </ul>; </li>; <li>display <code>git --version</code> in error report.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2210"">#2210</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>add <code>language: lua</code> as a supported language.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2158"">#2158</a> PR by <a href=""https://github.com/mblayman""><code>@​mblayman</code></a>.</li>; </ul>; </li>; </ul>; <h3>Fixes</h3>; <ul>; <li>temporarily add <code>setuptools</code> to the zipapp.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2122"">#2122</a> issue by <a href=""https://github.com/andreoliwa""><code>@​andreoliwa</code></a>.</li>; <li>a737d5f commit by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>use <code>go install</code> instead of <code>go get</code> for go 1.18+ support.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2161"">#2161</a> PR by <a href=""https://github.com/schmir""><code>@​schmir</code></a>.</li>; </ul>; </li>; <li>fix <code>language: r</code> with a local renv and <code>RENV_PROJECT</code> set.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2170"">#2170</a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11460:8394,depend,dependabot,8394,https://hail.is,https://github.com/hail-is/hail/pull/11460,2,['depend'],['dependabot']
Integrability,"/github.com/jpadilla/pyjwt/commit/19ce9c5ec7947428d35aaffd302eb2629210a697""><code>19ce9c5</code></a> Remove upper bound on cryptography version (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/693"">#693</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/9249fc70b5aede04c3dcb86e4b6560ab7e032563""><code>9249fc7</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/689"">#689</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/jpadilla/pyjwt/compare/1.7.1...2.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyjwt&package-manager=pip&previous-version=1.7.1&new-version=2.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11457:14055,Depend,Dependabot,14055,https://hail.is,https://github.com/hail-is/hail/pull/11457,1,['Depend'],['Dependabot']
Integrability,"/github.com/jupyter/notebook/commit/d717c6b3613f3609139bc2b9fe8d0a126aaeeae2""><code>d717c6b</code></a> Add Python 3.12 classifier (<a href=""https://redirect.github.com/jupyter/notebook/issues/7111"">#7111</a>)</li>; <li>See full diff in <a href=""https://github.com/jupyter/notebook/compare/@jupyter-notebook/tree@7.0.6...@jupyter-notebook/tree@7.0.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=notebook&package-manager=pip&previous-version=7.0.6&new-version=7.0.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14182:9263,Depend,Dependabot,9263,https://hail.is,https://github.com/hail-is/hail/pull/14182,1,['Depend'],['Dependabot']
Integrability,"/github.com/michel-kraemer/gradle-download-task/commit/b3fa29f9ffb4d4544e13ef84601e371fb2778ddf""><code>b3fa29f</code></a> Revert &quot;Update Apache HttpClient to 5.2.1&quot;</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/01f05e046be0dca18f506723c79e88f208336e71""><code>01f05e0</code></a> Add integration tests for Gradle 6.9.3 and 7.6</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a998a544908a8b39f713f4526f717fcb328c06eb""><code>a998a54</code></a> Upgrade Gradle to 7.6</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/5.3.0...5.3.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=5.3.0&new-version=5.3.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12707:3551,depend,dependabot-security-updates,3551,https://hail.is,https://github.com/hail-is/hail/pull/12707,1,['depend'],['dependabot-security-updates']
Integrability,"/github.com/numpy/numpy/commit/1cbd12765a3d3301d424df5251bc92f7fcd10756""><code>1cbd127</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22413"">#22413</a> from charris/prepare-for-1.23.4</li>; <li><a href=""https://github.com/numpy/numpy/commit/8cfc899f74db48698c5739a672c3539b96127b63""><code>8cfc899</code></a> REL: Prepare for the NumPy 1.23.4 release.</li>; <li><a href=""https://github.com/numpy/numpy/commit/22a41b5f3bcf34ac91b89c082c4531433646270b""><code>22a41b5</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22392"">#22392</a> from charris/backport-22296</li>; <li><a href=""https://github.com/numpy/numpy/commit/f6a3c119dabe1173ebe0d06a3472577b6405a042""><code>f6a3c11</code></a> Adding missing Py_DECREF call on iter</li>; <li><a href=""https://github.com/numpy/numpy/commit/8274a16bd4434405597f32aacaf8a53002718fc5""><code>8274a16</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22391"">#22391</a> from charris/backport-22372</li>; <li><a href=""https://github.com/numpy/numpy/commit/fa16a0ca51ef0654f541fcf6fa8d30f0f6263a94""><code>fa16a0c</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22390"">#22390</a> from charris/backport-22360</li>; <li>Additional commits viewable in <a href=""https://github.com/numpy/numpy/compare/v1.21.6...v1.23.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.6&new-version=1.23.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-autome",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12441:5375,depend,dependabot,5375,https://hail.is,https://github.com/hail-is/hail/pull/12441,1,['depend'],['dependabot']
Integrability,"/github.com/pandas-dev/pandas/commit/1418835ea328eb402686c31c8d6de0a99ad55bc9""><code>1418835</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45633"">#45633</a>: DOC: Fix typo in nth docstring (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45924"">#45924</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/f035290718ef8e0683ecb16a20639ed5e57e10eb""><code>f035290</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45853"">#45853</a>: Fixing documentation format in read_csv (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45922"">#45922</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/ebf024eb886a8e81922250a386c8d1c8bfa13b2a""><code>ebf024e</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45923"">#45923</a>: DOC: add Python 3.10 to doc (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45927"">#45927</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/deea0562e1ebabc874011575293103d0ba35d0f0""><code>deea056</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45910"">#45910</a>: TST/CI: Set hypothesis deadline to None to avoid flaky fa...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/58aebf1940b56b77279174f5413b76a5aaba465c""><code>58aebf1</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45909"">#45909</a>: BUG: DateOffset(n) not defaulting to days (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45918"">#45918</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.0...v1.4.1"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11521:3629,depend,dependabot,3629,https://hail.is,https://github.com/hail-is/hail/pull/11521,1,['depend'],['dependabot']
Integrability,"/github.com/pandas-dev/pandas/commit/1418835ea328eb402686c31c8d6de0a99ad55bc9""><code>1418835</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45633"">#45633</a>: DOC: Fix typo in nth docstring (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45924"">#45924</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/f035290718ef8e0683ecb16a20639ed5e57e10eb""><code>f035290</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45853"">#45853</a>: Fixing documentation format in read_csv (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45922"">#45922</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/ebf024eb886a8e81922250a386c8d1c8bfa13b2a""><code>ebf024e</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45923"">#45923</a>: DOC: add Python 3.10 to doc (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45927"">#45927</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/deea0562e1ebabc874011575293103d0ba35d0f0""><code>deea056</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45910"">#45910</a>: TST/CI: Set hypothesis deadline to None to avoid flaky fa...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/58aebf1940b56b77279174f5413b76a5aaba465c""><code>58aebf1</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45909"">#45909</a>: BUG: DateOffset(n) not defaulting to days (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45918"">#45918</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.0...v1.4.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pan",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11539:5147,depend,dependabot,5147,https://hail.is,https://github.com/hail-is/hail/pull/11539,1,['depend'],['dependabot']
Integrability,"/github.com/potiuk""><code>@​potiuk</code></a>.</li>; </ul>; </li>; <li>allow passthrough of <code>GIT_CONFIG_KEY_*</code>, <code>GIT_CONFIG_VALUE_*</code>, and <code>GIT_CONFIG_COUNT</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2136"">#2136</a> PR by <a href=""https://github.com/emzeat""><code>@​emzeat</code></a>.</li>; </ul>; </li>; </ul>; <h3>Fixes</h3>; <ul>; <li>fix pre-commit autoupdate for <code>core.useBuiltinFSMonitor=true</code> on windows.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2047"">#2047</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2046"">#2046</a> issue by <a href=""https://github.com/lcnittl""><code>@​lcnittl</code></a>.</li>; </ul>; </li>; <li>fix temporary file stashing with for <code>submodule.recurse=1</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2071"">#2071</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2063"">#2063</a> issue by <a href=""https://github.com/a666""><code>@​a666</code></a>.</li>; </ul>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pre-commit/pre-commit/blob/master/CHANGELOG.md"">pre-commit's changelog</a>.</em></p>; <blockquote>; <h1>2.17.0 - 2022-01-18</h1>; <h3>Features</h3>; <ul>; <li>add warnings for regexes containing <code>[\\/]</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2151"">#2151</a> issue by <a href=""https://github.com/sanjioh""><code>@​sanjioh</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2154"">#2154</a> PR by <a hre",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11460:6141,depend,dependabot,6141,https://hail.is,https://github.com/hail-is/hail/pull/11460,2,['depend'],['dependabot']
Integrability,"/github.com/psf/black/commit/afed2c01903465f9a486ac481a66aa3413cc1b01""><code>afed2c0</code></a> Load .gitignore and exclude regex at time of use</li>; <li><a href=""https://github.com/psf/black/commit/e269f44b25737360e0dc65379f889dfa931dc68a""><code>e269f44</code></a> Lazily import parallelized format modules</li>; <li><a href=""https://github.com/psf/black/commit/c47b91f513052cd39b818ea7c19716423c85c04e""><code>c47b91f</code></a> Fix misdetection of project root with <code>--stdin-filename</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3216"">#3216</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/psf/black/compare/22.3.0...22.8.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=black&package-manager=pip&previous-version=22.3.0&new-version=22.8.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12174:11542,depend,dependabot-security-updates,11542,https://hail.is,https://github.com/hail-is/hail/pull/12174,1,['depend'],['dependabot-security-updates']
Integrability,"/github.com/psf/black/commit/c47b91f513052cd39b818ea7c19716423c85c04e""><code>c47b91f</code></a> Fix misdetection of project root with <code>--stdin-filename</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3216"">#3216</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/psf/black/compare/22.3.0...22.8.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=black&package-manager=pip&previous-version=22.3.0&new-version=22.8.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12174:11864,Depend,Dependabot,11864,https://hail.is,https://github.com/hail-is/hail/pull/12174,1,['Depend'],['Dependabot']
Integrability,"/github.com/psf/requests/commit/60047ade64b0b882cbc94e047198818ab580911e""><code>60047ad</code></a> Bump github/codeql-action from 3.24.0 to 3.25.0</li>; <li><a href=""https://github.com/psf/requests/commit/31ebb8102c00f8cf8b396a6356743cca4362e07b""><code>31ebb81</code></a> Merge pull request <a href=""https://redirect.github.com/psf/requests/issues/6682"">#6682</a> from frenzymadness/pytest8</li>; <li>Additional commits viewable in <a href=""https://github.com/psf/requests/compare/v2.31.0...v2.32.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=requests&package-manager=pip&previous-version=2.31.0&new-version=2.32.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major versio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14555:10385,depend,dependabot,10385,https://hail.is,https://github.com/hail-is/hail/pull/14555,1,['depend'],['dependabot']
Integrability,"/github.com/pyca/cryptography/commit/0e0e46f5f73f477b8ee9682738c42129d5d60177""><code>0e0e46f</code></a> backport: initialize openssl's legacy provider in rust (<a href=""https://redirect.github.com/pyca/cryptography/issues/10323"">#10323</a>) (<a href=""https://redirect.github.com/pyca/cryptography/issues/10333"">#10333</a>)</li>; <li>See full diff in <a href=""https://github.com/pyca/cryptography/compare/42.0.2...42.0.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=42.0.2&new-version=42.0.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14332:3717,depend,dependabot-automerge-start,3717,https://hail.is,https://github.com/hail-is/hail/pull/14332,6,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"/github.com/python-jsonschema/jsonschema/commit/76b2e597d691e4cf5e9ebb7f3d1cff4f5da0115a""><code>76b2e59</code></a> Merge commit '095a009acc1938caf9596085d5581e7196021f66'</li>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/aeecae37b17b430c328d3c3e15bec90d30c8848b""><code>aeecae3</code></a> Squashed 'json/' changes from d40b3e62f..cf78d97d0</li>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/2f3a79c61176f60c9244d07fa8afb728218270ff""><code>2f3a79c</code></a> Merge commit 'aeecae37b17b430c328d3c3e15bec90d30c8848b'</li>; <li>Additional commits viewable in <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.6.0...v4.6.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jsonschema&package-manager=pip&previous-version=4.6.0&new-version=4.6.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11981:4230,depend,dependabot-security-updates,4230,https://hail.is,https://github.com/hail-is/hail/pull/11981,1,['depend'],['dependabot-security-updates']
Integrability,"/github.com/python-parsy/parsy/commit/2968580f9e98b44181d2c6c48c4890bc03081ebd""><code>2968580</code></a> Version bump for 1.4.0-dev1</li>; <li><a href=""https://github.com/python-parsy/parsy/commit/bbc1d75065108a4de64f10e169ea542b6f3167b6""><code>bbc1d75</code></a> Test example code as part of tests</li>; <li><a href=""https://github.com/python-parsy/parsy/commit/18df37a479f1bc4170999866433ca19f92f19f63""><code>18df37a</code></a> Dropped Python 3.4 from tox</li>; <li><a href=""https://github.com/python-parsy/parsy/commit/1d7189b5bf78bd0d8d6e4bb2170dfeabba659c5c""><code>1d7189b</code></a> Merge branch 'master' of github.com:python-parsy/parsy</li>; <li><a href=""https://github.com/python-parsy/parsy/commit/8ec01153ccf6c58e2811c0e4c760b98125aeebca""><code>8ec0115</code></a> Link to SQL example from README</li>; <li>Additional commits viewable in <a href=""https://github.com/python-parsy/parsy/compare/v1.1.0...v1.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=parsy&package-manager=pip&previous-version=1.1.0&new-version=1.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12007:3234,Depend,Dependabot,3234,https://hail.is,https://github.com/hail-is/hail/pull/12007,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"/github.com/robscott""><code>@​robscott</code></a>) [SIG API Machinery, Apps, Auth, Cloud Provider, Instrumentation, Network and Testing]</li>; <li>CustomResourceDefinitions added support for marking versions as deprecated by setting <code>spec.versions[*].deprecated</code> to <code>true</code>, and for optionally overriding the default deprecation warning with a <code>spec.versions[*].deprecationWarning</code> field. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92329"">kubernetes/kubernetes#92329</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>) [SIG API Machinery]</li>; <li>EnvVarSource api doc bug fixes (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91194"">kubernetes/kubernetes#91194</a>, <a href=""https://github.com/wawa0210""><code>@​wawa0210</code></a>) [SIG Apps]</li>; <li>Fix bug in reflector that couldn't recover from &quot;Too large resource version&quot; errors (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92537"">kubernetes/kubernetes#92537</a>, <a href=""https://github.com/wojtek-t""><code>@​wojtek-t</code></a>) [SIG API Machinery]</li>; <li>Fixed: log timestamps now include trailing zeros to maintain a fixed width (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91207"">kubernetes/kubernetes#91207</a>, <a href=""https://github.com/iamchuckss""><code>@​iamchuckss</code></a>) [SIG Apps and Node]</li>; <li>Generic ephemeral volumes, a new alpha feature under the <code>GenericEphemeralVolume</code> feature gate, provide a more flexible alternative to <code>EmptyDir</code> volumes: as with <code>EmptyDir</code>, volumes are created and deleted for each pod automatically by Kubernetes. But because the normal provisioning process is used (<code>PersistentVolumeClaim</code>), storage can be provided by third-party storage vendors and all of the usual volume features work. Volumes don't need to be empt; for example, restoring from snapsh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:6721,depend,dependabot,6721,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['depend'],['dependabot']
Integrability,"/github.com/tornadoweb/tornado/commit/7dfe8b597f2d179334d7b528f61e9449ac131273""><code>7dfe8b5</code></a> httpserver_test: Add ExpectLog to fix CI</li>; <li><a href=""https://github.com/tornadoweb/tornado/commit/217295b1dd30f556ea374d62007f6821688f00f0""><code>217295b</code></a> http1connection: Make content-length parsing more strict</li>; <li><a href=""https://github.com/tornadoweb/tornado/commit/e3aa6c5e2943242d8ab25448c2798365b3cb9945""><code>e3aa6c5</code></a> Merge pull request <a href=""https://redirect.github.com/tornadoweb/tornado/issues/3267"">#3267</a> from bdarnell/branch6.3</li>; <li>See full diff in <a href=""https://github.com/tornadoweb/tornado/compare/v6.3.2...v6.3.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=tornado&package-manager=pip&previous-version=6.3.2&new-version=6.3.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13432:2791,depend,dependabot-security-updates,2791,https://hail.is,https://github.com/hail-is/hail/pull/13432,2,['depend'],['dependabot-security-updates']
Integrability,"/googleapis/google-auth-library-python/commit/bd0ccc5fe77d55f7a19f5278d6b60587c393ee3c"">bd0ccc5</a>)</li>; </ul>; <h2>v2.3.2</h2>; <h3>Bug Fixes</h3>; <ul>; <li>add clock_skew_in_seconds to verify_token functions (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/894"">#894</a>) (<a href=""https://www.github.com/googleapis/google-auth-library-python/commit/8e95c1e458793593972b6b05a355aaeaecd31670"">8e95c1e</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/google-auth-library-python/blob/main/CHANGELOG.md"">google-auth's changelog</a>.</em></p>; <blockquote>; <h2><a href=""https://github.com/googleapis/google-auth-library-python/compare/v2.5.0...v2.6.0"">2.6.0</a> (2022-01-31)</h2>; <h3>Features</h3>; <ul>; <li>ADC can load an impersonated service account credentials. (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/962"">#962</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/52c8ef90058120d7d04d3d201adc111664be526c"">52c8ef9</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <ul>; <li>revert &quot;feat: add api key support (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/826"">#826</a>)&quot; (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/964"">#964</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/f9f23f4370f2a7a5b2c66ee56a5e700ef03b5b06"">f9f23f4</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/google-auth-library-python/compare/v2.4.1...v2.5.0"">2.5.0</a> (2022-01-25)</h2>; <h3>Features</h3>; <ul>; <li>ADC can load an impersonated service account credentials. (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/956"">#956</a>) (<a href=""https://github.com/googl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11546:5406,depend,dependabot,5406,https://hail.is,https://github.com/hail-is/hail/pull/11546,1,['depend'],['dependabot']
Integrability,"/googleapis/java-storage/issues/1775"">#1775</a>) (<a href=""https://github.com/googleapis/java-storage/commit/3b8d137a113376d7dac9010b9207d435df2622f7"">3b8d137</a>)</li>; </ul>; <h2>v2.15.0</h2>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.14.0...v2.15.0"">2.15.0</a> (2022-11-07)</h2>; <h3>Features</h3>; <ul>; <li>Add Autoclass support and sample (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1697"">#1697</a>) (<a href=""https://github.com/googleapis/java-storage/commit/82aacd7922573d6f4779f21cdc83de10616d7a08"">82aacd7</a>)</li>; <li>Update retries for Notifications (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1734"">#1734</a>) (<a href=""https://github.com/googleapis/java-storage/commit/0fb2f1823f9eff8534f15240321003f120fed3f4"">0fb2f18</a>)</li>; </ul>; <h3>Dependencies</h3>; <ul>; <li>Update dependency com.google.cloud:google-cloud-shared-dependencies to v3.0.6 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1761"">#1761</a>) (<a href=""https://github.com/googleapis/java-storage/commit/803a90b7747b8972f51d1407616c51084d97c589"">803a90b</a>)</li>; <li>Update dependency net.jqwik:jqwik to v1.7.1 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1758"">#1758</a>) (<a href=""https://github.com/googleapis/java-storage/commit/140e90911229c876de7b674dd1e61b278e8b07fd"">140e909</a>)</li>; <li>Update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.17 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1759"">#1759</a>) (<a href=""https://github.com/googleapis/java-storage/commit/7e3175a56a06dac0aa0841f221a486bb69b5c9bf"">7e3175a</a>)</li>; </ul>; <h2>v2.14.0</h2>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.13.1...v2.14.0"">2.14.0</a> (2022-10-26)</h2>; <h3>Google Cloud Storage gRPC API Preview</h3>; <p>The first release of <code>google-cloud-storage</code> with support for a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12529:2134,depend,dependabot,2134,https://hail.is,https://github.com/hail-is/hail/pull/12529,1,['depend'],['dependabot']
Integrability,"/h2>; <p>Added a function <code>decoratorx</code> using the <code>FunctionMaker</code> and thus; preserving the signature of <code>__code__</code> objects. Then fixed three small bugs:</p>; <ul>; <li>Sphinx was printing a few warnings when building the documentation, as; signaled by Tomasz Kłoczko</li>; <li>functions decorated with <code>decorator.contextmanager</code> were one-shot,; as discovered by Alex Pizarro.</li>; <li><code>decorator.decorator</code> was not passing the kwsyntax argument.</li>; </ul>; <h2>5.0.9 (2021-05-16)</h2>; <p>Fixed a test breaking PyPy. Restored support for Sphinx.</p>; <h2>5.0.8 (2021-05-15)</h2>; <p>Made the decorator module more robust when decorating builtin functions; lacking dunder attributes, like <code>dict.__setitem__</code>.</p>; <h2>5.0.7 (2021-04-14)</h2>; <p>The decorator module was not passing correctly the defaults inside the; <code>*args</code> tuple, thanks to Dan Shult for the fix. Also fixed some mispellings; in the documentation and integrated codespell in the CI, thanks to; Christian Clauss.</p>; <h2>5.0.6 (2021-04-08)</h2>; <p>The decorator module was not copying the <strong>module</strong> attribute anymore.; Thanks to Nikolay Markov for the notice.</p>; <h2>5.0.5 (2021-04-04)</h2>; <p>Dropped support for Python &lt; 3.5 with a substantial simplification of; the code base (now building a decorator does not require calling &quot;exec&quot;).; Added a way to mimic functools.wraps-generated decorators.; Ported the Continuous Integration from Travis to GitHub.</p>; <h2>4.4.2 (2020-02-29)</h2>; <p>Sylvan Mosberger (<a href=""https://github.com/Infinisil"">https://github.com/Infinisil</a>) contributed a patch to; some doctests that were breaking on NixOS.; John Vandenberg (<a href=""https://github.com/jayvdb"">https://github.com/jayvdb</a>) made a case for removing the usage</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://gi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11490:1658,integrat,integrated,1658,https://hail.is,https://github.com/hail-is/hail/pull/11490,1,['integrat'],['integrated']
Integrability,"/h2>; <p>Added a function <code>decoratorx</code> using the <code>FunctionMaker</code> and thus; preserving the signature of <code>__code__</code> objects. Then fixed three small bugs:</p>; <ul>; <li>Sphinx was printing a few warnings when building the documentation, as; signaled by Tomasz Kłoczko</li>; <li>functions decorated with <code>decorator.contextmanager</code> were one-shot,; as discovered by Alex Pizarro.</li>; <li><code>decorator.decorator</code> was not passing the kwsyntax argument.</li>; </ul>; <h2>5.0.9 (2021-05-16)</h2>; <p>Fixed a test breaking PyPy. Restored support for Sphinx.</p>; <h2>5.0.8 (2021-05-15)</h2>; <p>Made the decorator module more robust when decorating builtin functions; lacking dunder attributes, like <code>dict.__setitem__</code>.</p>; <h2>5.0.7 (2021-04-14)</h2>; <p>The decorator module was not passing correctly the defaults inside the; <code>*args</code> tuple, thanks to Dan Shult for the fix. Also fixed some mispellings; in the documentation and integrated codespell in the CI, thanks to; Christian Clauss.</p>; <h2>5.0.6 (2021-04-08)</h2>; <p>The decorator module was not copying the <strong>module</strong> attribute anymore.; Thanks to Nikolay Markov for the notice.</p>; <h2>5.0.5 (2021-04-04)</h2>; <p>Dropped support for Python &lt; 3.5 with a substantial simplification of; the code base (now building a decorator does not require calling &quot;exec&quot;).; Added a way to mimic functools.wraps-generated decorators.; Ported the Continuous Integration from Travis to GitHub.</p>; <h2>4.4.2 (2020-02-29)</h2>; <p>Sylvan Mosberger (<a href=""https://github.com/Infinisil"">https://github.com/Infinisil</a>) contributed a patch to; some doctests that were breaking on NixOS.; John Vandenberg (<a href=""https://github.com/jayvdb"">https://github.com/jayvdb</a>) made a case for removing the usage</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11799:1627,integrat,integrated,1627,https://hail.is,https://github.com/hail-is/hail/pull/11799,1,['integrat'],['integrated']
Integrability,"/h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.1.html</a></p>; <h2>Elasticsearch Hadoop 8.5.0</h2>; <p>Downloads: <a href=""https://elastic.co/downloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/da4f3c3f209aea47d69c4faf90029a6933bd3a60""><code>da4f3c3</code></a> [DOCS] Add 8.5.3 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2045"">#2045</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2050"">#2050</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/79d592abdce1cd90845d153afab8b66069e2a172""><code>79d592a</code></a> [DOCS] Add 8.5.2 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2042"">#2042</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2049"">#2049</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/712f518822ff281abdd6f83c2e0ea97857dbf6ba""><code>712f518</code></a> [DOCS] Add 8.5.1 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2040"">#2040</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/0a8e0bca839408ba7cdd4e1e4ef669894f29e96f""><code>0a8e0bc</code></a> [DOCS] Add 8.5.0 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2032"">#2032</a>)</li>; <li><a h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12601:2311,depend,dependabot,2311,https://hail.is,https://github.com/hail-is/hail/pull/12601,1,['depend'],['dependabot']
Integrability,"/htsjdk/issues/1632"">#1632</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/14a8cc022c98caa27df9d5aa876aeb5394f197ad""><code>14a8cc0</code></a> Use allele info in VariantContext comparisons for stable sorts (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1593"">#1593</a>)</li>; <li>See full diff in <a href=""https://github.com/samtools/htsjdk/compare/3.0.2...3.0.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.github.samtools:htsjdk&package-manager=gradle&previous-version=3.0.2&new-version=3.0.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12700:3650,depend,dependabot-automerge-start,3650,https://hail.is,https://github.com/hail-is/hail/pull/12700,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"/ipython/comm/issues/27"">#27</a>)</li>; <li><a href=""https://github.com/ipython/comm/commit/915898ddeddd0d1c8a1b87c5dcfbe6392fd225b7""><code>915898d</code></a> chore: update pre-commit hooks (<a href=""https://redirect.github.com/ipython/comm/issues/26"">#26</a>)</li>; <li>See full diff in <a href=""https://github.com/ipython/comm/compare/v0.2.1...v0.2.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=comm&package-manager=pip&previous-version=0.2.1&new-version=0.2.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14492:4124,Depend,Dependabot,4124,https://hail.is,https://github.com/hail-is/hail/pull/14492,1,['Depend'],['Dependabot']
Integrability,"/ipython/commit/560ad109197c0f8373865896af369bb3b36fd229""><code>560ad10</code></a> DOC: Update what's new for 8.10 (<a href=""https://github-redirect.dependabot.com/ipython/ipython/issues/13939"">#13939</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/7557ade0ed927475d5ab5b573d0ea4febfb22683""><code>7557ade</code></a> DOC: Update what's new for 8.10</li>; <li><a href=""https://github.com/ipython/ipython/commit/385d69325319a5972ee9b5983638e3617f21cb1f""><code>385d693</code></a> Merge pull request from GHSA-29gw-9793-fvw7</li>; <li><a href=""https://github.com/ipython/ipython/commit/e548ee23ac460a99901f1cd43b94ae84a35ec393""><code>e548ee2</code></a> Swallow potential exceptions from showtraceback() (<a href=""https://github-redirect.dependabot.com/ipython/ipython/issues/13934"">#13934</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/0694b08b436203817059ec7e7136cf8561a6f013""><code>0694b08</code></a> MAINT: mock slowest test. (<a href=""https://github-redirect.dependabot.com/ipython/ipython/issues/13885"">#13885</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/865591252a67c6907fe03228b4053305715286e6""><code>8655912</code></a> MAINT: mock slowest test.</li>; <li><a href=""https://github.com/ipython/ipython/commit/a011765b44febfb11bae122d2ed7db763621ac8f""><code>a011765</code></a> Isolate the attack tests with setUp and tearDown methods</li>; <li><a href=""https://github.com/ipython/ipython/commit/c7a9470e540392c575aac46c3ee5cf4fe5123eb1""><code>c7a9470</code></a> Add some regression tests for this change</li>; <li><a href=""https://github.com/ipython/ipython/commit/fd34cf5f1f6e243243c738c6e0cf62eb682c4d68""><code>fd34cf5</code></a> Swallow potential exceptions from showtraceback()</li>; <li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/7.34.0...8.10.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12683:1298,depend,dependabot,1298,https://hail.is,https://github.com/hail-is/hail/pull/12683,1,['depend'],['dependabot']
Integrability,"/ipython/issues/13885"">#13885</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/865591252a67c6907fe03228b4053305715286e6""><code>8655912</code></a> MAINT: mock slowest test.</li>; <li><a href=""https://github.com/ipython/ipython/commit/a011765b44febfb11bae122d2ed7db763621ac8f""><code>a011765</code></a> Isolate the attack tests with setUp and tearDown methods</li>; <li><a href=""https://github.com/ipython/ipython/commit/c7a9470e540392c575aac46c3ee5cf4fe5123eb1""><code>c7a9470</code></a> Add some regression tests for this change</li>; <li><a href=""https://github.com/ipython/ipython/commit/fd34cf5f1f6e243243c738c6e0cf62eb682c4d68""><code>fd34cf5</code></a> Swallow potential exceptions from showtraceback()</li>; <li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/7.34.0...8.10.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ipython&package-manager=pip&previous-version=7.34.0&new-version=8.10.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` w",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12683:2304,depend,dependency-name,2304,https://hail.is,https://github.com/hail-is/hail/pull/12683,2,['depend'],['dependency-name']
Integrability,"/issues/10112"">#10112</a>: extlinks: Disable hardcoded links detector by default</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9993"">#9993</a>, <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10177"">#10177</a>: std domain: Disallow to refer an inline target via; :rst:role:<code>ref</code> role</li>; </ul>; <h2>Deprecated</h2>; <ul>; <li><code>sphinx.ext.napoleon.docstring.GoogleDocstring._qualify_name()</code></li>; </ul>; <h2>Features added</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10260"">#10260</a>: Enable <code>FORCE_COLOR</code> and <code>NO_COLOR</code> for terminal colouring</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10234"">#10234</a>: autosummary: Add &quot;autosummary&quot; CSS class to summary tables</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10125"">#10125</a>: extlinks: Improve suggestion message for a reference having title</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10112"">#10112</a>: extlinks: Add :confval:<code>extlinks_detect_hardcoded_links</code> to enable; hardcoded links detector feature</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9494"">#9494</a>, <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9456"">#9456</a>: html search: Add a config variable; :confval:<code>html_show_search_summary</code> to enable/disable the search summaries</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9337"">#9337</a>: HTML theme, add option <code>enable_search_shortcuts</code> that enables :kbd:'/' as; a Quick search shortcut and :kbd:<code>Esc</code> shortcut that; removes search highlighting.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10107"">#10107</a>: i18n: Allow to suppress translation warnings by adding <c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11714:1948,message,message,1948,https://hail.is,https://github.com/hail-is/hail/pull/11714,2,['message'],['message']
Integrability,"/issues/11618"">#11618</a> [component: tests] Reduce Tornado imports</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11628"">#11628</a> [component: docs] Correct path in dev guide server instructions</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11652"">#11652</a> [component: build] Update bokehjs' dependencies</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11668"">#11668</a> [component: docs] Add information about mathjax bundle</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11681"">#11681</a> [NO SQUASH] Batch of 3.0 -&gt; 2.4 backports</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11712"">#11712</a> [component: tests] Upgrade baselines to Chrome 94</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11722"">#11722</a> [component: tests] Update visual baselines on MacOS</li>; <li><a href=""https://github-redirect.dependabot.com/bokeh/bokeh/issues/11724"">#11724</a> [NO SQUASH] More 3.0 -&gt; 2.4 backports</li>; </ul>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/bokeh/bokeh/commit/ad33147f5762af8830e68144419e31e46a024caf""><code>ad33147</code></a> Deployment updates for release 2.4.2</li>; <li><a href=""https://github.com/bokeh/bokeh/commit/17578f3a7fce22af09cf105c67769890dfdb5705""><code>17578f3</code></a> also update latest=2.4.2</li>; <li><a href=""https://github.com/bokeh/bokeh/commit/e3e182a740b1a88f6b13d83656df296e02616506""><code>e3e182a</code></a> Merge deployment staging branch staging-2.4.2rc1</li>; <li><a href=""https://github.com/bokeh/bokeh/commit/6bcda8a0b0a6ff9c4449abb40082b63c3ea7e3e4""><code>6bcda8a</code></a> Deployment updates for release 2.4.2rc1</li>; <li><a href=""https://github.com/bokeh/bokeh/commit/638d3ee438716feceac319c40fa6b17655457e5d""><code>638d3ee</code></a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11540:6490,depend,dependabot,6490,https://hail.is,https://github.com/hail-is/hail/pull/11540,1,['depend'],['dependabot']
Integrability,"/issues/1188"">#1188</a>)</li>; <li>Fix navigation right padding on level2+ elements (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1068"">#1068</a>)</li>; <li>Fix navigation expansion button sizes (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1067"">#1067</a>)</li>; <li>Wrap inline literals (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1050"">#1050</a>)</li>; <li>Fix aria labels (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1056"">#1056</a>)</li>; <li>Don't toggle navigation terminal nodes (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1049"">#1049</a>)</li>; <li>Fix <code>&lt;pre&gt;</code> overflow (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1220"">#1220</a>)</li>; <li>Fix literal/ref style inside <code>&lt;dl&gt;</code> (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1088"">#1088</a>)</li>; </ul>; <p>Other Changes</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/readthedocs/sphinx_rtd_theme/commit/c9b1bde560d8ee31400e4e4f92f2e8d7a42265ce""><code>c9b1bde</code></a> Replace sphinx reST with native reST</li>; <li><a href=""https://github.com/readthedocs/sphinx_rtd_theme/commit/15e4a9029194083d34e0dffa9b3f297a7692164e""><code>15e4a90</code></a> Update translations for 1.0 release</li>; <li><a href=""https://github.com/readthedocs/sphinx_rtd_theme/commit/2254b1f1e871f05036c47324825c601c422702c5""><code>2254b1f</code></a> Update docs and versions for 1.0.0 release</li>; <li><a href=""https://github.com/readthedocs/sphinx_rtd_theme/commit/acada32f5d3c57d38413434a6ee83d28b5d61cd8""><code>acada32</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/122",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11464:4413,depend,dependabot,4413,https://hail.is,https://github.com/hail-is/hail/pull/11464,2,['depend'],['dependabot']
Integrability,"/issues/13425"">#13425</a>) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/python/mypy/compare/v0.950...v0.982"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mypy&package-manager=pip&previous-version=0.950&new-version=0.982)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12291:3391,Depend,Dependabot,3391,https://hail.is,https://github.com/hail-is/hail/pull/12291,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"/issues/1602"">#1602</a>)</li>; <li><a href=""https://github.com/samtools/htsjdk/commit/6507249a4422d021b984e710e8f031816f6d8da2""><code>6507249</code></a> Make the CRAM MD5 failure message more user friendly. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1607"">#1607</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/samtools/htsjdk/compare/2.24.1...3.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.github.samtools:htsjdk&package-manager=gradle&previous-version=2.24.1&new-version=3.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12229:9445,depend,dependabot-automerge-start,9445,https://hail.is,https://github.com/hail-is/hail/pull/12229,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"/issues/1768"">#1768</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/e194631088aee587140c029a0404f8d40c6765b5""><code>e194631</code></a> Bump astroid to 2.12.6, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/1f5dc457729d7219178ace9705d8445e89513472""><code>1f5dc45</code></a> Handle <code>dataclass</code> <code>kw_only</code> keyword correctly (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1764"">#1764</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/astroid/compare/v2.11.5...v2.12.9"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=astroid&package-manager=pip&previous-version=2.11.5&new-version=2.12.9)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12161:5114,Depend,Dependabot,5114,https://hail.is,https://github.com/hail-is/hail/pull/12161,1,['Depend'],['Dependabot']
Integrability,"/issues/222"">#222</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/a9b90238f74f1c5f69d7dcafb83c9775504f9b3b""><code>a9b9023</code></a> Fix typos (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/224"">#224</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/compare/1.11.1...1.18.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx-autodoc-typehints&package-manager=pip&previous-version=1.11.1&new-version=1.18.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11909:7827,depend,dependabot-automerge-start,7827,https://hail.is,https://github.com/hail-is/hail/pull/11909,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"/issues/2301"">#2301</a> PR by <a href=""https://github.com/jeff-m-sullivan""><code>@​jeff-m-sullivan</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2300"">#2300</a> issue by <a href=""https://github.com/jeff-m-sullivan""><code>@​jeff-m-sullivan</code></a>.</li>; </ul>; </li>; <li>Fix a rare race condition in change stashing.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2323"">#2323</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2287"">#2287</a> issue by <a href=""https://github.com/ian-h-chamberlain""><code>@​ian-h-chamberlain</code></a>.</li>; </ul>; </li>; </ul>; <h3>Updating</h3>; <ul>; <li>Remove python3.6 support. Note that pre-commit still supports running hooks written in older versions, but pre-commit itself requires python 3.7+.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2215"">#2215</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>pre-commit has migrated from the <code>master</code> branch to <code>main</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2302"">#2302</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pre-commit/pre-commit/blob/main/CHANGELOG.md"">pre-commit's changelog</a>.</em></p>; <blockquote>; <h1>2.18.1 - 2022-04-02</h1>; <h3>Fixes</h3>; <ul>; <li>Fix regression for <code>repo: local</code> hooks running <code>python&lt;3.7</code>; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2324"">#2324</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; </ul>; <h1>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11731:4778,depend,dependabot,4778,https://hail.is,https://github.com/hail-is/hail/pull/11731,1,['depend'],['dependabot']
Integrability,"/issues/23179"">#23179</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/038b35f890d2363edc1254ac2ee61918b2b84b66""><code>038b35f</code></a> [Storage] Fix bug with <code>ignore_read_only</code> in <code>start_copy_from_url()</code> (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23141"">#23141</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/5166ee94acdb80f2217a1ce694e169ea2b33219d""><code>5166ee9</code></a> [Storage] Fix <code>upload_blob()</code> from an OS pipe on Linux (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23211"">#23211</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-storage-blob_12.8.1...azure-storage-blob_12.11.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=azure-storage-blob&package-manager=pip&previous-version=12.8.1&new-version=12.11.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11703:6406,depend,dependency-name,6406,https://hail.is,https://github.com/hail-is/hail/pull/11703,1,['depend'],['dependency-name']
Integrability,"/issues/30163"">#30163</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/grpc/grpc/compare/v1.47.0...v1.48.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=grpcio&package-manager=pip&previous-version=1.47.0&new-version=1.48.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12201:6775,Depend,Dependabot,6775,https://hail.is,https://github.com/hail-is/hail/pull/12201,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"/issues/375"">#375</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/6fa17735fe3edb45483ec5e3abd1f53c24ffa881""><code>6fa1773</code></a> feat!: support string-encoded json (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/339"">#339</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/python-logging/compare/v1.12.1...v3.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=google-cloud-logging&package-manager=pip&previous-version=1.12.1&new-version=3.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11574:14583,depend,dependabot-automerge-start,14583,https://hail.is,https://github.com/hail-is/hail/pull/11574,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"/issues/5273"">#5273</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/c688451ce31b914c71b11d2ac6c326b0c87e6d1f""><code>c688451</code></a> Removed duplicate timeout parameter in ClientSession reference docs. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5262"">#5262</a>) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10115:9451,depend,dependabot-automerge-start,9451,https://hail.is,https://github.com/hail-is/hail/pull/10115,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"/issues/61"">Issue 61</a> - Add documentation for methods or helpers that are specific to qtpy (<a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/357"">PR 357</a> by <a href=""https://github.com/dalthviz""><code>@​dalthviz</code></a>)</li>; </ul>; <p>In this release 5 issues were closed.</p>; <h3>Pull Requests Merged</h3>; <ul>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/358"">PR 358</a> - PR: Fix PyQt6 typing import for Qt, by <a href=""https://github.com/tlambert03""><code>@​tlambert03</code></a></li>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/357"">PR 357</a> - PR: Add initial <code>Methods, helpers and QtPy namespace specifics</code> section to the README, by <a href=""https://github.com/dalthviz""><code>@​dalthviz</code></a> (<a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/issues/61"">61</a>)</li>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/354"">PR 354</a> - PR: Add wrapper around sip/shiboken isdeleted/isvalid (compat.py), by <a href=""https://github.com/zjp""><code>@​zjp</code></a> (<a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/issues/302"">302</a>)</li>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/353"">PR 353</a> - PR: Add note to readme about use with Pyright, by <a href=""https://github.com/CAM-Gerlach""><code>@​CAM-Gerlach</code></a> (<a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/issues/352"">352</a>)</li>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/350"">PR 350</a> - PR: Restore <code>WEBENGINE</code> constant in <code>QtWebEngineWidgets</code>, by <a href=""https://github.com/ccordoba12""><code>@​ccordoba12</code></a></li>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/346"">PR 346</a> - PR: Add workaround for <code>mode</code> argument in QTextCursor.movePosition (PySide6), by <a href=""https://github.com/rear1019""><code>@​rear1019",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12194:5045,wrap,wrapper,5045,https://hail.is,https://github.com/hail-is/hail/pull/12194,1,['wrap'],['wrapper']
Integrability,"/issues/8153"">#8153</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/338a65a7df74e189f6b5d1d3a6315ffa911b21c2""><code>338a65a</code></a> 39.0.0 version bump (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7954"">#7954</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/84a3cd7abb16f594d8c315e8aedb4be02583bf6a""><code>84a3cd7</code></a> automatically download and upload circleci wheels (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7949"">#7949</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/525c0b3d5d89eab7f953be5de5d2b75da1c816f8""><code>525c0b3</code></a> Type annotate release.py (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7951"">#7951</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/46d2a94d1b574abf5b9e88f84fa7400a138c4edb""><code>46d2a94</code></a> Use the latest 3.10 release when wheel building (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7953"">#7953</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/f150dc15582c05b1b94cf08ed3b1fbc9c4f52267""><code>f150dc1</code></a> fix CI to work with ubuntu 22.04 (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7950"">#7950</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/8867724b2b6db528d2900414ef86c122a1f5602a""><code>8867724</code></a> fix README for python3 (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7947"">#7947</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pyca/cryptography/compare/38.0.4...39.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=38.0.4&new-version=39.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12668:5422,depend,dependabot,5422,https://hail.is,https://github.com/hail-is/hail/pull/12668,4,['depend'],['dependabot']
Integrability,"/issues/995"">#995</a></li>; <li>Additional commits viewable in <a href=""https://github.com/microsoft/debugpy/compare/v1.6.0...v1.6.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=debugpy&package-manager=pip&previous-version=1.6.0&new-version=1.6.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12103:6071,Depend,Dependabot,6071,https://hail.is,https://github.com/hail-is/hail/pull/12103,34,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"/jna/commit/0d7499f105e4495bdea15fc21f5b1046e81ca822""><code>0d7499f</code></a> Release 5.12.0</li>; <li><a href=""https://github.com/java-native-access/jna/commit/fa86166d4f75ef4478de7ad9d7d6c0b6b6933ee0""><code>fa86166</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1445"">#1445</a> from matthiasblaesing/aix</li>; <li><a href=""https://github.com/java-native-access/jna/commit/4cca4405f7f6bc32d2a08495efb81c081b065279""><code>4cca440</code></a> Fix name mapping difference between AIX JDK 8 and Semeru JDK 18</li>; <li><a href=""https://github.com/java-native-access/jna/commit/f58b0f8f6b5c013adfe44a2cfb018ccb6ef6a688""><code>f58b0f8</code></a> Improve test stability on AIX (exclude tests that are expected to fail)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/c1565fb89469cbcba67b1cc305e16d520779b270""><code>c1565fb</code></a> Handle race condition in PdhUtil#PdhEnumObjectItems (<a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1442"">#1442</a>)</li>; <li><a href=""https://github.com/java-native-access/jna/commit/99fcfa822db86b1f2ba5823dbf17efeb3d246ad5""><code>99fcfa8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1444"">#1444</a> from matthiasblaesing/update_libffi</li>; <li><a href=""https://github.com/java-native-access/jna/commit/9e473350a5ad5e04aab8b01e4018f973976e19f8""><code>9e47335</code></a> Update CHANGES.md</li>; <li>Additional commits viewable in <a href=""https://github.com/java-native-access/jna/compare/5.6.0...5.12.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=net.java.dev.jna:jna&package-manager=gradle&previous-version=5.6.0&new-version=5.12.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Depe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:7206,depend,dependabot,7206,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['depend'],['dependabot']
Integrability,"/jupyter/jupyter_client/pull/924"">#924</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; <li>Prefer print in kernelspecapp <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/923"">#923</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_client/graphs/contributors?from=2023-01-26&amp;to=2023-01-30&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Ablink1073+updated%3A2023-01-26..2023-01-30&amp;type=Issues""><code>@​blink1073</code></a></p>; <!-- raw HTML omitted -->; <h2>8.0.1</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v8.0.0...dc6113c360e05122430b8e130374e9f4e4b701d7"">Full Changelog</a>)</p>; <h3>Bugs fixed</h3>; <ul>; <li>Fix json_output in kernelspec app <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/921"">#921</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_client/graphs/contributors?from=2023-01-26&amp;to=2023-01-26&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Ablink1073+updated%3A2023-01-26..2023-01-26&amp;type=Issues""><code>@​blink1073</code></a></p>; <h2>8.0.0</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v7.3.5...760a7835d8b20a9daea3737759b1751d5e55dad8"">Full Changelog</a>)</p>; <p>This release is primarily focused on improving <code>asyncio</code> support, while aiming to have minimal API changes.</p>; <h3>Enhancements made</h3>; <ul>; <li>Remove nest-asyncio dependency <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/835"">#835</a> (<a href=""https://github.com/blink10",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12656:4482,depend,dependabot,4482,https://hail.is,https://github.com/hail-is/hail/pull/12656,1,['depend'],['dependabot']
Integrability,"/jupyter/nbconvert/pull/1795"">jupyter/nbconvert#1795</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1796"">jupyter/nbconvert#1796</a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/jupyter/nbconvert/commit/27a7fcbd9cb55d1c30818b1c8b5918bb178a243f""><code>27a7fcb</code></a> Release 7.0.0</li>; <li><a href=""https://github.com/jupyter/nbconvert/commit/a5e2666d580d2a289fe879c2feaf70809ce3446b""><code>a5e2666</code></a> Update Changelog for 7.0 (<a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/issues/1845"">#1845</a>)</li>; <li><a href=""https://github.com/jupyter/nbconvert/commit/8c1146d756175824dfb1e939d86fddfcc3979fdd""><code>8c1146d</code></a> Handle nbformat 5.5 (<a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/issues/1841"">#1841</a>)</li>; <li><a href=""https://github.com/jupyter/nbconvert/commit/aec39288c9a6c614d659bcaf9f5cb36634d6b37b""><code>aec3928</code></a> Encode SVG image data as UTF-8 before calling lxml cleaner (fixes <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/issues/1836"">#1836</a>) (<a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/issues/1837"">#1837</a>)</li>; <li><a href=""https://github.com/jupyter/nbconvert/commit/fec53c9f5fa21f91d5a13c2295f7f9b1e6a1d41f""><code>fec53c9</code></a> Remove tests from bdist (<a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/issues/1822"">#1822</a>)</li>; <li><a href=""https://github.com/jupyter/nbconvert/commit/af4ee6ba3e4badbb42fdce4b34d1d34a4fccc655""><code>af4ee6b</code></a> Fix title (<a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/issues/1832"">#1832</a>)</li>; <li><a href=""https://github.com/jupyter/nbconvert/commit/4680a6db10338ea14c39fe0e6cc6a1959",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12126:9720,depend,dependabot,9720,https://hail.is,https://github.com/hail-is/hail/pull/12126,1,['depend'],['dependabot']
Integrability,"/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2842"">cbeust/testng#2842</a></li>; <li>Deprecate support for running Spock Tests by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2846"">cbeust/testng#2846</a></li>; <li>Streamline dependsOnMethods for configurations by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2845"">cbeust/testng#2845</a></li>; <li>Ensure ITestContext available for JUnit4 tests by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2848"">cbeust/testng#2848</a></li>; <li>Deprecate support for running JUnit tests by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2849"">cbeust/testng#2849</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/gruenich""><code>@​gruenich</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2781"">cbeust/testng#2781</a></li>; <li><a href=""https://github.com/anatolyuzhakov""><code>@​anatolyuzhakov</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2793"">cbeust/testng#2793</a></li>; <li><a href=""https://github.com/spkrka""><code>@​spkrka</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2802"">cbeust/testng#2802</a></li>; <li><a href=""https://github.com/JLLeitschuh""><code>@​JLLeitschuh</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2806"">cbeust/testng#2806</a></li>; <li><a href=""https://github.com/seregamorph""><code>@​seregamorp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:7959,depend,dependabot,7959,https://hail.is,https://github.com/hail-is/hail/pull/12665,1,['depend'],['dependabot']
Integrability,"/li>; </ul>; <h1>v24.2.1</h1>; <ul>; <li>fixed watch.stream bug of not working with apis with follow kwarg (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/pull/216"">#216</a>, <a href=""https://github.com/mcreng""><code>@​mcreng</code></a>)</li>; </ul>; <h1>v24.2.0</h1>; <p>Kubernetes API Version: v1.24.2</p>; <h3>API Change</h3>; <ul>; <li>Add 2 new options for kube-proxy running in winkernel mode. <code>--forward-healthcheck-vip</code>, if specified as true, health check traffic whose destination is service VIP will be forwarded to kube-proxy's healthcheck service. <code>--root-hnsendpoint-name</code> specifies the name of the hns endpoint for the root network namespace. This option enables the pass-through load balancers like Google's GCLB to correctly health check the backend services. Without this change, the health check packets is dropped, and Windows node will be considered to be unhealthy by those load balancers. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/99287"">kubernetes/kubernetes#99287</a>, <a href=""https://github.com/anfernee""><code>@​anfernee</code></a>)</li>; <li>Added CEL runtime cost calculation into CustomerResource validation. CustomerResource validation will fail if runtime cost exceeds the budget. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108482"">kubernetes/kubernetes#108482</a>, <a href=""https://github.com/cici37""><code>@​cici37</code></a>)</li>; <li>Added a new metric <code>webhook_fail_open_count</code> to monitor webhooks that fail to open. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107171"">kubernetes/kubernetes#107171</a>, <a href=""https://github.com/ltagliamonte-dd""><code>@​ltagliamonte-dd</code></a>)</li>; <li>Adds a new Status subresource in Network Policy objects (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107963"">kubernetes/kubernetes#107963</a>, <a href=""https://github.com/rikatz""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:1523,depend,dependabot,1523,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['depend'],['dependabot']
Integrability,"/li>; </ul>; <h2>3.13.1</h2>; <h2>Fixed</h2>; <ul>; <li>Temporarily comment out to avoid warning during <code>import humanize</code> (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/243"">#243</a>) <a href=""https://github.com/hugovk""><code>@​hugovk</code></a></li>; </ul>; <h2>3.13.0</h2>; <h2>Added</h2>; <ul>; <li>Add da_DK language (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/238"">#238</a>) <a href=""https://github.com/dejurin""><code>@​dejurin</code></a></li>; <li>Fix and add Russian and Ukrainian words (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/235"">#235</a>) <a href=""https://github.com/dejurin""><code>@​dejurin</code></a></li>; <li>Add missing strings for Polish translation (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/182"">#182</a>) <a href=""https://github.com/kpostekk""><code>@​kpostekk</code></a></li>; <li>Add Traditional Chinese (zh-HK) (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/233"">#233</a>) <a href=""https://github.com/edwardmfho""><code>@​edwardmfho</code></a></li>; </ul>; <h2>Changed</h2>; <ul>; <li>Remove redundant setuptools from install_requires (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/232"">#232</a>) <a href=""https://github.com/arthurzam""><code>@​arthurzam</code></a></li>; </ul>; <h2>Deprecated</h2>; <ul>; <li>This is the last release to support Python 3.6</li>; <li>Deprecate private functions (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/234"">#234</a>) <a href=""https://github.com/samueljsb""><code>@​samueljsb</code></a></li>; <li>Reinstate <code>VERSION</code> and deprecate (<a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/240"">#240</a>) <a href=""https://github.com/hugovk""><code>@​hugovk</code></a></li>; </ul>; <h2>3.12.0</h2>; <h2>Added</h2>; <ul>; <li>Add support for Python 3.10 (<a href=""https://github-redirect.dependabot.com/jmoiron/huma",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11517:2931,depend,dependabot,2931,https://hail.is,https://github.com/hail-is/hail/pull/11517,2,['depend'],['dependabot']
Integrability,"/li>; </ul>; <h2>5.0.0</h2>; <ul>; <li>Add <code>gidgethub.routing.Router.fetch</code> for obtaining a frozenset of functions; registered to the router that the event would be called on.; [Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/74"">#74</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/74"">brettcannon/gidgethub#74</a>).</li>; <li>Add support for GitHub Actions Environment Files with <code>gidgethub.actions.setenv</code>; and <code>gidgethub.actions.addpath</code>.; [Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/137"">#137</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/132"">brettcannon/gidgethub#132</a>).</li>; <li>Make router callback execution order non-deterministic to avoid relying on; registration order.; [Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/74"">#74</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/74"">brettcannon/gidgethub#74</a>).</li>; <li>Fix mypy errors in <code>gidgethub.httpx.GitHubAPI._request</code>[Issue <a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/133"">#133</a>](<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/133"">brettcannon/gidgethub#133</a>).</li>; <li>Make the minimum version of PyJWT be v2.0.0.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/brettcannon/gidgethub/blob/main/docs/changelog.rst"">gidgethub's changelog</a>.</em></p>; <blockquote>; <h2>5.2.1</h2>; <ul>; <li>; <p>Fix cgi and importlib_resources deprecations.; (<code>PR [#185](https://github.com/brettcannon/gidgethub/issues/185) &lt;https://github.com/brettcannon/gidgethub/pull/185&gt;_</code>)</p>; </li>; <li>; <p>Add support for Python 3.11 and drop EOL Python 3.6; (<code>PR [#184](https://github.com/brettcannon/gidgethub/issu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12328:3666,depend,dependabot,3666,https://hail.is,https://github.com/hail-is/hail/pull/12328,1,['depend'],['dependabot']
Integrability,"/li>; <li><a href=""https://github.com/PyCQA/pylint/commit/b25859c4a56ccce61087f7a1270f40deaed68169""><code>b25859c</code></a> Fix false positive for <code>superfluous-parens</code> for <code>return (a or b) in iterable</code>...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/0e1ca11ac65cbe5a65437518fca1e25f1ad0e48e""><code>0e1ca11</code></a> Bump pylint to 2.13.1, update changelog</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/v2.12.2...v2.13.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pylint&package-manager=pip&previous-version=2.12.2&new-version=2.13.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11702:5208,depend,dependabot,5208,https://hail.is,https://github.com/hail-is/hail/pull/11702,1,['depend'],['dependabot']
Integrability,"/li>; <li><a href=""https://github.com/PyCQA/pylint/commit/f8f05f12522c0036668f9a0da86fa0d3456ed795""><code>f8f05f1</code></a> Don't emit <code>modified-iterating-dict</code> when updating existing keys (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7037"">#7037</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/bee24cd55af4f1231e787aed5a1cc072492adee6""><code>bee24cd</code></a> Avoid hangs on many-core Windows machines (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7035"">#7035</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/b379ef3acc2a983140994c93a2ea2c99e260c9c1""><code>b379ef3</code></a> Fix handling of quoted <code>init-hook</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7010"">#7010</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c15902462af9100b5f7301f0cc978f2296e5d42f""><code>c159024</code></a> Fix differing param doc false positive (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6980"">#6980</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/680edebc686cad664bbed934a490aeafa775f163""><code>680edeb</code></a> Bump pylint to 2.14.3, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/b05ac51ad2e3785b6b9b071b8cb241993c914105""><code>b05ac51</code></a> Pin <code>colorama</code> to lowest supported version (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6970"">#6970</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/v2.13.5...v2.14.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pylint&package-manager=pip&previous-version=2.13.5&new-version=2.14.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11980:2175,depend,dependabot,2175,https://hail.is,https://github.com/hail-is/hail/pull/11980,1,['depend'],['dependabot']
Integrability,"/li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/9d498ca1e632fe1976ea1dae0ea083b29b0cc4c0""><code>9d498ca</code></a> Bump sphinx from 7.1.1 to 7.2.6 (<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7606"">#7606</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.8.6...v3.9.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.8.6&new-version=3.9.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14027:10250,Depend,Dependabot,10250,https://hail.is,https://github.com/hail-is/hail/pull/14027,6,['Depend'],['Dependabot']
Integrability,"/li>; <li><a href=""https://github.com/boto/boto3/commit/47f20744b3c57223da5e14e185120586f8212af8""><code>47f2074</code></a> Merge branch 'release-1.26.13'</li>; <li><a href=""https://github.com/boto/boto3/commit/3d4081ccb7c350538ba3d6a5073c59575a812eb0""><code>3d4081c</code></a> Merge branch 'release-1.26.13' into develop</li>; <li>Additional commits viewable in <a href=""https://github.com/boto/boto3/compare/1.26.7...1.26.15"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=boto3&package-manager=pip&previous-version=1.26.7&new-version=1.26.15)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12498:9821,depend,dependabot-automerge-start,9821,https://hail.is,https://github.com/hail-is/hail/pull/12498,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"/li>; <li><a href=""https://github.com/boto/boto3/commit/cc2984fc4fe2a399404a81711eb9ece3fb8d6eb7""><code>cc2984f</code></a> Merge branch 'release-1.26.15'</li>; <li><a href=""https://github.com/boto/boto3/commit/9280e856b07feef67b8dc08c3663ffd0b65b8f55""><code>9280e85</code></a> Merge branch 'release-1.26.15' into develop</li>; <li>Additional commits viewable in <a href=""https://github.com/boto/boto3/compare/1.26.7...1.26.17"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=boto3&package-manager=pip&previous-version=1.26.7&new-version=1.26.17)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12507:9015,depend,dependabot-automerge-start,9015,https://hail.is,https://github.com/hail-is/hail/pull/12507,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"/li>; <li><a href=""https://github.com/ipython/ipython/commit/f64d2b1d0a32b858cbcb540699c9d7997d9ae935""><code>f64d2b1</code></a> Merge branch 'main' into madbird1304/issue-13073-fix-paste-magic</li>; <li><a href=""https://github.com/ipython/ipython/commit/0a8b189aa2ef5e146dcd6aa461c7ba67e979c430""><code>0a8b189</code></a> Show &quot;maxlen&quot; in deque repr</li>; <li><a href=""https://github.com/ipython/ipython/commit/6e3d5b4f5290b03b42fc64c94f902281d1c739d9""><code>6e3d5b4</code></a> Replaced getting cwd from os.getcwd() to pathlib.Path.cwd() in cd().</li>; <li><a href=""https://github.com/ipython/ipython/commit/4e1c56c056e1b7e234bcef3572aff5cd630ed0d9""><code>4e1c56c</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/ipython/ipython/issues/13739"">#13739</a> from Carreau/black</li>; <li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/7.34.0...8.5.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ipython&package-manager=pip&previous-version=7.34.0&new-version=8.5.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` w",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12180:2446,Depend,Dependabot,2446,https://hail.is,https://github.com/hail-is/hail/pull/12180,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"/li>; <li><a href=""https://github.com/java-native-access/jna/commit/db1b5531b10fed9fb68d6d4d79913660759b22d3""><code>db1b553</code></a> Merge pull request <a href=""https://redirect.github.com/java-native-access/jna/issues/1490"">#1490</a> from korlibs/feature/direct.mapping.custom.symbol.pr...</li>; <li>Additional commits viewable in <a href=""https://github.com/java-native-access/jna/compare/5.12.1...5.13.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=net.java.dev.jna:jna&package-manager=gradle&previous-version=5.12.1&new-version=5.13.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12886:6657,depend,dependabot-automerge-start,6657,https://hail.is,https://github.com/hail-is/hail/pull/12886,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"/li>; <li><a href=""https://github.com/jupyter/jupyter_core/commit/dfed905e5ce3550e1bdae60e9e9242f0d0d2faae""><code>dfed905</code></a> chore: update pre-commit hooks (<a href=""https://redirect.github.com/jupyter/jupyter_core/issues/392"">#392</a>)</li>; <li>See full diff in <a href=""https://github.com/jupyter/jupyter_core/compare/v5.7.1...v5.7.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jupyter-core&package-manager=pip&previous-version=5.7.1&new-version=5.7.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14484:4835,Depend,Dependabot,4835,https://hail.is,https://github.com/hail-is/hail/pull/14484,1,['Depend'],['Dependabot']
Integrability,"/li>; <li><a href=""https://github.com/pallets/jinja/commit/466a200ea40642b674db77588d13889abbad55f5""><code>466a200</code></a> update requirements</li>; <li><a href=""https://github.com/pallets/jinja/commit/990602f719b4086540287e95f601baefd830d790""><code>990602f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/jinja/issues/1647"">#1647</a> from Tom-Brouwer/202204/add-missing-overlay-options</li>; <li><a href=""https://github.com/pallets/jinja/commit/5d3d2414710c1439105d84efc58e4aba8e453cb3""><code>5d3d241</code></a> fix flake8-bugbear finding</li>; <li>Additional commits viewable in <a href=""https://github.com/pallets/jinja/compare/3.0.3...3.1.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jinja2&package-manager=pip&previous-version=3.0.3&new-version=3.1.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12173:6837,depend,dependabot-security-updates,6837,https://hail.is,https://github.com/hail-is/hail/pull/12173,1,['depend'],['dependabot-security-updates']
Integrability,"/li>; <li><a href=""https://github.com/psf/requests/commit/ab38e2c72608b95b047b05ccfaca833edb9db1b1""><code>ab38e2c</code></a> Make the <code>data</code> vs <code>json</code> parameters more clear (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5382"">#5382</a>)</li>; <li><a href=""https://github.com/psf/requests/commit/77d1e9aa3e000b40fdf93cfc355e1fe7cc52b6ac""><code>77d1e9a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/psf/requests/issues/5894"">#5894</a> from dbaxa/do-not-re-build-proxies-when-proxies-have...</li>; <li><a href=""https://github.com/psf/requests/commit/b0829a869081c2a6180db2cdc41a5676922becd0""><code>b0829a8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/psf/requests/issues/6020"">#6020</a> from nateprewitt/pypy_37</li>; <li><a href=""https://github.com/psf/requests/commit/28d537dde33b35c3b7071afd99122eff3538b42c""><code>28d537d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/psf/requests/issues/5917"">#5917</a> from nateprewitt/proxy_scheme_unknown_fix</li>; <li>Additional commits viewable in <a href=""https://github.com/psf/requests/compare/v2.25.1...v2.27.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=requests&package-manager=pip&previous-version=2.25.1&new-version=2.27.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@depen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11528:8792,depend,dependabot,8792,https://hail.is,https://github.com/hail-is/hail/pull/11528,2,['depend'],['dependabot']
Integrability,"/li>; <li><a href=""https://github.com/py4j/py4j/commit/1c622faa81e983f5ceface5290859d6a49974849""><code>1c622fa</code></a> Migrate nosetest to pytest (<a href=""https://redirect.github.com/bartdag/py4j/issues/481"">#481</a>)</li>; <li><a href=""https://github.com/py4j/py4j/commit/64ba89c5a680218d682161a4a6d952a969d1299b""><code>64ba89c</code></a> Add explanations for releasing Py4J for eclipse. Convert .txt to .md (<a href=""https://redirect.github.com/bartdag/py4j/issues/479"">#479</a>)</li>; <li>See full diff in <a href=""https://github.com/bartdag/py4j/compare/0.10.9.5...0.10.9.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=py4j&package-manager=pip&previous-version=0.10.9.5&new-version=0.10.9.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12978:2741,Depend,Dependabot,2741,https://hail.is,https://github.com/hail-is/hail/pull/12978,1,['Depend'],['Dependabot']
Integrability,"/li>; <li><a href=""https://github.com/pyasn1/pyasn1-modules/commit/252ac00bf1e119a044cc579ffade30164e2cdfff""><code>252ac00</code></a> Add support for Python 3.12 (<a href=""https://redirect.github.com/pyasn1/pyasn1-modules/issues/11"">#11</a>)</li>; <li>See full diff in <a href=""https://github.com/pyasn1/pyasn1-modules/compare/v0.3.0...v0.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyasn1-modules&package-manager=pip&previous-version=0.3.0&new-version=0.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14472:2735,Depend,Dependabot,2735,https://hail.is,https://github.com/hail-is/hail/pull/14472,1,['Depend'],['Dependabot']
Integrability,"/li>; <li><a href=""https://github.com/scipy/scipy/commit/1ab9f1b10145f0a974d5531700e72d1fb4229b76""><code>1ab9f1b</code></a> DOC: update 1.10.0 relnotes</li>; <li><a href=""https://github.com/scipy/scipy/commit/ac2f45fbe1e39a8f52c1ea2e68764009f02973c0""><code>ac2f45f</code></a> MAINT: integrate._qmc_quad: mark as private with preceding underscore</li>; <li><a href=""https://github.com/scipy/scipy/commit/3e0ae1a21f51ebee3a77733c42700d87a0c35d7d""><code>3e0ae1a</code></a> REV: integrate.qmc_quad: delay release to SciPy 1.11.0</li>; <li><a href=""https://github.com/scipy/scipy/commit/34cdf05c86548de1c4ca1b2798cdc23885af807b""><code>34cdf05</code></a> MAINT: FFT pybind11 fixups</li>; <li><a href=""https://github.com/scipy/scipy/commit/843500aabde17aaf1eec65c589d50bd12ee35039""><code>843500a</code></a> Merge pull request <a href=""https://redirect.github.com/scipy/scipy/issues/17689"">#17689</a> from mdhaber/gh17686</li>; <li><a href=""https://github.com/scipy/scipy/commit/089924b61012a106ffa4f58939b0180124051a0b""><code>089924b</code></a> REL: integrate.qmc_quad: remove from release notes</li>; <li><a href=""https://github.com/scipy/scipy/commit/3e47110f10e3267d228e9da84174f3cee325e7c3""><code>3e47110</code></a> REL: 1.10.0rc3 unreleased</li>; <li>Additional commits viewable in <a href=""https://github.com/scipy/scipy/compare/v1.9.3...v1.10.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=scipy&package-manager=pip&previous-version=1.9.3&new-version=1.10.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13227:4553,integrat,integrate,4553,https://hail.is,https://github.com/hail-is/hail/pull/13227,1,['integrat'],['integrate']
Integrability,"/li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/308f153f91b7942476f2d4ddda3dc8c99933d598""><code>308f153</code></a> ci: add workflow to publish sdist/wheel to PyPI (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/issues/202"">#202</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/961624063383cbcdc78a61b1d18448429a61a489""><code>9616240</code></a> [chore] update changelog</li>; <li>Additional commits viewable in <a href=""https://github.com/tomplus/kubernetes_asyncio/compare/v19.15.1...23.6.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=kubernetes-asyncio&package-manager=pip&previous-version=19.15.1&new-version=23.6.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:15899,Depend,Dependabot,15899,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['Depend'],['Dependabot']
Integrability,"/li>; <li>Allow <code>download</code> and <code>verify</code> extensions to be created on demand in custom tasks, so these tasks can be made compatible with Gradle's configuration cache (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/284"">#284</a>). Thanks to <a href=""https://github.com/liblit""><code>@​liblit</code></a> for testing!</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; <li>Improve documentation</li>; <li>Add integration tests for Gradle 6.9.3 and 7.6</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a0374fc7c895ae53309ea351e989571204e0ea5f""><code>a0374fc</code></a> Bump up version number to 5.3.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/612f57a382b8640cc730dc5e75d1c809e3e772bd""><code>612f57a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/291"">#291</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/53af1049f5514afe58e884d487d7c57dae47759d""><code>53af104</code></a> Bump http-cache-semantics from 4.1.0 to 4.1.1 in /screencast</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/398c14c05c6448b380ac35c6095598299c5e23c5""><code>398c14c</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/15cf7eecfbc17d2466143828b9b69494c6cb6f2b""><code>15cf7ee</code></a> Bump up version number to 5.3.1-SNAPSHOT</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/e3c65ffcb49b9c5a33fde5f31fb63043dbf21134""><code>e3c65ff</code></a> Allow extensions to be created from tasks</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/34e2dd41477f18b1ae3d6d5a71dca5449d6cd1e0",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12707:1422,depend,dependabot,1422,https://hail.is,https://github.com/hail-is/hail/pull/12707,1,['depend'],['dependabot']
Integrability,"/li>; <li>Fix SimpleTestServer demo, actually counting now to 5, not 6.</li>; <li>Make builds reproducible, align timestamps with git commit</li>; </ul>; <p>NOTE: If you're seeing unexpected errors in selftest, please verify with the attached <code>junixsocket-selftest-2.6.1-hotpatch-jar-with-dependencies.jar</code>. There may be false-positive socket timeout issues on very slow machines (e.g., qemu s390).</p>; <h2>junixsocket 2.6.0</h2>; <ul>; <li>Add support for GraalVM native-image</li>; <li>Add support for native-image selftest</li>; <li>Add support for AF_VSOCK (on Linux, and some macOS VMs)</li>; <li>Reintroduce deprecated legacy constructors for AFUNIXSocketAddress that were removed in 2.5.0.</li>; <li>Parent POM has been renamed from junixsocket-parent to junixsocket</li>; </ul>; <h2>junixsocket 2.5.2</h2>; <ul>; <li>Fix address handling in the Abstract Namespace</li>; <li>Fix support for very large datagrams (&gt; 1MB)</li>; <li>Fix InetAddress-wrapping of long addresses</li>; <li>Update Xcode support script, crossclang</li>; <li>Bump postgresql version in demo code</li>; <li>Fix dependency for custom architecture artifact</li>; </ul>; <h2>junixsocket 2.5.1</h2>; <ul>; <li>Add support for IBM z/OS (experimental, binary not included)</li>; <li>Add support for building from source on arm64-Linux</li>; <li>Add junixsocket support for jetty via <a href=""http://kohlschutter.github.io/junixsocket/junixsocket-jetty/"">junixsocket-jetty</a></li>; <li>Fix Selector logic (more bug fixes)</li>; <li>Documentation updates</li>; </ul>; <h2>junixsocket 2.5.0</h2>; <ul>; <li>New supported platforms: AIX 7 Power64, IBM i Power64, Windows ARM64, Windows Server 2019 &amp; 2022</li>; <li>Generic rework to support more than just Unix Domain sockets</li>; <li>Add support for AF_TIPC (on Linux)</li>; <li>Add support for using sockets passed as standard input</li>; <li>Add support for address-specific, non-standard URIs (for example; unix:// and tipc://), as well as socat addresses",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12483:1652,wrap,wrapping,1652,https://hail.is,https://github.com/hail-is/hail/pull/12483,2,"['depend', 'wrap']","['dependency', 'wrapping']"
Integrability,"/li>; <li>Fixed exception in Markdown with partial table <a href=""https://redirect.github.com/Textualize/rich/issues/3053"">Textualize/rich#3053</a></li>; <li>Fixed the HTML export template so that the <code>&lt;html&gt;</code> tag comes before the <code>&lt;head&gt;</code> tag <a href=""https://redirect.github.com/Textualize/rich/issues/3021"">Textualize/rich#3021</a></li>; <li>Fixed issue with custom classes overwriting <code>__eq__</code> <a href=""https://redirect.github.com/Textualize/rich/issues/2875"">Textualize/rich#2875</a></li>; <li>Fix rich.pretty.install breakage in iPython <a href=""https://redirect.github.com/Textualize/rich/issues/3013"">Textualize/rich#3013</a></li>; </ul>; <h3>Added</h3>; <ul>; <li>Added Text.extend_style method.</li>; <li>Added Span.extend method.</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Text.tab_size now defaults to <code>None</code> to indicate that Console.tab_size should be used.</li>; </ul>; <h2>[13.4.2] - 2023-06-12</h2>; <h3>Changed</h3>; <ul>; <li>Relaxed markdown-it-py dependency</li>; </ul>; <h2>[13.4.1] - 2023-05-31</h2>; <h3>Fixed</h3>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Textualize/rich/commit/ec91917deb47b43188312e0e3f03bbab7e4e2e7e""><code>ec91917</code></a> changelog</li>; <li><a href=""https://github.com/Textualize/rich/commit/5360fe6fe4f582e5a5bec591cf7433ed85e6863d""><code>5360fe6</code></a> version bump</li>; <li><a href=""https://github.com/Textualize/rich/commit/e0d3aee1eccd424c98d05b94910f9d5ddb821a40""><code>e0d3aee</code></a> Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3132"">#3132</a> from Textualize/fix-markdown-on-light</li>; <li><a href=""https://github.com/Textualize/rich/commit/db07a2aad2c18a1a4ab2345bb2d5adbd2f9c0eaa""><code>db07a2a</code></a> Restore text</li>; <li><a href=""https://github.com/Textualize/rich/commit/44e36aaf6f8c5b4aba4d66bcf895b25c3b5fa32e""><code>4",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13651:4883,depend,dependency,4883,https://hail.is,https://github.com/hail-is/hail/pull/13651,2,['depend'],['dependency']
Integrability,"/li>; <li>Fixed exception in Markdown with partial table <a href=""https://redirect.github.com/Textualize/rich/issues/3053"">Textualize/rich#3053</a></li>; <li>Fixed the HTML export template so that the <code>&lt;html&gt;</code> tag comes before the <code>&lt;head&gt;</code> tag <a href=""https://redirect.github.com/Textualize/rich/issues/3021"">Textualize/rich#3021</a></li>; <li>Fixed issue with custom classes overwriting <code>__eq__</code> <a href=""https://redirect.github.com/Textualize/rich/issues/2875"">Textualize/rich#2875</a></li>; <li>Fix rich.pretty.install breakage in iPython <a href=""https://redirect.github.com/Textualize/rich/issues/3013"">Textualize/rich#3013</a></li>; </ul>; <h3>Added</h3>; <ul>; <li>Added Text.extend_style method.</li>; <li>Added Span.extend method.</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Text.tab_size now defaults to <code>None</code> to indicate that Console.tab_size should be used.</li>; </ul>; <h2>[13.4.2] - 2023-06-12</h2>; <h3>Changed</h3>; <ul>; <li>Relaxed markdown-it-py dependency</li>; </ul>; <h2>[13.4.1] - 2023-05-31</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed typing extensions import in markdown <a href=""https://redirect.github.com/Textualize/rich/issues/2979"">Textualize/rich#2979</a></li>; </ul>; <h2>[13.4.0] - 2023-05-31</h2>; <h3>Added</h3>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Textualize/rich/commit/720800e6930d85ad027b1e9bd0cbb96b5e994ce3""><code>720800e</code></a> fix tab size issue</li>; <li><a href=""https://github.com/Textualize/rich/commit/4037906f2be2d07f864687ef324da2abdf2028b9""><code>4037906</code></a> Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3071"">#3071</a> from ThiefMaster/patch-1</li>; <li><a href=""https://github.com/Textualize/rich/commit/e66d43baeafe6536e6ceda97202853a70c3d45f0""><code>e66d43b</code></a> Fix nonsensical date in changelog</li>; <li><a href=""https://gi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13380:4287,depend,dependency,4287,https://hail.is,https://github.com/hail-is/hail/pull/13380,2,['depend'],['dependency']
Integrability,"/li>; <li>Fixed the issue that async OBO credential does not refresh correctly. (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/21981"">#21981</a>)</li>; </ul>; <h3>Other Changes</h3>; <ul>; <li>Removed <code>resource_id</code>, please use <code>identity_config</code> instead.</li>; <li>Renamed argument name <code>get_assertion</code> to <code>func</code> for <code>ClientAssertionCredential</code>.</li>; </ul>; <h2>azure-identity_1.9.0b1</h2>; <h2>1.9.0b1 (2022-03-08)</h2>; <h3>Features Added</h3>; <ul>; <li>Added <code>validate_authority</code> support for msal client (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22625"">#22625</a>)</li>; <li>Added <code>resource_id</code> support for user-assigned managed identity (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22329"">#22329</a>)</li>; <li>Added <code>ClientAssertionCredential</code> support (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22328"">#22328</a>)</li>; <li>Updated App service API version to &quot;2019-08-01&quot; (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23034"">#23034</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/e650a8ca8b4cf01ec7a2961f4a50187d1528a122""><code>e650a8c</code></a> update troubleshooting (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23681"">#23681</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/58613a167a5383a459a57b34c6208d7762b90264""><code>58613a1</code></a> enable pii logging (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23658"">#23658</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/ab4c52ce05bb3fda401a834cbf669c32d6d83b90""><code>ab4c52c</code></a> add doc string for authori",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11752:1835,depend,dependabot,1835,https://hail.is,https://github.com/hail-is/hail/pull/11752,1,['depend'],['dependabot']
Integrability,"/li>; <li>Implicitly concatenated strings inside a list, set, or tuple are now wrapped inside parentheses (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3162"">#3162</a>)</li>; <li>Fix a string merging/split issue when a comment is present in the middle of implicitly concatenated strings on its own line (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3227"">#3227</a>)</li>; </ul>; <h3><em>Blackd</em></h3>; <ul>; <li><code>blackd</code> now supports enabling the preview style via the <code>X-Preview</code> header (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3217"">#3217</a>)</li>; </ul>; <h3>Configuration</h3>; <ul>; <li>Black now uses the presence of debug f-strings to detect target version (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3215"">#3215</a>)</li>; <li>Fix misdetection of project root and verbose logging of sources in cases involving <code>--stdin-filename</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3216"">#3216</a>)</li>; <li>Immediate <code>.gitignore</code> files in source directories given on the command line are now also respected, previously only <code>.gitignore</code> files in the project root and automatically discovered directories were respected (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3237"">#3237</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Recommend using BlackConnect in IntelliJ IDEs (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3150"">#3150</a>)</li>; </ul>; <h3>Integrations</h3>; <ul>; <li>Vim plugin: prefix messages with <code>Black: </code> so it's clear they come from Black (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3194"">#3194</a>)</li>; <li>Docker: changed to a /opt/venv installation + added to PATH to be available to non-root users (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3202"">#3202</a>)</li>; </ul>; <h3>Output</h3>; <ul>; <li>Change fr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12174:3183,depend,dependabot,3183,https://hail.is,https://github.com/hail-is/hail/pull/12174,1,['depend'],['dependabot']
Integrability,"/li>; <li>Simplified handling of bytes and bytearray in <code>_parser._timelex</code>. Reported</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/dateutil/dateutil/blob/master/NEWS"">python-dateutil's changelog</a>.</em></p>; <blockquote>; <h1>Version 2.8.2 (2021-07-08)</h1>; <h2>Data updates</h2>; <ul>; <li>Updated tzdata version to 2021a. (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1128"">#1128</a>)</li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>Fixed a bug in the parser where non-<code>ValueError</code> exceptions would be raised; during exception handling; this would happen, for example, if an; <code>IllegalMonthError</code> was raised in <code>dateutil</code> code. Fixed by Mark Bailey.; (gh issue <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/981"">#981</a>, pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/987"">#987</a>).</li>; <li>Fixed the custom <code>repr</code> for <code>dateutil.parser.ParserError</code>, which was not; defined due to an indentation error. (gh issue <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/991"">#991</a>, gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/993"">#993</a>)</li>; <li>Fixed a bug that caused <code>b'</code> prefixes to appear in parse_isodate exception; messages. Reported and fixed by Paul Brown (<a href=""https://github.com/pawl""><code>@​pawl</code></a>) (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1122"">#1122</a>)</li>; <li>Make <code>isoparse</code> raise when trying to parse times with inconsistent use of; <code>:</code> separator. Reported and fixed by <a href=""https://github.com/mariocj89""><code>@​mariocj89</code></a> (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1125"">#1125</a>).</li>; <l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11518:5224,depend,dependabot,5224,https://hail.is,https://github.com/hail-is/hail/pull/11518,1,['depend'],['dependabot']
Integrability,"/li>; <li>misc test/ci updates; <ul>; <li>test forks</li>; <li>tidy OS &amp; Python version tests</li>; <li>bump primary python version 3.7 =&gt; 3.8</li>; <li>beta py3.10 testing</li>; <li>fix py2.7 tests</li>; <li>better timeout handling</li>; </ul>; </li>; </ul>; <h2>tqdm v4.62.2 stable</h2>; <ul>; <li>fix notebook memory leak (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1216"">#1216</a>)</li>; <li>fix <code>contrib.concurrent</code> with generators (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1233"">#1233</a> &lt;- <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1231"">#1231</a>)</li>; </ul>; <h2>tqdm v4.62.1 stable</h2>; <ul>; <li><code>contrib.logging</code>: inherit existing handler output stream (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1191"">#1191</a>)</li>; <li>fix <code>PermissionError</code> by using <code>weakref</code> in <code>DisableOnWriteError</code> (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1207"">#1207</a>)</li>; <li>fix <code>contrib.telegram</code> creation rate limit handling (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1223"">#1223</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1221"">#1221</a> &lt;- <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1220"">#1220</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1076"">#1076</a>)</li>; <li>tests: fix py27 <code>keras</code> dependencies (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1222"">#1222</a>)</li>; <li>misc tidy: use relative imports (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1222"">#1222</a>)</li>; <li>minor documentation updates (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1222"">#1222</a>)</li>; </ul>; <h2>tqdm v4.62.0 stable</h2>; <ul>; <li><code>asyncio.gather</code> API consistency with stdlib (<a href=""https://github-redirect.dependabot.com/tqdm/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11587:2649,depend,dependabot,2649,https://hail.is,https://github.com/hail-is/hail/pull/11587,1,['depend'],['dependabot']
Integrability,"/local/lib/python3.6/dist-packages/aiohttp/web_protocol.py"", line 418, in start; resp = await task; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py"", line 458, in _handle; resp = await handler(request); File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_urldispatcher.py"", line 157, in handler_wrapper; result = await result; File ""/usr/local/lib/python3.6/dist-packages/batch/batch.py"", line 914, in create_jobs; success = await jobs_builder.commit(); File ""/usr/local/lib/python3.6/dist-packages/batch/database.py"", line 161, in commit; await cursor.executemany(self._jobs_sql, self._jobs); File ""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py"", line 283, in executemany; self._get_db().encoding)); File ""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py"", line 318, in _do_execute_many; r = await self.execute(sql + postfix); File ""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py"", line 239, in execute; await self._query(query); File ""/usr/local/lib/python3.6/dist-packages/aiomysql/cursors.py"", line 457, in _query; await conn.query(q); File ""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py"", line 428, in query; await self._read_query_result(unbuffered=unbuffered); File ""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py"", line 622, in _read_query_result; await result.read(); File ""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py"", line 1105, in read; first_packet = await self.connection._read_packet(); File ""/usr/local/lib/python3.6/dist-packages/aiomysql/connection.py"", line 593, in _read_packet; packet.check_error(); File ""/usr/local/lib/python3.6/dist-packages/pymysql/protocol.py"", line 220, in check_error; err.raise_mysql_exception(self._data); File ""/usr/local/lib/python3.6/dist-packages/pymysql/err.py"", line 109, in raise_mysql_exception; raise errorclass(errno, errval); pymysql.err.OperationalError: (1213, 'Deadlock found when trying to get lock; try restarting transaction'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6543:4612,protocol,protocol,4612,https://hail.is,https://github.com/hail-is/hail/issues/6543,1,['protocol'],['protocol']
Integrability,"/local/lib/python3.6/dist-packages/google/resumable_media/_helpers.py"", line 96, in require_status_code; *status_codes; google.resumable_media.common.InvalidResponse: ('Request failed with status code', 403, 'Expected one of', <HTTPStatus.OK: 200>, <HTTPStatus.PARTIAL_CONTENT: 206>). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_protocol.py"", line 418, in start; resp = await task; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py"", line 458, in _handle; resp = await handler(request); File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_middlewares.py"", line 119, in impl; return await handler(request); File ""/usr/local/lib/python3.6/dist-packages/aiohttp_session/__init__.py"", line 152, in factory; response = await handler(request); File ""/usr/local/lib/python3.6/dist-packages/prometheus_async/aio/_decorators.py"", line 42, in time_decorator; rv = await wrapped(*args, **kw); File ""/usr/local/lib/python3.6/dist-packages/gear/auth.py"", line 86, in wrapped; return await fun(request, userdata, *args, **kwargs); File ""/usr/local/lib/python3.6/dist-packages/batch/front_end/front_end.py"", line 383, in ui_get_job_log; 'job_log': await _get_job_log(request.app, batch_id, job_id, user); File ""/usr/local/lib/python3.6/dist-packages/batch/front_end/front_end.py"", line 112, in _get_job_log; job_log = await job._read_logs(); File ""/usr/local/lib/python3.6/dist-packages/batch/batch.py"", line 57, in _read_logs; return {k: v for k, v in await future_logs}; File ""/usr/local/lib/python3.6/dist-packages/batch/batch.py"", line 52, in _read_log_from_gcs; pod_log = await self.app['log_store'].read_gs_file(LogStore.container_log_path(self.directory, task_name)); File ""/usr/local/lib/python3.6/dist-packages/batch/log_store.py"", line 40, in read_gs_file; return await self.gcs.read_gs_file(uri); File ""/usr/local/lib/python3.6/dist-packages/batch/google_storage.py"", ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7412:3288,wrap,wrapped,3288,https://hail.is,https://github.com/hail-is/hail/pull/7412,1,['wrap'],['wrapped']
Integrability,"/master/CHANGES.txt"">aiohttp-session's changelog</a>.</em></p>; <blockquote>; <h1>2.11.0 (2021-01-31)</h1>; <ul>; <li>Support initialising <code>EncryptedCookieStorage</code> with <code>Fernet</code> object directly.</li>; <li>Fix an issue where the session would get reset before the cookie expiry.</li>; </ul>; <h1>2.10.0 (2021-12-30)</h1>; <ul>; <li>Typing support</li>; <li>Add samesite cookie option</li>; <li>Support aioredis 2</li>; </ul>; <h1>2.9.0 (2019-11-04)</h1>; <ul>; <li>Fix memcached expiring time (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/398"">#398</a>)</li>; </ul>; <h1>2.8.0 (2019-09-17)</h1>; <ul>; <li>Make this compatible with Python 3.7+. Import from collections.abc, instead; of from collections. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/373"">#373</a>)</li>; </ul>; <h1>2.7.0 (2018-10-13)</h1>; <ul>; <li>; <p>Reset a session if the session age &gt; max_age (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/331"">#331</a>)</p>; </li>; <li>; <p>Reset a session on TTL expiration for EncryptedCookieStorage (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/326"">#326</a>)</p>; </li>; </ul>; <h1>2.6.0 (2018-09-12)</h1>; <ul>; <li>Create a new session if <code>NaClCookieStorage</code> cannot decode a; corrupted cookie (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/317"">#317</a>)</li>; </ul>; <h1>2.5.0 (2018-05-12)</h1>; <ul>; <li>Add an API for requesting new session explicitly (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/281"">#281</a>)</li>; </ul>; <h1>2.4.0 (2018-05-04)</h1>; <ul>; <li>Fix a bug for session fixation (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/272"">#272</a>)</li>; </ul>; <h1>2.3.0 (2018-02-13)</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11577:1669,depend,dependabot,1669,https://hail.is,https://github.com/hail-is/hail/pull/11577,1,['depend'],['dependabot']
Integrability,"/microsoft/debugpy/issues/1008"">#1008</a>: Re-attaching continuously creates 'accept_worker' threads in debugpy</li>; <li><a href=""https://github.com/microsoft/debugpy/commit/71d42ed63fdbac538b3341a2dc585583eb44e881""><code>71d42ed</code></a> Support top-level async. Fixes <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/951"">#951</a></li>; <li><a href=""https://github.com/microsoft/debugpy/commit/6e247fb17bc15488a2cbefb7eed80c87179b147c""><code>6e247fb</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/1009"">#1009</a> from rchiodo/rchiodo/missed_thread_for_self_trace</li>; <li><a href=""https://github.com/microsoft/debugpy/commit/cccfb954bd7321fbb25f234f0c9a2e8372646297""><code>cccfb95</code></a> Missed a thread to allow debugging</li>; <li><a href=""https://github.com/microsoft/debugpy/commit/6c19aba462d2a9b6ea79d5cbce2886bd961823eb""><code>6c19aba</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/1007"">#1007</a> from rchiodo/rchiodo/allow_adapter_debugging</li>; <li><a href=""https://github.com/microsoft/debugpy/commit/10d8839a4cac4bdaf99cfe44ca2ee5479c95c003""><code>10d8839</code></a> Review feedback</li>; <li><a href=""https://github.com/microsoft/debugpy/commit/83ff28006d2f85cfbd03fcdc2650eea6831ab2b1""><code>83ff280</code></a> Add DEBUGPY_TRACE_DEBUGPY variable to allow debugpy to debug itself</li>; <li><a href=""https://github.com/microsoft/debugpy/commit/4f6638b0a6bbdec598987f7c2b62107a57edd6a6""><code>4f6638b</code></a> Fix <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/1001"">#1001</a>: Enable controlling shell expansion via &quot;argsCanBeInterpretedByShell&quot;</li>; <li><a href=""https://github.com/microsoft/debugpy/commit/6b276e339cd850c5f8c93ff4bdbd305dd963d7bb""><code>6b276e3</code></a> Step in/step over support for IPython. Fixes <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/869"">#869<",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12103:3980,depend,dependabot,3980,https://hail.is,https://github.com/hail-is/hail/pull/12103,2,['depend'],['dependabot']
Integrability,"/microsoft/debugpy/issues/975"">#975</a>).</p>; <p>Other fixes: <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/969"">#969</a></p>; <h2>debugpy v1.6.1</h2>; <p>debugpy API now has type annotations.</p>; <p>Optimizations based on frame evaluation API are re-enabled by default.</p>; <p>Other improvements: <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/743"">#743</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/774"">#774</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/893"">#893</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/945"">#945</a></p>; <p>Bug fixes: <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/705"">#705</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/731"">#731</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/861"">#861</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/865"">#865</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/882"">#882</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/889"">#889</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/896"">#896</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/915"">#915</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/921"">#921</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/928"">#928</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/934"">#934</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/microsoft/debugpy/commit/8b5eeee7e0b1678e701b07d94e6c3cf07b923597""><code>8b5eeee</code></a> Fix <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/1008"">#1008</a>: Re-attaching continuously creates 'accept",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12103:2063,depend,dependabot,2063,https://hail.is,https://github.com/hail-is/hail/pull/12103,2,['depend'],['dependabot']
Integrability,"/numpy/commit/45329c1ee92d00959d11cdfa0a2c5a25a6867933""><code>45329c1</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22593"">#22593</a> from charris/backport-22447</li>; <li><a href=""https://github.com/numpy/numpy/commit/3ca02ce5b1a4ec2412cad839d42452a4200a5270""><code>3ca02ce</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22594"">#22594</a> from charris/backport-22450</li>; <li><a href=""https://github.com/numpy/numpy/commit/8cededdf4eeebd4f1985bd74c11fbf44f367937f""><code>8cededd</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22592"">#22592</a> from charris/backport-22393</li>; <li>Additional commits viewable in <a href=""https://github.com/numpy/numpy/compare/v1.21.6...v1.23.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.6&new-version=1.23.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` wi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12515:6368,depend,dependency-name,6368,https://hail.is,https://github.com/hail-is/hail/pull/12515,1,['depend'],['dependency-name']
Integrability,"/numpy/numpy/issues/22593"">#22593</a> from charris/backport-22447</li>; <li><a href=""https://github.com/numpy/numpy/commit/3ca02ce5b1a4ec2412cad839d42452a4200a5270""><code>3ca02ce</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22594"">#22594</a> from charris/backport-22450</li>; <li><a href=""https://github.com/numpy/numpy/commit/8cededdf4eeebd4f1985bd74c11fbf44f367937f""><code>8cededd</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22592"">#22592</a> from charris/backport-22393</li>; <li>Additional commits viewable in <a href=""https://github.com/numpy/numpy/compare/v1.21.6...v1.23.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.6&new-version=1.23.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12515:6529,depend,dependabot-security-updates,6529,https://hail.is,https://github.com/hail-is/hail/pull/12515,1,['depend'],['dependabot-security-updates']
Integrability,"/opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals); 1329 ; 1330 if not _read_if_exists or not hl.hadoop_exists(f'{output}/_SUCCESS'):; -> 1331 self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); 1332 _assert_type = self._type; 1333 _load_refs = False. <decorator-gen-1332> in write(self, output, overwrite, stage_locally, _codec_spec). /opt/conda/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_); 588 ; 589 return wrapper. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/table.py in write(self, output, overwrite, stage_locally, _codec_spec); 1375 hl.current_backend().validate_file_scheme(output); 1376 ; -> 1377 Env.backend().execute(ir.TableWrite(self._tir, ir.TableNativeWriter(output, overwrite, stage_locally, _codec_spec))); 1378 ; 1379 @typecheck_method(output=str,. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/backend/py4j_backend.py in execute(self, ir, timed); 80 return (value, timings) if timed else value; 81 except FatalError as e:; ---> 82 raise e.maybe_user_error(ir) from None; 83 ; 84 async def _async_execute(self, ir, timed=False):. /opt/conda/miniconda3/lib/python3.10/site-packages/hail/backend/py4j_backend.py in execute(self, ir,",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124:4875,wrap,wrapper,4875,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1734196124,2,['wrap'],['wrapper']
Integrability,"/p>; <p>This release includes 120 Jira issues, including some interesting features:</p>; <p>Specification: AVRO-3212 Support documentation tags for FIXED types; C#: AVRO-2961 Support dotnet framework 5.0; C#: AVRO-3225 Prevent memory errors when deserializing untrusted data; C++: AVRO-2923 Logical type corrections; Java: AVRO-2863 Support Avro core on android; Javascript: AVRO-3131 Drop support for node.js 10; Perl: AVRO-3190 Fix error when reading from EOF; Python: AVRO-2906 Improved performance validating deep record data; Python: AVRO-2914 Drop Python 2 support; Python: AVRO-3004 Drop Python 3.5 support; Ruby: AVRO-3108 Drop Ruby 2.5 support</p>; <p>For the first time, the 1.11.0 release includes experimental support for; Rust. Work is continuing on this donated SDK, but we have not versioned and; published official artifacts for this release.</p>; <p>Python: The avro package fully supports Python 3. We will no longer publish a; separate avro-python3 package</p>; <p>And of course upgraded dependencies to latest versions, CVE fixes and more:; <a href=""https://issues.apache.org/jira/issues/?jql=project%3DAVRO%20AND%20fixVersion%3D1.11.0"">https://issues.apache.org/jira/issues/?jql=project%3DAVRO%20AND%20fixVersion%3D1.11.0</a></p>; <p>The link to all fixed JIRA issues and a brief summary can be found at:; <a href=""https://github.com/apache/avro/releases/tag/release-1.11.0"">https://github.com/apache/avro/releases/tag/release-1.11.0</a></p>; <p>In addition, language-specific release artifacts are available:</p>; <ul>; <li>C#: <a href=""https://www.nuget.org/packages/Apache.Avro/1.11.0"">https://www.nuget.org/packages/Apache.Avro/1.11.0</a></li>; <li>Java: from Maven Central,</li>; <li>Javascript: <a href=""https://www.npmjs.com/package/avro-js/v/1.11.0"">https://www.npmjs.com/package/avro-js/v/1.11.0</a></li>; <li>Perl: <a href=""https://metacpan.org/release/Avro"">https://metacpan.org/release/Avro</a></li>; <li>Python 3: <a href=""https://pypi.org/project/avro/1.11.0"">https:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11475:1563,depend,dependencies,1563,https://hail.is,https://github.com/hail-is/hail/pull/11475,1,['depend'],['dependencies']
Integrability,"/p>; <ul>; <li>; <p>Fix a regression in 2.13.0 where <code>used-before-assignment</code> was emitted for; the usage of a nonlocal in a try block.</p>; <p>Fixes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5965"">#5965</a></p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/pylint/commit/7591ac04dcefc527c42fd7713c909d1319e83fab""><code>7591ac0</code></a> Bump pylint to 2.13.3, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/a880bd6d85d2487f509d1505b5146d608b15d870""><code>a880bd6</code></a> Change 'nonexistent-operator' to allow repeated unary ops (with space or pare...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c73353064f934ae49472eb6138e1f8071b6b733e""><code>c733530</code></a> <code>unnecessary-ellipsis</code> false positive: allow ellipsis as default argument (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6"">#6</a>...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/19e6531068cf95d602054ff8638adcb79971d552""><code>19e6531</code></a> Fix crash on unbalanced tuple unpacking</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/2066cab9bbe43341b84014ac9610e275db586431""><code>2066cab</code></a> Bump pylint to 2.13.2, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/6a25d7048edadc18a05e999021049ade86ef2bd9""><code>6a25d70</code></a> Better error message when we cant write the crash files (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5987"">#5987</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c42fe73a1613bbfb52a5ba9129efa45a3fd76401""><code>c42fe73</code></a> Fix false negative for <code>protected-access</code> on functions (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5990"">#5990</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/dec241b1787e6c99a092bb9ef6",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11702:2922,depend,dependabot,2922,https://hail.is,https://github.com/hail-is/hail/pull/11702,1,['depend'],['dependabot']
Integrability,"/packages/vite/issues/8094"">#8094</a>) (<a href=""https://github.com/vitejs/vite/commit/a24b5e3"">a24b5e3</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8091"">#8091</a> <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8094"">#8094</a></li>; <li>fix: graceful rename in windows (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8036"">#8036</a>) (<a href=""https://github.com/vitejs/vite/commit/84496f8"">84496f8</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8036"">#8036</a></li>; <li>fix: image-set with base64 images (fix <a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8028"">#8028</a>) (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8035"">#8035</a>) (<a href=""https://github.com/vitejs/vite/commit/992aee2"">992aee2</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8028"">#8028</a> <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8035"">#8035</a></li>; <li>fix: invalidate ssrError when HMR update occurs (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8052"">#8052</a>) (<a href=""https://github.com/vitejs/vite/commit/22fa882"">22fa882</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8052"">#8052</a></li>; <li>fix: use <code>strip-literal</code> to strip string lterals (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8054"">#8054</a>) (<a href=""https://github.com/vitejs/vite/commit/b6fc3cd"">b6fc3cd</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8054"">#8054</a></li>; <li>perf(lib): reduce backtrack when injecting esbuild helpers (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/8110"">#8110</a>) (<a href=""https://github.com/vitejs/vite/commit/e5556ab"">e5556ab</a>), closes <a href=""https://github-redirect.dependabot.com/vitejs/vite/issues/8110"">#8110</a></li>; </u",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12142:7432,depend,dependabot,7432,https://hail.is,https://github.com/hail-is/hail/pull/12142,2,['depend'],['dependabot']
Integrability,"/pallets/click/issues/2234"">#2234</a> from pallets/release-8.1.1</li>; <li><a href=""https://github.com/pallets/click/commit/3c301ebacbfe8ec7dc3d9d46ebf517082a8ee4b1""><code>3c301eb</code></a> release version 8.1.1</li>; <li><a href=""https://github.com/pallets/click/commit/d5741a2ca2ebc21d525c903f628b1bebad75b735""><code>d5741a2</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2233"">#2233</a> from henryiii/henryiii/fix/commandtype</li>; <li>Additional commits viewable in <a href=""https://github.com/pallets/click/compare/8.0.4...8.1.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=click&package-manager=pip&previous-version=8.0.4&new-version=8.1.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11801:7077,Depend,Dependabot,7077,https://hail.is,https://github.com/hail-is/hail/pull/11801,1,['Depend'],['Dependabot']
Integrability,"/pallets/jinja/commit/990602f719b4086540287e95f601baefd830d790""><code>990602f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/jinja/issues/1647"">#1647</a> from Tom-Brouwer/202204/add-missing-overlay-options</li>; <li><a href=""https://github.com/pallets/jinja/commit/5d3d2414710c1439105d84efc58e4aba8e453cb3""><code>5d3d241</code></a> fix flake8-bugbear finding</li>; <li>Additional commits viewable in <a href=""https://github.com/pallets/jinja/compare/3.0.3...3.1.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jinja2&package-manager=pip&previous-version=3.0.3&new-version=3.1.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12173:7040,depend,dependabot,7040,https://hail.is,https://github.com/hail-is/hail/pull/12173,1,['depend'],['dependabot']
Integrability,"/pandas-dev/pandas/issues/45910"">#45910</a>: TST/CI: Set hypothesis deadline to None to avoid flaky fa...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/58aebf1940b56b77279174f5413b76a5aaba465c""><code>58aebf1</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45909"">#45909</a>: BUG: DateOffset(n) not defaulting to days (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45918"">#45918</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.0...v1.4.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pandas&package-manager=pip&previous-version=1.3.0&new-version=1.4.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11539:6351,Depend,Dependabot,6351,https://hail.is,https://github.com/hail-is/hail/pull/11539,1,['Depend'],['Dependabot']
Integrability,"/pandas-docs/version/1.4/whatsnew/v1.4.0.html"">whatsnew</a> for a list of all the changes. pandas 1.4.0 supports Python 3.8 and higher.</p>; <p>The release will be available on conda-forge and PyPI.</p>; <p>The release can be installed from PyPI</p>; <pre><code>python -m pip install --upgrade --pre pandas==1.4.0rc0; </code></pre>; <p>Or from conda-forge</p>; <pre><code>conda install -c conda-forge/label/pandas_rc pandas==1.4.0rc0; </code></pre>; <p>Please report any issues with the release candidate on the pandas issue tracker.</p>; <h2>Pandas 1.3.5</h2>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pandas-dev/pandas/commit/06d230151e6f18fdb8139d09abf539867a8cd481""><code>06d2301</code></a> RLS: 1.4.1</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/47e3b409deb41f18e30e447579cba3a246db050e""><code>47e3b40</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45587"">#45587</a>: DOC: append deprecation (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45942"">#45942</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/f61dfde6abbe33e143e83c6685e4b3c1c488f92b""><code>f61dfde</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45936"">#45936</a>: DOC: 1.4.1 release date (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45941"">#45941</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/28f5e9093377f72742b60e458949b7b4714141ed""><code>28f5e90</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45925"">#45925</a>: BUG: rolling(axis=1).apply() raising ValueError (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45939"">#45939</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/0fc655f84c6b51552a7c70f2b92c846b4d24e381""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11539:2861,depend,dependabot,2861,https://hail.is,https://github.com/hail-is/hail/pull/11539,1,['depend'],['dependabot']
Integrability,"/pre-commit/issues/2322"">#2322</a> from pre-commit/default-install-hook-types</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/e11163d010447ce83aae996cf5a76038aa975fe4""><code>e11163d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2301"">#2301</a> from jeff-m-sullivan/rscript-path</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/d65016042b67d09139876e1903e839a168dfa7c3""><code>d650160</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2252"">#2252</a> from daschuer/worktree_fix</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/fd0177ae3ae5f94b36aafb54ab496f76fcead7b9""><code>fd0177a</code></a> implement default_install_hook_types</li>; <li>Additional commits viewable in <a href=""https://github.com/pre-commit/pre-commit/compare/v2.17.0...v2.18.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pre-commit&package-manager=pip&previous-version=2.17.0&new-version=2.18.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merg",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11731:12876,Depend,Dependabot,12876,https://hail.is,https://github.com/hail-is/hail/pull/11731,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"/protobuf/issues/9486"">#9486</a>)</li>; <li>Allocate with xrealloc()/xfree() so message allocation is visible to the; Ruby GC. In certain tests this leads to much lower memory usage due to more; frequent GC runs (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9586"">#9586</a>).</li>; <li>Fix conversion of singleton classes in Ruby (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9342"">#9342</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/protocolbuffers/protobuf/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.19.6&new-version=4.21.12)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12563:4244,depend,dependabot-security-updates,4244,https://hail.is,https://github.com/hail-is/hail/pull/12563,1,['depend'],['dependabot-security-updates']
Integrability,"/psf/black/issues/3248"">#3248</a>)</li>; <li><a href=""https://github.com/psf/black/commit/0019261abcf6d9e564ba32d3cc15534b9026f29e""><code>0019261</code></a> Update stable branch after publishing to PyPI (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3223"">#3223</a>)</li>; <li><a href=""https://github.com/psf/black/commit/7757078ecd84d349bb24ab61e79062ba50162ef9""><code>7757078</code></a> Improve &amp; update release process to reflect recent changes (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3242"">#3242</a>)</li>; <li><a href=""https://github.com/psf/black/commit/767604e03f5e454ae5b5c268cd5831c672f46de8""><code>767604e</code></a> Use .gitignore files in the initial source directories (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3237"">#3237</a>)</li>; <li><a href=""https://github.com/psf/black/commit/2c90480e1a102ab0fac57737d2ba5143d82abed7""><code>2c90480</code></a> Use strict mypy checking (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3222"">#3222</a>)</li>; <li><a href=""https://github.com/psf/black/commit/ba618a307a30a119b4fafe526ebf7d5f092ba981""><code>ba618a3</code></a> Add parens around implicit string concatenations where it increases readabili...</li>; <li><a href=""https://github.com/psf/black/commit/c0cc19b5b3371842d696875897bebefebd5e1596""><code>c0cc19b</code></a> Delay worker count determination</li>; <li><a href=""https://github.com/psf/black/commit/afed2c01903465f9a486ac481a66aa3413cc1b01""><code>afed2c0</code></a> Load .gitignore and exclude regex at time of use</li>; <li><a href=""https://github.com/psf/black/commit/e269f44b25737360e0dc65379f889dfa931dc68a""><code>e269f44</code></a> Lazily import parallelized format modules</li>; <li><a href=""https://github.com/psf/black/commit/c47b91f513052cd39b818ea7c19716423c85c04e""><code>c47b91f</code></a> Fix misdetection of project root with <code>--stdin-filename</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/3216"">#3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12174:10110,depend,dependabot,10110,https://hail.is,https://github.com/hail-is/hail/pull/12174,1,['depend'],['dependabot']
Integrability,"/psf/requests/commit/e50dc12b0f620ff80a0d2026b5b0a5282894bfd4""><code>e50dc12</code></a> Fix doc link</li>; <li><a href=""https://github.com/psf/requests/commit/17e6e27a93131b7295165408e69b4cadb098b0d7""><code>17e6e27</code></a> General cleanup for 2.27.0</li>; <li><a href=""https://github.com/psf/requests/commit/ab38e2c72608b95b047b05ccfaca833edb9db1b1""><code>ab38e2c</code></a> Make the <code>data</code> vs <code>json</code> parameters more clear (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5382"">#5382</a>)</li>; <li><a href=""https://github.com/psf/requests/commit/77d1e9aa3e000b40fdf93cfc355e1fe7cc52b6ac""><code>77d1e9a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/psf/requests/issues/5894"">#5894</a> from dbaxa/do-not-re-build-proxies-when-proxies-have...</li>; <li><a href=""https://github.com/psf/requests/commit/b0829a869081c2a6180db2cdc41a5676922becd0""><code>b0829a8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/psf/requests/issues/6020"">#6020</a> from nateprewitt/pypy_37</li>; <li><a href=""https://github.com/psf/requests/commit/28d537dde33b35c3b7071afd99122eff3538b42c""><code>28d537d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/psf/requests/issues/5917"">#5917</a> from nateprewitt/proxy_scheme_unknown_fix</li>; <li>Additional commits viewable in <a href=""https://github.com/psf/requests/compare/v2.25.1...v2.27.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=requests&package-manager=pip&previous-version=2.25.1&new-version=2.27.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dep",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11528:8539,depend,dependabot,8539,https://hail.is,https://github.com/hail-is/hail/pull/11528,2,['depend'],['dependabot']
Integrability,"/pyasn1/pyasn1-modules/issues/136"">#136</a>)</li>; <li><a href=""https://github.com/pyasn1/pyasn1-modules/commit/13ca0da0cc4d0703ca42113f607bde95cf0bfd9c""><code>13ca0da</code></a> Fix tox deps inheritance</li>; <li><a href=""https://github.com/pyasn1/pyasn1-modules/commit/00fa3b9d15c783389afee7887f5ba3738a005545""><code>00fa3b9</code></a> Run unittests across many Python versions</li>; <li>Additional commits viewable in <a href=""https://github.com/pyasn1/pyasn1-modules/compare/v0.2.8...v0.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyasn1-modules&package-manager=pip&previous-version=0.2.8&new-version=0.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12928:9450,depend,dependabot,9450,https://hail.is,https://github.com/hail-is/hail/pull/12928,1,['depend'],['dependabot']
Integrability,"/pyca/cryptography/commit/851d8ccb340bfc93c827b9e80af939a216b34925""><code>851d8cc</code></a> Bump openssl from 0.10.52 to 0.10.53 in /src/rust (<a href=""https://redirect.github.com/pyca/cryptography/issues/8986"">#8986</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/0918c7236c94c29272e0790ba0227cfa9401943b""><code>0918c72</code></a> Bump coverage from 7.2.6 to 7.2.7 (<a href=""https://redirect.github.com/pyca/cryptography/issues/8985"">#8985</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pyca/cryptography/compare/40.0.2...41.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=40.0.2&new-version=41.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13146:5130,Depend,Dependabot,5130,https://hail.is,https://github.com/hail-is/hail/pull/13146,1,['Depend'],['Dependabot']
Integrability,"/pyjwt/issues/689"">#689</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/jpadilla/pyjwt/compare/1.7.1...2.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyjwt&package-manager=pip&previous-version=1.7.1&new-version=2.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11457:14387,Depend,Dependabot,14387,https://hail.is,https://github.com/hail-is/hail/pull/11457,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"/pylint#7427</a></p>; </li>; <li>; <p>Fixed a crash on <code>namedtuples</code> that use <code>typename</code> to specify their name.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7429"">PyCQA/pylint#7429</a></p>; </li>; </ul>; <h1>What's New in astroid 2.12.8?</h1>; <p>Release date: 2022-09-06</p>; <ul>; <li>; <p>Fixed a crash in the <code>dataclass</code> brain for <code>InitVars</code> without subscript typing.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7422"">PyCQA/pylint#7422</a></p>; </li>; <li>; <p>Fixed parsing of default values in <code>dataclass</code> attributes.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7425"">PyCQA/pylint#7425</a></p>; </li>; </ul>; <h1>What's New in astroid 2.12.7?</h1>; <p>Release date: 2022-09-06</p>; <ul>; <li>; <p>Fixed a crash in the <code>dataclass</code> brain for uninferable bases.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7418"">PyCQA/pylint#7418</a></p>; </li>; </ul>; <h1>What's New in astroid 2.12.6?</h1>; <p>Release date: 2022-09-05</p>; <ul>; <li>; <p>Fix a crash involving <code>Uninferable</code> arguments to <code>namedtuple()</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7375"">PyCQA/pylint#7375</a></p>; </li>; <li>; <p>The <code>dataclass</code> brain now understands the <code>kw_only</code> keyword in dataclass decorators.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7290"">PyCQA/pylint#7290</a></p>; </li>; </ul>; <h1>What's New in astroid 2.12.5?</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/astroid/commit/7352e947bdf9b9c5ea51e601bbed7a063e98316d""><code>7352e94</code></a> Bump astroid to 2.12.9, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/comm",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12161:1524,depend,dependabot,1524,https://hail.is,https://github.com/hail-is/hail/pull/12161,1,['depend'],['dependabot']
Integrability,"/python-certifi) from 2022.9.24 to 2022.12.7.; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/certifi/python-certifi/commit/9e9e840925d7b8e76c76fdac1fab7e6e88c1c3b8""><code>9e9e840</code></a> 2022.12.07</li>; <li>See full diff in <a href=""https://github.com/certifi/python-certifi/compare/2022.09.24...2022.12.07"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=certifi&package-manager=pip&previous-version=2022.9.24&new-version=2022.12.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12549:1028,Depend,Dependabot,1028,https://hail.is,https://github.com/hail-is/hail/pull/12549,3,['Depend'],['Dependabot']
Integrability,"/python-humanize/humanize/commit/7b0d9be9e472b5e99e4db2ed15dc5716639c2121""><code>7b0d9be</code></a> Fix wrong declinations of googol and a year</li>; <li><a href=""https://github.com/python-humanize/humanize/commit/d0dde8f2e4ab13de51c6920f6ed523eadd2d4d3c""><code>d0dde8f</code></a> Replace short scale with long scale for Polish</li>; <li><a href=""https://github.com/python-humanize/humanize/commit/72d3ef4209d806f45db8de02fe095d46aeaccad1""><code>72d3ef4</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/53"">#53</a> from Luflosi/implement-decimal-sep-i18n</li>; <li><a href=""https://github.com/python-humanize/humanize/commit/862748a7acd3db1257418101eec626688e0d3c78""><code>862748a</code></a> Internationalise the decimal separator in intcomma()</li>; <li><a href=""https://github.com/python-humanize/humanize/commit/d8e27393dbf4ed3645ffc3464c9c44f4d8e47534""><code>d8e2739</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/52"">#52</a> from Luflosi/fix-intcomma-with-str-and-ndigits</li>; <li>Additional commits viewable in <a href=""https://github.com/python-humanize/humanize/compare/1.1.0...4.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=humanize&package-manager=pip&previous-version=1.1.0&new-version=4.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12329:6963,depend,dependabot,6963,https://hail.is,https://github.com/hail-is/hail/pull/12329,1,['depend'],['dependabot']
Integrability,"/python-logging/commit/5055919f70c82b38de6d1fa7f1df6006865a857b"">5055919</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/googleapis/python-logging/commit/10727ef3c8cca7e20484e58e6afdc79e81a4d4c9""><code>10727ef</code></a> chore(main): release 3.0.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/473"">#473</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/d86be6cf83c3f3b91c4fc0b2e0666b0ca1d7e248""><code>d86be6c</code></a> chore(deps): update dependency google-cloud-storage to v2.1.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/469"">#469</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/8a67b73cdfcb9da545671be6cf59c724360b1544""><code>8a67b73</code></a> docs: update usage guide for v3.0.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/456"">#456</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/e0c5fc02160ae87faf4ba5c2b62be86de6b02cf3""><code>e0c5fc0</code></a> feat: trace improvements (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/450"">#450</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/97e32b67603553fe350b6327455fc9f80b8aa6ce""><code>97e32b6</code></a> fix: allow reading logs from non-project paths (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/444"">#444</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/a760e02371a55d6262e42de9e0222fffa2c7192b""><code>a760e02</code></a> feat: add json_fields extras argument for adding to jsonPayload (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/447"">#447</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/83d9ca8521fe7c470bb6755a48a9749",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11574:11875,depend,dependabot,11875,https://hail.is,https://github.com/hail-is/hail/pull/11574,1,['depend'],['dependabot']
Integrability,"/python-storage/issues/622"">#622</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/8aa4130ee068a1922161c8ca54a53a4a51d65ce0""><code>8aa4130</code></a> feat: remove python 3.6 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/689"">#689</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/fe1855a5f23dd49f5d2f830d9ae39b8f2f0a4aaf""><code>fe1855a</code></a> chore(python): update release.sh to use keystore (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/692"">#692</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/b53feaaaf0af92ea9e1d16abd317f798f2b6e17a""><code>b53feaa</code></a> build: switch to release-please for tagging (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/691"">#691</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/7f771077511d6b446686724f48514d5b903ec036""><code>7f77107</code></a> chore(deps): update dependency google-cloud-storage to v2 (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/690"">#690</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/7891dcc6c0bd90da192691025c910cf30c98407b""><code>7891dcc</code></a> chore(main): release 2.0.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/687"">#687</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/python-storage/compare/v1.25.0...v2.1.0"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11520:8002,depend,dependency,8002,https://hail.is,https://github.com/hail-is/hail/pull/11520,1,['depend'],['dependency']
Integrability,"/python/importlib_metadata/blob/main/CHANGES.rst"">importlib-metadata's changelog</a>.</em></p>; <blockquote>; <h1>v5.0.0</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/97"">#97</a>, <a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/284"">#284</a>, <a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/300"">#300</a>: Removed compatibility shims for deprecated entry; point interfaces.</li>; </ul>; <h1>v4.13.0</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/396"">#396</a>: Added compatibility for <code>PathDistributions</code> originating; from Python 3.8 and 3.9.</li>; </ul>; <h1>v4.12.0</h1>; <ul>; <li>py-93259: Now raise <code>ValueError</code> when <code>None</code> or an empty; string are passed to <code>Distribution.from_name</code> (and other; callers).</li>; </ul>; <h1>v4.11.4</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/379"">#379</a>: In <code>PathDistribution._name_from_stem</code>, avoid including; parts of the extension in the result.</li>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/381"">#381</a>: In <code>PathDistribution._normalized_name</code>, ensure names; loaded from the stem of the filename are also normalized, ensuring; duplicate entry points by packages varying only by non-normalized; name are hidden.</li>; </ul>; <h1>v4.11.3</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/372"">#372</a>: Removed cast of path items in FastPath, not needed.</li>; </ul>; <h1>v4.11.2</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/369"">#369</a>: Fixed bug where <code>EntryPoint.extras</code> was returning; match objects and not the extras strings.</li>; </ul>; <h1>v4.11.1</h1>; <ul>; <li><a href=""https://github-redirect.dependabot.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12391:1179,depend,dependabot,1179,https://hail.is,https://github.com/hail-is/hail/pull/12391,1,['depend'],['dependabot']
Integrability,"/python/typing_extensions/issues/42"">#42</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/e9d09b5bb998693c3565a276a27f424b327b0f7b""><code>e9d09b5</code></a> Remove obsolete README.rst (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/41"">#41</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/447b62c4816efbd85727a12191a310bac5c416cc""><code>447b62c</code></a> fix CI (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/4"">#4</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/47600f62c354ca028c29762fa6ff0b007716ef88""><code>47600f6</code></a> update links (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/3"">#3</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/bc9317ef90a629f27f1ab706bfce99da873044b4""><code>bc9317e</code></a> Change home URL to tree instead of README (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/1157"">#1157</a>)</li>; <li><a href=""https://github.com/python/typing_extensions/commit/c10296f15f92277ed1d3ed0c83103ae3818d3669""><code>c10296f</code></a> Add a README.rst file back temporarily. (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/1156"">#1156</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/python/typing_extensions/compare/4.2.0...4.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=typing-extensions&package-manager=pip&previous-version=4.2.0&new-version=4.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12200:3466,depend,dependabot,3466,https://hail.is,https://github.com/hail-is/hail/pull/12200,1,['depend'],['dependabot']
Integrability,"/qos-ch/slf4j/commit/e02244c39f11cdcdb07d6b291f157e3687d5b920""><code>e02244c</code></a> fix FUNDING file</li>; <li><a href=""https://github.com/qos-ch/slf4j/commit/441d4584bed16ec8fe54a9c4acb8d289e51005b8""><code>441d458</code></a> fix FUNDING file</li>; <li><a href=""https://github.com/qos-ch/slf4j/commit/f5e741ba1af6565269499d34c725c32ef8ca467f""><code>f5e741b</code></a> add FUNDING file</li>; <li><a href=""https://github.com/qos-ch/slf4j/commit/2e71327c8ee745927d731e8d9f4e51d331dad138""><code>2e71327</code></a> remove unused log4j dependency in the version definition section of pom.xml</li>; <li><a href=""https://github.com/qos-ch/slf4j/commit/3ff2a30e05e5825d96ddb54da243df48f1a9d897""><code>3ff2a30</code></a> start work on 2.0.6-SNAPSHOT</li>; <li>Additional commits viewable in <a href=""https://github.com/qos-ch/slf4j/compare/v_1.7.25...v_2.0.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.slf4j:slf4j-api&package-manager=gradle&previous-version=1.7.25&new-version=2.0.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block au",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12714:1938,depend,dependency-name,1938,https://hail.is,https://github.com/hail-is/hail/pull/12714,1,['depend'],['dependency-name']
Integrability,"/qos-ch/slf4j/commit/f5e741ba1af6565269499d34c725c32ef8ca467f""><code>f5e741b</code></a> add FUNDING file</li>; <li><a href=""https://github.com/qos-ch/slf4j/commit/2e71327c8ee745927d731e8d9f4e51d331dad138""><code>2e71327</code></a> remove unused log4j dependency in the version definition section of pom.xml</li>; <li><a href=""https://github.com/qos-ch/slf4j/commit/3ff2a30e05e5825d96ddb54da243df48f1a9d897""><code>3ff2a30</code></a> start work on 2.0.6-SNAPSHOT</li>; <li>Additional commits viewable in <a href=""https://github.com/qos-ch/slf4j/compare/v_1.7.25...v_2.0.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.slf4j:slf4j-api&package-manager=gradle&previous-version=1.7.25&new-version=2.0.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12714:2172,Depend,Dependabot,2172,https://hail.is,https://github.com/hail-is/hail/pull/12714,1,['Depend'],['Dependabot']
Integrability,"/qtpy/commit/b3efba8b2f5ef670842c73dd171aaa98e298db37""><code>b3efba8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/issues/354"">#354</a> from zjp/objectisalive</li>; <li><a href=""https://github.com/spyder-ide/qtpy/commit/60af2d85eb25590e2ae7c1382011fe7fac818279""><code>60af2d8</code></a> compat.py: Add wrapper around sip/shiboken isdeleted/isvalid</li>; <li>Additional commits viewable in <a href=""https://github.com/spyder-ide/qtpy/compare/v2.1.0...v2.2.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=qtpy&package-manager=pip&previous-version=2.1.0&new-version=2.2.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12194:8979,depend,dependabot,8979,https://hail.is,https://github.com/hail-is/hail/pull/12194,1,['depend'],['dependabot']
Integrability,"/redirect.github.com/pyca/cryptography/issues/8975"">#8975</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/851d8ccb340bfc93c827b9e80af939a216b34925""><code>851d8cc</code></a> Bump openssl from 0.10.52 to 0.10.53 in /src/rust (<a href=""https://redirect.github.com/pyca/cryptography/issues/8986"">#8986</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/0918c7236c94c29272e0790ba0227cfa9401943b""><code>0918c72</code></a> Bump coverage from 7.2.6 to 7.2.7 (<a href=""https://redirect.github.com/pyca/cryptography/issues/8985"">#8985</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pyca/cryptography/compare/40.0.2...41.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=40.0.2&new-version=41.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13146:5073,depend,dependabot-security-updates,5073,https://hail.is,https://github.com/hail-is/hail/pull/13146,1,['depend'],['dependabot-security-updates']
Integrability,"/requests/issues/5391"">#5391</a>)</p>; </li>; <li>; <p>Fixed regression in Requests 2.26.0 where <code>Proxy-Authorization</code> was; incorrectly stripped from all requests sent with <code>Session.send</code>. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5924"">#5924</a>)</p>; </li>; <li>; <p>Fixed performance regression in 2.26.0 for hosts with a large number of; proxies available in the environment. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5924"">#5924</a>)</p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/psf/requests/blob/main/HISTORY.md"">requests's changelog</a>.</em></p>; <blockquote>; <h2>2.27.1 (2022-01-05)</h2>; <p><strong>Bugfixes</strong></p>; <ul>; <li>Fixed parsing issue that resulted in the <code>auth</code> component being; dropped from proxy URLs. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/6028"">#6028</a>)</li>; </ul>; <h2>2.27.0 (2022-01-03)</h2>; <p><strong>Improvements</strong></p>; <ul>; <li>; <p>Officially added support for Python 3.10. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5928"">#5928</a>)</p>; </li>; <li>; <p>Added a <code>requests.exceptions.JSONDecodeError</code> to unify JSON exceptions between; Python 2 and 3. This gets raised in the <code>response.json()</code> method, and is; backwards compatible as it inherits from previously thrown exceptions.; Can be caught from <code>requests.exceptions.RequestException</code> as well. (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/5856"">#5856</a>)</p>; </li>; <li>; <p>Improved error text for misnamed <code>InvalidSchema</code> and <code>MissingSchema</code>; exceptions. This is a temporary fix until exceptions can be renamed; (Schema-&gt;Scheme). (<a href=""https://github-redirect.dependabot.com/psf/requests/issues/6017"">#6017</a>)</p>; </l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11528:3794,depend,dependabot,3794,https://hail.is,https://github.com/hail-is/hail/pull/11528,2,['depend'],['dependabot']
Integrability,"/sphinx/commit/52c7f66ce172f723e8227896fe02165d288cb28f""><code>52c7f66</code></a> Use the correct token minting URL for TestPyPI</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/6079f28faa2a60d00f62b02786f23cd489019cdb""><code>6079f28</code></a> Install twine in PyPI publish workflow</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/3d43b9efdb49706cad6947f0c4d877d603781fe6""><code>3d43b9e</code></a> Fix github-script syntax in create-release.yml</li>; <li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v6.2.1...v7.1.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx&package-manager=pip&previous-version=6.2.1&new-version=7.1.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13295:7069,Depend,Dependabot,7069,https://hail.is,https://github.com/hail-is/hail/pull/13295,1,['Depend'],['Dependabot']
Integrability,"/sphinx/issues/10481"">#10481</a> from AA-Turner/lang-none-en</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/200414982c768c213ca66f41fa331a5b4d129d94""><code>2004149</code></a> Update test</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/78c478a579b9d3f57091544d1717ee7f1c507ff1""><code>78c478a</code></a> Merge remote-tracking branch 'upstream/5.0.x' into lang-none-en</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/479e48266c025c99025787a8004a82b2afda8e6c""><code>479e482</code></a> Update warning, revert my original warning patch</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/fb6db30c1024ce5838dcf330f275cdf2adbd94b6""><code>fb6db30</code></a> Update comment</li>; <li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v3.5.4...v5.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx&package-manager=pip&previous-version=3.5.4&new-version=5.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11871:6396,depend,dependency-name,6396,https://hail.is,https://github.com/hail-is/hail/pull/11871,1,['depend'],['dependency-name']
Integrability,"/sphinx_rtd_theme/issues/1183"">#1183</a>)</li>; <li>Added support for logos as URLs (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1171"">#1171</a>)</li>; <li>Align top and side navigation background colors on mobile (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1132"">#1132</a>)</li>; <li>Added support for deep toc levels (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1089"">#1089</a>)</li>; <li>Updated translations for Chinese, Dutch, Estonian, French, German, Italian,; Lithuanian, Persian, Polish, Portuguese, Russian, Spanish, Swedish, and; Turkish locales</li>; </ul>; <p>A number of accessibility features were added in this release:</p>; <ul>; <li>Allow keyboard to toggle menu expansion (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1167"">#1167</a>)</li>; <li>Allow keyboard to activate permalink (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1162"">#1162</a>)</li>; <li>Show keyboard focus on buttons (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1161"">#1161</a>)</li>; <li>Maintain aria-expanded along with .current in menu (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1151"">#1151</a>)</li>; <li>Respect tab order for prev/next buttons (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1051"">#1051</a>)</li>; </ul>; <h2>Fixes</h2>; <ul>; <li>Updated Google analytics integration (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1129"">#1129</a>)</li>; <li>Add classifier separation on Sphinx 2+ HTML4 writer (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1192"">#1192</a>)</li>; <li>Added missing space char in footer (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1188"">#1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11464:2428,depend,dependabot,2428,https://hail.is,https://github.com/hail-is/hail/pull/11464,2,['depend'],['dependabot']
Integrability,"/sphinxcontrib-katex/commit/0164f90b8242f65911ac1b4c86afe09082e527bc""><code>0164f90</code></a> Server side implementation of pre rendering of Latex equations (<a href=""https://github-redirect.dependabot.com/hagenw/sphinxcontrib-katex/issues/69"">#69</a>)</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/7946b7d8bae7fd7dead59377cd944f3949768376""><code>7946b7d</code></a> DOC: fix typo in usage section (<a href=""https://github-redirect.dependabot.com/hagenw/sphinxcontrib-katex/issues/80"">#80</a>)</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/e643524b34edddb30517f77eadea2d5c614b9957""><code>e643524</code></a> Use KaTeX 0.16.0 (<a href=""https://github-redirect.dependabot.com/hagenw/sphinxcontrib-katex/issues/77"">#77</a>)</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/258a8832d9518340386e584206d7b5116185b182""><code>258a883</code></a> DOC: adjust test badge to point to Github Actions (<a href=""https://github-redirect.dependabot.com/hagenw/sphinxcontrib-katex/issues/76"">#76</a>)</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/ef894b2bf6ae4b1eaa0c5adec7ab5c1540da97cd""><code>ef894b2</code></a> Support Python 3.10 (<a href=""https://github-redirect.dependabot.com/hagenw/sphinxcontrib-katex/issues/74"">#74</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/hagenw/sphinxcontrib-katex/compare/0.5.1...v0.9.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinxcontrib-katex&package-manager=pip&previous-version=0.5.1&new-version=0.9.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12241:5891,depend,dependabot,5891,https://hail.is,https://github.com/hail-is/hail/pull/12241,1,['depend'],['dependabot']
Integrability,"/sphinxcontrib-katex/issues/76"">#76</a>)</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/ef894b2bf6ae4b1eaa0c5adec7ab5c1540da97cd""><code>ef894b2</code></a> Support Python 3.10 (<a href=""https://github-redirect.dependabot.com/hagenw/sphinxcontrib-katex/issues/74"">#74</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/hagenw/sphinxcontrib-katex/compare/0.5.1...v0.9.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinxcontrib-katex&package-manager=pip&previous-version=0.5.1&new-version=0.9.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12241:6885,depend,dependabot-automerge-start,6885,https://hail.is,https://github.com/hail-is/hail/pull/12241,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"/substack/minimist/commit/ef88b9325f77b5ee643ccfc97e2ebda577e4c4e2""><code>ef88b93</code></a> security notice for additional prototype pollution issue</li>; <li><a href=""https://github.com/substack/minimist/commit/c2b981977fa834b223b408cfb860f933c9811e4d""><code>c2b9819</code></a> isConstructorOrProto adapted from PR</li>; <li><a href=""https://github.com/substack/minimist/commit/bc8ecee43875261f4f17eb20b1243d3ed15e70eb""><code>bc8ecee</code></a> test from prototype pollution PR</li>; <li>See full diff in <a href=""https://github.com/substack/minimist/compare/1.2.5...1.2.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=minimist&package-manager=npm_and_yarn&previous-version=1.2.5&new-version=1.2.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11653:1245,Depend,Dependabot,1245,https://hail.is,https://github.com/hail-is/hail/pull/11653,1,['Depend'],['Dependabot']
Integrability,"/summary>; <ul>; <li><a href=""https://github.com/ipython/comm/commit/d119118d950f2c64f184c37e7e42b4c968701668""><code>d119118</code></a> Publish 0.2.2</li>; <li><a href=""https://github.com/ipython/comm/commit/76149e7ee0f331772c964ae86cdb8bafebe6dfa2""><code>76149e7</code></a> Update Release Scripts (<a href=""https://redirect.github.com/ipython/comm/issues/27"">#27</a>)</li>; <li><a href=""https://github.com/ipython/comm/commit/915898ddeddd0d1c8a1b87c5dcfbe6392fd225b7""><code>915898d</code></a> chore: update pre-commit hooks (<a href=""https://redirect.github.com/ipython/comm/issues/26"">#26</a>)</li>; <li>See full diff in <a href=""https://github.com/ipython/comm/compare/v0.2.1...v0.2.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=comm&package-manager=pip&previous-version=0.2.1&new-version=0.2.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14492:3802,depend,dependabot-security-updates,3802,https://hail.is,https://github.com/hail-is/hail/pull/14492,1,['depend'],['dependabot-security-updates']
Integrability,"/tomplus/kubernetes_asyncio/issues/202"">#202</a>)</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/961624063383cbcdc78a61b1d18448429a61a489""><code>9616240</code></a> [chore] update changelog</li>; <li>Additional commits viewable in <a href=""https://github.com/tomplus/kubernetes_asyncio/compare/v19.15.1...23.6.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=kubernetes-asyncio&package-manager=pip&previous-version=19.15.1&new-version=23.6.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:16164,Depend,Dependabot,16164,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['Depend'],['Dependabot']
Integrability,"/tornadoweb/tornado/commit/217295b1dd30f556ea374d62007f6821688f00f0""><code>217295b</code></a> http1connection: Make content-length parsing more strict</li>; <li><a href=""https://github.com/tornadoweb/tornado/commit/e3aa6c5e2943242d8ab25448c2798365b3cb9945""><code>e3aa6c5</code></a> Merge pull request <a href=""https://redirect.github.com/tornadoweb/tornado/issues/3267"">#3267</a> from bdarnell/branch6.3</li>; <li>See full diff in <a href=""https://github.com/tornadoweb/tornado/compare/v6.3.2...v6.3.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=tornado&package-manager=pip&previous-version=6.3.2&new-version=6.3.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major versio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13432:2994,depend,dependabot,2994,https://hail.is,https://github.com/hail-is/hail/pull/13432,2,['depend'],['dependabot']
Integrability,"/tqdm/commit/7994aa8285743b351cf1a3b36275335d8d0730b7""><code>7994aa8</code></a> warn once on error</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/a1d4401f186dc5a79b4ad452f38cae75e1f2e6da""><code>a1d4401</code></a> remove unneeded variable</li>; <li>Additional commits viewable in <a href=""https://github.com/tqdm/tqdm/compare/v4.42.1...v4.64.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=tqdm&package-manager=pip&previous-version=4.42.1&new-version=4.64.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12260:6317,Depend,Dependabot,6317,https://hail.is,https://github.com/hail-is/hail/pull/12260,1,['Depend'],['Dependabot']
Integrability,"/ul>; <h3>Bug Fixes</h3>; <ul>; <li>allow reading logs from non-project paths (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/444"">#444</a>) (<a href=""https://github.com/googleapis/python-logging/commit/97e32b67603553fe350b6327455fc9f80b8aa6ce"">97e32b6</a>)</li>; <li>api consistency between HTTP and Gapic layers (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/375"">#375</a>) (<a href=""https://github.com/googleapis/python-logging/commit/e1506fa9030776353878048ce562c53bf6ccf7bf"">e1506fa</a>)</li>; </ul>; <h3>Miscellaneous Chores</h3>; <ul>; <li>deprecate AppEngineHandler and ContainerEngineHandler (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/310"">#310</a>) (<a href=""https://github.com/googleapis/python-logging/commit/e3cac888d40bf67af11e57b74615b0c3b8e8aa3e"">e3cac88</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>update usage guide for v3.0.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/456"">#456</a>) (<a href=""https://github.com/googleapis/python-logging/commit/8a67b73cdfcb9da545671be6cf59c724360b1544"">8a67b73</a>)</li>; </ul>; <h2><a href=""https://www.github.com/googleapis/python-logging/compare/v2.6.0...v2.7.0"">2.7.0</a> (2021-11-02)</h2>; <h3>Features</h3>; <ul>; <li>add context manager support in client (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/415"">#415</a>) (<a href=""https://www.github.com/googleapis/python-logging/commit/f5af16439807a0954ee78fa91cb69b9493b80176"">f5af164</a>)</li>; <li>added support for iam AuditData proto (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/396"">#396</a>) (<a href=""https://www.github.com/googleapis/python-logging/commit/e3a1eba74dd8b67bcc73a78f784189ef2a9927c2"">e3a1eba</a>)</li>; <li>use structured logging on GCF with python 3.7 (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/434"">#43",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11574:9824,depend,dependabot,9824,https://hail.is,https://github.com/hail-is/hail/pull/11574,1,['depend'],['dependabot']
Integrability,"/ul>; <h3>Bug Fixes</h3>; <ul>; <li>allow reading logs from non-project paths (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/444"">#444</a>) (<a href=""https://github.com/googleapis/python-logging/commit/97e32b67603553fe350b6327455fc9f80b8aa6ce"">97e32b6</a>)</li>; <li>api consistency between HTTP and Gapic layers (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/375"">#375</a>) (<a href=""https://github.com/googleapis/python-logging/commit/e1506fa9030776353878048ce562c53bf6ccf7bf"">e1506fa</a>)</li>; </ul>; <h3>Miscellaneous Chores</h3>; <ul>; <li>deprecate AppEngineHandler and ContainerEngineHandler (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/310"">#310</a>) (<a href=""https://github.com/googleapis/python-logging/commit/e3cac888d40bf67af11e57b74615b0c3b8e8aa3e"">e3cac88</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>update usage guide for v3.0.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/456"">#456</a>) (<a href=""https://github.com/googleapis/python-logging/commit/8a67b73cdfcb9da545671be6cf59c724360b1544"">8a67b73</a>)</li>; </ul>; <h2>v2.7.0</h2>; <h3>Features</h3>; <ul>; <li>add context manager support in client (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/415"">#415</a>) (<a href=""https://www.github.com/googleapis/python-logging/commit/f5af16439807a0954ee78fa91cb69b9493b80176"">f5af164</a>)</li>; <li>added support for iam AuditData proto (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/396"">#396</a>) (<a href=""https://www.github.com/googleapis/python-logging/commit/e3a1eba74dd8b67bcc73a78f784189ef2a9927c2"">e3a1eba</a>)</li>; <li>use structured logging on GCF with python 3.7 (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/434"">#434</a>) (<a href=""https://www.github.com/googleapis/python-logging/commit/5055919f70c82b38de6d1fa7f1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11574:4391,depend,dependabot,4391,https://hail.is,https://github.com/hail-is/hail/pull/11574,1,['depend'],['dependabot']
Integrability,"/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Use of a Broken or Risky Cryptographic Algorithm <br/>[SNYK-PYTHON-PYJWT-2840625](https://snyk.io/vuln/SNYK-PYTHON-PYJWT-2840625) | `pyjwt:` <br> `1.7.1 -> 2.4.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Timing Attack <br/>[SNYK-PYTHON-RSA-1038401](https://snyk.io/vuln/SNYK-PYTHON-RSA-1038401) | `rsa:` <br> `4.5 -> 4.7` <br> | No | No Known Exploit . Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxMjk3MjE5NC04YzAyLTRhMjQtYTA0Ni0yZjIxMjk4YjQ2NmEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjEyOTcyMTk0LThjMDItNGEyNC1hMDQ2LTJmMjEyOThiNDY2YSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14134:7963,depend,dependency,7963,https://hail.is,https://github.com/hail-is/hail/pull/14134,2,['depend'],"['dependencies', 'dependency']"
Integrability,"/utils.py"", line 35, in <lambda>; thread_pool, lambda: fun(*args, **kwargs)); File ""/usr/local/lib/python3.6/site-packages/batch/google_storage.py"", line 65, in _write_gs_file; f.upload_from_string(string, *args, **kwargs); File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 1257, in upload_from_string; predefined_acl=predefined_acl,; File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 1157, in upload_from_file; client, file_obj, content_type, size, num_retries, predefined_acl; File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 1063, in _do_upload; client, stream, content_type, size, num_retries, predefined_acl; File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 857, in _do_multipart_upload; response = upload.transmit(transport, data, object_metadata, content_type); File ""/usr/local/lib/python3.6/site-packages/google/resumable_media/requests/upload.py"", line 106, in transmit; retry_strategy=self._retry_strategy,; File ""/usr/local/lib/python3.6/site-packages/google/resumable_media/requests/_helpers.py"", line 136, in http_request; return _helpers.wait_and_retry(func, RequestsMixin._get_status_code, retry_strategy); File ""/usr/local/lib/python3.6/site-packages/google/resumable_media/_helpers.py"", line 150, in wait_and_retry; response = func(); File ""/usr/local/lib/python3.6/site-packages/google/auth/transport/requests.py"", line 317, in request; **kwargs; File ""/usr/local/lib/python3.6/site-packages/requests/sessions.py"", line 533, in request; resp = self.send(prep, **send_kwargs); File ""/usr/local/lib/python3.6/site-packages/requests/sessions.py"", line 646, in send; r = adapter.send(request, **kwargs); File ""/usr/local/lib/python3.6/site-packages/requests/adapters.py"", line 529, in send; raise ReadTimeout(e, request=request); requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='www.googleapis.com', port=443): Read timed out. (read timeout=60). ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8083:4990,adapter,adapter,4990,https://hail.is,https://github.com/hail-is/hail/issues/8083,2,['adapter'],"['adapter', 'adapters']"
Integrability,"/utils.py"", line 35, in <lambda>; thread_pool, lambda: fun(*args, **kwargs)); File ""/usr/local/lib/python3.6/site-packages/batch/google_storage.py"", line 65, in _write_gs_file; f.upload_from_string(string, *args, **kwargs); File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 1257, in upload_from_string; predefined_acl=predefined_acl,; File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 1157, in upload_from_file; client, file_obj, content_type, size, num_retries, predefined_acl; File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 1063, in _do_upload; client, stream, content_type, size, num_retries, predefined_acl; File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 857, in _do_multipart_upload; response = upload.transmit(transport, data, object_metadata, content_type); File ""/usr/local/lib/python3.6/site-packages/google/resumable_media/requests/upload.py"", line 106, in transmit; retry_strategy=self._retry_strategy,; File ""/usr/local/lib/python3.6/site-packages/google/resumable_media/requests/_helpers.py"", line 136, in http_request; return _helpers.wait_and_retry(func, RequestsMixin._get_status_code, retry_strategy); File ""/usr/local/lib/python3.6/site-packages/google/resumable_media/_helpers.py"", line 150, in wait_and_retry; response = func(); File ""/usr/local/lib/python3.6/site-packages/google/auth/transport/requests.py"", line 317, in request; **kwargs; File ""/usr/local/lib/python3.6/site-packages/requests/sessions.py"", line 533, in request; resp = self.send(prep, **send_kwargs); File ""/usr/local/lib/python3.6/site-packages/requests/sessions.py"", line 646, in send; r = adapter.send(request, **kwargs); File ""/usr/local/lib/python3.6/site-packages/requests/adapters.py"", line 529, in send; raise ReadTimeout(e, request=request); requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='www.googleapis.com', port=443): Read timed out. (read timeout=60); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8053:5000,adapter,adapter,5000,https://hail.is,https://github.com/hail-is/hail/issues/8053,4,['adapter'],"['adapter', 'adapters']"
Integrability,"/v12.6.0...v13.5.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=rich&package-manager=pip&previous-version=12.6.0&new-version=13.5.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13575:7426,Depend,Dependabot,7426,https://hail.is,https://github.com/hail-is/hail/pull/13575,9,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"/v12.6.0...v13.5.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=rich&package-manager=pip&previous-version=12.6.0&new-version=13.5.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13651:7564,Depend,Dependabot,7564,https://hail.is,https://github.com/hail-is/hail/pull/13651,18,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"/v1561977819/icon/m.png ""medium severity"") | Remote Code Execution (RCE) <br/>[SNYK-PYTHON-IPYTHON-3318382](https://snyk.io/vuln/SNYK-PYTHON-IPYTHON-3318382) | `ipython:` <br> `7.34.0 -> 8.10.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Access Control Bypass <br/>[SNYK-PYTHON-JUPYTERSERVER-5862881](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862881) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Open Redirect <br/>[SNYK-PYTHON-JUPYTERSERVER-5862882](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-5862882) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Generation of Error Message Containing Sensitive Information <br/>[SNYK-PYTHON-JUPYTERSERVER-6099119](https://snyk.io/vuln/SNYK-PYTHON-JUPYTERSERVER-6099119) | `jupyter-server:` <br> `1.24.0 -> 2.11.2` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SETUPTOOLS-3180412](https://snyk.io/vuln/SNYK-PYTHON-SETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNA",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14074:2646,Message,Message,2646,https://hail.is,https://github.com/hail-is/hail/pull/14074,1,['Message'],['Message']
Integrability,"/v3.17.0...v3.18.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=zipp&package-manager=pip&previous-version=3.17.0&new-version=3.18.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14473:3503,Depend,Dependabot,3503,https://hail.is,https://github.com/hail-is/hail/pull/14473,9,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"/v3.2.0...v3.2.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=oauthlib&package-manager=pip&previous-version=3.2.0&new-version=3.2.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/netw",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12197:7564,Depend,Dependabot,7564,https://hail.is,https://github.com/hail-is/hail/pull/12197,18,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"/zipp/commit/4cceb497c278ad0ecb11a9472e58f4130f5ff16b""><code>4cceb49</code></a> Add special accounting for pypy when computing the stack level for text encod...</li>; <li><a href=""https://github.com/jaraco/zipp/commit/2ec3ed8567d0842675c38fd8ef0a28db668e602d""><code>2ec3ed8</code></a> Add another test at another magnitude.</li>; <li><a href=""https://github.com/jaraco/zipp/commit/d9bf5aab8b39c6a124d9499ae0315d3bf2ac2f46""><code>d9bf5aa</code></a> Fix name generator for width=1</li>; <li>Additional commits viewable in <a href=""https://github.com/jaraco/zipp/compare/v3.17.0...v3.18.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=zipp&package-manager=pip&previous-version=3.17.0&new-version=3.18.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ign",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14473:3171,Depend,Dependabot,3171,https://hail.is,https://github.com/hail-is/hail/pull/14473,1,['Depend'],['Dependabot']
Integrability,"0 azure-mgmt-storage-20.1.0 azure-storage-blob-12.17.0 bokeh-3.2.2 boto3-1.28.41 botocore-1.31.; 41 cachetools-5.3.1 certifi-2023.7.22 cffi-1.15.1 charset-normalizer-3.2.0 commonmark-0.9.1 contourpy-1.1.0 cryptography-41.0.3 decorator-4.4.2 deprecated-1.2.14 dill-0.3.7 frozenlist-1.4.0 google-api-core-2.11.1 google-auth-2.22.0 google-auth-oauthlib-0.8.0 google-cloud-core-2.3.3 google-cloud-storag; e-2.10.0 google-crc32c-1.5.0 google-resumable-media-2.5.0 googleapis-common-protos-1.60.0 humanize-1.1.0 idna-3.4 isodate-0.6.1 janus-1.0.0 jinja2-3.1.2 jmespath-1.0.1 jproperties-2.1.1 markupsafe-2.1.3 msal-1.23.0 msal-extensions-1.0.0 msrest-0.7.1 multidict-6.0.4 nest-asyncio-1.5.7 numpy-1.25.2 oaut; hlib-3.2.2 orjson-3.9.5 packaging-23.1 pandas-2.1.0 parsimonious-0.10.0 pillow-10.0.0 plotly-5.16.1 portalocker-2.7.0 protobuf-3.20.2 py4j-0.10.9.5 pyasn1-0.5.0 pyasn1-modules-0.3.0 pycares-4.3.0 pycparser-2.21 pygments-2.16.1 pyjwt-2.8.0 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3.post; 1 pyyaml-6.0.1 regex-2023.8.8 requests-2.31.0 requests-oauthlib-1.3.1 rich-12.6.0 rsa-4.9 s3transfer-0.6.2 scipy-1.11.2 six-1.16.0 sortedcontainers-2.4.0 tabulate-0.9.0 tenacity-8.2.3 tornado-6.3.3 typer-0.9.0 typing-extensions-4.7.1 tzdata-2023.3 urllib3-1.26.16 uvloop-0.17.0 wrapt-1.15.0 xyzservices; -2023.7.0 yarl-1.9.2. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; python3 -m pip uninstall -y hail; WARNING: Skipping hail as it is not installed.; python3 -m pip install build/deploy/dist/hail-0.2.124-py3-none-any.whl --no-deps; Defaulting to user installation because normal site-packages is not writeable; Processing ./build/deploy/dist/hail-0.2.124-py3-none-any.whl; Installing collected packages: hail; Successfully installed hail-0.2.124. [notice] A new release of pip is available: 23.0.1 -> 23.3; [notice] To update, run: pip3.9 install --upgrade pip; hailctl config set query/backend spark; </p>; </details>",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:44347,wrap,wrapt-,44347,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221,1,['wrap'],['wrapt-']
Integrability,"0 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/151"">tox-dev/py-filelock#151</a></li>; <li>Bump actions/checkout from 2 to 3 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/153"">tox-dev/py-filelock#153</a></li>; <li>Bump actions/setup-python from 2 to 4 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/150"">tox-dev/py-filelock#150</a></li>; <li>Add timeout unit to docstrings by <a href=""https://github.com/jnordberg""><code>@​jnordberg</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/148"">tox-dev/py-filelock#148</a></li>; <li>Unify badges style by <a href=""https://github.com/DeadNews""><code>@​DeadNews</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/155"">tox-dev/py-filelock#155</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/156"">tox-dev/py-filelock#156</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/157"">tox-dev/py-filelock#157</a></li>; <li>Check 3.11 support by <a href=""https://github.com/gaborbernat""><code>@​gaborbernat</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/158"">tox-dev/py-filelock#158</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/pull/159"">tox-dev/py-filelock#159</a></li>; <li>Bu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12157:2042,depend,dependabot,2042,https://hail.is,https://github.com/hail-is/hail/pull/12157,1,['depend'],['dependabot']
Integrability,"0 stable</h2>; <ul>; <li>add <code>contrib.slack</code> (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1313"">#1313</a>)</li>; </ul>; <h2>tqdm v4.63.2 stable</h2>; <ul>; <li><code>rich</code>: expose <code>options</code> kwargs (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1282"">#1282</a>)</li>; <li><code>autonotebook</code>: re-enable VSCode (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1309"">#1309</a>)</li>; <li>misc docs typos (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1301"">#1301</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1299"">#1299</a>)</li>; <li>update dev dependencies (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1311"">#1311</a>)</li>; </ul>; <h2>tqdm v4.63.1 stable</h2>; <ul>; <li>fix stderr/stdout missing <code>flush()</code> (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1248"">#1248</a> &lt;- <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1177"">#1177</a>)</li>; <li>misc speed improvements/optimisations</li>; </ul>; <h2>tqdm v4.63.0 stable</h2>; <ul>; <li>add <code>__reversed__()</code></li>; <li>add efficient <code>__contains__()</code></li>; <li>improve CLI startup time (replace <code>pkg_resources</code> =&gt; <code>importlib</code>)</li>; <li><code>tqdm.autonotebook</code> warning &amp; <code>std</code> fallback on missing <code>ipywidgets</code> (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1218"">#1218</a> &lt;- <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1082"">#1082</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1217"">#1217</a>)</li>; <li>warn on positional CLI arguments</li>; <li>misc build/test framework updates; <ul>; <li>enable <code>py3.10</code> tests</li>; <li>add <code>conda</code> dependencies</li>; <li>update pre-commit hooks</li>; <li>fix <code>pytest</code> config (<code>nbval</code>, <code>asyncio</code>)</li>; <l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12260:1905,depend,dependabot,1905,https://hail.is,https://github.com/hail-is/hail/pull/12260,1,['depend'],['dependabot']
Integrability,"0""><code>e0b3b35</code></a> fix: retry client side requests timeout (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/727"">#727</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/c64779df2fb22d22e76adee00b8a40f3b5bb4b14""><code>c64779d</code></a> chore(deps): update dependency google-cloud-pubsub to v2.11.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/729"">#729</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/2cb0892f4965a42c51b8d6b7127087a6f435b07b""><code>2cb0892</code></a> tests: add retry conf s7 resumable upload test cases (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/720"">#720</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/c7bf615909a04f3bab3efb1047a9f4ba659bba19""><code>c7bf615</code></a> fix: add user agent in python-storage when calling resumable media (WIP) (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/715"">#715</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/4fbbf02d3d2fb7e16c3db32eee0474655247c3bc""><code>4fbbf02</code></a> chore: Adding support for pytest-xdist and pytest-parallel (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/723"">#723</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/dbfe520008a25c4e6f5b94e332129affa0f0d869""><code>dbfe520</code></a> chore(deps): update dependency google-cloud-pubsub to v2.10.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/724"">#724</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/e9aab389f868799d4425133954bad4f1cbb85786""><code>e9aab38</code></a> fix(deps): require google-api-core&gt;=1.31.5, &gt;=2.3.2 (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/722"">#722</a>)</li>; <li>Additional commits viewable in <a href=""https://g",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11578:8112,depend,dependabot,8112,https://hail.is,https://github.com/hail-is/hail/pull/11578,1,['depend'],['dependabot']
Integrability,0); at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:162); at com.esotericsoftware.kryo.util.IdentityObjectIntMap.putStash(IdentityObjectIntMap.java:307); at com.esotericsoftware.kryo.util.IdentityObjectIntMap.push(IdentityObjectIntMap.java:300); at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:162); at com.esotericsoftware.kryo.util.MapReferenceResolver.addWrittenObject(MapReferenceResolver.java:41); at com.esotericsoftware.kryo.Kryo.writeReferenceOrNull(Kryo.java:681); at com.esotericsoftware.kryo.Kryo.writeObjectOrNull(Kryo.java:616); at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$StringArraySerializer.write(DefaultArraySerializers.java:272); at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$StringArraySerializer.write(DefaultArraySerializers.java:258); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651); at com.twitter.chill.WrappedArraySerializer.write(WrappedArraySerializer.scala:28); at com.twitter.chill.WrappedArraySerializer.write(WrappedArraySerializer.scala:23); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651); at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:361); at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:302); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508); at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651); at com.esotericsoftware.kryo.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14168:2481,Wrap,WrappedArraySerializer,2481,https://hail.is,https://github.com/hail-is/hail/issues/14168,2,['Wrap'],['WrappedArraySerializer']
Integrability,"0...v0.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyasn1-modules&package-manager=pip&previous-version=0.3.0&new-version=0.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14472:2802,Depend,Dependabot,2802,https://hail.is,https://github.com/hail-is/hail/pull/14472,9,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"0.0 requires pycares, which is not installed. ```; </details>. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **556/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.4 | Cross-site Scripting (XSS) <br/>[SNYK-PYTHON-JINJA2-6150717](https://snyk.io/vuln/SNYK-PYTHON-JINJA2-6150717) | `jinja2:` <br> `3.1.2 -> 3.1.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI0M2ViODJhZS04ZDkwLTRjZWUtYjIzMS01ZDMyYmZiZWM4OWEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjQzZWI4MmFlLThkOTAtNGNlZS1iMjMxLTVkMzJiZmJlYzg5YSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14136:1571,depend,dependency,1571,https://hail.is,https://github.com/hail-is/hail/pull/14136,2,['depend'],"['dependencies', 'dependency']"
Integrability,"0.1 (2022-02-11)</h1>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9608"">#9608</a>: Fix invalid importing of <code>importlib.readers</code> in Python 3.9.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9610"">#9610</a>: Restore [UnitTestFunction.obj]{.title-ref} to return unbound rather than bound method.; Fixes a crash during a failed teardown in unittest TestCases with non-default [__init__]{.title-ref}.; Regressed in pytest 7.0.0.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9636"">#9636</a>: The <code>pythonpath</code> plugin was renamed to <code>python_path</code>. This avoids a conflict with the <code>pytest-pythonpath</code> plugin.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9642"">#9642</a>: Fix running tests by id with <code>::</code> in the parametrize portion.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9643"">#9643</a>: Delay issuing a <code>~pytest.PytestWarning</code>{.interpreted-text role=&quot;class&quot;} about diamond inheritance involving <code>~pytest.Item</code>{.interpreted-text role=&quot;class&quot;} and; <code>~pytest.Collector</code>{.interpreted-text role=&quot;class&quot;} so it can be filtered using <code>standard warning filters &lt;warnings&gt;</code>{.interpreted-text role=&quot;ref&quot;}.</li>; </ul>; <h2>7.0.0</h2>; <h1>pytest 7.0.0 (2022-02-03)</h1>; <p>(<strong>Please see the full set of changes for this release also in the 7.0.0rc1 notes below</strong>)</p>; <h2>Deprecations</h2>; <ul>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9488"">#9488</a>: If custom subclasses of nodes like <code>pytest.Item</code>{.interpreted-text role=&quot;class&quot;} override the; <code>__init__</code> method, they should take <code>**kwargs</code>. See; <code>uncooperative-constructors-deprecated</code>{.in",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11516:1267,depend,dependabot,1267,https://hail.is,https://github.com/hail-is/hail/pull/11516,3,['depend'],['dependabot']
Integrability,"0.1 to 2.0.2.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pytest-dev/pytest-metadata/blob/master/CHANGES.rst"">pytest-metadata's changelog</a>.</em></p>; <blockquote>; <h2>2.0.2 (2022-07-15)</h2>; <ul>; <li>Allow all python versions above 3.7</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/6688a6f21c7bef1aaea5f8ac171be4a5df2eb527""><code>6688a6f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-metadata/issues/50"">#50</a> from BeyondEvil/release-v2.0.2</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/f0b5503452f922a84faa213224a4970c57d8a654""><code>f0b5503</code></a> Release v2.0.2</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/ff493afce81b1bbe7a2f866cd27510e5d9b8feef""><code>ff493af</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-metadata/issues/47"">#47</a> from pytest-dev/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/4591db1fa5546ff372ae95155caed99ce8dc4842""><code>4591db1</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/0414bb9f81cc1856ea021504eecd22d202462f1d""><code>0414bb9</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-metadata/issues/46"">#46</a> from pytest-dev/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/025be8999a22ae395b0e2b8ae4e7c9fa2334f874""><code>025be89</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/429840f4de26276560961929f21aab79ed305875""><code>429840f</code></a> Avoid running nightly on forks</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/c1968f396",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12188:1073,depend,dependabot,1073,https://hail.is,https://github.com/hail-is/hail/pull/12188,1,['depend'],['dependabot']
Integrability,"0.21.2 (September 4, 2021)</h3>; <p>Fixes and Functionality:</p>; <ul>; <li>Updating axios requests to be delayed by pre-emptive promise creation (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2702"">#2702</a>)</li>; <li>Adding &quot;synchronous&quot; and &quot;runWhen&quot; options to interceptors api (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2702"">#2702</a>)</li>; <li>Updating of transformResponse (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3377"">#3377</a>)</li>; <li>Adding ability to omit User-Agent header (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3703"">#3703</a>)</li>; <li>Adding multiple JSON improvements (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3688"">#3688</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3763"">#3763</a>)</li>; <li>Fixing quadratic runtime and extra memory usage when setting a maxContentLength (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3738"">#3738</a>)</li>; <li>Adding parseInt to config.timeout (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3781"">#3781</a>)</li>; <li>Adding custom return type support to interceptor (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3783"">#3783</a>)</li>; <li>Adding security fix for ReDoS vulnerability (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3980"">#3980</a>)</li>; </ul>; <p>Internal and Tests:</p>; <ul>; <li>Updating build dev dependancies (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3401"">#3401</a>)</li>; <li>Fixing builds running on Travis CI (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3538"">#3538</a>)</li>; <li>Updating follow rediect version (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3694"">#3694</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3771"">#3771</a>)</li>; <li>Updating karma sauce launcher to fix fai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:1248,depend,dependabot,1248,https://hail.is,https://github.com/hail-is/hail/pull/11080,4,['depend'],['dependabot']
