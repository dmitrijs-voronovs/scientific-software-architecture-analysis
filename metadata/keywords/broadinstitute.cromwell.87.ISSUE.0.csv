id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/broadinstitute/cromwell/pull/1:236,Usability,simpl,simply,236,"To see it in action, run as:. ```; java -jar target/scala-2.11/cromwell-0.1-SNAPSHOT.jar run src/main/resources/3step.wdl; ```. Also, as a note for now and the future, any changes to `WdlParser.java` should not be reviewed because it's simply generated code... The changes that cause that code to be generated are in the grammar file",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1
https://github.com/broadinstitute/cromwell/pull/14:144,Testability,test,tests,144,This is the implementation of the rest of the expression evaluator. Most of it is just semantics for how operators behave on their operands and tests of that.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/14
https://github.com/broadinstitute/cromwell/pull/16:33,Testability,test,tests,33,I'm aware that there are no unit tests and that there's some serious placeholder (e.g. there's no way to get a workflow's status). Putting this out here now to start iterating on comments sooner than later.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/16
https://github.com/broadinstitute/cromwell/pull/20:265,Deployability,update,updates,265,"This is green and actually does appear to work with a couple of mods to the three-step workflow, one to fake the `ps` for deterministic results, another to fix a bug in the wc command. But this seriously needs refactoring:; 1. Proper concurrency handling for store updates. The current code is awful, the mutable stores are just passed around the various concurrently executing actors. Probably the stores should be behind an actor which the CallActor and WorkflowActor would `ask` for queries or updates, and then compose a `pipeTo` with the `Future` response.; 2. While the potential parallelism of the cgrep and wc calls does appear to work as intended, the current test does not assert this.; 3. The call dependency determination only works for member access expressions and is kind of gross.; 4. The connection of inputs to outputs requires member access expressions and uses logic very much like point 3. Also the way outputs are copied to inputs in the symbol store seems clunky and wasteful; if the input expressions could be truly evaluated at call invocation it wouldn't be necessary to create copies of this data.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/20
https://github.com/broadinstitute/cromwell/pull/20:497,Deployability,update,updates,497,"This is green and actually does appear to work with a couple of mods to the three-step workflow, one to fake the `ps` for deterministic results, another to fix a bug in the wc command. But this seriously needs refactoring:; 1. Proper concurrency handling for store updates. The current code is awful, the mutable stores are just passed around the various concurrently executing actors. Probably the stores should be behind an actor which the CallActor and WorkflowActor would `ask` for queries or updates, and then compose a `pipeTo` with the `Future` response.; 2. While the potential parallelism of the cgrep and wc calls does appear to work as intended, the current test does not assert this.; 3. The call dependency determination only works for member access expressions and is kind of gross.; 4. The connection of inputs to outputs requires member access expressions and uses logic very much like point 3. Also the way outputs are copied to inputs in the symbol store seems clunky and wasteful; if the input expressions could be truly evaluated at call invocation it wouldn't be necessary to create copies of this data.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/20
https://github.com/broadinstitute/cromwell/pull/20:8,Energy Efficiency,green,green,8,"This is green and actually does appear to work with a couple of mods to the three-step workflow, one to fake the `ps` for deterministic results, another to fix a bug in the wc command. But this seriously needs refactoring:; 1. Proper concurrency handling for store updates. The current code is awful, the mutable stores are just passed around the various concurrently executing actors. Probably the stores should be behind an actor which the CallActor and WorkflowActor would `ask` for queries or updates, and then compose a `pipeTo` with the `Future` response.; 2. While the potential parallelism of the cgrep and wc calls does appear to work as intended, the current test does not assert this.; 3. The call dependency determination only works for member access expressions and is kind of gross.; 4. The connection of inputs to outputs requires member access expressions and uses logic very much like point 3. Also the way outputs are copied to inputs in the symbol store seems clunky and wasteful; if the input expressions could be truly evaluated at call invocation it wouldn't be necessary to create copies of this data.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/20
https://github.com/broadinstitute/cromwell/pull/20:709,Integrability,depend,dependency,709,"This is green and actually does appear to work with a couple of mods to the three-step workflow, one to fake the `ps` for deterministic results, another to fix a bug in the wc command. But this seriously needs refactoring:; 1. Proper concurrency handling for store updates. The current code is awful, the mutable stores are just passed around the various concurrently executing actors. Probably the stores should be behind an actor which the CallActor and WorkflowActor would `ask` for queries or updates, and then compose a `pipeTo` with the `Future` response.; 2. While the potential parallelism of the cgrep and wc calls does appear to work as intended, the current test does not assert this.; 3. The call dependency determination only works for member access expressions and is kind of gross.; 4. The connection of inputs to outputs requires member access expressions and uses logic very much like point 3. Also the way outputs are copied to inputs in the symbol store seems clunky and wasteful; if the input expressions could be truly evaluated at call invocation it wouldn't be necessary to create copies of this data.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/20
https://github.com/broadinstitute/cromwell/pull/20:210,Modifiability,refactor,refactoring,210,"This is green and actually does appear to work with a couple of mods to the three-step workflow, one to fake the `ps` for deterministic results, another to fix a bug in the wc command. But this seriously needs refactoring:; 1. Proper concurrency handling for store updates. The current code is awful, the mutable stores are just passed around the various concurrently executing actors. Probably the stores should be behind an actor which the CallActor and WorkflowActor would `ask` for queries or updates, and then compose a `pipeTo` with the `Future` response.; 2. While the potential parallelism of the cgrep and wc calls does appear to work as intended, the current test does not assert this.; 3. The call dependency determination only works for member access expressions and is kind of gross.; 4. The connection of inputs to outputs requires member access expressions and uses logic very much like point 3. Also the way outputs are copied to inputs in the symbol store seems clunky and wasteful; if the input expressions could be truly evaluated at call invocation it wouldn't be necessary to create copies of this data.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/20
https://github.com/broadinstitute/cromwell/pull/20:234,Performance,concurren,concurrency,234,"This is green and actually does appear to work with a couple of mods to the three-step workflow, one to fake the `ps` for deterministic results, another to fix a bug in the wc command. But this seriously needs refactoring:; 1. Proper concurrency handling for store updates. The current code is awful, the mutable stores are just passed around the various concurrently executing actors. Probably the stores should be behind an actor which the CallActor and WorkflowActor would `ask` for queries or updates, and then compose a `pipeTo` with the `Future` response.; 2. While the potential parallelism of the cgrep and wc calls does appear to work as intended, the current test does not assert this.; 3. The call dependency determination only works for member access expressions and is kind of gross.; 4. The connection of inputs to outputs requires member access expressions and uses logic very much like point 3. Also the way outputs are copied to inputs in the symbol store seems clunky and wasteful; if the input expressions could be truly evaluated at call invocation it wouldn't be necessary to create copies of this data.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/20
https://github.com/broadinstitute/cromwell/pull/20:355,Performance,concurren,concurrently,355,"This is green and actually does appear to work with a couple of mods to the three-step workflow, one to fake the `ps` for deterministic results, another to fix a bug in the wc command. But this seriously needs refactoring:; 1. Proper concurrency handling for store updates. The current code is awful, the mutable stores are just passed around the various concurrently executing actors. Probably the stores should be behind an actor which the CallActor and WorkflowActor would `ask` for queries or updates, and then compose a `pipeTo` with the `Future` response.; 2. While the potential parallelism of the cgrep and wc calls does appear to work as intended, the current test does not assert this.; 3. The call dependency determination only works for member access expressions and is kind of gross.; 4. The connection of inputs to outputs requires member access expressions and uses logic very much like point 3. Also the way outputs are copied to inputs in the symbol store seems clunky and wasteful; if the input expressions could be truly evaluated at call invocation it wouldn't be necessary to create copies of this data.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/20
https://github.com/broadinstitute/cromwell/pull/20:756,Security,access,access,756,"This is green and actually does appear to work with a couple of mods to the three-step workflow, one to fake the `ps` for deterministic results, another to fix a bug in the wc command. But this seriously needs refactoring:; 1. Proper concurrency handling for store updates. The current code is awful, the mutable stores are just passed around the various concurrently executing actors. Probably the stores should be behind an actor which the CallActor and WorkflowActor would `ask` for queries or updates, and then compose a `pipeTo` with the `Future` response.; 2. While the potential parallelism of the cgrep and wc calls does appear to work as intended, the current test does not assert this.; 3. The call dependency determination only works for member access expressions and is kind of gross.; 4. The connection of inputs to outputs requires member access expressions and uses logic very much like point 3. Also the way outputs are copied to inputs in the symbol store seems clunky and wasteful; if the input expressions could be truly evaluated at call invocation it wouldn't be necessary to create copies of this data.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/20
https://github.com/broadinstitute/cromwell/pull/20:853,Security,access,access,853,"This is green and actually does appear to work with a couple of mods to the three-step workflow, one to fake the `ps` for deterministic results, another to fix a bug in the wc command. But this seriously needs refactoring:; 1. Proper concurrency handling for store updates. The current code is awful, the mutable stores are just passed around the various concurrently executing actors. Probably the stores should be behind an actor which the CallActor and WorkflowActor would `ask` for queries or updates, and then compose a `pipeTo` with the `Future` response.; 2. While the potential parallelism of the cgrep and wc calls does appear to work as intended, the current test does not assert this.; 3. The call dependency determination only works for member access expressions and is kind of gross.; 4. The connection of inputs to outputs requires member access expressions and uses logic very much like point 3. Also the way outputs are copied to inputs in the symbol store seems clunky and wasteful; if the input expressions could be truly evaluated at call invocation it wouldn't be necessary to create copies of this data.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/20
https://github.com/broadinstitute/cromwell/pull/20:669,Testability,test,test,669,"This is green and actually does appear to work with a couple of mods to the three-step workflow, one to fake the `ps` for deterministic results, another to fix a bug in the wc command. But this seriously needs refactoring:; 1. Proper concurrency handling for store updates. The current code is awful, the mutable stores are just passed around the various concurrently executing actors. Probably the stores should be behind an actor which the CallActor and WorkflowActor would `ask` for queries or updates, and then compose a `pipeTo` with the `Future` response.; 2. While the potential parallelism of the cgrep and wc calls does appear to work as intended, the current test does not assert this.; 3. The call dependency determination only works for member access expressions and is kind of gross.; 4. The connection of inputs to outputs requires member access expressions and uses logic very much like point 3. Also the way outputs are copied to inputs in the symbol store seems clunky and wasteful; if the input expressions could be truly evaluated at call invocation it wouldn't be necessary to create copies of this data.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/20
https://github.com/broadinstitute/cromwell/pull/20:683,Testability,assert,assert,683,"This is green and actually does appear to work with a couple of mods to the three-step workflow, one to fake the `ps` for deterministic results, another to fix a bug in the wc command. But this seriously needs refactoring:; 1. Proper concurrency handling for store updates. The current code is awful, the mutable stores are just passed around the various concurrently executing actors. Probably the stores should be behind an actor which the CallActor and WorkflowActor would `ask` for queries or updates, and then compose a `pipeTo` with the `Future` response.; 2. While the potential parallelism of the cgrep and wc calls does appear to work as intended, the current test does not assert this.; 3. The call dependency determination only works for member access expressions and is kind of gross.; 4. The connection of inputs to outputs requires member access expressions and uses logic very much like point 3. Also the way outputs are copied to inputs in the symbol store seems clunky and wasteful; if the input expressions could be truly evaluated at call invocation it wouldn't be necessary to create copies of this data.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/20
https://github.com/broadinstitute/cromwell/pull/20:881,Testability,log,logic,881,"This is green and actually does appear to work with a couple of mods to the three-step workflow, one to fake the `ps` for deterministic results, another to fix a bug in the wc command. But this seriously needs refactoring:; 1. Proper concurrency handling for store updates. The current code is awful, the mutable stores are just passed around the various concurrently executing actors. Probably the stores should be behind an actor which the CallActor and WorkflowActor would `ask` for queries or updates, and then compose a `pipeTo` with the `Future` response.; 2. While the potential parallelism of the cgrep and wc calls does appear to work as intended, the current test does not assert this.; 3. The call dependency determination only works for member access expressions and is kind of gross.; 4. The connection of inputs to outputs requires member access expressions and uses logic very much like point 3. Also the way outputs are copied to inputs in the symbol store seems clunky and wasteful; if the input expressions could be truly evaluated at call invocation it wouldn't be necessary to create copies of this data.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/20
https://github.com/broadinstitute/cromwell/pull/24:9,Testability,test,tests,9,"… of the tests I commented out. @mcovarr @kcibul -> This is the start of an attempt to merge/finish the combination of Kristian's spray stuff with the workflow manager, plus fixing some of the tests I commented out earlier (whilst commenting out another one. I have to lower test coverage somehow!)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/24
https://github.com/broadinstitute/cromwell/pull/24:193,Testability,test,tests,193,"… of the tests I commented out. @mcovarr @kcibul -> This is the start of an attempt to merge/finish the combination of Kristian's spray stuff with the workflow manager, plus fixing some of the tests I commented out earlier (whilst commenting out another one. I have to lower test coverage somehow!)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/24
https://github.com/broadinstitute/cromwell/pull/24:275,Testability,test,test,275,"… of the tests I commented out. @mcovarr @kcibul -> This is the start of an attempt to merge/finish the combination of Kristian's spray stuff with the workflow manager, plus fixing some of the tests I commented out earlier (whilst commenting out another one. I have to lower test coverage somehow!)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/24
https://github.com/broadinstitute/cromwell/pull/40:1097,Modifiability,variab,variable,1097,"The high level overview:; 1. Rename `WdlBinding` to `WdlNamespace`; 2. Move AST specific functions into `AstTools`. In more detail:; 1. `WdlBinding` was feeling poorly named since the import statement was introduced. All of a sudden this object became recursive and started to really resemble how namespaces worked in WDL. And that's not on accident because the object structure is laid out exactly like the lexical structure of WDL. So naturally we would call ""the thing that holds workflows and tasks"" as a ""namespace"".; 2. The main entry point into the binding layer is the `WdlNamespace` object, in which users call `WdlNamespace.load(...)` with either String or File parameters. Client code now looks like this:. ``` scala; val namespace = WdlNamespace.load(new File(args(0))); namespace.workflows; namespace.namespaces; namespace.tasks; ```; 1. All `Ast => Workflow | Call | Task | ...` functions are in `class WdlNamespace`. All AST related tools are now in `AstTools` (things like `findAsts`, `terminalMap`). `object WdlNamespace` only contains various `load()` functions.; 2. Changed all variable references to 'binding' in any way to reference 'namespace' instead.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/40
https://github.com/broadinstitute/cromwell/pull/40:634,Performance,load,load,634,"The high level overview:; 1. Rename `WdlBinding` to `WdlNamespace`; 2. Move AST specific functions into `AstTools`. In more detail:; 1. `WdlBinding` was feeling poorly named since the import statement was introduced. All of a sudden this object became recursive and started to really resemble how namespaces worked in WDL. And that's not on accident because the object structure is laid out exactly like the lexical structure of WDL. So naturally we would call ""the thing that holds workflows and tasks"" as a ""namespace"".; 2. The main entry point into the binding layer is the `WdlNamespace` object, in which users call `WdlNamespace.load(...)` with either String or File parameters. Client code now looks like this:. ``` scala; val namespace = WdlNamespace.load(new File(args(0))); namespace.workflows; namespace.namespaces; namespace.tasks; ```; 1. All `Ast => Workflow | Call | Task | ...` functions are in `class WdlNamespace`. All AST related tools are now in `AstTools` (things like `findAsts`, `terminalMap`). `object WdlNamespace` only contains various `load()` functions.; 2. Changed all variable references to 'binding' in any way to reference 'namespace' instead.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/40
https://github.com/broadinstitute/cromwell/pull/40:758,Performance,load,load,758,"The high level overview:; 1. Rename `WdlBinding` to `WdlNamespace`; 2. Move AST specific functions into `AstTools`. In more detail:; 1. `WdlBinding` was feeling poorly named since the import statement was introduced. All of a sudden this object became recursive and started to really resemble how namespaces worked in WDL. And that's not on accident because the object structure is laid out exactly like the lexical structure of WDL. So naturally we would call ""the thing that holds workflows and tasks"" as a ""namespace"".; 2. The main entry point into the binding layer is the `WdlNamespace` object, in which users call `WdlNamespace.load(...)` with either String or File parameters. Client code now looks like this:. ``` scala; val namespace = WdlNamespace.load(new File(args(0))); namespace.workflows; namespace.namespaces; namespace.tasks; ```; 1. All `Ast => Workflow | Call | Task | ...` functions are in `class WdlNamespace`. All AST related tools are now in `AstTools` (things like `findAsts`, `terminalMap`). `object WdlNamespace` only contains various `load()` functions.; 2. Changed all variable references to 'binding' in any way to reference 'namespace' instead.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/40
https://github.com/broadinstitute/cromwell/pull/40:1062,Performance,load,load,1062,"The high level overview:; 1. Rename `WdlBinding` to `WdlNamespace`; 2. Move AST specific functions into `AstTools`. In more detail:; 1. `WdlBinding` was feeling poorly named since the import statement was introduced. All of a sudden this object became recursive and started to really resemble how namespaces worked in WDL. And that's not on accident because the object structure is laid out exactly like the lexical structure of WDL. So naturally we would call ""the thing that holds workflows and tasks"" as a ""namespace"".; 2. The main entry point into the binding layer is the `WdlNamespace` object, in which users call `WdlNamespace.load(...)` with either String or File parameters. Client code now looks like this:. ``` scala; val namespace = WdlNamespace.load(new File(args(0))); namespace.workflows; namespace.namespaces; namespace.tasks; ```; 1. All `Ast => Workflow | Call | Task | ...` functions are in `class WdlNamespace`. All AST related tools are now in `AstTools` (things like `findAsts`, `terminalMap`). `object WdlNamespace` only contains various `load()` functions.; 2. Changed all variable references to 'binding' in any way to reference 'namespace' instead.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/40
https://github.com/broadinstitute/cromwell/pull/44:911,Availability,ERROR,ERROR,911,"![screen shot 2015-06-14 at 8 36 19 am](https://cloud.githubusercontent.com/assets/58551/8148606/0f7b94f6-1273-11e5-8f6e-8fb7b23aa935.png). No rush to review this. This is ancillary to the sprint but it'd be nice if we could get it in by the end of the sprint. Changes:. 1) SLF4J logging hooked in with the actor system too. 2) Two modes of logging, set by the Java Property `CROMWELL_LOGGER=[SERVER|CONSOLE]`:; - In SERVER mode, it logs to a rolling file appender with all the bells and whistles. This will default to DEBUG level.; - In CONSOLE mode, there's code in `cromwell.logging` that handles these messages from SLF4J and prints them out to the console is as human-readable way as possible. I welcome comments about how to make it more readable. Though, if you are going to do that make sure you first run it so you can see the colors, which are an important aspect of this! CONSOLE logs on INFO, WARN, ERROR.; - The modes are toggled either by explicitly setting CROMWELL_LOGGER, or based on the CLI sub-command you chose: `server` will do SERVER logging and every other sub-command uses CONSOLE logging. 3) I've tried to establish some conventions for logging:; - INFO, WARN, ERROR is meant to be read by _users_ to debug their WDL executions. It should equally be helpful for _developers_ to debug many issues. We must keep in mind that these are also show up in the server logs so they could also help us add context to debugging an issue easier if we're used to these messages from the command line.; - Messages should contain the workflow UUID wherever appropriate. Anything that exists only in a context of a workflow execution: CallActors, WorkflowActors, SymbolStores, etc.; - Messages should be chosen to craft a story about how a workflow is progressing. Highlight the big points (something starts, something finishes, something is launched, symbol store entry is updated, etc)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/44
https://github.com/broadinstitute/cromwell/pull/44:1186,Availability,ERROR,ERROR,1186,"![screen shot 2015-06-14 at 8 36 19 am](https://cloud.githubusercontent.com/assets/58551/8148606/0f7b94f6-1273-11e5-8f6e-8fb7b23aa935.png). No rush to review this. This is ancillary to the sprint but it'd be nice if we could get it in by the end of the sprint. Changes:. 1) SLF4J logging hooked in with the actor system too. 2) Two modes of logging, set by the Java Property `CROMWELL_LOGGER=[SERVER|CONSOLE]`:; - In SERVER mode, it logs to a rolling file appender with all the bells and whistles. This will default to DEBUG level.; - In CONSOLE mode, there's code in `cromwell.logging` that handles these messages from SLF4J and prints them out to the console is as human-readable way as possible. I welcome comments about how to make it more readable. Though, if you are going to do that make sure you first run it so you can see the colors, which are an important aspect of this! CONSOLE logs on INFO, WARN, ERROR.; - The modes are toggled either by explicitly setting CROMWELL_LOGGER, or based on the CLI sub-command you chose: `server` will do SERVER logging and every other sub-command uses CONSOLE logging. 3) I've tried to establish some conventions for logging:; - INFO, WARN, ERROR is meant to be read by _users_ to debug their WDL executions. It should equally be helpful for _developers_ to debug many issues. We must keep in mind that these are also show up in the server logs so they could also help us add context to debugging an issue easier if we're used to these messages from the command line.; - Messages should contain the workflow UUID wherever appropriate. Anything that exists only in a context of a workflow execution: CallActors, WorkflowActors, SymbolStores, etc.; - Messages should be chosen to craft a story about how a workflow is progressing. Highlight the big points (something starts, something finishes, something is launched, symbol store entry is updated, etc)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/44
https://github.com/broadinstitute/cromwell/pull/44:443,Deployability,rolling,rolling,443,"![screen shot 2015-06-14 at 8 36 19 am](https://cloud.githubusercontent.com/assets/58551/8148606/0f7b94f6-1273-11e5-8f6e-8fb7b23aa935.png). No rush to review this. This is ancillary to the sprint but it'd be nice if we could get it in by the end of the sprint. Changes:. 1) SLF4J logging hooked in with the actor system too. 2) Two modes of logging, set by the Java Property `CROMWELL_LOGGER=[SERVER|CONSOLE]`:; - In SERVER mode, it logs to a rolling file appender with all the bells and whistles. This will default to DEBUG level.; - In CONSOLE mode, there's code in `cromwell.logging` that handles these messages from SLF4J and prints them out to the console is as human-readable way as possible. I welcome comments about how to make it more readable. Though, if you are going to do that make sure you first run it so you can see the colors, which are an important aspect of this! CONSOLE logs on INFO, WARN, ERROR.; - The modes are toggled either by explicitly setting CROMWELL_LOGGER, or based on the CLI sub-command you chose: `server` will do SERVER logging and every other sub-command uses CONSOLE logging. 3) I've tried to establish some conventions for logging:; - INFO, WARN, ERROR is meant to be read by _users_ to debug their WDL executions. It should equally be helpful for _developers_ to debug many issues. We must keep in mind that these are also show up in the server logs so they could also help us add context to debugging an issue easier if we're used to these messages from the command line.; - Messages should contain the workflow UUID wherever appropriate. Anything that exists only in a context of a workflow execution: CallActors, WorkflowActors, SymbolStores, etc.; - Messages should be chosen to craft a story about how a workflow is progressing. Highlight the big points (something starts, something finishes, something is launched, symbol store entry is updated, etc)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/44
https://github.com/broadinstitute/cromwell/pull/44:935,Deployability,toggle,toggled,935,"![screen shot 2015-06-14 at 8 36 19 am](https://cloud.githubusercontent.com/assets/58551/8148606/0f7b94f6-1273-11e5-8f6e-8fb7b23aa935.png). No rush to review this. This is ancillary to the sprint but it'd be nice if we could get it in by the end of the sprint. Changes:. 1) SLF4J logging hooked in with the actor system too. 2) Two modes of logging, set by the Java Property `CROMWELL_LOGGER=[SERVER|CONSOLE]`:; - In SERVER mode, it logs to a rolling file appender with all the bells and whistles. This will default to DEBUG level.; - In CONSOLE mode, there's code in `cromwell.logging` that handles these messages from SLF4J and prints them out to the console is as human-readable way as possible. I welcome comments about how to make it more readable. Though, if you are going to do that make sure you first run it so you can see the colors, which are an important aspect of this! CONSOLE logs on INFO, WARN, ERROR.; - The modes are toggled either by explicitly setting CROMWELL_LOGGER, or based on the CLI sub-command you chose: `server` will do SERVER logging and every other sub-command uses CONSOLE logging. 3) I've tried to establish some conventions for logging:; - INFO, WARN, ERROR is meant to be read by _users_ to debug their WDL executions. It should equally be helpful for _developers_ to debug many issues. We must keep in mind that these are also show up in the server logs so they could also help us add context to debugging an issue easier if we're used to these messages from the command line.; - Messages should contain the workflow UUID wherever appropriate. Anything that exists only in a context of a workflow execution: CallActors, WorkflowActors, SymbolStores, etc.; - Messages should be chosen to craft a story about how a workflow is progressing. Highlight the big points (something starts, something finishes, something is launched, symbol store entry is updated, etc)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/44
https://github.com/broadinstitute/cromwell/pull/44:1883,Deployability,update,updated,1883,"![screen shot 2015-06-14 at 8 36 19 am](https://cloud.githubusercontent.com/assets/58551/8148606/0f7b94f6-1273-11e5-8f6e-8fb7b23aa935.png). No rush to review this. This is ancillary to the sprint but it'd be nice if we could get it in by the end of the sprint. Changes:. 1) SLF4J logging hooked in with the actor system too. 2) Two modes of logging, set by the Java Property `CROMWELL_LOGGER=[SERVER|CONSOLE]`:; - In SERVER mode, it logs to a rolling file appender with all the bells and whistles. This will default to DEBUG level.; - In CONSOLE mode, there's code in `cromwell.logging` that handles these messages from SLF4J and prints them out to the console is as human-readable way as possible. I welcome comments about how to make it more readable. Though, if you are going to do that make sure you first run it so you can see the colors, which are an important aspect of this! CONSOLE logs on INFO, WARN, ERROR.; - The modes are toggled either by explicitly setting CROMWELL_LOGGER, or based on the CLI sub-command you chose: `server` will do SERVER logging and every other sub-command uses CONSOLE logging. 3) I've tried to establish some conventions for logging:; - INFO, WARN, ERROR is meant to be read by _users_ to debug their WDL executions. It should equally be helpful for _developers_ to debug many issues. We must keep in mind that these are also show up in the server logs so they could also help us add context to debugging an issue easier if we're used to these messages from the command line.; - Messages should contain the workflow UUID wherever appropriate. Anything that exists only in a context of a workflow execution: CallActors, WorkflowActors, SymbolStores, etc.; - Messages should be chosen to craft a story about how a workflow is progressing. Highlight the big points (something starts, something finishes, something is launched, symbol store entry is updated, etc)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/44
https://github.com/broadinstitute/cromwell/pull/44:606,Integrability,message,messages,606,"![screen shot 2015-06-14 at 8 36 19 am](https://cloud.githubusercontent.com/assets/58551/8148606/0f7b94f6-1273-11e5-8f6e-8fb7b23aa935.png). No rush to review this. This is ancillary to the sprint but it'd be nice if we could get it in by the end of the sprint. Changes:. 1) SLF4J logging hooked in with the actor system too. 2) Two modes of logging, set by the Java Property `CROMWELL_LOGGER=[SERVER|CONSOLE]`:; - In SERVER mode, it logs to a rolling file appender with all the bells and whistles. This will default to DEBUG level.; - In CONSOLE mode, there's code in `cromwell.logging` that handles these messages from SLF4J and prints them out to the console is as human-readable way as possible. I welcome comments about how to make it more readable. Though, if you are going to do that make sure you first run it so you can see the colors, which are an important aspect of this! CONSOLE logs on INFO, WARN, ERROR.; - The modes are toggled either by explicitly setting CROMWELL_LOGGER, or based on the CLI sub-command you chose: `server` will do SERVER logging and every other sub-command uses CONSOLE logging. 3) I've tried to establish some conventions for logging:; - INFO, WARN, ERROR is meant to be read by _users_ to debug their WDL executions. It should equally be helpful for _developers_ to debug many issues. We must keep in mind that these are also show up in the server logs so they could also help us add context to debugging an issue easier if we're used to these messages from the command line.; - Messages should contain the workflow UUID wherever appropriate. Anything that exists only in a context of a workflow execution: CallActors, WorkflowActors, SymbolStores, etc.; - Messages should be chosen to craft a story about how a workflow is progressing. Highlight the big points (something starts, something finishes, something is launched, symbol store entry is updated, etc)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/44
https://github.com/broadinstitute/cromwell/pull/44:1481,Integrability,message,messages,1481,"![screen shot 2015-06-14 at 8 36 19 am](https://cloud.githubusercontent.com/assets/58551/8148606/0f7b94f6-1273-11e5-8f6e-8fb7b23aa935.png). No rush to review this. This is ancillary to the sprint but it'd be nice if we could get it in by the end of the sprint. Changes:. 1) SLF4J logging hooked in with the actor system too. 2) Two modes of logging, set by the Java Property `CROMWELL_LOGGER=[SERVER|CONSOLE]`:; - In SERVER mode, it logs to a rolling file appender with all the bells and whistles. This will default to DEBUG level.; - In CONSOLE mode, there's code in `cromwell.logging` that handles these messages from SLF4J and prints them out to the console is as human-readable way as possible. I welcome comments about how to make it more readable. Though, if you are going to do that make sure you first run it so you can see the colors, which are an important aspect of this! CONSOLE logs on INFO, WARN, ERROR.; - The modes are toggled either by explicitly setting CROMWELL_LOGGER, or based on the CLI sub-command you chose: `server` will do SERVER logging and every other sub-command uses CONSOLE logging. 3) I've tried to establish some conventions for logging:; - INFO, WARN, ERROR is meant to be read by _users_ to debug their WDL executions. It should equally be helpful for _developers_ to debug many issues. We must keep in mind that these are also show up in the server logs so they could also help us add context to debugging an issue easier if we're used to these messages from the command line.; - Messages should contain the workflow UUID wherever appropriate. Anything that exists only in a context of a workflow execution: CallActors, WorkflowActors, SymbolStores, etc.; - Messages should be chosen to craft a story about how a workflow is progressing. Highlight the big points (something starts, something finishes, something is launched, symbol store entry is updated, etc)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/44
https://github.com/broadinstitute/cromwell/pull/44:1516,Integrability,Message,Messages,1516,"![screen shot 2015-06-14 at 8 36 19 am](https://cloud.githubusercontent.com/assets/58551/8148606/0f7b94f6-1273-11e5-8f6e-8fb7b23aa935.png). No rush to review this. This is ancillary to the sprint but it'd be nice if we could get it in by the end of the sprint. Changes:. 1) SLF4J logging hooked in with the actor system too. 2) Two modes of logging, set by the Java Property `CROMWELL_LOGGER=[SERVER|CONSOLE]`:; - In SERVER mode, it logs to a rolling file appender with all the bells and whistles. This will default to DEBUG level.; - In CONSOLE mode, there's code in `cromwell.logging` that handles these messages from SLF4J and prints them out to the console is as human-readable way as possible. I welcome comments about how to make it more readable. Though, if you are going to do that make sure you first run it so you can see the colors, which are an important aspect of this! CONSOLE logs on INFO, WARN, ERROR.; - The modes are toggled either by explicitly setting CROMWELL_LOGGER, or based on the CLI sub-command you chose: `server` will do SERVER logging and every other sub-command uses CONSOLE logging. 3) I've tried to establish some conventions for logging:; - INFO, WARN, ERROR is meant to be read by _users_ to debug their WDL executions. It should equally be helpful for _developers_ to debug many issues. We must keep in mind that these are also show up in the server logs so they could also help us add context to debugging an issue easier if we're used to these messages from the command line.; - Messages should contain the workflow UUID wherever appropriate. Anything that exists only in a context of a workflow execution: CallActors, WorkflowActors, SymbolStores, etc.; - Messages should be chosen to craft a story about how a workflow is progressing. Highlight the big points (something starts, something finishes, something is launched, symbol store entry is updated, etc)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/44
https://github.com/broadinstitute/cromwell/pull/44:1694,Integrability,Message,Messages,1694,"![screen shot 2015-06-14 at 8 36 19 am](https://cloud.githubusercontent.com/assets/58551/8148606/0f7b94f6-1273-11e5-8f6e-8fb7b23aa935.png). No rush to review this. This is ancillary to the sprint but it'd be nice if we could get it in by the end of the sprint. Changes:. 1) SLF4J logging hooked in with the actor system too. 2) Two modes of logging, set by the Java Property `CROMWELL_LOGGER=[SERVER|CONSOLE]`:; - In SERVER mode, it logs to a rolling file appender with all the bells and whistles. This will default to DEBUG level.; - In CONSOLE mode, there's code in `cromwell.logging` that handles these messages from SLF4J and prints them out to the console is as human-readable way as possible. I welcome comments about how to make it more readable. Though, if you are going to do that make sure you first run it so you can see the colors, which are an important aspect of this! CONSOLE logs on INFO, WARN, ERROR.; - The modes are toggled either by explicitly setting CROMWELL_LOGGER, or based on the CLI sub-command you chose: `server` will do SERVER logging and every other sub-command uses CONSOLE logging. 3) I've tried to establish some conventions for logging:; - INFO, WARN, ERROR is meant to be read by _users_ to debug their WDL executions. It should equally be helpful for _developers_ to debug many issues. We must keep in mind that these are also show up in the server logs so they could also help us add context to debugging an issue easier if we're used to these messages from the command line.; - Messages should contain the workflow UUID wherever appropriate. Anything that exists only in a context of a workflow execution: CallActors, WorkflowActors, SymbolStores, etc.; - Messages should be chosen to craft a story about how a workflow is progressing. Highlight the big points (something starts, something finishes, something is launched, symbol store entry is updated, etc)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/44
https://github.com/broadinstitute/cromwell/pull/44:280,Testability,log,logging,280,"![screen shot 2015-06-14 at 8 36 19 am](https://cloud.githubusercontent.com/assets/58551/8148606/0f7b94f6-1273-11e5-8f6e-8fb7b23aa935.png). No rush to review this. This is ancillary to the sprint but it'd be nice if we could get it in by the end of the sprint. Changes:. 1) SLF4J logging hooked in with the actor system too. 2) Two modes of logging, set by the Java Property `CROMWELL_LOGGER=[SERVER|CONSOLE]`:; - In SERVER mode, it logs to a rolling file appender with all the bells and whistles. This will default to DEBUG level.; - In CONSOLE mode, there's code in `cromwell.logging` that handles these messages from SLF4J and prints them out to the console is as human-readable way as possible. I welcome comments about how to make it more readable. Though, if you are going to do that make sure you first run it so you can see the colors, which are an important aspect of this! CONSOLE logs on INFO, WARN, ERROR.; - The modes are toggled either by explicitly setting CROMWELL_LOGGER, or based on the CLI sub-command you chose: `server` will do SERVER logging and every other sub-command uses CONSOLE logging. 3) I've tried to establish some conventions for logging:; - INFO, WARN, ERROR is meant to be read by _users_ to debug their WDL executions. It should equally be helpful for _developers_ to debug many issues. We must keep in mind that these are also show up in the server logs so they could also help us add context to debugging an issue easier if we're used to these messages from the command line.; - Messages should contain the workflow UUID wherever appropriate. Anything that exists only in a context of a workflow execution: CallActors, WorkflowActors, SymbolStores, etc.; - Messages should be chosen to craft a story about how a workflow is progressing. Highlight the big points (something starts, something finishes, something is launched, symbol store entry is updated, etc)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/44
https://github.com/broadinstitute/cromwell/pull/44:341,Testability,log,logging,341,"![screen shot 2015-06-14 at 8 36 19 am](https://cloud.githubusercontent.com/assets/58551/8148606/0f7b94f6-1273-11e5-8f6e-8fb7b23aa935.png). No rush to review this. This is ancillary to the sprint but it'd be nice if we could get it in by the end of the sprint. Changes:. 1) SLF4J logging hooked in with the actor system too. 2) Two modes of logging, set by the Java Property `CROMWELL_LOGGER=[SERVER|CONSOLE]`:; - In SERVER mode, it logs to a rolling file appender with all the bells and whistles. This will default to DEBUG level.; - In CONSOLE mode, there's code in `cromwell.logging` that handles these messages from SLF4J and prints them out to the console is as human-readable way as possible. I welcome comments about how to make it more readable. Though, if you are going to do that make sure you first run it so you can see the colors, which are an important aspect of this! CONSOLE logs on INFO, WARN, ERROR.; - The modes are toggled either by explicitly setting CROMWELL_LOGGER, or based on the CLI sub-command you chose: `server` will do SERVER logging and every other sub-command uses CONSOLE logging. 3) I've tried to establish some conventions for logging:; - INFO, WARN, ERROR is meant to be read by _users_ to debug their WDL executions. It should equally be helpful for _developers_ to debug many issues. We must keep in mind that these are also show up in the server logs so they could also help us add context to debugging an issue easier if we're used to these messages from the command line.; - Messages should contain the workflow UUID wherever appropriate. Anything that exists only in a context of a workflow execution: CallActors, WorkflowActors, SymbolStores, etc.; - Messages should be chosen to craft a story about how a workflow is progressing. Highlight the big points (something starts, something finishes, something is launched, symbol store entry is updated, etc)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/44
https://github.com/broadinstitute/cromwell/pull/44:433,Testability,log,logs,433,"![screen shot 2015-06-14 at 8 36 19 am](https://cloud.githubusercontent.com/assets/58551/8148606/0f7b94f6-1273-11e5-8f6e-8fb7b23aa935.png). No rush to review this. This is ancillary to the sprint but it'd be nice if we could get it in by the end of the sprint. Changes:. 1) SLF4J logging hooked in with the actor system too. 2) Two modes of logging, set by the Java Property `CROMWELL_LOGGER=[SERVER|CONSOLE]`:; - In SERVER mode, it logs to a rolling file appender with all the bells and whistles. This will default to DEBUG level.; - In CONSOLE mode, there's code in `cromwell.logging` that handles these messages from SLF4J and prints them out to the console is as human-readable way as possible. I welcome comments about how to make it more readable. Though, if you are going to do that make sure you first run it so you can see the colors, which are an important aspect of this! CONSOLE logs on INFO, WARN, ERROR.; - The modes are toggled either by explicitly setting CROMWELL_LOGGER, or based on the CLI sub-command you chose: `server` will do SERVER logging and every other sub-command uses CONSOLE logging. 3) I've tried to establish some conventions for logging:; - INFO, WARN, ERROR is meant to be read by _users_ to debug their WDL executions. It should equally be helpful for _developers_ to debug many issues. We must keep in mind that these are also show up in the server logs so they could also help us add context to debugging an issue easier if we're used to these messages from the command line.; - Messages should contain the workflow UUID wherever appropriate. Anything that exists only in a context of a workflow execution: CallActors, WorkflowActors, SymbolStores, etc.; - Messages should be chosen to craft a story about how a workflow is progressing. Highlight the big points (something starts, something finishes, something is launched, symbol store entry is updated, etc)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/44
https://github.com/broadinstitute/cromwell/pull/44:578,Testability,log,logging,578,"![screen shot 2015-06-14 at 8 36 19 am](https://cloud.githubusercontent.com/assets/58551/8148606/0f7b94f6-1273-11e5-8f6e-8fb7b23aa935.png). No rush to review this. This is ancillary to the sprint but it'd be nice if we could get it in by the end of the sprint. Changes:. 1) SLF4J logging hooked in with the actor system too. 2) Two modes of logging, set by the Java Property `CROMWELL_LOGGER=[SERVER|CONSOLE]`:; - In SERVER mode, it logs to a rolling file appender with all the bells and whistles. This will default to DEBUG level.; - In CONSOLE mode, there's code in `cromwell.logging` that handles these messages from SLF4J and prints them out to the console is as human-readable way as possible. I welcome comments about how to make it more readable. Though, if you are going to do that make sure you first run it so you can see the colors, which are an important aspect of this! CONSOLE logs on INFO, WARN, ERROR.; - The modes are toggled either by explicitly setting CROMWELL_LOGGER, or based on the CLI sub-command you chose: `server` will do SERVER logging and every other sub-command uses CONSOLE logging. 3) I've tried to establish some conventions for logging:; - INFO, WARN, ERROR is meant to be read by _users_ to debug their WDL executions. It should equally be helpful for _developers_ to debug many issues. We must keep in mind that these are also show up in the server logs so they could also help us add context to debugging an issue easier if we're used to these messages from the command line.; - Messages should contain the workflow UUID wherever appropriate. Anything that exists only in a context of a workflow execution: CallActors, WorkflowActors, SymbolStores, etc.; - Messages should be chosen to craft a story about how a workflow is progressing. Highlight the big points (something starts, something finishes, something is launched, symbol store entry is updated, etc)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/44
https://github.com/broadinstitute/cromwell/pull/44:891,Testability,log,logs,891,"![screen shot 2015-06-14 at 8 36 19 am](https://cloud.githubusercontent.com/assets/58551/8148606/0f7b94f6-1273-11e5-8f6e-8fb7b23aa935.png). No rush to review this. This is ancillary to the sprint but it'd be nice if we could get it in by the end of the sprint. Changes:. 1) SLF4J logging hooked in with the actor system too. 2) Two modes of logging, set by the Java Property `CROMWELL_LOGGER=[SERVER|CONSOLE]`:; - In SERVER mode, it logs to a rolling file appender with all the bells and whistles. This will default to DEBUG level.; - In CONSOLE mode, there's code in `cromwell.logging` that handles these messages from SLF4J and prints them out to the console is as human-readable way as possible. I welcome comments about how to make it more readable. Though, if you are going to do that make sure you first run it so you can see the colors, which are an important aspect of this! CONSOLE logs on INFO, WARN, ERROR.; - The modes are toggled either by explicitly setting CROMWELL_LOGGER, or based on the CLI sub-command you chose: `server` will do SERVER logging and every other sub-command uses CONSOLE logging. 3) I've tried to establish some conventions for logging:; - INFO, WARN, ERROR is meant to be read by _users_ to debug their WDL executions. It should equally be helpful for _developers_ to debug many issues. We must keep in mind that these are also show up in the server logs so they could also help us add context to debugging an issue easier if we're used to these messages from the command line.; - Messages should contain the workflow UUID wherever appropriate. Anything that exists only in a context of a workflow execution: CallActors, WorkflowActors, SymbolStores, etc.; - Messages should be chosen to craft a story about how a workflow is progressing. Highlight the big points (something starts, something finishes, something is launched, symbol store entry is updated, etc)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/44
https://github.com/broadinstitute/cromwell/pull/44:1056,Testability,log,logging,1056,"![screen shot 2015-06-14 at 8 36 19 am](https://cloud.githubusercontent.com/assets/58551/8148606/0f7b94f6-1273-11e5-8f6e-8fb7b23aa935.png). No rush to review this. This is ancillary to the sprint but it'd be nice if we could get it in by the end of the sprint. Changes:. 1) SLF4J logging hooked in with the actor system too. 2) Two modes of logging, set by the Java Property `CROMWELL_LOGGER=[SERVER|CONSOLE]`:; - In SERVER mode, it logs to a rolling file appender with all the bells and whistles. This will default to DEBUG level.; - In CONSOLE mode, there's code in `cromwell.logging` that handles these messages from SLF4J and prints them out to the console is as human-readable way as possible. I welcome comments about how to make it more readable. Though, if you are going to do that make sure you first run it so you can see the colors, which are an important aspect of this! CONSOLE logs on INFO, WARN, ERROR.; - The modes are toggled either by explicitly setting CROMWELL_LOGGER, or based on the CLI sub-command you chose: `server` will do SERVER logging and every other sub-command uses CONSOLE logging. 3) I've tried to establish some conventions for logging:; - INFO, WARN, ERROR is meant to be read by _users_ to debug their WDL executions. It should equally be helpful for _developers_ to debug many issues. We must keep in mind that these are also show up in the server logs so they could also help us add context to debugging an issue easier if we're used to these messages from the command line.; - Messages should contain the workflow UUID wherever appropriate. Anything that exists only in a context of a workflow execution: CallActors, WorkflowActors, SymbolStores, etc.; - Messages should be chosen to craft a story about how a workflow is progressing. Highlight the big points (something starts, something finishes, something is launched, symbol store entry is updated, etc)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/44
https://github.com/broadinstitute/cromwell/pull/44:1105,Testability,log,logging,1105,"![screen shot 2015-06-14 at 8 36 19 am](https://cloud.githubusercontent.com/assets/58551/8148606/0f7b94f6-1273-11e5-8f6e-8fb7b23aa935.png). No rush to review this. This is ancillary to the sprint but it'd be nice if we could get it in by the end of the sprint. Changes:. 1) SLF4J logging hooked in with the actor system too. 2) Two modes of logging, set by the Java Property `CROMWELL_LOGGER=[SERVER|CONSOLE]`:; - In SERVER mode, it logs to a rolling file appender with all the bells and whistles. This will default to DEBUG level.; - In CONSOLE mode, there's code in `cromwell.logging` that handles these messages from SLF4J and prints them out to the console is as human-readable way as possible. I welcome comments about how to make it more readable. Though, if you are going to do that make sure you first run it so you can see the colors, which are an important aspect of this! CONSOLE logs on INFO, WARN, ERROR.; - The modes are toggled either by explicitly setting CROMWELL_LOGGER, or based on the CLI sub-command you chose: `server` will do SERVER logging and every other sub-command uses CONSOLE logging. 3) I've tried to establish some conventions for logging:; - INFO, WARN, ERROR is meant to be read by _users_ to debug their WDL executions. It should equally be helpful for _developers_ to debug many issues. We must keep in mind that these are also show up in the server logs so they could also help us add context to debugging an issue easier if we're used to these messages from the command line.; - Messages should contain the workflow UUID wherever appropriate. Anything that exists only in a context of a workflow execution: CallActors, WorkflowActors, SymbolStores, etc.; - Messages should be chosen to craft a story about how a workflow is progressing. Highlight the big points (something starts, something finishes, something is launched, symbol store entry is updated, etc)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/44
https://github.com/broadinstitute/cromwell/pull/44:1162,Testability,log,logging,1162,"![screen shot 2015-06-14 at 8 36 19 am](https://cloud.githubusercontent.com/assets/58551/8148606/0f7b94f6-1273-11e5-8f6e-8fb7b23aa935.png). No rush to review this. This is ancillary to the sprint but it'd be nice if we could get it in by the end of the sprint. Changes:. 1) SLF4J logging hooked in with the actor system too. 2) Two modes of logging, set by the Java Property `CROMWELL_LOGGER=[SERVER|CONSOLE]`:; - In SERVER mode, it logs to a rolling file appender with all the bells and whistles. This will default to DEBUG level.; - In CONSOLE mode, there's code in `cromwell.logging` that handles these messages from SLF4J and prints them out to the console is as human-readable way as possible. I welcome comments about how to make it more readable. Though, if you are going to do that make sure you first run it so you can see the colors, which are an important aspect of this! CONSOLE logs on INFO, WARN, ERROR.; - The modes are toggled either by explicitly setting CROMWELL_LOGGER, or based on the CLI sub-command you chose: `server` will do SERVER logging and every other sub-command uses CONSOLE logging. 3) I've tried to establish some conventions for logging:; - INFO, WARN, ERROR is meant to be read by _users_ to debug their WDL executions. It should equally be helpful for _developers_ to debug many issues. We must keep in mind that these are also show up in the server logs so they could also help us add context to debugging an issue easier if we're used to these messages from the command line.; - Messages should contain the workflow UUID wherever appropriate. Anything that exists only in a context of a workflow execution: CallActors, WorkflowActors, SymbolStores, etc.; - Messages should be chosen to craft a story about how a workflow is progressing. Highlight the big points (something starts, something finishes, something is launched, symbol store entry is updated, etc)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/44
https://github.com/broadinstitute/cromwell/pull/44:1385,Testability,log,logs,1385,"![screen shot 2015-06-14 at 8 36 19 am](https://cloud.githubusercontent.com/assets/58551/8148606/0f7b94f6-1273-11e5-8f6e-8fb7b23aa935.png). No rush to review this. This is ancillary to the sprint but it'd be nice if we could get it in by the end of the sprint. Changes:. 1) SLF4J logging hooked in with the actor system too. 2) Two modes of logging, set by the Java Property `CROMWELL_LOGGER=[SERVER|CONSOLE]`:; - In SERVER mode, it logs to a rolling file appender with all the bells and whistles. This will default to DEBUG level.; - In CONSOLE mode, there's code in `cromwell.logging` that handles these messages from SLF4J and prints them out to the console is as human-readable way as possible. I welcome comments about how to make it more readable. Though, if you are going to do that make sure you first run it so you can see the colors, which are an important aspect of this! CONSOLE logs on INFO, WARN, ERROR.; - The modes are toggled either by explicitly setting CROMWELL_LOGGER, or based on the CLI sub-command you chose: `server` will do SERVER logging and every other sub-command uses CONSOLE logging. 3) I've tried to establish some conventions for logging:; - INFO, WARN, ERROR is meant to be read by _users_ to debug their WDL executions. It should equally be helpful for _developers_ to debug many issues. We must keep in mind that these are also show up in the server logs so they could also help us add context to debugging an issue easier if we're used to these messages from the command line.; - Messages should contain the workflow UUID wherever appropriate. Anything that exists only in a context of a workflow execution: CallActors, WorkflowActors, SymbolStores, etc.; - Messages should be chosen to craft a story about how a workflow is progressing. Highlight the big points (something starts, something finishes, something is launched, symbol store entry is updated, etc)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/44
https://github.com/broadinstitute/cromwell/pull/48:1,Testability,test,test,1,…test',MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/48
https://github.com/broadinstitute/cromwell/pull/51:169,Modifiability,variab,variable,169,"Adding the following features:; - Optional parameters; - Expressions in output strings (e.g. an output file that's named as some function of the inputs); - Command line variable quantifiers (`*`, `?`, `+`); - Command line variable attributes (e.g. `${sep="", "" String stuff+}`), also default values for parameters.; - Command line variable prefixes (e.g. `${""-maxdepth "" maxdepth?}`); - `tsv()` function; - Declarations at the workflow and task level; - Array and Map data types",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/51
https://github.com/broadinstitute/cromwell/pull/51:222,Modifiability,variab,variable,222,"Adding the following features:; - Optional parameters; - Expressions in output strings (e.g. an output file that's named as some function of the inputs); - Command line variable quantifiers (`*`, `?`, `+`); - Command line variable attributes (e.g. `${sep="", "" String stuff+}`), also default values for parameters.; - Command line variable prefixes (e.g. `${""-maxdepth "" maxdepth?}`); - `tsv()` function; - Declarations at the workflow and task level; - Array and Map data types",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/51
https://github.com/broadinstitute/cromwell/pull/51:330,Modifiability,variab,variable,330,"Adding the following features:; - Optional parameters; - Expressions in output strings (e.g. an output file that's named as some function of the inputs); - Command line variable quantifiers (`*`, `?`, `+`); - Command line variable attributes (e.g. `${sep="", "" String stuff+}`), also default values for parameters.; - Command line variable prefixes (e.g. `${""-maxdepth "" maxdepth?}`); - `tsv()` function; - Declarations at the workflow and task level; - Array and Map data types",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/51
https://github.com/broadinstitute/cromwell/pull/64:673,Availability,down,down,673,"DO NOT MERGE YET!. Hopefully a final-ish version of the DataAccess API to unblock its implementation in Slick. . RIP StoreActor, SymbolStore, and ExecutionStore. The spirit of ExecutionStore lives on in WorkflowActor, and maybe SymbolStore might find a place there too to rid us of some Await.result()s. StoreActor is dead for real. . Known issues:. FIXED ~~1) The Docker test is broken because the backend-specific initialization was accidentally refactored away. Shouldn't be a big deal to restore that.~~; 2) All other tests pass, but that might just be because the restart test stinks. There are worrisome messages being emitted from that test which need to be tracked down and have assertions put on them. It might also be a good idea to test restarting a workflow more complex than ""Hello World"".; 3) No persistence of BackendInfo yet, shouldn't be tough but that needs a bit of discussion.; 4) More Await.results() in WorkflowActor than I would like or are probably necessary. This could be a separate Tech Debt issue. At least DataAccess is fully async.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/64
https://github.com/broadinstitute/cromwell/pull/64:610,Integrability,message,messages,610,"DO NOT MERGE YET!. Hopefully a final-ish version of the DataAccess API to unblock its implementation in Slick. . RIP StoreActor, SymbolStore, and ExecutionStore. The spirit of ExecutionStore lives on in WorkflowActor, and maybe SymbolStore might find a place there too to rid us of some Await.result()s. StoreActor is dead for real. . Known issues:. FIXED ~~1) The Docker test is broken because the backend-specific initialization was accidentally refactored away. Shouldn't be a big deal to restore that.~~; 2) All other tests pass, but that might just be because the restart test stinks. There are worrisome messages being emitted from that test which need to be tracked down and have assertions put on them. It might also be a good idea to test restarting a workflow more complex than ""Hello World"".; 3) No persistence of BackendInfo yet, shouldn't be tough but that needs a bit of discussion.; 4) More Await.results() in WorkflowActor than I would like or are probably necessary. This could be a separate Tech Debt issue. At least DataAccess is fully async.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/64
https://github.com/broadinstitute/cromwell/pull/64:448,Modifiability,refactor,refactored,448,"DO NOT MERGE YET!. Hopefully a final-ish version of the DataAccess API to unblock its implementation in Slick. . RIP StoreActor, SymbolStore, and ExecutionStore. The spirit of ExecutionStore lives on in WorkflowActor, and maybe SymbolStore might find a place there too to rid us of some Await.result()s. StoreActor is dead for real. . Known issues:. FIXED ~~1) The Docker test is broken because the backend-specific initialization was accidentally refactored away. Shouldn't be a big deal to restore that.~~; 2) All other tests pass, but that might just be because the restart test stinks. There are worrisome messages being emitted from that test which need to be tracked down and have assertions put on them. It might also be a good idea to test restarting a workflow more complex than ""Hello World"".; 3) No persistence of BackendInfo yet, shouldn't be tough but that needs a bit of discussion.; 4) More Await.results() in WorkflowActor than I would like or are probably necessary. This could be a separate Tech Debt issue. At least DataAccess is fully async.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/64
https://github.com/broadinstitute/cromwell/pull/64:372,Testability,test,test,372,"DO NOT MERGE YET!. Hopefully a final-ish version of the DataAccess API to unblock its implementation in Slick. . RIP StoreActor, SymbolStore, and ExecutionStore. The spirit of ExecutionStore lives on in WorkflowActor, and maybe SymbolStore might find a place there too to rid us of some Await.result()s. StoreActor is dead for real. . Known issues:. FIXED ~~1) The Docker test is broken because the backend-specific initialization was accidentally refactored away. Shouldn't be a big deal to restore that.~~; 2) All other tests pass, but that might just be because the restart test stinks. There are worrisome messages being emitted from that test which need to be tracked down and have assertions put on them. It might also be a good idea to test restarting a workflow more complex than ""Hello World"".; 3) No persistence of BackendInfo yet, shouldn't be tough but that needs a bit of discussion.; 4) More Await.results() in WorkflowActor than I would like or are probably necessary. This could be a separate Tech Debt issue. At least DataAccess is fully async.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/64
https://github.com/broadinstitute/cromwell/pull/64:522,Testability,test,tests,522,"DO NOT MERGE YET!. Hopefully a final-ish version of the DataAccess API to unblock its implementation in Slick. . RIP StoreActor, SymbolStore, and ExecutionStore. The spirit of ExecutionStore lives on in WorkflowActor, and maybe SymbolStore might find a place there too to rid us of some Await.result()s. StoreActor is dead for real. . Known issues:. FIXED ~~1) The Docker test is broken because the backend-specific initialization was accidentally refactored away. Shouldn't be a big deal to restore that.~~; 2) All other tests pass, but that might just be because the restart test stinks. There are worrisome messages being emitted from that test which need to be tracked down and have assertions put on them. It might also be a good idea to test restarting a workflow more complex than ""Hello World"".; 3) No persistence of BackendInfo yet, shouldn't be tough but that needs a bit of discussion.; 4) More Await.results() in WorkflowActor than I would like or are probably necessary. This could be a separate Tech Debt issue. At least DataAccess is fully async.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/64
https://github.com/broadinstitute/cromwell/pull/64:577,Testability,test,test,577,"DO NOT MERGE YET!. Hopefully a final-ish version of the DataAccess API to unblock its implementation in Slick. . RIP StoreActor, SymbolStore, and ExecutionStore. The spirit of ExecutionStore lives on in WorkflowActor, and maybe SymbolStore might find a place there too to rid us of some Await.result()s. StoreActor is dead for real. . Known issues:. FIXED ~~1) The Docker test is broken because the backend-specific initialization was accidentally refactored away. Shouldn't be a big deal to restore that.~~; 2) All other tests pass, but that might just be because the restart test stinks. There are worrisome messages being emitted from that test which need to be tracked down and have assertions put on them. It might also be a good idea to test restarting a workflow more complex than ""Hello World"".; 3) No persistence of BackendInfo yet, shouldn't be tough but that needs a bit of discussion.; 4) More Await.results() in WorkflowActor than I would like or are probably necessary. This could be a separate Tech Debt issue. At least DataAccess is fully async.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/64
https://github.com/broadinstitute/cromwell/pull/64:643,Testability,test,test,643,"DO NOT MERGE YET!. Hopefully a final-ish version of the DataAccess API to unblock its implementation in Slick. . RIP StoreActor, SymbolStore, and ExecutionStore. The spirit of ExecutionStore lives on in WorkflowActor, and maybe SymbolStore might find a place there too to rid us of some Await.result()s. StoreActor is dead for real. . Known issues:. FIXED ~~1) The Docker test is broken because the backend-specific initialization was accidentally refactored away. Shouldn't be a big deal to restore that.~~; 2) All other tests pass, but that might just be because the restart test stinks. There are worrisome messages being emitted from that test which need to be tracked down and have assertions put on them. It might also be a good idea to test restarting a workflow more complex than ""Hello World"".; 3) No persistence of BackendInfo yet, shouldn't be tough but that needs a bit of discussion.; 4) More Await.results() in WorkflowActor than I would like or are probably necessary. This could be a separate Tech Debt issue. At least DataAccess is fully async.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/64
https://github.com/broadinstitute/cromwell/pull/64:687,Testability,assert,assertions,687,"DO NOT MERGE YET!. Hopefully a final-ish version of the DataAccess API to unblock its implementation in Slick. . RIP StoreActor, SymbolStore, and ExecutionStore. The spirit of ExecutionStore lives on in WorkflowActor, and maybe SymbolStore might find a place there too to rid us of some Await.result()s. StoreActor is dead for real. . Known issues:. FIXED ~~1) The Docker test is broken because the backend-specific initialization was accidentally refactored away. Shouldn't be a big deal to restore that.~~; 2) All other tests pass, but that might just be because the restart test stinks. There are worrisome messages being emitted from that test which need to be tracked down and have assertions put on them. It might also be a good idea to test restarting a workflow more complex than ""Hello World"".; 3) No persistence of BackendInfo yet, shouldn't be tough but that needs a bit of discussion.; 4) More Await.results() in WorkflowActor than I would like or are probably necessary. This could be a separate Tech Debt issue. At least DataAccess is fully async.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/64
https://github.com/broadinstitute/cromwell/pull/64:743,Testability,test,test,743,"DO NOT MERGE YET!. Hopefully a final-ish version of the DataAccess API to unblock its implementation in Slick. . RIP StoreActor, SymbolStore, and ExecutionStore. The spirit of ExecutionStore lives on in WorkflowActor, and maybe SymbolStore might find a place there too to rid us of some Await.result()s. StoreActor is dead for real. . Known issues:. FIXED ~~1) The Docker test is broken because the backend-specific initialization was accidentally refactored away. Shouldn't be a big deal to restore that.~~; 2) All other tests pass, but that might just be because the restart test stinks. There are worrisome messages being emitted from that test which need to be tracked down and have assertions put on them. It might also be a good idea to test restarting a workflow more complex than ""Hello World"".; 3) No persistence of BackendInfo yet, shouldn't be tough but that needs a bit of discussion.; 4) More Await.results() in WorkflowActor than I would like or are probably necessary. This could be a separate Tech Debt issue. At least DataAccess is fully async.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/64
https://github.com/broadinstitute/cromwell/pull/67:18,Testability,log,logging,18,"This folds in the logging improvements that were merged to develop today. This is done on a separate branch/PR to be sure not to stomp on Khalid's work, though hopefully what he's working on is largely orthogonal to this anyway.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/67
https://github.com/broadinstitute/cromwell/pull/68:329,Testability,Test,Tests,329,"This adds on to mlc_persistence_rebased (#67):; - Removed a couple dead columns from the DB; - `[WORKFLOW_EXECUTION].[WDL_URI]`; - `[LOCAL_JOB].[COMMAND]`; - Removed the key `callFqn` stored, and unused, in trait `BackendInfo` ; - For command line use, added a default in memory DB initialized with Slick instead of Liquibase; - Tests against hsqldb, using the default db, plus a liquibase initialized test; - Optionally tests against mysql, throwing skip exceptions if it can't connect",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/68
https://github.com/broadinstitute/cromwell/pull/68:402,Testability,test,test,402,"This adds on to mlc_persistence_rebased (#67):; - Removed a couple dead columns from the DB; - `[WORKFLOW_EXECUTION].[WDL_URI]`; - `[LOCAL_JOB].[COMMAND]`; - Removed the key `callFqn` stored, and unused, in trait `BackendInfo` ; - For command line use, added a default in memory DB initialized with Slick instead of Liquibase; - Tests against hsqldb, using the default db, plus a liquibase initialized test; - Optionally tests against mysql, throwing skip exceptions if it can't connect",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/68
https://github.com/broadinstitute/cromwell/pull/68:421,Testability,test,tests,421,"This adds on to mlc_persistence_rebased (#67):; - Removed a couple dead columns from the DB; - `[WORKFLOW_EXECUTION].[WDL_URI]`; - `[LOCAL_JOB].[COMMAND]`; - Removed the key `callFqn` stored, and unused, in trait `BackendInfo` ; - For command line use, added a default in memory DB initialized with Slick instead of Liquibase; - Tests against hsqldb, using the default db, plus a liquibase initialized test; - Optionally tests against mysql, throwing skip exceptions if it can't connect",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/68
https://github.com/broadinstitute/cromwell/pull/70:37,Deployability,release,release,37,They already run once as part of the release process and the second run trips up the Dockerized container-building process.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/70
https://github.com/broadinstitute/cromwell/pull/74:12,Integrability,depend,dependency,12,"Moved mysql dependency to test, and the server actually uses google-api-services-drive at runtime.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/74
https://github.com/broadinstitute/cromwell/pull/74:26,Testability,test,test,26,"Moved mysql dependency to test, and the server actually uses google-api-services-drive at runtime.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/74
https://github.com/broadinstitute/cromwell/pull/76:32,Performance,concurren,concurrent,32,So it can manipulated safely by concurrent workflow actors in the WorkflowManagerActorSpec and tests pass consistently.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/76
https://github.com/broadinstitute/cromwell/pull/76:22,Safety,safe,safely,22,So it can manipulated safely by concurrent workflow actors in the WorkflowManagerActorSpec and tests pass consistently.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/76
https://github.com/broadinstitute/cromwell/pull/76:95,Testability,test,tests,95,So it can manipulated safely by concurrent workflow actors in the WorkflowManagerActorSpec and tests pass consistently.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/76
https://github.com/broadinstitute/cromwell/pull/78:367,Deployability,update,updates,367,Switched `WorkflowExecutionAux` Slick columns from `String` to `Clob`.; Added a test to store/retrieve the 441 char `/3step.wdl` resource paired with a ~10K generated json.; Fixed bug where workflow creation was storing `Call`s using `.taskFqn` instead of `.fullyQualifiedName`.; Added a set of permuted tests for regression checking fully qualified name inserts and updates.; Fixed typo in `to*Worfk*low` utility method.; Re-enabling connection pool for main and tests.; Switched off command line Hikari info & warning logging via logback.xml.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/78
https://github.com/broadinstitute/cromwell/pull/78:80,Testability,test,test,80,Switched `WorkflowExecutionAux` Slick columns from `String` to `Clob`.; Added a test to store/retrieve the 441 char `/3step.wdl` resource paired with a ~10K generated json.; Fixed bug where workflow creation was storing `Call`s using `.taskFqn` instead of `.fullyQualifiedName`.; Added a set of permuted tests for regression checking fully qualified name inserts and updates.; Fixed typo in `to*Worfk*low` utility method.; Re-enabling connection pool for main and tests.; Switched off command line Hikari info & warning logging via logback.xml.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/78
https://github.com/broadinstitute/cromwell/pull/78:304,Testability,test,tests,304,Switched `WorkflowExecutionAux` Slick columns from `String` to `Clob`.; Added a test to store/retrieve the 441 char `/3step.wdl` resource paired with a ~10K generated json.; Fixed bug where workflow creation was storing `Call`s using `.taskFqn` instead of `.fullyQualifiedName`.; Added a set of permuted tests for regression checking fully qualified name inserts and updates.; Fixed typo in `to*Worfk*low` utility method.; Re-enabling connection pool for main and tests.; Switched off command line Hikari info & warning logging via logback.xml.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/78
https://github.com/broadinstitute/cromwell/pull/78:464,Testability,test,tests,464,Switched `WorkflowExecutionAux` Slick columns from `String` to `Clob`.; Added a test to store/retrieve the 441 char `/3step.wdl` resource paired with a ~10K generated json.; Fixed bug where workflow creation was storing `Call`s using `.taskFqn` instead of `.fullyQualifiedName`.; Added a set of permuted tests for regression checking fully qualified name inserts and updates.; Fixed typo in `to*Worfk*low` utility method.; Re-enabling connection pool for main and tests.; Switched off command line Hikari info & warning logging via logback.xml.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/78
https://github.com/broadinstitute/cromwell/pull/78:520,Testability,log,logging,520,Switched `WorkflowExecutionAux` Slick columns from `String` to `Clob`.; Added a test to store/retrieve the 441 char `/3step.wdl` resource paired with a ~10K generated json.; Fixed bug where workflow creation was storing `Call`s using `.taskFqn` instead of `.fullyQualifiedName`.; Added a set of permuted tests for regression checking fully qualified name inserts and updates.; Fixed typo in `to*Worfk*low` utility method.; Re-enabling connection pool for main and tests.; Switched off command line Hikari info & warning logging via logback.xml.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/78
https://github.com/broadinstitute/cromwell/pull/78:532,Testability,log,logback,532,Switched `WorkflowExecutionAux` Slick columns from `String` to `Clob`.; Added a test to store/retrieve the 441 char `/3step.wdl` resource paired with a ~10K generated json.; Fixed bug where workflow creation was storing `Call`s using `.taskFqn` instead of `.fullyQualifiedName`.; Added a set of permuted tests for regression checking fully qualified name inserts and updates.; Fixed typo in `to*Worfk*low` utility method.; Re-enabling connection pool for main and tests.; Switched off command line Hikari info & warning logging via logback.xml.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/78
https://github.com/broadinstitute/cromwell/pull/84:402,Availability,error,error,402,"Fixed Symbol doubly qualifying the symbol names. (thx mcovarr/scottfrazer); Added `WdlType.fromRawString`, with test against respective `WdlValue.toRawString`.; `DummyDataAccess` replaced with using `DataAccess` instances, with cleanup of connections.; When creating in memory databases will create unique `DataAccess` instances, just like Dummy.; TestSlickDatabase now prints a warning, instead of an error, when unable to connect to MySql.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/84
https://github.com/broadinstitute/cromwell/pull/84:112,Testability,test,test,112,"Fixed Symbol doubly qualifying the symbol names. (thx mcovarr/scottfrazer); Added `WdlType.fromRawString`, with test against respective `WdlValue.toRawString`.; `DummyDataAccess` replaced with using `DataAccess` instances, with cleanup of connections.; When creating in memory databases will create unique `DataAccess` instances, just like Dummy.; TestSlickDatabase now prints a warning, instead of an error, when unable to connect to MySql.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/84
https://github.com/broadinstitute/cromwell/pull/84:348,Testability,Test,TestSlickDatabase,348,"Fixed Symbol doubly qualifying the symbol names. (thx mcovarr/scottfrazer); Added `WdlType.fromRawString`, with test against respective `WdlValue.toRawString`.; `DummyDataAccess` replaced with using `DataAccess` instances, with cleanup of connections.; When creating in memory databases will create unique `DataAccess` instances, just like Dummy.; TestSlickDatabase now prints a warning, instead of an error, when unable to connect to MySql.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/84
https://github.com/broadinstitute/cromwell/pull/85:5,Deployability,update,updated,5,Also updated jenkins with file that appears in the dev /etc/cromwell.conf.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/85
https://github.com/broadinstitute/cromwell/pull/87:27,Testability,test,test,27,Modify Docker file-passing test to pass deterministic content so assertions can be made to see if the files were actually passed!,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/87
https://github.com/broadinstitute/cromwell/pull/87:65,Testability,assert,assertions,65,Modify Docker file-passing test to pass deterministic content so assertions can be made to see if the files were actually passed!,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/87
https://github.com/broadinstitute/cromwell/pull/88:377,Modifiability,refactor,refactorings,377,… if it'll be run.; - Convert WdlNamespace into a sum type w/ a worfklowless and workflowed version; - Workflowless namespaces are valid but not runnable; - Decompose monolithic WdlNamespace constructor to separate local workflow logic into workflowed namespaces only; - Decompose validation logic of a Namespace's component parts into the construction of those parts; - Minor refactorings; - Many FIXMEs posing as TODOs and TODOs as well; - Some commentary on old stuff I found particularly confusing in an attempt to work through them,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/88
https://github.com/broadinstitute/cromwell/pull/88:281,Security,validat,validation,281,… if it'll be run.; - Convert WdlNamespace into a sum type w/ a worfklowless and workflowed version; - Workflowless namespaces are valid but not runnable; - Decompose monolithic WdlNamespace constructor to separate local workflow logic into workflowed namespaces only; - Decompose validation logic of a Namespace's component parts into the construction of those parts; - Minor refactorings; - Many FIXMEs posing as TODOs and TODOs as well; - Some commentary on old stuff I found particularly confusing in an attempt to work through them,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/88
https://github.com/broadinstitute/cromwell/pull/88:230,Testability,log,logic,230,… if it'll be run.; - Convert WdlNamespace into a sum type w/ a worfklowless and workflowed version; - Workflowless namespaces are valid but not runnable; - Decompose monolithic WdlNamespace constructor to separate local workflow logic into workflowed namespaces only; - Decompose validation logic of a Namespace's component parts into the construction of those parts; - Minor refactorings; - Many FIXMEs posing as TODOs and TODOs as well; - Some commentary on old stuff I found particularly confusing in an attempt to work through them,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/88
https://github.com/broadinstitute/cromwell/pull/88:292,Testability,log,logic,292,… if it'll be run.; - Convert WdlNamespace into a sum type w/ a worfklowless and workflowed version; - Workflowless namespaces are valid but not runnable; - Decompose monolithic WdlNamespace constructor to separate local workflow logic into workflowed namespaces only; - Decompose validation logic of a Namespace's component parts into the construction of those parts; - Minor refactorings; - Many FIXMEs posing as TODOs and TODOs as well; - Some commentary on old stuff I found particularly confusing in an attempt to work through them,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/88
https://github.com/broadinstitute/cromwell/pull/95:35,Modifiability,variab,variable,35,"This will ensure that if you use a variable declaration twice that they must be identical definitions. Not perfect, but handles the majority case easily.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/95
https://github.com/broadinstitute/cromwell/pull/97:42,Modifiability,enhance,enhanced,42,"Minor change to FileUtil to convert to an enhanced class pattern instead of util functions. Reviewable now, but hold off on merging until the end of the sprint.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/97
https://github.com/broadinstitute/cromwell/pull/103:2,Deployability,Update,Updated,2,- Updated version to 0.7; - Added a much better [Getting Started with WDL](https://github.com/broadinstitute/cromwell/blob/sprint_7_docs/README.md#getting-started-with-wdl),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/103
https://github.com/broadinstitute/cromwell/pull/105:200,Testability,test,tests,200,"Previously only returned outputs for in-memory workflows.; With DSDEEPB-364 storing outputs for JES in the db, this should satisfy DSDEEPB-393; Also added slightly faster debugging of failed workflow tests, with the `fsm.stateData` of why the test actually failed, instead of just timing out.; TODO: For even more helpful debugging, print stderr during tests, or capture tail of stderr to `fsm.stateData` object.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/105
https://github.com/broadinstitute/cromwell/pull/105:243,Testability,test,test,243,"Previously only returned outputs for in-memory workflows.; With DSDEEPB-364 storing outputs for JES in the db, this should satisfy DSDEEPB-393; Also added slightly faster debugging of failed workflow tests, with the `fsm.stateData` of why the test actually failed, instead of just timing out.; TODO: For even more helpful debugging, print stderr during tests, or capture tail of stderr to `fsm.stateData` object.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/105
https://github.com/broadinstitute/cromwell/pull/105:353,Testability,test,tests,353,"Previously only returned outputs for in-memory workflows.; With DSDEEPB-364 storing outputs for JES in the db, this should satisfy DSDEEPB-393; Also added slightly faster debugging of failed workflow tests, with the `fsm.stateData` of why the test actually failed, instead of just timing out.; TODO: For even more helpful debugging, print stderr during tests, or capture tail of stderr to `fsm.stateData` object.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/105
https://github.com/broadinstitute/cromwell/pull/113:82,Testability,test,test,82,- Change SYMBOL.WDL_VALUE to a CLOB; - Add a JSON formatter for WDL Arrays; - Add test,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/113
https://github.com/broadinstitute/cromwell/pull/118:744,Testability,test,tests,744,"I forgot to make the expression evaluator understand `ArrayLiteral` ASTs. Without it, users cannot create WDL array literals within WDL source code. For example:. ```; Array[String] strs = [""x"", ""y"", ""z""]; ```. The `[""x"", ""y"", ""z""]` part is an `ArrayLiteral` AST. Coercions also had to be specified so that the following declaration. ```; Array[File] files = [""x"", ""y"", ""z""]; ```. means: `x`, `y`, and `z` are WdlFiles, which in this case because of no trailing `/`, they are treated as relative to VM. This is very useful for analysts running with the JAR file locally. With WDL files meant for the cloud, file arrays would likely be defined as:. ```; Array[File] files = [""gs://bucket/x"", ""gs://bucket/y"", ""gs://bucket/z""]; ```. Also added a tests:; - Test the `Array[String] -> Array[File]` auto conversion; - Test Array literals in WDL",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/118
https://github.com/broadinstitute/cromwell/pull/118:754,Testability,Test,Test,754,"I forgot to make the expression evaluator understand `ArrayLiteral` ASTs. Without it, users cannot create WDL array literals within WDL source code. For example:. ```; Array[String] strs = [""x"", ""y"", ""z""]; ```. The `[""x"", ""y"", ""z""]` part is an `ArrayLiteral` AST. Coercions also had to be specified so that the following declaration. ```; Array[File] files = [""x"", ""y"", ""z""]; ```. means: `x`, `y`, and `z` are WdlFiles, which in this case because of no trailing `/`, they are treated as relative to VM. This is very useful for analysts running with the JAR file locally. With WDL files meant for the cloud, file arrays would likely be defined as:. ```; Array[File] files = [""gs://bucket/x"", ""gs://bucket/y"", ""gs://bucket/z""]; ```. Also added a tests:; - Test the `Array[String] -> Array[File]` auto conversion; - Test Array literals in WDL",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/118
https://github.com/broadinstitute/cromwell/pull/118:813,Testability,Test,Test,813,"I forgot to make the expression evaluator understand `ArrayLiteral` ASTs. Without it, users cannot create WDL array literals within WDL source code. For example:. ```; Array[String] strs = [""x"", ""y"", ""z""]; ```. The `[""x"", ""y"", ""z""]` part is an `ArrayLiteral` AST. Coercions also had to be specified so that the following declaration. ```; Array[File] files = [""x"", ""y"", ""z""]; ```. means: `x`, `y`, and `z` are WdlFiles, which in this case because of no trailing `/`, they are treated as relative to VM. This is very useful for analysts running with the JAR file locally. With WDL files meant for the cloud, file arrays would likely be defined as:. ```; Array[File] files = [""gs://bucket/x"", ""gs://bucket/y"", ""gs://bucket/z""]; ```. Also added a tests:; - Test the `Array[String] -> Array[File]` auto conversion; - Test Array literals in WDL",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/118
https://github.com/broadinstitute/cromwell/pull/119:0,Deployability,Patch,Patched,0,Patched swagger-ui routes and added tests.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/119
https://github.com/broadinstitute/cromwell/pull/119:19,Integrability,rout,routes,19,Patched swagger-ui routes and added tests.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/119
https://github.com/broadinstitute/cromwell/pull/119:36,Testability,test,tests,36,Patched swagger-ui routes and added tests.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/119
https://github.com/broadinstitute/cromwell/pull/123:48,Testability,test,tests,48,"Supersedes the work on sfrazer_bugs. Non-Docker tests pass on gce-ces-build, I don't know how to run Docker tests there from the CLI. This does not include @kshakir's MVCC database changes as those don't appear to be strictly necessary to solve these problems, though they might be desirable on their own merits.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/123
https://github.com/broadinstitute/cromwell/pull/123:108,Testability,test,tests,108,"Supersedes the work on sfrazer_bugs. Non-Docker tests pass on gce-ces-build, I don't know how to run Docker tests there from the CLI. This does not include @kshakir's MVCC database changes as those don't appear to be strictly necessary to solve these problems, though they might be desirable on their own merits.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/123
https://github.com/broadinstitute/cromwell/pull/128:0,Testability,Test,Test,0,Test cases to follow.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/128
https://github.com/broadinstitute/cromwell/pull/132:333,Integrability,depend,dependent,333,"What's happening here is that we're breaking the command on newlines, specifically `[\r\n]+` and then reassembling the pieces with `.mkString("""")` effectively removing all newlines from a user's command. This not a problem for one line commands and also many multi-line commands, but it is a problem for commands that are whitespace dependent (see the test case for an example).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/132
https://github.com/broadinstitute/cromwell/pull/132:352,Testability,test,test,352,"What's happening here is that we're breaking the command on newlines, specifically `[\r\n]+` and then reassembling the pieces with `.mkString("""")` effectively removing all newlines from a user's command. This not a problem for one line commands and also many multi-line commands, but it is a problem for commands that are whitespace dependent (see the test case for an example).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/132
https://github.com/broadinstitute/cromwell/pull/135:0,Deployability,Update,Updated,0,"Updated Language Spec: https://github.com/broadinstitute/wdl/blob/spec/SPEC.md#workflow-description-language. What you'll find in here:; - Updates to the parser for the various syntax changes we decided on. Tests have also been updated and all WDL files I could find have been updated for the new syntax.; - `EngineFunctions` -> `WdlStandardLibraryFunctions` with stubs for everything that's in the specification.; - Implemented the following on `LocalEngineFunctions`: `write_map()`, `read_map()`, `write_lines()`. Tests also added for these; - Refactoring of parts of the backend to be able to accommodate the implementation of the functions described above.; - Syntax Highlighter updated for new syntax; - Map literals now allowed in WDL source. Tests included.; - Slightly better coercion semantics: Added an identity coercion ; - Remove / refactor a lot of tech debt.; - Removed the `Command` class, now consumed into `Task` class. Since the spec change, Commands needed to know more about stuff defined at the task level (specifically, Declarations).; - Exposure of workflow outputs section in the `Workflow` class, they are not honored further than that though.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/135
https://github.com/broadinstitute/cromwell/pull/135:139,Deployability,Update,Updates,139,"Updated Language Spec: https://github.com/broadinstitute/wdl/blob/spec/SPEC.md#workflow-description-language. What you'll find in here:; - Updates to the parser for the various syntax changes we decided on. Tests have also been updated and all WDL files I could find have been updated for the new syntax.; - `EngineFunctions` -> `WdlStandardLibraryFunctions` with stubs for everything that's in the specification.; - Implemented the following on `LocalEngineFunctions`: `write_map()`, `read_map()`, `write_lines()`. Tests also added for these; - Refactoring of parts of the backend to be able to accommodate the implementation of the functions described above.; - Syntax Highlighter updated for new syntax; - Map literals now allowed in WDL source. Tests included.; - Slightly better coercion semantics: Added an identity coercion ; - Remove / refactor a lot of tech debt.; - Removed the `Command` class, now consumed into `Task` class. Since the spec change, Commands needed to know more about stuff defined at the task level (specifically, Declarations).; - Exposure of workflow outputs section in the `Workflow` class, they are not honored further than that though.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/135
https://github.com/broadinstitute/cromwell/pull/135:228,Deployability,update,updated,228,"Updated Language Spec: https://github.com/broadinstitute/wdl/blob/spec/SPEC.md#workflow-description-language. What you'll find in here:; - Updates to the parser for the various syntax changes we decided on. Tests have also been updated and all WDL files I could find have been updated for the new syntax.; - `EngineFunctions` -> `WdlStandardLibraryFunctions` with stubs for everything that's in the specification.; - Implemented the following on `LocalEngineFunctions`: `write_map()`, `read_map()`, `write_lines()`. Tests also added for these; - Refactoring of parts of the backend to be able to accommodate the implementation of the functions described above.; - Syntax Highlighter updated for new syntax; - Map literals now allowed in WDL source. Tests included.; - Slightly better coercion semantics: Added an identity coercion ; - Remove / refactor a lot of tech debt.; - Removed the `Command` class, now consumed into `Task` class. Since the spec change, Commands needed to know more about stuff defined at the task level (specifically, Declarations).; - Exposure of workflow outputs section in the `Workflow` class, they are not honored further than that though.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/135
https://github.com/broadinstitute/cromwell/pull/135:277,Deployability,update,updated,277,"Updated Language Spec: https://github.com/broadinstitute/wdl/blob/spec/SPEC.md#workflow-description-language. What you'll find in here:; - Updates to the parser for the various syntax changes we decided on. Tests have also been updated and all WDL files I could find have been updated for the new syntax.; - `EngineFunctions` -> `WdlStandardLibraryFunctions` with stubs for everything that's in the specification.; - Implemented the following on `LocalEngineFunctions`: `write_map()`, `read_map()`, `write_lines()`. Tests also added for these; - Refactoring of parts of the backend to be able to accommodate the implementation of the functions described above.; - Syntax Highlighter updated for new syntax; - Map literals now allowed in WDL source. Tests included.; - Slightly better coercion semantics: Added an identity coercion ; - Remove / refactor a lot of tech debt.; - Removed the `Command` class, now consumed into `Task` class. Since the spec change, Commands needed to know more about stuff defined at the task level (specifically, Declarations).; - Exposure of workflow outputs section in the `Workflow` class, they are not honored further than that though.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/135
https://github.com/broadinstitute/cromwell/pull/135:683,Deployability,update,updated,683,"Updated Language Spec: https://github.com/broadinstitute/wdl/blob/spec/SPEC.md#workflow-description-language. What you'll find in here:; - Updates to the parser for the various syntax changes we decided on. Tests have also been updated and all WDL files I could find have been updated for the new syntax.; - `EngineFunctions` -> `WdlStandardLibraryFunctions` with stubs for everything that's in the specification.; - Implemented the following on `LocalEngineFunctions`: `write_map()`, `read_map()`, `write_lines()`. Tests also added for these; - Refactoring of parts of the backend to be able to accommodate the implementation of the functions described above.; - Syntax Highlighter updated for new syntax; - Map literals now allowed in WDL source. Tests included.; - Slightly better coercion semantics: Added an identity coercion ; - Remove / refactor a lot of tech debt.; - Removed the `Command` class, now consumed into `Task` class. Since the spec change, Commands needed to know more about stuff defined at the task level (specifically, Declarations).; - Exposure of workflow outputs section in the `Workflow` class, they are not honored further than that though.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/135
https://github.com/broadinstitute/cromwell/pull/135:546,Modifiability,Refactor,Refactoring,546,"Updated Language Spec: https://github.com/broadinstitute/wdl/blob/spec/SPEC.md#workflow-description-language. What you'll find in here:; - Updates to the parser for the various syntax changes we decided on. Tests have also been updated and all WDL files I could find have been updated for the new syntax.; - `EngineFunctions` -> `WdlStandardLibraryFunctions` with stubs for everything that's in the specification.; - Implemented the following on `LocalEngineFunctions`: `write_map()`, `read_map()`, `write_lines()`. Tests also added for these; - Refactoring of parts of the backend to be able to accommodate the implementation of the functions described above.; - Syntax Highlighter updated for new syntax; - Map literals now allowed in WDL source. Tests included.; - Slightly better coercion semantics: Added an identity coercion ; - Remove / refactor a lot of tech debt.; - Removed the `Command` class, now consumed into `Task` class. Since the spec change, Commands needed to know more about stuff defined at the task level (specifically, Declarations).; - Exposure of workflow outputs section in the `Workflow` class, they are not honored further than that though.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/135
https://github.com/broadinstitute/cromwell/pull/135:844,Modifiability,refactor,refactor,844,"Updated Language Spec: https://github.com/broadinstitute/wdl/blob/spec/SPEC.md#workflow-description-language. What you'll find in here:; - Updates to the parser for the various syntax changes we decided on. Tests have also been updated and all WDL files I could find have been updated for the new syntax.; - `EngineFunctions` -> `WdlStandardLibraryFunctions` with stubs for everything that's in the specification.; - Implemented the following on `LocalEngineFunctions`: `write_map()`, `read_map()`, `write_lines()`. Tests also added for these; - Refactoring of parts of the backend to be able to accommodate the implementation of the functions described above.; - Syntax Highlighter updated for new syntax; - Map literals now allowed in WDL source. Tests included.; - Slightly better coercion semantics: Added an identity coercion ; - Remove / refactor a lot of tech debt.; - Removed the `Command` class, now consumed into `Task` class. Since the spec change, Commands needed to know more about stuff defined at the task level (specifically, Declarations).; - Exposure of workflow outputs section in the `Workflow` class, they are not honored further than that though.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/135
https://github.com/broadinstitute/cromwell/pull/135:207,Testability,Test,Tests,207,"Updated Language Spec: https://github.com/broadinstitute/wdl/blob/spec/SPEC.md#workflow-description-language. What you'll find in here:; - Updates to the parser for the various syntax changes we decided on. Tests have also been updated and all WDL files I could find have been updated for the new syntax.; - `EngineFunctions` -> `WdlStandardLibraryFunctions` with stubs for everything that's in the specification.; - Implemented the following on `LocalEngineFunctions`: `write_map()`, `read_map()`, `write_lines()`. Tests also added for these; - Refactoring of parts of the backend to be able to accommodate the implementation of the functions described above.; - Syntax Highlighter updated for new syntax; - Map literals now allowed in WDL source. Tests included.; - Slightly better coercion semantics: Added an identity coercion ; - Remove / refactor a lot of tech debt.; - Removed the `Command` class, now consumed into `Task` class. Since the spec change, Commands needed to know more about stuff defined at the task level (specifically, Declarations).; - Exposure of workflow outputs section in the `Workflow` class, they are not honored further than that though.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/135
https://github.com/broadinstitute/cromwell/pull/135:364,Testability,stub,stubs,364,"Updated Language Spec: https://github.com/broadinstitute/wdl/blob/spec/SPEC.md#workflow-description-language. What you'll find in here:; - Updates to the parser for the various syntax changes we decided on. Tests have also been updated and all WDL files I could find have been updated for the new syntax.; - `EngineFunctions` -> `WdlStandardLibraryFunctions` with stubs for everything that's in the specification.; - Implemented the following on `LocalEngineFunctions`: `write_map()`, `read_map()`, `write_lines()`. Tests also added for these; - Refactoring of parts of the backend to be able to accommodate the implementation of the functions described above.; - Syntax Highlighter updated for new syntax; - Map literals now allowed in WDL source. Tests included.; - Slightly better coercion semantics: Added an identity coercion ; - Remove / refactor a lot of tech debt.; - Removed the `Command` class, now consumed into `Task` class. Since the spec change, Commands needed to know more about stuff defined at the task level (specifically, Declarations).; - Exposure of workflow outputs section in the `Workflow` class, they are not honored further than that though.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/135
https://github.com/broadinstitute/cromwell/pull/135:516,Testability,Test,Tests,516,"Updated Language Spec: https://github.com/broadinstitute/wdl/blob/spec/SPEC.md#workflow-description-language. What you'll find in here:; - Updates to the parser for the various syntax changes we decided on. Tests have also been updated and all WDL files I could find have been updated for the new syntax.; - `EngineFunctions` -> `WdlStandardLibraryFunctions` with stubs for everything that's in the specification.; - Implemented the following on `LocalEngineFunctions`: `write_map()`, `read_map()`, `write_lines()`. Tests also added for these; - Refactoring of parts of the backend to be able to accommodate the implementation of the functions described above.; - Syntax Highlighter updated for new syntax; - Map literals now allowed in WDL source. Tests included.; - Slightly better coercion semantics: Added an identity coercion ; - Remove / refactor a lot of tech debt.; - Removed the `Command` class, now consumed into `Task` class. Since the spec change, Commands needed to know more about stuff defined at the task level (specifically, Declarations).; - Exposure of workflow outputs section in the `Workflow` class, they are not honored further than that though.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/135
https://github.com/broadinstitute/cromwell/pull/135:749,Testability,Test,Tests,749,"Updated Language Spec: https://github.com/broadinstitute/wdl/blob/spec/SPEC.md#workflow-description-language. What you'll find in here:; - Updates to the parser for the various syntax changes we decided on. Tests have also been updated and all WDL files I could find have been updated for the new syntax.; - `EngineFunctions` -> `WdlStandardLibraryFunctions` with stubs for everything that's in the specification.; - Implemented the following on `LocalEngineFunctions`: `write_map()`, `read_map()`, `write_lines()`. Tests also added for these; - Refactoring of parts of the backend to be able to accommodate the implementation of the functions described above.; - Syntax Highlighter updated for new syntax; - Map literals now allowed in WDL source. Tests included.; - Slightly better coercion semantics: Added an identity coercion ; - Remove / refactor a lot of tech debt.; - Removed the `Command` class, now consumed into `Task` class. Since the spec change, Commands needed to know more about stuff defined at the task level (specifically, Declarations).; - Exposure of workflow outputs section in the `Workflow` class, they are not honored further than that though.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/135
https://github.com/broadinstitute/cromwell/pull/145:835,Integrability,depend,depending,835,"- Refactoring the `TaskExecutionContext` (and children) into `BackendCall`. `BackendCall` represents the marriage of a (you guessed it...) `Backend` and a `Call`. The `BackendCall` also stores the `Map[LocallyQualifiedName, WdlValue]`. A `BackendCall` is basically a way to package up a (Call + Backend + Inputs) so you can simply do `.execute` with no parameters and it can start running.; ; This actually sets us up nicely for tasks to define which backend they run on (if we choose to support that). This could be implemented simply by honoring a runtime section like this.; ; ```; task sge_task {; command { ... }; runtime {; backend: ""sge""; }; }; ```; ; At the time we're creating the `BackendCall`, we just switch on the 'backend' value on the task, and either return a `SgeBackendCall`, `LocalBackendCall`, or `JesBackendCall` (depending on what we support); - Add SGE backend based off of Local Backend; - Created a `LocalFileSystemOperations` trait which fulfills some of the `Backend` API. SGE and Local backends currently make an assumption: the Cromwell process writes everything to filesystem paths and jobs that Cromwell launch can see and write into those directories. So operations like initializing a workflow or post-processing a job that has completed are the same between SGE and Local backends.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/145
https://github.com/broadinstitute/cromwell/pull/145:2,Modifiability,Refactor,Refactoring,2,"- Refactoring the `TaskExecutionContext` (and children) into `BackendCall`. `BackendCall` represents the marriage of a (you guessed it...) `Backend` and a `Call`. The `BackendCall` also stores the `Map[LocallyQualifiedName, WdlValue]`. A `BackendCall` is basically a way to package up a (Call + Backend + Inputs) so you can simply do `.execute` with no parameters and it can start running.; ; This actually sets us up nicely for tasks to define which backend they run on (if we choose to support that). This could be implemented simply by honoring a runtime section like this.; ; ```; task sge_task {; command { ... }; runtime {; backend: ""sge""; }; }; ```; ; At the time we're creating the `BackendCall`, we just switch on the 'backend' value on the task, and either return a `SgeBackendCall`, `LocalBackendCall`, or `JesBackendCall` (depending on what we support); - Add SGE backend based off of Local Backend; - Created a `LocalFileSystemOperations` trait which fulfills some of the `Backend` API. SGE and Local backends currently make an assumption: the Cromwell process writes everything to filesystem paths and jobs that Cromwell launch can see and write into those directories. So operations like initializing a workflow or post-processing a job that has completed are the same between SGE and Local backends.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/145
https://github.com/broadinstitute/cromwell/pull/145:324,Usability,simpl,simply,324,"- Refactoring the `TaskExecutionContext` (and children) into `BackendCall`. `BackendCall` represents the marriage of a (you guessed it...) `Backend` and a `Call`. The `BackendCall` also stores the `Map[LocallyQualifiedName, WdlValue]`. A `BackendCall` is basically a way to package up a (Call + Backend + Inputs) so you can simply do `.execute` with no parameters and it can start running.; ; This actually sets us up nicely for tasks to define which backend they run on (if we choose to support that). This could be implemented simply by honoring a runtime section like this.; ; ```; task sge_task {; command { ... }; runtime {; backend: ""sge""; }; }; ```; ; At the time we're creating the `BackendCall`, we just switch on the 'backend' value on the task, and either return a `SgeBackendCall`, `LocalBackendCall`, or `JesBackendCall` (depending on what we support); - Add SGE backend based off of Local Backend; - Created a `LocalFileSystemOperations` trait which fulfills some of the `Backend` API. SGE and Local backends currently make an assumption: the Cromwell process writes everything to filesystem paths and jobs that Cromwell launch can see and write into those directories. So operations like initializing a workflow or post-processing a job that has completed are the same between SGE and Local backends.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/145
https://github.com/broadinstitute/cromwell/pull/145:529,Usability,simpl,simply,529,"- Refactoring the `TaskExecutionContext` (and children) into `BackendCall`. `BackendCall` represents the marriage of a (you guessed it...) `Backend` and a `Call`. The `BackendCall` also stores the `Map[LocallyQualifiedName, WdlValue]`. A `BackendCall` is basically a way to package up a (Call + Backend + Inputs) so you can simply do `.execute` with no parameters and it can start running.; ; This actually sets us up nicely for tasks to define which backend they run on (if we choose to support that). This could be implemented simply by honoring a runtime section like this.; ; ```; task sge_task {; command { ... }; runtime {; backend: ""sge""; }; }; ```; ; At the time we're creating the `BackendCall`, we just switch on the 'backend' value on the task, and either return a `SgeBackendCall`, `LocalBackendCall`, or `JesBackendCall` (depending on what we support); - Add SGE backend based off of Local Backend; - Created a `LocalFileSystemOperations` trait which fulfills some of the `Backend` API. SGE and Local backends currently make an assumption: the Cromwell process writes everything to filesystem paths and jobs that Cromwell launch can see and write into those directories. So operations like initializing a workflow or post-processing a job that has completed are the same between SGE and Local backends.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/145
https://github.com/broadinstitute/cromwell/pull/147:24,Usability,simpl,simpler,24,This ended up being far simpler than I thought. I just did it in a few mins so there are likely cleanups necessary and/or maybe I'm missing something else. I did build and run it against LocalBackend and JesBackend though so it seems ok.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/147
https://github.com/broadinstitute/cromwell/pull/153:123,Deployability,pipeline,pipeline,123,"…ed to mount that into the docker image by using JES disk input parameters, which it turns out you have to specify both at pipeline time and runtime (question out to Garrick). This is important because currently if you try to localize or produce more than 10gb of input your pipeline will die. This bumps that up to 100G of local ssd. Eventually, after getting some road time, we might want to think about how to parameterize this so users could specify/override",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/153
https://github.com/broadinstitute/cromwell/pull/153:275,Deployability,pipeline,pipeline,275,"…ed to mount that into the docker image by using JES disk input parameters, which it turns out you have to specify both at pipeline time and runtime (question out to Garrick). This is important because currently if you try to localize or produce more than 10gb of input your pipeline will die. This bumps that up to 100G of local ssd. Eventually, after getting some road time, we might want to think about how to parameterize this so users could specify/override",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/153
https://github.com/broadinstitute/cromwell/pull/153:413,Modifiability,parameteriz,parameterize,413,"…ed to mount that into the docker image by using JES disk input parameters, which it turns out you have to specify both at pipeline time and runtime (question out to Garrick). This is important because currently if you try to localize or produce more than 10gb of input your pipeline will die. This bumps that up to 100G of local ssd. Eventually, after getting some road time, we might want to think about how to parameterize this so users could specify/override",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/153
https://github.com/broadinstitute/cromwell/pull/156:72,Testability,test,tests,72,This needs refinement but it's rebased on scatter-gather branch and the tests pass.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/156
https://github.com/broadinstitute/cromwell/pull/163:33,Availability,error,errors,33,"…, with ability to have multiple errors",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/163
https://github.com/broadinstitute/cromwell/pull/166:21,Testability,test,test,21,Found this trying to test s/g,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/166
https://github.com/broadinstitute/cromwell/pull/174:83,Integrability,interface,interface,83,- Moved all expression related code into `cromwell.binding.expression`.; - Defined interface `Evaluator` which evaluates into a `type T`. The 3 currently implemented evaluators are:; - `ValueEvaluator` - Evaluate a `WdlExpression` into a `WdlValue`; - `TypeEvaluator` - Evaluate a `WdlExpression` into a `WdlType`; - `FileEvaluator` - Evaluate a `WdlExpression` into a `Seq[WdlFile]`; - Public API for evaluating expressions is not changed much. Basically:; - `WdlExpression.evaluate(...): Try[WdlValue]`; - `WdlExpression.evaluateType(...): Try[WdlType]`; - `WdlExpression.evaluateFiles(...): Try[Seq[WdlValue]]`; - `JesBackend` now uses the `WdlExpression.evaluateFiles()` for calculating all `JesOutput`s; - Statically type-check the `output` section of a task defintion!; - Coercion of input types happens when locally qualified inputs are created,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/174
https://github.com/broadinstitute/cromwell/pull/177:63,Testability,test,tested,63,"Works on LocalBackend, code is in place for SGEBackend but not tested yet.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/177
https://github.com/broadinstitute/cromwell/pull/181:117,Integrability,message,message,117,"This only worked if the first line contained the `Your job 1234` string. However, sometimes there's a little warning message that appears on the first line.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/181
https://github.com/broadinstitute/cromwell/pull/186:34,Testability,test,test,34,do we have a way to automatically test JES-execution? This should be backwards compatible so the existing tests are testing something,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/186
https://github.com/broadinstitute/cromwell/pull/186:106,Testability,test,tests,106,do we have a way to automatically test JES-execution? This should be backwards compatible so the existing tests are testing something,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/186
https://github.com/broadinstitute/cromwell/pull/186:116,Testability,test,testing,116,do we have a way to automatically test JES-execution? This should be backwards compatible so the existing tests are testing something,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/186
https://github.com/broadinstitute/cromwell/pull/189:93,Testability,test,test,93,"it fixes the issue where ""sbt assembly"" on newer versions of sbt and docker will ignore the `test in assembly := {}` in the build.sbt",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/189
https://github.com/broadinstitute/cromwell/pull/190:376,Availability,avail,available,376,"The way this works for now is:; In JES configuration you need to specify an `authenticationMode` parameter which can take one of those 2 values: `service_account` or `refresh_token`; `service_account` works exactly the same way as it did before; `refresh_token` will require 2 fields to be passed as workflow options:; `account_name` and `refresh_token`. Depending on what is available, the JES backend will create, only if necessary and at workflow initialization time, a json file (gcloudauth.json) and upload it to the root directory of the workflow.; Currently this json file can contain 2 types of information:; - Docker credentials: These are optional and can be specified in the `jes` section in application.conf. They look like this:. ```; dockerAccount = ""my.docker@account.com""; dockerToken = ""mydockertoken""; ```. If they are specified a ""docker"" value will be added to gcloudauth.json containing those values.; This will allow using a private docker image that would not be accessible otherwise.; This functionality was mostly already there from Kristian PR, I just moved the credential location from gcs to conf.; - User credentials: These need to be added as workflow options : . ```; {; ""account_name"": ""myaccount@broadinstitute.org"",; ""refresh_token"": ""refresh_token""; }; ```. Again if in RefreshToken mode, they need to be there for every workflow call or an exception will be thrown at initialization time.; If they are there they will be added to the gcloudauth.json in the same way docker crednetials are, under a ""gcloud"" value. You should then get permission to localize input files that are only accessible to this user. So depending on what is provided (docker info, user info), you can get a gcloudauth.json with both credentials, only one, or no file at all. In any case the JES backend will try to delete this file when the workflow reaches a terminal state.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/190
https://github.com/broadinstitute/cromwell/pull/190:39,Deployability,configurat,configuration,39,"The way this works for now is:; In JES configuration you need to specify an `authenticationMode` parameter which can take one of those 2 values: `service_account` or `refresh_token`; `service_account` works exactly the same way as it did before; `refresh_token` will require 2 fields to be passed as workflow options:; `account_name` and `refresh_token`. Depending on what is available, the JES backend will create, only if necessary and at workflow initialization time, a json file (gcloudauth.json) and upload it to the root directory of the workflow.; Currently this json file can contain 2 types of information:; - Docker credentials: These are optional and can be specified in the `jes` section in application.conf. They look like this:. ```; dockerAccount = ""my.docker@account.com""; dockerToken = ""mydockertoken""; ```. If they are specified a ""docker"" value will be added to gcloudauth.json containing those values.; This will allow using a private docker image that would not be accessible otherwise.; This functionality was mostly already there from Kristian PR, I just moved the credential location from gcs to conf.; - User credentials: These need to be added as workflow options : . ```; {; ""account_name"": ""myaccount@broadinstitute.org"",; ""refresh_token"": ""refresh_token""; }; ```. Again if in RefreshToken mode, they need to be there for every workflow call or an exception will be thrown at initialization time.; If they are there they will be added to the gcloudauth.json in the same way docker crednetials are, under a ""gcloud"" value. You should then get permission to localize input files that are only accessible to this user. So depending on what is provided (docker info, user info), you can get a gcloudauth.json with both credentials, only one, or no file at all. In any case the JES backend will try to delete this file when the workflow reaches a terminal state.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/190
https://github.com/broadinstitute/cromwell/pull/190:355,Integrability,Depend,Depending,355,"The way this works for now is:; In JES configuration you need to specify an `authenticationMode` parameter which can take one of those 2 values: `service_account` or `refresh_token`; `service_account` works exactly the same way as it did before; `refresh_token` will require 2 fields to be passed as workflow options:; `account_name` and `refresh_token`. Depending on what is available, the JES backend will create, only if necessary and at workflow initialization time, a json file (gcloudauth.json) and upload it to the root directory of the workflow.; Currently this json file can contain 2 types of information:; - Docker credentials: These are optional and can be specified in the `jes` section in application.conf. They look like this:. ```; dockerAccount = ""my.docker@account.com""; dockerToken = ""mydockertoken""; ```. If they are specified a ""docker"" value will be added to gcloudauth.json containing those values.; This will allow using a private docker image that would not be accessible otherwise.; This functionality was mostly already there from Kristian PR, I just moved the credential location from gcs to conf.; - User credentials: These need to be added as workflow options : . ```; {; ""account_name"": ""myaccount@broadinstitute.org"",; ""refresh_token"": ""refresh_token""; }; ```. Again if in RefreshToken mode, they need to be there for every workflow call or an exception will be thrown at initialization time.; If they are there they will be added to the gcloudauth.json in the same way docker crednetials are, under a ""gcloud"" value. You should then get permission to localize input files that are only accessible to this user. So depending on what is provided (docker info, user info), you can get a gcloudauth.json with both credentials, only one, or no file at all. In any case the JES backend will try to delete this file when the workflow reaches a terminal state.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/190
https://github.com/broadinstitute/cromwell/pull/190:1647,Integrability,depend,depending,1647,"The way this works for now is:; In JES configuration you need to specify an `authenticationMode` parameter which can take one of those 2 values: `service_account` or `refresh_token`; `service_account` works exactly the same way as it did before; `refresh_token` will require 2 fields to be passed as workflow options:; `account_name` and `refresh_token`. Depending on what is available, the JES backend will create, only if necessary and at workflow initialization time, a json file (gcloudauth.json) and upload it to the root directory of the workflow.; Currently this json file can contain 2 types of information:; - Docker credentials: These are optional and can be specified in the `jes` section in application.conf. They look like this:. ```; dockerAccount = ""my.docker@account.com""; dockerToken = ""mydockertoken""; ```. If they are specified a ""docker"" value will be added to gcloudauth.json containing those values.; This will allow using a private docker image that would not be accessible otherwise.; This functionality was mostly already there from Kristian PR, I just moved the credential location from gcs to conf.; - User credentials: These need to be added as workflow options : . ```; {; ""account_name"": ""myaccount@broadinstitute.org"",; ""refresh_token"": ""refresh_token""; }; ```. Again if in RefreshToken mode, they need to be there for every workflow call or an exception will be thrown at initialization time.; If they are there they will be added to the gcloudauth.json in the same way docker crednetials are, under a ""gcloud"" value. You should then get permission to localize input files that are only accessible to this user. So depending on what is provided (docker info, user info), you can get a gcloudauth.json with both credentials, only one, or no file at all. In any case the JES backend will try to delete this file when the workflow reaches a terminal state.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/190
https://github.com/broadinstitute/cromwell/pull/190:39,Modifiability,config,configuration,39,"The way this works for now is:; In JES configuration you need to specify an `authenticationMode` parameter which can take one of those 2 values: `service_account` or `refresh_token`; `service_account` works exactly the same way as it did before; `refresh_token` will require 2 fields to be passed as workflow options:; `account_name` and `refresh_token`. Depending on what is available, the JES backend will create, only if necessary and at workflow initialization time, a json file (gcloudauth.json) and upload it to the root directory of the workflow.; Currently this json file can contain 2 types of information:; - Docker credentials: These are optional and can be specified in the `jes` section in application.conf. They look like this:. ```; dockerAccount = ""my.docker@account.com""; dockerToken = ""mydockertoken""; ```. If they are specified a ""docker"" value will be added to gcloudauth.json containing those values.; This will allow using a private docker image that would not be accessible otherwise.; This functionality was mostly already there from Kristian PR, I just moved the credential location from gcs to conf.; - User credentials: These need to be added as workflow options : . ```; {; ""account_name"": ""myaccount@broadinstitute.org"",; ""refresh_token"": ""refresh_token""; }; ```. Again if in RefreshToken mode, they need to be there for every workflow call or an exception will be thrown at initialization time.; If they are there they will be added to the gcloudauth.json in the same way docker crednetials are, under a ""gcloud"" value. You should then get permission to localize input files that are only accessible to this user. So depending on what is provided (docker info, user info), you can get a gcloudauth.json with both credentials, only one, or no file at all. In any case the JES backend will try to delete this file when the workflow reaches a terminal state.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/190
https://github.com/broadinstitute/cromwell/pull/190:77,Security,authenticat,authenticationMode,77,"The way this works for now is:; In JES configuration you need to specify an `authenticationMode` parameter which can take one of those 2 values: `service_account` or `refresh_token`; `service_account` works exactly the same way as it did before; `refresh_token` will require 2 fields to be passed as workflow options:; `account_name` and `refresh_token`. Depending on what is available, the JES backend will create, only if necessary and at workflow initialization time, a json file (gcloudauth.json) and upload it to the root directory of the workflow.; Currently this json file can contain 2 types of information:; - Docker credentials: These are optional and can be specified in the `jes` section in application.conf. They look like this:. ```; dockerAccount = ""my.docker@account.com""; dockerToken = ""mydockertoken""; ```. If they are specified a ""docker"" value will be added to gcloudauth.json containing those values.; This will allow using a private docker image that would not be accessible otherwise.; This functionality was mostly already there from Kristian PR, I just moved the credential location from gcs to conf.; - User credentials: These need to be added as workflow options : . ```; {; ""account_name"": ""myaccount@broadinstitute.org"",; ""refresh_token"": ""refresh_token""; }; ```. Again if in RefreshToken mode, they need to be there for every workflow call or an exception will be thrown at initialization time.; If they are there they will be added to the gcloudauth.json in the same way docker crednetials are, under a ""gcloud"" value. You should then get permission to localize input files that are only accessible to this user. So depending on what is provided (docker info, user info), you can get a gcloudauth.json with both credentials, only one, or no file at all. In any case the JES backend will try to delete this file when the workflow reaches a terminal state.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/190
https://github.com/broadinstitute/cromwell/pull/190:986,Security,access,accessible,986,"The way this works for now is:; In JES configuration you need to specify an `authenticationMode` parameter which can take one of those 2 values: `service_account` or `refresh_token`; `service_account` works exactly the same way as it did before; `refresh_token` will require 2 fields to be passed as workflow options:; `account_name` and `refresh_token`. Depending on what is available, the JES backend will create, only if necessary and at workflow initialization time, a json file (gcloudauth.json) and upload it to the root directory of the workflow.; Currently this json file can contain 2 types of information:; - Docker credentials: These are optional and can be specified in the `jes` section in application.conf. They look like this:. ```; dockerAccount = ""my.docker@account.com""; dockerToken = ""mydockertoken""; ```. If they are specified a ""docker"" value will be added to gcloudauth.json containing those values.; This will allow using a private docker image that would not be accessible otherwise.; This functionality was mostly already there from Kristian PR, I just moved the credential location from gcs to conf.; - User credentials: These need to be added as workflow options : . ```; {; ""account_name"": ""myaccount@broadinstitute.org"",; ""refresh_token"": ""refresh_token""; }; ```. Again if in RefreshToken mode, they need to be there for every workflow call or an exception will be thrown at initialization time.; If they are there they will be added to the gcloudauth.json in the same way docker crednetials are, under a ""gcloud"" value. You should then get permission to localize input files that are only accessible to this user. So depending on what is provided (docker info, user info), you can get a gcloudauth.json with both credentials, only one, or no file at all. In any case the JES backend will try to delete this file when the workflow reaches a terminal state.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/190
https://github.com/broadinstitute/cromwell/pull/190:1619,Security,access,accessible,1619,"The way this works for now is:; In JES configuration you need to specify an `authenticationMode` parameter which can take one of those 2 values: `service_account` or `refresh_token`; `service_account` works exactly the same way as it did before; `refresh_token` will require 2 fields to be passed as workflow options:; `account_name` and `refresh_token`. Depending on what is available, the JES backend will create, only if necessary and at workflow initialization time, a json file (gcloudauth.json) and upload it to the root directory of the workflow.; Currently this json file can contain 2 types of information:; - Docker credentials: These are optional and can be specified in the `jes` section in application.conf. They look like this:. ```; dockerAccount = ""my.docker@account.com""; dockerToken = ""mydockertoken""; ```. If they are specified a ""docker"" value will be added to gcloudauth.json containing those values.; This will allow using a private docker image that would not be accessible otherwise.; This functionality was mostly already there from Kristian PR, I just moved the credential location from gcs to conf.; - User credentials: These need to be added as workflow options : . ```; {; ""account_name"": ""myaccount@broadinstitute.org"",; ""refresh_token"": ""refresh_token""; }; ```. Again if in RefreshToken mode, they need to be there for every workflow call or an exception will be thrown at initialization time.; If they are there they will be added to the gcloudauth.json in the same way docker crednetials are, under a ""gcloud"" value. You should then get permission to localize input files that are only accessible to this user. So depending on what is provided (docker info, user info), you can get a gcloudauth.json with both credentials, only one, or no file at all. In any case the JES backend will try to delete this file when the workflow reaches a terminal state.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/190
https://github.com/broadinstitute/cromwell/pull/193:5,Deployability,update,updated,5,"I've updated JES_STATUS too. It was initialised to """". It felt disingenuous to claim that represents a real status name so now it's explicitly None instead.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/193
https://github.com/broadinstitute/cromwell/pull/194:5,Deployability,update,updated,5,"I've updated JES_STATUS too. It was initialised to """". It felt disingenuous to claim that an empty string represents a real status name so now it's explicitly None instead.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/194
https://github.com/broadinstitute/cromwell/pull/195:315,Deployability,update,updates,315,"This is just a suggestion:. I was poking at the 1333 ticket and it made me realize that we pass around the slick `dataAccess` value as a function parameter anywhere it's needed, from the very top in `WorkflowManagerSystem` where it's created to the very bottom of `Backend` implementations where we need to make DB updates etc...; I was thinking we could pull it away from `WorkflowManagerSystem` and use it in a ""cake pattern"" way by mixing it to whatever class needs it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/195
https://github.com/broadinstitute/cromwell/pull/200:58,Testability,log,logs,58,"If running the script fails, printing out the tail of the logs.; Modified `CromwellTestkitSpec` and `SampleWdl.HelloWorld` to pass custom runtimes.; DSDEEPB-1331",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/200
https://github.com/broadinstitute/cromwell/pull/205:3,Testability,test,tests,3,No tests yet.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/205
https://github.com/broadinstitute/cromwell/pull/207:465,Modifiability,variab,variables,465,"This will allow this WDL file to run:. ```; task a {; File in; String out_name = ""out"". command {; cat ${in} > ${out_name}; }; runtime {; docker: ""kcibul/picard""; }; output {; File out = ""out""; File out_interpolation = ""${out_name}""; String contents = read_string(""${out_name}""); }; }. workflow file_passing {; File f. call a {input: in=f}; call a as b {input: in=a.out}; }; ```. This also fixes a bug where static declarations weren't being honored when resolving variables in all cases. This lead to some frustrating bugs with Yossi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/207
https://github.com/broadinstitute/cromwell/pull/215:32,Deployability,update,updateExecutionBackendInfo,32,This change does two things:; - updateExecutionBackendInfo now works correctly with sharded input; - The function no longer updates the EXECUTION table - this turned out to be unnecessary as other hooks are already updating this in full.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/215
https://github.com/broadinstitute/cromwell/pull/215:124,Deployability,update,updates,124,This change does two things:; - updateExecutionBackendInfo now works correctly with sharded input; - The function no longer updates the EXECUTION table - this turned out to be unnecessary as other hooks are already updating this in full.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/215
https://github.com/broadinstitute/cromwell/pull/225:30,Security,authenticat,authentication,30,Brand new version of Cromwell authentication process to JES.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/225
https://github.com/broadinstitute/cromwell/pull/226:70,Deployability,deploy,deploys,70,I suspect that this might be a problem (or become a problem) with our deploys,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/226
https://github.com/broadinstitute/cromwell/pull/227:84,Availability,failure,failure,84,"- Retries the creation of the `Pipeline` and `Run`; - If all retries fail, a proper failure is propagated and the call will fail",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/227
https://github.com/broadinstitute/cromwell/pull/227:31,Deployability,Pipeline,Pipeline,31,"- Retries the creation of the `Pipeline` and `Run`; - If all retries fail, a proper failure is propagated and the call will fail",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/227
https://github.com/broadinstitute/cromwell/pull/233:51,Testability,test,test,51,"Not too happy that I had to change the way the FSM test worked, but the WorkflowActor seemed to be running fine.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/233
https://github.com/broadinstitute/cromwell/pull/234:17,Integrability,wrap,wrapped,17,"Job ID no longer wrapped in an `Option`:. ```; ""three_step.ps"": [{; ""executionStatus"": ""Done"",; ""stdout"": ""gs://cromwell-dev/mlc-executions/three_step/970f7494-0ff3-4003-96c2-70c62e51ae78/call-ps/job.stdout.txt"",; ""backendStatus"": ""Success"",; ""outputs"": {; ""procs"": ""gs://cromwell-dev/mlc-executions/three_step/970f7494-0ff3-4003-96c2-70c62e51ae78/call-ps/job.stdout.txt""; },; ""inputs"": {. },; ""returnCode"": 0,; ""jobId"": ""operations/EIaox_OEKhjR54ODuIHi_fUBIMO73rS7FyoKcHJvZHVjdGlvbg"",; ""backend"": ""JES"",; ""end"": ""2015-10-09T17:16:21.000-04:00"",; ""stderr"": ""gs://cromwell-dev/mlc-executions/three_step/970f7494-0ff3-4003-96c2-70c62e51ae78/call-ps/job.stderr.txt"",; ""start"": ""2015-10-09T17:11:47.000-04:00""; }],; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/234
https://github.com/broadinstitute/cromwell/pull/240:91,Availability,failure,failures,91,"Removing a duplicate write of workflow state that seemed to be responsible for some Tyburn failures. The WorkflowActor already handles the persistence of its own state, WorkflowManagerActor doesn't need to be doing this as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/240
https://github.com/broadinstitute/cromwell/pull/250:25,Integrability,rout,routeUnwrapped,25,Added config option 'api.routeUnwrapped' to optionally allow still serving '/workflows'.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/250
https://github.com/broadinstitute/cromwell/pull/250:6,Modifiability,config,config,6,Added config option 'api.routeUnwrapped' to optionally allow still serving '/workflows'.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/250
https://github.com/broadinstitute/cromwell/pull/254:1667,Integrability,depend,depend,1667," as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not propagate messages (`setAdditive(false)`)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:1902,Integrability,message,messages,1902," as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not propagate messages (`setAdditive(false)`)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:2009,Integrability,message,messages,2009," as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not propagate messages (`setAdditive(false)`)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:18,Testability,log,log,18,"This allows for a log file per workflow, as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not pr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:79,Testability,log,log,79,"This allows for a log file per workflow, as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not pr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:131,Testability,log,logging,131,"This allows for a log file per workflow, as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not pr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:361,Testability,log,log,361,"This allows for a log file per workflow, as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not pr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:532,Testability,log,logging,532,"This allows for a log file per workflow, as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not pr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:562,Testability,log,log,562,"This allows for a log file per workflow, as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not pr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:654,Testability,log,log,654,"This allows for a log file per workflow, as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not pr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:734,Testability,log,log,734,"This allows for a log file per workflow, as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not pr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:756,Testability,log,log,756,"This allows for a log file per workflow, as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not pr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:785,Testability,log,log,785,"This allows for a log file per workflow, as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not pr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:840,Testability,log,log,840,"This allows for a log file per workflow, as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not pr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:895,Testability,log,log,895,"This allows for a log file per workflow, as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not pr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:950,Testability,log,log,950,"This allows for a log file per workflow, as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not pr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:1039,Testability,log,log,1039," as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not propagate messages (`setAdditive(false)`)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:1049,Testability,log,log,1049," as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not propagate messages (`setAdditive(false)`)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:1303,Testability,log,logback,1303," as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not propagate messages (`setAdditive(false)`)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:1346,Testability,log,logback,1346," as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not propagate messages (`setAdditive(false)`)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:1610,Testability,log,log,1610," as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not propagate messages (`setAdditive(false)`)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:1626,Testability,log,logger,1626," as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not propagate messages (`setAdditive(false)`)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:1661,Testability,test,tests,1661," as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not propagate messages (`setAdditive(false)`)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:1688,Testability,log,logger,1688," as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not propagate messages (`setAdditive(false)`)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:1718,Testability,log,logger,1718," as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not propagate messages (`setAdditive(false)`)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:1727,Testability,log,logback,1727," as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not propagate messages (`setAdditive(false)`)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:1750,Testability,log,logger,1750," as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not propagate messages (`setAdditive(false)`)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:1813,Testability,log,logger,1813," as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not propagate messages (`setAdditive(false)`)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:1837,Testability,log,logger,1837," as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not propagate messages (`setAdditive(false)`)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:1866,Testability,log,logger,1866," as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not propagate messages (`setAdditive(false)`)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:1958,Testability,log,logger,1958," as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not propagate messages (`setAdditive(false)`)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/254:1978,Testability,log,logger,1978," as well as the ability to specify the log root. This also allows for both stdout and file-logging simultaneously. This will allow us to have an API endpoint which just reads this the particular file for the workflow and sends it back over HTTP. Cromwell now accepts three Java Properties:; - `LOG_ROOT` - location where log files go (default `.`); - `LOG_MODE` - `server`, `console`, or `server,console` (default `console`); - `LOG_LEVEL` - info, debug, etc (default `info`). **Standard out logging and the main Cromwell log were not changed by this PR**. If the command `sbt -DLOG_MODE=server,console -DLOG_ROOT=log ""run run 3step.wdl 3step.json""` were run three times, we'd see this in the `log` directory:. ```; log; ├── cromwell.2015-10-26.log; ├── workflow.319df202-a60f-47c8-b886-bd4821747c68.log; ├── workflow.36e07688-9e47-45bd-9930-aff58471541e.log; └── workflow.7dad065d-9d7a-4450-91c8-1f7ece184851.log; ```. FAQ:. > Scott, why did you not use the `application.conf` file for things like log root, log mode? Seems obvious, right?. Glad you asked. I tried, for a very long time, to allow for the values to be set in `application.conf`. However, I was unable to get it to work. It seems that by querying for a value in `application.conf`, it causes the `logback.xml` to be read and processed. The logback.xml file does not recognize values in `application.conf` natively, it must have Java Properties set. > What the hell were you thinking with the `WorkflowLogger` class?. I'd be very happy to discuss how to do this better. The problem is this:; - We need to log to the Akka logger whenever we can because the tests depend on it; - Akka logger descends from the root logger (`logback.xml`); - A new logger needs to be created for each workflow.; - Both the Akka logger and the workflow logger descend from the root logger so they both can't propagate messages or we'll get doubles of everything in the root logger.; - Workflow logger is set to not propagate messages (`setAdditive(false)`)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/254
https://github.com/broadinstitute/cromwell/pull/264:191,Performance,concurren,concurrent,191,"Note this is based on the JES restarts branch; that will need to get merged first and I have to make sure that's still okay after all the rebasing I've done there. I was able to run about 70 concurrent Hello Worlds on JES without any Cromwell issues, though I did see some oddities I suspect could be JES issues: lots of Running -> Initializing transitions, and some nearly 30 minute turnaround times for Hello World.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/264
https://github.com/broadinstitute/cromwell/pull/265:184,Availability,error,error,184,"Using `better.files` for metadata writing, and removed heaviest duplicated `FileUtil` similarity.; Refactored `Main` to avoid test issues with `DelayedInit`, `System.exit`, consistent error generation, etc.; Removed blocking code from `SingleWorkflowRunnerActor`, and passing `Shutdown` as message now, instead of killing system directly.; Reused / refactored some of the test methods for actors, and removed bitrotted `DefaultWorkflowManagerActor`.; Left comments (warnings?) about possible bugs / improvements to workflow `Actor` messaging.; Replaced use of Java `SystemProperties` with Scala `sys.props`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/265
https://github.com/broadinstitute/cromwell/pull/265:290,Integrability,message,message,290,"Using `better.files` for metadata writing, and removed heaviest duplicated `FileUtil` similarity.; Refactored `Main` to avoid test issues with `DelayedInit`, `System.exit`, consistent error generation, etc.; Removed blocking code from `SingleWorkflowRunnerActor`, and passing `Shutdown` as message now, instead of killing system directly.; Reused / refactored some of the test methods for actors, and removed bitrotted `DefaultWorkflowManagerActor`.; Left comments (warnings?) about possible bugs / improvements to workflow `Actor` messaging.; Replaced use of Java `SystemProperties` with Scala `sys.props`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/265
https://github.com/broadinstitute/cromwell/pull/265:99,Modifiability,Refactor,Refactored,99,"Using `better.files` for metadata writing, and removed heaviest duplicated `FileUtil` similarity.; Refactored `Main` to avoid test issues with `DelayedInit`, `System.exit`, consistent error generation, etc.; Removed blocking code from `SingleWorkflowRunnerActor`, and passing `Shutdown` as message now, instead of killing system directly.; Reused / refactored some of the test methods for actors, and removed bitrotted `DefaultWorkflowManagerActor`.; Left comments (warnings?) about possible bugs / improvements to workflow `Actor` messaging.; Replaced use of Java `SystemProperties` with Scala `sys.props`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/265
https://github.com/broadinstitute/cromwell/pull/265:349,Modifiability,refactor,refactored,349,"Using `better.files` for metadata writing, and removed heaviest duplicated `FileUtil` similarity.; Refactored `Main` to avoid test issues with `DelayedInit`, `System.exit`, consistent error generation, etc.; Removed blocking code from `SingleWorkflowRunnerActor`, and passing `Shutdown` as message now, instead of killing system directly.; Reused / refactored some of the test methods for actors, and removed bitrotted `DefaultWorkflowManagerActor`.; Left comments (warnings?) about possible bugs / improvements to workflow `Actor` messaging.; Replaced use of Java `SystemProperties` with Scala `sys.props`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/265
https://github.com/broadinstitute/cromwell/pull/265:120,Safety,avoid,avoid,120,"Using `better.files` for metadata writing, and removed heaviest duplicated `FileUtil` similarity.; Refactored `Main` to avoid test issues with `DelayedInit`, `System.exit`, consistent error generation, etc.; Removed blocking code from `SingleWorkflowRunnerActor`, and passing `Shutdown` as message now, instead of killing system directly.; Reused / refactored some of the test methods for actors, and removed bitrotted `DefaultWorkflowManagerActor`.; Left comments (warnings?) about possible bugs / improvements to workflow `Actor` messaging.; Replaced use of Java `SystemProperties` with Scala `sys.props`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/265
https://github.com/broadinstitute/cromwell/pull/265:126,Testability,test,test,126,"Using `better.files` for metadata writing, and removed heaviest duplicated `FileUtil` similarity.; Refactored `Main` to avoid test issues with `DelayedInit`, `System.exit`, consistent error generation, etc.; Removed blocking code from `SingleWorkflowRunnerActor`, and passing `Shutdown` as message now, instead of killing system directly.; Reused / refactored some of the test methods for actors, and removed bitrotted `DefaultWorkflowManagerActor`.; Left comments (warnings?) about possible bugs / improvements to workflow `Actor` messaging.; Replaced use of Java `SystemProperties` with Scala `sys.props`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/265
https://github.com/broadinstitute/cromwell/pull/265:372,Testability,test,test,372,"Using `better.files` for metadata writing, and removed heaviest duplicated `FileUtil` similarity.; Refactored `Main` to avoid test issues with `DelayedInit`, `System.exit`, consistent error generation, etc.; Removed blocking code from `SingleWorkflowRunnerActor`, and passing `Shutdown` as message now, instead of killing system directly.; Reused / refactored some of the test methods for actors, and removed bitrotted `DefaultWorkflowManagerActor`.; Left comments (warnings?) about possible bugs / improvements to workflow `Actor` messaging.; Replaced use of Java `SystemProperties` with Scala `sys.props`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/265
https://github.com/broadinstitute/cromwell/pull/270:4,Testability,log,logging,4,…er logging for server mode. Make console logging report the thread name like the ex-server logging since console is now default for server mode,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/270
https://github.com/broadinstitute/cromwell/pull/270:42,Testability,log,logging,42,…er logging for server mode. Make console logging report the thread name like the ex-server logging since console is now default for server mode,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/270
https://github.com/broadinstitute/cromwell/pull/270:92,Testability,log,logging,92,…er logging for server mode. Make console logging report the thread name like the ex-server logging since console is now default for server mode,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/270
https://github.com/broadinstitute/cromwell/pull/276:38,Safety,Avoid,Avoidance,38,Added the new database tables for Job Avoidance. It may be better to do all Avoidance work in a branch rather than merging into DEVELOP one piece at a time.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/276
https://github.com/broadinstitute/cromwell/pull/276:76,Safety,Avoid,Avoidance,76,Added the new database tables for Job Avoidance. It may be better to do all Avoidance work in a branch rather than merging into DEVELOP one piece at a time.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/276
https://github.com/broadinstitute/cromwell/pull/277:74,Energy Efficiency,charge,charge,74,"5 Await.results removed for DSDEEPB-1549, fixes DSDEEPB-1631 for no extra charge.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/277
https://github.com/broadinstitute/cromwell/pull/284:19,Safety,avoid,avoidance,19,"This makes the job-avoidance conf really optional.; Also fixed a small bug when you don't specify the path for inputs, the default one was not correct.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/284
https://github.com/broadinstitute/cromwell/pull/291:209,Modifiability,refactor,refactor,209,…age information. Practically non-existent comments.; Tests are incomplete / non-unit tests. May mock out a true client.; Google authentication not pulled from credentials. TODO: look at JES client auth.; May refactor location / names of classes.; Typoes.; Etc.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/291
https://github.com/broadinstitute/cromwell/pull/291:129,Security,authenticat,authentication,129,…age information. Practically non-existent comments.; Tests are incomplete / non-unit tests. May mock out a true client.; Google authentication not pulled from credentials. TODO: look at JES client auth.; May refactor location / names of classes.; Typoes.; Etc.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/291
https://github.com/broadinstitute/cromwell/pull/291:54,Testability,Test,Tests,54,…age information. Practically non-existent comments.; Tests are incomplete / non-unit tests. May mock out a true client.; Google authentication not pulled from credentials. TODO: look at JES client auth.; May refactor location / names of classes.; Typoes.; Etc.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/291
https://github.com/broadinstitute/cromwell/pull/291:86,Testability,test,tests,86,…age information. Practically non-existent comments.; Tests are incomplete / non-unit tests. May mock out a true client.; Google authentication not pulled from credentials. TODO: look at JES client auth.; May refactor location / names of classes.; Typoes.; Etc.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/291
https://github.com/broadinstitute/cromwell/pull/291:97,Testability,mock,mock,97,…age information. Practically non-existent comments.; Tests are incomplete / non-unit tests. May mock out a true client.; Google authentication not pulled from credentials. TODO: look at JES client auth.; May refactor location / names of classes.; Typoes.; Etc.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/291
https://github.com/broadinstitute/cromwell/pull/294:55,Availability,error,error,55,"DSDEEPB-2026 Fixes Akka logging. The invocation of the error method flipped the arguments such that the exception was thrown away, the other methods don't accept an exception which also effectively threw away the exception. Below is what it looks like on current develop when an exception is thrown away. The Akka formatter realizes it has more substitution arguments than it is able to substitute. WorkflowActor [UUID(8ae8f57a)]: Failed to transition workflow status from Submitted to Failed WARNING arguments left: 1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/294
https://github.com/broadinstitute/cromwell/pull/294:24,Testability,log,logging,24,"DSDEEPB-2026 Fixes Akka logging. The invocation of the error method flipped the arguments such that the exception was thrown away, the other methods don't accept an exception which also effectively threw away the exception. Below is what it looks like on current develop when an exception is thrown away. The Akka formatter realizes it has more substitution arguments than it is able to substitute. WorkflowActor [UUID(8ae8f57a)]: Failed to transition workflow status from Submitted to Failed WARNING arguments left: 1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/294
https://github.com/broadinstitute/cromwell/pull/295:174,Deployability,configurat,configuration,174,This reworks the JES Authentication schema in such a way that:; - All JES calls (launching a VM) are requested using the Cromwell Service Account (CSA) passed in through the configuration.; - The upload / delete of the authentication file to GCS is also done using CSA.; - All other GCS interactions are done using the user's credentials (with refresh token coming from WF options + clientID/secrets in the conf).; - a `billing_bucket` workflow option has been added that sets the gcs path where cromwell will write the auth.json file,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/295
https://github.com/broadinstitute/cromwell/pull/295:174,Modifiability,config,configuration,174,This reworks the JES Authentication schema in such a way that:; - All JES calls (launching a VM) are requested using the Cromwell Service Account (CSA) passed in through the configuration.; - The upload / delete of the authentication file to GCS is also done using CSA.; - All other GCS interactions are done using the user's credentials (with refresh token coming from WF options + clientID/secrets in the conf).; - a `billing_bucket` workflow option has been added that sets the gcs path where cromwell will write the auth.json file,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/295
https://github.com/broadinstitute/cromwell/pull/295:21,Security,Authenticat,Authentication,21,This reworks the JES Authentication schema in such a way that:; - All JES calls (launching a VM) are requested using the Cromwell Service Account (CSA) passed in through the configuration.; - The upload / delete of the authentication file to GCS is also done using CSA.; - All other GCS interactions are done using the user's credentials (with refresh token coming from WF options + clientID/secrets in the conf).; - a `billing_bucket` workflow option has been added that sets the gcs path where cromwell will write the auth.json file,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/295
https://github.com/broadinstitute/cromwell/pull/295:219,Security,authenticat,authentication,219,This reworks the JES Authentication schema in such a way that:; - All JES calls (launching a VM) are requested using the Cromwell Service Account (CSA) passed in through the configuration.; - The upload / delete of the authentication file to GCS is also done using CSA.; - All other GCS interactions are done using the user's credentials (with refresh token coming from WF options + clientID/secrets in the conf).; - a `billing_bucket` workflow option has been added that sets the gcs path where cromwell will write the auth.json file,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/295
https://github.com/broadinstitute/cromwell/pull/303:33,Modifiability,refactor,refactoring,33,"Probably mixed up the name while refactoring, the log path needs to be a file path (ie gs://balblabl/jes.log) for JES to use it as a filename when delocalizing its logs.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/303
https://github.com/broadinstitute/cromwell/pull/303:50,Testability,log,log,50,"Probably mixed up the name while refactoring, the log path needs to be a file path (ie gs://balblabl/jes.log) for JES to use it as a filename when delocalizing its logs.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/303
https://github.com/broadinstitute/cromwell/pull/303:105,Testability,log,log,105,"Probably mixed up the name while refactoring, the log path needs to be a file path (ie gs://balblabl/jes.log) for JES to use it as a filename when delocalizing its logs.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/303
https://github.com/broadinstitute/cromwell/pull/303:164,Testability,log,logs,164,"Probably mixed up the name while refactoring, the log path needs to be a file path (ie gs://balblabl/jes.log) for JES to use it as a filename when delocalizing its logs.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/303
https://github.com/broadinstitute/cromwell/pull/305:311,Availability,echo,echo,311,"This is an attempt to make the separation between (JES / Local / SGE) and File systems (GCS, SharedFilesystem) more obvious. It enables implementation of more Backend / File systems combinations.; For example this wdl runs, on a Local cromwell instance :; Wdl: . ```; task hello {; String addressee; command {; echo ""Hello ${addressee}!""; }; output {; String fileoutput = read_string(stdout()); String salutation = read_string(""gs://tjeandet/wdl_input_public.txt""); }; }. workflow hello {; File infile; String instring = read_string(infile); call hello {input: addressee = instring}; }; ```. Inputs:. ```; {; ""hello.infile"": ""gs://tjeandet/wdl_input_public.txt""; }; ```. It also works with user-defined authentication for GCS (refresh token).; More tests / cleaning is needed before it's reviewable but I wanted to put it out there before Thanksgiving.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/305
https://github.com/broadinstitute/cromwell/pull/305:703,Security,authenticat,authentication,703,"This is an attempt to make the separation between (JES / Local / SGE) and File systems (GCS, SharedFilesystem) more obvious. It enables implementation of more Backend / File systems combinations.; For example this wdl runs, on a Local cromwell instance :; Wdl: . ```; task hello {; String addressee; command {; echo ""Hello ${addressee}!""; }; output {; String fileoutput = read_string(stdout()); String salutation = read_string(""gs://tjeandet/wdl_input_public.txt""); }; }. workflow hello {; File infile; String instring = read_string(infile); call hello {input: addressee = instring}; }; ```. Inputs:. ```; {; ""hello.infile"": ""gs://tjeandet/wdl_input_public.txt""; }; ```. It also works with user-defined authentication for GCS (refresh token).; More tests / cleaning is needed before it's reviewable but I wanted to put it out there before Thanksgiving.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/305
https://github.com/broadinstitute/cromwell/pull/305:749,Testability,test,tests,749,"This is an attempt to make the separation between (JES / Local / SGE) and File systems (GCS, SharedFilesystem) more obvious. It enables implementation of more Backend / File systems combinations.; For example this wdl runs, on a Local cromwell instance :; Wdl: . ```; task hello {; String addressee; command {; echo ""Hello ${addressee}!""; }; output {; String fileoutput = read_string(stdout()); String salutation = read_string(""gs://tjeandet/wdl_input_public.txt""); }; }. workflow hello {; File infile; String instring = read_string(infile); call hello {input: addressee = instring}; }; ```. Inputs:. ```; {; ""hello.infile"": ""gs://tjeandet/wdl_input_public.txt""; }; ```. It also works with user-defined authentication for GCS (refresh token).; More tests / cleaning is needed before it's reviewable but I wanted to put it out there before Thanksgiving.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/305
https://github.com/broadinstitute/cromwell/pull/311:225,Availability,down,down,225,"Lots of changes to `SingleWorkflowRunnerActor`:; - Clients communicate with SWRA via an ask, giving callers like `Main` a `Future` whose success status can be used to generate an exit code.; - SWRA no longer manages shutting down the actor system, that becomes the responsibility of the caller. This allows tests that want to see certain error messages to shut down the system only after the error messages are seen by an event filter. The previous structure allowed for a race condition where messages that filters wanted to see were produced, but the actor system was torn down before the messages were delivered to the filters.; - SWRA is now an FSM. Also increased the default patience in `CromwellTestkitSpec` for `InputLocalizationWorkflowSpec` and friends. Does _not_ include any changes to address MySQL connection issues sporadically seen in SlickDataAccessSpec; per discussion with Jeff I'll ticket that separately.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/311
https://github.com/broadinstitute/cromwell/pull/311:338,Availability,error,error,338,"Lots of changes to `SingleWorkflowRunnerActor`:; - Clients communicate with SWRA via an ask, giving callers like `Main` a `Future` whose success status can be used to generate an exit code.; - SWRA no longer manages shutting down the actor system, that becomes the responsibility of the caller. This allows tests that want to see certain error messages to shut down the system only after the error messages are seen by an event filter. The previous structure allowed for a race condition where messages that filters wanted to see were produced, but the actor system was torn down before the messages were delivered to the filters.; - SWRA is now an FSM. Also increased the default patience in `CromwellTestkitSpec` for `InputLocalizationWorkflowSpec` and friends. Does _not_ include any changes to address MySQL connection issues sporadically seen in SlickDataAccessSpec; per discussion with Jeff I'll ticket that separately.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/311
https://github.com/broadinstitute/cromwell/pull/311:361,Availability,down,down,361,"Lots of changes to `SingleWorkflowRunnerActor`:; - Clients communicate with SWRA via an ask, giving callers like `Main` a `Future` whose success status can be used to generate an exit code.; - SWRA no longer manages shutting down the actor system, that becomes the responsibility of the caller. This allows tests that want to see certain error messages to shut down the system only after the error messages are seen by an event filter. The previous structure allowed for a race condition where messages that filters wanted to see were produced, but the actor system was torn down before the messages were delivered to the filters.; - SWRA is now an FSM. Also increased the default patience in `CromwellTestkitSpec` for `InputLocalizationWorkflowSpec` and friends. Does _not_ include any changes to address MySQL connection issues sporadically seen in SlickDataAccessSpec; per discussion with Jeff I'll ticket that separately.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/311
https://github.com/broadinstitute/cromwell/pull/311:392,Availability,error,error,392,"Lots of changes to `SingleWorkflowRunnerActor`:; - Clients communicate with SWRA via an ask, giving callers like `Main` a `Future` whose success status can be used to generate an exit code.; - SWRA no longer manages shutting down the actor system, that becomes the responsibility of the caller. This allows tests that want to see certain error messages to shut down the system only after the error messages are seen by an event filter. The previous structure allowed for a race condition where messages that filters wanted to see were produced, but the actor system was torn down before the messages were delivered to the filters.; - SWRA is now an FSM. Also increased the default patience in `CromwellTestkitSpec` for `InputLocalizationWorkflowSpec` and friends. Does _not_ include any changes to address MySQL connection issues sporadically seen in SlickDataAccessSpec; per discussion with Jeff I'll ticket that separately.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/311
https://github.com/broadinstitute/cromwell/pull/311:575,Availability,down,down,575,"Lots of changes to `SingleWorkflowRunnerActor`:; - Clients communicate with SWRA via an ask, giving callers like `Main` a `Future` whose success status can be used to generate an exit code.; - SWRA no longer manages shutting down the actor system, that becomes the responsibility of the caller. This allows tests that want to see certain error messages to shut down the system only after the error messages are seen by an event filter. The previous structure allowed for a race condition where messages that filters wanted to see were produced, but the actor system was torn down before the messages were delivered to the filters.; - SWRA is now an FSM. Also increased the default patience in `CromwellTestkitSpec` for `InputLocalizationWorkflowSpec` and friends. Does _not_ include any changes to address MySQL connection issues sporadically seen in SlickDataAccessSpec; per discussion with Jeff I'll ticket that separately.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/311
https://github.com/broadinstitute/cromwell/pull/311:344,Integrability,message,messages,344,"Lots of changes to `SingleWorkflowRunnerActor`:; - Clients communicate with SWRA via an ask, giving callers like `Main` a `Future` whose success status can be used to generate an exit code.; - SWRA no longer manages shutting down the actor system, that becomes the responsibility of the caller. This allows tests that want to see certain error messages to shut down the system only after the error messages are seen by an event filter. The previous structure allowed for a race condition where messages that filters wanted to see were produced, but the actor system was torn down before the messages were delivered to the filters.; - SWRA is now an FSM. Also increased the default patience in `CromwellTestkitSpec` for `InputLocalizationWorkflowSpec` and friends. Does _not_ include any changes to address MySQL connection issues sporadically seen in SlickDataAccessSpec; per discussion with Jeff I'll ticket that separately.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/311
https://github.com/broadinstitute/cromwell/pull/311:398,Integrability,message,messages,398,"Lots of changes to `SingleWorkflowRunnerActor`:; - Clients communicate with SWRA via an ask, giving callers like `Main` a `Future` whose success status can be used to generate an exit code.; - SWRA no longer manages shutting down the actor system, that becomes the responsibility of the caller. This allows tests that want to see certain error messages to shut down the system only after the error messages are seen by an event filter. The previous structure allowed for a race condition where messages that filters wanted to see were produced, but the actor system was torn down before the messages were delivered to the filters.; - SWRA is now an FSM. Also increased the default patience in `CromwellTestkitSpec` for `InputLocalizationWorkflowSpec` and friends. Does _not_ include any changes to address MySQL connection issues sporadically seen in SlickDataAccessSpec; per discussion with Jeff I'll ticket that separately.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/311
https://github.com/broadinstitute/cromwell/pull/311:494,Integrability,message,messages,494,"Lots of changes to `SingleWorkflowRunnerActor`:; - Clients communicate with SWRA via an ask, giving callers like `Main` a `Future` whose success status can be used to generate an exit code.; - SWRA no longer manages shutting down the actor system, that becomes the responsibility of the caller. This allows tests that want to see certain error messages to shut down the system only after the error messages are seen by an event filter. The previous structure allowed for a race condition where messages that filters wanted to see were produced, but the actor system was torn down before the messages were delivered to the filters.; - SWRA is now an FSM. Also increased the default patience in `CromwellTestkitSpec` for `InputLocalizationWorkflowSpec` and friends. Does _not_ include any changes to address MySQL connection issues sporadically seen in SlickDataAccessSpec; per discussion with Jeff I'll ticket that separately.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/311
https://github.com/broadinstitute/cromwell/pull/311:591,Integrability,message,messages,591,"Lots of changes to `SingleWorkflowRunnerActor`:; - Clients communicate with SWRA via an ask, giving callers like `Main` a `Future` whose success status can be used to generate an exit code.; - SWRA no longer manages shutting down the actor system, that becomes the responsibility of the caller. This allows tests that want to see certain error messages to shut down the system only after the error messages are seen by an event filter. The previous structure allowed for a race condition where messages that filters wanted to see were produced, but the actor system was torn down before the messages were delivered to the filters.; - SWRA is now an FSM. Also increased the default patience in `CromwellTestkitSpec` for `InputLocalizationWorkflowSpec` and friends. Does _not_ include any changes to address MySQL connection issues sporadically seen in SlickDataAccessSpec; per discussion with Jeff I'll ticket that separately.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/311
https://github.com/broadinstitute/cromwell/pull/311:473,Performance,race condition,race condition,473,"Lots of changes to `SingleWorkflowRunnerActor`:; - Clients communicate with SWRA via an ask, giving callers like `Main` a `Future` whose success status can be used to generate an exit code.; - SWRA no longer manages shutting down the actor system, that becomes the responsibility of the caller. This allows tests that want to see certain error messages to shut down the system only after the error messages are seen by an event filter. The previous structure allowed for a race condition where messages that filters wanted to see were produced, but the actor system was torn down before the messages were delivered to the filters.; - SWRA is now an FSM. Also increased the default patience in `CromwellTestkitSpec` for `InputLocalizationWorkflowSpec` and friends. Does _not_ include any changes to address MySQL connection issues sporadically seen in SlickDataAccessSpec; per discussion with Jeff I'll ticket that separately.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/311
https://github.com/broadinstitute/cromwell/pull/311:307,Testability,test,tests,307,"Lots of changes to `SingleWorkflowRunnerActor`:; - Clients communicate with SWRA via an ask, giving callers like `Main` a `Future` whose success status can be used to generate an exit code.; - SWRA no longer manages shutting down the actor system, that becomes the responsibility of the caller. This allows tests that want to see certain error messages to shut down the system only after the error messages are seen by an event filter. The previous structure allowed for a race condition where messages that filters wanted to see were produced, but the actor system was torn down before the messages were delivered to the filters.; - SWRA is now an FSM. Also increased the default patience in `CromwellTestkitSpec` for `InputLocalizationWorkflowSpec` and friends. Does _not_ include any changes to address MySQL connection issues sporadically seen in SlickDataAccessSpec; per discussion with Jeff I'll ticket that separately.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/311
https://github.com/broadinstitute/cromwell/pull/313:215,Availability,error,errors,215,"Submitting a workflow with wrong credentials (eg invalid refresh token) triggers retries which are bound to fail and are significantly delaying the response from JesBackend, which in turn seems to lead to 502 proxy errors.; This might not be the only cause of this error but when submitting a few workflow with wrong token there was a flood of retries in cromwell logs which probably slows everything down.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/313
https://github.com/broadinstitute/cromwell/pull/313:265,Availability,error,error,265,"Submitting a workflow with wrong credentials (eg invalid refresh token) triggers retries which are bound to fail and are significantly delaying the response from JesBackend, which in turn seems to lead to 502 proxy errors.; This might not be the only cause of this error but when submitting a few workflow with wrong token there was a flood of retries in cromwell logs which probably slows everything down.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/313
https://github.com/broadinstitute/cromwell/pull/313:401,Availability,down,down,401,"Submitting a workflow with wrong credentials (eg invalid refresh token) triggers retries which are bound to fail and are significantly delaying the response from JesBackend, which in turn seems to lead to 502 proxy errors.; This might not be the only cause of this error but when submitting a few workflow with wrong token there was a flood of retries in cromwell logs which probably slows everything down.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/313
https://github.com/broadinstitute/cromwell/pull/313:364,Testability,log,logs,364,"Submitting a workflow with wrong credentials (eg invalid refresh token) triggers retries which are bound to fail and are significantly delaying the response from JesBackend, which in turn seems to lead to 502 proxy errors.; This might not be the only cause of this error but when submitting a few workflow with wrong token there was a flood of retries in cromwell logs which probably slows everything down.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/313
https://github.com/broadinstitute/cromwell/pull/319:382,Availability,failure,failures,382,"After this morning's discussion of Cromwell's memory usage I poked around the Travis docs and found the container infrastructure on which we were running gave us only 4 GB:. https://docs.travis-ci.com/user/ci-environment. Also on this page is mentioned the new Trusty Tahr beta environment which offers 7.5 GB. I've tried this and have seen no intermittent SlickDataAccess or other failures. As a bonus this is a real VM (not a container) and can run all of our Docker tests. The one gotcha I've found is that these builds don't start as quickly as the container builds, but if this delay remains reasonable it may be worth trading some lag for stability and Docker coverage. There were some additional changes required to the Travis YAML to add MySQL as that's not baked into Trusty, and I also had to pull the ubuntu:latest image in advance to keep the first Docker test from timing out. There was also a bit of weirdness with files not globbing in alphabetical order which broke a test.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/319
https://github.com/broadinstitute/cromwell/pull/319:469,Testability,test,tests,469,"After this morning's discussion of Cromwell's memory usage I poked around the Travis docs and found the container infrastructure on which we were running gave us only 4 GB:. https://docs.travis-ci.com/user/ci-environment. Also on this page is mentioned the new Trusty Tahr beta environment which offers 7.5 GB. I've tried this and have seen no intermittent SlickDataAccess or other failures. As a bonus this is a real VM (not a container) and can run all of our Docker tests. The one gotcha I've found is that these builds don't start as quickly as the container builds, but if this delay remains reasonable it may be worth trading some lag for stability and Docker coverage. There were some additional changes required to the Travis YAML to add MySQL as that's not baked into Trusty, and I also had to pull the ubuntu:latest image in advance to keep the first Docker test from timing out. There was also a bit of weirdness with files not globbing in alphabetical order which broke a test.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/319
https://github.com/broadinstitute/cromwell/pull/319:868,Testability,test,test,868,"After this morning's discussion of Cromwell's memory usage I poked around the Travis docs and found the container infrastructure on which we were running gave us only 4 GB:. https://docs.travis-ci.com/user/ci-environment. Also on this page is mentioned the new Trusty Tahr beta environment which offers 7.5 GB. I've tried this and have seen no intermittent SlickDataAccess or other failures. As a bonus this is a real VM (not a container) and can run all of our Docker tests. The one gotcha I've found is that these builds don't start as quickly as the container builds, but if this delay remains reasonable it may be worth trading some lag for stability and Docker coverage. There were some additional changes required to the Travis YAML to add MySQL as that's not baked into Trusty, and I also had to pull the ubuntu:latest image in advance to keep the first Docker test from timing out. There was also a bit of weirdness with files not globbing in alphabetical order which broke a test.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/319
https://github.com/broadinstitute/cromwell/pull/319:984,Testability,test,test,984,"After this morning's discussion of Cromwell's memory usage I poked around the Travis docs and found the container infrastructure on which we were running gave us only 4 GB:. https://docs.travis-ci.com/user/ci-environment. Also on this page is mentioned the new Trusty Tahr beta environment which offers 7.5 GB. I've tried this and have seen no intermittent SlickDataAccess or other failures. As a bonus this is a real VM (not a container) and can run all of our Docker tests. The one gotcha I've found is that these builds don't start as quickly as the container builds, but if this delay remains reasonable it may be worth trading some lag for stability and Docker coverage. There were some additional changes required to the Travis YAML to add MySQL as that's not baked into Trusty, and I also had to pull the ubuntu:latest image in advance to keep the first Docker test from timing out. There was also a bit of weirdness with files not globbing in alphabetical order which broke a test.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/319
https://github.com/broadinstitute/cromwell/pull/320:219,Deployability,configurat,configuration,219,"…t specified. Instead of failing if there is no ""auth_bucket"" in the workflow options, fallback to the workflow execution directory.; This also fix a bug where the auth file would not be uploaded if we only have docker configuration but no refresh token / auth_bucket option.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/320
https://github.com/broadinstitute/cromwell/pull/320:219,Modifiability,config,configuration,219,"…t specified. Instead of failing if there is no ""auth_bucket"" in the workflow options, fallback to the workflow execution directory.; This also fix a bug where the auth file would not be uploaded if we only have docker configuration but no refresh token / auth_bucket option.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/320
https://github.com/broadinstitute/cromwell/pull/322:97,Testability,test,tests,97,"Given the current implemention of `actorSystem` in `Backend`, it's not a great sign that all the tests are passing. :frowning:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/322
https://github.com/broadinstitute/cromwell/pull/326:140,Deployability,update,update,140,"Triggered by investigation of DSDEEPB-1934. This caused problems in the past but I was unable to recreate a situation where a backend would update an abort function mid-call. Even if our backends no longer update abort functions mid-call, there's no reason not to allow it for potential future backends.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/326
https://github.com/broadinstitute/cromwell/pull/326:206,Deployability,update,update,206,"Triggered by investigation of DSDEEPB-1934. This caused problems in the past but I was unable to recreate a situation where a backend would update an abort function mid-call. Even if our backends no longer update abort functions mid-call, there's no reason not to allow it for potential future backends.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/326
https://github.com/broadinstitute/cromwell/pull/326:150,Safety,abort,abort,150,"Triggered by investigation of DSDEEPB-1934. This caused problems in the past but I was unable to recreate a situation where a backend would update an abort function mid-call. Even if our backends no longer update abort functions mid-call, there's no reason not to allow it for potential future backends.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/326
https://github.com/broadinstitute/cromwell/pull/326:213,Safety,abort,abort,213,"Triggered by investigation of DSDEEPB-1934. This caused problems in the past but I was unable to recreate a situation where a backend would update an abort function mid-call. Even if our backends no longer update abort functions mid-call, there's no reason not to allow it for potential future backends.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/326
https://github.com/broadinstitute/cromwell/pull/329:90,Security,authenticat,authenticate,90,…efault Credentials. This is especially useful when running on a GCE VM when you want to. authenticate with the standard compute service account.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/329
https://github.com/broadinstitute/cromwell/issues/334:141,Availability,error,error,141,"Hi,. I'm trying to run through the Hello World example. I'm running Cromwell on OS X with Java 8. Any ideas on how to troubleshoot the below error?. Thanks!. ```; › cromwell run hello.wdl hello.json; [2015-12-18 08:43:13,222] [info] Slf4jLogger started; [2015-12-18 08:43:13,335] [info] Default backend: LOCAL; [2015-12-18 08:43:13,335] [info] RUN sub-command; [2015-12-18 08:43:13,336] [info] WDL file: hello.wdl; [2015-12-18 08:43:13,439] [info] Inputs: hello.json; [2015-12-18 08:43:13,560] [info] input: test.hello.name => ""world""; [2015-12-18 08:43:13,776] [info] SingleWorkflowRunnerActor: launching workflow; [2015-12-18 08:43:15,936] [info] Running with database db.url = jdbc:hsqldb:mem:86473284-494c-43d2-94fd-d00107a2a787;shutdown=false;hsqldb.tx=mvcc; [2015-12-18 08:43:17,516] [info] WorkflowManagerActor submitWorkflow input id = None, effective id = e67af113-c3a7-41f4-9178-6640c1c652e9; [2015-12-18 08:43:17,592] [info] WorkflowManagerActor Found no workflows to restart.; [2015-12-18 08:43:18,816] [error] SingleWorkflowRunnerActor: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; akka.pattern.AskTimeoutException: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; at akka.pattern.PromiseActorRef$$anonfun$1.apply$mcV$sp(AskSupport.scala:334); at akka.actor.Scheduler$$anon$7.run(Scheduler.scala:117); at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:599); at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:109); at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:597); at akka.actor.LightArrayRevolverScheduler$TaskHolder.executeTask(Scheduler.scala:467); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.sca",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:1016,Availability,error,error,1016,"ell on OS X with Java 8. Any ideas on how to troubleshoot the below error?. Thanks!. ```; › cromwell run hello.wdl hello.json; [2015-12-18 08:43:13,222] [info] Slf4jLogger started; [2015-12-18 08:43:13,335] [info] Default backend: LOCAL; [2015-12-18 08:43:13,335] [info] RUN sub-command; [2015-12-18 08:43:13,336] [info] WDL file: hello.wdl; [2015-12-18 08:43:13,439] [info] Inputs: hello.json; [2015-12-18 08:43:13,560] [info] input: test.hello.name => ""world""; [2015-12-18 08:43:13,776] [info] SingleWorkflowRunnerActor: launching workflow; [2015-12-18 08:43:15,936] [info] Running with database db.url = jdbc:hsqldb:mem:86473284-494c-43d2-94fd-d00107a2a787;shutdown=false;hsqldb.tx=mvcc; [2015-12-18 08:43:17,516] [info] WorkflowManagerActor submitWorkflow input id = None, effective id = e67af113-c3a7-41f4-9178-6640c1c652e9; [2015-12-18 08:43:17,592] [info] WorkflowManagerActor Found no workflows to restart.; [2015-12-18 08:43:18,816] [error] SingleWorkflowRunnerActor: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; akka.pattern.AskTimeoutException: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; at akka.pattern.PromiseActorRef$$anonfun$1.apply$mcV$sp(AskSupport.scala:334); at akka.actor.Scheduler$$anon$7.run(Scheduler.scala:117); at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:599); at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:109); at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:597); at akka.actor.LightArrayRevolverScheduler$TaskHolder.executeTask(Scheduler.scala:467); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:2552,Availability,Failure,Failure,2552,"ure$InternalCallbackExecutor$.execute(Future.scala:597); at akka.actor.LightArrayRevolverScheduler$TaskHolder.executeTask(Scheduler.scala:467); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:245); at scala.util.Success$$anonfun$map$1.apply(Try.scala:237); at scala.util.Try$.apply(Try.scala:192); at scala.util.Success.map(Try.scala:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:2896,Availability,error,error,2896,"a.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:245); at scala.util.Success$$anonfun$map$1.apply(Try.scala:237); at scala.util.Try$.apply(Try.scala:192); at scala.util.Success.map(Try.scala:237); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121); at scala.co",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:2399,Deployability,configurat,configuration,2399,"duler$$anon$7.run(Scheduler.scala:117); at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:599); at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:109); at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:597); at akka.actor.LightArrayRevolverScheduler$TaskHolder.executeTask(Scheduler.scala:467); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:2776,Deployability,configurat,configuration,2776,"t akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:245); at scala.util.Success$$anonfun$map$1.apply(Try.scala:237); at scala.util.Try$.apply(Try.scala:192); at scala.util.Success.map(Try.scala:237); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at sc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:1385,Energy Efficiency,Schedul,Scheduler,1385,"WDL file: hello.wdl; [2015-12-18 08:43:13,439] [info] Inputs: hello.json; [2015-12-18 08:43:13,560] [info] input: test.hello.name => ""world""; [2015-12-18 08:43:13,776] [info] SingleWorkflowRunnerActor: launching workflow; [2015-12-18 08:43:15,936] [info] Running with database db.url = jdbc:hsqldb:mem:86473284-494c-43d2-94fd-d00107a2a787;shutdown=false;hsqldb.tx=mvcc; [2015-12-18 08:43:17,516] [info] WorkflowManagerActor submitWorkflow input id = None, effective id = e67af113-c3a7-41f4-9178-6640c1c652e9; [2015-12-18 08:43:17,592] [info] WorkflowManagerActor Found no workflows to restart.; [2015-12-18 08:43:18,816] [error] SingleWorkflowRunnerActor: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; akka.pattern.AskTimeoutException: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; at akka.pattern.PromiseActorRef$$anonfun$1.apply$mcV$sp(AskSupport.scala:334); at akka.actor.Scheduler$$anon$7.run(Scheduler.scala:117); at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:599); at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:109); at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:597); at akka.actor.LightArrayRevolverScheduler$TaskHolder.executeTask(Scheduler.scala:467); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:1407,Energy Efficiency,Schedul,Scheduler,1407,"wdl; [2015-12-18 08:43:13,439] [info] Inputs: hello.json; [2015-12-18 08:43:13,560] [info] input: test.hello.name => ""world""; [2015-12-18 08:43:13,776] [info] SingleWorkflowRunnerActor: launching workflow; [2015-12-18 08:43:15,936] [info] Running with database db.url = jdbc:hsqldb:mem:86473284-494c-43d2-94fd-d00107a2a787;shutdown=false;hsqldb.tx=mvcc; [2015-12-18 08:43:17,516] [info] WorkflowManagerActor submitWorkflow input id = None, effective id = e67af113-c3a7-41f4-9178-6640c1c652e9; [2015-12-18 08:43:17,592] [info] WorkflowManagerActor Found no workflows to restart.; [2015-12-18 08:43:18,816] [error] SingleWorkflowRunnerActor: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; akka.pattern.AskTimeoutException: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; at akka.pattern.PromiseActorRef$$anonfun$1.apply$mcV$sp(AskSupport.scala:334); at akka.actor.Scheduler$$anon$7.run(Scheduler.scala:117); at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:599); at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:109); at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:597); at akka.actor.LightArrayRevolverScheduler$TaskHolder.executeTask(Scheduler.scala:467); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configurati",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:1743,Energy Efficiency,Schedul,Scheduler,1743,"false;hsqldb.tx=mvcc; [2015-12-18 08:43:17,516] [info] WorkflowManagerActor submitWorkflow input id = None, effective id = e67af113-c3a7-41f4-9178-6640c1c652e9; [2015-12-18 08:43:17,592] [info] WorkflowManagerActor Found no workflows to restart.; [2015-12-18 08:43:18,816] [error] SingleWorkflowRunnerActor: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; akka.pattern.AskTimeoutException: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; at akka.pattern.PromiseActorRef$$anonfun$1.apply$mcV$sp(AskSupport.scala:334); at akka.actor.Scheduler$$anon$7.run(Scheduler.scala:117); at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:599); at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:109); at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:597); at akka.actor.LightArrayRevolverScheduler$TaskHolder.executeTask(Scheduler.scala:467); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:1831,Energy Efficiency,Schedul,Scheduler,1831,"flow input id = None, effective id = e67af113-c3a7-41f4-9178-6640c1c652e9; [2015-12-18 08:43:17,592] [info] WorkflowManagerActor Found no workflows to restart.; [2015-12-18 08:43:18,816] [error] SingleWorkflowRunnerActor: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; akka.pattern.AskTimeoutException: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; at akka.pattern.PromiseActorRef$$anonfun$1.apply$mcV$sp(AskSupport.scala:334); at akka.actor.Scheduler$$anon$7.run(Scheduler.scala:117); at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:599); at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:109); at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:597); at akka.actor.LightArrayRevolverScheduler$TaskHolder.executeTask(Scheduler.scala:467); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and '",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:1912,Energy Efficiency,Schedul,Scheduler,1912,"18 08:43:17,592] [info] WorkflowManagerActor Found no workflows to restart.; [2015-12-18 08:43:18,816] [error] SingleWorkflowRunnerActor: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; akka.pattern.AskTimeoutException: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; at akka.pattern.PromiseActorRef$$anonfun$1.apply$mcV$sp(AskSupport.scala:334); at akka.actor.Scheduler$$anon$7.run(Scheduler.scala:117); at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:599); at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:109); at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:597); at akka.actor.LightArrayRevolverScheduler$TaskHolder.executeTask(Scheduler.scala:467); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowMa",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:1988,Energy Efficiency,Schedul,Scheduler,1988,"015-12-18 08:43:18,816] [error] SingleWorkflowRunnerActor: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; akka.pattern.AskTimeoutException: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; at akka.pattern.PromiseActorRef$$anonfun$1.apply$mcV$sp(AskSupport.scala:334); at akka.actor.Scheduler$$anon$7.run(Scheduler.scala:117); at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:599); at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:109); at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:597); at akka.actor.LightArrayRevolverScheduler$TaskHolder.executeTask(Scheduler.scala:467); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminati",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:3872,Energy Efficiency,Adapt,AdaptedForkJoinTask,3872,"ers encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:245); at scala.util.Success$$anonfun$map$1.apply(Try.scala:237); at scala.util.Try$.apply(Try.scala:192); at scala.util.Success.map(Try.scala:237); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); cromwell run hello.wdl hello.json 9.53s user 0.80s system 108% cpu 9.542 total; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:2085,Integrability,Message,Message,2085,"r[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; akka.pattern.AskTimeoutException: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; at akka.pattern.PromiseActorRef$$anonfun$1.apply$mcV$sp(AskSupport.scala:334); at akka.actor.Scheduler$$anon$7.run(Scheduler.scala:117); at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:599); at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:109); at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:597); at akka.actor.LightArrayRevolverScheduler$TaskHolder.executeTask(Scheduler.scala:467); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while t",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:2525,Integrability,Message,Message,2525,"9); at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:109); at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:597); at akka.actor.LightArrayRevolverScheduler$TaskHolder.executeTask(Scheduler.scala:467); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:245); at scala.util.Success$$anonfun",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:2399,Modifiability,config,configuration,2399,"duler$$anon$7.run(Scheduler.scala:117); at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:599); at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:109); at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:597); at akka.actor.LightArrayRevolverScheduler$TaskHolder.executeTask(Scheduler.scala:467); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:2776,Modifiability,config,configuration,2776,"t akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:245); at scala.util.Success$$anonfun$map$1.apply(Try.scala:237); at scala.util.Try$.apply(Try.scala:192); at scala.util.Success.map(Try.scala:237); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at sc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:3872,Modifiability,Adapt,AdaptedForkJoinTask,3872,"ers encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:245); at scala.util.Success$$anonfun$map$1.apply(Try.scala:237); at scala.util.Try$.apply(Try.scala:192); at scala.util.Success.map(Try.scala:237); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); cromwell run hello.wdl hello.json 9.53s user 0.80s system 108% cpu 9.542 total; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:1438,Performance,concurren,concurrent,1438,"nfo] Inputs: hello.json; [2015-12-18 08:43:13,560] [info] input: test.hello.name => ""world""; [2015-12-18 08:43:13,776] [info] SingleWorkflowRunnerActor: launching workflow; [2015-12-18 08:43:15,936] [info] Running with database db.url = jdbc:hsqldb:mem:86473284-494c-43d2-94fd-d00107a2a787;shutdown=false;hsqldb.tx=mvcc; [2015-12-18 08:43:17,516] [info] WorkflowManagerActor submitWorkflow input id = None, effective id = e67af113-c3a7-41f4-9178-6640c1c652e9; [2015-12-18 08:43:17,592] [info] WorkflowManagerActor Found no workflows to restart.; [2015-12-18 08:43:18,816] [error] SingleWorkflowRunnerActor: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; akka.pattern.AskTimeoutException: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; at akka.pattern.PromiseActorRef$$anonfun$1.apply$mcV$sp(AskSupport.scala:334); at akka.actor.Scheduler$$anon$7.run(Scheduler.scala:117); at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:599); at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:109); at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:597); at akka.actor.LightArrayRevolverScheduler$TaskHolder.executeTask(Scheduler.scala:467); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:1527,Performance,concurren,concurrent,1527,"d""; [2015-12-18 08:43:13,776] [info] SingleWorkflowRunnerActor: launching workflow; [2015-12-18 08:43:15,936] [info] Running with database db.url = jdbc:hsqldb:mem:86473284-494c-43d2-94fd-d00107a2a787;shutdown=false;hsqldb.tx=mvcc; [2015-12-18 08:43:17,516] [info] WorkflowManagerActor submitWorkflow input id = None, effective id = e67af113-c3a7-41f4-9178-6640c1c652e9; [2015-12-18 08:43:17,592] [info] WorkflowManagerActor Found no workflows to restart.; [2015-12-18 08:43:18,816] [error] SingleWorkflowRunnerActor: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; akka.pattern.AskTimeoutException: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; at akka.pattern.PromiseActorRef$$anonfun$1.apply$mcV$sp(AskSupport.scala:334); at akka.actor.Scheduler$$anon$7.run(Scheduler.scala:117); at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:599); at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:109); at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:597); at akka.actor.LightArrayRevolverScheduler$TaskHolder.executeTask(Scheduler.scala:467); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:1607,Performance,concurren,concurrent,1607,"ow; [2015-12-18 08:43:15,936] [info] Running with database db.url = jdbc:hsqldb:mem:86473284-494c-43d2-94fd-d00107a2a787;shutdown=false;hsqldb.tx=mvcc; [2015-12-18 08:43:17,516] [info] WorkflowManagerActor submitWorkflow input id = None, effective id = e67af113-c3a7-41f4-9178-6640c1c652e9; [2015-12-18 08:43:17,592] [info] WorkflowManagerActor Found no workflows to restart.; [2015-12-18 08:43:18,816] [error] SingleWorkflowRunnerActor: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; akka.pattern.AskTimeoutException: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; at akka.pattern.PromiseActorRef$$anonfun$1.apply$mcV$sp(AskSupport.scala:334); at akka.actor.Scheduler$$anon$7.run(Scheduler.scala:117); at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:599); at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:109); at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:597); at akka.actor.LightArrayRevolverScheduler$TaskHolder.executeTask(Scheduler.scala:467); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManag",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:3636,Performance,concurren,concurrent,3636,"ers encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:245); at scala.util.Success$$anonfun$map$1.apply(Try.scala:237); at scala.util.Try$.apply(Try.scala:192); at scala.util.Success.map(Try.scala:237); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); cromwell run hello.wdl hello.json 9.53s user 0.80s system 108% cpu 9.542 total; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:3703,Performance,concurren,concurrent,3703,"ers encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:245); at scala.util.Success$$anonfun$map$1.apply(Try.scala:237); at scala.util.Try$.apply(Try.scala:192); at scala.util.Success.map(Try.scala:237); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); cromwell run hello.wdl hello.json 9.53s user 0.80s system 108% cpu 9.542 total; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:3770,Performance,concurren,concurrent,3770,"ers encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:245); at scala.util.Success$$anonfun$map$1.apply(Try.scala:237); at scala.util.Try$.apply(Try.scala:192); at scala.util.Success.map(Try.scala:237); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); cromwell run hello.wdl hello.json 9.53s user 0.80s system 108% cpu 9.542 total; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:3835,Performance,concurren,concurrent,3835,"ers encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:245); at scala.util.Success$$anonfun$map$1.apply(Try.scala:237); at scala.util.Try$.apply(Try.scala:192); at scala.util.Success.map(Try.scala:237); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); cromwell run hello.wdl hello.json 9.53s user 0.80s system 108% cpu 9.542 total; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:3939,Performance,concurren,concurrent,3939,"ers encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:245); at scala.util.Success$$anonfun$map$1.apply(Try.scala:237); at scala.util.Try$.apply(Try.scala:192); at scala.util.Success.map(Try.scala:237); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); cromwell run hello.wdl hello.json 9.53s user 0.80s system 108% cpu 9.542 total; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:4012,Performance,concurren,concurrent,4012,"ers encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:245); at scala.util.Success$$anonfun$map$1.apply(Try.scala:237); at scala.util.Try$.apply(Try.scala:192); at scala.util.Success.map(Try.scala:237); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); cromwell run hello.wdl hello.json 9.53s user 0.80s system 108% cpu 9.542 total; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:4097,Performance,concurren,concurrent,4097,"ers encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:245); at scala.util.Success$$anonfun$map$1.apply(Try.scala:237); at scala.util.Try$.apply(Try.scala:192); at scala.util.Success.map(Try.scala:237); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); cromwell run hello.wdl hello.json 9.53s user 0.80s system 108% cpu 9.542 total; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:4174,Performance,concurren,concurrent,4174,"ers encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:245); at scala.util.Success$$anonfun$map$1.apply(Try.scala:237); at scala.util.Try$.apply(Try.scala:192); at scala.util.Success.map(Try.scala:237); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); cromwell run hello.wdl hello.json 9.53s user 0.80s system 108% cpu 9.542 total; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:508,Testability,test,test,508,"Hi,. I'm trying to run through the Hello World example. I'm running Cromwell on OS X with Java 8. Any ideas on how to troubleshoot the below error?. Thanks!. ```; › cromwell run hello.wdl hello.json; [2015-12-18 08:43:13,222] [info] Slf4jLogger started; [2015-12-18 08:43:13,335] [info] Default backend: LOCAL; [2015-12-18 08:43:13,335] [info] RUN sub-command; [2015-12-18 08:43:13,336] [info] WDL file: hello.wdl; [2015-12-18 08:43:13,439] [info] Inputs: hello.json; [2015-12-18 08:43:13,560] [info] input: test.hello.name => ""world""; [2015-12-18 08:43:13,776] [info] SingleWorkflowRunnerActor: launching workflow; [2015-12-18 08:43:15,936] [info] Running with database db.url = jdbc:hsqldb:mem:86473284-494c-43d2-94fd-d00107a2a787;shutdown=false;hsqldb.tx=mvcc; [2015-12-18 08:43:17,516] [info] WorkflowManagerActor submitWorkflow input id = None, effective id = e67af113-c3a7-41f4-9178-6640c1c652e9; [2015-12-18 08:43:17,592] [info] WorkflowManagerActor Found no workflows to restart.; [2015-12-18 08:43:18,816] [error] SingleWorkflowRunnerActor: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; akka.pattern.AskTimeoutException: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; at akka.pattern.PromiseActorRef$$anonfun$1.apply$mcV$sp(AskSupport.scala:334); at akka.actor.Scheduler$$anon$7.run(Scheduler.scala:117); at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:599); at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:109); at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:597); at akka.actor.LightArrayRevolverScheduler$TaskHolder.executeTask(Scheduler.scala:467); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.sca",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:2356,Testability,log,logging,2356,"duler$$anon$7.run(Scheduler.scala:117); at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:599); at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:109); at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:597); at akka.actor.LightArrayRevolverScheduler$TaskHolder.executeTask(Scheduler.scala:467); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:2428,Testability,log,log-dead-letters,2428,"urrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:599); at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:109); at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:597); at akka.actor.LightArrayRevolverScheduler$TaskHolder.executeTask(Scheduler.scala:467); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:2456,Testability,log,log-dead-letters-during-shutdown,2456,"xecutor$.unbatchedExecute(Future.scala:599); at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:109); at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:597); at akka.actor.LightArrayRevolverScheduler$TaskHolder.executeTask(Scheduler.scala:467); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:2733,Testability,log,logging,2733,"t akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:245); at scala.util.Success$$anonfun$map$1.apply(Try.scala:237); at scala.util.Try$.apply(Try.scala:192); at scala.util.Success.map(Try.scala:237); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at sc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:2805,Testability,log,log-dead-letters,2805,"uteBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:245); at scala.util.Success$$anonfun$map$1.apply(Try.scala:237); at scala.util.Try$.apply(Try.scala:192); at scala.util.Success.map(Try.scala:237); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.impl.CallbackRunnable.run(Promise.scal",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/issues/334:2833,Testability,log,log-dead-letters-during-shutdown,2833,"); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while terminating or terminated; at akka.actor.dungeon.Children$class.makeChild(Children.scala:199); at akka.actor.dungeon.Children$class.actorOf(Children.scala:37); at akka.actor.ActorCell.actorOf(ActorCell.scala:369); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:246); at cromwell.engine.workflow.WorkflowManagerActor$$anonfun$11.apply(WorkflowManagerActor.scala:245); at scala.util.Success$$anonfun$map$1.apply(Try.scala:237); at scala.util.Try$.apply(Try.scala:192); at scala.util.Success.map(Try.scala:237); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); at scala.concurrent.impl",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334
https://github.com/broadinstitute/cromwell/pull/335:8,Deployability,update,updates,8,This PR updates the documentation with instructions on installing Cromwell on OS X via Homebrew. This simplifies the process for getting the `cromwell` executable in the command-line environment. TODO:; - [x] Wait for [formula](https://github.com/Homebrew/homebrew/pull/47153) to be merged into Homebrew.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/335
https://github.com/broadinstitute/cromwell/pull/335:55,Deployability,install,installing,55,This PR updates the documentation with instructions on installing Cromwell on OS X via Homebrew. This simplifies the process for getting the `cromwell` executable in the command-line environment. TODO:; - [x] Wait for [formula](https://github.com/Homebrew/homebrew/pull/47153) to be merged into Homebrew.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/335
https://github.com/broadinstitute/cromwell/pull/335:102,Usability,simpl,simplifies,102,This PR updates the documentation with instructions on installing Cromwell on OS X via Homebrew. This simplifies the process for getting the `cromwell` executable in the command-line environment. TODO:; - [x] Wait for [formula](https://github.com/Homebrew/homebrew/pull/47153) to be merged into Homebrew.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/335
https://github.com/broadinstitute/cromwell/pull/338:90,Security,authenticat,authenticate,90,…efault Credentials. This is especially useful when running on a GCE VM when you want to. authenticate with the standard compute service account.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/338
https://github.com/broadinstitute/cromwell/pull/340:2,Availability,error,error,2,….error,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/340
https://github.com/broadinstitute/cromwell/pull/341:65,Deployability,update,update,65,"A quick explanation of the strategy - I did this with a database update at (actually just after) evaluation time. This has a few benefits (as I see it):; - The database is as easy to read and interpret as the metadata.; - We don't need to rehydrate the various data structures required by the expression evaluation logic just to perform a metadata query.; - We know that the evaluated expression in the database is the **exact** expression used in the call. There's no possibility of it being re-calculated incorrectly at a later time (maybe expression logic changes, etc); - I got to re-learn slick database update operations :-D",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/341
https://github.com/broadinstitute/cromwell/pull/341:609,Deployability,update,update,609,"A quick explanation of the strategy - I did this with a database update at (actually just after) evaluation time. This has a few benefits (as I see it):; - The database is as easy to read and interpret as the metadata.; - We don't need to rehydrate the various data structures required by the expression evaluation logic just to perform a metadata query.; - We know that the evaluated expression in the database is the **exact** expression used in the call. There's no possibility of it being re-calculated incorrectly at a later time (maybe expression logic changes, etc); - I got to re-learn slick database update operations :-D",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/341
https://github.com/broadinstitute/cromwell/pull/341:329,Performance,perform,perform,329,"A quick explanation of the strategy - I did this with a database update at (actually just after) evaluation time. This has a few benefits (as I see it):; - The database is as easy to read and interpret as the metadata.; - We don't need to rehydrate the various data structures required by the expression evaluation logic just to perform a metadata query.; - We know that the evaluated expression in the database is the **exact** expression used in the call. There's no possibility of it being re-calculated incorrectly at a later time (maybe expression logic changes, etc); - I got to re-learn slick database update operations :-D",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/341
https://github.com/broadinstitute/cromwell/pull/341:315,Testability,log,logic,315,"A quick explanation of the strategy - I did this with a database update at (actually just after) evaluation time. This has a few benefits (as I see it):; - The database is as easy to read and interpret as the metadata.; - We don't need to rehydrate the various data structures required by the expression evaluation logic just to perform a metadata query.; - We know that the evaluated expression in the database is the **exact** expression used in the call. There's no possibility of it being re-calculated incorrectly at a later time (maybe expression logic changes, etc); - I got to re-learn slick database update operations :-D",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/341
https://github.com/broadinstitute/cromwell/pull/341:553,Testability,log,logic,553,"A quick explanation of the strategy - I did this with a database update at (actually just after) evaluation time. This has a few benefits (as I see it):; - The database is as easy to read and interpret as the metadata.; - We don't need to rehydrate the various data structures required by the expression evaluation logic just to perform a metadata query.; - We know that the evaluated expression in the database is the **exact** expression used in the call. There's no possibility of it being re-calculated incorrectly at a later time (maybe expression logic changes, etc); - I got to re-learn slick database update operations :-D",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/341
https://github.com/broadinstitute/cromwell/pull/341:588,Usability,learn,learn,588,"A quick explanation of the strategy - I did this with a database update at (actually just after) evaluation time. This has a few benefits (as I see it):; - The database is as easy to read and interpret as the metadata.; - We don't need to rehydrate the various data structures required by the expression evaluation logic just to perform a metadata query.; - We know that the evaluated expression in the database is the **exact** expression used in the call. There's no possibility of it being re-calculated incorrectly at a later time (maybe expression logic changes, etc); - I got to re-learn slick database update operations :-D",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/341
https://github.com/broadinstitute/cromwell/pull/342:22,Integrability,rout,route,22,Looks like the status route vanished during call caching merging.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/342
https://github.com/broadinstitute/cromwell/pull/347:267,Availability,down,down,267,"`CromwellServer` now exits with a 1 if the server does not start up. Still could use clean termination handling (via lenthall?).; Refactored the `WorkflowManagerSystem` passing into `Main`, including ensuring that during tests the internal actor system does get shut down, but not prematurely.; Made the `PromiseActor` more generic. TODO: Could move to lenthall, and possibly make it even easier to use, as right now it requires using `tell` instead of `!` to ensure the `sender` is set correctly.; `sys.exit()` is only called in the `object Main`, not conditionally in the `class Main`.; Moved `getAction()` from the `Main` class to the object.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/347
https://github.com/broadinstitute/cromwell/pull/347:130,Modifiability,Refactor,Refactored,130,"`CromwellServer` now exits with a 1 if the server does not start up. Still could use clean termination handling (via lenthall?).; Refactored the `WorkflowManagerSystem` passing into `Main`, including ensuring that during tests the internal actor system does get shut down, but not prematurely.; Made the `PromiseActor` more generic. TODO: Could move to lenthall, and possibly make it even easier to use, as right now it requires using `tell` instead of `!` to ensure the `sender` is set correctly.; `sys.exit()` is only called in the `object Main`, not conditionally in the `class Main`.; Moved `getAction()` from the `Main` class to the object.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/347
https://github.com/broadinstitute/cromwell/pull/347:221,Testability,test,tests,221,"`CromwellServer` now exits with a 1 if the server does not start up. Still could use clean termination handling (via lenthall?).; Refactored the `WorkflowManagerSystem` passing into `Main`, including ensuring that during tests the internal actor system does get shut down, but not prematurely.; Made the `PromiseActor` more generic. TODO: Could move to lenthall, and possibly make it even easier to use, as right now it requires using `tell` instead of `!` to ensure the `sender` is set correctly.; `sys.exit()` is only called in the `object Main`, not conditionally in the `class Main`.; Moved `getAction()` from the `Main` class to the object.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/347
https://github.com/broadinstitute/cromwell/pull/354:91,Deployability,integrat,integrated,91,"Create a new ""final call"" execution to manage the copying of workflow outputs. Needs to be integrated with the changes in #351.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/354
https://github.com/broadinstitute/cromwell/pull/354:91,Integrability,integrat,integrated,91,"Create a new ""final call"" execution to manage the copying of workflow outputs. Needs to be integrated with the changes in #351.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/354
https://github.com/broadinstitute/cromwell/issues/360:454,Energy Efficiency,allocate,allocate,454,"The highlight subcommand of cromwell strips out the runtime, param_meta and meta information. . test.wdl:. ```; task runtime_meta {; String memory_mb; String sample_id; String param; String sample_id. command {; java -Xmx${memory_mb}M -jar task.jar -id ${sample_id} -param ${param} -out ${sample_id}.out; }; output {; File results = ""${sample_id}.out""; }; runtime {; docker: ""broadinstitute/baseimg""; }; parameter_meta {; memory_mb: ""Amount of memory to allocate to the JVM""; param: ""Some arbitrary parameter""; sample_id: ""The ID of the sample in format foo_bar_baz""; }; meta {; author: ""Joe Somebody""; email: ""joe@company.org""; }; }. workflow test {; call runtime_meta; }; ```. The command `$ java -jar cromwell-0.15.jar highlight test.wdl console` outputs:. ```; task runtime_meta {; String memory_mb; String sample_id; String param; String sample_id. command {; java -Xmx${memory_mb}M -jar task.jar -id ${sample_id} -param ${param} -out ${sample_id}.out; }; output {; File results = ""${sample_id}.out""; }. workflow test {; call runtime_meta; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/360
https://github.com/broadinstitute/cromwell/issues/360:96,Testability,test,test,96,"The highlight subcommand of cromwell strips out the runtime, param_meta and meta information. . test.wdl:. ```; task runtime_meta {; String memory_mb; String sample_id; String param; String sample_id. command {; java -Xmx${memory_mb}M -jar task.jar -id ${sample_id} -param ${param} -out ${sample_id}.out; }; output {; File results = ""${sample_id}.out""; }; runtime {; docker: ""broadinstitute/baseimg""; }; parameter_meta {; memory_mb: ""Amount of memory to allocate to the JVM""; param: ""Some arbitrary parameter""; sample_id: ""The ID of the sample in format foo_bar_baz""; }; meta {; author: ""Joe Somebody""; email: ""joe@company.org""; }; }. workflow test {; call runtime_meta; }; ```. The command `$ java -jar cromwell-0.15.jar highlight test.wdl console` outputs:. ```; task runtime_meta {; String memory_mb; String sample_id; String param; String sample_id. command {; java -Xmx${memory_mb}M -jar task.jar -id ${sample_id} -param ${param} -out ${sample_id}.out; }; output {; File results = ""${sample_id}.out""; }. workflow test {; call runtime_meta; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/360
https://github.com/broadinstitute/cromwell/issues/360:644,Testability,test,test,644,"The highlight subcommand of cromwell strips out the runtime, param_meta and meta information. . test.wdl:. ```; task runtime_meta {; String memory_mb; String sample_id; String param; String sample_id. command {; java -Xmx${memory_mb}M -jar task.jar -id ${sample_id} -param ${param} -out ${sample_id}.out; }; output {; File results = ""${sample_id}.out""; }; runtime {; docker: ""broadinstitute/baseimg""; }; parameter_meta {; memory_mb: ""Amount of memory to allocate to the JVM""; param: ""Some arbitrary parameter""; sample_id: ""The ID of the sample in format foo_bar_baz""; }; meta {; author: ""Joe Somebody""; email: ""joe@company.org""; }; }. workflow test {; call runtime_meta; }; ```. The command `$ java -jar cromwell-0.15.jar highlight test.wdl console` outputs:. ```; task runtime_meta {; String memory_mb; String sample_id; String param; String sample_id. command {; java -Xmx${memory_mb}M -jar task.jar -id ${sample_id} -param ${param} -out ${sample_id}.out; }; output {; File results = ""${sample_id}.out""; }. workflow test {; call runtime_meta; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/360
https://github.com/broadinstitute/cromwell/issues/360:732,Testability,test,test,732,"The highlight subcommand of cromwell strips out the runtime, param_meta and meta information. . test.wdl:. ```; task runtime_meta {; String memory_mb; String sample_id; String param; String sample_id. command {; java -Xmx${memory_mb}M -jar task.jar -id ${sample_id} -param ${param} -out ${sample_id}.out; }; output {; File results = ""${sample_id}.out""; }; runtime {; docker: ""broadinstitute/baseimg""; }; parameter_meta {; memory_mb: ""Amount of memory to allocate to the JVM""; param: ""Some arbitrary parameter""; sample_id: ""The ID of the sample in format foo_bar_baz""; }; meta {; author: ""Joe Somebody""; email: ""joe@company.org""; }; }. workflow test {; call runtime_meta; }; ```. The command `$ java -jar cromwell-0.15.jar highlight test.wdl console` outputs:. ```; task runtime_meta {; String memory_mb; String sample_id; String param; String sample_id. command {; java -Xmx${memory_mb}M -jar task.jar -id ${sample_id} -param ${param} -out ${sample_id}.out; }; output {; File results = ""${sample_id}.out""; }. workflow test {; call runtime_meta; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/360
https://github.com/broadinstitute/cromwell/issues/360:1018,Testability,test,test,1018,"The highlight subcommand of cromwell strips out the runtime, param_meta and meta information. . test.wdl:. ```; task runtime_meta {; String memory_mb; String sample_id; String param; String sample_id. command {; java -Xmx${memory_mb}M -jar task.jar -id ${sample_id} -param ${param} -out ${sample_id}.out; }; output {; File results = ""${sample_id}.out""; }; runtime {; docker: ""broadinstitute/baseimg""; }; parameter_meta {; memory_mb: ""Amount of memory to allocate to the JVM""; param: ""Some arbitrary parameter""; sample_id: ""The ID of the sample in format foo_bar_baz""; }; meta {; author: ""Joe Somebody""; email: ""joe@company.org""; }; }. workflow test {; call runtime_meta; }; ```. The command `$ java -jar cromwell-0.15.jar highlight test.wdl console` outputs:. ```; task runtime_meta {; String memory_mb; String sample_id; String param; String sample_id. command {; java -Xmx${memory_mb}M -jar task.jar -id ${sample_id} -param ${param} -out ${sample_id}.out; }; output {; File results = ""${sample_id}.out""; }. workflow test {; call runtime_meta; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/360
https://github.com/broadinstitute/cromwell/pull/365:214,Performance,load,loading,214,"…lity. Notes: ; - As w/ the WDL half of this, I will not be accepting passenger requests for random fixups but only on the actual changes (should be easier here); - sbt assembly is borked, I know that; - currently loading in wdl4s as an unmanaged jar, that'll change prior to merging",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/365
https://github.com/broadinstitute/cromwell/issues/375:48,Deployability,configurat,configuration,48,"Hi,; ### TL;DR. **Cromwell should allow for the configuration of Docker resource / environment flags at run-time.**. ---. I have a use-case where I'd like to run Cromwell jobs in a cluster environment via Docker Swarm. Since Swarm doesn't require any additional configuration outside of standard `docker run` commands, it's trivial to distribute Cromwell jobs across Swarm nodes. However, Swarm provides a series of [filters](https://github.com/docker/swarm/tree/master/scheduler/filter) and constrains that control how the scheduler distributes containers to nodes. For example, I might be interested in limiting the execution of a Cromwell job to a specific region / datacenter. This requires you to specify filters in the `docker run` command with the environment flag, `-e`. For example, to run a container on Swarm nodes that run in the `us-east` region:. ```; › docker run -d --name my_image -e constraint:region!=us-east* my_container; ```. Obviously, this configuration should _not_ be managed in the WDL document. Instead, it would be great for the Cromwell command-line tool and REST API to support additional runtime options for specifying Docker environment variables. For example:. ```; › cromwell run --docker-env ""constraint:region!=us-east*"" my_workflow.wdl -; ```. > Hint: Docker supports daemon labels. In the above case, the workflow would; > execute on a Swarm node whose Docker daemon that was started with:; > ; > ```; > docker daemon --label region=us-east; > ```. As for the API, the POST action to `/api/workflows/:version` would allow for multiple Docker env strings. The other feature I would like to request is translating `memory` and `cpu` configuration options (at the task level) to Docker via `--memory` and `--cpuset-cpus` `docker run` flags, respectively. These options are currently only used for the JES backend, but it seems as though they can also be used for the Local backend if Docker is specified. So, to summarize:; 1. Allow Docker `-e` flags to be specifie",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/375
https://github.com/broadinstitute/cromwell/issues/375:262,Deployability,configurat,configuration,262,"Hi,; ### TL;DR. **Cromwell should allow for the configuration of Docker resource / environment flags at run-time.**. ---. I have a use-case where I'd like to run Cromwell jobs in a cluster environment via Docker Swarm. Since Swarm doesn't require any additional configuration outside of standard `docker run` commands, it's trivial to distribute Cromwell jobs across Swarm nodes. However, Swarm provides a series of [filters](https://github.com/docker/swarm/tree/master/scheduler/filter) and constrains that control how the scheduler distributes containers to nodes. For example, I might be interested in limiting the execution of a Cromwell job to a specific region / datacenter. This requires you to specify filters in the `docker run` command with the environment flag, `-e`. For example, to run a container on Swarm nodes that run in the `us-east` region:. ```; › docker run -d --name my_image -e constraint:region!=us-east* my_container; ```. Obviously, this configuration should _not_ be managed in the WDL document. Instead, it would be great for the Cromwell command-line tool and REST API to support additional runtime options for specifying Docker environment variables. For example:. ```; › cromwell run --docker-env ""constraint:region!=us-east*"" my_workflow.wdl -; ```. > Hint: Docker supports daemon labels. In the above case, the workflow would; > execute on a Swarm node whose Docker daemon that was started with:; > ; > ```; > docker daemon --label region=us-east; > ```. As for the API, the POST action to `/api/workflows/:version` would allow for multiple Docker env strings. The other feature I would like to request is translating `memory` and `cpu` configuration options (at the task level) to Docker via `--memory` and `--cpuset-cpus` `docker run` flags, respectively. These options are currently only used for the JES backend, but it seems as though they can also be used for the Local backend if Docker is specified. So, to summarize:; 1. Allow Docker `-e` flags to be specifie",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/375
https://github.com/broadinstitute/cromwell/issues/375:964,Deployability,configurat,configuration,964,"Hi,; ### TL;DR. **Cromwell should allow for the configuration of Docker resource / environment flags at run-time.**. ---. I have a use-case where I'd like to run Cromwell jobs in a cluster environment via Docker Swarm. Since Swarm doesn't require any additional configuration outside of standard `docker run` commands, it's trivial to distribute Cromwell jobs across Swarm nodes. However, Swarm provides a series of [filters](https://github.com/docker/swarm/tree/master/scheduler/filter) and constrains that control how the scheduler distributes containers to nodes. For example, I might be interested in limiting the execution of a Cromwell job to a specific region / datacenter. This requires you to specify filters in the `docker run` command with the environment flag, `-e`. For example, to run a container on Swarm nodes that run in the `us-east` region:. ```; › docker run -d --name my_image -e constraint:region!=us-east* my_container; ```. Obviously, this configuration should _not_ be managed in the WDL document. Instead, it would be great for the Cromwell command-line tool and REST API to support additional runtime options for specifying Docker environment variables. For example:. ```; › cromwell run --docker-env ""constraint:region!=us-east*"" my_workflow.wdl -; ```. > Hint: Docker supports daemon labels. In the above case, the workflow would; > execute on a Swarm node whose Docker daemon that was started with:; > ; > ```; > docker daemon --label region=us-east; > ```. As for the API, the POST action to `/api/workflows/:version` would allow for multiple Docker env strings. The other feature I would like to request is translating `memory` and `cpu` configuration options (at the task level) to Docker via `--memory` and `--cpuset-cpus` `docker run` flags, respectively. These options are currently only used for the JES backend, but it seems as though they can also be used for the Local backend if Docker is specified. So, to summarize:; 1. Allow Docker `-e` flags to be specifie",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/375
https://github.com/broadinstitute/cromwell/issues/375:1670,Deployability,configurat,configuration,1670,"uration outside of standard `docker run` commands, it's trivial to distribute Cromwell jobs across Swarm nodes. However, Swarm provides a series of [filters](https://github.com/docker/swarm/tree/master/scheduler/filter) and constrains that control how the scheduler distributes containers to nodes. For example, I might be interested in limiting the execution of a Cromwell job to a specific region / datacenter. This requires you to specify filters in the `docker run` command with the environment flag, `-e`. For example, to run a container on Swarm nodes that run in the `us-east` region:. ```; › docker run -d --name my_image -e constraint:region!=us-east* my_container; ```. Obviously, this configuration should _not_ be managed in the WDL document. Instead, it would be great for the Cromwell command-line tool and REST API to support additional runtime options for specifying Docker environment variables. For example:. ```; › cromwell run --docker-env ""constraint:region!=us-east*"" my_workflow.wdl -; ```. > Hint: Docker supports daemon labels. In the above case, the workflow would; > execute on a Swarm node whose Docker daemon that was started with:; > ; > ```; > docker daemon --label region=us-east; > ```. As for the API, the POST action to `/api/workflows/:version` would allow for multiple Docker env strings. The other feature I would like to request is translating `memory` and `cpu` configuration options (at the task level) to Docker via `--memory` and `--cpuset-cpus` `docker run` flags, respectively. These options are currently only used for the JES backend, but it seems as though they can also be used for the Local backend if Docker is specified. So, to summarize:; 1. Allow Docker `-e` flags to be specified for all tasks in a given workflow.; 2. Allow task `memory` and `cpu` options in a WDL document to be translated to `--memory` and `--cpuset-cpus` in the `docker run` command. Please let me know if there's anything I can do to help this move forward. Cheers! :beers:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/375
https://github.com/broadinstitute/cromwell/issues/375:470,Energy Efficiency,schedul,scheduler,470,"Hi,; ### TL;DR. **Cromwell should allow for the configuration of Docker resource / environment flags at run-time.**. ---. I have a use-case where I'd like to run Cromwell jobs in a cluster environment via Docker Swarm. Since Swarm doesn't require any additional configuration outside of standard `docker run` commands, it's trivial to distribute Cromwell jobs across Swarm nodes. However, Swarm provides a series of [filters](https://github.com/docker/swarm/tree/master/scheduler/filter) and constrains that control how the scheduler distributes containers to nodes. For example, I might be interested in limiting the execution of a Cromwell job to a specific region / datacenter. This requires you to specify filters in the `docker run` command with the environment flag, `-e`. For example, to run a container on Swarm nodes that run in the `us-east` region:. ```; › docker run -d --name my_image -e constraint:region!=us-east* my_container; ```. Obviously, this configuration should _not_ be managed in the WDL document. Instead, it would be great for the Cromwell command-line tool and REST API to support additional runtime options for specifying Docker environment variables. For example:. ```; › cromwell run --docker-env ""constraint:region!=us-east*"" my_workflow.wdl -; ```. > Hint: Docker supports daemon labels. In the above case, the workflow would; > execute on a Swarm node whose Docker daemon that was started with:; > ; > ```; > docker daemon --label region=us-east; > ```. As for the API, the POST action to `/api/workflows/:version` would allow for multiple Docker env strings. The other feature I would like to request is translating `memory` and `cpu` configuration options (at the task level) to Docker via `--memory` and `--cpuset-cpus` `docker run` flags, respectively. These options are currently only used for the JES backend, but it seems as though they can also be used for the Local backend if Docker is specified. So, to summarize:; 1. Allow Docker `-e` flags to be specifie",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/375
https://github.com/broadinstitute/cromwell/issues/375:524,Energy Efficiency,schedul,scheduler,524,"Hi,; ### TL;DR. **Cromwell should allow for the configuration of Docker resource / environment flags at run-time.**. ---. I have a use-case where I'd like to run Cromwell jobs in a cluster environment via Docker Swarm. Since Swarm doesn't require any additional configuration outside of standard `docker run` commands, it's trivial to distribute Cromwell jobs across Swarm nodes. However, Swarm provides a series of [filters](https://github.com/docker/swarm/tree/master/scheduler/filter) and constrains that control how the scheduler distributes containers to nodes. For example, I might be interested in limiting the execution of a Cromwell job to a specific region / datacenter. This requires you to specify filters in the `docker run` command with the environment flag, `-e`. For example, to run a container on Swarm nodes that run in the `us-east` region:. ```; › docker run -d --name my_image -e constraint:region!=us-east* my_container; ```. Obviously, this configuration should _not_ be managed in the WDL document. Instead, it would be great for the Cromwell command-line tool and REST API to support additional runtime options for specifying Docker environment variables. For example:. ```; › cromwell run --docker-env ""constraint:region!=us-east*"" my_workflow.wdl -; ```. > Hint: Docker supports daemon labels. In the above case, the workflow would; > execute on a Swarm node whose Docker daemon that was started with:; > ; > ```; > docker daemon --label region=us-east; > ```. As for the API, the POST action to `/api/workflows/:version` would allow for multiple Docker env strings. The other feature I would like to request is translating `memory` and `cpu` configuration options (at the task level) to Docker via `--memory` and `--cpuset-cpus` `docker run` flags, respectively. These options are currently only used for the JES backend, but it seems as though they can also be used for the Local backend if Docker is specified. So, to summarize:; 1. Allow Docker `-e` flags to be specifie",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/375
https://github.com/broadinstitute/cromwell/issues/375:48,Modifiability,config,configuration,48,"Hi,; ### TL;DR. **Cromwell should allow for the configuration of Docker resource / environment flags at run-time.**. ---. I have a use-case where I'd like to run Cromwell jobs in a cluster environment via Docker Swarm. Since Swarm doesn't require any additional configuration outside of standard `docker run` commands, it's trivial to distribute Cromwell jobs across Swarm nodes. However, Swarm provides a series of [filters](https://github.com/docker/swarm/tree/master/scheduler/filter) and constrains that control how the scheduler distributes containers to nodes. For example, I might be interested in limiting the execution of a Cromwell job to a specific region / datacenter. This requires you to specify filters in the `docker run` command with the environment flag, `-e`. For example, to run a container on Swarm nodes that run in the `us-east` region:. ```; › docker run -d --name my_image -e constraint:region!=us-east* my_container; ```. Obviously, this configuration should _not_ be managed in the WDL document. Instead, it would be great for the Cromwell command-line tool and REST API to support additional runtime options for specifying Docker environment variables. For example:. ```; › cromwell run --docker-env ""constraint:region!=us-east*"" my_workflow.wdl -; ```. > Hint: Docker supports daemon labels. In the above case, the workflow would; > execute on a Swarm node whose Docker daemon that was started with:; > ; > ```; > docker daemon --label region=us-east; > ```. As for the API, the POST action to `/api/workflows/:version` would allow for multiple Docker env strings. The other feature I would like to request is translating `memory` and `cpu` configuration options (at the task level) to Docker via `--memory` and `--cpuset-cpus` `docker run` flags, respectively. These options are currently only used for the JES backend, but it seems as though they can also be used for the Local backend if Docker is specified. So, to summarize:; 1. Allow Docker `-e` flags to be specifie",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/375
https://github.com/broadinstitute/cromwell/issues/375:262,Modifiability,config,configuration,262,"Hi,; ### TL;DR. **Cromwell should allow for the configuration of Docker resource / environment flags at run-time.**. ---. I have a use-case where I'd like to run Cromwell jobs in a cluster environment via Docker Swarm. Since Swarm doesn't require any additional configuration outside of standard `docker run` commands, it's trivial to distribute Cromwell jobs across Swarm nodes. However, Swarm provides a series of [filters](https://github.com/docker/swarm/tree/master/scheduler/filter) and constrains that control how the scheduler distributes containers to nodes. For example, I might be interested in limiting the execution of a Cromwell job to a specific region / datacenter. This requires you to specify filters in the `docker run` command with the environment flag, `-e`. For example, to run a container on Swarm nodes that run in the `us-east` region:. ```; › docker run -d --name my_image -e constraint:region!=us-east* my_container; ```. Obviously, this configuration should _not_ be managed in the WDL document. Instead, it would be great for the Cromwell command-line tool and REST API to support additional runtime options for specifying Docker environment variables. For example:. ```; › cromwell run --docker-env ""constraint:region!=us-east*"" my_workflow.wdl -; ```. > Hint: Docker supports daemon labels. In the above case, the workflow would; > execute on a Swarm node whose Docker daemon that was started with:; > ; > ```; > docker daemon --label region=us-east; > ```. As for the API, the POST action to `/api/workflows/:version` would allow for multiple Docker env strings. The other feature I would like to request is translating `memory` and `cpu` configuration options (at the task level) to Docker via `--memory` and `--cpuset-cpus` `docker run` flags, respectively. These options are currently only used for the JES backend, but it seems as though they can also be used for the Local backend if Docker is specified. So, to summarize:; 1. Allow Docker `-e` flags to be specifie",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/375
https://github.com/broadinstitute/cromwell/issues/375:964,Modifiability,config,configuration,964,"Hi,; ### TL;DR. **Cromwell should allow for the configuration of Docker resource / environment flags at run-time.**. ---. I have a use-case where I'd like to run Cromwell jobs in a cluster environment via Docker Swarm. Since Swarm doesn't require any additional configuration outside of standard `docker run` commands, it's trivial to distribute Cromwell jobs across Swarm nodes. However, Swarm provides a series of [filters](https://github.com/docker/swarm/tree/master/scheduler/filter) and constrains that control how the scheduler distributes containers to nodes. For example, I might be interested in limiting the execution of a Cromwell job to a specific region / datacenter. This requires you to specify filters in the `docker run` command with the environment flag, `-e`. For example, to run a container on Swarm nodes that run in the `us-east` region:. ```; › docker run -d --name my_image -e constraint:region!=us-east* my_container; ```. Obviously, this configuration should _not_ be managed in the WDL document. Instead, it would be great for the Cromwell command-line tool and REST API to support additional runtime options for specifying Docker environment variables. For example:. ```; › cromwell run --docker-env ""constraint:region!=us-east*"" my_workflow.wdl -; ```. > Hint: Docker supports daemon labels. In the above case, the workflow would; > execute on a Swarm node whose Docker daemon that was started with:; > ; > ```; > docker daemon --label region=us-east; > ```. As for the API, the POST action to `/api/workflows/:version` would allow for multiple Docker env strings. The other feature I would like to request is translating `memory` and `cpu` configuration options (at the task level) to Docker via `--memory` and `--cpuset-cpus` `docker run` flags, respectively. These options are currently only used for the JES backend, but it seems as though they can also be used for the Local backend if Docker is specified. So, to summarize:; 1. Allow Docker `-e` flags to be specifie",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/375
https://github.com/broadinstitute/cromwell/issues/375:1170,Modifiability,variab,variables,1170,"at run-time.**. ---. I have a use-case where I'd like to run Cromwell jobs in a cluster environment via Docker Swarm. Since Swarm doesn't require any additional configuration outside of standard `docker run` commands, it's trivial to distribute Cromwell jobs across Swarm nodes. However, Swarm provides a series of [filters](https://github.com/docker/swarm/tree/master/scheduler/filter) and constrains that control how the scheduler distributes containers to nodes. For example, I might be interested in limiting the execution of a Cromwell job to a specific region / datacenter. This requires you to specify filters in the `docker run` command with the environment flag, `-e`. For example, to run a container on Swarm nodes that run in the `us-east` region:. ```; › docker run -d --name my_image -e constraint:region!=us-east* my_container; ```. Obviously, this configuration should _not_ be managed in the WDL document. Instead, it would be great for the Cromwell command-line tool and REST API to support additional runtime options for specifying Docker environment variables. For example:. ```; › cromwell run --docker-env ""constraint:region!=us-east*"" my_workflow.wdl -; ```. > Hint: Docker supports daemon labels. In the above case, the workflow would; > execute on a Swarm node whose Docker daemon that was started with:; > ; > ```; > docker daemon --label region=us-east; > ```. As for the API, the POST action to `/api/workflows/:version` would allow for multiple Docker env strings. The other feature I would like to request is translating `memory` and `cpu` configuration options (at the task level) to Docker via `--memory` and `--cpuset-cpus` `docker run` flags, respectively. These options are currently only used for the JES backend, but it seems as though they can also be used for the Local backend if Docker is specified. So, to summarize:; 1. Allow Docker `-e` flags to be specified for all tasks in a given workflow.; 2. Allow task `memory` and `cpu` options in a WDL document to ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/375
https://github.com/broadinstitute/cromwell/issues/375:1670,Modifiability,config,configuration,1670,"uration outside of standard `docker run` commands, it's trivial to distribute Cromwell jobs across Swarm nodes. However, Swarm provides a series of [filters](https://github.com/docker/swarm/tree/master/scheduler/filter) and constrains that control how the scheduler distributes containers to nodes. For example, I might be interested in limiting the execution of a Cromwell job to a specific region / datacenter. This requires you to specify filters in the `docker run` command with the environment flag, `-e`. For example, to run a container on Swarm nodes that run in the `us-east` region:. ```; › docker run -d --name my_image -e constraint:region!=us-east* my_container; ```. Obviously, this configuration should _not_ be managed in the WDL document. Instead, it would be great for the Cromwell command-line tool and REST API to support additional runtime options for specifying Docker environment variables. For example:. ```; › cromwell run --docker-env ""constraint:region!=us-east*"" my_workflow.wdl -; ```. > Hint: Docker supports daemon labels. In the above case, the workflow would; > execute on a Swarm node whose Docker daemon that was started with:; > ; > ```; > docker daemon --label region=us-east; > ```. As for the API, the POST action to `/api/workflows/:version` would allow for multiple Docker env strings. The other feature I would like to request is translating `memory` and `cpu` configuration options (at the task level) to Docker via `--memory` and `--cpuset-cpus` `docker run` flags, respectively. These options are currently only used for the JES backend, but it seems as though they can also be used for the Local backend if Docker is specified. So, to summarize:; 1. Allow Docker `-e` flags to be specified for all tasks in a given workflow.; 2. Allow task `memory` and `cpu` options in a WDL document to be translated to `--memory` and `--cpuset-cpus` in the `docker run` command. Please let me know if there's anything I can do to help this move forward. Cheers! :beers:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/375
https://github.com/broadinstitute/cromwell/pull/377:189,Security,encrypt,encryption,189,"This change comes with a related change to vault to add a value. This has been added to dev as:. ""workflow_options_encryption_key"": ""nottheactualvalue"". but devops needs to to generate the encryption key for staging/alpha/prod and add these to vault before this version is promoted to those environments ( @abaumann @mmonnar )",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/377
https://github.com/broadinstitute/cromwell/pull/378:232,Testability,log,log,232,See the corresponding wdl4s change: https://github.com/broadinstitute/wdl4s/pull/6; See the corresponding Tyburn change: https://github.com/broadinstitute/tyburn/pull/17. Instead of creating these files:. ```; gs://path/to/call/jes.log; gs://path/to/call/jes-stdout.log; gs://path/to/call/jes-stderr.log; ```. We will now create (`hello` is the name of the call). ```; gs://path/to/call/hello.log; gs://path/to/call/hello-stdout.log; gs://path/to/call/hello-stderr.log; ```. We no longer manually redirect the stdout/stderr and let JES take care of it. [Example output](https://console.developers.google.com/storage/browser/cromwell-dev/stdout_stderr_passing/0f3758c3-b186-41d3-86c1-d92e55b24332/?project=broad-dsde-dev&pli=1) of running the WDL in https://github.com/broadinstitute/tyburn/pull/17,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/378
https://github.com/broadinstitute/cromwell/pull/378:266,Testability,log,log,266,See the corresponding wdl4s change: https://github.com/broadinstitute/wdl4s/pull/6; See the corresponding Tyburn change: https://github.com/broadinstitute/tyburn/pull/17. Instead of creating these files:. ```; gs://path/to/call/jes.log; gs://path/to/call/jes-stdout.log; gs://path/to/call/jes-stderr.log; ```. We will now create (`hello` is the name of the call). ```; gs://path/to/call/hello.log; gs://path/to/call/hello-stdout.log; gs://path/to/call/hello-stderr.log; ```. We no longer manually redirect the stdout/stderr and let JES take care of it. [Example output](https://console.developers.google.com/storage/browser/cromwell-dev/stdout_stderr_passing/0f3758c3-b186-41d3-86c1-d92e55b24332/?project=broad-dsde-dev&pli=1) of running the WDL in https://github.com/broadinstitute/tyburn/pull/17,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/378
https://github.com/broadinstitute/cromwell/pull/378:300,Testability,log,log,300,See the corresponding wdl4s change: https://github.com/broadinstitute/wdl4s/pull/6; See the corresponding Tyburn change: https://github.com/broadinstitute/tyburn/pull/17. Instead of creating these files:. ```; gs://path/to/call/jes.log; gs://path/to/call/jes-stdout.log; gs://path/to/call/jes-stderr.log; ```. We will now create (`hello` is the name of the call). ```; gs://path/to/call/hello.log; gs://path/to/call/hello-stdout.log; gs://path/to/call/hello-stderr.log; ```. We no longer manually redirect the stdout/stderr and let JES take care of it. [Example output](https://console.developers.google.com/storage/browser/cromwell-dev/stdout_stderr_passing/0f3758c3-b186-41d3-86c1-d92e55b24332/?project=broad-dsde-dev&pli=1) of running the WDL in https://github.com/broadinstitute/tyburn/pull/17,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/378
https://github.com/broadinstitute/cromwell/pull/378:393,Testability,log,log,393,See the corresponding wdl4s change: https://github.com/broadinstitute/wdl4s/pull/6; See the corresponding Tyburn change: https://github.com/broadinstitute/tyburn/pull/17. Instead of creating these files:. ```; gs://path/to/call/jes.log; gs://path/to/call/jes-stdout.log; gs://path/to/call/jes-stderr.log; ```. We will now create (`hello` is the name of the call). ```; gs://path/to/call/hello.log; gs://path/to/call/hello-stdout.log; gs://path/to/call/hello-stderr.log; ```. We no longer manually redirect the stdout/stderr and let JES take care of it. [Example output](https://console.developers.google.com/storage/browser/cromwell-dev/stdout_stderr_passing/0f3758c3-b186-41d3-86c1-d92e55b24332/?project=broad-dsde-dev&pli=1) of running the WDL in https://github.com/broadinstitute/tyburn/pull/17,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/378
https://github.com/broadinstitute/cromwell/pull/378:429,Testability,log,log,429,See the corresponding wdl4s change: https://github.com/broadinstitute/wdl4s/pull/6; See the corresponding Tyburn change: https://github.com/broadinstitute/tyburn/pull/17. Instead of creating these files:. ```; gs://path/to/call/jes.log; gs://path/to/call/jes-stdout.log; gs://path/to/call/jes-stderr.log; ```. We will now create (`hello` is the name of the call). ```; gs://path/to/call/hello.log; gs://path/to/call/hello-stdout.log; gs://path/to/call/hello-stderr.log; ```. We no longer manually redirect the stdout/stderr and let JES take care of it. [Example output](https://console.developers.google.com/storage/browser/cromwell-dev/stdout_stderr_passing/0f3758c3-b186-41d3-86c1-d92e55b24332/?project=broad-dsde-dev&pli=1) of running the WDL in https://github.com/broadinstitute/tyburn/pull/17,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/378
https://github.com/broadinstitute/cromwell/pull/378:465,Testability,log,log,465,See the corresponding wdl4s change: https://github.com/broadinstitute/wdl4s/pull/6; See the corresponding Tyburn change: https://github.com/broadinstitute/tyburn/pull/17. Instead of creating these files:. ```; gs://path/to/call/jes.log; gs://path/to/call/jes-stdout.log; gs://path/to/call/jes-stderr.log; ```. We will now create (`hello` is the name of the call). ```; gs://path/to/call/hello.log; gs://path/to/call/hello-stdout.log; gs://path/to/call/hello-stderr.log; ```. We no longer manually redirect the stdout/stderr and let JES take care of it. [Example output](https://console.developers.google.com/storage/browser/cromwell-dev/stdout_stderr_passing/0f3758c3-b186-41d3-86c1-d92e55b24332/?project=broad-dsde-dev&pli=1) of running the WDL in https://github.com/broadinstitute/tyburn/pull/17,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/378
https://github.com/broadinstitute/cromwell/pull/379:0,Safety,Abort,Abort,0,"Abort was just failing everything, this fixes it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/379
https://github.com/broadinstitute/cromwell/pull/388:42,Security,validat,validation,42,Just after merging the runtime attributes validation I realized that there is a better way to get a JesBackend instance in the tests than mocking half of Cromwell.. so here it is,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/388
https://github.com/broadinstitute/cromwell/pull/388:127,Testability,test,tests,127,Just after merging the runtime attributes validation I realized that there is a better way to get a JesBackend instance in the tests than mocking half of Cromwell.. so here it is,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/388
https://github.com/broadinstitute/cromwell/pull/388:138,Testability,mock,mocking,138,Just after merging the runtime attributes validation I realized that there is a better way to get a JesBackend instance in the tests than mocking half of Cromwell.. so here it is,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/388
https://github.com/broadinstitute/cromwell/pull/395:252,Availability,echo,echo,252,JIRA: [DSDEEPB-2455](https://broadinstitute.atlassian.net/browse/DSDEEPB-2455); wdl4s PR: https://github.com/broadinstitute/wdl4s/pull/7. This WDL file now runs as expected. ```; task golden_pie {; Float pi = 3.1415926; Float tau = pi + pi. command {; echo 1.6180339887; echo ${tau} 1>&2; }. output {; Float Au = read_float(stdout()); Float tauValue = read_float(stderr()); }; }. workflow wf {; call golden_pie; output {; golden_pie.pi; golden_pie.Au; }; }; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/395
https://github.com/broadinstitute/cromwell/pull/395:271,Availability,echo,echo,271,JIRA: [DSDEEPB-2455](https://broadinstitute.atlassian.net/browse/DSDEEPB-2455); wdl4s PR: https://github.com/broadinstitute/wdl4s/pull/7. This WDL file now runs as expected. ```; task golden_pie {; Float pi = 3.1415926; Float tau = pi + pi. command {; echo 1.6180339887; echo ${tau} 1>&2; }. output {; Float Au = read_float(stdout()); Float tauValue = read_float(stderr()); }; }. workflow wf {; call golden_pie; output {; golden_pie.pi; golden_pie.Au; }; }; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/395
https://github.com/broadinstitute/cromwell/pull/398:147,Availability,avail,available,147,"Tagged all database specific tests as `IntegrationTest`.; As mysql now has 5s to timeout, increased the testing timeout used to detect if mysql is available.; Removed unused code and optimized imports.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/398
https://github.com/broadinstitute/cromwell/pull/398:39,Deployability,Integrat,IntegrationTest,39,"Tagged all database specific tests as `IntegrationTest`.; As mysql now has 5s to timeout, increased the testing timeout used to detect if mysql is available.; Removed unused code and optimized imports.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/398
https://github.com/broadinstitute/cromwell/pull/398:39,Integrability,Integrat,IntegrationTest,39,"Tagged all database specific tests as `IntegrationTest`.; As mysql now has 5s to timeout, increased the testing timeout used to detect if mysql is available.; Removed unused code and optimized imports.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/398
https://github.com/broadinstitute/cromwell/pull/398:183,Performance,optimiz,optimized,183,"Tagged all database specific tests as `IntegrationTest`.; As mysql now has 5s to timeout, increased the testing timeout used to detect if mysql is available.; Removed unused code and optimized imports.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/398
https://github.com/broadinstitute/cromwell/pull/398:81,Safety,timeout,timeout,81,"Tagged all database specific tests as `IntegrationTest`.; As mysql now has 5s to timeout, increased the testing timeout used to detect if mysql is available.; Removed unused code and optimized imports.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/398
https://github.com/broadinstitute/cromwell/pull/398:112,Safety,timeout,timeout,112,"Tagged all database specific tests as `IntegrationTest`.; As mysql now has 5s to timeout, increased the testing timeout used to detect if mysql is available.; Removed unused code and optimized imports.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/398
https://github.com/broadinstitute/cromwell/pull/398:128,Safety,detect,detect,128,"Tagged all database specific tests as `IntegrationTest`.; As mysql now has 5s to timeout, increased the testing timeout used to detect if mysql is available.; Removed unused code and optimized imports.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/398
https://github.com/broadinstitute/cromwell/pull/398:29,Testability,test,tests,29,"Tagged all database specific tests as `IntegrationTest`.; As mysql now has 5s to timeout, increased the testing timeout used to detect if mysql is available.; Removed unused code and optimized imports.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/398
https://github.com/broadinstitute/cromwell/pull/398:104,Testability,test,testing,104,"Tagged all database specific tests as `IntegrationTest`.; As mysql now has 5s to timeout, increased the testing timeout used to detect if mysql is available.; Removed unused code and optimized imports.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/398
https://github.com/broadinstitute/cromwell/pull/399:230,Usability,guid,guide,230,"To give people a lot more sight on the big architectural change which Intel have been working on, and see just how different it really is. Let's review the changes, make sure it meets the high Cromwell standards and try to review/guide the development to make sure this big architectural change gets done right for both sides.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/399
https://github.com/broadinstitute/cromwell/pull/400:230,Energy Efficiency,Monitor,Monitoring,230,"This contains a feature of accepting business events like workflow execution events and other events through the event bus provided by Akka framework and delegate them to centralized logging like Logstash, Fluentd etc for further Monitoring/UI status. There is also a wrapper that encapsulate event bus subscription/publication behaviour.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/400
https://github.com/broadinstitute/cromwell/pull/400:268,Integrability,wrap,wrapper,268,"This contains a feature of accepting business events like workflow execution events and other events through the event bus provided by Akka framework and delegate them to centralized logging like Logstash, Fluentd etc for further Monitoring/UI status. There is also a wrapper that encapsulate event bus subscription/publication behaviour.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/400
https://github.com/broadinstitute/cromwell/pull/400:183,Testability,log,logging,183,"This contains a feature of accepting business events like workflow execution events and other events through the event bus provided by Akka framework and delegate them to centralized logging like Logstash, Fluentd etc for further Monitoring/UI status. There is also a wrapper that encapsulate event bus subscription/publication behaviour.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/400
https://github.com/broadinstitute/cromwell/pull/400:196,Testability,Log,Logstash,196,"This contains a feature of accepting business events like workflow execution events and other events through the event bus provided by Akka framework and delegate them to centralized logging like Logstash, Fluentd etc for further Monitoring/UI status. There is also a wrapper that encapsulate event bus subscription/publication behaviour.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/400
https://github.com/broadinstitute/cromwell/pull/401:260,Usability,guid,guide,260,"Comment from @cjllanwarne: ; ""To give people a lot more sight on the big architectural change which Intel have been working on, and see just how different it really is. Let's review the changes, make sure it meets the high Cromwell standards and try to review/guide the development to make sure this big architectural change gets done right for both sides.""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/401
https://github.com/broadinstitute/cromwell/pull/403:57,Testability,test,test,57,"Added a database schema diff util using liquibase, and a test to verify the schema stays similar to slick.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/403
https://github.com/broadinstitute/cromwell/issues/404:404,Availability,echo,echo,404,"https://github.com/broadinstitute/cromwell#continueonreturncode; doesn't seem to work as documented for me. Here's the test I ran, and the behavior was identical to the behavior without continueOnReturnCode as far as I can tell. . This isn't a high priority for me - I believe we can get the information we need without this option. ; # cat error_continue.wdl. task hello {; String addressee; command {; echo ""Hello ${addressee}!"" && exit 1; }; output {; String salutation = read_string(stdout()); }; runtime {; docker: ""ubuntu:latest""; continueOnReturnCode: true; }; }. workflow w {; call hello; }; # curl -v ""localhost:8000/api/workflows/v1"" -F wdlSource=@error_continue.wdl -F workflowInputs=@hello.inputs. -> {; ""id"": ""dbd26ad6-5a29-4c80-8f49-8b5f53830782"",; ""status"": ""Submitted""; }; curl -v ""localhost:8000/api/workflows/v1/dbd26ad6-5a29-4c80-8f49-8b5f53830782/status""; -> {; ""id"": ""dbd26ad6-5a29-4c80-8f49-8b5f53830782"",; ""status"": ""Failed""; }; curl -v ""localhost:8000/api/workflows/v1/dbd26ad6-5a29-4c80-8f49-8b5f53830782/outputs""; {; ""id"": ""dbd26ad6-5a29-4c80-8f49-8b5f53830782"",; ""outputs"": {. }; }",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/404
https://github.com/broadinstitute/cromwell/issues/404:119,Testability,test,test,119,"https://github.com/broadinstitute/cromwell#continueonreturncode; doesn't seem to work as documented for me. Here's the test I ran, and the behavior was identical to the behavior without continueOnReturnCode as far as I can tell. . This isn't a high priority for me - I believe we can get the information we need without this option. ; # cat error_continue.wdl. task hello {; String addressee; command {; echo ""Hello ${addressee}!"" && exit 1; }; output {; String salutation = read_string(stdout()); }; runtime {; docker: ""ubuntu:latest""; continueOnReturnCode: true; }; }. workflow w {; call hello; }; # curl -v ""localhost:8000/api/workflows/v1"" -F wdlSource=@error_continue.wdl -F workflowInputs=@hello.inputs. -> {; ""id"": ""dbd26ad6-5a29-4c80-8f49-8b5f53830782"",; ""status"": ""Submitted""; }; curl -v ""localhost:8000/api/workflows/v1/dbd26ad6-5a29-4c80-8f49-8b5f53830782/status""; -> {; ""id"": ""dbd26ad6-5a29-4c80-8f49-8b5f53830782"",; ""status"": ""Failed""; }; curl -v ""localhost:8000/api/workflows/v1/dbd26ad6-5a29-4c80-8f49-8b5f53830782/outputs""; {; ""id"": ""dbd26ad6-5a29-4c80-8f49-8b5f53830782"",; ""outputs"": {. }; }",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/404
https://github.com/broadinstitute/cromwell/pull/405:75,Deployability,release,release-,75,RC branch for 0.17 is here https://github.com/broadinstitute/cromwell/tree/release-0.17,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/405
https://github.com/broadinstitute/cromwell/pull/407:46,Availability,error,errors,46,"Fix the ""non-infinite"" retry bug on transient errors",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/407
https://github.com/broadinstitute/cromwell/pull/413:54,Testability,test,testing,54,Basic structure should be okay but I haven't finished testing it.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/413
https://github.com/broadinstitute/cromwell/pull/420:122,Testability,test,test,122,"See corresponding wdl4s changes: https://github.com/broadinstitute/wdl4s/pull/9. We can now do stuff like this. ```; task test {; String tag; Int disk_gb; Int memory_gb. command { ps }; runtime {; docker: ""ubuntu:"" + tag; defaultDisks: ""Disk1 "" + disk_gb + "" SSD""; memory: memory_gb + "" GB""; }; }. workflow w {; call test; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/420
https://github.com/broadinstitute/cromwell/pull/420:317,Testability,test,test,317,"See corresponding wdl4s changes: https://github.com/broadinstitute/wdl4s/pull/9. We can now do stuff like this. ```; task test {; String tag; Int disk_gb; Int memory_gb. command { ps }; runtime {; docker: ""ubuntu:"" + tag; defaultDisks: ""Disk1 "" + disk_gb + "" SSD""; memory: memory_gb + "" GB""; }; }. workflow w {; call test; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/420
https://github.com/broadinstitute/cromwell/pull/427:23,Testability,test,testing,23,Needs cleanup and some testing around JES restart in particular but AFAICT works.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/427
https://github.com/broadinstitute/cromwell/issues/433:29,Integrability,message,message,29,"To create a workflow, send a message to WorkflowValidationActor with WorkflowSourceFiles, it tries to build a namespace and coerced inputs. If this passes, iterate the backends sending validation messages to the BackendWorkflowValidationActors. The workflow is validated if it passes one of these.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/433
https://github.com/broadinstitute/cromwell/issues/433:196,Integrability,message,messages,196,"To create a workflow, send a message to WorkflowValidationActor with WorkflowSourceFiles, it tries to build a namespace and coerced inputs. If this passes, iterate the backends sending validation messages to the BackendWorkflowValidationActors. The workflow is validated if it passes one of these.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/433
https://github.com/broadinstitute/cromwell/issues/433:185,Security,validat,validation,185,"To create a workflow, send a message to WorkflowValidationActor with WorkflowSourceFiles, it tries to build a namespace and coerced inputs. If this passes, iterate the backends sending validation messages to the BackendWorkflowValidationActors. The workflow is validated if it passes one of these.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/433
https://github.com/broadinstitute/cromwell/issues/433:261,Security,validat,validated,261,"To create a workflow, send a message to WorkflowValidationActor with WorkflowSourceFiles, it tries to build a namespace and coerced inputs. If this passes, iterate the backends sending validation messages to the BackendWorkflowValidationActors. The workflow is validated if it passes one of these.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/433
https://github.com/broadinstitute/cromwell/issues/435:22,Usability,resume,resume,22,Also make the restart/resume terminology consistent,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/435
https://github.com/broadinstitute/cromwell/pull/436:222,Availability,failure,failures,222,"This change makes workflows fail slow instead of fail fast. I'm uncomfortable committing this as-is because I don't fully understand when startRunnableCalls is used - and is it possible to miss the ""are we done (including failures)"" check. This _does_ work when a single call fails as part of a longer workflow. No other cases have been tested. Can anyone give me a quick tour of the control flow in WorkflowActor to make sure I haven't missed anything?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/436
https://github.com/broadinstitute/cromwell/pull/436:337,Testability,test,tested,337,"This change makes workflows fail slow instead of fail fast. I'm uncomfortable committing this as-is because I don't fully understand when startRunnableCalls is used - and is it possible to miss the ""are we done (including failures)"" check. This _does_ work when a single call fails as part of a longer workflow. No other cases have been tested. Can anyone give me a quick tour of the control flow in WorkflowActor to make sure I haven't missed anything?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/436
https://github.com/broadinstitute/cromwell/pull/441:121,Deployability,update,updates,121,"Specifically when you run with the command-line runner using the in-memory DB, it spits out pages and pages of liquibase updates",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/441
https://github.com/broadinstitute/cromwell/pull/442:119,Deployability,configurat,configuration,119,From investigation of https://broadinstitute.atlassian.net/browse/DSDEEPB-2736. We decided to have these values in the configuration but to keep them commented out so GotC can optionally tune these.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/442
https://github.com/broadinstitute/cromwell/pull/442:119,Modifiability,config,configuration,119,From investigation of https://broadinstitute.atlassian.net/browse/DSDEEPB-2736. We decided to have these values in the configuration but to keep them commented out so GotC can optionally tune these.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/442
https://github.com/broadinstitute/cromwell/pull/442:187,Performance,tune,tune,187,From investigation of https://broadinstitute.atlassian.net/browse/DSDEEPB-2736. We decided to have these values in the configuration but to keep them commented out so GotC can optionally tune these.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/442
https://github.com/broadinstitute/cromwell/pull/452:16,Availability,failure,failures,16,staring at test failures on branch leads to realization that test was broken on develop,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/452
https://github.com/broadinstitute/cromwell/pull/452:11,Testability,test,test,11,staring at test failures on branch leads to realization that test was broken on develop,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/452
https://github.com/broadinstitute/cromwell/pull/452:61,Testability,test,test,61,staring at test failures on branch leads to realization that test was broken on develop,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/452
https://github.com/broadinstitute/cromwell/pull/458:285,Usability,Simpl,SimpleHTTPServer,285,"To verify this fix, I did the following:; 1. rename the attached file (VIR_912.preempt.tieout.json) to 'metadata' and put it in a directory (e.g. /tmp/foo) along with the /src/main/resources/workflowTimings/workflowTimings.html from cromwell.; 2. From that directory run:; ; python -m SimpleHTTPServer 8080; to start up a simple http server on port 8080 serving out of the local directory; 3. Hit http://localhost:8080/workflowTimings.html in your browser. This works because the html makes a AJAX call to ./metadata to get the metadata for the chart. You can't do this on a local filesystem because of cross-site garbage but this simple server does the trick.; You can see the calls that have retries are labeled as such. For example AggregatedBamMarkDuplicates or the HaplotypeCaller (see attached screenshot). <img width=""534"" alt=""examplefix"" src=""https://cloud.githubusercontent.com/assets/1423491/13155522/2701b2fc-d64c-11e5-97a3-7b6f3be7bd10.png"">",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/458
https://github.com/broadinstitute/cromwell/pull/458:322,Usability,simpl,simple,322,"To verify this fix, I did the following:; 1. rename the attached file (VIR_912.preempt.tieout.json) to 'metadata' and put it in a directory (e.g. /tmp/foo) along with the /src/main/resources/workflowTimings/workflowTimings.html from cromwell.; 2. From that directory run:; ; python -m SimpleHTTPServer 8080; to start up a simple http server on port 8080 serving out of the local directory; 3. Hit http://localhost:8080/workflowTimings.html in your browser. This works because the html makes a AJAX call to ./metadata to get the metadata for the chart. You can't do this on a local filesystem because of cross-site garbage but this simple server does the trick.; You can see the calls that have retries are labeled as such. For example AggregatedBamMarkDuplicates or the HaplotypeCaller (see attached screenshot). <img width=""534"" alt=""examplefix"" src=""https://cloud.githubusercontent.com/assets/1423491/13155522/2701b2fc-d64c-11e5-97a3-7b6f3be7bd10.png"">",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/458
https://github.com/broadinstitute/cromwell/pull/458:631,Usability,simpl,simple,631,"To verify this fix, I did the following:; 1. rename the attached file (VIR_912.preempt.tieout.json) to 'metadata' and put it in a directory (e.g. /tmp/foo) along with the /src/main/resources/workflowTimings/workflowTimings.html from cromwell.; 2. From that directory run:; ; python -m SimpleHTTPServer 8080; to start up a simple http server on port 8080 serving out of the local directory; 3. Hit http://localhost:8080/workflowTimings.html in your browser. This works because the html makes a AJAX call to ./metadata to get the metadata for the chart. You can't do this on a local filesystem because of cross-site garbage but this simple server does the trick.; You can see the calls that have retries are labeled as such. For example AggregatedBamMarkDuplicates or the HaplotypeCaller (see attached screenshot). <img width=""534"" alt=""examplefix"" src=""https://cloud.githubusercontent.com/assets/1423491/13155522/2701b2fc-d64c-11e5-97a3-7b6f3be7bd10.png"">",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/458
https://github.com/broadinstitute/cromwell/pull/470:57,Deployability,pipeline,pipeline,57,- [x] CHANGELOG and README; - [x] Test with SingleSample pipeline; - [x] Add new Tyburn WDLs; - [x] Travis Tests Pass. wdl4s PR: https://github.com/broadinstitute/wdl4s/pull/14 [merged]; Tyburn PR: https://github.com/broadinstitute/tyburn/pull/27 [merged],MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/470
https://github.com/broadinstitute/cromwell/pull/470:34,Testability,Test,Test,34,- [x] CHANGELOG and README; - [x] Test with SingleSample pipeline; - [x] Add new Tyburn WDLs; - [x] Travis Tests Pass. wdl4s PR: https://github.com/broadinstitute/wdl4s/pull/14 [merged]; Tyburn PR: https://github.com/broadinstitute/tyburn/pull/27 [merged],MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/470
https://github.com/broadinstitute/cromwell/pull/470:107,Testability,Test,Tests,107,- [x] CHANGELOG and README; - [x] Test with SingleSample pipeline; - [x] Add new Tyburn WDLs; - [x] Travis Tests Pass. wdl4s PR: https://github.com/broadinstitute/wdl4s/pull/14 [merged]; Tyburn PR: https://github.com/broadinstitute/tyburn/pull/27 [merged],MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/470
https://github.com/broadinstitute/cromwell/issues/472:425,Availability,error,error,425,"When running a docker image through Cromwell, it assumes that you are the root user for the docker container. I was trying to run a docker image which has to be run as a non-root user, so they don't have access to the root user home folder (/root). The problem with this is that Cromwell will place any files you pass to the container in the /root directory, so you need to be the root user or else you will get a permission error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/472
https://github.com/broadinstitute/cromwell/issues/472:204,Security,access,access,204,"When running a docker image through Cromwell, it assumes that you are the root user for the docker container. I was trying to run a docker image which has to be run as a non-root user, so they don't have access to the root user home folder (/root). The problem with this is that Cromwell will place any files you pass to the container in the /root directory, so you need to be the root user or else you will get a permission error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/472
https://github.com/broadinstitute/cromwell/pull/473:20,Testability,test,test,20,Only fixes this one test (hopefully).; Once the - vs _ battle settles we can act accordingly.; A few things to consider are:; - ~most of our settings in application.conf are -; - All akka/spray conf settings are -; - All our workflow options are _; - There can be no - in wdl,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/473
https://github.com/broadinstitute/cromwell/issues/474:21,Usability,simpl,simple,21,This appears to be a simple parent/child relationship.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/474
https://github.com/broadinstitute/cromwell/issues/487:99,Energy Efficiency,adapt,adapted,99,"Look at code in existing but closed PRs in cromwell-backend/cromwell. This will need to be greatly adapted for develop, but should be doable.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/487
https://github.com/broadinstitute/cromwell/issues/487:99,Modifiability,adapt,adapted,99,"Look at code in existing but closed PRs in cromwell-backend/cromwell. This will need to be greatly adapted for develop, but should be doable.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/487
https://github.com/broadinstitute/cromwell/issues/489:0,Integrability,depend,depends,0,depends on #488,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/489
https://github.com/broadinstitute/cromwell/issues/494:89,Integrability,interface,interfaces,89,Add Cromwell-backend as a sub-project of Cromwell.; Cromwell-backend should have minimal interfaces needed to add basic required functionality in the future.; Connect #495,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/494
https://github.com/broadinstitute/cromwell/pull/495:77,Integrability,interface,interfaces,77,1. Added Cromwell-backend library as sub-project of Cromwell.; 2. Added base interfaces from Cromwell-backend.; 3. Tried to use SBT Git plugin for versioning but I couldn't get it work with sbt multi-projects. @geoffjentry and @scottfrazer could you please review this PR?,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/495
https://github.com/broadinstitute/cromwell/pull/495:136,Modifiability,plugin,plugin,136,1. Added Cromwell-backend library as sub-project of Cromwell.; 2. Added base interfaces from Cromwell-backend.; 3. Tried to use SBT Git plugin for versioning but I couldn't get it work with sbt multi-projects. @geoffjentry and @scottfrazer could you please review this PR?,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/495
https://github.com/broadinstitute/cromwell/pull/499:22,Testability,test,tests,22,"- [x] Run full Tyburn tests to make sure remaining failing workflows now pass. This appears to NOT affect the GotC workflow, but it does affect 3 of the Tyburn WDLs",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/499
https://github.com/broadinstitute/cromwell/pull/502:290,Modifiability,refactor,refactor,290,"This introduces a ~~`CallDescriptor`~~ `JobDescriptor` abstraction that I hope resembles what we'd want in the world of pluggable backends. Although this is a backend class, it holds a reference to a `WorkflowDescriptor` which still has tons of references to engine things which we plan to refactor out, possibly into backend. `CallDescriptor` currently interacts with `BackendCall`s because that's what Cromwell has right now. :smile: . There was one very special bit of weirdness about our backend handling exposed by `RetryableCallsSpec` where the backend passed to `WorkflowManagerActor` is not necessarily the same backend used to build `WorkflowDescriptor`s. :frowning: That could use some extra scrutiny by reviewers.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/502
https://github.com/broadinstitute/cromwell/pull/502:509,Security,expose,exposed,509,"This introduces a ~~`CallDescriptor`~~ `JobDescriptor` abstraction that I hope resembles what we'd want in the world of pluggable backends. Although this is a backend class, it holds a reference to a `WorkflowDescriptor` which still has tons of references to engine things which we plan to refactor out, possibly into backend. `CallDescriptor` currently interacts with `BackendCall`s because that's what Cromwell has right now. :smile: . There was one very special bit of weirdness about our backend handling exposed by `RetryableCallsSpec` where the backend passed to `WorkflowManagerActor` is not necessarily the same backend used to build `WorkflowDescriptor`s. :frowning: That could use some extra scrutiny by reviewers.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/502
https://github.com/broadinstitute/cromwell/issues/506:0,Integrability,depend,depends,0,depends on #497,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/506
https://github.com/broadinstitute/cromwell/issues/517:29,Availability,error,error,29,JES gave an intermittent 404 error when trying to copy outputs from the cached call directory to the current call directory (discovered by Vivek when using Call Caching for GoTC) . AC: Have Cromwell retry Call Caching when upon receipt of the 404 error.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/517
https://github.com/broadinstitute/cromwell/issues/517:247,Availability,error,error,247,JES gave an intermittent 404 error when trying to copy outputs from the cached call directory to the current call directory (discovered by Vivek when using Call Caching for GoTC) . AC: Have Cromwell retry Call Caching when upon receipt of the 404 error.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/517
https://github.com/broadinstitute/cromwell/issues/517:72,Performance,cache,cached,72,JES gave an intermittent 404 error when trying to copy outputs from the cached call directory to the current call directory (discovered by Vivek when using Call Caching for GoTC) . AC: Have Cromwell retry Call Caching when upon receipt of the 404 error.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/517
https://github.com/broadinstitute/cromwell/pull/519:17,Testability,test,tests,17,- [x] Run Tyburn tests,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/519
https://github.com/broadinstitute/cromwell/issues/520:2962,Performance,concurren,concurrent,2962,leLike$class.map(TraversableLike.scala:245); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.buildSymbolStoreEntries(WorkflowActor.scala:1049); at cromwell.engine.workflow.WorkflowActor.createWorkflow(WorkflowActor.scala:241); at cromwell.engine.workflow.WorkflowActor$Start.runInitialization(WorkflowActor.scala:120); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$initializeExecutionStore(WorkflowActor.scala:326); at cromwell.engine.workflow.WorkflowActor$$anonfun$1.applyOrElse(WorkflowActor.scala:364); at cromwell.engine.workflow.WorkflowActor$$anonfun$1.applyOrElse(WorkflowActor.scala:360); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:237); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActor.processEvent(WorkflowActor.scala:237); at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:598); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:592); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.WorkflowActor.aroundReceive(WorkflowActor.scala:237); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke(ActorCell.scala:487); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238); at akka.dispatch.Mailbox.run(Mailbox.scala:220); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/520
https://github.com/broadinstitute/cromwell/issues/520:3035,Performance,concurren,concurrent,3035,leLike$class.map(TraversableLike.scala:245); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.buildSymbolStoreEntries(WorkflowActor.scala:1049); at cromwell.engine.workflow.WorkflowActor.createWorkflow(WorkflowActor.scala:241); at cromwell.engine.workflow.WorkflowActor$Start.runInitialization(WorkflowActor.scala:120); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$initializeExecutionStore(WorkflowActor.scala:326); at cromwell.engine.workflow.WorkflowActor$$anonfun$1.applyOrElse(WorkflowActor.scala:364); at cromwell.engine.workflow.WorkflowActor$$anonfun$1.applyOrElse(WorkflowActor.scala:360); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:237); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActor.processEvent(WorkflowActor.scala:237); at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:598); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:592); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.WorkflowActor.aroundReceive(WorkflowActor.scala:237); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke(ActorCell.scala:487); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238); at akka.dispatch.Mailbox.run(Mailbox.scala:220); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/520
https://github.com/broadinstitute/cromwell/issues/520:3120,Performance,concurren,concurrent,3120,leLike$class.map(TraversableLike.scala:245); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.buildSymbolStoreEntries(WorkflowActor.scala:1049); at cromwell.engine.workflow.WorkflowActor.createWorkflow(WorkflowActor.scala:241); at cromwell.engine.workflow.WorkflowActor$Start.runInitialization(WorkflowActor.scala:120); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$initializeExecutionStore(WorkflowActor.scala:326); at cromwell.engine.workflow.WorkflowActor$$anonfun$1.applyOrElse(WorkflowActor.scala:364); at cromwell.engine.workflow.WorkflowActor$$anonfun$1.applyOrElse(WorkflowActor.scala:360); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:237); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActor.processEvent(WorkflowActor.scala:237); at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:598); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:592); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.WorkflowActor.aroundReceive(WorkflowActor.scala:237); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke(ActorCell.scala:487); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238); at akka.dispatch.Mailbox.run(Mailbox.scala:220); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/520
https://github.com/broadinstitute/cromwell/issues/520:3197,Performance,concurren,concurrent,3197,leLike$class.map(TraversableLike.scala:245); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.buildSymbolStoreEntries(WorkflowActor.scala:1049); at cromwell.engine.workflow.WorkflowActor.createWorkflow(WorkflowActor.scala:241); at cromwell.engine.workflow.WorkflowActor$Start.runInitialization(WorkflowActor.scala:120); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$initializeExecutionStore(WorkflowActor.scala:326); at cromwell.engine.workflow.WorkflowActor$$anonfun$1.applyOrElse(WorkflowActor.scala:364); at cromwell.engine.workflow.WorkflowActor$$anonfun$1.applyOrElse(WorkflowActor.scala:360); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:237); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActor.processEvent(WorkflowActor.scala:237); at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:598); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:592); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.WorkflowActor.aroundReceive(WorkflowActor.scala:237); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke(ActorCell.scala:487); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238); at akka.dispatch.Mailbox.run(Mailbox.scala:220); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/520
https://github.com/broadinstitute/cromwell/issues/520:416,Security,hash,hash,416,Give a JES-pointing server a non-GCS url in the inputs file and the API gives no response. Looking in the server logs you get . ```; java.lang.IllegalArgumentException: Not a valid Google Cloud Storage URI: /Users/chrisl/Desktop/workflowTimings.html; at cromwell.engine.io.gcs.GcsPath$.parse(GcsPath.scala:32); at cromwell.engine.io.gcs.GcsPath$.apply(GcsPath.scala:22); at cromwell.engine.io.gcs.GoogleCloudStorage.hash(GoogleCloudStorage.scala:76); at cromwell.engine.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:62); at cromwell.engine.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:62); at wdl4s.values.WdlValue$class.computeHash(WdlValue.scala:63); at wdl4s.values.WdlSingleFile.computeHash(WdlFile.scala:39); at cromwell.engine.WorkflowDescriptor.hash(WorkflowDescriptor.scala:176); at cromwell.engine.workflow.WorkflowActor$$anonfun$52.apply(WorkflowActor.scala:1050); at cromwell.engine.workflow.WorkflowActor$$anonfun$52.apply(WorkflowActor.scala:1049); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245); at scala.collection.immutable.Map$Map2.foreach(Map.scala:137); at scala.collection.TraversableLike$class.map(TraversableLike.scala:245); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.buildSymbolStoreEntries(WorkflowActor.scala:1049); at cromwell.engine.workflow.WorkflowActor.createWorkflow(WorkflowActor.scala:241); at cromwell.engine.workflow.WorkflowActor$Start.runInitialization(WorkflowActor.scala:120); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$initializeExecutionStore(WorkflowActor.scala:326); at cromwell.engine.workflow.WorkflowActor$$anonfun$1.applyOrElse(WorkflowActor.scala:364); at cromwell.engine.workflow.WorkflowActor$$anonfun$1.applyOrElse(WorkflowActor.scala:360); at scala.runtime.AbstractPar,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/520
https://github.com/broadinstitute/cromwell/issues/520:805,Security,hash,hash,805,Give a JES-pointing server a non-GCS url in the inputs file and the API gives no response. Looking in the server logs you get . ```; java.lang.IllegalArgumentException: Not a valid Google Cloud Storage URI: /Users/chrisl/Desktop/workflowTimings.html; at cromwell.engine.io.gcs.GcsPath$.parse(GcsPath.scala:32); at cromwell.engine.io.gcs.GcsPath$.apply(GcsPath.scala:22); at cromwell.engine.io.gcs.GoogleCloudStorage.hash(GoogleCloudStorage.scala:76); at cromwell.engine.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:62); at cromwell.engine.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:62); at wdl4s.values.WdlValue$class.computeHash(WdlValue.scala:63); at wdl4s.values.WdlSingleFile.computeHash(WdlFile.scala:39); at cromwell.engine.WorkflowDescriptor.hash(WorkflowDescriptor.scala:176); at cromwell.engine.workflow.WorkflowActor$$anonfun$52.apply(WorkflowActor.scala:1050); at cromwell.engine.workflow.WorkflowActor$$anonfun$52.apply(WorkflowActor.scala:1049); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245); at scala.collection.immutable.Map$Map2.foreach(Map.scala:137); at scala.collection.TraversableLike$class.map(TraversableLike.scala:245); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.buildSymbolStoreEntries(WorkflowActor.scala:1049); at cromwell.engine.workflow.WorkflowActor.createWorkflow(WorkflowActor.scala:241); at cromwell.engine.workflow.WorkflowActor$Start.runInitialization(WorkflowActor.scala:120); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$initializeExecutionStore(WorkflowActor.scala:326); at cromwell.engine.workflow.WorkflowActor$$anonfun$1.applyOrElse(WorkflowActor.scala:364); at cromwell.engine.workflow.WorkflowActor$$anonfun$1.applyOrElse(WorkflowActor.scala:360); at scala.runtime.AbstractPar,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/520
https://github.com/broadinstitute/cromwell/issues/520:113,Testability,log,logs,113,Give a JES-pointing server a non-GCS url in the inputs file and the API gives no response. Looking in the server logs you get . ```; java.lang.IllegalArgumentException: Not a valid Google Cloud Storage URI: /Users/chrisl/Desktop/workflowTimings.html; at cromwell.engine.io.gcs.GcsPath$.parse(GcsPath.scala:32); at cromwell.engine.io.gcs.GcsPath$.apply(GcsPath.scala:22); at cromwell.engine.io.gcs.GoogleCloudStorage.hash(GoogleCloudStorage.scala:76); at cromwell.engine.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:62); at cromwell.engine.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:62); at wdl4s.values.WdlValue$class.computeHash(WdlValue.scala:63); at wdl4s.values.WdlSingleFile.computeHash(WdlFile.scala:39); at cromwell.engine.WorkflowDescriptor.hash(WorkflowDescriptor.scala:176); at cromwell.engine.workflow.WorkflowActor$$anonfun$52.apply(WorkflowActor.scala:1050); at cromwell.engine.workflow.WorkflowActor$$anonfun$52.apply(WorkflowActor.scala:1049); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245); at scala.collection.immutable.Map$Map2.foreach(Map.scala:137); at scala.collection.TraversableLike$class.map(TraversableLike.scala:245); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.buildSymbolStoreEntries(WorkflowActor.scala:1049); at cromwell.engine.workflow.WorkflowActor.createWorkflow(WorkflowActor.scala:241); at cromwell.engine.workflow.WorkflowActor$Start.runInitialization(WorkflowActor.scala:120); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$initializeExecutionStore(WorkflowActor.scala:326); at cromwell.engine.workflow.WorkflowActor$$anonfun$1.applyOrElse(WorkflowActor.scala:364); at cromwell.engine.workflow.WorkflowActor$$anonfun$1.applyOrElse(WorkflowActor.scala:360); at scala.runtime.AbstractPar,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/520
https://github.com/broadinstitute/cromwell/issues/520:2161,Testability,Log,LoggingFSM,2161,:245); at scala.collection.immutable.Map$Map2.foreach(Map.scala:137); at scala.collection.TraversableLike$class.map(TraversableLike.scala:245); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.buildSymbolStoreEntries(WorkflowActor.scala:1049); at cromwell.engine.workflow.WorkflowActor.createWorkflow(WorkflowActor.scala:241); at cromwell.engine.workflow.WorkflowActor$Start.runInitialization(WorkflowActor.scala:120); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$initializeExecutionStore(WorkflowActor.scala:326); at cromwell.engine.workflow.WorkflowActor$$anonfun$1.applyOrElse(WorkflowActor.scala:364); at cromwell.engine.workflow.WorkflowActor$$anonfun$1.applyOrElse(WorkflowActor.scala:360); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:237); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActor.processEvent(WorkflowActor.scala:237); at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:598); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:592); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.WorkflowActor.aroundReceive(WorkflowActor.scala:237); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke(ActorCell.scala:487); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238); at akka.dispatch.Mailbox.run(Mailbox.scala:220); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.ja,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/520
https://github.com/broadinstitute/cromwell/issues/520:2232,Testability,Log,LoggingFSM,2232,a:137); at scala.collection.TraversableLike$class.map(TraversableLike.scala:245); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.buildSymbolStoreEntries(WorkflowActor.scala:1049); at cromwell.engine.workflow.WorkflowActor.createWorkflow(WorkflowActor.scala:241); at cromwell.engine.workflow.WorkflowActor$Start.runInitialization(WorkflowActor.scala:120); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$initializeExecutionStore(WorkflowActor.scala:326); at cromwell.engine.workflow.WorkflowActor$$anonfun$1.applyOrElse(WorkflowActor.scala:364); at cromwell.engine.workflow.WorkflowActor$$anonfun$1.applyOrElse(WorkflowActor.scala:360); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:237); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActor.processEvent(WorkflowActor.scala:237); at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:598); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:592); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.WorkflowActor.aroundReceive(WorkflowActor.scala:237); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke(ActorCell.scala:487); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238); at akka.dispatch.Mailbox.run(Mailbox.scala:220); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/520
https://github.com/broadinstitute/cromwell/pull/522:53,Security,validat,validation,53,"Solves #488. ; Initial work for Making a centralized validation. Currently, it brings the methods for inputs/options/runtime attr. validation, and uses it for validation via endpoints (like before). Next step will be to make Workflow descriptor a little cleaner, by removing (most) of the validation from there and only instantiate the WorkflowDescriptor once the WDL passes validation (in the WFManagerActor).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/522
https://github.com/broadinstitute/cromwell/pull/522:131,Security,validat,validation,131,"Solves #488. ; Initial work for Making a centralized validation. Currently, it brings the methods for inputs/options/runtime attr. validation, and uses it for validation via endpoints (like before). Next step will be to make Workflow descriptor a little cleaner, by removing (most) of the validation from there and only instantiate the WorkflowDescriptor once the WDL passes validation (in the WFManagerActor).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/522
https://github.com/broadinstitute/cromwell/pull/522:159,Security,validat,validation,159,"Solves #488. ; Initial work for Making a centralized validation. Currently, it brings the methods for inputs/options/runtime attr. validation, and uses it for validation via endpoints (like before). Next step will be to make Workflow descriptor a little cleaner, by removing (most) of the validation from there and only instantiate the WorkflowDescriptor once the WDL passes validation (in the WFManagerActor).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/522
https://github.com/broadinstitute/cromwell/pull/522:289,Security,validat,validation,289,"Solves #488. ; Initial work for Making a centralized validation. Currently, it brings the methods for inputs/options/runtime attr. validation, and uses it for validation via endpoints (like before). Next step will be to make Workflow descriptor a little cleaner, by removing (most) of the validation from there and only instantiate the WorkflowDescriptor once the WDL passes validation (in the WFManagerActor).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/522
https://github.com/broadinstitute/cromwell/pull/522:375,Security,validat,validation,375,"Solves #488. ; Initial work for Making a centralized validation. Currently, it brings the methods for inputs/options/runtime attr. validation, and uses it for validation via endpoints (like before). Next step will be to make Workflow descriptor a little cleaner, by removing (most) of the validation from there and only instantiate the WorkflowDescriptor once the WDL passes validation (in the WFManagerActor).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/522
https://github.com/broadinstitute/cromwell/pull/524:700,Availability,avail,available,700,"I know that this is bigger than what the issue says - I'm sorry about that. It just felt like now or never to rework a little bit our communication with GCS and remove some duplicate code in the process. This PR removes the `IoInterface`/`IoManager` and uses `java.nio.FileSystem` implementations instead to provide file system interactions.; The (now removed) `IoInterface` was nothing but a wrapper interface around a `FileSystem`.; The (also removed) `IoManager` was a wrapper of `IoInterface`s that selected the most appropriate interface according to the path to be processed. This functionality is now provided by the `cromwell.engine.backend.io.PathString.toPath` method which takes a list of available `FileSystem`s and tries to create a `java.nio.Path`. If it succeeds (ie if there is a suitable `FileSystem` able to parse the raw `String`), the created `Path` can now be used in an abstract way (with `Files.*`) or `better.files` as long as the corresponding `FileSystemProvider` implements the required methods. . The `WdlStandardLibraryImpl` now has a `List[FileSystem]` at its disposal and uses it to parse raw `String` paths with the `toPath` method. Most of the implementation can then be the same and rely entirely on the `FileSystem`s implementations. Engine functions can always be overridden by their respective backend implementations if a special treatment is needed. The functionalities previously in `GoogleCloudStorage` have been merged into `GcsFileSystemProvider`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/524
https://github.com/broadinstitute/cromwell/pull/524:393,Integrability,wrap,wrapper,393,"I know that this is bigger than what the issue says - I'm sorry about that. It just felt like now or never to rework a little bit our communication with GCS and remove some duplicate code in the process. This PR removes the `IoInterface`/`IoManager` and uses `java.nio.FileSystem` implementations instead to provide file system interactions.; The (now removed) `IoInterface` was nothing but a wrapper interface around a `FileSystem`.; The (also removed) `IoManager` was a wrapper of `IoInterface`s that selected the most appropriate interface according to the path to be processed. This functionality is now provided by the `cromwell.engine.backend.io.PathString.toPath` method which takes a list of available `FileSystem`s and tries to create a `java.nio.Path`. If it succeeds (ie if there is a suitable `FileSystem` able to parse the raw `String`), the created `Path` can now be used in an abstract way (with `Files.*`) or `better.files` as long as the corresponding `FileSystemProvider` implements the required methods. . The `WdlStandardLibraryImpl` now has a `List[FileSystem]` at its disposal and uses it to parse raw `String` paths with the `toPath` method. Most of the implementation can then be the same and rely entirely on the `FileSystem`s implementations. Engine functions can always be overridden by their respective backend implementations if a special treatment is needed. The functionalities previously in `GoogleCloudStorage` have been merged into `GcsFileSystemProvider`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/524
https://github.com/broadinstitute/cromwell/pull/524:401,Integrability,interface,interface,401,"I know that this is bigger than what the issue says - I'm sorry about that. It just felt like now or never to rework a little bit our communication with GCS and remove some duplicate code in the process. This PR removes the `IoInterface`/`IoManager` and uses `java.nio.FileSystem` implementations instead to provide file system interactions.; The (now removed) `IoInterface` was nothing but a wrapper interface around a `FileSystem`.; The (also removed) `IoManager` was a wrapper of `IoInterface`s that selected the most appropriate interface according to the path to be processed. This functionality is now provided by the `cromwell.engine.backend.io.PathString.toPath` method which takes a list of available `FileSystem`s and tries to create a `java.nio.Path`. If it succeeds (ie if there is a suitable `FileSystem` able to parse the raw `String`), the created `Path` can now be used in an abstract way (with `Files.*`) or `better.files` as long as the corresponding `FileSystemProvider` implements the required methods. . The `WdlStandardLibraryImpl` now has a `List[FileSystem]` at its disposal and uses it to parse raw `String` paths with the `toPath` method. Most of the implementation can then be the same and rely entirely on the `FileSystem`s implementations. Engine functions can always be overridden by their respective backend implementations if a special treatment is needed. The functionalities previously in `GoogleCloudStorage` have been merged into `GcsFileSystemProvider`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/524
https://github.com/broadinstitute/cromwell/pull/524:472,Integrability,wrap,wrapper,472,"I know that this is bigger than what the issue says - I'm sorry about that. It just felt like now or never to rework a little bit our communication with GCS and remove some duplicate code in the process. This PR removes the `IoInterface`/`IoManager` and uses `java.nio.FileSystem` implementations instead to provide file system interactions.; The (now removed) `IoInterface` was nothing but a wrapper interface around a `FileSystem`.; The (also removed) `IoManager` was a wrapper of `IoInterface`s that selected the most appropriate interface according to the path to be processed. This functionality is now provided by the `cromwell.engine.backend.io.PathString.toPath` method which takes a list of available `FileSystem`s and tries to create a `java.nio.Path`. If it succeeds (ie if there is a suitable `FileSystem` able to parse the raw `String`), the created `Path` can now be used in an abstract way (with `Files.*`) or `better.files` as long as the corresponding `FileSystemProvider` implements the required methods. . The `WdlStandardLibraryImpl` now has a `List[FileSystem]` at its disposal and uses it to parse raw `String` paths with the `toPath` method. Most of the implementation can then be the same and rely entirely on the `FileSystem`s implementations. Engine functions can always be overridden by their respective backend implementations if a special treatment is needed. The functionalities previously in `GoogleCloudStorage` have been merged into `GcsFileSystemProvider`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/524
https://github.com/broadinstitute/cromwell/pull/524:533,Integrability,interface,interface,533,"I know that this is bigger than what the issue says - I'm sorry about that. It just felt like now or never to rework a little bit our communication with GCS and remove some duplicate code in the process. This PR removes the `IoInterface`/`IoManager` and uses `java.nio.FileSystem` implementations instead to provide file system interactions.; The (now removed) `IoInterface` was nothing but a wrapper interface around a `FileSystem`.; The (also removed) `IoManager` was a wrapper of `IoInterface`s that selected the most appropriate interface according to the path to be processed. This functionality is now provided by the `cromwell.engine.backend.io.PathString.toPath` method which takes a list of available `FileSystem`s and tries to create a `java.nio.Path`. If it succeeds (ie if there is a suitable `FileSystem` able to parse the raw `String`), the created `Path` can now be used in an abstract way (with `Files.*`) or `better.files` as long as the corresponding `FileSystemProvider` implements the required methods. . The `WdlStandardLibraryImpl` now has a `List[FileSystem]` at its disposal and uses it to parse raw `String` paths with the `toPath` method. Most of the implementation can then be the same and rely entirely on the `FileSystem`s implementations. Engine functions can always be overridden by their respective backend implementations if a special treatment is needed. The functionalities previously in `GoogleCloudStorage` have been merged into `GcsFileSystemProvider`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/524
https://github.com/broadinstitute/cromwell/pull/527:541,Integrability,depend,dependency,541,"Far from perfect, but starts moving towards a repo with multiple sub-projects. . Key highlights:; - All current code except for Main and Main related stuff has been moved to an `engine` subproject. Yes astute reader, you're correct - not everything actually belongs there. The idea is that we'll peel stuff out as we go along.; - Creates a `core` subproject (currently empty) for code which doesn't have a true home but should be shared. For example, if something would otherwise move from `engine` to `backend` for no other reason than the dependency direction and it really isn't a backend-y thing.; - The root project depends on `core`, `engine` and `backend`, `engine` depends on `backend` and `core` and `backend` on `core`; - Started to decompose our SBT structure into more digestible chunks to make it easier to figure out what is where. Key lowlights:; - All of the code which went into `engine` retained `cromwell` as the package instead of `cromwell.engine`, which causes IntelliJ to whine. I thought it'd be weird as there _is_ a `cromwell.engine` package already (`cromwell.engine.engine`?). However I view this as a temporary thing, I figure stuff is going to be moving around and we can figure out a package/naming structure which makes sense once we see what's where.; - Some of the abstractions are a little hokey at the moment as a side effect of 99.9999999% of the code living in one subproject. I expect that to start changing soon, mainly I was trying to give some examples of a path forward; - I'm almost positive there's a lot more stuff going on than necessary (e.g. multiple de-dups, etc). Example - I want to disable assembly on all subprojects but backend, but i still wanted to run tests. Wasn't clear how to have root assembly run tests but not assembly on other subprojects; - I'm 100% certain that some of the sbt directives aren't totally idiomatic (which causes the previous statement); - Some of the ancillary stuff (e.g. conf files) might need to be rethought. I cha",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/527
https://github.com/broadinstitute/cromwell/pull/527:621,Integrability,depend,depends,621,"Far from perfect, but starts moving towards a repo with multiple sub-projects. . Key highlights:; - All current code except for Main and Main related stuff has been moved to an `engine` subproject. Yes astute reader, you're correct - not everything actually belongs there. The idea is that we'll peel stuff out as we go along.; - Creates a `core` subproject (currently empty) for code which doesn't have a true home but should be shared. For example, if something would otherwise move from `engine` to `backend` for no other reason than the dependency direction and it really isn't a backend-y thing.; - The root project depends on `core`, `engine` and `backend`, `engine` depends on `backend` and `core` and `backend` on `core`; - Started to decompose our SBT structure into more digestible chunks to make it easier to figure out what is where. Key lowlights:; - All of the code which went into `engine` retained `cromwell` as the package instead of `cromwell.engine`, which causes IntelliJ to whine. I thought it'd be weird as there _is_ a `cromwell.engine` package already (`cromwell.engine.engine`?). However I view this as a temporary thing, I figure stuff is going to be moving around and we can figure out a package/naming structure which makes sense once we see what's where.; - Some of the abstractions are a little hokey at the moment as a side effect of 99.9999999% of the code living in one subproject. I expect that to start changing soon, mainly I was trying to give some examples of a path forward; - I'm almost positive there's a lot more stuff going on than necessary (e.g. multiple de-dups, etc). Example - I want to disable assembly on all subprojects but backend, but i still wanted to run tests. Wasn't clear how to have root assembly run tests but not assembly on other subprojects; - I'm 100% certain that some of the sbt directives aren't totally idiomatic (which causes the previous statement); - Some of the ancillary stuff (e.g. conf files) might need to be rethought. I cha",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/527
https://github.com/broadinstitute/cromwell/pull/527:673,Integrability,depend,depends,673,"Far from perfect, but starts moving towards a repo with multiple sub-projects. . Key highlights:; - All current code except for Main and Main related stuff has been moved to an `engine` subproject. Yes astute reader, you're correct - not everything actually belongs there. The idea is that we'll peel stuff out as we go along.; - Creates a `core` subproject (currently empty) for code which doesn't have a true home but should be shared. For example, if something would otherwise move from `engine` to `backend` for no other reason than the dependency direction and it really isn't a backend-y thing.; - The root project depends on `core`, `engine` and `backend`, `engine` depends on `backend` and `core` and `backend` on `core`; - Started to decompose our SBT structure into more digestible chunks to make it easier to figure out what is where. Key lowlights:; - All of the code which went into `engine` retained `cromwell` as the package instead of `cromwell.engine`, which causes IntelliJ to whine. I thought it'd be weird as there _is_ a `cromwell.engine` package already (`cromwell.engine.engine`?). However I view this as a temporary thing, I figure stuff is going to be moving around and we can figure out a package/naming structure which makes sense once we see what's where.; - Some of the abstractions are a little hokey at the moment as a side effect of 99.9999999% of the code living in one subproject. I expect that to start changing soon, mainly I was trying to give some examples of a path forward; - I'm almost positive there's a lot more stuff going on than necessary (e.g. multiple de-dups, etc). Example - I want to disable assembly on all subprojects but backend, but i still wanted to run tests. Wasn't clear how to have root assembly run tests but not assembly on other subprojects; - I'm 100% certain that some of the sbt directives aren't totally idiomatic (which causes the previous statement); - Some of the ancillary stuff (e.g. conf files) might need to be rethought. I cha",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/527
https://github.com/broadinstitute/cromwell/pull/527:1710,Testability,test,tests,1710,"pt for Main and Main related stuff has been moved to an `engine` subproject. Yes astute reader, you're correct - not everything actually belongs there. The idea is that we'll peel stuff out as we go along.; - Creates a `core` subproject (currently empty) for code which doesn't have a true home but should be shared. For example, if something would otherwise move from `engine` to `backend` for no other reason than the dependency direction and it really isn't a backend-y thing.; - The root project depends on `core`, `engine` and `backend`, `engine` depends on `backend` and `core` and `backend` on `core`; - Started to decompose our SBT structure into more digestible chunks to make it easier to figure out what is where. Key lowlights:; - All of the code which went into `engine` retained `cromwell` as the package instead of `cromwell.engine`, which causes IntelliJ to whine. I thought it'd be weird as there _is_ a `cromwell.engine` package already (`cromwell.engine.engine`?). However I view this as a temporary thing, I figure stuff is going to be moving around and we can figure out a package/naming structure which makes sense once we see what's where.; - Some of the abstractions are a little hokey at the moment as a side effect of 99.9999999% of the code living in one subproject. I expect that to start changing soon, mainly I was trying to give some examples of a path forward; - I'm almost positive there's a lot more stuff going on than necessary (e.g. multiple de-dups, etc). Example - I want to disable assembly on all subprojects but backend, but i still wanted to run tests. Wasn't clear how to have root assembly run tests but not assembly on other subprojects; - I'm 100% certain that some of the sbt directives aren't totally idiomatic (which causes the previous statement); - Some of the ancillary stuff (e.g. conf files) might need to be rethought. I chalk that up along the same lines as the package naming in that some of this stuff will become more clear as it progresses",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/527
https://github.com/broadinstitute/cromwell/pull/527:1760,Testability,test,tests,1760,"pt for Main and Main related stuff has been moved to an `engine` subproject. Yes astute reader, you're correct - not everything actually belongs there. The idea is that we'll peel stuff out as we go along.; - Creates a `core` subproject (currently empty) for code which doesn't have a true home but should be shared. For example, if something would otherwise move from `engine` to `backend` for no other reason than the dependency direction and it really isn't a backend-y thing.; - The root project depends on `core`, `engine` and `backend`, `engine` depends on `backend` and `core` and `backend` on `core`; - Started to decompose our SBT structure into more digestible chunks to make it easier to figure out what is where. Key lowlights:; - All of the code which went into `engine` retained `cromwell` as the package instead of `cromwell.engine`, which causes IntelliJ to whine. I thought it'd be weird as there _is_ a `cromwell.engine` package already (`cromwell.engine.engine`?). However I view this as a temporary thing, I figure stuff is going to be moving around and we can figure out a package/naming structure which makes sense once we see what's where.; - Some of the abstractions are a little hokey at the moment as a side effect of 99.9999999% of the code living in one subproject. I expect that to start changing soon, mainly I was trying to give some examples of a path forward; - I'm almost positive there's a lot more stuff going on than necessary (e.g. multiple de-dups, etc). Example - I want to disable assembly on all subprojects but backend, but i still wanted to run tests. Wasn't clear how to have root assembly run tests but not assembly on other subprojects; - I'm 100% certain that some of the sbt directives aren't totally idiomatic (which causes the previous statement); - Some of the ancillary stuff (e.g. conf files) might need to be rethought. I chalk that up along the same lines as the package naming in that some of this stuff will become more clear as it progresses",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/527
https://github.com/broadinstitute/cromwell/pull/527:1724,Usability,clear,clear,1724,"pt for Main and Main related stuff has been moved to an `engine` subproject. Yes astute reader, you're correct - not everything actually belongs there. The idea is that we'll peel stuff out as we go along.; - Creates a `core` subproject (currently empty) for code which doesn't have a true home but should be shared. For example, if something would otherwise move from `engine` to `backend` for no other reason than the dependency direction and it really isn't a backend-y thing.; - The root project depends on `core`, `engine` and `backend`, `engine` depends on `backend` and `core` and `backend` on `core`; - Started to decompose our SBT structure into more digestible chunks to make it easier to figure out what is where. Key lowlights:; - All of the code which went into `engine` retained `cromwell` as the package instead of `cromwell.engine`, which causes IntelliJ to whine. I thought it'd be weird as there _is_ a `cromwell.engine` package already (`cromwell.engine.engine`?). However I view this as a temporary thing, I figure stuff is going to be moving around and we can figure out a package/naming structure which makes sense once we see what's where.; - Some of the abstractions are a little hokey at the moment as a side effect of 99.9999999% of the code living in one subproject. I expect that to start changing soon, mainly I was trying to give some examples of a path forward; - I'm almost positive there's a lot more stuff going on than necessary (e.g. multiple de-dups, etc). Example - I want to disable assembly on all subprojects but backend, but i still wanted to run tests. Wasn't clear how to have root assembly run tests but not assembly on other subprojects; - I'm 100% certain that some of the sbt directives aren't totally idiomatic (which causes the previous statement); - Some of the ancillary stuff (e.g. conf files) might need to be rethought. I chalk that up along the same lines as the package naming in that some of this stuff will become more clear as it progresses",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/527
https://github.com/broadinstitute/cromwell/pull/527:2099,Usability,clear,clear,2099,"pt for Main and Main related stuff has been moved to an `engine` subproject. Yes astute reader, you're correct - not everything actually belongs there. The idea is that we'll peel stuff out as we go along.; - Creates a `core` subproject (currently empty) for code which doesn't have a true home but should be shared. For example, if something would otherwise move from `engine` to `backend` for no other reason than the dependency direction and it really isn't a backend-y thing.; - The root project depends on `core`, `engine` and `backend`, `engine` depends on `backend` and `core` and `backend` on `core`; - Started to decompose our SBT structure into more digestible chunks to make it easier to figure out what is where. Key lowlights:; - All of the code which went into `engine` retained `cromwell` as the package instead of `cromwell.engine`, which causes IntelliJ to whine. I thought it'd be weird as there _is_ a `cromwell.engine` package already (`cromwell.engine.engine`?). However I view this as a temporary thing, I figure stuff is going to be moving around and we can figure out a package/naming structure which makes sense once we see what's where.; - Some of the abstractions are a little hokey at the moment as a side effect of 99.9999999% of the code living in one subproject. I expect that to start changing soon, mainly I was trying to give some examples of a path forward; - I'm almost positive there's a lot more stuff going on than necessary (e.g. multiple de-dups, etc). Example - I want to disable assembly on all subprojects but backend, but i still wanted to run tests. Wasn't clear how to have root assembly run tests but not assembly on other subprojects; - I'm 100% certain that some of the sbt directives aren't totally idiomatic (which causes the previous statement); - Some of the ancillary stuff (e.g. conf files) might need to be rethought. I chalk that up along the same lines as the package naming in that some of this stuff will become more clear as it progresses",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/527
https://github.com/broadinstitute/cromwell/issues/531:173,Availability,echo,echo,173,"The following workflow always fails on JES if call-caching is enabled. File paths are getting horribly mangled and the getHash fails. ```; task mirror {; File x; command {; echo noop; }; output {; File y = x; }; }. workflow call_caching {; File x_in; Array[Int] blahs = [1,2,3,4,5,6,7,8,9,10]. call mirror { input: x = x_in }. scatter ( blah in blahs ) {; call mirror as cached_mirror1 { input: x = mirror.y }; call mirror as cached_mirror2 { input: x = cached_mirror1.y }; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/531
https://github.com/broadinstitute/cromwell/pull/532:41,Security,authenticat,authentication,41,I did not add documentation for the user authentication portion because I didn't understand how it works! If somebody would like to explain it to me I can expand these docs,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/532
https://github.com/broadinstitute/cromwell/issues/537:82,Availability,error,errors,82,"Once we decide on a style guide, go through the code and resolve all the issues / errors cropping up because of the check style.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/537
https://github.com/broadinstitute/cromwell/issues/537:26,Usability,guid,guide,26,"Once we decide on a style guide, go through the code and resolve all the issues / errors cropping up because of the check style.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/537
https://github.com/broadinstitute/cromwell/pull/548:30,Security,Validat,ValidateActor,30,CromwellApiHandler now uses a ValidateActor to validate a WF received via the API endpoint,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/548
https://github.com/broadinstitute/cromwell/pull/548:47,Security,validat,validate,47,CromwellApiHandler now uses a ValidateActor to validate a WF received via the API endpoint,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/548
https://github.com/broadinstitute/cromwell/issues/554:157,Availability,down,down,157,Backend should not have any dependency from Engine.; This means that all utils implementation should be moved to backend or removed.; It may require a break down in sub-tasks.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/554
https://github.com/broadinstitute/cromwell/issues/554:28,Integrability,depend,dependency,28,Backend should not have any dependency from Engine.; This means that all utils implementation should be moved to backend or removed.; It may require a break down in sub-tasks.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/554
https://github.com/broadinstitute/cromwell/issues/559:182,Safety,avoid,avoid,182,"At least ""allows result reuse"" and ""results cloned"" (the latter being transformed from an fk to a boolean). Returning hashes might be helpful too for diagnosing why executions don't avoid.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/559
https://github.com/broadinstitute/cromwell/issues/559:118,Security,hash,hashes,118,"At least ""allows result reuse"" and ""results cloned"" (the latter being transformed from an fk to a boolean). Returning hashes might be helpful too for diagnosing why executions don't avoid.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/559
https://github.com/broadinstitute/cromwell/pull/562:28,Security,Validat,ValidateActor,28,Added scalaz lib support to ValidateActor in order to match Workflow descriptor.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/562
https://github.com/broadinstitute/cromwell/issues/564:130,Availability,error,error,130,"Proposed high-level flow:. Workflows + inputs + options are submitted. Any grossly malformed submission would quickly generate an error returned to the client immediately. Otherwise save everything to WORKFLOW_EXECUTION and WORKFLOW_EXECUTION_AUX at status Submitted, and return the generated UUID to the client. THAT’S IT. Do not validate workflows synchronously to submission, that’s expensive and difficult to throttle back. The returned UUID constitutes a pollable handle for the submission. Technically this UUID is now a submission ID rather than a workflow ID, though if the workflow is eventually validated that UUID could certainly be thought of as the workflow ID. When Cromwell is ready to validate a submission, the status of the WORKFLOW_EXECUTION can be moved to Validating and validation initiated. Assuming the validation succeeds the workflow would move to state Validated. Again when Cromwell is ready to run the workflow, it can be moved to state Running and the workflow would begin to run. Workflows that fail validation would get status Failed with text describing the nature of the failures in the FAILURE_MESSAGES table.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/564
https://github.com/broadinstitute/cromwell/issues/564:1105,Availability,failure,failures,1105,"Proposed high-level flow:. Workflows + inputs + options are submitted. Any grossly malformed submission would quickly generate an error returned to the client immediately. Otherwise save everything to WORKFLOW_EXECUTION and WORKFLOW_EXECUTION_AUX at status Submitted, and return the generated UUID to the client. THAT’S IT. Do not validate workflows synchronously to submission, that’s expensive and difficult to throttle back. The returned UUID constitutes a pollable handle for the submission. Technically this UUID is now a submission ID rather than a workflow ID, though if the workflow is eventually validated that UUID could certainly be thought of as the workflow ID. When Cromwell is ready to validate a submission, the status of the WORKFLOW_EXECUTION can be moved to Validating and validation initiated. Assuming the validation succeeds the workflow would move to state Validated. Again when Cromwell is ready to run the workflow, it can be moved to state Running and the workflow would begin to run. Workflows that fail validation would get status Failed with text describing the nature of the failures in the FAILURE_MESSAGES table.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/564
https://github.com/broadinstitute/cromwell/issues/564:413,Performance,throttle,throttle,413,"Proposed high-level flow:. Workflows + inputs + options are submitted. Any grossly malformed submission would quickly generate an error returned to the client immediately. Otherwise save everything to WORKFLOW_EXECUTION and WORKFLOW_EXECUTION_AUX at status Submitted, and return the generated UUID to the client. THAT’S IT. Do not validate workflows synchronously to submission, that’s expensive and difficult to throttle back. The returned UUID constitutes a pollable handle for the submission. Technically this UUID is now a submission ID rather than a workflow ID, though if the workflow is eventually validated that UUID could certainly be thought of as the workflow ID. When Cromwell is ready to validate a submission, the status of the WORKFLOW_EXECUTION can be moved to Validating and validation initiated. Assuming the validation succeeds the workflow would move to state Validated. Again when Cromwell is ready to run the workflow, it can be moved to state Running and the workflow would begin to run. Workflows that fail validation would get status Failed with text describing the nature of the failures in the FAILURE_MESSAGES table.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/564
https://github.com/broadinstitute/cromwell/issues/564:331,Security,validat,validate,331,"Proposed high-level flow:. Workflows + inputs + options are submitted. Any grossly malformed submission would quickly generate an error returned to the client immediately. Otherwise save everything to WORKFLOW_EXECUTION and WORKFLOW_EXECUTION_AUX at status Submitted, and return the generated UUID to the client. THAT’S IT. Do not validate workflows synchronously to submission, that’s expensive and difficult to throttle back. The returned UUID constitutes a pollable handle for the submission. Technically this UUID is now a submission ID rather than a workflow ID, though if the workflow is eventually validated that UUID could certainly be thought of as the workflow ID. When Cromwell is ready to validate a submission, the status of the WORKFLOW_EXECUTION can be moved to Validating and validation initiated. Assuming the validation succeeds the workflow would move to state Validated. Again when Cromwell is ready to run the workflow, it can be moved to state Running and the workflow would begin to run. Workflows that fail validation would get status Failed with text describing the nature of the failures in the FAILURE_MESSAGES table.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/564
https://github.com/broadinstitute/cromwell/issues/564:605,Security,validat,validated,605,"Proposed high-level flow:. Workflows + inputs + options are submitted. Any grossly malformed submission would quickly generate an error returned to the client immediately. Otherwise save everything to WORKFLOW_EXECUTION and WORKFLOW_EXECUTION_AUX at status Submitted, and return the generated UUID to the client. THAT’S IT. Do not validate workflows synchronously to submission, that’s expensive and difficult to throttle back. The returned UUID constitutes a pollable handle for the submission. Technically this UUID is now a submission ID rather than a workflow ID, though if the workflow is eventually validated that UUID could certainly be thought of as the workflow ID. When Cromwell is ready to validate a submission, the status of the WORKFLOW_EXECUTION can be moved to Validating and validation initiated. Assuming the validation succeeds the workflow would move to state Validated. Again when Cromwell is ready to run the workflow, it can be moved to state Running and the workflow would begin to run. Workflows that fail validation would get status Failed with text describing the nature of the failures in the FAILURE_MESSAGES table.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/564
https://github.com/broadinstitute/cromwell/issues/564:701,Security,validat,validate,701,"Proposed high-level flow:. Workflows + inputs + options are submitted. Any grossly malformed submission would quickly generate an error returned to the client immediately. Otherwise save everything to WORKFLOW_EXECUTION and WORKFLOW_EXECUTION_AUX at status Submitted, and return the generated UUID to the client. THAT’S IT. Do not validate workflows synchronously to submission, that’s expensive and difficult to throttle back. The returned UUID constitutes a pollable handle for the submission. Technically this UUID is now a submission ID rather than a workflow ID, though if the workflow is eventually validated that UUID could certainly be thought of as the workflow ID. When Cromwell is ready to validate a submission, the status of the WORKFLOW_EXECUTION can be moved to Validating and validation initiated. Assuming the validation succeeds the workflow would move to state Validated. Again when Cromwell is ready to run the workflow, it can be moved to state Running and the workflow would begin to run. Workflows that fail validation would get status Failed with text describing the nature of the failures in the FAILURE_MESSAGES table.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/564
https://github.com/broadinstitute/cromwell/issues/564:777,Security,Validat,Validating,777,"Proposed high-level flow:. Workflows + inputs + options are submitted. Any grossly malformed submission would quickly generate an error returned to the client immediately. Otherwise save everything to WORKFLOW_EXECUTION and WORKFLOW_EXECUTION_AUX at status Submitted, and return the generated UUID to the client. THAT’S IT. Do not validate workflows synchronously to submission, that’s expensive and difficult to throttle back. The returned UUID constitutes a pollable handle for the submission. Technically this UUID is now a submission ID rather than a workflow ID, though if the workflow is eventually validated that UUID could certainly be thought of as the workflow ID. When Cromwell is ready to validate a submission, the status of the WORKFLOW_EXECUTION can be moved to Validating and validation initiated. Assuming the validation succeeds the workflow would move to state Validated. Again when Cromwell is ready to run the workflow, it can be moved to state Running and the workflow would begin to run. Workflows that fail validation would get status Failed with text describing the nature of the failures in the FAILURE_MESSAGES table.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/564
https://github.com/broadinstitute/cromwell/issues/564:792,Security,validat,validation,792,"Proposed high-level flow:. Workflows + inputs + options are submitted. Any grossly malformed submission would quickly generate an error returned to the client immediately. Otherwise save everything to WORKFLOW_EXECUTION and WORKFLOW_EXECUTION_AUX at status Submitted, and return the generated UUID to the client. THAT’S IT. Do not validate workflows synchronously to submission, that’s expensive and difficult to throttle back. The returned UUID constitutes a pollable handle for the submission. Technically this UUID is now a submission ID rather than a workflow ID, though if the workflow is eventually validated that UUID could certainly be thought of as the workflow ID. When Cromwell is ready to validate a submission, the status of the WORKFLOW_EXECUTION can be moved to Validating and validation initiated. Assuming the validation succeeds the workflow would move to state Validated. Again when Cromwell is ready to run the workflow, it can be moved to state Running and the workflow would begin to run. Workflows that fail validation would get status Failed with text describing the nature of the failures in the FAILURE_MESSAGES table.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/564
https://github.com/broadinstitute/cromwell/issues/564:827,Security,validat,validation,827,"Proposed high-level flow:. Workflows + inputs + options are submitted. Any grossly malformed submission would quickly generate an error returned to the client immediately. Otherwise save everything to WORKFLOW_EXECUTION and WORKFLOW_EXECUTION_AUX at status Submitted, and return the generated UUID to the client. THAT’S IT. Do not validate workflows synchronously to submission, that’s expensive and difficult to throttle back. The returned UUID constitutes a pollable handle for the submission. Technically this UUID is now a submission ID rather than a workflow ID, though if the workflow is eventually validated that UUID could certainly be thought of as the workflow ID. When Cromwell is ready to validate a submission, the status of the WORKFLOW_EXECUTION can be moved to Validating and validation initiated. Assuming the validation succeeds the workflow would move to state Validated. Again when Cromwell is ready to run the workflow, it can be moved to state Running and the workflow would begin to run. Workflows that fail validation would get status Failed with text describing the nature of the failures in the FAILURE_MESSAGES table.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/564
https://github.com/broadinstitute/cromwell/issues/564:880,Security,Validat,Validated,880,"Proposed high-level flow:. Workflows + inputs + options are submitted. Any grossly malformed submission would quickly generate an error returned to the client immediately. Otherwise save everything to WORKFLOW_EXECUTION and WORKFLOW_EXECUTION_AUX at status Submitted, and return the generated UUID to the client. THAT’S IT. Do not validate workflows synchronously to submission, that’s expensive and difficult to throttle back. The returned UUID constitutes a pollable handle for the submission. Technically this UUID is now a submission ID rather than a workflow ID, though if the workflow is eventually validated that UUID could certainly be thought of as the workflow ID. When Cromwell is ready to validate a submission, the status of the WORKFLOW_EXECUTION can be moved to Validating and validation initiated. Assuming the validation succeeds the workflow would move to state Validated. Again when Cromwell is ready to run the workflow, it can be moved to state Running and the workflow would begin to run. Workflows that fail validation would get status Failed with text describing the nature of the failures in the FAILURE_MESSAGES table.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/564
https://github.com/broadinstitute/cromwell/issues/564:1031,Security,validat,validation,1031,"Proposed high-level flow:. Workflows + inputs + options are submitted. Any grossly malformed submission would quickly generate an error returned to the client immediately. Otherwise save everything to WORKFLOW_EXECUTION and WORKFLOW_EXECUTION_AUX at status Submitted, and return the generated UUID to the client. THAT’S IT. Do not validate workflows synchronously to submission, that’s expensive and difficult to throttle back. The returned UUID constitutes a pollable handle for the submission. Technically this UUID is now a submission ID rather than a workflow ID, though if the workflow is eventually validated that UUID could certainly be thought of as the workflow ID. When Cromwell is ready to validate a submission, the status of the WORKFLOW_EXECUTION can be moved to Validating and validation initiated. Assuming the validation succeeds the workflow would move to state Validated. Again when Cromwell is ready to run the workflow, it can be moved to state Running and the workflow would begin to run. Workflows that fail validation would get status Failed with text describing the nature of the failures in the FAILURE_MESSAGES table.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/564
https://github.com/broadinstitute/cromwell/issues/570:52,Security,validat,validation,52,"Already part of the plans for reworked, centralized validation",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/570
https://github.com/broadinstitute/cromwell/issues/575:41,Availability,echo,echo,41,"```; task test {; String? s. command { ; echo ""Here's s:""; echo ""${s}""; }; }. workflow printString {; String? inputS; call test {input: s = inputS}; }; ```. Acceptance criteria: make the above work... or have it report an error",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/575
https://github.com/broadinstitute/cromwell/issues/575:59,Availability,echo,echo,59,"```; task test {; String? s. command { ; echo ""Here's s:""; echo ""${s}""; }; }. workflow printString {; String? inputS; call test {input: s = inputS}; }; ```. Acceptance criteria: make the above work... or have it report an error",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/575
https://github.com/broadinstitute/cromwell/issues/575:222,Availability,error,error,222,"```; task test {; String? s. command { ; echo ""Here's s:""; echo ""${s}""; }; }. workflow printString {; String? inputS; call test {input: s = inputS}; }; ```. Acceptance criteria: make the above work... or have it report an error",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/575
https://github.com/broadinstitute/cromwell/issues/575:10,Testability,test,test,10,"```; task test {; String? s. command { ; echo ""Here's s:""; echo ""${s}""; }; }. workflow printString {; String? inputS; call test {input: s = inputS}; }; ```. Acceptance criteria: make the above work... or have it report an error",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/575
https://github.com/broadinstitute/cromwell/issues/575:123,Testability,test,test,123,"```; task test {; String? s. command { ; echo ""Here's s:""; echo ""${s}""; }; }. workflow printString {; String? inputS; call test {input: s = inputS}; }; ```. Acceptance criteria: make the above work... or have it report an error",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/575
https://github.com/broadinstitute/cromwell/issues/576:812,Deployability,Pipeline,Pipeline,812,"**As a first step -- please confirm that this issue still exists**. It seems that some inputs are being copied over twice to the same path for all tasks. I'm not exactly sure when this started happening but the cromwell git hash we are currently using is https://github.com/broadinstitute/cromwell/tree/c66eabc3582085e28b197b667cb82b241ab6d1dd . Logs in comment. In this example the input_bam and interval_list are listed twice as inputs.; jes operations ID for the following call : operations/EI3Pz-W1KhiNs_ydkKOavrwBIJ-ikOmeDSoPcHJvZHVjdGlvblF1ZXVl; 295959:2016-03-09 18:46:47,375 cromwell-system-akka.actor.default-dispatcher-12 INFO - JesBackend UUID(a7884b2d):HaplotypeCaller:12: Starting call with pre-emptible VM; 295960:2016-03-09 18:46:47,375 cromwell-system-akka.actor.default-dispatcher-12 INFO - JES Pipeline UUID(a7884b2d):HaplotypeCaller:12: Inputs:; 295961: input_bam-0 -> disk:local-disk relpath:broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/a7884b2d-e859-4ef3-bb74-b820623755b4/call-GatherBamFiles/M1132.bam; 295964: 2eb61371-0 -> disk:local-disk relpath:broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/a7884b2d-e859-4ef3-bb74-b820623755b4/call-GatherBamFiles/M1132.bam; 295965: e1220deb-0 -> disk:local-disk relpath:broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/a7884b2d-e859-4ef3-bb74-b820623755b4/call-ScatterIntervalList/glob-cb4648beeaff920acb03de7603c06f98/20scattered.interval_list; 295966: interval_list-0 -> disk:local-disk relpath:broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/a7884b2d-e859-4ef3-bb74-b820623755b4/call-ScatterIntervalList/glob-cb4648beeaff920acb03de7603c06f98/20scattered.interval_list; 295968: input_bam_index-0 -> disk:local-disk relpath:broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/a7884b2d-e859-4ef3-bb74-b820623755b4/call-GatherBamFiles/M1132.bai",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/576
https://github.com/broadinstitute/cromwell/issues/576:224,Security,hash,hash,224,"**As a first step -- please confirm that this issue still exists**. It seems that some inputs are being copied over twice to the same path for all tasks. I'm not exactly sure when this started happening but the cromwell git hash we are currently using is https://github.com/broadinstitute/cromwell/tree/c66eabc3582085e28b197b667cb82b241ab6d1dd . Logs in comment. In this example the input_bam and interval_list are listed twice as inputs.; jes operations ID for the following call : operations/EI3Pz-W1KhiNs_ydkKOavrwBIJ-ikOmeDSoPcHJvZHVjdGlvblF1ZXVl; 295959:2016-03-09 18:46:47,375 cromwell-system-akka.actor.default-dispatcher-12 INFO - JesBackend UUID(a7884b2d):HaplotypeCaller:12: Starting call with pre-emptible VM; 295960:2016-03-09 18:46:47,375 cromwell-system-akka.actor.default-dispatcher-12 INFO - JES Pipeline UUID(a7884b2d):HaplotypeCaller:12: Inputs:; 295961: input_bam-0 -> disk:local-disk relpath:broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/a7884b2d-e859-4ef3-bb74-b820623755b4/call-GatherBamFiles/M1132.bam; 295964: 2eb61371-0 -> disk:local-disk relpath:broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/a7884b2d-e859-4ef3-bb74-b820623755b4/call-GatherBamFiles/M1132.bam; 295965: e1220deb-0 -> disk:local-disk relpath:broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/a7884b2d-e859-4ef3-bb74-b820623755b4/call-ScatterIntervalList/glob-cb4648beeaff920acb03de7603c06f98/20scattered.interval_list; 295966: interval_list-0 -> disk:local-disk relpath:broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/a7884b2d-e859-4ef3-bb74-b820623755b4/call-ScatterIntervalList/glob-cb4648beeaff920acb03de7603c06f98/20scattered.interval_list; 295968: input_bam_index-0 -> disk:local-disk relpath:broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/a7884b2d-e859-4ef3-bb74-b820623755b4/call-GatherBamFiles/M1132.bai",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/576
https://github.com/broadinstitute/cromwell/issues/576:346,Testability,Log,Logs,346,"**As a first step -- please confirm that this issue still exists**. It seems that some inputs are being copied over twice to the same path for all tasks. I'm not exactly sure when this started happening but the cromwell git hash we are currently using is https://github.com/broadinstitute/cromwell/tree/c66eabc3582085e28b197b667cb82b241ab6d1dd . Logs in comment. In this example the input_bam and interval_list are listed twice as inputs.; jes operations ID for the following call : operations/EI3Pz-W1KhiNs_ydkKOavrwBIJ-ikOmeDSoPcHJvZHVjdGlvblF1ZXVl; 295959:2016-03-09 18:46:47,375 cromwell-system-akka.actor.default-dispatcher-12 INFO - JesBackend UUID(a7884b2d):HaplotypeCaller:12: Starting call with pre-emptible VM; 295960:2016-03-09 18:46:47,375 cromwell-system-akka.actor.default-dispatcher-12 INFO - JES Pipeline UUID(a7884b2d):HaplotypeCaller:12: Inputs:; 295961: input_bam-0 -> disk:local-disk relpath:broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/a7884b2d-e859-4ef3-bb74-b820623755b4/call-GatherBamFiles/M1132.bam; 295964: 2eb61371-0 -> disk:local-disk relpath:broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/a7884b2d-e859-4ef3-bb74-b820623755b4/call-GatherBamFiles/M1132.bam; 295965: e1220deb-0 -> disk:local-disk relpath:broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/a7884b2d-e859-4ef3-bb74-b820623755b4/call-ScatterIntervalList/glob-cb4648beeaff920acb03de7603c06f98/20scattered.interval_list; 295966: interval_list-0 -> disk:local-disk relpath:broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/a7884b2d-e859-4ef3-bb74-b820623755b4/call-ScatterIntervalList/glob-cb4648beeaff920acb03de7603c06f98/20scattered.interval_list; 295968: input_bam_index-0 -> disk:local-disk relpath:broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/a7884b2d-e859-4ef3-bb74-b820623755b4/call-GatherBamFiles/M1132.bai",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/576
https://github.com/broadinstitute/cromwell/issues/577:92,Availability,error,error,92,"This happened after we turned off call caching to work around DSDEEPB-2938 for now and this error popped up in what seems to be post success processing of the task. Logs are in the comment. This was run on gotc-prod against JES-staging. ``` scala; 34108:2016-03-10 22:53:11,258 cromwell-system-akka.actor.default-dispatcher-8 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from - to Initializing; 50265:2016-03-10 22:55:07,880 cromwell-system-akka.actor.default-dispatcher-27 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from Initializing to Running; 64201:2016-03-10 22:57:00,293 cromwell-system-akka.actor.default-dispatcher-27 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from Running to Success. 2016-03-10 22:57:05,450 cromwell-system-akka.actor.default-dispatcher-27 ERROR - CallActor [UUID(7721686a):StripBamExtension:8]: Failing call: 500 Internal Server Error; Internal Error; cromwell.util.AggregatedException: 500 Internal Server Error; Internal Error; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:112) ~[cromwell.jar:0.19]; at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:124) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:623) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:662) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:657) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureIn",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/577
https://github.com/broadinstitute/cromwell/issues/577:837,Availability,ERROR,ERROR,837,"This happened after we turned off call caching to work around DSDEEPB-2938 for now and this error popped up in what seems to be post success processing of the task. Logs are in the comment. This was run on gotc-prod against JES-staging. ``` scala; 34108:2016-03-10 22:53:11,258 cromwell-system-akka.actor.default-dispatcher-8 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from - to Initializing; 50265:2016-03-10 22:55:07,880 cromwell-system-akka.actor.default-dispatcher-27 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from Initializing to Running; 64201:2016-03-10 22:57:00,293 cromwell-system-akka.actor.default-dispatcher-27 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from Running to Success. 2016-03-10 22:57:05,450 cromwell-system-akka.actor.default-dispatcher-27 ERROR - CallActor [UUID(7721686a):StripBamExtension:8]: Failing call: 500 Internal Server Error; Internal Error; cromwell.util.AggregatedException: 500 Internal Server Error; Internal Error; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:112) ~[cromwell.jar:0.19]; at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:124) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:623) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:662) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:657) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureIn",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/577
https://github.com/broadinstitute/cromwell/issues/577:927,Availability,Error,Error,927,"This happened after we turned off call caching to work around DSDEEPB-2938 for now and this error popped up in what seems to be post success processing of the task. Logs are in the comment. This was run on gotc-prod against JES-staging. ``` scala; 34108:2016-03-10 22:53:11,258 cromwell-system-akka.actor.default-dispatcher-8 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from - to Initializing; 50265:2016-03-10 22:55:07,880 cromwell-system-akka.actor.default-dispatcher-27 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from Initializing to Running; 64201:2016-03-10 22:57:00,293 cromwell-system-akka.actor.default-dispatcher-27 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from Running to Success. 2016-03-10 22:57:05,450 cromwell-system-akka.actor.default-dispatcher-27 ERROR - CallActor [UUID(7721686a):StripBamExtension:8]: Failing call: 500 Internal Server Error; Internal Error; cromwell.util.AggregatedException: 500 Internal Server Error; Internal Error; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:112) ~[cromwell.jar:0.19]; at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:124) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:623) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:662) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:657) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureIn",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/577
https://github.com/broadinstitute/cromwell/issues/577:943,Availability,Error,Error,943,"This happened after we turned off call caching to work around DSDEEPB-2938 for now and this error popped up in what seems to be post success processing of the task. Logs are in the comment. This was run on gotc-prod against JES-staging. ``` scala; 34108:2016-03-10 22:53:11,258 cromwell-system-akka.actor.default-dispatcher-8 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from - to Initializing; 50265:2016-03-10 22:55:07,880 cromwell-system-akka.actor.default-dispatcher-27 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from Initializing to Running; 64201:2016-03-10 22:57:00,293 cromwell-system-akka.actor.default-dispatcher-27 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from Running to Success. 2016-03-10 22:57:05,450 cromwell-system-akka.actor.default-dispatcher-27 ERROR - CallActor [UUID(7721686a):StripBamExtension:8]: Failing call: 500 Internal Server Error; Internal Error; cromwell.util.AggregatedException: 500 Internal Server Error; Internal Error; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:112) ~[cromwell.jar:0.19]; at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:124) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:623) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:662) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:657) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureIn",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/577
https://github.com/broadinstitute/cromwell/issues/577:1005,Availability,Error,Error,1005,"is happened after we turned off call caching to work around DSDEEPB-2938 for now and this error popped up in what seems to be post success processing of the task. Logs are in the comment. This was run on gotc-prod against JES-staging. ``` scala; 34108:2016-03-10 22:53:11,258 cromwell-system-akka.actor.default-dispatcher-8 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from - to Initializing; 50265:2016-03-10 22:55:07,880 cromwell-system-akka.actor.default-dispatcher-27 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from Initializing to Running; 64201:2016-03-10 22:57:00,293 cromwell-system-akka.actor.default-dispatcher-27 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from Running to Success. 2016-03-10 22:57:05,450 cromwell-system-akka.actor.default-dispatcher-27 ERROR - CallActor [UUID(7721686a):StripBamExtension:8]: Failing call: 500 Internal Server Error; Internal Error; cromwell.util.AggregatedException: 500 Internal Server Error; Internal Error; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:112) ~[cromwell.jar:0.19]; at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:124) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:623) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:662) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:657) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureIns",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/577
https://github.com/broadinstitute/cromwell/issues/577:1021,Availability,Error,Error,1021,"is happened after we turned off call caching to work around DSDEEPB-2938 for now and this error popped up in what seems to be post success processing of the task. Logs are in the comment. This was run on gotc-prod against JES-staging. ``` scala; 34108:2016-03-10 22:53:11,258 cromwell-system-akka.actor.default-dispatcher-8 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from - to Initializing; 50265:2016-03-10 22:55:07,880 cromwell-system-akka.actor.default-dispatcher-27 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from Initializing to Running; 64201:2016-03-10 22:57:00,293 cromwell-system-akka.actor.default-dispatcher-27 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from Running to Success. 2016-03-10 22:57:05,450 cromwell-system-akka.actor.default-dispatcher-27 ERROR - CallActor [UUID(7721686a):StripBamExtension:8]: Failing call: 500 Internal Server Error; Internal Error; cromwell.util.AggregatedException: 500 Internal Server Error; Internal Error; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:112) ~[cromwell.jar:0.19]; at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:124) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:623) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:662) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:657) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureIns",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/577
https://github.com/broadinstitute/cromwell/issues/577:1536,Performance,concurren,concurrent,1536,"ion:8]: Status change from Initializing to Running; 64201:2016-03-10 22:57:00,293 cromwell-system-akka.actor.default-dispatcher-27 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from Running to Success. 2016-03-10 22:57:05,450 cromwell-system-akka.actor.default-dispatcher-27 ERROR - CallActor [UUID(7721686a):StripBamExtension:8]: Failing call: 500 Internal Server Error; Internal Error; cromwell.util.AggregatedException: 500 Internal Server Error; Internal Error; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:112) ~[cromwell.jar:0.19]; at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:124) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:623) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:662) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:657) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:23) ~[cromwell.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$Akk",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/577
https://github.com/broadinstitute/cromwell/issues/577:1647,Performance,concurren,concurrent,1647,"fault-dispatcher-27 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from Running to Success. 2016-03-10 22:57:05,450 cromwell-system-akka.actor.default-dispatcher-27 ERROR - CallActor [UUID(7721686a):StripBamExtension:8]: Failing call: 500 Internal Server Error; Internal Error; cromwell.util.AggregatedException: 500 Internal Server Error; Internal Error; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:112) ~[cromwell.jar:0.19]; at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:124) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:623) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:662) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:657) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:23) ~[cromwell.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/577
https://github.com/broadinstitute/cromwell/issues/577:1760,Performance,concurren,concurrent,1760,"016-03-10 22:57:05,450 cromwell-system-akka.actor.default-dispatcher-27 ERROR - CallActor [UUID(7721686a):StripBamExtension:8]: Failing call: 500 Internal Server Error; Internal Error; cromwell.util.AggregatedException: 500 Internal Server Error; Internal Error; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:112) ~[cromwell.jar:0.19]; at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:124) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:623) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:662) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:657) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:23) ~[cromwell.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(F",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/577
https://github.com/broadinstitute/cromwell/issues/577:2314,Performance,concurren,concurrent,2314,"ar:0.19]; at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:623) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:662) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:657) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:23) ~[cromwell.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-03-10 22:57:05,450 cromwell-system-akka.actor.default-dispatcher-27 INFO - WorkflowActor [UUID(7721686a)]: persisting status of StripBamExtension:8 to Failed.; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/577
https://github.com/broadinstitute/cromwell/issues/577:2621,Performance,concurren,concurrent,2621,"ar:0.19]; at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:623) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:662) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:657) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:23) ~[cromwell.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-03-10 22:57:05,450 cromwell-system-akka.actor.default-dispatcher-27 INFO - WorkflowActor [UUID(7721686a)]: persisting status of StripBamExtension:8 to Failed.; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/577
https://github.com/broadinstitute/cromwell/issues/577:2714,Performance,concurren,concurrent,2714,"ar:0.19]; at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:623) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:662) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:657) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:23) ~[cromwell.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-03-10 22:57:05,450 cromwell-system-akka.actor.default-dispatcher-27 INFO - WorkflowActor [UUID(7721686a)]: persisting status of StripBamExtension:8 to Failed.; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/577
https://github.com/broadinstitute/cromwell/issues/577:2819,Performance,concurren,concurrent,2819,"ar:0.19]; at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:623) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:662) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:657) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:23) ~[cromwell.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-03-10 22:57:05,450 cromwell-system-akka.actor.default-dispatcher-27 INFO - WorkflowActor [UUID(7721686a)]: persisting status of StripBamExtension:8 to Failed.; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/577
https://github.com/broadinstitute/cromwell/issues/577:2916,Performance,concurren,concurrent,2916,"ar:0.19]; at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:623) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:662) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:657) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:23) ~[cromwell.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-03-10 22:57:05,450 cromwell-system-akka.actor.default-dispatcher-27 INFO - WorkflowActor [UUID(7721686a)]: persisting status of StripBamExtension:8 to Failed.; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/577
https://github.com/broadinstitute/cromwell/issues/577:165,Testability,Log,Logs,165,"This happened after we turned off call caching to work around DSDEEPB-2938 for now and this error popped up in what seems to be post success processing of the task. Logs are in the comment. This was run on gotc-prod against JES-staging. ``` scala; 34108:2016-03-10 22:53:11,258 cromwell-system-akka.actor.default-dispatcher-8 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from - to Initializing; 50265:2016-03-10 22:55:07,880 cromwell-system-akka.actor.default-dispatcher-27 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from Initializing to Running; 64201:2016-03-10 22:57:00,293 cromwell-system-akka.actor.default-dispatcher-27 INFO - JES Run [UUID(7721686a):StripBamExtension:8]: Status change from Running to Success. 2016-03-10 22:57:05,450 cromwell-system-akka.actor.default-dispatcher-27 ERROR - CallActor [UUID(7721686a):StripBamExtension:8]: Failing call: 500 Internal Server Error; Internal Error; cromwell.util.AggregatedException: 500 Internal Server Error; Internal Error; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:112) ~[cromwell.jar:0.19]; at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:124) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:623) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:662) ~[cromwell.jar:0.19]; at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:657) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureIn",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/577
https://github.com/broadinstitute/cromwell/pull/582:294,Integrability,rout,route,294,"Solves #544. (Might also close #568 #569 #570 ); Intentions: ; 1.) Make the erstwhile `ValidateActor` (now `MaterializeWorkflowDescriptorActor`) central to instantiating the `WorkflowDescriptor` which does so only after all validations succeed. In essence, workflow submissions now go via this route.; 2.) Clean up validation code from `WorkflowDescriptor.scala` (All of that code comes to the above actor); 3.) WorkflowDescriptor should (ideally) be just a case class. Change relevant files where the constructors were being called (quite a lot ~3-liner changes)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/582
https://github.com/broadinstitute/cromwell/pull/582:87,Security,Validat,ValidateActor,87,"Solves #544. (Might also close #568 #569 #570 ); Intentions: ; 1.) Make the erstwhile `ValidateActor` (now `MaterializeWorkflowDescriptorActor`) central to instantiating the `WorkflowDescriptor` which does so only after all validations succeed. In essence, workflow submissions now go via this route.; 2.) Clean up validation code from `WorkflowDescriptor.scala` (All of that code comes to the above actor); 3.) WorkflowDescriptor should (ideally) be just a case class. Change relevant files where the constructors were being called (quite a lot ~3-liner changes)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/582
https://github.com/broadinstitute/cromwell/pull/582:224,Security,validat,validations,224,"Solves #544. (Might also close #568 #569 #570 ); Intentions: ; 1.) Make the erstwhile `ValidateActor` (now `MaterializeWorkflowDescriptorActor`) central to instantiating the `WorkflowDescriptor` which does so only after all validations succeed. In essence, workflow submissions now go via this route.; 2.) Clean up validation code from `WorkflowDescriptor.scala` (All of that code comes to the above actor); 3.) WorkflowDescriptor should (ideally) be just a case class. Change relevant files where the constructors were being called (quite a lot ~3-liner changes)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/582
https://github.com/broadinstitute/cromwell/pull/582:315,Security,validat,validation,315,"Solves #544. (Might also close #568 #569 #570 ); Intentions: ; 1.) Make the erstwhile `ValidateActor` (now `MaterializeWorkflowDescriptorActor`) central to instantiating the `WorkflowDescriptor` which does so only after all validations succeed. In essence, workflow submissions now go via this route.; 2.) Clean up validation code from `WorkflowDescriptor.scala` (All of that code comes to the above actor); 3.) WorkflowDescriptor should (ideally) be just a case class. Change relevant files where the constructors were being called (quite a lot ~3-liner changes)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/582
https://github.com/broadinstitute/cromwell/pull/585:19,Performance,cache,cache,19,"see `calls['w.x']['cache']` and `calls['w.y']['cache']`:. ``` json; HTTP/1.1 200 OK; Content-Length: 2056; Content-Type: application/json; charset=UTF-8; Date: Wed, 23 Mar 2016 13:22:35 GMT; Server: spray-can/1.3.2. {; ""calls"": {; ""w.x"": [; {; ""attempt"": 1,; ""backend"": ""Local"",; ""cache"": {; ""allowResultReuse"": true; },; ""end"": ""2016-03-23T09:22:30.000-04:00"",; ""executionEvents"": [],; ""executionStatus"": ""Done"",; ""inputs"": {; ""s"": ""foo""; },; ""outputs"": {; ""t"": ""foo""; },; ""returnCode"": 0,; ""runtimeAttributes"": {; ""continueOnReturnCode"": ""0"",; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false""; },; ""shardIndex"": -1,; ""start"": ""2016-03-23T09:22:28.000-04:00"",; ""stderr"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-x/stderr"",; ""stdout"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-x/stdout""; }; ],; ""w.y"": [; {; ""attempt"": 1,; ""backend"": ""Local"",; ""cache"": {; ""allowResultReuse"": true,; ""cacheHitCall"": ""w.x"",; ""cacheHitWorkflow"": ""d21f9706-0d85-4859-af96-cb58b6913085""; },; ""end"": ""2016-03-23T09:22:30.000-04:00"",; ""executionEvents"": [],; ""executionStatus"": ""Done"",; ""inputs"": {; ""s"": ""foo""; },; ""outputs"": {; ""t"": ""foo""; },; ""returnCode"": 0,; ""runtimeAttributes"": {; ""continueOnReturnCode"": ""0"",; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false""; },; ""shardIndex"": -1,; ""start"": ""2016-03-23T09:22:30.000-04:00"",; ""stderr"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-y/stderr"",; ""stdout"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-y/stdout""; }; ]; },; ""end"": ""2016-03-23T09:22:31.000-04:00"",; ""id"": ""d21f9706-0d85-4859-af96-cb58b6913085"",; ""inputs"": {},; ""outputs"": {; ""w.x.t"": ""foo"",; ""w.y.t"": ""foo""; },; ""start"": ""2016-03-23T09:22:28.000-04:00"",; ""status"": ""Succeeded"",; ""submission"": ""2016-03-23T09:22:28.000-04:00"",; ""workflowName"": ""w""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/585
https://github.com/broadinstitute/cromwell/pull/585:47,Performance,cache,cache,47,"see `calls['w.x']['cache']` and `calls['w.y']['cache']`:. ``` json; HTTP/1.1 200 OK; Content-Length: 2056; Content-Type: application/json; charset=UTF-8; Date: Wed, 23 Mar 2016 13:22:35 GMT; Server: spray-can/1.3.2. {; ""calls"": {; ""w.x"": [; {; ""attempt"": 1,; ""backend"": ""Local"",; ""cache"": {; ""allowResultReuse"": true; },; ""end"": ""2016-03-23T09:22:30.000-04:00"",; ""executionEvents"": [],; ""executionStatus"": ""Done"",; ""inputs"": {; ""s"": ""foo""; },; ""outputs"": {; ""t"": ""foo""; },; ""returnCode"": 0,; ""runtimeAttributes"": {; ""continueOnReturnCode"": ""0"",; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false""; },; ""shardIndex"": -1,; ""start"": ""2016-03-23T09:22:28.000-04:00"",; ""stderr"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-x/stderr"",; ""stdout"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-x/stdout""; }; ],; ""w.y"": [; {; ""attempt"": 1,; ""backend"": ""Local"",; ""cache"": {; ""allowResultReuse"": true,; ""cacheHitCall"": ""w.x"",; ""cacheHitWorkflow"": ""d21f9706-0d85-4859-af96-cb58b6913085""; },; ""end"": ""2016-03-23T09:22:30.000-04:00"",; ""executionEvents"": [],; ""executionStatus"": ""Done"",; ""inputs"": {; ""s"": ""foo""; },; ""outputs"": {; ""t"": ""foo""; },; ""returnCode"": 0,; ""runtimeAttributes"": {; ""continueOnReturnCode"": ""0"",; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false""; },; ""shardIndex"": -1,; ""start"": ""2016-03-23T09:22:30.000-04:00"",; ""stderr"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-y/stderr"",; ""stdout"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-y/stdout""; }; ]; },; ""end"": ""2016-03-23T09:22:31.000-04:00"",; ""id"": ""d21f9706-0d85-4859-af96-cb58b6913085"",; ""inputs"": {},; ""outputs"": {; ""w.x.t"": ""foo"",; ""w.y.t"": ""foo""; },; ""start"": ""2016-03-23T09:22:28.000-04:00"",; ""status"": ""Succeeded"",; ""submission"": ""2016-03-23T09:22:28.000-04:00"",; ""workflowName"": ""w""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/585
https://github.com/broadinstitute/cromwell/pull/585:281,Performance,cache,cache,281,"see `calls['w.x']['cache']` and `calls['w.y']['cache']`:. ``` json; HTTP/1.1 200 OK; Content-Length: 2056; Content-Type: application/json; charset=UTF-8; Date: Wed, 23 Mar 2016 13:22:35 GMT; Server: spray-can/1.3.2. {; ""calls"": {; ""w.x"": [; {; ""attempt"": 1,; ""backend"": ""Local"",; ""cache"": {; ""allowResultReuse"": true; },; ""end"": ""2016-03-23T09:22:30.000-04:00"",; ""executionEvents"": [],; ""executionStatus"": ""Done"",; ""inputs"": {; ""s"": ""foo""; },; ""outputs"": {; ""t"": ""foo""; },; ""returnCode"": 0,; ""runtimeAttributes"": {; ""continueOnReturnCode"": ""0"",; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false""; },; ""shardIndex"": -1,; ""start"": ""2016-03-23T09:22:28.000-04:00"",; ""stderr"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-x/stderr"",; ""stdout"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-x/stdout""; }; ],; ""w.y"": [; {; ""attempt"": 1,; ""backend"": ""Local"",; ""cache"": {; ""allowResultReuse"": true,; ""cacheHitCall"": ""w.x"",; ""cacheHitWorkflow"": ""d21f9706-0d85-4859-af96-cb58b6913085""; },; ""end"": ""2016-03-23T09:22:30.000-04:00"",; ""executionEvents"": [],; ""executionStatus"": ""Done"",; ""inputs"": {; ""s"": ""foo""; },; ""outputs"": {; ""t"": ""foo""; },; ""returnCode"": 0,; ""runtimeAttributes"": {; ""continueOnReturnCode"": ""0"",; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false""; },; ""shardIndex"": -1,; ""start"": ""2016-03-23T09:22:30.000-04:00"",; ""stderr"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-y/stderr"",; ""stdout"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-y/stdout""; }; ]; },; ""end"": ""2016-03-23T09:22:31.000-04:00"",; ""id"": ""d21f9706-0d85-4859-af96-cb58b6913085"",; ""inputs"": {},; ""outputs"": {; ""w.x.t"": ""foo"",; ""w.y.t"": ""foo""; },; ""start"": ""2016-03-23T09:22:28.000-04:00"",; ""status"": ""Succeeded"",; ""submission"": ""2016-03-23T09:22:28.000-04:00"",; ""workflowName"": ""w""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/585
https://github.com/broadinstitute/cromwell/pull/585:961,Performance,cache,cache,961,"see `calls['w.x']['cache']` and `calls['w.y']['cache']`:. ``` json; HTTP/1.1 200 OK; Content-Length: 2056; Content-Type: application/json; charset=UTF-8; Date: Wed, 23 Mar 2016 13:22:35 GMT; Server: spray-can/1.3.2. {; ""calls"": {; ""w.x"": [; {; ""attempt"": 1,; ""backend"": ""Local"",; ""cache"": {; ""allowResultReuse"": true; },; ""end"": ""2016-03-23T09:22:30.000-04:00"",; ""executionEvents"": [],; ""executionStatus"": ""Done"",; ""inputs"": {; ""s"": ""foo""; },; ""outputs"": {; ""t"": ""foo""; },; ""returnCode"": 0,; ""runtimeAttributes"": {; ""continueOnReturnCode"": ""0"",; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false""; },; ""shardIndex"": -1,; ""start"": ""2016-03-23T09:22:28.000-04:00"",; ""stderr"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-x/stderr"",; ""stdout"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-x/stdout""; }; ],; ""w.y"": [; {; ""attempt"": 1,; ""backend"": ""Local"",; ""cache"": {; ""allowResultReuse"": true,; ""cacheHitCall"": ""w.x"",; ""cacheHitWorkflow"": ""d21f9706-0d85-4859-af96-cb58b6913085""; },; ""end"": ""2016-03-23T09:22:30.000-04:00"",; ""executionEvents"": [],; ""executionStatus"": ""Done"",; ""inputs"": {; ""s"": ""foo""; },; ""outputs"": {; ""t"": ""foo""; },; ""returnCode"": 0,; ""runtimeAttributes"": {; ""continueOnReturnCode"": ""0"",; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false""; },; ""shardIndex"": -1,; ""start"": ""2016-03-23T09:22:30.000-04:00"",; ""stderr"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-y/stderr"",; ""stdout"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-y/stdout""; }; ]; },; ""end"": ""2016-03-23T09:22:31.000-04:00"",; ""id"": ""d21f9706-0d85-4859-af96-cb58b6913085"",; ""inputs"": {},; ""outputs"": {; ""w.x.t"": ""foo"",; ""w.y.t"": ""foo""; },; ""start"": ""2016-03-23T09:22:28.000-04:00"",; ""status"": ""Succeeded"",; ""submission"": ""2016-03-23T09:22:28.000-04:00"",; ""workflowName"": ""w""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/585
https://github.com/broadinstitute/cromwell/pull/585:1000,Performance,cache,cacheHitCall,1000,"see `calls['w.x']['cache']` and `calls['w.y']['cache']`:. ``` json; HTTP/1.1 200 OK; Content-Length: 2056; Content-Type: application/json; charset=UTF-8; Date: Wed, 23 Mar 2016 13:22:35 GMT; Server: spray-can/1.3.2. {; ""calls"": {; ""w.x"": [; {; ""attempt"": 1,; ""backend"": ""Local"",; ""cache"": {; ""allowResultReuse"": true; },; ""end"": ""2016-03-23T09:22:30.000-04:00"",; ""executionEvents"": [],; ""executionStatus"": ""Done"",; ""inputs"": {; ""s"": ""foo""; },; ""outputs"": {; ""t"": ""foo""; },; ""returnCode"": 0,; ""runtimeAttributes"": {; ""continueOnReturnCode"": ""0"",; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false""; },; ""shardIndex"": -1,; ""start"": ""2016-03-23T09:22:28.000-04:00"",; ""stderr"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-x/stderr"",; ""stdout"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-x/stdout""; }; ],; ""w.y"": [; {; ""attempt"": 1,; ""backend"": ""Local"",; ""cache"": {; ""allowResultReuse"": true,; ""cacheHitCall"": ""w.x"",; ""cacheHitWorkflow"": ""d21f9706-0d85-4859-af96-cb58b6913085""; },; ""end"": ""2016-03-23T09:22:30.000-04:00"",; ""executionEvents"": [],; ""executionStatus"": ""Done"",; ""inputs"": {; ""s"": ""foo""; },; ""outputs"": {; ""t"": ""foo""; },; ""returnCode"": 0,; ""runtimeAttributes"": {; ""continueOnReturnCode"": ""0"",; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false""; },; ""shardIndex"": -1,; ""start"": ""2016-03-23T09:22:30.000-04:00"",; ""stderr"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-y/stderr"",; ""stdout"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-y/stdout""; }; ]; },; ""end"": ""2016-03-23T09:22:31.000-04:00"",; ""id"": ""d21f9706-0d85-4859-af96-cb58b6913085"",; ""inputs"": {},; ""outputs"": {; ""w.x.t"": ""foo"",; ""w.y.t"": ""foo""; },; ""start"": ""2016-03-23T09:22:28.000-04:00"",; ""status"": ""Succeeded"",; ""submission"": ""2016-03-23T09:22:28.000-04:00"",; ""workflowName"": ""w""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/585
https://github.com/broadinstitute/cromwell/pull/585:1024,Performance,cache,cacheHitWorkflow,1024,"see `calls['w.x']['cache']` and `calls['w.y']['cache']`:. ``` json; HTTP/1.1 200 OK; Content-Length: 2056; Content-Type: application/json; charset=UTF-8; Date: Wed, 23 Mar 2016 13:22:35 GMT; Server: spray-can/1.3.2. {; ""calls"": {; ""w.x"": [; {; ""attempt"": 1,; ""backend"": ""Local"",; ""cache"": {; ""allowResultReuse"": true; },; ""end"": ""2016-03-23T09:22:30.000-04:00"",; ""executionEvents"": [],; ""executionStatus"": ""Done"",; ""inputs"": {; ""s"": ""foo""; },; ""outputs"": {; ""t"": ""foo""; },; ""returnCode"": 0,; ""runtimeAttributes"": {; ""continueOnReturnCode"": ""0"",; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false""; },; ""shardIndex"": -1,; ""start"": ""2016-03-23T09:22:28.000-04:00"",; ""stderr"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-x/stderr"",; ""stdout"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-x/stdout""; }; ],; ""w.y"": [; {; ""attempt"": 1,; ""backend"": ""Local"",; ""cache"": {; ""allowResultReuse"": true,; ""cacheHitCall"": ""w.x"",; ""cacheHitWorkflow"": ""d21f9706-0d85-4859-af96-cb58b6913085""; },; ""end"": ""2016-03-23T09:22:30.000-04:00"",; ""executionEvents"": [],; ""executionStatus"": ""Done"",; ""inputs"": {; ""s"": ""foo""; },; ""outputs"": {; ""t"": ""foo""; },; ""returnCode"": 0,; ""runtimeAttributes"": {; ""continueOnReturnCode"": ""0"",; ""docker"": ""ubuntu:latest"",; ""failOnStderr"": ""false""; },; ""shardIndex"": -1,; ""start"": ""2016-03-23T09:22:30.000-04:00"",; ""stderr"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-y/stderr"",; ""stdout"": ""/Users/sfrazer/projects/cromwell/cromwell-executions/w/d21f9706-0d85-4859-af96-cb58b6913085/call-y/stdout""; }; ]; },; ""end"": ""2016-03-23T09:22:31.000-04:00"",; ""id"": ""d21f9706-0d85-4859-af96-cb58b6913085"",; ""inputs"": {},; ""outputs"": {; ""w.x.t"": ""foo"",; ""w.y.t"": ""foo""; },; ""start"": ""2016-03-23T09:22:28.000-04:00"",; ""status"": ""Succeeded"",; ""submission"": ""2016-03-23T09:22:28.000-04:00"",; ""workflowName"": ""w""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/585
https://github.com/broadinstitute/cromwell/issues/587:521,Availability,failure,failure,521,"In cases where call caching is not being used (as is the case for Genomes On the Cloud for the time being), the ability to have workflows ""fail fast"" is desired. Fail fast in this case mean, once a task has failed no new tasks should be started (currently running tasks can finish) and then the workflow should be set to failed. This is important because when running a workflow, and you can't reuse the non-failed work, you want to know the workflow will fail as soon as possible. With a long running workflow, an early failure with few downstream dependencies you have to wait a long time (24 hours for GOTC) to realize it's actually failed. This should be specifyable as a workflow option, e.g. failure-strategy = fast where the current behavior is 'slow'. If it's easy to also have this as a server config setting for the default that would be a nice to have but not critical.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/587
https://github.com/broadinstitute/cromwell/issues/587:538,Availability,down,downstream,538,"In cases where call caching is not being used (as is the case for Genomes On the Cloud for the time being), the ability to have workflows ""fail fast"" is desired. Fail fast in this case mean, once a task has failed no new tasks should be started (currently running tasks can finish) and then the workflow should be set to failed. This is important because when running a workflow, and you can't reuse the non-failed work, you want to know the workflow will fail as soon as possible. With a long running workflow, an early failure with few downstream dependencies you have to wait a long time (24 hours for GOTC) to realize it's actually failed. This should be specifyable as a workflow option, e.g. failure-strategy = fast where the current behavior is 'slow'. If it's easy to also have this as a server config setting for the default that would be a nice to have but not critical.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/587
https://github.com/broadinstitute/cromwell/issues/587:698,Availability,failure,failure-strategy,698,"In cases where call caching is not being used (as is the case for Genomes On the Cloud for the time being), the ability to have workflows ""fail fast"" is desired. Fail fast in this case mean, once a task has failed no new tasks should be started (currently running tasks can finish) and then the workflow should be set to failed. This is important because when running a workflow, and you can't reuse the non-failed work, you want to know the workflow will fail as soon as possible. With a long running workflow, an early failure with few downstream dependencies you have to wait a long time (24 hours for GOTC) to realize it's actually failed. This should be specifyable as a workflow option, e.g. failure-strategy = fast where the current behavior is 'slow'. If it's easy to also have this as a server config setting for the default that would be a nice to have but not critical.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/587
https://github.com/broadinstitute/cromwell/issues/587:549,Integrability,depend,dependencies,549,"In cases where call caching is not being used (as is the case for Genomes On the Cloud for the time being), the ability to have workflows ""fail fast"" is desired. Fail fast in this case mean, once a task has failed no new tasks should be started (currently running tasks can finish) and then the workflow should be set to failed. This is important because when running a workflow, and you can't reuse the non-failed work, you want to know the workflow will fail as soon as possible. With a long running workflow, an early failure with few downstream dependencies you have to wait a long time (24 hours for GOTC) to realize it's actually failed. This should be specifyable as a workflow option, e.g. failure-strategy = fast where the current behavior is 'slow'. If it's easy to also have this as a server config setting for the default that would be a nice to have but not critical.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/587
https://github.com/broadinstitute/cromwell/issues/587:803,Modifiability,config,config,803,"In cases where call caching is not being used (as is the case for Genomes On the Cloud for the time being), the ability to have workflows ""fail fast"" is desired. Fail fast in this case mean, once a task has failed no new tasks should be started (currently running tasks can finish) and then the workflow should be set to failed. This is important because when running a workflow, and you can't reuse the non-failed work, you want to know the workflow will fail as soon as possible. With a long running workflow, an early failure with few downstream dependencies you have to wait a long time (24 hours for GOTC) to realize it's actually failed. This should be specifyable as a workflow option, e.g. failure-strategy = fast where the current behavior is 'slow'. If it's easy to also have this as a server config setting for the default that would be a nice to have but not critical.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/587
https://github.com/broadinstitute/cromwell/issues/588:101,Testability,log,logs,101,"Here is the general pattern we saw during this last 200 (3/17). This is a very basic outline but the logs can be found in the log file 20160317-cromwell.log on gotc-prod. WorkflowActor [UUID(71b8d356)]: persisting status of StripUnmappedBamSuffix:17 to Starting; WorkflowActor [UUID(71b8d356)]: persisting status of StripUnmappedBamSuffix:17 to Running; JES Run [UUID(71b8d356):StripUnmappedBamSuffix:17]: Status change from - to Initializing; ----- Cromwell restarted -----; JES Run [UUID(71b8d356):StripUnmappedBamSuffix:17]: Status change from - to Initializing; ----- Cromwell restarted -----; JES Run [UUID(71b8d356):StripUnmappedBamSuffix:17]: Status change from - to Success; ----- Cromwell restarted -----; JES Run [UUID(71b8d356):StripUnmappedBamSuffix:17]: Status change from - to Success; WorkflowActor [UUID(71b8d356)]: persisting status of StripUnmappedBamSuffix:17 to Running.; WorkflowActor [UUID(71b8d356)]: Completion work failed for call StripUnmappedBamSuffix:17; WorkflowActor [UUID(71b8d356)]: persisting status of StripUnmappedBamSuffix:17 to Failed.; WorkflowActor [UUID(71b8d356)]: Duplicate entry '558-PairedEndSingleSampleWorkflow.StripUnmappedBamSuffix-base_na' for key 'UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO'. times of the 3 restarts:; 20:55:14,969; 22:22:09,207; 23:02:54,544",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/588
https://github.com/broadinstitute/cromwell/issues/588:126,Testability,log,log,126,"Here is the general pattern we saw during this last 200 (3/17). This is a very basic outline but the logs can be found in the log file 20160317-cromwell.log on gotc-prod. WorkflowActor [UUID(71b8d356)]: persisting status of StripUnmappedBamSuffix:17 to Starting; WorkflowActor [UUID(71b8d356)]: persisting status of StripUnmappedBamSuffix:17 to Running; JES Run [UUID(71b8d356):StripUnmappedBamSuffix:17]: Status change from - to Initializing; ----- Cromwell restarted -----; JES Run [UUID(71b8d356):StripUnmappedBamSuffix:17]: Status change from - to Initializing; ----- Cromwell restarted -----; JES Run [UUID(71b8d356):StripUnmappedBamSuffix:17]: Status change from - to Success; ----- Cromwell restarted -----; JES Run [UUID(71b8d356):StripUnmappedBamSuffix:17]: Status change from - to Success; WorkflowActor [UUID(71b8d356)]: persisting status of StripUnmappedBamSuffix:17 to Running.; WorkflowActor [UUID(71b8d356)]: Completion work failed for call StripUnmappedBamSuffix:17; WorkflowActor [UUID(71b8d356)]: persisting status of StripUnmappedBamSuffix:17 to Failed.; WorkflowActor [UUID(71b8d356)]: Duplicate entry '558-PairedEndSingleSampleWorkflow.StripUnmappedBamSuffix-base_na' for key 'UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO'. times of the 3 restarts:; 20:55:14,969; 22:22:09,207; 23:02:54,544",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/588
https://github.com/broadinstitute/cromwell/issues/588:153,Testability,log,log,153,"Here is the general pattern we saw during this last 200 (3/17). This is a very basic outline but the logs can be found in the log file 20160317-cromwell.log on gotc-prod. WorkflowActor [UUID(71b8d356)]: persisting status of StripUnmappedBamSuffix:17 to Starting; WorkflowActor [UUID(71b8d356)]: persisting status of StripUnmappedBamSuffix:17 to Running; JES Run [UUID(71b8d356):StripUnmappedBamSuffix:17]: Status change from - to Initializing; ----- Cromwell restarted -----; JES Run [UUID(71b8d356):StripUnmappedBamSuffix:17]: Status change from - to Initializing; ----- Cromwell restarted -----; JES Run [UUID(71b8d356):StripUnmappedBamSuffix:17]: Status change from - to Success; ----- Cromwell restarted -----; JES Run [UUID(71b8d356):StripUnmappedBamSuffix:17]: Status change from - to Success; WorkflowActor [UUID(71b8d356)]: persisting status of StripUnmappedBamSuffix:17 to Running.; WorkflowActor [UUID(71b8d356)]: Completion work failed for call StripUnmappedBamSuffix:17; WorkflowActor [UUID(71b8d356)]: persisting status of StripUnmappedBamSuffix:17 to Failed.; WorkflowActor [UUID(71b8d356)]: Duplicate entry '558-PairedEndSingleSampleWorkflow.StripUnmappedBamSuffix-base_na' for key 'UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO'. times of the 3 restarts:; 20:55:14,969; 22:22:09,207; 23:02:54,544",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/588
https://github.com/broadinstitute/cromwell/issues/589:178,Availability,error,error,178,"I recently attempted to run a workflow with files in a separate non public google project as inputs. I submitted it using both Swagger and curl but neither gave very informative error messages. Here's the curl command and output:. ```; curl -v https://cromwell.gotc-dev.broadinstitute.org/api/workflows/v1 -F wdlSource=@PairedSingleSampleWf.wdl -F workflowInputs=@ExampleOfIncorrectProject.json; * Trying 104.197.140.34...; * Connected to cromwell.gotc-dev.broadinstitute.org (104.197.140.34) port 443 (#0); * TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384; * Server certificate: cromwell.gotc-dev.broadinstitute.org; * Server certificate: InCommon RSA Server CA; * Server certificate: USERTrust RSA Certification Authority; * Server certificate: AddTrust External CA Root; > POST /api/workflows/v1 HTTP/1.1; > Host: cromwell.gotc-dev.broadinstitute.org; > User-Agent: curl/7.43.0; > Accept: */*; > Content-Length: 38237; > Expect: 100-continue; > Content-Type: multipart/form-data; boundary=------------------------c2956aa00c34148a; > ; < HTTP/1.1 100 Continue; < HTTP/1.1 500 Internal Server Error; < Date: Fri, 18 Mar 2016 17:59:04 GMT; < Server: spray-can/1.3.2; < X-Frame-Options: SAMEORIGIN; < Access-Control-Allow-Origin: *; < Access-Control-Allow-Headers: authorization,content-type,accept,origin; < Access-Control-Allow-Methods: GET,POST,PUT,PATCH,DELETE,OPTIONS,HEAD; < Access-Control-Max-Age: 1728000; < Content-Type: text/plain; charset=UTF-8; < Content-Length: 69; < Connection: close; < ; * Closing connection 0; The server was not able to produce a timely response to your request.%; ```. The issue was that I was using the broad-gotc-dev project to run the workflow, but two of my input files were in broad-gp-gotc-pilot, but I had trouble figuring that out from this error message. Happy to provide the wdl and json files as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/589
https://github.com/broadinstitute/cromwell/issues/589:1110,Availability,Error,Error,1110,"I recently attempted to run a workflow with files in a separate non public google project as inputs. I submitted it using both Swagger and curl but neither gave very informative error messages. Here's the curl command and output:. ```; curl -v https://cromwell.gotc-dev.broadinstitute.org/api/workflows/v1 -F wdlSource=@PairedSingleSampleWf.wdl -F workflowInputs=@ExampleOfIncorrectProject.json; * Trying 104.197.140.34...; * Connected to cromwell.gotc-dev.broadinstitute.org (104.197.140.34) port 443 (#0); * TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384; * Server certificate: cromwell.gotc-dev.broadinstitute.org; * Server certificate: InCommon RSA Server CA; * Server certificate: USERTrust RSA Certification Authority; * Server certificate: AddTrust External CA Root; > POST /api/workflows/v1 HTTP/1.1; > Host: cromwell.gotc-dev.broadinstitute.org; > User-Agent: curl/7.43.0; > Accept: */*; > Content-Length: 38237; > Expect: 100-continue; > Content-Type: multipart/form-data; boundary=------------------------c2956aa00c34148a; > ; < HTTP/1.1 100 Continue; < HTTP/1.1 500 Internal Server Error; < Date: Fri, 18 Mar 2016 17:59:04 GMT; < Server: spray-can/1.3.2; < X-Frame-Options: SAMEORIGIN; < Access-Control-Allow-Origin: *; < Access-Control-Allow-Headers: authorization,content-type,accept,origin; < Access-Control-Allow-Methods: GET,POST,PUT,PATCH,DELETE,OPTIONS,HEAD; < Access-Control-Max-Age: 1728000; < Content-Type: text/plain; charset=UTF-8; < Content-Length: 69; < Connection: close; < ; * Closing connection 0; The server was not able to produce a timely response to your request.%; ```. The issue was that I was using the broad-gotc-dev project to run the workflow, but two of my input files were in broad-gp-gotc-pilot, but I had trouble figuring that out from this error message. Happy to provide the wdl and json files as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/589
https://github.com/broadinstitute/cromwell/issues/589:1800,Availability,error,error,1800,"I recently attempted to run a workflow with files in a separate non public google project as inputs. I submitted it using both Swagger and curl but neither gave very informative error messages. Here's the curl command and output:. ```; curl -v https://cromwell.gotc-dev.broadinstitute.org/api/workflows/v1 -F wdlSource=@PairedSingleSampleWf.wdl -F workflowInputs=@ExampleOfIncorrectProject.json; * Trying 104.197.140.34...; * Connected to cromwell.gotc-dev.broadinstitute.org (104.197.140.34) port 443 (#0); * TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384; * Server certificate: cromwell.gotc-dev.broadinstitute.org; * Server certificate: InCommon RSA Server CA; * Server certificate: USERTrust RSA Certification Authority; * Server certificate: AddTrust External CA Root; > POST /api/workflows/v1 HTTP/1.1; > Host: cromwell.gotc-dev.broadinstitute.org; > User-Agent: curl/7.43.0; > Accept: */*; > Content-Length: 38237; > Expect: 100-continue; > Content-Type: multipart/form-data; boundary=------------------------c2956aa00c34148a; > ; < HTTP/1.1 100 Continue; < HTTP/1.1 500 Internal Server Error; < Date: Fri, 18 Mar 2016 17:59:04 GMT; < Server: spray-can/1.3.2; < X-Frame-Options: SAMEORIGIN; < Access-Control-Allow-Origin: *; < Access-Control-Allow-Headers: authorization,content-type,accept,origin; < Access-Control-Allow-Methods: GET,POST,PUT,PATCH,DELETE,OPTIONS,HEAD; < Access-Control-Max-Age: 1728000; < Content-Type: text/plain; charset=UTF-8; < Content-Length: 69; < Connection: close; < ; * Closing connection 0; The server was not able to produce a timely response to your request.%; ```. The issue was that I was using the broad-gotc-dev project to run the workflow, but two of my input files were in broad-gp-gotc-pilot, but I had trouble figuring that out from this error message. Happy to provide the wdl and json files as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/589
https://github.com/broadinstitute/cromwell/issues/589:1367,Deployability,PATCH,PATCH,1367,"I recently attempted to run a workflow with files in a separate non public google project as inputs. I submitted it using both Swagger and curl but neither gave very informative error messages. Here's the curl command and output:. ```; curl -v https://cromwell.gotc-dev.broadinstitute.org/api/workflows/v1 -F wdlSource=@PairedSingleSampleWf.wdl -F workflowInputs=@ExampleOfIncorrectProject.json; * Trying 104.197.140.34...; * Connected to cromwell.gotc-dev.broadinstitute.org (104.197.140.34) port 443 (#0); * TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384; * Server certificate: cromwell.gotc-dev.broadinstitute.org; * Server certificate: InCommon RSA Server CA; * Server certificate: USERTrust RSA Certification Authority; * Server certificate: AddTrust External CA Root; > POST /api/workflows/v1 HTTP/1.1; > Host: cromwell.gotc-dev.broadinstitute.org; > User-Agent: curl/7.43.0; > Accept: */*; > Content-Length: 38237; > Expect: 100-continue; > Content-Type: multipart/form-data; boundary=------------------------c2956aa00c34148a; > ; < HTTP/1.1 100 Continue; < HTTP/1.1 500 Internal Server Error; < Date: Fri, 18 Mar 2016 17:59:04 GMT; < Server: spray-can/1.3.2; < X-Frame-Options: SAMEORIGIN; < Access-Control-Allow-Origin: *; < Access-Control-Allow-Headers: authorization,content-type,accept,origin; < Access-Control-Allow-Methods: GET,POST,PUT,PATCH,DELETE,OPTIONS,HEAD; < Access-Control-Max-Age: 1728000; < Content-Type: text/plain; charset=UTF-8; < Content-Length: 69; < Connection: close; < ; * Closing connection 0; The server was not able to produce a timely response to your request.%; ```. The issue was that I was using the broad-gotc-dev project to run the workflow, but two of my input files were in broad-gp-gotc-pilot, but I had trouble figuring that out from this error message. Happy to provide the wdl and json files as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/589
https://github.com/broadinstitute/cromwell/issues/589:184,Integrability,message,messages,184,"I recently attempted to run a workflow with files in a separate non public google project as inputs. I submitted it using both Swagger and curl but neither gave very informative error messages. Here's the curl command and output:. ```; curl -v https://cromwell.gotc-dev.broadinstitute.org/api/workflows/v1 -F wdlSource=@PairedSingleSampleWf.wdl -F workflowInputs=@ExampleOfIncorrectProject.json; * Trying 104.197.140.34...; * Connected to cromwell.gotc-dev.broadinstitute.org (104.197.140.34) port 443 (#0); * TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384; * Server certificate: cromwell.gotc-dev.broadinstitute.org; * Server certificate: InCommon RSA Server CA; * Server certificate: USERTrust RSA Certification Authority; * Server certificate: AddTrust External CA Root; > POST /api/workflows/v1 HTTP/1.1; > Host: cromwell.gotc-dev.broadinstitute.org; > User-Agent: curl/7.43.0; > Accept: */*; > Content-Length: 38237; > Expect: 100-continue; > Content-Type: multipart/form-data; boundary=------------------------c2956aa00c34148a; > ; < HTTP/1.1 100 Continue; < HTTP/1.1 500 Internal Server Error; < Date: Fri, 18 Mar 2016 17:59:04 GMT; < Server: spray-can/1.3.2; < X-Frame-Options: SAMEORIGIN; < Access-Control-Allow-Origin: *; < Access-Control-Allow-Headers: authorization,content-type,accept,origin; < Access-Control-Allow-Methods: GET,POST,PUT,PATCH,DELETE,OPTIONS,HEAD; < Access-Control-Max-Age: 1728000; < Content-Type: text/plain; charset=UTF-8; < Content-Length: 69; < Connection: close; < ; * Closing connection 0; The server was not able to produce a timely response to your request.%; ```. The issue was that I was using the broad-gotc-dev project to run the workflow, but two of my input files were in broad-gp-gotc-pilot, but I had trouble figuring that out from this error message. Happy to provide the wdl and json files as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/589
https://github.com/broadinstitute/cromwell/issues/589:1806,Integrability,message,message,1806,"I recently attempted to run a workflow with files in a separate non public google project as inputs. I submitted it using both Swagger and curl but neither gave very informative error messages. Here's the curl command and output:. ```; curl -v https://cromwell.gotc-dev.broadinstitute.org/api/workflows/v1 -F wdlSource=@PairedSingleSampleWf.wdl -F workflowInputs=@ExampleOfIncorrectProject.json; * Trying 104.197.140.34...; * Connected to cromwell.gotc-dev.broadinstitute.org (104.197.140.34) port 443 (#0); * TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384; * Server certificate: cromwell.gotc-dev.broadinstitute.org; * Server certificate: InCommon RSA Server CA; * Server certificate: USERTrust RSA Certification Authority; * Server certificate: AddTrust External CA Root; > POST /api/workflows/v1 HTTP/1.1; > Host: cromwell.gotc-dev.broadinstitute.org; > User-Agent: curl/7.43.0; > Accept: */*; > Content-Length: 38237; > Expect: 100-continue; > Content-Type: multipart/form-data; boundary=------------------------c2956aa00c34148a; > ; < HTTP/1.1 100 Continue; < HTTP/1.1 500 Internal Server Error; < Date: Fri, 18 Mar 2016 17:59:04 GMT; < Server: spray-can/1.3.2; < X-Frame-Options: SAMEORIGIN; < Access-Control-Allow-Origin: *; < Access-Control-Allow-Headers: authorization,content-type,accept,origin; < Access-Control-Allow-Methods: GET,POST,PUT,PATCH,DELETE,OPTIONS,HEAD; < Access-Control-Max-Age: 1728000; < Content-Type: text/plain; charset=UTF-8; < Content-Length: 69; < Connection: close; < ; * Closing connection 0; The server was not able to produce a timely response to your request.%; ```. The issue was that I was using the broad-gotc-dev project to run the workflow, but two of my input files were in broad-gp-gotc-pilot, but I had trouble figuring that out from this error message. Happy to provide the wdl and json files as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/589
https://github.com/broadinstitute/cromwell/issues/589:583,Security,certificate,certificate,583,"I recently attempted to run a workflow with files in a separate non public google project as inputs. I submitted it using both Swagger and curl but neither gave very informative error messages. Here's the curl command and output:. ```; curl -v https://cromwell.gotc-dev.broadinstitute.org/api/workflows/v1 -F wdlSource=@PairedSingleSampleWf.wdl -F workflowInputs=@ExampleOfIncorrectProject.json; * Trying 104.197.140.34...; * Connected to cromwell.gotc-dev.broadinstitute.org (104.197.140.34) port 443 (#0); * TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384; * Server certificate: cromwell.gotc-dev.broadinstitute.org; * Server certificate: InCommon RSA Server CA; * Server certificate: USERTrust RSA Certification Authority; * Server certificate: AddTrust External CA Root; > POST /api/workflows/v1 HTTP/1.1; > Host: cromwell.gotc-dev.broadinstitute.org; > User-Agent: curl/7.43.0; > Accept: */*; > Content-Length: 38237; > Expect: 100-continue; > Content-Type: multipart/form-data; boundary=------------------------c2956aa00c34148a; > ; < HTTP/1.1 100 Continue; < HTTP/1.1 500 Internal Server Error; < Date: Fri, 18 Mar 2016 17:59:04 GMT; < Server: spray-can/1.3.2; < X-Frame-Options: SAMEORIGIN; < Access-Control-Allow-Origin: *; < Access-Control-Allow-Headers: authorization,content-type,accept,origin; < Access-Control-Allow-Methods: GET,POST,PUT,PATCH,DELETE,OPTIONS,HEAD; < Access-Control-Max-Age: 1728000; < Content-Type: text/plain; charset=UTF-8; < Content-Length: 69; < Connection: close; < ; * Closing connection 0; The server was not able to produce a timely response to your request.%; ```. The issue was that I was using the broad-gotc-dev project to run the workflow, but two of my input files were in broad-gp-gotc-pilot, but I had trouble figuring that out from this error message. Happy to provide the wdl and json files as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/589
https://github.com/broadinstitute/cromwell/issues/589:643,Security,certificate,certificate,643,"I recently attempted to run a workflow with files in a separate non public google project as inputs. I submitted it using both Swagger and curl but neither gave very informative error messages. Here's the curl command and output:. ```; curl -v https://cromwell.gotc-dev.broadinstitute.org/api/workflows/v1 -F wdlSource=@PairedSingleSampleWf.wdl -F workflowInputs=@ExampleOfIncorrectProject.json; * Trying 104.197.140.34...; * Connected to cromwell.gotc-dev.broadinstitute.org (104.197.140.34) port 443 (#0); * TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384; * Server certificate: cromwell.gotc-dev.broadinstitute.org; * Server certificate: InCommon RSA Server CA; * Server certificate: USERTrust RSA Certification Authority; * Server certificate: AddTrust External CA Root; > POST /api/workflows/v1 HTTP/1.1; > Host: cromwell.gotc-dev.broadinstitute.org; > User-Agent: curl/7.43.0; > Accept: */*; > Content-Length: 38237; > Expect: 100-continue; > Content-Type: multipart/form-data; boundary=------------------------c2956aa00c34148a; > ; < HTTP/1.1 100 Continue; < HTTP/1.1 500 Internal Server Error; < Date: Fri, 18 Mar 2016 17:59:04 GMT; < Server: spray-can/1.3.2; < X-Frame-Options: SAMEORIGIN; < Access-Control-Allow-Origin: *; < Access-Control-Allow-Headers: authorization,content-type,accept,origin; < Access-Control-Allow-Methods: GET,POST,PUT,PATCH,DELETE,OPTIONS,HEAD; < Access-Control-Max-Age: 1728000; < Content-Type: text/plain; charset=UTF-8; < Content-Length: 69; < Connection: close; < ; * Closing connection 0; The server was not able to produce a timely response to your request.%; ```. The issue was that I was using the broad-gotc-dev project to run the workflow, but two of my input files were in broad-gp-gotc-pilot, but I had trouble figuring that out from this error message. Happy to provide the wdl and json files as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/589
https://github.com/broadinstitute/cromwell/issues/589:689,Security,certificate,certificate,689,"I recently attempted to run a workflow with files in a separate non public google project as inputs. I submitted it using both Swagger and curl but neither gave very informative error messages. Here's the curl command and output:. ```; curl -v https://cromwell.gotc-dev.broadinstitute.org/api/workflows/v1 -F wdlSource=@PairedSingleSampleWf.wdl -F workflowInputs=@ExampleOfIncorrectProject.json; * Trying 104.197.140.34...; * Connected to cromwell.gotc-dev.broadinstitute.org (104.197.140.34) port 443 (#0); * TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384; * Server certificate: cromwell.gotc-dev.broadinstitute.org; * Server certificate: InCommon RSA Server CA; * Server certificate: USERTrust RSA Certification Authority; * Server certificate: AddTrust External CA Root; > POST /api/workflows/v1 HTTP/1.1; > Host: cromwell.gotc-dev.broadinstitute.org; > User-Agent: curl/7.43.0; > Accept: */*; > Content-Length: 38237; > Expect: 100-continue; > Content-Type: multipart/form-data; boundary=------------------------c2956aa00c34148a; > ; < HTTP/1.1 100 Continue; < HTTP/1.1 500 Internal Server Error; < Date: Fri, 18 Mar 2016 17:59:04 GMT; < Server: spray-can/1.3.2; < X-Frame-Options: SAMEORIGIN; < Access-Control-Allow-Origin: *; < Access-Control-Allow-Headers: authorization,content-type,accept,origin; < Access-Control-Allow-Methods: GET,POST,PUT,PATCH,DELETE,OPTIONS,HEAD; < Access-Control-Max-Age: 1728000; < Content-Type: text/plain; charset=UTF-8; < Content-Length: 69; < Connection: close; < ; * Closing connection 0; The server was not able to produce a timely response to your request.%; ```. The issue was that I was using the broad-gotc-dev project to run the workflow, but two of my input files were in broad-gp-gotc-pilot, but I had trouble figuring that out from this error message. Happy to provide the wdl and json files as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/589
https://github.com/broadinstitute/cromwell/issues/589:750,Security,certificate,certificate,750,"I recently attempted to run a workflow with files in a separate non public google project as inputs. I submitted it using both Swagger and curl but neither gave very informative error messages. Here's the curl command and output:. ```; curl -v https://cromwell.gotc-dev.broadinstitute.org/api/workflows/v1 -F wdlSource=@PairedSingleSampleWf.wdl -F workflowInputs=@ExampleOfIncorrectProject.json; * Trying 104.197.140.34...; * Connected to cromwell.gotc-dev.broadinstitute.org (104.197.140.34) port 443 (#0); * TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384; * Server certificate: cromwell.gotc-dev.broadinstitute.org; * Server certificate: InCommon RSA Server CA; * Server certificate: USERTrust RSA Certification Authority; * Server certificate: AddTrust External CA Root; > POST /api/workflows/v1 HTTP/1.1; > Host: cromwell.gotc-dev.broadinstitute.org; > User-Agent: curl/7.43.0; > Accept: */*; > Content-Length: 38237; > Expect: 100-continue; > Content-Type: multipart/form-data; boundary=------------------------c2956aa00c34148a; > ; < HTTP/1.1 100 Continue; < HTTP/1.1 500 Internal Server Error; < Date: Fri, 18 Mar 2016 17:59:04 GMT; < Server: spray-can/1.3.2; < X-Frame-Options: SAMEORIGIN; < Access-Control-Allow-Origin: *; < Access-Control-Allow-Headers: authorization,content-type,accept,origin; < Access-Control-Allow-Methods: GET,POST,PUT,PATCH,DELETE,OPTIONS,HEAD; < Access-Control-Max-Age: 1728000; < Content-Type: text/plain; charset=UTF-8; < Content-Length: 69; < Connection: close; < ; * Closing connection 0; The server was not able to produce a timely response to your request.%; ```. The issue was that I was using the broad-gotc-dev project to run the workflow, but two of my input files were in broad-gp-gotc-pilot, but I had trouble figuring that out from this error message. Happy to provide the wdl and json files as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/589
https://github.com/broadinstitute/cromwell/issues/589:1216,Security,Access,Access-Control-Allow-Origin,1216,"I recently attempted to run a workflow with files in a separate non public google project as inputs. I submitted it using both Swagger and curl but neither gave very informative error messages. Here's the curl command and output:. ```; curl -v https://cromwell.gotc-dev.broadinstitute.org/api/workflows/v1 -F wdlSource=@PairedSingleSampleWf.wdl -F workflowInputs=@ExampleOfIncorrectProject.json; * Trying 104.197.140.34...; * Connected to cromwell.gotc-dev.broadinstitute.org (104.197.140.34) port 443 (#0); * TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384; * Server certificate: cromwell.gotc-dev.broadinstitute.org; * Server certificate: InCommon RSA Server CA; * Server certificate: USERTrust RSA Certification Authority; * Server certificate: AddTrust External CA Root; > POST /api/workflows/v1 HTTP/1.1; > Host: cromwell.gotc-dev.broadinstitute.org; > User-Agent: curl/7.43.0; > Accept: */*; > Content-Length: 38237; > Expect: 100-continue; > Content-Type: multipart/form-data; boundary=------------------------c2956aa00c34148a; > ; < HTTP/1.1 100 Continue; < HTTP/1.1 500 Internal Server Error; < Date: Fri, 18 Mar 2016 17:59:04 GMT; < Server: spray-can/1.3.2; < X-Frame-Options: SAMEORIGIN; < Access-Control-Allow-Origin: *; < Access-Control-Allow-Headers: authorization,content-type,accept,origin; < Access-Control-Allow-Methods: GET,POST,PUT,PATCH,DELETE,OPTIONS,HEAD; < Access-Control-Max-Age: 1728000; < Content-Type: text/plain; charset=UTF-8; < Content-Length: 69; < Connection: close; < ; * Closing connection 0; The server was not able to produce a timely response to your request.%; ```. The issue was that I was using the broad-gotc-dev project to run the workflow, but two of my input files were in broad-gp-gotc-pilot, but I had trouble figuring that out from this error message. Happy to provide the wdl and json files as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/589
https://github.com/broadinstitute/cromwell/issues/589:1250,Security,Access,Access-Control-Allow-Headers,1250,"I recently attempted to run a workflow with files in a separate non public google project as inputs. I submitted it using both Swagger and curl but neither gave very informative error messages. Here's the curl command and output:. ```; curl -v https://cromwell.gotc-dev.broadinstitute.org/api/workflows/v1 -F wdlSource=@PairedSingleSampleWf.wdl -F workflowInputs=@ExampleOfIncorrectProject.json; * Trying 104.197.140.34...; * Connected to cromwell.gotc-dev.broadinstitute.org (104.197.140.34) port 443 (#0); * TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384; * Server certificate: cromwell.gotc-dev.broadinstitute.org; * Server certificate: InCommon RSA Server CA; * Server certificate: USERTrust RSA Certification Authority; * Server certificate: AddTrust External CA Root; > POST /api/workflows/v1 HTTP/1.1; > Host: cromwell.gotc-dev.broadinstitute.org; > User-Agent: curl/7.43.0; > Accept: */*; > Content-Length: 38237; > Expect: 100-continue; > Content-Type: multipart/form-data; boundary=------------------------c2956aa00c34148a; > ; < HTTP/1.1 100 Continue; < HTTP/1.1 500 Internal Server Error; < Date: Fri, 18 Mar 2016 17:59:04 GMT; < Server: spray-can/1.3.2; < X-Frame-Options: SAMEORIGIN; < Access-Control-Allow-Origin: *; < Access-Control-Allow-Headers: authorization,content-type,accept,origin; < Access-Control-Allow-Methods: GET,POST,PUT,PATCH,DELETE,OPTIONS,HEAD; < Access-Control-Max-Age: 1728000; < Content-Type: text/plain; charset=UTF-8; < Content-Length: 69; < Connection: close; < ; * Closing connection 0; The server was not able to produce a timely response to your request.%; ```. The issue was that I was using the broad-gotc-dev project to run the workflow, but two of my input files were in broad-gp-gotc-pilot, but I had trouble figuring that out from this error message. Happy to provide the wdl and json files as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/589
https://github.com/broadinstitute/cromwell/issues/589:1280,Security,authoriz,authorization,1280,"I recently attempted to run a workflow with files in a separate non public google project as inputs. I submitted it using both Swagger and curl but neither gave very informative error messages. Here's the curl command and output:. ```; curl -v https://cromwell.gotc-dev.broadinstitute.org/api/workflows/v1 -F wdlSource=@PairedSingleSampleWf.wdl -F workflowInputs=@ExampleOfIncorrectProject.json; * Trying 104.197.140.34...; * Connected to cromwell.gotc-dev.broadinstitute.org (104.197.140.34) port 443 (#0); * TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384; * Server certificate: cromwell.gotc-dev.broadinstitute.org; * Server certificate: InCommon RSA Server CA; * Server certificate: USERTrust RSA Certification Authority; * Server certificate: AddTrust External CA Root; > POST /api/workflows/v1 HTTP/1.1; > Host: cromwell.gotc-dev.broadinstitute.org; > User-Agent: curl/7.43.0; > Accept: */*; > Content-Length: 38237; > Expect: 100-continue; > Content-Type: multipart/form-data; boundary=------------------------c2956aa00c34148a; > ; < HTTP/1.1 100 Continue; < HTTP/1.1 500 Internal Server Error; < Date: Fri, 18 Mar 2016 17:59:04 GMT; < Server: spray-can/1.3.2; < X-Frame-Options: SAMEORIGIN; < Access-Control-Allow-Origin: *; < Access-Control-Allow-Headers: authorization,content-type,accept,origin; < Access-Control-Allow-Methods: GET,POST,PUT,PATCH,DELETE,OPTIONS,HEAD; < Access-Control-Max-Age: 1728000; < Content-Type: text/plain; charset=UTF-8; < Content-Length: 69; < Connection: close; < ; * Closing connection 0; The server was not able to produce a timely response to your request.%; ```. The issue was that I was using the broad-gotc-dev project to run the workflow, but two of my input files were in broad-gp-gotc-pilot, but I had trouble figuring that out from this error message. Happy to provide the wdl and json files as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/589
https://github.com/broadinstitute/cromwell/issues/589:1324,Security,Access,Access-Control-Allow-Methods,1324,"I recently attempted to run a workflow with files in a separate non public google project as inputs. I submitted it using both Swagger and curl but neither gave very informative error messages. Here's the curl command and output:. ```; curl -v https://cromwell.gotc-dev.broadinstitute.org/api/workflows/v1 -F wdlSource=@PairedSingleSampleWf.wdl -F workflowInputs=@ExampleOfIncorrectProject.json; * Trying 104.197.140.34...; * Connected to cromwell.gotc-dev.broadinstitute.org (104.197.140.34) port 443 (#0); * TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384; * Server certificate: cromwell.gotc-dev.broadinstitute.org; * Server certificate: InCommon RSA Server CA; * Server certificate: USERTrust RSA Certification Authority; * Server certificate: AddTrust External CA Root; > POST /api/workflows/v1 HTTP/1.1; > Host: cromwell.gotc-dev.broadinstitute.org; > User-Agent: curl/7.43.0; > Accept: */*; > Content-Length: 38237; > Expect: 100-continue; > Content-Type: multipart/form-data; boundary=------------------------c2956aa00c34148a; > ; < HTTP/1.1 100 Continue; < HTTP/1.1 500 Internal Server Error; < Date: Fri, 18 Mar 2016 17:59:04 GMT; < Server: spray-can/1.3.2; < X-Frame-Options: SAMEORIGIN; < Access-Control-Allow-Origin: *; < Access-Control-Allow-Headers: authorization,content-type,accept,origin; < Access-Control-Allow-Methods: GET,POST,PUT,PATCH,DELETE,OPTIONS,HEAD; < Access-Control-Max-Age: 1728000; < Content-Type: text/plain; charset=UTF-8; < Content-Length: 69; < Connection: close; < ; * Closing connection 0; The server was not able to produce a timely response to your request.%; ```. The issue was that I was using the broad-gotc-dev project to run the workflow, but two of my input files were in broad-gp-gotc-pilot, but I had trouble figuring that out from this error message. Happy to provide the wdl and json files as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/589
https://github.com/broadinstitute/cromwell/issues/589:1396,Security,Access,Access-Control-Max-Age,1396,"I recently attempted to run a workflow with files in a separate non public google project as inputs. I submitted it using both Swagger and curl but neither gave very informative error messages. Here's the curl command and output:. ```; curl -v https://cromwell.gotc-dev.broadinstitute.org/api/workflows/v1 -F wdlSource=@PairedSingleSampleWf.wdl -F workflowInputs=@ExampleOfIncorrectProject.json; * Trying 104.197.140.34...; * Connected to cromwell.gotc-dev.broadinstitute.org (104.197.140.34) port 443 (#0); * TLS 1.2 connection using TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384; * Server certificate: cromwell.gotc-dev.broadinstitute.org; * Server certificate: InCommon RSA Server CA; * Server certificate: USERTrust RSA Certification Authority; * Server certificate: AddTrust External CA Root; > POST /api/workflows/v1 HTTP/1.1; > Host: cromwell.gotc-dev.broadinstitute.org; > User-Agent: curl/7.43.0; > Accept: */*; > Content-Length: 38237; > Expect: 100-continue; > Content-Type: multipart/form-data; boundary=------------------------c2956aa00c34148a; > ; < HTTP/1.1 100 Continue; < HTTP/1.1 500 Internal Server Error; < Date: Fri, 18 Mar 2016 17:59:04 GMT; < Server: spray-can/1.3.2; < X-Frame-Options: SAMEORIGIN; < Access-Control-Allow-Origin: *; < Access-Control-Allow-Headers: authorization,content-type,accept,origin; < Access-Control-Allow-Methods: GET,POST,PUT,PATCH,DELETE,OPTIONS,HEAD; < Access-Control-Max-Age: 1728000; < Content-Type: text/plain; charset=UTF-8; < Content-Length: 69; < Connection: close; < ; * Closing connection 0; The server was not able to produce a timely response to your request.%; ```. The issue was that I was using the broad-gotc-dev project to run the workflow, but two of my input files were in broad-gp-gotc-pilot, but I had trouble figuring that out from this error message. Happy to provide the wdl and json files as well.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/589
https://github.com/broadinstitute/cromwell/issues/591:12,Availability,error,errors,12,Returns 404 errors on JES API calls. Likely due to new API?,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/591
https://github.com/broadinstitute/cromwell/pull/593:49,Testability,test,test,49,Suggested comments for reviewers:; - [x] Needs a test; - [x] Needs docs; - [x] Add to changelog; - [x] How about a proper type for this?; - [x] Best code I've ever seen; - [x] The test is failing,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/593
https://github.com/broadinstitute/cromwell/pull/593:180,Testability,test,test,180,Suggested comments for reviewers:; - [x] Needs a test; - [x] Needs docs; - [x] Add to changelog; - [x] How about a proper type for this?; - [x] Best code I've ever seen; - [x] The test is failing,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/593
https://github.com/broadinstitute/cromwell/issues/596:804,Testability,log,logs,804,"The complicated retry/ack dance between WA and CA is meant to ensure the proper sequencing of status writes. A more straightforward way to accomplish this would be to use CRDTs as per Kuhn and Allen Reactive Design Patterns. This way we don't have to care about the order of the writes, executions will always end up with the right status no matter which write attempt happens last. A superior sequel to this could use the EXECUTION_INFO table in an event sourcing-like append-only manner to record all statuses and the times at which they were generated within Cromwell. A database view could present an image of all this that looked the same as the EXECUTION table does now, except we'd have conflict-free writes, simplified Cromwell internals, and event data in the DB that ops currently has to scour logs to find. But the first paragraph here is a prerequisite for all this and a good place to start.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/596
https://github.com/broadinstitute/cromwell/issues/596:716,Usability,simpl,simplified,716,"The complicated retry/ack dance between WA and CA is meant to ensure the proper sequencing of status writes. A more straightforward way to accomplish this would be to use CRDTs as per Kuhn and Allen Reactive Design Patterns. This way we don't have to care about the order of the writes, executions will always end up with the right status no matter which write attempt happens last. A superior sequel to this could use the EXECUTION_INFO table in an event sourcing-like append-only manner to record all statuses and the times at which they were generated within Cromwell. A database view could present an image of all this that looked the same as the EXECUTION table does now, except we'd have conflict-free writes, simplified Cromwell internals, and event data in the DB that ops currently has to scour logs to find. But the first paragraph here is a prerequisite for all this and a good place to start.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/596
https://github.com/broadinstitute/cromwell/issues/597:5,Deployability,pipeline,pipeline,5,"As a pipeline author, I don't enjoy having to spin up a VM, with docker in order to do string substitutions on my parameters. In the GOTC pipeline, we do this in order to strip off the extension of the input file in order to get a base-name, which happens ~40 times in a 20-plex workflow. . This causes a real problem because by requiring so many VMs to spun up, we spend more money (although that cost is quite small) but also eat into our quotas and QPS limits, which actually does hurt our scalability. The proposal is to add a new expression language function which allows for regex substitutions:. sub(string, pattern, replacement). For example,. to strip off an extension from a file you could use `sub(filename, "".bam$"","""")`; to swap an extension, you could use `sub(filename, "".bam$"", "".metrics"")`. By being constrained to a regex (unlike an arbitrary code block) we don't have concerns about security or evaluating these in the cromwell engine. This does not eliminate the need for a generally more expressive expression language or user defined functions, but does solve a large class of common usages that impact ease of use and performance",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/597
https://github.com/broadinstitute/cromwell/issues/597:138,Deployability,pipeline,pipeline,138,"As a pipeline author, I don't enjoy having to spin up a VM, with docker in order to do string substitutions on my parameters. In the GOTC pipeline, we do this in order to strip off the extension of the input file in order to get a base-name, which happens ~40 times in a 20-plex workflow. . This causes a real problem because by requiring so many VMs to spun up, we spend more money (although that cost is quite small) but also eat into our quotas and QPS limits, which actually does hurt our scalability. The proposal is to add a new expression language function which allows for regex substitutions:. sub(string, pattern, replacement). For example,. to strip off an extension from a file you could use `sub(filename, "".bam$"","""")`; to swap an extension, you could use `sub(filename, "".bam$"", "".metrics"")`. By being constrained to a regex (unlike an arbitrary code block) we don't have concerns about security or evaluating these in the cromwell engine. This does not eliminate the need for a generally more expressive expression language or user defined functions, but does solve a large class of common usages that impact ease of use and performance",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/597
https://github.com/broadinstitute/cromwell/issues/597:493,Performance,scalab,scalability,493,"As a pipeline author, I don't enjoy having to spin up a VM, with docker in order to do string substitutions on my parameters. In the GOTC pipeline, we do this in order to strip off the extension of the input file in order to get a base-name, which happens ~40 times in a 20-plex workflow. . This causes a real problem because by requiring so many VMs to spun up, we spend more money (although that cost is quite small) but also eat into our quotas and QPS limits, which actually does hurt our scalability. The proposal is to add a new expression language function which allows for regex substitutions:. sub(string, pattern, replacement). For example,. to strip off an extension from a file you could use `sub(filename, "".bam$"","""")`; to swap an extension, you could use `sub(filename, "".bam$"", "".metrics"")`. By being constrained to a regex (unlike an arbitrary code block) we don't have concerns about security or evaluating these in the cromwell engine. This does not eliminate the need for a generally more expressive expression language or user defined functions, but does solve a large class of common usages that impact ease of use and performance",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/597
https://github.com/broadinstitute/cromwell/issues/597:1140,Performance,perform,performance,1140,"As a pipeline author, I don't enjoy having to spin up a VM, with docker in order to do string substitutions on my parameters. In the GOTC pipeline, we do this in order to strip off the extension of the input file in order to get a base-name, which happens ~40 times in a 20-plex workflow. . This causes a real problem because by requiring so many VMs to spun up, we spend more money (although that cost is quite small) but also eat into our quotas and QPS limits, which actually does hurt our scalability. The proposal is to add a new expression language function which allows for regex substitutions:. sub(string, pattern, replacement). For example,. to strip off an extension from a file you could use `sub(filename, "".bam$"","""")`; to swap an extension, you could use `sub(filename, "".bam$"", "".metrics"")`. By being constrained to a regex (unlike an arbitrary code block) we don't have concerns about security or evaluating these in the cromwell engine. This does not eliminate the need for a generally more expressive expression language or user defined functions, but does solve a large class of common usages that impact ease of use and performance",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/597
https://github.com/broadinstitute/cromwell/issues/597:901,Security,secur,security,901,"As a pipeline author, I don't enjoy having to spin up a VM, with docker in order to do string substitutions on my parameters. In the GOTC pipeline, we do this in order to strip off the extension of the input file in order to get a base-name, which happens ~40 times in a 20-plex workflow. . This causes a real problem because by requiring so many VMs to spun up, we spend more money (although that cost is quite small) but also eat into our quotas and QPS limits, which actually does hurt our scalability. The proposal is to add a new expression language function which allows for regex substitutions:. sub(string, pattern, replacement). For example,. to strip off an extension from a file you could use `sub(filename, "".bam$"","""")`; to swap an extension, you could use `sub(filename, "".bam$"", "".metrics"")`. By being constrained to a regex (unlike an arbitrary code block) we don't have concerns about security or evaluating these in the cromwell engine. This does not eliminate the need for a generally more expressive expression language or user defined functions, but does solve a large class of common usages that impact ease of use and performance",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/597
https://github.com/broadinstitute/cromwell/issues/600:47,Availability,error,error,47,These workflows all failed with the stacktrace error in the comments section. These were run on gotc-prod. 836783df-339e-4631-a7cd-038072899edb - operations/EIfzx8m1Khjt87q2wPLY8CAgn6KQ6Z4NKg9wcm9kdWN0aW9uUXVldWU. 9925f072-debf-4e4c-98aa-01db0a34a62f - operations/EOqx-cy1KhioppLVjZKx1XQgn6KQ6Z4NKg9wcm9kdWN0aW9uUXVldWU. f7c465bb-e5e5-4cb8-b493-82f072a40040 - operations/EIL4ks21Khi1zfCMm4HHpO8BIJ-ikOmeDSoPcHJvZHVjdGlvblF1ZXVl,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/600
https://github.com/broadinstitute/cromwell/issues/601:260,Safety,avoid,avoidance,260,"As a user, I would like to be able to call an endpoint in cromwell which takes in a workflow submission identifier and have cromwell clean up all intermediate outputs of the workflow (files that are not declared as outputs of the workflow).; If there is a job avoidance feature when this is worked on, these cleaned up tasks internal to the workflow should not be eligible for job avoidance. However, the overall workflow would be eligible.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/601
https://github.com/broadinstitute/cromwell/issues/601:381,Safety,avoid,avoidance,381,"As a user, I would like to be able to call an endpoint in cromwell which takes in a workflow submission identifier and have cromwell clean up all intermediate outputs of the workflow (files that are not declared as outputs of the workflow).; If there is a job avoidance feature when this is worked on, these cleaned up tasks internal to the workflow should not be eligible for job avoidance. However, the overall workflow would be eligible.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/601
https://github.com/broadinstitute/cromwell/issues/602:233,Performance,cache,cached,233,"As a user of the cromwell REST services, I would like to be able to get:; - the size of the current total output of the workflow; - the size after cleaning up intermediate results; - outputs retained due to their reference in a call cached execution",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/602
https://github.com/broadinstitute/cromwell/issues/603:101,Availability,echo,echo,101,"With a clean database, run this with the JES backend (no inputs):. ```; task x {; String s; command {echo ${s}}; output {String t = read_string(stdout())}; runtime {docker: ""ubuntu:latest""}; }. workflow w {; call x {input: s=""foo""}; call x as y {input: s=x.t}; }; ```. call x runs fine. call y _should_ get a cache hit to call x, but instead:. ```; [2016-03-22 15:20:59,921] [info] WorkflowActor [54108c5b]: starting calls: w.y; [2016-03-22 15:20:59,921] [info] WorkflowActor [54108c5b]: persisting status of y to Starting.; [2016-03-22 15:21:00,344] [info] WorkflowActor [54108c5b]: Call Caching: Cache hit. Using 54108c5b:x as results for 54108c5b:y; [2016-03-22 15:21:00,351] [info] WorkflowActor [54108c5b]: inputs for call 'y':; s -> WdlString(foo); [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: created call actor for y.; [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: persisting status of y to Running.; [2016-03-22 15:21:05,567] [error] CallActor [54108c5b:y]: Failing call: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; cromwell.util.AggregatedException: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:112); at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:124); at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:640); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:424); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:418); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/603
https://github.com/broadinstitute/cromwell/issues/603:963,Availability,error,error,963,"database, run this with the JES backend (no inputs):. ```; task x {; String s; command {echo ${s}}; output {String t = read_string(stdout())}; runtime {docker: ""ubuntu:latest""}; }. workflow w {; call x {input: s=""foo""}; call x as y {input: s=x.t}; }; ```. call x runs fine. call y _should_ get a cache hit to call x, but instead:. ```; [2016-03-22 15:20:59,921] [info] WorkflowActor [54108c5b]: starting calls: w.y; [2016-03-22 15:20:59,921] [info] WorkflowActor [54108c5b]: persisting status of y to Starting.; [2016-03-22 15:21:00,344] [info] WorkflowActor [54108c5b]: Call Caching: Cache hit. Using 54108c5b:x as results for 54108c5b:y; [2016-03-22 15:21:00,351] [info] WorkflowActor [54108c5b]: inputs for call 'y':; s -> WdlString(foo); [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: created call actor for y.; [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: persisting status of y to Running.; [2016-03-22 15:21:05,567] [error] CallActor [54108c5b:y]: Failing call: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; cromwell.util.AggregatedException: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:112); at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:124); at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:640); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:424); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:418); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/603
https://github.com/broadinstitute/cromwell/issues/603:309,Performance,cache,cache,309,"With a clean database, run this with the JES backend (no inputs):. ```; task x {; String s; command {echo ${s}}; output {String t = read_string(stdout())}; runtime {docker: ""ubuntu:latest""}; }. workflow w {; call x {input: s=""foo""}; call x as y {input: s=x.t}; }; ```. call x runs fine. call y _should_ get a cache hit to call x, but instead:. ```; [2016-03-22 15:20:59,921] [info] WorkflowActor [54108c5b]: starting calls: w.y; [2016-03-22 15:20:59,921] [info] WorkflowActor [54108c5b]: persisting status of y to Starting.; [2016-03-22 15:21:00,344] [info] WorkflowActor [54108c5b]: Call Caching: Cache hit. Using 54108c5b:x as results for 54108c5b:y; [2016-03-22 15:21:00,351] [info] WorkflowActor [54108c5b]: inputs for call 'y':; s -> WdlString(foo); [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: created call actor for y.; [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: persisting status of y to Running.; [2016-03-22 15:21:05,567] [error] CallActor [54108c5b:y]: Failing call: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; cromwell.util.AggregatedException: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:112); at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:124); at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:640); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:424); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:418); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/603
https://github.com/broadinstitute/cromwell/issues/603:598,Performance,Cache,Cache,598,"With a clean database, run this with the JES backend (no inputs):. ```; task x {; String s; command {echo ${s}}; output {String t = read_string(stdout())}; runtime {docker: ""ubuntu:latest""}; }. workflow w {; call x {input: s=""foo""}; call x as y {input: s=x.t}; }; ```. call x runs fine. call y _should_ get a cache hit to call x, but instead:. ```; [2016-03-22 15:20:59,921] [info] WorkflowActor [54108c5b]: starting calls: w.y; [2016-03-22 15:20:59,921] [info] WorkflowActor [54108c5b]: persisting status of y to Starting.; [2016-03-22 15:21:00,344] [info] WorkflowActor [54108c5b]: Call Caching: Cache hit. Using 54108c5b:x as results for 54108c5b:y; [2016-03-22 15:21:00,351] [info] WorkflowActor [54108c5b]: inputs for call 'y':; s -> WdlString(foo); [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: created call actor for y.; [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: persisting status of y to Running.; [2016-03-22 15:21:05,567] [error] CallActor [54108c5b:y]: Failing call: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; cromwell.util.AggregatedException: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:112); at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:124); at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:640); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:424); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:418); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/603
https://github.com/broadinstitute/cromwell/issues/603:1620,Performance,concurren,concurrent,1620,"20:59,921] [info] WorkflowActor [54108c5b]: starting calls: w.y; [2016-03-22 15:20:59,921] [info] WorkflowActor [54108c5b]: persisting status of y to Starting.; [2016-03-22 15:21:00,344] [info] WorkflowActor [54108c5b]: Call Caching: Cache hit. Using 54108c5b:x as results for 54108c5b:y; [2016-03-22 15:21:00,351] [info] WorkflowActor [54108c5b]: inputs for call 'y':; s -> WdlString(foo); [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: created call actor for y.; [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: persisting status of y to Running.; [2016-03-22 15:21:05,567] [error] CallActor [54108c5b:y]: Failing call: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; cromwell.util.AggregatedException: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:112); at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:124); at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:640); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:424); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:418); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2016-03-22 15:21:05,568] [info] WorkflowActor [54108c5b]: persisting status of y to Failed.; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/603
https://github.com/broadinstitute/cromwell/issues/603:1710,Performance,concurren,concurrent,1710,"20:59,921] [info] WorkflowActor [54108c5b]: starting calls: w.y; [2016-03-22 15:20:59,921] [info] WorkflowActor [54108c5b]: persisting status of y to Starting.; [2016-03-22 15:21:00,344] [info] WorkflowActor [54108c5b]: Call Caching: Cache hit. Using 54108c5b:x as results for 54108c5b:y; [2016-03-22 15:21:00,351] [info] WorkflowActor [54108c5b]: inputs for call 'y':; s -> WdlString(foo); [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: created call actor for y.; [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: persisting status of y to Running.; [2016-03-22 15:21:05,567] [error] CallActor [54108c5b:y]: Failing call: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; cromwell.util.AggregatedException: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:112); at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:124); at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:640); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:424); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:418); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2016-03-22 15:21:05,568] [info] WorkflowActor [54108c5b]: persisting status of y to Failed.; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/603
https://github.com/broadinstitute/cromwell/issues/603:1955,Performance,concurren,concurrent,1955,"20:59,921] [info] WorkflowActor [54108c5b]: starting calls: w.y; [2016-03-22 15:20:59,921] [info] WorkflowActor [54108c5b]: persisting status of y to Starting.; [2016-03-22 15:21:00,344] [info] WorkflowActor [54108c5b]: Call Caching: Cache hit. Using 54108c5b:x as results for 54108c5b:y; [2016-03-22 15:21:00,351] [info] WorkflowActor [54108c5b]: inputs for call 'y':; s -> WdlString(foo); [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: created call actor for y.; [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: persisting status of y to Running.; [2016-03-22 15:21:05,567] [error] CallActor [54108c5b:y]: Failing call: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; cromwell.util.AggregatedException: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:112); at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:124); at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:640); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:424); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:418); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2016-03-22 15:21:05,568] [info] WorkflowActor [54108c5b]: persisting status of y to Failed.; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/603
https://github.com/broadinstitute/cromwell/issues/603:2028,Performance,concurren,concurrent,2028,"20:59,921] [info] WorkflowActor [54108c5b]: starting calls: w.y; [2016-03-22 15:20:59,921] [info] WorkflowActor [54108c5b]: persisting status of y to Starting.; [2016-03-22 15:21:00,344] [info] WorkflowActor [54108c5b]: Call Caching: Cache hit. Using 54108c5b:x as results for 54108c5b:y; [2016-03-22 15:21:00,351] [info] WorkflowActor [54108c5b]: inputs for call 'y':; s -> WdlString(foo); [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: created call actor for y.; [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: persisting status of y to Running.; [2016-03-22 15:21:05,567] [error] CallActor [54108c5b:y]: Failing call: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; cromwell.util.AggregatedException: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:112); at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:124); at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:640); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:424); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:418); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2016-03-22 15:21:05,568] [info] WorkflowActor [54108c5b]: persisting status of y to Failed.; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/603
https://github.com/broadinstitute/cromwell/issues/603:2113,Performance,concurren,concurrent,2113,"20:59,921] [info] WorkflowActor [54108c5b]: starting calls: w.y; [2016-03-22 15:20:59,921] [info] WorkflowActor [54108c5b]: persisting status of y to Starting.; [2016-03-22 15:21:00,344] [info] WorkflowActor [54108c5b]: Call Caching: Cache hit. Using 54108c5b:x as results for 54108c5b:y; [2016-03-22 15:21:00,351] [info] WorkflowActor [54108c5b]: inputs for call 'y':; s -> WdlString(foo); [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: created call actor for y.; [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: persisting status of y to Running.; [2016-03-22 15:21:05,567] [error] CallActor [54108c5b:y]: Failing call: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; cromwell.util.AggregatedException: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:112); at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:124); at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:640); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:424); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:418); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2016-03-22 15:21:05,568] [info] WorkflowActor [54108c5b]: persisting status of y to Failed.; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/603
https://github.com/broadinstitute/cromwell/issues/603:2190,Performance,concurren,concurrent,2190,"20:59,921] [info] WorkflowActor [54108c5b]: starting calls: w.y; [2016-03-22 15:20:59,921] [info] WorkflowActor [54108c5b]: persisting status of y to Starting.; [2016-03-22 15:21:00,344] [info] WorkflowActor [54108c5b]: Call Caching: Cache hit. Using 54108c5b:x as results for 54108c5b:y; [2016-03-22 15:21:00,351] [info] WorkflowActor [54108c5b]: inputs for call 'y':; s -> WdlString(foo); [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: created call actor for y.; [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: persisting status of y to Running.; [2016-03-22 15:21:05,567] [error] CallActor [54108c5b:y]: Failing call: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; cromwell.util.AggregatedException: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:112); at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:124); at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:640); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:424); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:418); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2016-03-22 15:21:05,568] [info] WorkflowActor [54108c5b]: persisting status of y to Failed.; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/603
https://github.com/broadinstitute/cromwell/issues/603:1092,Testability,log,log,1092," {echo ${s}}; output {String t = read_string(stdout())}; runtime {docker: ""ubuntu:latest""}; }. workflow w {; call x {input: s=""foo""}; call x as y {input: s=x.t}; }; ```. call x runs fine. call y _should_ get a cache hit to call x, but instead:. ```; [2016-03-22 15:20:59,921] [info] WorkflowActor [54108c5b]: starting calls: w.y; [2016-03-22 15:20:59,921] [info] WorkflowActor [54108c5b]: persisting status of y to Starting.; [2016-03-22 15:21:00,344] [info] WorkflowActor [54108c5b]: Call Caching: Cache hit. Using 54108c5b:x as results for 54108c5b:y; [2016-03-22 15:21:00,351] [info] WorkflowActor [54108c5b]: inputs for call 'y':; s -> WdlString(foo); [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: created call actor for y.; [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: persisting status of y to Running.; [2016-03-22 15:21:05,567] [error] CallActor [54108c5b:y]: Failing call: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; cromwell.util.AggregatedException: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:112); at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:124); at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:640); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:424); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:418); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:13",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/603
https://github.com/broadinstitute/cromwell/issues/603:1216,Testability,log,log,1216,"=""foo""}; call x as y {input: s=x.t}; }; ```. call x runs fine. call y _should_ get a cache hit to call x, but instead:. ```; [2016-03-22 15:20:59,921] [info] WorkflowActor [54108c5b]: starting calls: w.y; [2016-03-22 15:20:59,921] [info] WorkflowActor [54108c5b]: persisting status of y to Starting.; [2016-03-22 15:21:00,344] [info] WorkflowActor [54108c5b]: Call Caching: Cache hit. Using 54108c5b:x as results for 54108c5b:y; [2016-03-22 15:21:00,351] [info] WorkflowActor [54108c5b]: inputs for call 'y':; s -> WdlString(foo); [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: created call actor for y.; [2016-03-22 15:21:00,352] [info] WorkflowActor [54108c5b]: persisting status of y to Running.; [2016-03-22 15:21:05,567] [error] CallActor [54108c5b:y]: Failing call: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; cromwell.util.AggregatedException: Item not found: cromwell-dev/w/54108c5b-29a7-430e-b16b-07bd8dba47e7/call-y/y-stdout.log; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:112); at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:124); at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:640); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:424); at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:418); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerT",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/603
https://github.com/broadinstitute/cromwell/pull/604:191,Modifiability,refactor,refactoring,191,"This is the first iteration on the Cromwell-backend LCM design and implementation. The idea is to start commenting on this in order to get a final initial version to start the implementation/refactoring of different backends. Please, DO NOT MERGE.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/604
https://github.com/broadinstitute/cromwell/pull/605:102,Deployability,Update,Update,102,- [x] Needs https://github.com/broadinstitute/wdl4s/pull/19 merged to compile; - [x] Changelog; - [x] Update WDL SPEC. ~~Add documentation~~ Documentation is in WDL SPEC. Also https://github.com/broadinstitute/wdl/pull/32,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/605
https://github.com/broadinstitute/cromwell/issues/606:103,Safety,abort,abort,103,"Currently, we are storing a relatively not-so-useful state data in the WMA. It is only used in case of abort to get the WA corresponding to the abortable workflow ID. The current scheme of things can be replaced by a relatively simple actor selection method for abort, which may have varied opinions amongst developers but I believe it provides a more bang for buck.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/606
https://github.com/broadinstitute/cromwell/issues/606:144,Safety,abort,abortable,144,"Currently, we are storing a relatively not-so-useful state data in the WMA. It is only used in case of abort to get the WA corresponding to the abortable workflow ID. The current scheme of things can be replaced by a relatively simple actor selection method for abort, which may have varied opinions amongst developers but I believe it provides a more bang for buck.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/606
https://github.com/broadinstitute/cromwell/issues/606:262,Safety,abort,abort,262,"Currently, we are storing a relatively not-so-useful state data in the WMA. It is only used in case of abort to get the WA corresponding to the abortable workflow ID. The current scheme of things can be replaced by a relatively simple actor selection method for abort, which may have varied opinions amongst developers but I believe it provides a more bang for buck.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/606
https://github.com/broadinstitute/cromwell/issues/606:228,Usability,simpl,simple,228,"Currently, we are storing a relatively not-so-useful state data in the WMA. It is only used in case of abort to get the WA corresponding to the abortable workflow ID. The current scheme of things can be replaced by a relatively simple actor selection method for abort, which may have varied opinions amongst developers but I believe it provides a more bang for buck.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/606
https://github.com/broadinstitute/cromwell/issues/608:79,Deployability,release,release,79,Releasing lenthall; This should be done if Lenthall has changed since the last release. Releasing wdl4s; This should be done if wdl4s has changed since the last release. Releasing wdltool; This should be done if either lenthall or wdl4s has changed since the last release. Further details:https://broadinstitute.atlassian.net/wiki/display/DSDEEPB/Cromwell+Release,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/608
https://github.com/broadinstitute/cromwell/issues/608:161,Deployability,release,release,161,Releasing lenthall; This should be done if Lenthall has changed since the last release. Releasing wdl4s; This should be done if wdl4s has changed since the last release. Releasing wdltool; This should be done if either lenthall or wdl4s has changed since the last release. Further details:https://broadinstitute.atlassian.net/wiki/display/DSDEEPB/Cromwell+Release,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/608
https://github.com/broadinstitute/cromwell/issues/608:264,Deployability,release,release,264,Releasing lenthall; This should be done if Lenthall has changed since the last release. Releasing wdl4s; This should be done if wdl4s has changed since the last release. Releasing wdltool; This should be done if either lenthall or wdl4s has changed since the last release. Further details:https://broadinstitute.atlassian.net/wiki/display/DSDEEPB/Cromwell+Release,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/608
https://github.com/broadinstitute/cromwell/issues/608:356,Deployability,Release,Release,356,Releasing lenthall; This should be done if Lenthall has changed since the last release. Releasing wdl4s; This should be done if wdl4s has changed since the last release. Releasing wdltool; This should be done if either lenthall or wdl4s has changed since the last release. Further details:https://broadinstitute.atlassian.net/wiki/display/DSDEEPB/Cromwell+Release,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/608
https://github.com/broadinstitute/cromwell/issues/609:7,Deployability,Release,Release,7,"Create Release candidate branch (Please keep in mind the various issues marked ""Blocks Release"" as the plan is to include those changes in the next release.). Verifying Release Branch. https://broadinstitute.atlassian.net/wiki/display/DSDEEPB/Cromwell+Release",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/609
https://github.com/broadinstitute/cromwell/issues/609:87,Deployability,Release,Release,87,"Create Release candidate branch (Please keep in mind the various issues marked ""Blocks Release"" as the plan is to include those changes in the next release.). Verifying Release Branch. https://broadinstitute.atlassian.net/wiki/display/DSDEEPB/Cromwell+Release",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/609
https://github.com/broadinstitute/cromwell/issues/609:148,Deployability,release,release,148,"Create Release candidate branch (Please keep in mind the various issues marked ""Blocks Release"" as the plan is to include those changes in the next release.). Verifying Release Branch. https://broadinstitute.atlassian.net/wiki/display/DSDEEPB/Cromwell+Release",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/609
https://github.com/broadinstitute/cromwell/issues/609:169,Deployability,Release,Release,169,"Create Release candidate branch (Please keep in mind the various issues marked ""Blocks Release"" as the plan is to include those changes in the next release.). Verifying Release Branch. https://broadinstitute.atlassian.net/wiki/display/DSDEEPB/Cromwell+Release",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/609
https://github.com/broadinstitute/cromwell/issues/609:252,Deployability,Release,Release,252,"Create Release candidate branch (Please keep in mind the various issues marked ""Blocks Release"" as the plan is to include those changes in the next release.). Verifying Release Branch. https://broadinstitute.atlassian.net/wiki/display/DSDEEPB/Cromwell+Release",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/609
https://github.com/broadinstitute/cromwell/issues/610:17,Deployability,release,release,17,Create new JAR / release notes; Update Cromwell Version in Homebrew. More details: https://broadinstitute.atlassian.net/wiki/display/DSDEEPB/Cromwell+Release,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/610
https://github.com/broadinstitute/cromwell/issues/610:32,Deployability,Update,Update,32,Create new JAR / release notes; Update Cromwell Version in Homebrew. More details: https://broadinstitute.atlassian.net/wiki/display/DSDEEPB/Cromwell+Release,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/610
https://github.com/broadinstitute/cromwell/issues/610:150,Deployability,Release,Release,150,Create new JAR / release notes; Update Cromwell Version in Homebrew. More details: https://broadinstitute.atlassian.net/wiki/display/DSDEEPB/Cromwell+Release,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/610
https://github.com/broadinstitute/cromwell/pull/612:53,Usability,simpl,simple,53,"Jose ran into this issue, I investigated and found a simple fix for some of the issues. This does not solve all issues around using `write_` functions (see https://github.com/broadinstitute/wdl4s/issues/20)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/612
https://github.com/broadinstitute/cromwell/issues/615:567,Availability,Avail,Avail,567,"I'm trying to run a WDL that examines disk sizes using `df -kh`. Unfortunately, read_object is not able to parse the output which appears to match the spec:; The WDL:. ```; task df_kh {; Int bootDiskSizeGb; command { df -kh / }; runtime {; docker: ""ubuntu:latest""; bootDiskSizeGb: bootDiskSizeGb; }; output {; Int size = read_object(stdout()).Size[0]; }; }. workflow someBootDisks {; call df_kh as smallBootDisk { input: bootDiskSizeGb = 10 }; call df_kh as bigBootDisk { input: bootDiskSizeGb = 50 }; }; ```. The console output (example):. ```; Filesystem Size Used Avail Use% Mounted on; /dev/disk1 465G 70G 396G 15% /; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/615
https://github.com/broadinstitute/cromwell/pull/627:362,Deployability,configurat,configuration,362,"Warning: kind of a trainwreck. This PR is aimed in the general direction of #580 but ""closes"" might be too strong a term for this. . This has a DO NOT MERGE on it since it definitely shouldn't go into 0.19, and maybe also for the trainwreck comment above. Naughty list:; - Might break GCS with Local and SGE backends; - Doesn't cleanly deal with filesystems, so configuration is currently duplicated among backends. Blech. Nice list:; - Does get the config closer to what it should look like for PBEs.; - Might be able to plug in a backend type that isn't compiled in. Maybe.; - Might be able to do sneaky things like have the LocalBackend specified twice with two different names to test call-granular backends. Again, maybe.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/627
https://github.com/broadinstitute/cromwell/pull/627:362,Modifiability,config,configuration,362,"Warning: kind of a trainwreck. This PR is aimed in the general direction of #580 but ""closes"" might be too strong a term for this. . This has a DO NOT MERGE on it since it definitely shouldn't go into 0.19, and maybe also for the trainwreck comment above. Naughty list:; - Might break GCS with Local and SGE backends; - Doesn't cleanly deal with filesystems, so configuration is currently duplicated among backends. Blech. Nice list:; - Does get the config closer to what it should look like for PBEs.; - Might be able to plug in a backend type that isn't compiled in. Maybe.; - Might be able to do sneaky things like have the LocalBackend specified twice with two different names to test call-granular backends. Again, maybe.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/627
https://github.com/broadinstitute/cromwell/pull/627:450,Modifiability,config,config,450,"Warning: kind of a trainwreck. This PR is aimed in the general direction of #580 but ""closes"" might be too strong a term for this. . This has a DO NOT MERGE on it since it definitely shouldn't go into 0.19, and maybe also for the trainwreck comment above. Naughty list:; - Might break GCS with Local and SGE backends; - Doesn't cleanly deal with filesystems, so configuration is currently duplicated among backends. Blech. Nice list:; - Does get the config closer to what it should look like for PBEs.; - Might be able to plug in a backend type that isn't compiled in. Maybe.; - Might be able to do sneaky things like have the LocalBackend specified twice with two different names to test call-granular backends. Again, maybe.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/627
https://github.com/broadinstitute/cromwell/pull/627:684,Testability,test,test,684,"Warning: kind of a trainwreck. This PR is aimed in the general direction of #580 but ""closes"" might be too strong a term for this. . This has a DO NOT MERGE on it since it definitely shouldn't go into 0.19, and maybe also for the trainwreck comment above. Naughty list:; - Might break GCS with Local and SGE backends; - Doesn't cleanly deal with filesystems, so configuration is currently duplicated among backends. Blech. Nice list:; - Does get the config closer to what it should look like for PBEs.; - Might be able to plug in a backend type that isn't compiled in. Maybe.; - Might be able to do sneaky things like have the LocalBackend specified twice with two different names to test call-granular backends. Again, maybe.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/627
https://github.com/broadinstitute/cromwell/issues/649:24,Integrability,depend,depends,24,Create Backend Factory (depends on completion of Backend Configs),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/649
https://github.com/broadinstitute/cromwell/issues/649:57,Modifiability,Config,Configs,57,Create Backend Factory (depends on completion of Backend Configs),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/649
https://github.com/broadinstitute/cromwell/issues/651:0,Integrability,Depend,Depends,0,Depends upon the Stubbed out backends.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/651
https://github.com/broadinstitute/cromwell/issues/651:17,Testability,Stub,Stubbed,17,Depends upon the Stubbed out backends.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/651
https://github.com/broadinstitute/cromwell/issues/654:412,Availability,echo,echo,412,"How to evaluate engine functions in a Pluggable Backends World?. **Acceptance Criteria**:. Use the following WDLs files to test isolated components of engine function implementation:. Read/Write file at a task level when running against the Local Backend:. ```; task t {; Array[String] a = [""a"", ""b"", ""c""]; File x = write_lines(a); String y = read_string(""/foo/bar/some-public-object.txt""); command {; cat ${x}; echo ${y}; }; }. workflow w { call t }; ```. read functions from the task output section when running against the Local Backend:. ```; task t {; command {; echo foo; echo bar; }; output {; Array[String] array = read_lines(stdout()); }; }. workflow w { call t }; ```. **Unanswered Questions**. What do we do when a user wants to call `write_lines` from the workflow level? If multiple filesystems are supported, then it's unclear where this gets written to. Perhaps all of them? If `x` is used by a JES job, then the file _must_ be written to at least GCS. ```; workflow w {; String x = write_lines([""a"", ""b"", ""c""]); }; ```. *\* Decision **; We should make this operation unsupported until we have a concrete use case for it, and likely this will be easier when we have filesystem separated out entirely from backend.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/654
https://github.com/broadinstitute/cromwell/issues/654:568,Availability,echo,echo,568,"How to evaluate engine functions in a Pluggable Backends World?. **Acceptance Criteria**:. Use the following WDLs files to test isolated components of engine function implementation:. Read/Write file at a task level when running against the Local Backend:. ```; task t {; Array[String] a = [""a"", ""b"", ""c""]; File x = write_lines(a); String y = read_string(""/foo/bar/some-public-object.txt""); command {; cat ${x}; echo ${y}; }; }. workflow w { call t }; ```. read functions from the task output section when running against the Local Backend:. ```; task t {; command {; echo foo; echo bar; }; output {; Array[String] array = read_lines(stdout()); }; }. workflow w { call t }; ```. **Unanswered Questions**. What do we do when a user wants to call `write_lines` from the workflow level? If multiple filesystems are supported, then it's unclear where this gets written to. Perhaps all of them? If `x` is used by a JES job, then the file _must_ be written to at least GCS. ```; workflow w {; String x = write_lines([""a"", ""b"", ""c""]); }; ```. *\* Decision **; We should make this operation unsupported until we have a concrete use case for it, and likely this will be easier when we have filesystem separated out entirely from backend.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/654
https://github.com/broadinstitute/cromwell/issues/654:578,Availability,echo,echo,578,"How to evaluate engine functions in a Pluggable Backends World?. **Acceptance Criteria**:. Use the following WDLs files to test isolated components of engine function implementation:. Read/Write file at a task level when running against the Local Backend:. ```; task t {; Array[String] a = [""a"", ""b"", ""c""]; File x = write_lines(a); String y = read_string(""/foo/bar/some-public-object.txt""); command {; cat ${x}; echo ${y}; }; }. workflow w { call t }; ```. read functions from the task output section when running against the Local Backend:. ```; task t {; command {; echo foo; echo bar; }; output {; Array[String] array = read_lines(stdout()); }; }. workflow w { call t }; ```. **Unanswered Questions**. What do we do when a user wants to call `write_lines` from the workflow level? If multiple filesystems are supported, then it's unclear where this gets written to. Perhaps all of them? If `x` is used by a JES job, then the file _must_ be written to at least GCS. ```; workflow w {; String x = write_lines([""a"", ""b"", ""c""]); }; ```. *\* Decision **; We should make this operation unsupported until we have a concrete use case for it, and likely this will be easier when we have filesystem separated out entirely from backend.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/654
https://github.com/broadinstitute/cromwell/issues/654:123,Testability,test,test,123,"How to evaluate engine functions in a Pluggable Backends World?. **Acceptance Criteria**:. Use the following WDLs files to test isolated components of engine function implementation:. Read/Write file at a task level when running against the Local Backend:. ```; task t {; Array[String] a = [""a"", ""b"", ""c""]; File x = write_lines(a); String y = read_string(""/foo/bar/some-public-object.txt""); command {; cat ${x}; echo ${y}; }; }. workflow w { call t }; ```. read functions from the task output section when running against the Local Backend:. ```; task t {; command {; echo foo; echo bar; }; output {; Array[String] array = read_lines(stdout()); }; }. workflow w { call t }; ```. **Unanswered Questions**. What do we do when a user wants to call `write_lines` from the workflow level? If multiple filesystems are supported, then it's unclear where this gets written to. Perhaps all of them? If `x` is used by a JES job, then the file _must_ be written to at least GCS. ```; workflow w {; String x = write_lines([""a"", ""b"", ""c""]); }; ```. *\* Decision **; We should make this operation unsupported until we have a concrete use case for it, and likely this will be easier when we have filesystem separated out entirely from backend.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/654
https://github.com/broadinstitute/cromwell/issues/655:103,Availability,failure,failure,103,The (edit by Chris: ~~Workflow Actor~~ WorkflowExecutionActor) should take action based on the kind of failure returned by the BE and retry if so indicated,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/655
https://github.com/broadinstitute/cromwell/issues/657:119,Availability,recover,recovery,119,"Implement a JES PBE, this ticket covers the basics but should NOT include:; - retry support; - call caching support; - recovery support; - metadata support; - abort support. as these are covered in other tickets with the ""JES PBE""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/657
https://github.com/broadinstitute/cromwell/issues/657:119,Safety,recover,recovery,119,"Implement a JES PBE, this ticket covers the basics but should NOT include:; - retry support; - call caching support; - recovery support; - metadata support; - abort support. as these are covered in other tickets with the ""JES PBE""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/657
https://github.com/broadinstitute/cromwell/issues/657:159,Safety,abort,abort,159,"Implement a JES PBE, this ticket covers the basics but should NOT include:; - retry support; - call caching support; - recovery support; - metadata support; - abort support. as these are covered in other tickets with the ""JES PBE""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/657
https://github.com/broadinstitute/cromwell/pull/678:47,Integrability,depend,dependencies,47,This is not the complete code. I'm waiting for dependencies: ShadowWorkflowActor and BackendConfiguration impl. to finish with it.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/678
https://github.com/broadinstitute/cromwell/issues/679:20,Integrability,rout,route,20,"To exercise the new route of execution using pluggable backends, create a secondary workflow actor (currently with empty behavior).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/679
https://github.com/broadinstitute/cromwell/issues/684:170,Availability,ERROR,ERROR,170,"I restarted Cromwell with one workflow running and one of my tasks failed with this exception: . 2016-04-07 20:32:28,188 cromwell-system-akka.actor.default-dispatcher-20 ERROR - WorkflowActor [UUID(03db4daf)]: Completion work failed for call CollectQualityYieldMetrics:9.; com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException: Duplicate entry '27-PairedEndSingleSampleWorkflow.CollectQualityYieldMetrics-metr' for key 'UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO'. the logs can be found on gotc-staging - 20160407-cromwell.log",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/684
https://github.com/broadinstitute/cromwell/issues/684:500,Testability,log,logs,500,"I restarted Cromwell with one workflow running and one of my tasks failed with this exception: . 2016-04-07 20:32:28,188 cromwell-system-akka.actor.default-dispatcher-20 ERROR - WorkflowActor [UUID(03db4daf)]: Completion work failed for call CollectQualityYieldMetrics:9.; com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException: Duplicate entry '27-PairedEndSingleSampleWorkflow.CollectQualityYieldMetrics-metr' for key 'UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO'. the logs can be found on gotc-staging - 20160407-cromwell.log",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/684
https://github.com/broadinstitute/cromwell/issues/684:554,Testability,log,log,554,"I restarted Cromwell with one workflow running and one of my tasks failed with this exception: . 2016-04-07 20:32:28,188 cromwell-system-akka.actor.default-dispatcher-20 ERROR - WorkflowActor [UUID(03db4daf)]: Completion work failed for call CollectQualityYieldMetrics:9.; com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException: Duplicate entry '27-PairedEndSingleSampleWorkflow.CollectQualityYieldMetrics-metr' for key 'UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO'. the logs can be found on gotc-staging - 20160407-cromwell.log",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/684
https://github.com/broadinstitute/cromwell/issues/685:78,Performance,cache,cached,78,It would be nice to know when upgrading to a new version of Cromwell if calls cached by the previous version are expected to be usable in the new version.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/685
https://github.com/broadinstitute/cromwell/issues/685:128,Usability,usab,usable,128,It would be nice to know when upgrading to a new version of Cromwell if calls cached by the previous version are expected to be usable in the new version.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/685
https://github.com/broadinstitute/cromwell/issues/687:19,Availability,error,error,19,"This wdl throws an error:. ```; scatter (unmapped_bam in flowcell_unmapped_bams) {; String base_name = sub(sub(unmapped_bam, ""gs://.*/"",""""), "".unmapped.bam$"", """"); call CollectQualityYieldMetrics {; input:; input_bam = unmapped_bam,; metrics_filename = base_name + "".unmapped.quality_yield_metrics"",; disk_size = flowcell_small_disk; }; }; ```. ```; ""Workflow has invalid declarations: Invalid parameters for engine function sub: (Failure(java.lang.IllegalArgumentException: Invalid parameters for engine function sub: (Failure(wdl4s.WdlExpressionException: Could not find a value for unmapped_bam),Success(WdlString(gs://.*/)),Success(WdlString())).),Success(WdlString(.unmapped.bam$)),Success(WdlString())).""; ```. But if used inside the task call it is successful:. ```; scatter (unmapped_bam in flowcell_unmapped_bams) {; call CollectQualityYieldMetrics {; input:; input_bam = unmapped_bam,; metrics_filename = sub(sub(unmapped_bam, ""gs://.*/"",""""), "".unmapped.bam$"", """") + "".unmapped.quality_yield_metrics"",; disk_size = flowcell_small_disk; }; }; ```. This just makes it very inconvenient if there are multiple tasks that need the value from the sub function as an input.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/687
https://github.com/broadinstitute/cromwell/issues/687:431,Availability,Failure,Failure,431,"This wdl throws an error:. ```; scatter (unmapped_bam in flowcell_unmapped_bams) {; String base_name = sub(sub(unmapped_bam, ""gs://.*/"",""""), "".unmapped.bam$"", """"); call CollectQualityYieldMetrics {; input:; input_bam = unmapped_bam,; metrics_filename = base_name + "".unmapped.quality_yield_metrics"",; disk_size = flowcell_small_disk; }; }; ```. ```; ""Workflow has invalid declarations: Invalid parameters for engine function sub: (Failure(java.lang.IllegalArgumentException: Invalid parameters for engine function sub: (Failure(wdl4s.WdlExpressionException: Could not find a value for unmapped_bam),Success(WdlString(gs://.*/)),Success(WdlString())).),Success(WdlString(.unmapped.bam$)),Success(WdlString())).""; ```. But if used inside the task call it is successful:. ```; scatter (unmapped_bam in flowcell_unmapped_bams) {; call CollectQualityYieldMetrics {; input:; input_bam = unmapped_bam,; metrics_filename = sub(sub(unmapped_bam, ""gs://.*/"",""""), "".unmapped.bam$"", """") + "".unmapped.quality_yield_metrics"",; disk_size = flowcell_small_disk; }; }; ```. This just makes it very inconvenient if there are multiple tasks that need the value from the sub function as an input.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/687
https://github.com/broadinstitute/cromwell/issues/687:520,Availability,Failure,Failure,520,"This wdl throws an error:. ```; scatter (unmapped_bam in flowcell_unmapped_bams) {; String base_name = sub(sub(unmapped_bam, ""gs://.*/"",""""), "".unmapped.bam$"", """"); call CollectQualityYieldMetrics {; input:; input_bam = unmapped_bam,; metrics_filename = base_name + "".unmapped.quality_yield_metrics"",; disk_size = flowcell_small_disk; }; }; ```. ```; ""Workflow has invalid declarations: Invalid parameters for engine function sub: (Failure(java.lang.IllegalArgumentException: Invalid parameters for engine function sub: (Failure(wdl4s.WdlExpressionException: Could not find a value for unmapped_bam),Success(WdlString(gs://.*/)),Success(WdlString())).),Success(WdlString(.unmapped.bam$)),Success(WdlString())).""; ```. But if used inside the task call it is successful:. ```; scatter (unmapped_bam in flowcell_unmapped_bams) {; call CollectQualityYieldMetrics {; input:; input_bam = unmapped_bam,; metrics_filename = sub(sub(unmapped_bam, ""gs://.*/"",""""), "".unmapped.bam$"", """") + "".unmapped.quality_yield_metrics"",; disk_size = flowcell_small_disk; }; }; ```. This just makes it very inconvenient if there are multiple tasks that need the value from the sub function as an input.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/687
https://github.com/broadinstitute/cromwell/pull/690:97,Testability,test,test,97,"Extracted the retries out of SlickDataAccess.; Having trouble producing a true positive deadlock test that this code fixes, so left that out and moving on for now.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/690
https://github.com/broadinstitute/cromwell/issues/691:460,Availability,avail,availability,460,"From Henry --. My comment is a little different than the commenter above. So I will try to provide some context in order to differentiate. If one looks at Cromwell as being part of a larger application infrastructure/service such as a Genomics Pipeline where sequenced data is constantly being processed through the system or providing a service where users on the Internet can launch workflows ""as a Service"" - whenever they way. In these systems, uptime and availability are critical - at all times. Below are several scenarios where I could see running multiple Cromwells would be very beneficial. High availability:; Having multiple Cromwells running where jobs are ""load balanced"" between them would allow us to continue operate when there are systems issues or failures with one of the Cromwell instances. Zero-downtime deployments:; Supporting multiple Cromwells running different versions of the code, could provide the ability to upgrade Cromwell with little or no user impact. Essentially the new version is deployed to a new server, it is started up and at an appropriate time traffic (via a load balancer or proxy maybe) is directed away from the ""old version"" Cromwell to the new. Similar to item 2: being able to introduce infrastructure changes (host OS, security patches, host resizing,..) more seamlessly:; If I can support multiple instances of Cromwell, I can build a new instance of the host with all the updates and changes I require - deploy cromwell to the new node and cut over. A corollary to this request is also the ability to ""move"" workflows from one Cromwell instance to another. Maybe this is just workflows not in flight or active - but waiting to run. This capability could make it easier to retire older cromwell instances (once multiple cromwell instances support is in place). Some workflows may take days to run, being able to ""relocate"" these workflows to the ""new"" cromwell - allows us to decommission ""old"" cromwells faster.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/691
https://github.com/broadinstitute/cromwell/issues/691:606,Availability,avail,availability,606,"From Henry --. My comment is a little different than the commenter above. So I will try to provide some context in order to differentiate. If one looks at Cromwell as being part of a larger application infrastructure/service such as a Genomics Pipeline where sequenced data is constantly being processed through the system or providing a service where users on the Internet can launch workflows ""as a Service"" - whenever they way. In these systems, uptime and availability are critical - at all times. Below are several scenarios where I could see running multiple Cromwells would be very beneficial. High availability:; Having multiple Cromwells running where jobs are ""load balanced"" between them would allow us to continue operate when there are systems issues or failures with one of the Cromwell instances. Zero-downtime deployments:; Supporting multiple Cromwells running different versions of the code, could provide the ability to upgrade Cromwell with little or no user impact. Essentially the new version is deployed to a new server, it is started up and at an appropriate time traffic (via a load balancer or proxy maybe) is directed away from the ""old version"" Cromwell to the new. Similar to item 2: being able to introduce infrastructure changes (host OS, security patches, host resizing,..) more seamlessly:; If I can support multiple instances of Cromwell, I can build a new instance of the host with all the updates and changes I require - deploy cromwell to the new node and cut over. A corollary to this request is also the ability to ""move"" workflows from one Cromwell instance to another. Maybe this is just workflows not in flight or active - but waiting to run. This capability could make it easier to retire older cromwell instances (once multiple cromwell instances support is in place). Some workflows may take days to run, being able to ""relocate"" these workflows to the ""new"" cromwell - allows us to decommission ""old"" cromwells faster.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/691
https://github.com/broadinstitute/cromwell/issues/691:767,Availability,failure,failures,767,"From Henry --. My comment is a little different than the commenter above. So I will try to provide some context in order to differentiate. If one looks at Cromwell as being part of a larger application infrastructure/service such as a Genomics Pipeline where sequenced data is constantly being processed through the system or providing a service where users on the Internet can launch workflows ""as a Service"" - whenever they way. In these systems, uptime and availability are critical - at all times. Below are several scenarios where I could see running multiple Cromwells would be very beneficial. High availability:; Having multiple Cromwells running where jobs are ""load balanced"" between them would allow us to continue operate when there are systems issues or failures with one of the Cromwell instances. Zero-downtime deployments:; Supporting multiple Cromwells running different versions of the code, could provide the ability to upgrade Cromwell with little or no user impact. Essentially the new version is deployed to a new server, it is started up and at an appropriate time traffic (via a load balancer or proxy maybe) is directed away from the ""old version"" Cromwell to the new. Similar to item 2: being able to introduce infrastructure changes (host OS, security patches, host resizing,..) more seamlessly:; If I can support multiple instances of Cromwell, I can build a new instance of the host with all the updates and changes I require - deploy cromwell to the new node and cut over. A corollary to this request is also the ability to ""move"" workflows from one Cromwell instance to another. Maybe this is just workflows not in flight or active - but waiting to run. This capability could make it easier to retire older cromwell instances (once multiple cromwell instances support is in place). Some workflows may take days to run, being able to ""relocate"" these workflows to the ""new"" cromwell - allows us to decommission ""old"" cromwells faster.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/691
https://github.com/broadinstitute/cromwell/issues/691:817,Availability,downtime,downtime,817,"From Henry --. My comment is a little different than the commenter above. So I will try to provide some context in order to differentiate. If one looks at Cromwell as being part of a larger application infrastructure/service such as a Genomics Pipeline where sequenced data is constantly being processed through the system or providing a service where users on the Internet can launch workflows ""as a Service"" - whenever they way. In these systems, uptime and availability are critical - at all times. Below are several scenarios where I could see running multiple Cromwells would be very beneficial. High availability:; Having multiple Cromwells running where jobs are ""load balanced"" between them would allow us to continue operate when there are systems issues or failures with one of the Cromwell instances. Zero-downtime deployments:; Supporting multiple Cromwells running different versions of the code, could provide the ability to upgrade Cromwell with little or no user impact. Essentially the new version is deployed to a new server, it is started up and at an appropriate time traffic (via a load balancer or proxy maybe) is directed away from the ""old version"" Cromwell to the new. Similar to item 2: being able to introduce infrastructure changes (host OS, security patches, host resizing,..) more seamlessly:; If I can support multiple instances of Cromwell, I can build a new instance of the host with all the updates and changes I require - deploy cromwell to the new node and cut over. A corollary to this request is also the ability to ""move"" workflows from one Cromwell instance to another. Maybe this is just workflows not in flight or active - but waiting to run. This capability could make it easier to retire older cromwell instances (once multiple cromwell instances support is in place). Some workflows may take days to run, being able to ""relocate"" these workflows to the ""new"" cromwell - allows us to decommission ""old"" cromwells faster.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/691
https://github.com/broadinstitute/cromwell/issues/691:244,Deployability,Pipeline,Pipeline,244,"From Henry --. My comment is a little different than the commenter above. So I will try to provide some context in order to differentiate. If one looks at Cromwell as being part of a larger application infrastructure/service such as a Genomics Pipeline where sequenced data is constantly being processed through the system or providing a service where users on the Internet can launch workflows ""as a Service"" - whenever they way. In these systems, uptime and availability are critical - at all times. Below are several scenarios where I could see running multiple Cromwells would be very beneficial. High availability:; Having multiple Cromwells running where jobs are ""load balanced"" between them would allow us to continue operate when there are systems issues or failures with one of the Cromwell instances. Zero-downtime deployments:; Supporting multiple Cromwells running different versions of the code, could provide the ability to upgrade Cromwell with little or no user impact. Essentially the new version is deployed to a new server, it is started up and at an appropriate time traffic (via a load balancer or proxy maybe) is directed away from the ""old version"" Cromwell to the new. Similar to item 2: being able to introduce infrastructure changes (host OS, security patches, host resizing,..) more seamlessly:; If I can support multiple instances of Cromwell, I can build a new instance of the host with all the updates and changes I require - deploy cromwell to the new node and cut over. A corollary to this request is also the ability to ""move"" workflows from one Cromwell instance to another. Maybe this is just workflows not in flight or active - but waiting to run. This capability could make it easier to retire older cromwell instances (once multiple cromwell instances support is in place). Some workflows may take days to run, being able to ""relocate"" these workflows to the ""new"" cromwell - allows us to decommission ""old"" cromwells faster.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/691
https://github.com/broadinstitute/cromwell/issues/691:826,Deployability,deploy,deployments,826,"From Henry --. My comment is a little different than the commenter above. So I will try to provide some context in order to differentiate. If one looks at Cromwell as being part of a larger application infrastructure/service such as a Genomics Pipeline where sequenced data is constantly being processed through the system or providing a service where users on the Internet can launch workflows ""as a Service"" - whenever they way. In these systems, uptime and availability are critical - at all times. Below are several scenarios where I could see running multiple Cromwells would be very beneficial. High availability:; Having multiple Cromwells running where jobs are ""load balanced"" between them would allow us to continue operate when there are systems issues or failures with one of the Cromwell instances. Zero-downtime deployments:; Supporting multiple Cromwells running different versions of the code, could provide the ability to upgrade Cromwell with little or no user impact. Essentially the new version is deployed to a new server, it is started up and at an appropriate time traffic (via a load balancer or proxy maybe) is directed away from the ""old version"" Cromwell to the new. Similar to item 2: being able to introduce infrastructure changes (host OS, security patches, host resizing,..) more seamlessly:; If I can support multiple instances of Cromwell, I can build a new instance of the host with all the updates and changes I require - deploy cromwell to the new node and cut over. A corollary to this request is also the ability to ""move"" workflows from one Cromwell instance to another. Maybe this is just workflows not in flight or active - but waiting to run. This capability could make it easier to retire older cromwell instances (once multiple cromwell instances support is in place). Some workflows may take days to run, being able to ""relocate"" these workflows to the ""new"" cromwell - allows us to decommission ""old"" cromwells faster.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/691
https://github.com/broadinstitute/cromwell/issues/691:939,Deployability,upgrade,upgrade,939,"From Henry --. My comment is a little different than the commenter above. So I will try to provide some context in order to differentiate. If one looks at Cromwell as being part of a larger application infrastructure/service such as a Genomics Pipeline where sequenced data is constantly being processed through the system or providing a service where users on the Internet can launch workflows ""as a Service"" - whenever they way. In these systems, uptime and availability are critical - at all times. Below are several scenarios where I could see running multiple Cromwells would be very beneficial. High availability:; Having multiple Cromwells running where jobs are ""load balanced"" between them would allow us to continue operate when there are systems issues or failures with one of the Cromwell instances. Zero-downtime deployments:; Supporting multiple Cromwells running different versions of the code, could provide the ability to upgrade Cromwell with little or no user impact. Essentially the new version is deployed to a new server, it is started up and at an appropriate time traffic (via a load balancer or proxy maybe) is directed away from the ""old version"" Cromwell to the new. Similar to item 2: being able to introduce infrastructure changes (host OS, security patches, host resizing,..) more seamlessly:; If I can support multiple instances of Cromwell, I can build a new instance of the host with all the updates and changes I require - deploy cromwell to the new node and cut over. A corollary to this request is also the ability to ""move"" workflows from one Cromwell instance to another. Maybe this is just workflows not in flight or active - but waiting to run. This capability could make it easier to retire older cromwell instances (once multiple cromwell instances support is in place). Some workflows may take days to run, being able to ""relocate"" these workflows to the ""new"" cromwell - allows us to decommission ""old"" cromwells faster.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/691
https://github.com/broadinstitute/cromwell/issues/691:1018,Deployability,deploy,deployed,1018,"From Henry --. My comment is a little different than the commenter above. So I will try to provide some context in order to differentiate. If one looks at Cromwell as being part of a larger application infrastructure/service such as a Genomics Pipeline where sequenced data is constantly being processed through the system or providing a service where users on the Internet can launch workflows ""as a Service"" - whenever they way. In these systems, uptime and availability are critical - at all times. Below are several scenarios where I could see running multiple Cromwells would be very beneficial. High availability:; Having multiple Cromwells running where jobs are ""load balanced"" between them would allow us to continue operate when there are systems issues or failures with one of the Cromwell instances. Zero-downtime deployments:; Supporting multiple Cromwells running different versions of the code, could provide the ability to upgrade Cromwell with little or no user impact. Essentially the new version is deployed to a new server, it is started up and at an appropriate time traffic (via a load balancer or proxy maybe) is directed away from the ""old version"" Cromwell to the new. Similar to item 2: being able to introduce infrastructure changes (host OS, security patches, host resizing,..) more seamlessly:; If I can support multiple instances of Cromwell, I can build a new instance of the host with all the updates and changes I require - deploy cromwell to the new node and cut over. A corollary to this request is also the ability to ""move"" workflows from one Cromwell instance to another. Maybe this is just workflows not in flight or active - but waiting to run. This capability could make it easier to retire older cromwell instances (once multiple cromwell instances support is in place). Some workflows may take days to run, being able to ""relocate"" these workflows to the ""new"" cromwell - allows us to decommission ""old"" cromwells faster.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/691
https://github.com/broadinstitute/cromwell/issues/691:1279,Deployability,patch,patches,1279,"From Henry --. My comment is a little different than the commenter above. So I will try to provide some context in order to differentiate. If one looks at Cromwell as being part of a larger application infrastructure/service such as a Genomics Pipeline where sequenced data is constantly being processed through the system or providing a service where users on the Internet can launch workflows ""as a Service"" - whenever they way. In these systems, uptime and availability are critical - at all times. Below are several scenarios where I could see running multiple Cromwells would be very beneficial. High availability:; Having multiple Cromwells running where jobs are ""load balanced"" between them would allow us to continue operate when there are systems issues or failures with one of the Cromwell instances. Zero-downtime deployments:; Supporting multiple Cromwells running different versions of the code, could provide the ability to upgrade Cromwell with little or no user impact. Essentially the new version is deployed to a new server, it is started up and at an appropriate time traffic (via a load balancer or proxy maybe) is directed away from the ""old version"" Cromwell to the new. Similar to item 2: being able to introduce infrastructure changes (host OS, security patches, host resizing,..) more seamlessly:; If I can support multiple instances of Cromwell, I can build a new instance of the host with all the updates and changes I require - deploy cromwell to the new node and cut over. A corollary to this request is also the ability to ""move"" workflows from one Cromwell instance to another. Maybe this is just workflows not in flight or active - but waiting to run. This capability could make it easier to retire older cromwell instances (once multiple cromwell instances support is in place). Some workflows may take days to run, being able to ""relocate"" these workflows to the ""new"" cromwell - allows us to decommission ""old"" cromwells faster.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/691
https://github.com/broadinstitute/cromwell/issues/691:1425,Deployability,update,updates,1425,"From Henry --. My comment is a little different than the commenter above. So I will try to provide some context in order to differentiate. If one looks at Cromwell as being part of a larger application infrastructure/service such as a Genomics Pipeline where sequenced data is constantly being processed through the system or providing a service where users on the Internet can launch workflows ""as a Service"" - whenever they way. In these systems, uptime and availability are critical - at all times. Below are several scenarios where I could see running multiple Cromwells would be very beneficial. High availability:; Having multiple Cromwells running where jobs are ""load balanced"" between them would allow us to continue operate when there are systems issues or failures with one of the Cromwell instances. Zero-downtime deployments:; Supporting multiple Cromwells running different versions of the code, could provide the ability to upgrade Cromwell with little or no user impact. Essentially the new version is deployed to a new server, it is started up and at an appropriate time traffic (via a load balancer or proxy maybe) is directed away from the ""old version"" Cromwell to the new. Similar to item 2: being able to introduce infrastructure changes (host OS, security patches, host resizing,..) more seamlessly:; If I can support multiple instances of Cromwell, I can build a new instance of the host with all the updates and changes I require - deploy cromwell to the new node and cut over. A corollary to this request is also the ability to ""move"" workflows from one Cromwell instance to another. Maybe this is just workflows not in flight or active - but waiting to run. This capability could make it easier to retire older cromwell instances (once multiple cromwell instances support is in place). Some workflows may take days to run, being able to ""relocate"" these workflows to the ""new"" cromwell - allows us to decommission ""old"" cromwells faster.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/691
https://github.com/broadinstitute/cromwell/issues/691:1457,Deployability,deploy,deploy,1457,"From Henry --. My comment is a little different than the commenter above. So I will try to provide some context in order to differentiate. If one looks at Cromwell as being part of a larger application infrastructure/service such as a Genomics Pipeline where sequenced data is constantly being processed through the system or providing a service where users on the Internet can launch workflows ""as a Service"" - whenever they way. In these systems, uptime and availability are critical - at all times. Below are several scenarios where I could see running multiple Cromwells would be very beneficial. High availability:; Having multiple Cromwells running where jobs are ""load balanced"" between them would allow us to continue operate when there are systems issues or failures with one of the Cromwell instances. Zero-downtime deployments:; Supporting multiple Cromwells running different versions of the code, could provide the ability to upgrade Cromwell with little or no user impact. Essentially the new version is deployed to a new server, it is started up and at an appropriate time traffic (via a load balancer or proxy maybe) is directed away from the ""old version"" Cromwell to the new. Similar to item 2: being able to introduce infrastructure changes (host OS, security patches, host resizing,..) more seamlessly:; If I can support multiple instances of Cromwell, I can build a new instance of the host with all the updates and changes I require - deploy cromwell to the new node and cut over. A corollary to this request is also the ability to ""move"" workflows from one Cromwell instance to another. Maybe this is just workflows not in flight or active - but waiting to run. This capability could make it easier to retire older cromwell instances (once multiple cromwell instances support is in place). Some workflows may take days to run, being able to ""relocate"" these workflows to the ""new"" cromwell - allows us to decommission ""old"" cromwells faster.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/691
https://github.com/broadinstitute/cromwell/issues/691:671,Performance,load,load,671,"From Henry --. My comment is a little different than the commenter above. So I will try to provide some context in order to differentiate. If one looks at Cromwell as being part of a larger application infrastructure/service such as a Genomics Pipeline where sequenced data is constantly being processed through the system or providing a service where users on the Internet can launch workflows ""as a Service"" - whenever they way. In these systems, uptime and availability are critical - at all times. Below are several scenarios where I could see running multiple Cromwells would be very beneficial. High availability:; Having multiple Cromwells running where jobs are ""load balanced"" between them would allow us to continue operate when there are systems issues or failures with one of the Cromwell instances. Zero-downtime deployments:; Supporting multiple Cromwells running different versions of the code, could provide the ability to upgrade Cromwell with little or no user impact. Essentially the new version is deployed to a new server, it is started up and at an appropriate time traffic (via a load balancer or proxy maybe) is directed away from the ""old version"" Cromwell to the new. Similar to item 2: being able to introduce infrastructure changes (host OS, security patches, host resizing,..) more seamlessly:; If I can support multiple instances of Cromwell, I can build a new instance of the host with all the updates and changes I require - deploy cromwell to the new node and cut over. A corollary to this request is also the ability to ""move"" workflows from one Cromwell instance to another. Maybe this is just workflows not in flight or active - but waiting to run. This capability could make it easier to retire older cromwell instances (once multiple cromwell instances support is in place). Some workflows may take days to run, being able to ""relocate"" these workflows to the ""new"" cromwell - allows us to decommission ""old"" cromwells faster.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/691
https://github.com/broadinstitute/cromwell/issues/691:1103,Performance,load,load,1103,"From Henry --. My comment is a little different than the commenter above. So I will try to provide some context in order to differentiate. If one looks at Cromwell as being part of a larger application infrastructure/service such as a Genomics Pipeline where sequenced data is constantly being processed through the system or providing a service where users on the Internet can launch workflows ""as a Service"" - whenever they way. In these systems, uptime and availability are critical - at all times. Below are several scenarios where I could see running multiple Cromwells would be very beneficial. High availability:; Having multiple Cromwells running where jobs are ""load balanced"" between them would allow us to continue operate when there are systems issues or failures with one of the Cromwell instances. Zero-downtime deployments:; Supporting multiple Cromwells running different versions of the code, could provide the ability to upgrade Cromwell with little or no user impact. Essentially the new version is deployed to a new server, it is started up and at an appropriate time traffic (via a load balancer or proxy maybe) is directed away from the ""old version"" Cromwell to the new. Similar to item 2: being able to introduce infrastructure changes (host OS, security patches, host resizing,..) more seamlessly:; If I can support multiple instances of Cromwell, I can build a new instance of the host with all the updates and changes I require - deploy cromwell to the new node and cut over. A corollary to this request is also the ability to ""move"" workflows from one Cromwell instance to another. Maybe this is just workflows not in flight or active - but waiting to run. This capability could make it easier to retire older cromwell instances (once multiple cromwell instances support is in place). Some workflows may take days to run, being able to ""relocate"" these workflows to the ""new"" cromwell - allows us to decommission ""old"" cromwells faster.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/691
https://github.com/broadinstitute/cromwell/issues/691:1270,Security,secur,security,1270,"From Henry --. My comment is a little different than the commenter above. So I will try to provide some context in order to differentiate. If one looks at Cromwell as being part of a larger application infrastructure/service such as a Genomics Pipeline where sequenced data is constantly being processed through the system or providing a service where users on the Internet can launch workflows ""as a Service"" - whenever they way. In these systems, uptime and availability are critical - at all times. Below are several scenarios where I could see running multiple Cromwells would be very beneficial. High availability:; Having multiple Cromwells running where jobs are ""load balanced"" between them would allow us to continue operate when there are systems issues or failures with one of the Cromwell instances. Zero-downtime deployments:; Supporting multiple Cromwells running different versions of the code, could provide the ability to upgrade Cromwell with little or no user impact. Essentially the new version is deployed to a new server, it is started up and at an appropriate time traffic (via a load balancer or proxy maybe) is directed away from the ""old version"" Cromwell to the new. Similar to item 2: being able to introduce infrastructure changes (host OS, security patches, host resizing,..) more seamlessly:; If I can support multiple instances of Cromwell, I can build a new instance of the host with all the updates and changes I require - deploy cromwell to the new node and cut over. A corollary to this request is also the ability to ""move"" workflows from one Cromwell instance to another. Maybe this is just workflows not in flight or active - but waiting to run. This capability could make it easier to retire older cromwell instances (once multiple cromwell instances support is in place). Some workflows may take days to run, being able to ""relocate"" these workflows to the ""new"" cromwell - allows us to decommission ""old"" cromwells faster.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/691
https://github.com/broadinstitute/cromwell/pull/694:213,Testability,test,tests,213,"`FinalCallJobDescriptor`, `JobDescriptor`, and `BackendCallJobDescriptors` merged into one.; BIG TODO: Final calls ""run"" on the local backend via a `FinalCallCopyHack` that runs them in process.; Moved final call tests from `WorkflowDescriptorSpec` to `FinalCallSpec`. Creating a pull request to review current changes, while discussing best ways to execute copies out of process.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/694
https://github.com/broadinstitute/cromwell/issues/695:3054,Availability,ERROR,ERROR,3054,"yping/606107ba-fb48-489f-8d14-e19192331b82/call-SplitGvcf/shard-1/glob-a859a146d6b8e5fd268a04d997240e7e/NWD123256.a69a5041-cdcc-4c7d-82e4-47f3d422c441.0001.g.vcf.gz.tbi"", ""gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/606107ba-fb48-489f-8d14-e19192331b82/call-SplitGvcf/shard-2/glob-a859a146d6b8e5fd268a04d997240e7e/NWD145410.61ccb202-d666-4fad-ba17-351fabd79cd1.0001.g.vcf.gz.tbi""]`. **Start of the logs**. 2016-04-11 22:41:00,479 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: persisting status of TileDBCombineGVCF:1048 to Starting.; 2016-04-11 22:41:00,479 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,490 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,521 cromwell-system-akka.actor.default-dispatcher-2683 ERROR - WorkflowActor [UUID(606107ba)]: Failed to fetch locally qualified inputs for call TileDBCombineGVCF:1048; wdl4s.WdlExpressionException: Failed to find index Success(WdlInteger(1048)) on array:. **and the following stacktrace associated with these:**. 1048; at wdl4s.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:112) ~[cromwell.jar:0.19]; at wdl4s.WdlExpression$.evaluate(WdlExpression.scala:79) ~[cromwell.jar:0.19]; at wdl4s.WdlExpression.evaluate(WdlExpression.scala:192) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$fetchLocallyQualifiedInputs$1$$anonfun$apply$16.apply(WorkflowActor.scala:987) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$fetchLocallyQualifiedInputs$1$$anonfun$apply$16.apply(WorkflowActor.scala:982) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collecti",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:9736,Availability,error,error,9736,"kjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-04-11 22:41:00,528 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,543 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,556 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,617 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,841 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,912 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardInterpolator(StringContext.scala:128); at scala.StringContext.s(StringContext.scala:95); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:885); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:881); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieM",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:9816,Availability,down,down,9816,".ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-04-11 22:41:00,528 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,543 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,556 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,617 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,841 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,912 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardInterpolator(StringContext.scala:128); at scala.StringContext.s(StringContext.scala:95); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:885); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:881); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:9855,Availability,error,error,9855,"well.jar:0.19]; 2016-04-11 22:41:00,528 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,543 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,556 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,617 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,841 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,912 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardInterpolator(StringContext.scala:128); at scala.StringContext.s(StringContext.scala:95); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:885); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:881); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreac",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:12482,Availability,ERROR,ERROR,12482,"each(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:881); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActor.processEvent(WorkflowActor.scala:236); at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:598); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:592); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.WorkflowActor.aroundReceive(WorkflowActor.scala:236); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke_aroundBody0(ActorCell.scala:487); at akka.actor.ActorCell$AjcClosure1.run(ActorCell.scala:1); at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149); at akka.kamon.instrumentation.ActorCellInstrumentation$$anonfun$aroundBehaviourInvoke$1.apply(ActorCellInstrumentation.scala:63); 2016-04-11 22:41:17,520 cromwell-system-akka.actor.default-dispatcher-2661 ERROR - Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:12499,Availability,error,error,12499,"each(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:881); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActor.processEvent(WorkflowActor.scala:236); at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:598); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:592); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.WorkflowActor.aroundReceive(WorkflowActor.scala:236); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke_aroundBody0(ActorCell.scala:487); at akka.actor.ActorCell$AjcClosure1.run(ActorCell.scala:1); at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149); at akka.kamon.instrumentation.ActorCellInstrumentation$$anonfun$aroundBehaviourInvoke$1.apply(ActorCellInstrumentation.scala:63); 2016-04-11 22:41:17,520 cromwell-system-akka.actor.default-dispatcher-2661 ERROR - Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:12579,Availability,down,down,12579,"each(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:881); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActor.processEvent(WorkflowActor.scala:236); at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:598); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:592); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.WorkflowActor.aroundReceive(WorkflowActor.scala:236); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke_aroundBody0(ActorCell.scala:487); at akka.actor.ActorCell$AjcClosure1.run(ActorCell.scala:1); at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149); at akka.kamon.instrumentation.ActorCellInstrumentation$$anonfun$aroundBehaviourInvoke$1.apply(ActorCellInstrumentation.scala:63); 2016-04-11 22:41:17,520 cromwell-system-akka.actor.default-dispatcher-2661 ERROR - Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:12618,Availability,error,error,12618,"each(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:881); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActor.processEvent(WorkflowActor.scala:236); at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:598); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:592); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.WorkflowActor.aroundReceive(WorkflowActor.scala:236); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke_aroundBody0(ActorCell.scala:487); at akka.actor.ActorCell$AjcClosure1.run(ActorCell.scala:1); at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149); at akka.kamon.instrumentation.ActorCellInstrumentation$$anonfun$aroundBehaviourInvoke$1.apply(ActorCellInstrumentation.scala:63); 2016-04-11 22:41:17,520 cromwell-system-akka.actor.default-dispatcher-2661 ERROR - Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:2827,Performance,cache,cache,2827,"s://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/606107ba-fb48-489f-8d14-e19192331b82/call-SplitGvcf/shard-0/glob-a859a146d6b8e5fd268a04d997240e7e/NWD113429.7682e7b9-824b-4307-a101-98d0bcc31e82.0001.g.vcf.gz.tbi"", ""gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/606107ba-fb48-489f-8d14-e19192331b82/call-SplitGvcf/shard-1/glob-a859a146d6b8e5fd268a04d997240e7e/NWD123256.a69a5041-cdcc-4c7d-82e4-47f3d422c441.0001.g.vcf.gz.tbi"", ""gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/606107ba-fb48-489f-8d14-e19192331b82/call-SplitGvcf/shard-2/glob-a859a146d6b8e5fd268a04d997240e7e/NWD145410.61ccb202-d666-4fad-ba17-351fabd79cd1.0001.g.vcf.gz.tbi""]`. **Start of the logs**. 2016-04-11 22:41:00,479 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: persisting status of TileDBCombineGVCF:1048 to Starting.; 2016-04-11 22:41:00,479 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,490 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,521 cromwell-system-akka.actor.default-dispatcher-2683 ERROR - WorkflowActor [UUID(606107ba)]: Failed to fetch locally qualified inputs for call TileDBCombineGVCF:1048; wdl4s.WdlExpressionException: Failed to find index Success(WdlInteger(1048)) on array:. **and the following stacktrace associated with these:**. 1048; at wdl4s.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:112) ~[cromwell.jar:0.19]; at wdl4s.WdlExpression$.evaluate(WdlExpression.scala:79) ~[cromwell.jar:0.19]; at wdl4s.WdlExpression.evaluate(WdlExpression.scala:192) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$fetchLocallyQualifiedInputs$1$$anonfun$apply$16.apply(WorkflowActor.scala:987) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$fetchLocallyQualifiedInputs$1$$anonfun$apply$",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:2967,Performance,cache,cache,2967,"5fd268a04d997240e7e/NWD113429.7682e7b9-824b-4307-a101-98d0bcc31e82.0001.g.vcf.gz.tbi"", ""gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/606107ba-fb48-489f-8d14-e19192331b82/call-SplitGvcf/shard-1/glob-a859a146d6b8e5fd268a04d997240e7e/NWD123256.a69a5041-cdcc-4c7d-82e4-47f3d422c441.0001.g.vcf.gz.tbi"", ""gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/606107ba-fb48-489f-8d14-e19192331b82/call-SplitGvcf/shard-2/glob-a859a146d6b8e5fd268a04d997240e7e/NWD145410.61ccb202-d666-4fad-ba17-351fabd79cd1.0001.g.vcf.gz.tbi""]`. **Start of the logs**. 2016-04-11 22:41:00,479 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: persisting status of TileDBCombineGVCF:1048 to Starting.; 2016-04-11 22:41:00,479 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,490 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,521 cromwell-system-akka.actor.default-dispatcher-2683 ERROR - WorkflowActor [UUID(606107ba)]: Failed to fetch locally qualified inputs for call TileDBCombineGVCF:1048; wdl4s.WdlExpressionException: Failed to find index Success(WdlInteger(1048)) on array:. **and the following stacktrace associated with these:**. 1048; at wdl4s.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:112) ~[cromwell.jar:0.19]; at wdl4s.WdlExpression$.evaluate(WdlExpression.scala:79) ~[cromwell.jar:0.19]; at wdl4s.WdlExpression.evaluate(WdlExpression.scala:192) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$fetchLocallyQualifiedInputs$1$$anonfun$apply$16.apply(WorkflowActor.scala:987) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$fetchLocallyQualifiedInputs$1$$anonfun$apply$16.apply(WorkflowActor.scala:982) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:8495,Performance,concurren,concurrent,8495,"cromwell.jar:0.19]; at akka.actor.ActorCell.invoke_aroundBody0(ActorCell.scala:487) [cromwell.jar:0.19]; at akka.actor.ActorCell$AjcClosure1.run(ActorCell.scala:1) [cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) [cromwell.jar:0.19]; at akka.kamon.instrumentation.ActorCellInstrumentation$$anonfun$aroundBehaviourInvoke$1.apply(ActorCellInstrumentation.scala:63) [cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) [cromwell.jar:0.19]; at akka.kamon.instrumentation.ActorCellInstrumentation.aroundBehaviourInvoke(ActorCellInstrumentation.scala:62) [cromwell.jar:0.19]; at akka.actor.ActorCell.invoke(ActorCell.scala:483) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.run(Mailbox.scala:220) [cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-04-11 22:41:00,528 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,543 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,556 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,617 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,841 cromwell-system-akka.actor.def",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:8588,Performance,concurren,concurrent,8588,".jar:0.19]; at akka.actor.ActorCell$AjcClosure1.run(ActorCell.scala:1) [cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) [cromwell.jar:0.19]; at akka.kamon.instrumentation.ActorCellInstrumentation$$anonfun$aroundBehaviourInvoke$1.apply(ActorCellInstrumentation.scala:63) [cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) [cromwell.jar:0.19]; at akka.kamon.instrumentation.ActorCellInstrumentation.aroundBehaviourInvoke(ActorCellInstrumentation.scala:62) [cromwell.jar:0.19]; at akka.actor.ActorCell.invoke(ActorCell.scala:483) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.run(Mailbox.scala:220) [cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-04-11 22:41:00,528 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,543 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,556 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,617 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,841 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:8693,Performance,concurren,concurrent,8693,"j.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) [cromwell.jar:0.19]; at akka.kamon.instrumentation.ActorCellInstrumentation$$anonfun$aroundBehaviourInvoke$1.apply(ActorCellInstrumentation.scala:63) [cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) [cromwell.jar:0.19]; at akka.kamon.instrumentation.ActorCellInstrumentation.aroundBehaviourInvoke(ActorCellInstrumentation.scala:62) [cromwell.jar:0.19]; at akka.actor.ActorCell.invoke(ActorCell.scala:483) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.run(Mailbox.scala:220) [cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-04-11 22:41:00,528 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,543 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,556 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,617 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,841 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,912 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:8790,Performance,concurren,concurrent,8790,"n.instrumentation.ActorCellInstrumentation$$anonfun$aroundBehaviourInvoke$1.apply(ActorCellInstrumentation.scala:63) [cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) [cromwell.jar:0.19]; at akka.kamon.instrumentation.ActorCellInstrumentation.aroundBehaviourInvoke(ActorCellInstrumentation.scala:62) [cromwell.jar:0.19]; at akka.actor.ActorCell.invoke(ActorCell.scala:483) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.run(Mailbox.scala:220) [cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-04-11 22:41:00,528 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,543 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,556 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,617 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,841 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,912 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; Uncaught error from thread [cromwell-system-akka.actor.default-dispat",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:9015,Performance,cache,cache,9015,"0.19]; at akka.kamon.instrumentation.ActorCellInstrumentation.aroundBehaviourInvoke(ActorCellInstrumentation.scala:62) [cromwell.jar:0.19]; at akka.actor.ActorCell.invoke(ActorCell.scala:483) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.run(Mailbox.scala:220) [cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-04-11 22:41:00,528 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,543 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,556 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,617 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,841 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,912 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:9155,Performance,cache,cache,9155,"at akka.actor.ActorCell.invoke(ActorCell.scala:483) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.run(Mailbox.scala:220) [cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-04-11 22:41:00,528 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,543 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,556 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,617 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,841 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,912 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardI",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:9295,Performance,cache,cache,9295,"l.jar:0.19]; at akka.dispatch.Mailbox.run(Mailbox.scala:220) [cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-04-11 22:41:00,528 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,543 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,556 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,617 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,841 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,912 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardInterpolator(StringContext.scala:128); at scala.StringContext.s(StringContext.scala:95); at cromwell.engine.workflow.WorkflowActor$$anonfun$3",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:9435,Performance,cache,cache,9435,"Task.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-04-11 22:41:00,528 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,543 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,556 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,617 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,841 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,912 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardInterpolator(StringContext.scala:128); at scala.StringContext.s(StringContext.scala:95); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:885); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:881); at scala.collection.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:9575,Performance,cache,cache,9575,"ll.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-04-11 22:41:00,528 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,543 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,556 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,617 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,841 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,912 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardInterpolator(StringContext.scala:128); at scala.StringContext.s(StringContext.scala:95); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:885); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:881); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(Traversa",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:9715,Performance,cache,cache,9715,"kjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-04-11 22:41:00,528 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,543 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,556 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,617 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,841 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,912 cromwell-system-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardInterpolator(StringContext.scala:128); at scala.StringContext.s(StringContext.scala:95); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:885); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:881); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieM",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:5673,Security,Hash,HashMap,5673,lyQualifiedInputs$1.apply(WorkflowActor.scala:982) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$fetchLocallyQualifiedInputs$1.apply(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.fetchLocallyQualifiedInputs(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$processRunnableCall(WorkflowActor.scala:1254) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:868) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467) ~[cromwell.jar:0.19]; at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36) ~[cromwel,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:5698,Security,Hash,HashMap,5698,$1.apply(WorkflowActor.scala:982) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$fetchLocallyQualifiedInputs$1.apply(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.fetchLocallyQualifiedInputs(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$processRunnableCall(WorkflowActor.scala:1254) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:868) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467) ~[cromwell.jar:0.19]; at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36) ~[cromwell.jar:0.19]; at ,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:5769,Security,Hash,HashMap,5769,ow.WorkflowActor$$anonfun$fetchLocallyQualifiedInputs$1.apply(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.fetchLocallyQualifiedInputs(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$processRunnableCall(WorkflowActor.scala:1254) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:868) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467) ~[cromwell.jar:0.19]; at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36) ~[cromwell.jar:0.19]; at akka.actor.FSM$class.processEvent(FSM.scala:604) ~[cromwell.jar:0.19]; at cromwel,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:5777,Security,Hash,HashTrieMap,5777,ow.WorkflowActor$$anonfun$fetchLocallyQualifiedInputs$1.apply(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.fetchLocallyQualifiedInputs(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$processRunnableCall(WorkflowActor.scala:1254) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:868) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467) ~[cromwell.jar:0.19]; at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36) ~[cromwell.jar:0.19]; at akka.actor.FSM$class.processEvent(FSM.scala:604) ~[cromwell.jar:0.19]; at cromwel,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:5797,Security,Hash,HashMap,5797,anonfun$fetchLocallyQualifiedInputs$1.apply(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.fetchLocallyQualifiedInputs(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$processRunnableCall(WorkflowActor.scala:1254) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:868) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467) ~[cromwell.jar:0.19]; at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36) ~[cromwell.jar:0.19]; at akka.actor.FSM$class.processEvent(FSM.scala:604) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:5868,Security,Hash,HashMap,5868,ar:0.19]; at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.fetchLocallyQualifiedInputs(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$processRunnableCall(WorkflowActor.scala:1254) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:868) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467) ~[cromwell.jar:0.19]; at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36) ~[cromwell.jar:0.19]; at akka.actor.FSM$class.processEvent(FSM.scala:604) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236) ,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:5876,Security,Hash,HashTrieMap,5876,ar:0.19]; at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.fetchLocallyQualifiedInputs(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$processRunnableCall(WorkflowActor.scala:1254) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:868) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467) ~[cromwell.jar:0.19]; at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36) ~[cromwell.jar:0.19]; at akka.actor.FSM$class.processEvent(FSM.scala:604) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236) ,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:5896,Security,Hash,HashMap,5896,.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.fetchLocallyQualifiedInputs(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$processRunnableCall(WorkflowActor.scala:1254) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:868) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467) ~[cromwell.jar:0.19]; at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36) ~[cromwell.jar:0.19]; at akka.actor.FSM$class.processEvent(FSM.scala:604) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236) ~[cromwell.jar:0.1,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:5967,Security,Hash,HashMap,5967,.WorkflowActor.fetchLocallyQualifiedInputs(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$processRunnableCall(WorkflowActor.scala:1254) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:868) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467) ~[cromwell.jar:0.19]; at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36) ~[cromwell.jar:0.19]; at akka.actor.FSM$class.processEvent(FSM.scala:604) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236) ~[cromwell.jar:0.19]; at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734) ~[cromwell.jar:0.1,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:5975,Security,Hash,HashTrieMap,5975,.WorkflowActor.fetchLocallyQualifiedInputs(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$processRunnableCall(WorkflowActor.scala:1254) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:868) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467) ~[cromwell.jar:0.19]; at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36) ~[cromwell.jar:0.19]; at akka.actor.FSM$class.processEvent(FSM.scala:604) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236) ~[cromwell.jar:0.19]; at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734) ~[cromwell.jar:0.1,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:5995,Security,Hash,HashMap,5995,chLocallyQualifiedInputs(WorkflowActor.scala:962) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$processRunnableCall(WorkflowActor.scala:1254) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:868) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$33.apply(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467) ~[cromwell.jar:0.19]; at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36) ~[cromwell.jar:0.19]; at akka.actor.FSM$class.processEvent(FSM.scala:604) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236) ~[cromwell.jar:0.19]; at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734) ~[cromwell.jar:0.19]; at cromwell.en,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:10615,Security,Hash,HashMap,10615,tem-akka.actor.default-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardInterpolator(StringContext.scala:128); at scala.StringContext.s(StringContext.scala:95); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:885); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:881); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:881); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236); at akka.actor.LoggingFSM,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:10640,Security,Hash,HashMap,10640,fault-dispatcher-2666 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardInterpolator(StringContext.scala:128); at scala.StringContext.s(StringContext.scala:95); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:885); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:881); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:881); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236); at akka.actor.LoggingFSM$class.processEv,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:10690,Security,Hash,HashMap,10690, Call Caching: cache miss; Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardInterpolator(StringContext.scala:128); at scala.StringContext.s(StringContext.scala:95); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:885); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:881); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:881); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActo,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:10698,Security,Hash,HashTrieMap,10698, Call Caching: cache miss; Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardInterpolator(StringContext.scala:128); at scala.StringContext.s(StringContext.scala:95); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:885); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:881); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:881); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActo,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:10718,Security,Hash,HashMap,10718,he miss; Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardInterpolator(StringContext.scala:128); at scala.StringContext.s(StringContext.scala:95); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:885); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:881); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:881); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActor.processEvent(Wor,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:10768,Security,Hash,HashMap,10768,tor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardInterpolator(StringContext.scala:128); at scala.StringContext.s(StringContext.scala:95); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:885); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:881); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:881); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActor.processEvent(WorkflowActor.scala:236); at akka.actor.FSM$class.akka$actor$FS,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:10776,Security,Hash,HashTrieMap,10776,tor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardInterpolator(StringContext.scala:128); at scala.StringContext.s(StringContext.scala:95); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:885); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:881); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:881); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActor.processEvent(WorkflowActor.scala:236); at akka.actor.FSM$class.akka$actor$FS,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:10796,Security,Hash,HashMap,10796,cher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardInterpolator(StringContext.scala:128); at scala.StringContext.s(StringContext.scala:95); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:885); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:881); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:881); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActor.processEvent(WorkflowActor.scala:236); at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:10846,Security,Hash,HashMap,10846,rror' is enabled for ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardInterpolator(StringContext.scala:128); at scala.StringContext.s(StringContext.scala:95); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:885); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:881); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:881); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActor.processEvent(WorkflowActor.scala:236); at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:598); at akka.actor.FSM$$anonfun$receive$1.applyOrElse,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:10854,Security,Hash,HashTrieMap,10854,rror' is enabled for ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardInterpolator(StringContext.scala:128); at scala.StringContext.s(StringContext.scala:95); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:885); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:881); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:881); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActor.processEvent(WorkflowActor.scala:236); at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:598); at akka.actor.FSM$$anonfun$receive$1.applyOrElse,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:10874,Security,Hash,HashMap,10874,or ActorSystem[cromwell-system]. **java.lang.OutOfMemoryError: Java heap space**; at java.util.Arrays.copyOfRange(Arrays.java:3664); at java.lang.String.<init>(String.java:207); at java.lang.StringBuilder.toString(StringBuilder.java:407); at scala.StringContext.standardInterpolator(StringContext.scala:128); at scala.StringContext.s(StringContext.scala:95); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:885); at cromwell.engine.workflow.WorkflowActor$$anonfun$34.apply(WorkflowActor.scala:881); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:155); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:881); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActor.processEvent(WorkflowActor.scala:236); at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:598); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:592); a,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:2519,Testability,log,logs,2519,"7e/NWD123256.a69a5041-cdcc-4c7d-82e4-47f3d422c441.0000.g.vcf.gz.tbi"", ""gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/606107ba-fb48-489f-8d14-e19192331b82/call-SplitGvcf/shard-2/glob-a859a146d6b8e5fd268a04d997240e7e/NWD145410.61ccb202-d666-4fad-ba17-351fabd79cd1.0000.g.vcf.gz.tbi""], [""gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/606107ba-fb48-489f-8d14-e19192331b82/call-SplitGvcf/shard-0/glob-a859a146d6b8e5fd268a04d997240e7e/NWD113429.7682e7b9-824b-4307-a101-98d0bcc31e82.0001.g.vcf.gz.tbi"", ""gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/606107ba-fb48-489f-8d14-e19192331b82/call-SplitGvcf/shard-1/glob-a859a146d6b8e5fd268a04d997240e7e/NWD123256.a69a5041-cdcc-4c7d-82e4-47f3d422c441.0001.g.vcf.gz.tbi"", ""gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/606107ba-fb48-489f-8d14-e19192331b82/call-SplitGvcf/shard-2/glob-a859a146d6b8e5fd268a04d997240e7e/NWD145410.61ccb202-d666-4fad-ba17-351fabd79cd1.0001.g.vcf.gz.tbi""]`. **Start of the logs**. 2016-04-11 22:41:00,479 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: persisting status of TileDBCombineGVCF:1048 to Starting.; 2016-04-11 22:41:00,479 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,490 cromwell-system-akka.actor.default-dispatcher-2683 INFO - WorkflowActor [UUID(606107ba)]: Call Caching: cache miss; 2016-04-11 22:41:00,521 cromwell-system-akka.actor.default-dispatcher-2683 ERROR - WorkflowActor [UUID(606107ba)]: Failed to fetch locally qualified inputs for call TileDBCombineGVCF:1048; wdl4s.WdlExpressionException: Failed to find index Success(WdlInteger(1048)) on array:. **and the following stacktrace associated with these:**. 1048; at wdl4s.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:112) ~[cromwell.jar:0.19]; at wdl4s.WdlExpression$.evaluate(WdlExpression.scala:79) ~[cromwell.jar:0.19]; at wdl4s.WdlExpression.ev",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:6822,Testability,Log,LoggingFSM,6822,t scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467) ~[cromwell.jar:0.19]; at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36) ~[cromwell.jar:0.19]; at akka.actor.FSM$class.processEvent(FSM.scala:604) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236) ~[cromwell.jar:0.19]; at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.processEvent(WorkflowActor.scala:236) ~[cromwell.jar:0.19]; at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:598) ~[cromwell.jar:0.19]; at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:592) ~[cromwell.jar:0.19]; at akka.actor.Actor$class.aroundReceive(Actor.scala:467) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.aroundReceive(WorkflowActor.scala:236) ~[cromwell.jar:0.19]; at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516) [cromwell.jar:0.19]; at akka.actor.ActorCell.invoke_aroundBody0(ActorCell.scala:487) [cromwell.jar:0.19]; at akka.actor.ActorCell$AjcClosure1.run(ActorCell.scala:1) [cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) [cromwell.jar:0.19]; at akka.kamon.instrumentation.ActorCellInstrumentation$$,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:6914,Testability,Log,LoggingFSM,6914,ell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:867) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467) ~[cromwell.jar:0.19]; at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36) ~[cromwell.jar:0.19]; at akka.actor.FSM$class.processEvent(FSM.scala:604) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236) ~[cromwell.jar:0.19]; at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.processEvent(WorkflowActor.scala:236) ~[cromwell.jar:0.19]; at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:598) ~[cromwell.jar:0.19]; at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:592) ~[cromwell.jar:0.19]; at akka.actor.Actor$class.aroundReceive(Actor.scala:467) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowActor.aroundReceive(WorkflowActor.scala:236) ~[cromwell.jar:0.19]; at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516) [cromwell.jar:0.19]; at akka.actor.ActorCell.invoke_aroundBody0(ActorCell.scala:487) [cromwell.jar:0.19]; at akka.actor.ActorCell$AjcClosure1.run(ActorCell.scala:1) [cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) [cromwell.jar:0.19]; at akka.kamon.instrumentation.ActorCellInstrumentation$$anonfun$aroundBehaviourInvoke$1.apply(ActorCellInstrumentation.scala:63) [cromwell.j,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:11543,Testability,Log,LoggingFSM,11543,"versableOnce.scala:155); at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:881); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActor.processEvent(WorkflowActor.scala:236); at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:598); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:592); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.WorkflowActor.aroundReceive(WorkflowActor.scala:236); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke_aroundBody0(ActorCell.scala:487); at akka.actor.ActorCell$AjcClosure1.run(ActorCell.scala:1); at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149); at akka.kamon.instrumentation.ActorCellInstrumentation$$anonfun$aroundBehaviourInvoke$1.apply(ActorCellInstrumentation.scala:63); 2016-04-11 22:41:17,520 cromwell-system-akka.actor.default-dispatcher-2661 ERROR - Uncaught error from thread [cromwell-system-akka.actor.default-dispatc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/695:11614,Testability,Log,LoggingFSM,11614,"$HashMap1.foreach(HashMap.scala:221); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at cromwell.engine.workflow.WorkflowActor.cromwell$engine$workflow$WorkflowActor$$startRunnableCalls(WorkflowActor.scala:881); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:532); at cromwell.engine.workflow.WorkflowActor$$anonfun$2.applyOrElse(WorkflowActor.scala:467); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at akka.actor.FSM$class.processEvent(FSM.scala:604); at cromwell.engine.workflow.WorkflowActor.akka$actor$LoggingFSM$$super$processEvent(WorkflowActor.scala:236); at akka.actor.LoggingFSM$class.processEvent(FSM.scala:734); at cromwell.engine.workflow.WorkflowActor.processEvent(WorkflowActor.scala:236); at akka.actor.FSM$class.akka$actor$FSM$$processMsg(FSM.scala:598); at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:592); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.WorkflowActor.aroundReceive(WorkflowActor.scala:236); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke_aroundBody0(ActorCell.scala:487); at akka.actor.ActorCell$AjcClosure1.run(ActorCell.scala:1); at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149); at akka.kamon.instrumentation.ActorCellInstrumentation$$anonfun$aroundBehaviourInvoke$1.apply(ActorCellInstrumentation.scala:63); 2016-04-11 22:41:17,520 cromwell-system-akka.actor.default-dispatcher-2661 ERROR - Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2676] shutting down JVM since 'akka.jvm-exit-on-fatal-error",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/695
https://github.com/broadinstitute/cromwell/issues/699:445,Availability,down,down,445,"I tried running a these two glob output commands; `Array[File] gvcf_list = glob(""split_gvcfs/*.gz"")`; `Array[File] gvcf_index_list = glob(""split_gvcfs/*.tbi"")`; Which should have had 3457 elements in each array. When I go to the output directory bucket of the above task, I see each glob directory does indeed have 3457 elements but when I go to the symbols table in the Cromwell db the arrays only have 1000 elements. This causes tasks further down in the workflow to fail because I am expecting an array of 3457 elements but I am only getting 1000.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/699
https://github.com/broadinstitute/cromwell/issues/700:419,Availability,ERROR,ERROR,419,"Log from broad-dsde-dev here: https://gist.githubusercontent.com/scottfrazer/a0838aa2180e7972da84c4730975b9f5/raw/d0cebdd317489298d6553e5602bfd4b775ab9ea3/gistfile1.txt. Most specifically:. ```; WorkflowActor [UUID(0790bc7e)]: Beginning transition from Running to Aborting.; WorkflowActor [UUID(0790bc7e)]: transitioning from Running to Aborting.; JES Run [UUID(0790bc7e):hello]: Status change from Running to Success; ERROR - 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Precondition check failed."",; ""reason"" : ""failedPrecondition""; } ],; ""message"" : ""Precondition check failed."",; ""status"" : ""FAILED_PRECONDITION""; }; com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Precondition check failed."",; ""reason"" : ""failedPrecondition""; } ],; ""message"" : ""Precondition check failed."",; ""status"" : ""FAILED_PRECONDITION""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/700
https://github.com/broadinstitute/cromwell/issues/700:463,Availability,error,errors,463,"Log from broad-dsde-dev here: https://gist.githubusercontent.com/scottfrazer/a0838aa2180e7972da84c4730975b9f5/raw/d0cebdd317489298d6553e5602bfd4b775ab9ea3/gistfile1.txt. Most specifically:. ```; WorkflowActor [UUID(0790bc7e)]: Beginning transition from Running to Aborting.; WorkflowActor [UUID(0790bc7e)]: transitioning from Running to Aborting.; JES Run [UUID(0790bc7e):hello]: Status change from Running to Success; ERROR - 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Precondition check failed."",; ""reason"" : ""failedPrecondition""; } ],; ""message"" : ""Precondition check failed."",; ""status"" : ""FAILED_PRECONDITION""; }; com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Precondition check failed."",; ""reason"" : ""failedPrecondition""; } ],; ""message"" : ""Precondition check failed."",; ""status"" : ""FAILED_PRECONDITION""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/700
https://github.com/broadinstitute/cromwell/issues/700:765,Availability,error,errors,765,"Log from broad-dsde-dev here: https://gist.githubusercontent.com/scottfrazer/a0838aa2180e7972da84c4730975b9f5/raw/d0cebdd317489298d6553e5602bfd4b775ab9ea3/gistfile1.txt. Most specifically:. ```; WorkflowActor [UUID(0790bc7e)]: Beginning transition from Running to Aborting.; WorkflowActor [UUID(0790bc7e)]: transitioning from Running to Aborting.; JES Run [UUID(0790bc7e):hello]: Status change from Running to Success; ERROR - 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Precondition check failed."",; ""reason"" : ""failedPrecondition""; } ],; ""message"" : ""Precondition check failed."",; ""status"" : ""FAILED_PRECONDITION""; }; com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Precondition check failed."",; ""reason"" : ""failedPrecondition""; } ],; ""message"" : ""Precondition check failed."",; ""status"" : ""FAILED_PRECONDITION""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/700
https://github.com/broadinstitute/cromwell/issues/700:501,Integrability,message,message,501,"Log from broad-dsde-dev here: https://gist.githubusercontent.com/scottfrazer/a0838aa2180e7972da84c4730975b9f5/raw/d0cebdd317489298d6553e5602bfd4b775ab9ea3/gistfile1.txt. Most specifically:. ```; WorkflowActor [UUID(0790bc7e)]: Beginning transition from Running to Aborting.; WorkflowActor [UUID(0790bc7e)]: transitioning from Running to Aborting.; JES Run [UUID(0790bc7e):hello]: Status change from Running to Success; ERROR - 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Precondition check failed."",; ""reason"" : ""failedPrecondition""; } ],; ""message"" : ""Precondition check failed."",; ""status"" : ""FAILED_PRECONDITION""; }; com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Precondition check failed."",; ""reason"" : ""failedPrecondition""; } ],; ""message"" : ""Precondition check failed."",; ""status"" : ""FAILED_PRECONDITION""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/700
https://github.com/broadinstitute/cromwell/issues/700:583,Integrability,message,message,583,"Log from broad-dsde-dev here: https://gist.githubusercontent.com/scottfrazer/a0838aa2180e7972da84c4730975b9f5/raw/d0cebdd317489298d6553e5602bfd4b775ab9ea3/gistfile1.txt. Most specifically:. ```; WorkflowActor [UUID(0790bc7e)]: Beginning transition from Running to Aborting.; WorkflowActor [UUID(0790bc7e)]: transitioning from Running to Aborting.; JES Run [UUID(0790bc7e):hello]: Status change from Running to Success; ERROR - 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Precondition check failed."",; ""reason"" : ""failedPrecondition""; } ],; ""message"" : ""Precondition check failed."",; ""status"" : ""FAILED_PRECONDITION""; }; com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Precondition check failed."",; ""reason"" : ""failedPrecondition""; } ],; ""message"" : ""Precondition check failed."",; ""status"" : ""FAILED_PRECONDITION""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/700
https://github.com/broadinstitute/cromwell/issues/700:803,Integrability,message,message,803,"Log from broad-dsde-dev here: https://gist.githubusercontent.com/scottfrazer/a0838aa2180e7972da84c4730975b9f5/raw/d0cebdd317489298d6553e5602bfd4b775ab9ea3/gistfile1.txt. Most specifically:. ```; WorkflowActor [UUID(0790bc7e)]: Beginning transition from Running to Aborting.; WorkflowActor [UUID(0790bc7e)]: transitioning from Running to Aborting.; JES Run [UUID(0790bc7e):hello]: Status change from Running to Success; ERROR - 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Precondition check failed."",; ""reason"" : ""failedPrecondition""; } ],; ""message"" : ""Precondition check failed."",; ""status"" : ""FAILED_PRECONDITION""; }; com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Precondition check failed."",; ""reason"" : ""failedPrecondition""; } ],; ""message"" : ""Precondition check failed."",; ""status"" : ""FAILED_PRECONDITION""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/700
https://github.com/broadinstitute/cromwell/issues/700:885,Integrability,message,message,885,"Log from broad-dsde-dev here: https://gist.githubusercontent.com/scottfrazer/a0838aa2180e7972da84c4730975b9f5/raw/d0cebdd317489298d6553e5602bfd4b775ab9ea3/gistfile1.txt. Most specifically:. ```; WorkflowActor [UUID(0790bc7e)]: Beginning transition from Running to Aborting.; WorkflowActor [UUID(0790bc7e)]: transitioning from Running to Aborting.; JES Run [UUID(0790bc7e):hello]: Status change from Running to Success; ERROR - 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Precondition check failed."",; ""reason"" : ""failedPrecondition""; } ],; ""message"" : ""Precondition check failed."",; ""status"" : ""FAILED_PRECONDITION""; }; com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Precondition check failed."",; ""reason"" : ""failedPrecondition""; } ],; ""message"" : ""Precondition check failed."",; ""status"" : ""FAILED_PRECONDITION""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/700
https://github.com/broadinstitute/cromwell/issues/700:264,Safety,Abort,Aborting,264,"Log from broad-dsde-dev here: https://gist.githubusercontent.com/scottfrazer/a0838aa2180e7972da84c4730975b9f5/raw/d0cebdd317489298d6553e5602bfd4b775ab9ea3/gistfile1.txt. Most specifically:. ```; WorkflowActor [UUID(0790bc7e)]: Beginning transition from Running to Aborting.; WorkflowActor [UUID(0790bc7e)]: transitioning from Running to Aborting.; JES Run [UUID(0790bc7e):hello]: Status change from Running to Success; ERROR - 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Precondition check failed."",; ""reason"" : ""failedPrecondition""; } ],; ""message"" : ""Precondition check failed."",; ""status"" : ""FAILED_PRECONDITION""; }; com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Precondition check failed."",; ""reason"" : ""failedPrecondition""; } ],; ""message"" : ""Precondition check failed."",; ""status"" : ""FAILED_PRECONDITION""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/700
https://github.com/broadinstitute/cromwell/issues/700:337,Safety,Abort,Aborting,337,"Log from broad-dsde-dev here: https://gist.githubusercontent.com/scottfrazer/a0838aa2180e7972da84c4730975b9f5/raw/d0cebdd317489298d6553e5602bfd4b775ab9ea3/gistfile1.txt. Most specifically:. ```; WorkflowActor [UUID(0790bc7e)]: Beginning transition from Running to Aborting.; WorkflowActor [UUID(0790bc7e)]: transitioning from Running to Aborting.; JES Run [UUID(0790bc7e):hello]: Status change from Running to Success; ERROR - 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Precondition check failed."",; ""reason"" : ""failedPrecondition""; } ],; ""message"" : ""Precondition check failed."",; ""status"" : ""FAILED_PRECONDITION""; }; com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Precondition check failed."",; ""reason"" : ""failedPrecondition""; } ],; ""message"" : ""Precondition check failed."",; ""status"" : ""FAILED_PRECONDITION""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/700
https://github.com/broadinstitute/cromwell/issues/700:0,Testability,Log,Log,0,"Log from broad-dsde-dev here: https://gist.githubusercontent.com/scottfrazer/a0838aa2180e7972da84c4730975b9f5/raw/d0cebdd317489298d6553e5602bfd4b775ab9ea3/gistfile1.txt. Most specifically:. ```; WorkflowActor [UUID(0790bc7e)]: Beginning transition from Running to Aborting.; WorkflowActor [UUID(0790bc7e)]: transitioning from Running to Aborting.; JES Run [UUID(0790bc7e):hello]: Status change from Running to Success; ERROR - 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Precondition check failed."",; ""reason"" : ""failedPrecondition""; } ],; ""message"" : ""Precondition check failed."",; ""status"" : ""FAILED_PRECONDITION""; }; com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Precondition check failed."",; ""reason"" : ""failedPrecondition""; } ],; ""message"" : ""Precondition check failed."",; ""status"" : ""FAILED_PRECONDITION""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/700
https://github.com/broadinstitute/cromwell/issues/703:203,Availability,avail,available,203,"## From @yfarjoun . I lost a whole day on this stupid bug....; when the input file specified in a JSON is missing, submitting the job takes a long time and returns with:. Resource representation is only available with these Content-Types:; text/plain; charset=UTF-8; text/plain. Which, needless to say is not pointing at the problem...I only managed to figure this out by slowly transitioning from a functioning JSON to the ""problematic"" one... Cheers,. Yossi.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/703
https://github.com/broadinstitute/cromwell/issues/705:441,Availability,avail,available,441,"For users just getting started with Cromwell, the documentation here:. https://github.com/broadinstitute/cromwell#getting-started-with-wdl. Points the user here:. https://github.com/broadinstitute/wdl#getting-started-with-wdl. and when you run your first workflow, you'll see in the output:. ```; [2016-04-14 16:21:12,82] [warn] Failed to get application default credentials; java.io.IOException: The Application Default Credentials are not available. They are available if running in Google Compute Engine. Otherwise, the environment variable GOOGLE_APPLICATION_CREDENTIALS must be defined pointing to a file defining the credentials. See https://developers.google.com/accounts/docs/application-default-credentials for more information.; at com.google.api.client.googleapis.auth.oauth2.DefaultCredentialProvider.getDefaultCredential(DefaultCredentialProvider.java:93); at com.google.api.client.googleapis.auth.oauth2.GoogleCredential.getApplicationDefault(GoogleCredential.java:213); at com.google.api.client.googleapis.auth.oauth2.GoogleCredential.getApplicationDefault(GoogleCredential.java:191); at cromwell.util.google.GoogleCredentialFactory.forApplicationDefaultCredentials(GoogleCredentialFactory.scala:125); at cromwell.util.google.GoogleCredentialFactory.fromCromwellAuthScheme$lzycompute(GoogleCredentialFactory.scala:64); at cromwell.util.google.GoogleCredentialFactory.fromCromwellAuthScheme(GoogleCredentialFactory.scala:61); at cromwell.engine.backend.io.filesystem.gcs.StorageFactory$$anonfun$cromwellAuthenticated$1.apply(StorageFactory.scala:20); at cromwell.engine.backend.io.filesystem.gcs.StorageFactory$$anonfun$cromwellAuthenticated$1.apply(StorageFactory.scala:20); at scala.util.Try$.apply(Try.scala:192); at cromwell.engine.backend.io.filesystem.gcs.StorageFactory$.cromwellAuthenticated$lzycompute(StorageFactory.scala:20); at cromwell.engine.backend.io.filesystem.gcs.StorageFactory$.cromwellAuthenticated(StorageFactory.scala:18); at cromwell.engine.backend.local.LocalBac",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/705
https://github.com/broadinstitute/cromwell/issues/705:461,Availability,avail,available,461,"For users just getting started with Cromwell, the documentation here:. https://github.com/broadinstitute/cromwell#getting-started-with-wdl. Points the user here:. https://github.com/broadinstitute/wdl#getting-started-with-wdl. and when you run your first workflow, you'll see in the output:. ```; [2016-04-14 16:21:12,82] [warn] Failed to get application default credentials; java.io.IOException: The Application Default Credentials are not available. They are available if running in Google Compute Engine. Otherwise, the environment variable GOOGLE_APPLICATION_CREDENTIALS must be defined pointing to a file defining the credentials. See https://developers.google.com/accounts/docs/application-default-credentials for more information.; at com.google.api.client.googleapis.auth.oauth2.DefaultCredentialProvider.getDefaultCredential(DefaultCredentialProvider.java:93); at com.google.api.client.googleapis.auth.oauth2.GoogleCredential.getApplicationDefault(GoogleCredential.java:213); at com.google.api.client.googleapis.auth.oauth2.GoogleCredential.getApplicationDefault(GoogleCredential.java:191); at cromwell.util.google.GoogleCredentialFactory.forApplicationDefaultCredentials(GoogleCredentialFactory.scala:125); at cromwell.util.google.GoogleCredentialFactory.fromCromwellAuthScheme$lzycompute(GoogleCredentialFactory.scala:64); at cromwell.util.google.GoogleCredentialFactory.fromCromwellAuthScheme(GoogleCredentialFactory.scala:61); at cromwell.engine.backend.io.filesystem.gcs.StorageFactory$$anonfun$cromwellAuthenticated$1.apply(StorageFactory.scala:20); at cromwell.engine.backend.io.filesystem.gcs.StorageFactory$$anonfun$cromwellAuthenticated$1.apply(StorageFactory.scala:20); at scala.util.Try$.apply(Try.scala:192); at cromwell.engine.backend.io.filesystem.gcs.StorageFactory$.cromwellAuthenticated$lzycompute(StorageFactory.scala:20); at cromwell.engine.backend.io.filesystem.gcs.StorageFactory$.cromwellAuthenticated(StorageFactory.scala:18); at cromwell.engine.backend.local.LocalBac",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/705
https://github.com/broadinstitute/cromwell/issues/705:5468,Availability,down,down,5468,"ctor.scala:103); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$receive$1.applyOrElse(MaterializeWorkflowDescriptorActor.scala:66); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:59); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke(ActorCell.scala:487); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238); at akka.dispatch.Mailbox.run(Mailbox.scala:220); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```. To a novice user it is not clear whether that this can safely be ignored. This is a problem in particular if this first use actually fails for some other reason. The user will spend time trying to figure out if the problem is caused by a credential issue. I tried to see if I could easily suppress this by setting up ""backends"" to only include ""local"". I pulled down the [application.conf](https://github.com/broadinstitute/cromwell/blob/9f759a54a0b8873f1338f36391f985477d83475a/engine/src/main/resources/application.conf) which sets:. ```; backend {; // Either ""jes"", ""local"", or ""sge"" (case insensitive); defaultBackend = ""local""; // List of backends which this Cromwell supports. Be sure to include the defaultBackend!; backendsAllowed = [ ""local"" ]; ```. and then passed the file as:. `$ java -Dconfig.file=application.conf -jar cromwell.jar run hello.wdl hello.json; `; But the exception and warning were still raised. Should the ADC check be occurring even when backendsAllowed does not include JES?. Thanks.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/705
https://github.com/broadinstitute/cromwell/issues/705:535,Modifiability,variab,variable,535,"For users just getting started with Cromwell, the documentation here:. https://github.com/broadinstitute/cromwell#getting-started-with-wdl. Points the user here:. https://github.com/broadinstitute/wdl#getting-started-with-wdl. and when you run your first workflow, you'll see in the output:. ```; [2016-04-14 16:21:12,82] [warn] Failed to get application default credentials; java.io.IOException: The Application Default Credentials are not available. They are available if running in Google Compute Engine. Otherwise, the environment variable GOOGLE_APPLICATION_CREDENTIALS must be defined pointing to a file defining the credentials. See https://developers.google.com/accounts/docs/application-default-credentials for more information.; at com.google.api.client.googleapis.auth.oauth2.DefaultCredentialProvider.getDefaultCredential(DefaultCredentialProvider.java:93); at com.google.api.client.googleapis.auth.oauth2.GoogleCredential.getApplicationDefault(GoogleCredential.java:213); at com.google.api.client.googleapis.auth.oauth2.GoogleCredential.getApplicationDefault(GoogleCredential.java:191); at cromwell.util.google.GoogleCredentialFactory.forApplicationDefaultCredentials(GoogleCredentialFactory.scala:125); at cromwell.util.google.GoogleCredentialFactory.fromCromwellAuthScheme$lzycompute(GoogleCredentialFactory.scala:64); at cromwell.util.google.GoogleCredentialFactory.fromCromwellAuthScheme(GoogleCredentialFactory.scala:61); at cromwell.engine.backend.io.filesystem.gcs.StorageFactory$$anonfun$cromwellAuthenticated$1.apply(StorageFactory.scala:20); at cromwell.engine.backend.io.filesystem.gcs.StorageFactory$$anonfun$cromwellAuthenticated$1.apply(StorageFactory.scala:20); at scala.util.Try$.apply(Try.scala:192); at cromwell.engine.backend.io.filesystem.gcs.StorageFactory$.cromwellAuthenticated$lzycompute(StorageFactory.scala:20); at cromwell.engine.backend.io.filesystem.gcs.StorageFactory$.cromwellAuthenticated(StorageFactory.scala:18); at cromwell.engine.backend.local.LocalBac",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/705
https://github.com/broadinstitute/cromwell/issues/705:4789,Performance,concurren,concurrent,4789,"torActor$$buildWorkflowDescriptor$2.apply(MaterializeWorkflowDescriptorActor.scala:103); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:103); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$receive$1.applyOrElse(MaterializeWorkflowDescriptorActor.scala:66); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:59); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke(ActorCell.scala:487); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238); at akka.dispatch.Mailbox.run(Mailbox.scala:220); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```. To a novice user it is not clear whether that this can safely be ignored. This is a problem in particular if this first use actually fails for some other reason. The user will spend time trying to figure out if the problem is caused by a credential issue. I tried to see if I could easily suppress this by setting up ""backends"" to only include ""local"". I pulled down the [application.conf](https://github.com/broadinstitute/cromwell/blob/9f759a54a0b8873f1338f36391f985477d83475a/engine/src/main/resources/application.conf) which sets:. ```; backend {; // Either ""jes"", ""local"", or ""sge"" (case insensitive); defaultBackend = ""local""; // List of backends which this Cromwell supports. Be sur",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/705
https://github.com/broadinstitute/cromwell/issues/705:4862,Performance,concurren,concurrent,4862,"tor.scala:103); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:103); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$receive$1.applyOrElse(MaterializeWorkflowDescriptorActor.scala:66); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:59); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke(ActorCell.scala:487); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238); at akka.dispatch.Mailbox.run(Mailbox.scala:220); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```. To a novice user it is not clear whether that this can safely be ignored. This is a problem in particular if this first use actually fails for some other reason. The user will spend time trying to figure out if the problem is caused by a credential issue. I tried to see if I could easily suppress this by setting up ""backends"" to only include ""local"". I pulled down the [application.conf](https://github.com/broadinstitute/cromwell/blob/9f759a54a0b8873f1338f36391f985477d83475a/engine/src/main/resources/application.conf) which sets:. ```; backend {; // Either ""jes"", ""local"", or ""sge"" (case insensitive); defaultBackend = ""local""; // List of backends which this Cromwell supports. Be sure to include the defaultBackend!; backendsAllowed = [ ""local"" ]; ```. and",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/705
https://github.com/broadinstitute/cromwell/issues/705:4947,Performance,concurren,concurrent,4947,"l.engine.workflow.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:103); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$receive$1.applyOrElse(MaterializeWorkflowDescriptorActor.scala:66); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:59); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke(ActorCell.scala:487); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238); at akka.dispatch.Mailbox.run(Mailbox.scala:220); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```. To a novice user it is not clear whether that this can safely be ignored. This is a problem in particular if this first use actually fails for some other reason. The user will spend time trying to figure out if the problem is caused by a credential issue. I tried to see if I could easily suppress this by setting up ""backends"" to only include ""local"". I pulled down the [application.conf](https://github.com/broadinstitute/cromwell/blob/9f759a54a0b8873f1338f36391f985477d83475a/engine/src/main/resources/application.conf) which sets:. ```; backend {; // Either ""jes"", ""local"", or ""sge"" (case insensitive); defaultBackend = ""local""; // List of backends which this Cromwell supports. Be sure to include the defaultBackend!; backendsAllowed = [ ""local"" ]; ```. and then passed the file as:. `$ java -Dconfig.file=application.conf -jar cromwell.jar r",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/705
https://github.com/broadinstitute/cromwell/issues/705:5024,Performance,concurren,concurrent,5024,"$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:103); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$receive$1.applyOrElse(MaterializeWorkflowDescriptorActor.scala:66); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:59); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke(ActorCell.scala:487); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238); at akka.dispatch.Mailbox.run(Mailbox.scala:220); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```. To a novice user it is not clear whether that this can safely be ignored. This is a problem in particular if this first use actually fails for some other reason. The user will spend time trying to figure out if the problem is caused by a credential issue. I tried to see if I could easily suppress this by setting up ""backends"" to only include ""local"". I pulled down the [application.conf](https://github.com/broadinstitute/cromwell/blob/9f759a54a0b8873f1338f36391f985477d83475a/engine/src/main/resources/application.conf) which sets:. ```; backend {; // Either ""jes"", ""local"", or ""sge"" (case insensitive); defaultBackend = ""local""; // List of backends which this Cromwell supports. Be sure to include the defaultBackend!; backendsAllowed = [ ""local"" ]; ```. and then passed the file as:. `$ java -Dconfig.file=application.conf -jar cromwell.jar run hello.wdl hello.json; `; But the exception and warning were still raised. ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/705
https://github.com/broadinstitute/cromwell/issues/705:5161,Safety,safe,safely,5161,"ctor.scala:103); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$receive$1.applyOrElse(MaterializeWorkflowDescriptorActor.scala:66); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:59); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke(ActorCell.scala:487); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238); at akka.dispatch.Mailbox.run(Mailbox.scala:220); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```. To a novice user it is not clear whether that this can safely be ignored. This is a problem in particular if this first use actually fails for some other reason. The user will spend time trying to figure out if the problem is caused by a credential issue. I tried to see if I could easily suppress this by setting up ""backends"" to only include ""local"". I pulled down the [application.conf](https://github.com/broadinstitute/cromwell/blob/9f759a54a0b8873f1338f36391f985477d83475a/engine/src/main/resources/application.conf) which sets:. ```; backend {; // Either ""jes"", ""local"", or ""sge"" (case insensitive); defaultBackend = ""local""; // List of backends which this Cromwell supports. Be sure to include the defaultBackend!; backendsAllowed = [ ""local"" ]; ```. and then passed the file as:. `$ java -Dconfig.file=application.conf -jar cromwell.jar run hello.wdl hello.json; `; But the exception and warning were still raised. Should the ADC check be occurring even when backendsAllowed does not include JES?. Thanks.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/705
https://github.com/broadinstitute/cromwell/issues/705:2697,Security,Validat,ValidationFlatMap,2697,y$.apply(Try.scala:192); at cromwell.engine.backend.io.filesystem.gcs.StorageFactory$.cromwellAuthenticated$lzycompute(StorageFactory.scala:20); at cromwell.engine.backend.io.filesystem.gcs.StorageFactory$.cromwellAuthenticated(StorageFactory.scala:18); at cromwell.engine.backend.local.LocalBackend$$anonfun$14.apply(LocalBackend.scala:239); at cromwell.engine.backend.local.LocalBackend$$anonfun$14.apply(LocalBackend.scala:239); at scala.util.Try.orElse(Try.scala:84); at cromwell.engine.backend.local.LocalBackend.fileSystems(LocalBackend.scala:239); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$1$1.apply(MaterializeWorkflowDescriptorActor.scala:89); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$1$1.apply(MaterializeWorkflowDescriptorActor.scala:86); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$1(MaterializeWorkflowDescriptorActor.scala:86); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2$$anonfun$apply$8.apply(MaterializeWorkflowDescriptorActor.scala:110); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2$$anonfun$apply$8.apply(MaterializeWorkflowDescriptorActor.scala:109); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2.apply(MaterializeWorkflowDescriptorActor.scala:109); at cromwell.engine.workflow.Materia,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/705
https://github.com/broadinstitute/cromwell/issues/705:2723,Security,Validat,Validation,2723,:192); at cromwell.engine.backend.io.filesystem.gcs.StorageFactory$.cromwellAuthenticated$lzycompute(StorageFactory.scala:20); at cromwell.engine.backend.io.filesystem.gcs.StorageFactory$.cromwellAuthenticated(StorageFactory.scala:18); at cromwell.engine.backend.local.LocalBackend$$anonfun$14.apply(LocalBackend.scala:239); at cromwell.engine.backend.local.LocalBackend$$anonfun$14.apply(LocalBackend.scala:239); at scala.util.Try.orElse(Try.scala:84); at cromwell.engine.backend.local.LocalBackend.fileSystems(LocalBackend.scala:239); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$1$1.apply(MaterializeWorkflowDescriptorActor.scala:89); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$1$1.apply(MaterializeWorkflowDescriptorActor.scala:86); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$1(MaterializeWorkflowDescriptorActor.scala:86); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2$$anonfun$apply$8.apply(MaterializeWorkflowDescriptorActor.scala:110); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2$$anonfun$apply$8.apply(MaterializeWorkflowDescriptorActor.scala:109); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2.apply(MaterializeWorkflowDescriptorActor.scala:109); at cromwell.engine.workflow.MaterializeWorkflowDescrip,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/705
https://github.com/broadinstitute/cromwell/issues/705:3410,Security,Validat,ValidationFlatMap,3410,$1.apply(MaterializeWorkflowDescriptorActor.scala:89); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$1$1.apply(MaterializeWorkflowDescriptorActor.scala:86); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$1(MaterializeWorkflowDescriptorActor.scala:86); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2$$anonfun$apply$8.apply(MaterializeWorkflowDescriptorActor.scala:110); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2$$anonfun$apply$8.apply(MaterializeWorkflowDescriptorActor.scala:109); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2.apply(MaterializeWorkflowDescriptorActor.scala:109); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2.apply(MaterializeWorkflowDescriptorActor.scala:103); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:103); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$receive$1.applyOrElse(MaterializeWorkflowDescriptorActor.scala:66); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.aroundReceive(Materia,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/705
https://github.com/broadinstitute/cromwell/issues/705:3436,Security,Validat,Validation,3436,zeWorkflowDescriptorActor.scala:89); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$1$1.apply(MaterializeWorkflowDescriptorActor.scala:86); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$1(MaterializeWorkflowDescriptorActor.scala:86); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2$$anonfun$apply$8.apply(MaterializeWorkflowDescriptorActor.scala:110); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2$$anonfun$apply$8.apply(MaterializeWorkflowDescriptorActor.scala:109); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2.apply(MaterializeWorkflowDescriptorActor.scala:109); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2.apply(MaterializeWorkflowDescriptorActor.scala:103); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:103); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$receive$1.applyOrElse(MaterializeWorkflowDescriptorActor.scala:66); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescrip,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/705
https://github.com/broadinstitute/cromwell/issues/705:3893,Security,Validat,ValidationFlatMap,3893,alizeWorkflowDescriptorActor.scala:86); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2$$anonfun$apply$8.apply(MaterializeWorkflowDescriptorActor.scala:110); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2$$anonfun$apply$8.apply(MaterializeWorkflowDescriptorActor.scala:109); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2.apply(MaterializeWorkflowDescriptorActor.scala:109); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2.apply(MaterializeWorkflowDescriptorActor.scala:103); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:103); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$receive$1.applyOrElse(MaterializeWorkflowDescriptorActor.scala:66); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:59); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke(ActorCell.scala:487); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238); at akka.dispatch.Mailbox.run(Mailbox.scala:220); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQue,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/705
https://github.com/broadinstitute/cromwell/issues/705:3919,Security,Validat,Validation,3919,iptorActor.scala:86); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2$$anonfun$apply$8.apply(MaterializeWorkflowDescriptorActor.scala:110); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2$$anonfun$apply$8.apply(MaterializeWorkflowDescriptorActor.scala:109); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2.apply(MaterializeWorkflowDescriptorActor.scala:109); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor$2.apply(MaterializeWorkflowDescriptorActor.scala:103); at scalaz.ValidationFlatMap.flatMap(Validation.scala:433); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:103); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$receive$1.applyOrElse(MaterializeWorkflowDescriptorActor.scala:66); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:59); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke(ActorCell.scala:487); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238); at akka.dispatch.Mailbox.run(Mailbox.scala:220); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoin,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/705
https://github.com/broadinstitute/cromwell/issues/705:5133,Usability,clear,clear,5133,"ctor.scala:103); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor$$anonfun$receive$1.applyOrElse(MaterializeWorkflowDescriptorActor.scala:66); at akka.actor.Actor$class.aroundReceive(Actor.scala:467); at cromwell.engine.workflow.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:59); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516); at akka.actor.ActorCell.invoke(ActorCell.scala:487); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238); at akka.dispatch.Mailbox.run(Mailbox.scala:220); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```. To a novice user it is not clear whether that this can safely be ignored. This is a problem in particular if this first use actually fails for some other reason. The user will spend time trying to figure out if the problem is caused by a credential issue. I tried to see if I could easily suppress this by setting up ""backends"" to only include ""local"". I pulled down the [application.conf](https://github.com/broadinstitute/cromwell/blob/9f759a54a0b8873f1338f36391f985477d83475a/engine/src/main/resources/application.conf) which sets:. ```; backend {; // Either ""jes"", ""local"", or ""sge"" (case insensitive); defaultBackend = ""local""; // List of backends which this Cromwell supports. Be sure to include the defaultBackend!; backendsAllowed = [ ""local"" ]; ```. and then passed the file as:. `$ java -Dconfig.file=application.conf -jar cromwell.jar run hello.wdl hello.json; `; But the exception and warning were still raised. Should the ADC check be occurring even when backendsAllowed does not include JES?. Thanks.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/705
https://github.com/broadinstitute/cromwell/pull/706:19,Availability,failure,failures,19,"May fix weird test failures. I began getting test failures on my BackendConfiguration branch after I rebased on develop unrelated to anything I had changed. It looks like the workflow from the KV store test is visible to the test that runs after it, which led to more success messages than the assertions expected. Making this a separate PR in case the problem is waiting to bite anyone else.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/706
https://github.com/broadinstitute/cromwell/pull/706:50,Availability,failure,failures,50,"May fix weird test failures. I began getting test failures on my BackendConfiguration branch after I rebased on develop unrelated to anything I had changed. It looks like the workflow from the KV store test is visible to the test that runs after it, which led to more success messages than the assertions expected. Making this a separate PR in case the problem is waiting to bite anyone else.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/706
https://github.com/broadinstitute/cromwell/pull/706:276,Integrability,message,messages,276,"May fix weird test failures. I began getting test failures on my BackendConfiguration branch after I rebased on develop unrelated to anything I had changed. It looks like the workflow from the KV store test is visible to the test that runs after it, which led to more success messages than the assertions expected. Making this a separate PR in case the problem is waiting to bite anyone else.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/706
https://github.com/broadinstitute/cromwell/pull/706:14,Testability,test,test,14,"May fix weird test failures. I began getting test failures on my BackendConfiguration branch after I rebased on develop unrelated to anything I had changed. It looks like the workflow from the KV store test is visible to the test that runs after it, which led to more success messages than the assertions expected. Making this a separate PR in case the problem is waiting to bite anyone else.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/706
https://github.com/broadinstitute/cromwell/pull/706:45,Testability,test,test,45,"May fix weird test failures. I began getting test failures on my BackendConfiguration branch after I rebased on develop unrelated to anything I had changed. It looks like the workflow from the KV store test is visible to the test that runs after it, which led to more success messages than the assertions expected. Making this a separate PR in case the problem is waiting to bite anyone else.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/706
https://github.com/broadinstitute/cromwell/pull/706:202,Testability,test,test,202,"May fix weird test failures. I began getting test failures on my BackendConfiguration branch after I rebased on develop unrelated to anything I had changed. It looks like the workflow from the KV store test is visible to the test that runs after it, which led to more success messages than the assertions expected. Making this a separate PR in case the problem is waiting to bite anyone else.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/706
https://github.com/broadinstitute/cromwell/pull/706:225,Testability,test,test,225,"May fix weird test failures. I began getting test failures on my BackendConfiguration branch after I rebased on develop unrelated to anything I had changed. It looks like the workflow from the KV store test is visible to the test that runs after it, which led to more success messages than the assertions expected. Making this a separate PR in case the problem is waiting to bite anyone else.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/706
https://github.com/broadinstitute/cromwell/pull/706:294,Testability,assert,assertions,294,"May fix weird test failures. I began getting test failures on my BackendConfiguration branch after I rebased on develop unrelated to anything I had changed. It looks like the workflow from the KV store test is visible to the test that runs after it, which led to more success messages than the assertions expected. Making this a separate PR in case the problem is waiting to bite anyone else.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/706
https://github.com/broadinstitute/cromwell/pull/707:69,Integrability,message,messages,69,"To set expectations, this PR sets up shadow mode to actually process messages through the new set of lifecycle actors. It can be seen that submissions return an ID and make it through the `MaterializeWorkflowDescriptor` phase. However not the `Initialize` phase. This is all done in a shadow hierarchy which has not affected the normal operation yet... We still need:; - The part which assigns backends to calls (currently blocked out to happen in `ShadowMaterializeWorkflowDescriptorActor`); - The part which generates actors from backend name strings (blocked out at the bottom of both the `InitializeWorkflowActor` and `FinalizeWorkflowActor`); - The entire `WorkflowExecutionActor`. If you try to run anything in shadow mode, it'll fail in the `InitializeWorkflow` phase with an exception saying that no backend assignments were found.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/707
https://github.com/broadinstitute/cromwell/pull/708:61,Performance,perform,perform,61,"Hi All,; This PR is intended to review the implementation to perform ""runtime attributes"" validation in the backend side. Please, feel free to add any comment/idea that can add value to this.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/708
https://github.com/broadinstitute/cromwell/pull/708:90,Security,validat,validation,90,"Hi All,; This PR is intended to review the implementation to perform ""runtime attributes"" validation in the backend side. Please, feel free to add any comment/idea that can add value to this.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/708
https://github.com/broadinstitute/cromwell/pull/710:83,Modifiability,config,configurable,83,"@jsotobroad the default limit on results for the GCS list API is 1000. I made this configurable and bumped up the default to 50K. That number is basically pulled out of thin air, if you have a more informed suggestion of a good value to use that would be great. 😄 . I still need to figure out the least awkward place to shoehorn the documentation for this value in the README.md.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/710
https://github.com/broadinstitute/cromwell/issues/711:24,Deployability,pipeline,pipeline,24,"I ran the single-sample pipeline on the small (20K bam) and one of the BQSR jobs (BaseRecalibrator.8.retry-1) took much longer than it should (8 hours instead of a few minutes) it was then preempted and replaced by retry-1 which, indeed concluded after a few minutes. . it would be good to know if there are many such instances and if we are being billed for them... [longBQSR.metadata.txt](https://github.com/broadinstitute/cromwell/files/221526/longBQSR.metadata.txt)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/711
https://github.com/broadinstitute/cromwell/pull/712:320,Safety,Abort,Abort,320,"First implementation of a pluggable LocalBackend. This is more a light basic implementation and a starting point to iterate over.; What is implemented : ; - Support for non-docker jobs; - Support for docker jobs; - Support for ""ContinueOnReturnCode"" ""FailOnStderr"" and ""docker"" runtime attributes; - Engine functions; - Abort. Things to think about:; - How to share code between backends ? runtime attributes validation, engine functions, shared filesystem code.. ; - Testing. Note: some code is duplicated from the engine as it's still used by the current non-PBE implementation. Eventually this will replace all local backend code in the engine. Currently adding more tests for ; - [x] abort. ~~\- [ ] engine functions~~; - [x] input localization; - [x] expression evaluation; - [x] coercion ; - [x] scatter",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/712
https://github.com/broadinstitute/cromwell/pull/712:688,Safety,abort,abort,688,"First implementation of a pluggable LocalBackend. This is more a light basic implementation and a starting point to iterate over.; What is implemented : ; - Support for non-docker jobs; - Support for docker jobs; - Support for ""ContinueOnReturnCode"" ""FailOnStderr"" and ""docker"" runtime attributes; - Engine functions; - Abort. Things to think about:; - How to share code between backends ? runtime attributes validation, engine functions, shared filesystem code.. ; - Testing. Note: some code is duplicated from the engine as it's still used by the current non-PBE implementation. Eventually this will replace all local backend code in the engine. Currently adding more tests for ; - [x] abort. ~~\- [ ] engine functions~~; - [x] input localization; - [x] expression evaluation; - [x] coercion ; - [x] scatter",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/712
https://github.com/broadinstitute/cromwell/pull/712:409,Security,validat,validation,409,"First implementation of a pluggable LocalBackend. This is more a light basic implementation and a starting point to iterate over.; What is implemented : ; - Support for non-docker jobs; - Support for docker jobs; - Support for ""ContinueOnReturnCode"" ""FailOnStderr"" and ""docker"" runtime attributes; - Engine functions; - Abort. Things to think about:; - How to share code between backends ? runtime attributes validation, engine functions, shared filesystem code.. ; - Testing. Note: some code is duplicated from the engine as it's still used by the current non-PBE implementation. Eventually this will replace all local backend code in the engine. Currently adding more tests for ; - [x] abort. ~~\- [ ] engine functions~~; - [x] input localization; - [x] expression evaluation; - [x] coercion ; - [x] scatter",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/712
https://github.com/broadinstitute/cromwell/pull/712:468,Testability,Test,Testing,468,"First implementation of a pluggable LocalBackend. This is more a light basic implementation and a starting point to iterate over.; What is implemented : ; - Support for non-docker jobs; - Support for docker jobs; - Support for ""ContinueOnReturnCode"" ""FailOnStderr"" and ""docker"" runtime attributes; - Engine functions; - Abort. Things to think about:; - How to share code between backends ? runtime attributes validation, engine functions, shared filesystem code.. ; - Testing. Note: some code is duplicated from the engine as it's still used by the current non-PBE implementation. Eventually this will replace all local backend code in the engine. Currently adding more tests for ; - [x] abort. ~~\- [ ] engine functions~~; - [x] input localization; - [x] expression evaluation; - [x] coercion ; - [x] scatter",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/712
https://github.com/broadinstitute/cromwell/pull/712:670,Testability,test,tests,670,"First implementation of a pluggable LocalBackend. This is more a light basic implementation and a starting point to iterate over.; What is implemented : ; - Support for non-docker jobs; - Support for docker jobs; - Support for ""ContinueOnReturnCode"" ""FailOnStderr"" and ""docker"" runtime attributes; - Engine functions; - Abort. Things to think about:; - How to share code between backends ? runtime attributes validation, engine functions, shared filesystem code.. ; - Testing. Note: some code is duplicated from the engine as it's still used by the current non-PBE implementation. Eventually this will replace all local backend code in the engine. Currently adding more tests for ; - [x] abort. ~~\- [ ] engine functions~~; - [x] input localization; - [x] expression evaluation; - [x] coercion ; - [x] scatter",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/712
https://github.com/broadinstitute/cromwell/pull/715:72,Deployability,Update,Updated,72,"Added Docker specification content types to the manifest unmarshaller.; Updated spec for testing GCR w/o authentication, as cromwell's Google Credentials utility now automatically detects the application default credentials on a system.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/715
https://github.com/broadinstitute/cromwell/pull/715:180,Safety,detect,detects,180,"Added Docker specification content types to the manifest unmarshaller.; Updated spec for testing GCR w/o authentication, as cromwell's Google Credentials utility now automatically detects the application default credentials on a system.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/715
https://github.com/broadinstitute/cromwell/pull/715:105,Security,authenticat,authentication,105,"Added Docker specification content types to the manifest unmarshaller.; Updated spec for testing GCR w/o authentication, as cromwell's Google Credentials utility now automatically detects the application default credentials on a system.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/715
https://github.com/broadinstitute/cromwell/pull/715:89,Testability,test,testing,89,"Added Docker specification content types to the manifest unmarshaller.; Updated spec for testing GCR w/o authentication, as cromwell's Google Credentials utility now automatically detects the application default credentials on a system.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/715
https://github.com/broadinstitute/cromwell/pull/720:214,Modifiability,evolve,evolve,214,To set expectations:; - Demonstrates the ShadowWorkflowActor progressing through every lifecycle state; - Hard-codes the DummyBackend for every call; - Doesn't store anything persistently; - Will certainly need to evolve from here...,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/720
https://github.com/broadinstitute/cromwell/pull/721:6,Testability,test,tests,6,MySQL tests are no longer optional when running DbmsTests.; Removed duplicate hsqldb test.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/721
https://github.com/broadinstitute/cromwell/pull/721:85,Testability,test,test,85,MySQL tests are no longer optional when running DbmsTests.; Removed duplicate hsqldb test.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/721
https://github.com/broadinstitute/cromwell/issues/724:29,Modifiability,config,configurable,29,Make backends default values configurable,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/724
https://github.com/broadinstitute/cromwell/issues/725:353,Testability,log,log,353,"Class: BackendWorkflowInitializationActor; Line: 115; Function: evaluateRuntimeAttributesWdlExpressions; Code: TryUtils.sequenceMap(evaluateAttrs, ""Runtime attributes evaluation"").get. This line is producing an exception when it cannot evaluate an expression in runtime attributes.; There are open questions to work on:; Should this catch exception and log or just fail here?; If the case it catch the exception and log, should this return 'InitializationSuccess' after that? or just fail and return a InitializationFailed?. Use case: task1 output is the input for task2 and that value is used within RuntimeAttributes."". One this is solve, enable ignored test case.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/725
https://github.com/broadinstitute/cromwell/issues/725:416,Testability,log,log,416,"Class: BackendWorkflowInitializationActor; Line: 115; Function: evaluateRuntimeAttributesWdlExpressions; Code: TryUtils.sequenceMap(evaluateAttrs, ""Runtime attributes evaluation"").get. This line is producing an exception when it cannot evaluate an expression in runtime attributes.; There are open questions to work on:; Should this catch exception and log or just fail here?; If the case it catch the exception and log, should this return 'InitializationSuccess' after that? or just fail and return a InitializationFailed?. Use case: task1 output is the input for task2 and that value is used within RuntimeAttributes."". One this is solve, enable ignored test case.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/725
https://github.com/broadinstitute/cromwell/issues/725:656,Testability,test,test,656,"Class: BackendWorkflowInitializationActor; Line: 115; Function: evaluateRuntimeAttributesWdlExpressions; Code: TryUtils.sequenceMap(evaluateAttrs, ""Runtime attributes evaluation"").get. This line is producing an exception when it cannot evaluate an expression in runtime attributes.; There are open questions to work on:; Should this catch exception and log or just fail here?; If the case it catch the exception and log, should this return 'InitializationSuccess' after that? or just fail and return a InitializationFailed?. Use case: task1 output is the input for task2 and that value is used within RuntimeAttributes."". One this is solve, enable ignored test case.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/725
https://github.com/broadinstitute/cromwell/issues/726:18,Security,validat,validation,18,"Once wdl4s memory validation removal PR is merge, enable ignored unit test cases and create missing one if there is one for this functionality.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/726
https://github.com/broadinstitute/cromwell/issues/726:70,Testability,test,test,70,"Once wdl4s memory validation removal PR is merge, enable ignored unit test cases and create missing one if there is one for this functionality.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/726
https://github.com/broadinstitute/cromwell/pull/727:0,Deployability,Update,Updated,0,"Updated the travis configuration to again use copy-only localization.; As the other localizers were previously broken, travis was _only_ able to run copy.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/727
https://github.com/broadinstitute/cromwell/pull/727:19,Deployability,configurat,configuration,19,"Updated the travis configuration to again use copy-only localization.; As the other localizers were previously broken, travis was _only_ able to run copy.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/727
https://github.com/broadinstitute/cromwell/pull/727:19,Modifiability,config,configuration,19,"Updated the travis configuration to again use copy-only localization.; As the other localizers were previously broken, travis was _only_ able to run copy.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/727
https://github.com/broadinstitute/cromwell/pull/728:22,Modifiability,config,config,22,Added an undocumented config option to tweak this value if we need to adjust it for further testing.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/728
https://github.com/broadinstitute/cromwell/pull/728:92,Testability,test,testing,92,Added an undocumented config option to tweak this value if we need to adjust it for further testing.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/728
https://github.com/broadinstitute/cromwell/pull/728:9,Usability,undo,undocumented,9,Added an undocumented config option to tweak this value if we need to adjust it for further testing.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/728
https://github.com/broadinstitute/cromwell/issues/730:9,Deployability,configurat,configuration,9,"Based on configuration (`shadowExecutionEnabled`), initialize the appropriate WorkflowManagerActor for both the CromwellServer mode and for command line execution.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/730
https://github.com/broadinstitute/cromwell/issues/730:9,Modifiability,config,configuration,9,"Based on configuration (`shadowExecutionEnabled`), initialize the appropriate WorkflowManagerActor for both the CromwellServer mode and for command line execution.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/730
https://github.com/broadinstitute/cromwell/issues/731:118,Availability,error,error,118,"I run a short bash pipeline like this : for CHROM in `cut -f1 $IN_FILE |grep -Pv '^@'| sort|uniq`; do. But I get this error : sort: cannot create temporary file in ‘/cromwell_root/tmp’: No such file or directory. when running in firecloud. should I ""mkdir -pv /cromwell_root/tmp"" first?. I see ""export TMPDIR=/cromwell_root/tmp"" in the exec.sh on the 3rd line.... I went ahead and issued before the pipeline starts the command ""mkdir -pv $TMPDIR"" and made the error go away!. Is it normal/expected to need to create TMPDIR ?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/731
https://github.com/broadinstitute/cromwell/issues/731:460,Availability,error,error,460,"I run a short bash pipeline like this : for CHROM in `cut -f1 $IN_FILE |grep -Pv '^@'| sort|uniq`; do. But I get this error : sort: cannot create temporary file in ‘/cromwell_root/tmp’: No such file or directory. when running in firecloud. should I ""mkdir -pv /cromwell_root/tmp"" first?. I see ""export TMPDIR=/cromwell_root/tmp"" in the exec.sh on the 3rd line.... I went ahead and issued before the pipeline starts the command ""mkdir -pv $TMPDIR"" and made the error go away!. Is it normal/expected to need to create TMPDIR ?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/731
https://github.com/broadinstitute/cromwell/issues/731:19,Deployability,pipeline,pipeline,19,"I run a short bash pipeline like this : for CHROM in `cut -f1 $IN_FILE |grep -Pv '^@'| sort|uniq`; do. But I get this error : sort: cannot create temporary file in ‘/cromwell_root/tmp’: No such file or directory. when running in firecloud. should I ""mkdir -pv /cromwell_root/tmp"" first?. I see ""export TMPDIR=/cromwell_root/tmp"" in the exec.sh on the 3rd line.... I went ahead and issued before the pipeline starts the command ""mkdir -pv $TMPDIR"" and made the error go away!. Is it normal/expected to need to create TMPDIR ?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/731
https://github.com/broadinstitute/cromwell/issues/731:399,Deployability,pipeline,pipeline,399,"I run a short bash pipeline like this : for CHROM in `cut -f1 $IN_FILE |grep -Pv '^@'| sort|uniq`; do. But I get this error : sort: cannot create temporary file in ‘/cromwell_root/tmp’: No such file or directory. when running in firecloud. should I ""mkdir -pv /cromwell_root/tmp"" first?. I see ""export TMPDIR=/cromwell_root/tmp"" in the exec.sh on the 3rd line.... I went ahead and issued before the pipeline starts the command ""mkdir -pv $TMPDIR"" and made the error go away!. Is it normal/expected to need to create TMPDIR ?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/731
https://github.com/broadinstitute/cromwell/pull/732:252,Integrability,rout,route,252,"Changes from `cjl_dummyWireThrough` were overwritten by Miguel's BackendConfig branch probably during a rebase. Bringing that functionality back here. This will enable to submit a Workflow using the Cromwell Server and execute it via the new execution route if the `shadowExecutionEnabled` config property is set to true. . `SingleWorkflowRunnerActor` (and hence a submission via command line route) hasn't been modified, since it requires a whole other set of commands / responses to track / emit output for a particular WF, possibly in all of the Shadow series actors.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/732
https://github.com/broadinstitute/cromwell/pull/732:393,Integrability,rout,route,393,"Changes from `cjl_dummyWireThrough` were overwritten by Miguel's BackendConfig branch probably during a rebase. Bringing that functionality back here. This will enable to submit a Workflow using the Cromwell Server and execute it via the new execution route if the `shadowExecutionEnabled` config property is set to true. . `SingleWorkflowRunnerActor` (and hence a submission via command line route) hasn't been modified, since it requires a whole other set of commands / responses to track / emit output for a particular WF, possibly in all of the Shadow series actors.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/732
https://github.com/broadinstitute/cromwell/pull/732:290,Modifiability,config,config,290,"Changes from `cjl_dummyWireThrough` were overwritten by Miguel's BackendConfig branch probably during a rebase. Bringing that functionality back here. This will enable to submit a Workflow using the Cromwell Server and execute it via the new execution route if the `shadowExecutionEnabled` config property is set to true. . `SingleWorkflowRunnerActor` (and hence a submission via command line route) hasn't been modified, since it requires a whole other set of commands / responses to track / emit output for a particular WF, possibly in all of the Shadow series actors.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/732
https://github.com/broadinstitute/cromwell/pull/733:22,Modifiability,config,config,22,Added an undocumented config option to tweak this value if we need to adjust it for further testing.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/733
https://github.com/broadinstitute/cromwell/pull/733:92,Testability,test,testing,92,Added an undocumented config option to tweak this value if we need to adjust it for further testing.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/733
https://github.com/broadinstitute/cromwell/pull/733:9,Usability,undo,undocumented,9,Added an undocumented config option to tweak this value if we need to adjust it for further testing.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/733
https://github.com/broadinstitute/cromwell/issues/735:797,Availability,ERROR,ERROR,797,"When running our joint genotyping workflow, after when starting workflows, we run into an array out of bounds index exception that references a histogram. This causes the machine to become locked up because all cpu resources are being used and then weirdness ensues. ![image](https://cloud.githubusercontent.com/assets/13023616/14790046/781a034a-0add-11e6-90b4-05df4ff61433.png). ```; 2016-04-22 04:01:20,697 cromwell-system-akka.actor.default-dispatcher-36 INFO - WorkflowActor [UUID(1f5b729c)]: starting calls: JointGenotyping.TabixAndGenotypeGVCF; 2016-04-22 04:01:20,697 cromwell-system-akka.actor.default-dispatcher-36 INFO - WorkflowActor [UUID(1f5b729c)]: persisting status of TabixAndGenotypeGVCF:2596 to Starting.; 2016-04-22 04:01:20,703 cromwell-system-akka.actor.default-dispatcher-21 ERROR - Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-41]; java.lang.ArrayIndexOutOfBoundsException: value outside of histogram covered range. Caused by: java.lang.IndexOutOfBoundsException: index 4737; at org.HdrHistogram.AbstractHistogram.handleRecordException(AbstractHistogram.java:441) ~[cromwell.jar:0.19]; at org.HdrHistogram.AbstractHistogram.recordSingleValue(AbstractHistogram.java:433) ~[cromwell.jar:0.19]; at org.HdrHistogram.AbstractHistogram.recordValue(AbstractHistogram.java:346) ~[cromwell.jar:0.19]; at kamon.metric.instrument.HdrHistogram.record(Histogram.scala:115) ~[cromwell.jar:0.19]; at akka.kamon.instrumentation.ActorCellInstrumentation.aroundBehaviourInvoke(ActorCellInstrumentation.scala:69) ~[cromwell.jar:0.19]; at akka.actor.ActorCell.invoke(ActorCell.scala:483) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.run(Mailbox.scala:220) [cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/735
https://github.com/broadinstitute/cromwell/issues/735:814,Availability,error,error,814,"When running our joint genotyping workflow, after when starting workflows, we run into an array out of bounds index exception that references a histogram. This causes the machine to become locked up because all cpu resources are being used and then weirdness ensues. ![image](https://cloud.githubusercontent.com/assets/13023616/14790046/781a034a-0add-11e6-90b4-05df4ff61433.png). ```; 2016-04-22 04:01:20,697 cromwell-system-akka.actor.default-dispatcher-36 INFO - WorkflowActor [UUID(1f5b729c)]: starting calls: JointGenotyping.TabixAndGenotypeGVCF; 2016-04-22 04:01:20,697 cromwell-system-akka.actor.default-dispatcher-36 INFO - WorkflowActor [UUID(1f5b729c)]: persisting status of TabixAndGenotypeGVCF:2596 to Starting.; 2016-04-22 04:01:20,703 cromwell-system-akka.actor.default-dispatcher-21 ERROR - Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-41]; java.lang.ArrayIndexOutOfBoundsException: value outside of histogram covered range. Caused by: java.lang.IndexOutOfBoundsException: index 4737; at org.HdrHistogram.AbstractHistogram.handleRecordException(AbstractHistogram.java:441) ~[cromwell.jar:0.19]; at org.HdrHistogram.AbstractHistogram.recordSingleValue(AbstractHistogram.java:433) ~[cromwell.jar:0.19]; at org.HdrHistogram.AbstractHistogram.recordValue(AbstractHistogram.java:346) ~[cromwell.jar:0.19]; at kamon.metric.instrument.HdrHistogram.record(Histogram.scala:115) ~[cromwell.jar:0.19]; at akka.kamon.instrumentation.ActorCellInstrumentation.aroundBehaviourInvoke(ActorCellInstrumentation.scala:69) ~[cromwell.jar:0.19]; at akka.actor.ActorCell.invoke(ActorCell.scala:483) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.run(Mailbox.scala:220) [cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/735
https://github.com/broadinstitute/cromwell/issues/735:1918,Performance,concurren,concurrent,1918,"ssets/13023616/14790046/781a034a-0add-11e6-90b4-05df4ff61433.png). ```; 2016-04-22 04:01:20,697 cromwell-system-akka.actor.default-dispatcher-36 INFO - WorkflowActor [UUID(1f5b729c)]: starting calls: JointGenotyping.TabixAndGenotypeGVCF; 2016-04-22 04:01:20,697 cromwell-system-akka.actor.default-dispatcher-36 INFO - WorkflowActor [UUID(1f5b729c)]: persisting status of TabixAndGenotypeGVCF:2596 to Starting.; 2016-04-22 04:01:20,703 cromwell-system-akka.actor.default-dispatcher-21 ERROR - Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-41]; java.lang.ArrayIndexOutOfBoundsException: value outside of histogram covered range. Caused by: java.lang.IndexOutOfBoundsException: index 4737; at org.HdrHistogram.AbstractHistogram.handleRecordException(AbstractHistogram.java:441) ~[cromwell.jar:0.19]; at org.HdrHistogram.AbstractHistogram.recordSingleValue(AbstractHistogram.java:433) ~[cromwell.jar:0.19]; at org.HdrHistogram.AbstractHistogram.recordValue(AbstractHistogram.java:346) ~[cromwell.jar:0.19]; at kamon.metric.instrument.HdrHistogram.record(Histogram.scala:115) ~[cromwell.jar:0.19]; at akka.kamon.instrumentation.ActorCellInstrumentation.aroundBehaviourInvoke(ActorCellInstrumentation.scala:69) ~[cromwell.jar:0.19]; at akka.actor.ActorCell.invoke(ActorCell.scala:483) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.run(Mailbox.scala:220) [cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/735
https://github.com/broadinstitute/cromwell/issues/735:2011,Performance,concurren,concurrent,2011,"ssets/13023616/14790046/781a034a-0add-11e6-90b4-05df4ff61433.png). ```; 2016-04-22 04:01:20,697 cromwell-system-akka.actor.default-dispatcher-36 INFO - WorkflowActor [UUID(1f5b729c)]: starting calls: JointGenotyping.TabixAndGenotypeGVCF; 2016-04-22 04:01:20,697 cromwell-system-akka.actor.default-dispatcher-36 INFO - WorkflowActor [UUID(1f5b729c)]: persisting status of TabixAndGenotypeGVCF:2596 to Starting.; 2016-04-22 04:01:20,703 cromwell-system-akka.actor.default-dispatcher-21 ERROR - Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-41]; java.lang.ArrayIndexOutOfBoundsException: value outside of histogram covered range. Caused by: java.lang.IndexOutOfBoundsException: index 4737; at org.HdrHistogram.AbstractHistogram.handleRecordException(AbstractHistogram.java:441) ~[cromwell.jar:0.19]; at org.HdrHistogram.AbstractHistogram.recordSingleValue(AbstractHistogram.java:433) ~[cromwell.jar:0.19]; at org.HdrHistogram.AbstractHistogram.recordValue(AbstractHistogram.java:346) ~[cromwell.jar:0.19]; at kamon.metric.instrument.HdrHistogram.record(Histogram.scala:115) ~[cromwell.jar:0.19]; at akka.kamon.instrumentation.ActorCellInstrumentation.aroundBehaviourInvoke(ActorCellInstrumentation.scala:69) ~[cromwell.jar:0.19]; at akka.actor.ActorCell.invoke(ActorCell.scala:483) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.run(Mailbox.scala:220) [cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/735
https://github.com/broadinstitute/cromwell/issues/735:2116,Performance,concurren,concurrent,2116,"ssets/13023616/14790046/781a034a-0add-11e6-90b4-05df4ff61433.png). ```; 2016-04-22 04:01:20,697 cromwell-system-akka.actor.default-dispatcher-36 INFO - WorkflowActor [UUID(1f5b729c)]: starting calls: JointGenotyping.TabixAndGenotypeGVCF; 2016-04-22 04:01:20,697 cromwell-system-akka.actor.default-dispatcher-36 INFO - WorkflowActor [UUID(1f5b729c)]: persisting status of TabixAndGenotypeGVCF:2596 to Starting.; 2016-04-22 04:01:20,703 cromwell-system-akka.actor.default-dispatcher-21 ERROR - Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-41]; java.lang.ArrayIndexOutOfBoundsException: value outside of histogram covered range. Caused by: java.lang.IndexOutOfBoundsException: index 4737; at org.HdrHistogram.AbstractHistogram.handleRecordException(AbstractHistogram.java:441) ~[cromwell.jar:0.19]; at org.HdrHistogram.AbstractHistogram.recordSingleValue(AbstractHistogram.java:433) ~[cromwell.jar:0.19]; at org.HdrHistogram.AbstractHistogram.recordValue(AbstractHistogram.java:346) ~[cromwell.jar:0.19]; at kamon.metric.instrument.HdrHistogram.record(Histogram.scala:115) ~[cromwell.jar:0.19]; at akka.kamon.instrumentation.ActorCellInstrumentation.aroundBehaviourInvoke(ActorCellInstrumentation.scala:69) ~[cromwell.jar:0.19]; at akka.actor.ActorCell.invoke(ActorCell.scala:483) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.run(Mailbox.scala:220) [cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/735
https://github.com/broadinstitute/cromwell/issues/735:2213,Performance,concurren,concurrent,2213,"ssets/13023616/14790046/781a034a-0add-11e6-90b4-05df4ff61433.png). ```; 2016-04-22 04:01:20,697 cromwell-system-akka.actor.default-dispatcher-36 INFO - WorkflowActor [UUID(1f5b729c)]: starting calls: JointGenotyping.TabixAndGenotypeGVCF; 2016-04-22 04:01:20,697 cromwell-system-akka.actor.default-dispatcher-36 INFO - WorkflowActor [UUID(1f5b729c)]: persisting status of TabixAndGenotypeGVCF:2596 to Starting.; 2016-04-22 04:01:20,703 cromwell-system-akka.actor.default-dispatcher-21 ERROR - Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-41]; java.lang.ArrayIndexOutOfBoundsException: value outside of histogram covered range. Caused by: java.lang.IndexOutOfBoundsException: index 4737; at org.HdrHistogram.AbstractHistogram.handleRecordException(AbstractHistogram.java:441) ~[cromwell.jar:0.19]; at org.HdrHistogram.AbstractHistogram.recordSingleValue(AbstractHistogram.java:433) ~[cromwell.jar:0.19]; at org.HdrHistogram.AbstractHistogram.recordValue(AbstractHistogram.java:346) ~[cromwell.jar:0.19]; at kamon.metric.instrument.HdrHistogram.record(Histogram.scala:115) ~[cromwell.jar:0.19]; at akka.kamon.instrumentation.ActorCellInstrumentation.aroundBehaviourInvoke(ActorCellInstrumentation.scala:69) ~[cromwell.jar:0.19]; at akka.actor.ActorCell.invoke(ActorCell.scala:483) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238) [cromwell.jar:0.19]; at akka.dispatch.Mailbox.run(Mailbox.scala:220) [cromwell.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/735
https://github.com/broadinstitute/cromwell/issues/737:953,Availability,failure,failures,953,"The following workflow failed in cromwell (4ef40f07-ff52-426b-9610-3c9dc66ec67e) on production. Looking metadata we have no logs for the step that failed. ```; {; ""executionStatus"": ""Failed"",; ""shardIndex"": 5,; ""outputs"": {. },; ""runtimeAttributes"": {. },; ""cache"": {; ""allowResultReuse"": true; },; ""inputs"": {; ""input_bam"": ""SortAndFixSampleBam.output_bam"",; ""ref_fasta"": ""ref_fasta"",; ""ref_dict"": ""ref_dict"",; ""disk_size"": ""agg_medium_disk"",; ""dbSNP_vcf"": ""dbSNP_vcf"",; ""known_snps_sites_vcf"": ""known_snps_sites_vcf"",; ""dbSNP_vcf_index"": ""dbSNP_vcf_index"",; ""known_indels_sites_vcf_index"": ""known_indels_sites_vcf_index"",; ""input_bam_index"": ""SortAndFixSampleBam.output_bam_index"",; ""recalibration_report_filename"": ""sample_name + \"".recal_data.csv\"""",; ""known_snps_sites_vcf_index"": ""known_snps_sites_vcf_index"",; ""ref_fasta_index"": ""ref_fasta_index"",; ""sequence_group_interval"": ""subgroup"",; ""known_indels_sites_vcf"": ""known_indels_sites_vcf""; },; ""failures"": [{; ""failure"": ""Call failed to initialize: Could not persist runtime attributes: Timeout after 5059ms of waiting for a connection."",; ""timestamp"": ""2016-04-23T09:14:54.651Z""; }],; ""backend"": ""JES"",; ""end"": ""2016-04-23T09:14:56.000Z"",; ""attempt"": 1,; ""executionEvents"": [],; ""start"": ""2016-04-23T09:14:45.000Z""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/737
https://github.com/broadinstitute/cromwell/issues/737:969,Availability,failure,failure,969,"The following workflow failed in cromwell (4ef40f07-ff52-426b-9610-3c9dc66ec67e) on production. Looking metadata we have no logs for the step that failed. ```; {; ""executionStatus"": ""Failed"",; ""shardIndex"": 5,; ""outputs"": {. },; ""runtimeAttributes"": {. },; ""cache"": {; ""allowResultReuse"": true; },; ""inputs"": {; ""input_bam"": ""SortAndFixSampleBam.output_bam"",; ""ref_fasta"": ""ref_fasta"",; ""ref_dict"": ""ref_dict"",; ""disk_size"": ""agg_medium_disk"",; ""dbSNP_vcf"": ""dbSNP_vcf"",; ""known_snps_sites_vcf"": ""known_snps_sites_vcf"",; ""dbSNP_vcf_index"": ""dbSNP_vcf_index"",; ""known_indels_sites_vcf_index"": ""known_indels_sites_vcf_index"",; ""input_bam_index"": ""SortAndFixSampleBam.output_bam_index"",; ""recalibration_report_filename"": ""sample_name + \"".recal_data.csv\"""",; ""known_snps_sites_vcf_index"": ""known_snps_sites_vcf_index"",; ""ref_fasta_index"": ""ref_fasta_index"",; ""sequence_group_interval"": ""subgroup"",; ""known_indels_sites_vcf"": ""known_indels_sites_vcf""; },; ""failures"": [{; ""failure"": ""Call failed to initialize: Could not persist runtime attributes: Timeout after 5059ms of waiting for a connection."",; ""timestamp"": ""2016-04-23T09:14:54.651Z""; }],; ""backend"": ""JES"",; ""end"": ""2016-04-23T09:14:56.000Z"",; ""attempt"": 1,; ""executionEvents"": [],; ""start"": ""2016-04-23T09:14:45.000Z""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/737
https://github.com/broadinstitute/cromwell/issues/737:258,Performance,cache,cache,258,"The following workflow failed in cromwell (4ef40f07-ff52-426b-9610-3c9dc66ec67e) on production. Looking metadata we have no logs for the step that failed. ```; {; ""executionStatus"": ""Failed"",; ""shardIndex"": 5,; ""outputs"": {. },; ""runtimeAttributes"": {. },; ""cache"": {; ""allowResultReuse"": true; },; ""inputs"": {; ""input_bam"": ""SortAndFixSampleBam.output_bam"",; ""ref_fasta"": ""ref_fasta"",; ""ref_dict"": ""ref_dict"",; ""disk_size"": ""agg_medium_disk"",; ""dbSNP_vcf"": ""dbSNP_vcf"",; ""known_snps_sites_vcf"": ""known_snps_sites_vcf"",; ""dbSNP_vcf_index"": ""dbSNP_vcf_index"",; ""known_indels_sites_vcf_index"": ""known_indels_sites_vcf_index"",; ""input_bam_index"": ""SortAndFixSampleBam.output_bam_index"",; ""recalibration_report_filename"": ""sample_name + \"".recal_data.csv\"""",; ""known_snps_sites_vcf_index"": ""known_snps_sites_vcf_index"",; ""ref_fasta_index"": ""ref_fasta_index"",; ""sequence_group_interval"": ""subgroup"",; ""known_indels_sites_vcf"": ""known_indels_sites_vcf""; },; ""failures"": [{; ""failure"": ""Call failed to initialize: Could not persist runtime attributes: Timeout after 5059ms of waiting for a connection."",; ""timestamp"": ""2016-04-23T09:14:54.651Z""; }],; ""backend"": ""JES"",; ""end"": ""2016-04-23T09:14:56.000Z"",; ""attempt"": 1,; ""executionEvents"": [],; ""start"": ""2016-04-23T09:14:45.000Z""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/737
https://github.com/broadinstitute/cromwell/issues/737:1045,Safety,Timeout,Timeout,1045,"The following workflow failed in cromwell (4ef40f07-ff52-426b-9610-3c9dc66ec67e) on production. Looking metadata we have no logs for the step that failed. ```; {; ""executionStatus"": ""Failed"",; ""shardIndex"": 5,; ""outputs"": {. },; ""runtimeAttributes"": {. },; ""cache"": {; ""allowResultReuse"": true; },; ""inputs"": {; ""input_bam"": ""SortAndFixSampleBam.output_bam"",; ""ref_fasta"": ""ref_fasta"",; ""ref_dict"": ""ref_dict"",; ""disk_size"": ""agg_medium_disk"",; ""dbSNP_vcf"": ""dbSNP_vcf"",; ""known_snps_sites_vcf"": ""known_snps_sites_vcf"",; ""dbSNP_vcf_index"": ""dbSNP_vcf_index"",; ""known_indels_sites_vcf_index"": ""known_indels_sites_vcf_index"",; ""input_bam_index"": ""SortAndFixSampleBam.output_bam_index"",; ""recalibration_report_filename"": ""sample_name + \"".recal_data.csv\"""",; ""known_snps_sites_vcf_index"": ""known_snps_sites_vcf_index"",; ""ref_fasta_index"": ""ref_fasta_index"",; ""sequence_group_interval"": ""subgroup"",; ""known_indels_sites_vcf"": ""known_indels_sites_vcf""; },; ""failures"": [{; ""failure"": ""Call failed to initialize: Could not persist runtime attributes: Timeout after 5059ms of waiting for a connection."",; ""timestamp"": ""2016-04-23T09:14:54.651Z""; }],; ""backend"": ""JES"",; ""end"": ""2016-04-23T09:14:56.000Z"",; ""attempt"": 1,; ""executionEvents"": [],; ""start"": ""2016-04-23T09:14:45.000Z""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/737
https://github.com/broadinstitute/cromwell/issues/737:124,Testability,log,logs,124,"The following workflow failed in cromwell (4ef40f07-ff52-426b-9610-3c9dc66ec67e) on production. Looking metadata we have no logs for the step that failed. ```; {; ""executionStatus"": ""Failed"",; ""shardIndex"": 5,; ""outputs"": {. },; ""runtimeAttributes"": {. },; ""cache"": {; ""allowResultReuse"": true; },; ""inputs"": {; ""input_bam"": ""SortAndFixSampleBam.output_bam"",; ""ref_fasta"": ""ref_fasta"",; ""ref_dict"": ""ref_dict"",; ""disk_size"": ""agg_medium_disk"",; ""dbSNP_vcf"": ""dbSNP_vcf"",; ""known_snps_sites_vcf"": ""known_snps_sites_vcf"",; ""dbSNP_vcf_index"": ""dbSNP_vcf_index"",; ""known_indels_sites_vcf_index"": ""known_indels_sites_vcf_index"",; ""input_bam_index"": ""SortAndFixSampleBam.output_bam_index"",; ""recalibration_report_filename"": ""sample_name + \"".recal_data.csv\"""",; ""known_snps_sites_vcf_index"": ""known_snps_sites_vcf_index"",; ""ref_fasta_index"": ""ref_fasta_index"",; ""sequence_group_interval"": ""subgroup"",; ""known_indels_sites_vcf"": ""known_indels_sites_vcf""; },; ""failures"": [{; ""failure"": ""Call failed to initialize: Could not persist runtime attributes: Timeout after 5059ms of waiting for a connection."",; ""timestamp"": ""2016-04-23T09:14:54.651Z""; }],; ""backend"": ""JES"",; ""end"": ""2016-04-23T09:14:56.000Z"",; ""attempt"": 1,; ""executionEvents"": [],; ""start"": ""2016-04-23T09:14:45.000Z""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/737
https://github.com/broadinstitute/cromwell/issues/738:1146,Availability,failure,failures,1146,"The following workflow failed in cromwell (3da6e34e-a2a1-49fb-8a84-4d62aada9b3d) on production. . ```; {; ""preemptible"": true,; ""executionStatus"": ""Failed"",; ""stdout"": ""gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/3da6e34e-a2a1-49fb-8a84-4d62aada9b3d/call-ApplyBQSR/shard-15/ApplyBQSR-15-stdout.log"",; ""backendStatus"": ""Success"",; ""shardIndex"": 15,; ""outputs"": {. },; ""runtimeAttributes"": {; ""preemptible"": ""3"",; ""failOnStderr"": ""false"",; ""bootDiskSizeGb"": ""10"",; ""disks"": ""local-disk 200 HDD"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""broadinstitute/genomes-in-the-cloud:2.0.0"",; ""cpu"": ""1"",; ""zones"": ""us-central1-c"",; ""memory"": ""3.5 GB""; },; ""cache"": {; ""allowResultReuse"": true; },; ""inputs"": {; ""input_bam"": ""SortAndFixSampleBam.output_bam"",; ""ref_fasta"": ""ref_fasta"",; ""ref_dict"": ""ref_dict"",; ""recalibration_report"": ""GatherBqsrReports.output_bqsr_report"",; ""disk_size"": ""agg_medium_disk"",; ""output_bam_basename"": ""recalibrated_bam_basename"",; ""input_bam_index"": ""SortAndFixSampleBam.output_bam_index"",; ""ref_fasta_index"": ""ref_fasta_index"",; ""sequence_group_interval"": ""subgroup""; },; ""returnCode"": 0,; ""failures"": [{; ""failure"": ""Read timed out"",; ""timestamp"": ""2016-04-23T18:29:53.764Z""; }],; ""jobId"": ""operations/EK2_jqLEKhiCmbzn296gnv4BIJ-ikOmeDSoPcHJvZHVjdGlvblF1ZXVl"",; ""backend"": ""JES"",; ""end"": ""2016-04-23T18:29:54.000Z"",; ""stderr"": ""gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/3da6e34e-a2a1-49fb-8a84-4d62aada9b3d/call-ApplyBQSR/shard-15/ApplyBQSR-15-stderr.log"",; ""attempt"": 1,; ""executionEvents"": [],; ""backendLogs"": {; ""log"": ""gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/3da6e34e-a2a1-49fb-8a84-4d62aada9b3d/call-ApplyBQSR/shard-15/ApplyBQSR-15.log""; },; ""start"": ""2016-04-23T17:56:02.000Z""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/738
https://github.com/broadinstitute/cromwell/issues/738:1162,Availability,failure,failure,1162,"The following workflow failed in cromwell (3da6e34e-a2a1-49fb-8a84-4d62aada9b3d) on production. . ```; {; ""preemptible"": true,; ""executionStatus"": ""Failed"",; ""stdout"": ""gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/3da6e34e-a2a1-49fb-8a84-4d62aada9b3d/call-ApplyBQSR/shard-15/ApplyBQSR-15-stdout.log"",; ""backendStatus"": ""Success"",; ""shardIndex"": 15,; ""outputs"": {. },; ""runtimeAttributes"": {; ""preemptible"": ""3"",; ""failOnStderr"": ""false"",; ""bootDiskSizeGb"": ""10"",; ""disks"": ""local-disk 200 HDD"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""broadinstitute/genomes-in-the-cloud:2.0.0"",; ""cpu"": ""1"",; ""zones"": ""us-central1-c"",; ""memory"": ""3.5 GB""; },; ""cache"": {; ""allowResultReuse"": true; },; ""inputs"": {; ""input_bam"": ""SortAndFixSampleBam.output_bam"",; ""ref_fasta"": ""ref_fasta"",; ""ref_dict"": ""ref_dict"",; ""recalibration_report"": ""GatherBqsrReports.output_bqsr_report"",; ""disk_size"": ""agg_medium_disk"",; ""output_bam_basename"": ""recalibrated_bam_basename"",; ""input_bam_index"": ""SortAndFixSampleBam.output_bam_index"",; ""ref_fasta_index"": ""ref_fasta_index"",; ""sequence_group_interval"": ""subgroup""; },; ""returnCode"": 0,; ""failures"": [{; ""failure"": ""Read timed out"",; ""timestamp"": ""2016-04-23T18:29:53.764Z""; }],; ""jobId"": ""operations/EK2_jqLEKhiCmbzn296gnv4BIJ-ikOmeDSoPcHJvZHVjdGlvblF1ZXVl"",; ""backend"": ""JES"",; ""end"": ""2016-04-23T18:29:54.000Z"",; ""stderr"": ""gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/3da6e34e-a2a1-49fb-8a84-4d62aada9b3d/call-ApplyBQSR/shard-15/ApplyBQSR-15-stderr.log"",; ""attempt"": 1,; ""executionEvents"": [],; ""backendLogs"": {; ""log"": ""gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/3da6e34e-a2a1-49fb-8a84-4d62aada9b3d/call-ApplyBQSR/shard-15/ApplyBQSR-15.log""; },; ""start"": ""2016-04-23T17:56:02.000Z""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/738
https://github.com/broadinstitute/cromwell/issues/738:680,Performance,cache,cache,680,"The following workflow failed in cromwell (3da6e34e-a2a1-49fb-8a84-4d62aada9b3d) on production. . ```; {; ""preemptible"": true,; ""executionStatus"": ""Failed"",; ""stdout"": ""gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/3da6e34e-a2a1-49fb-8a84-4d62aada9b3d/call-ApplyBQSR/shard-15/ApplyBQSR-15-stdout.log"",; ""backendStatus"": ""Success"",; ""shardIndex"": 15,; ""outputs"": {. },; ""runtimeAttributes"": {; ""preemptible"": ""3"",; ""failOnStderr"": ""false"",; ""bootDiskSizeGb"": ""10"",; ""disks"": ""local-disk 200 HDD"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""broadinstitute/genomes-in-the-cloud:2.0.0"",; ""cpu"": ""1"",; ""zones"": ""us-central1-c"",; ""memory"": ""3.5 GB""; },; ""cache"": {; ""allowResultReuse"": true; },; ""inputs"": {; ""input_bam"": ""SortAndFixSampleBam.output_bam"",; ""ref_fasta"": ""ref_fasta"",; ""ref_dict"": ""ref_dict"",; ""recalibration_report"": ""GatherBqsrReports.output_bqsr_report"",; ""disk_size"": ""agg_medium_disk"",; ""output_bam_basename"": ""recalibrated_bam_basename"",; ""input_bam_index"": ""SortAndFixSampleBam.output_bam_index"",; ""ref_fasta_index"": ""ref_fasta_index"",; ""sequence_group_interval"": ""subgroup""; },; ""returnCode"": 0,; ""failures"": [{; ""failure"": ""Read timed out"",; ""timestamp"": ""2016-04-23T18:29:53.764Z""; }],; ""jobId"": ""operations/EK2_jqLEKhiCmbzn296gnv4BIJ-ikOmeDSoPcHJvZHVjdGlvblF1ZXVl"",; ""backend"": ""JES"",; ""end"": ""2016-04-23T18:29:54.000Z"",; ""stderr"": ""gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/3da6e34e-a2a1-49fb-8a84-4d62aada9b3d/call-ApplyBQSR/shard-15/ApplyBQSR-15-stderr.log"",; ""attempt"": 1,; ""executionEvents"": [],; ""backendLogs"": {; ""log"": ""gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/3da6e34e-a2a1-49fb-8a84-4d62aada9b3d/call-ApplyBQSR/shard-15/ApplyBQSR-15.log""; },; ""start"": ""2016-04-23T17:56:02.000Z""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/738
https://github.com/broadinstitute/cromwell/issues/738:328,Testability,log,log,328,"The following workflow failed in cromwell (3da6e34e-a2a1-49fb-8a84-4d62aada9b3d) on production. . ```; {; ""preemptible"": true,; ""executionStatus"": ""Failed"",; ""stdout"": ""gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/3da6e34e-a2a1-49fb-8a84-4d62aada9b3d/call-ApplyBQSR/shard-15/ApplyBQSR-15-stdout.log"",; ""backendStatus"": ""Success"",; ""shardIndex"": 15,; ""outputs"": {. },; ""runtimeAttributes"": {; ""preemptible"": ""3"",; ""failOnStderr"": ""false"",; ""bootDiskSizeGb"": ""10"",; ""disks"": ""local-disk 200 HDD"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""broadinstitute/genomes-in-the-cloud:2.0.0"",; ""cpu"": ""1"",; ""zones"": ""us-central1-c"",; ""memory"": ""3.5 GB""; },; ""cache"": {; ""allowResultReuse"": true; },; ""inputs"": {; ""input_bam"": ""SortAndFixSampleBam.output_bam"",; ""ref_fasta"": ""ref_fasta"",; ""ref_dict"": ""ref_dict"",; ""recalibration_report"": ""GatherBqsrReports.output_bqsr_report"",; ""disk_size"": ""agg_medium_disk"",; ""output_bam_basename"": ""recalibrated_bam_basename"",; ""input_bam_index"": ""SortAndFixSampleBam.output_bam_index"",; ""ref_fasta_index"": ""ref_fasta_index"",; ""sequence_group_interval"": ""subgroup""; },; ""returnCode"": 0,; ""failures"": [{; ""failure"": ""Read timed out"",; ""timestamp"": ""2016-04-23T18:29:53.764Z""; }],; ""jobId"": ""operations/EK2_jqLEKhiCmbzn296gnv4BIJ-ikOmeDSoPcHJvZHVjdGlvblF1ZXVl"",; ""backend"": ""JES"",; ""end"": ""2016-04-23T18:29:54.000Z"",; ""stderr"": ""gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/3da6e34e-a2a1-49fb-8a84-4d62aada9b3d/call-ApplyBQSR/shard-15/ApplyBQSR-15-stderr.log"",; ""attempt"": 1,; ""executionEvents"": [],; ""backendLogs"": {; ""log"": ""gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/3da6e34e-a2a1-49fb-8a84-4d62aada9b3d/call-ApplyBQSR/shard-15/ApplyBQSR-15.log""; },; ""start"": ""2016-04-23T17:56:02.000Z""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/738
https://github.com/broadinstitute/cromwell/issues/738:1543,Testability,log,log,1543,"The following workflow failed in cromwell (3da6e34e-a2a1-49fb-8a84-4d62aada9b3d) on production. . ```; {; ""preemptible"": true,; ""executionStatus"": ""Failed"",; ""stdout"": ""gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/3da6e34e-a2a1-49fb-8a84-4d62aada9b3d/call-ApplyBQSR/shard-15/ApplyBQSR-15-stdout.log"",; ""backendStatus"": ""Success"",; ""shardIndex"": 15,; ""outputs"": {. },; ""runtimeAttributes"": {; ""preemptible"": ""3"",; ""failOnStderr"": ""false"",; ""bootDiskSizeGb"": ""10"",; ""disks"": ""local-disk 200 HDD"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""broadinstitute/genomes-in-the-cloud:2.0.0"",; ""cpu"": ""1"",; ""zones"": ""us-central1-c"",; ""memory"": ""3.5 GB""; },; ""cache"": {; ""allowResultReuse"": true; },; ""inputs"": {; ""input_bam"": ""SortAndFixSampleBam.output_bam"",; ""ref_fasta"": ""ref_fasta"",; ""ref_dict"": ""ref_dict"",; ""recalibration_report"": ""GatherBqsrReports.output_bqsr_report"",; ""disk_size"": ""agg_medium_disk"",; ""output_bam_basename"": ""recalibrated_bam_basename"",; ""input_bam_index"": ""SortAndFixSampleBam.output_bam_index"",; ""ref_fasta_index"": ""ref_fasta_index"",; ""sequence_group_interval"": ""subgroup""; },; ""returnCode"": 0,; ""failures"": [{; ""failure"": ""Read timed out"",; ""timestamp"": ""2016-04-23T18:29:53.764Z""; }],; ""jobId"": ""operations/EK2_jqLEKhiCmbzn296gnv4BIJ-ikOmeDSoPcHJvZHVjdGlvblF1ZXVl"",; ""backend"": ""JES"",; ""end"": ""2016-04-23T18:29:54.000Z"",; ""stderr"": ""gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/3da6e34e-a2a1-49fb-8a84-4d62aada9b3d/call-ApplyBQSR/shard-15/ApplyBQSR-15-stderr.log"",; ""attempt"": 1,; ""executionEvents"": [],; ""backendLogs"": {; ""log"": ""gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/3da6e34e-a2a1-49fb-8a84-4d62aada9b3d/call-ApplyBQSR/shard-15/ApplyBQSR-15.log""; },; ""start"": ""2016-04-23T17:56:02.000Z""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/738
https://github.com/broadinstitute/cromwell/issues/738:1608,Testability,log,log,1608,"The following workflow failed in cromwell (3da6e34e-a2a1-49fb-8a84-4d62aada9b3d) on production. . ```; {; ""preemptible"": true,; ""executionStatus"": ""Failed"",; ""stdout"": ""gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/3da6e34e-a2a1-49fb-8a84-4d62aada9b3d/call-ApplyBQSR/shard-15/ApplyBQSR-15-stdout.log"",; ""backendStatus"": ""Success"",; ""shardIndex"": 15,; ""outputs"": {. },; ""runtimeAttributes"": {; ""preemptible"": ""3"",; ""failOnStderr"": ""false"",; ""bootDiskSizeGb"": ""10"",; ""disks"": ""local-disk 200 HDD"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""broadinstitute/genomes-in-the-cloud:2.0.0"",; ""cpu"": ""1"",; ""zones"": ""us-central1-c"",; ""memory"": ""3.5 GB""; },; ""cache"": {; ""allowResultReuse"": true; },; ""inputs"": {; ""input_bam"": ""SortAndFixSampleBam.output_bam"",; ""ref_fasta"": ""ref_fasta"",; ""ref_dict"": ""ref_dict"",; ""recalibration_report"": ""GatherBqsrReports.output_bqsr_report"",; ""disk_size"": ""agg_medium_disk"",; ""output_bam_basename"": ""recalibrated_bam_basename"",; ""input_bam_index"": ""SortAndFixSampleBam.output_bam_index"",; ""ref_fasta_index"": ""ref_fasta_index"",; ""sequence_group_interval"": ""subgroup""; },; ""returnCode"": 0,; ""failures"": [{; ""failure"": ""Read timed out"",; ""timestamp"": ""2016-04-23T18:29:53.764Z""; }],; ""jobId"": ""operations/EK2_jqLEKhiCmbzn296gnv4BIJ-ikOmeDSoPcHJvZHVjdGlvblF1ZXVl"",; ""backend"": ""JES"",; ""end"": ""2016-04-23T18:29:54.000Z"",; ""stderr"": ""gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/3da6e34e-a2a1-49fb-8a84-4d62aada9b3d/call-ApplyBQSR/shard-15/ApplyBQSR-15-stderr.log"",; ""attempt"": 1,; ""executionEvents"": [],; ""backendLogs"": {; ""log"": ""gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/3da6e34e-a2a1-49fb-8a84-4d62aada9b3d/call-ApplyBQSR/shard-15/ApplyBQSR-15.log""; },; ""start"": ""2016-04-23T17:56:02.000Z""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/738
https://github.com/broadinstitute/cromwell/issues/738:1767,Testability,log,log,1767,"The following workflow failed in cromwell (3da6e34e-a2a1-49fb-8a84-4d62aada9b3d) on production. . ```; {; ""preemptible"": true,; ""executionStatus"": ""Failed"",; ""stdout"": ""gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/3da6e34e-a2a1-49fb-8a84-4d62aada9b3d/call-ApplyBQSR/shard-15/ApplyBQSR-15-stdout.log"",; ""backendStatus"": ""Success"",; ""shardIndex"": 15,; ""outputs"": {. },; ""runtimeAttributes"": {; ""preemptible"": ""3"",; ""failOnStderr"": ""false"",; ""bootDiskSizeGb"": ""10"",; ""disks"": ""local-disk 200 HDD"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""broadinstitute/genomes-in-the-cloud:2.0.0"",; ""cpu"": ""1"",; ""zones"": ""us-central1-c"",; ""memory"": ""3.5 GB""; },; ""cache"": {; ""allowResultReuse"": true; },; ""inputs"": {; ""input_bam"": ""SortAndFixSampleBam.output_bam"",; ""ref_fasta"": ""ref_fasta"",; ""ref_dict"": ""ref_dict"",; ""recalibration_report"": ""GatherBqsrReports.output_bqsr_report"",; ""disk_size"": ""agg_medium_disk"",; ""output_bam_basename"": ""recalibrated_bam_basename"",; ""input_bam_index"": ""SortAndFixSampleBam.output_bam_index"",; ""ref_fasta_index"": ""ref_fasta_index"",; ""sequence_group_interval"": ""subgroup""; },; ""returnCode"": 0,; ""failures"": [{; ""failure"": ""Read timed out"",; ""timestamp"": ""2016-04-23T18:29:53.764Z""; }],; ""jobId"": ""operations/EK2_jqLEKhiCmbzn296gnv4BIJ-ikOmeDSoPcHJvZHVjdGlvblF1ZXVl"",; ""backend"": ""JES"",; ""end"": ""2016-04-23T18:29:54.000Z"",; ""stderr"": ""gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/3da6e34e-a2a1-49fb-8a84-4d62aada9b3d/call-ApplyBQSR/shard-15/ApplyBQSR-15-stderr.log"",; ""attempt"": 1,; ""executionEvents"": [],; ""backendLogs"": {; ""log"": ""gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/3da6e34e-a2a1-49fb-8a84-4d62aada9b3d/call-ApplyBQSR/shard-15/ApplyBQSR-15.log""; },; ""start"": ""2016-04-23T17:56:02.000Z""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/738
https://github.com/broadinstitute/cromwell/pull/739:6,Testability,Test,Test,6,- [x] Test with MySQL; - [x] Test with in-memory DB; - [x] Test against `master` too; - [x] Create PR against `master`,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/739
https://github.com/broadinstitute/cromwell/pull/739:29,Testability,Test,Test,29,- [x] Test with MySQL; - [x] Test with in-memory DB; - [x] Test against `master` too; - [x] Create PR against `master`,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/739
https://github.com/broadinstitute/cromwell/pull/739:59,Testability,Test,Test,59,- [x] Test with MySQL; - [x] Test with in-memory DB; - [x] Test against `master` too; - [x] Create PR against `master`,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/739
https://github.com/broadinstitute/cromwell/pull/741:15,Security,validat,validation,15,- Moved memory validation from WDL4s to Backend validation.; - Removed unused validation functions from CromwellRuntimeAttributes.; - Added validation for negative values in memory and cpu.; - Moved CPU validation from JES backend to generic backend validation functions object.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/741
https://github.com/broadinstitute/cromwell/pull/741:48,Security,validat,validation,48,- Moved memory validation from WDL4s to Backend validation.; - Removed unused validation functions from CromwellRuntimeAttributes.; - Added validation for negative values in memory and cpu.; - Moved CPU validation from JES backend to generic backend validation functions object.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/741
https://github.com/broadinstitute/cromwell/pull/741:78,Security,validat,validation,78,- Moved memory validation from WDL4s to Backend validation.; - Removed unused validation functions from CromwellRuntimeAttributes.; - Added validation for negative values in memory and cpu.; - Moved CPU validation from JES backend to generic backend validation functions object.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/741
https://github.com/broadinstitute/cromwell/pull/741:140,Security,validat,validation,140,- Moved memory validation from WDL4s to Backend validation.; - Removed unused validation functions from CromwellRuntimeAttributes.; - Added validation for negative values in memory and cpu.; - Moved CPU validation from JES backend to generic backend validation functions object.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/741
https://github.com/broadinstitute/cromwell/pull/741:203,Security,validat,validation,203,- Moved memory validation from WDL4s to Backend validation.; - Removed unused validation functions from CromwellRuntimeAttributes.; - Added validation for negative values in memory and cpu.; - Moved CPU validation from JES backend to generic backend validation functions object.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/741
https://github.com/broadinstitute/cromwell/pull/741:250,Security,validat,validation,250,- Moved memory validation from WDL4s to Backend validation.; - Removed unused validation functions from CromwellRuntimeAttributes.; - Added validation for negative values in memory and cpu.; - Moved CPU validation from JES backend to generic backend validation functions object.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/741
https://github.com/broadinstitute/cromwell/issues/742:63,Availability,failure,failure,63,"Post task success processing failed with a Communications link failure. ```; 2016-04-26 14:06:36,930 cromwell-system-akka.actor.default-dispatcher-8 INFO - JES Run [UUID(143681e1):GatherBqsrReports]: Status change from Running to Success; 2016-04-26 14:06:37,506 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(143681e1)]: Completion work failed for call GatherBqsrReports.; com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure. The last packet successfully received from the server was 324 milliseconds ago. The last packet sent successfully to the server was 0 milliseconds ago.; at sun.reflect.GeneratedConstructorAccessor102.newInstance(Unknown Source) ~[na:na]; at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[na:1.8.0_72]; at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[na:1.8.0_72]; at com.mysql.jdbc.Util.handleNewInstance(Util.java:400) ~[cromwell.jar:0.19]; at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1038) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3434) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3334) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3774) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2447) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2594) ~[cromwell.jar:0.19]; at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2541) ~[cromwell.jar:0.19]; at com.mysql.jdbc.ConnectionImpl.setAutoCommit(ConnectionImpl.java:4882) ~[cromwell.jar:0.19]; at com.zaxxer.hikari.proxy.ConnectionProxy.setAutoCommit(ConnectionProxy.java:334) ~[cromwell.jar:0.19]; at com.zaxxer.hikari.proxy.ConnectionJavassistProxy.setAutoCommit(ConnectionJavassistProxy.java) ~[cromwell.jar:0.19]; at slick.jdbc.JdbcBackend$BaseSession.startInTransaction(JdbcBackend",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/742
https://github.com/broadinstitute/cromwell/issues/742:312,Availability,ERROR,ERROR,312,"Post task success processing failed with a Communications link failure. ```; 2016-04-26 14:06:36,930 cromwell-system-akka.actor.default-dispatcher-8 INFO - JES Run [UUID(143681e1):GatherBqsrReports]: Status change from Running to Success; 2016-04-26 14:06:37,506 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(143681e1)]: Completion work failed for call GatherBqsrReports.; com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure. The last packet successfully received from the server was 324 milliseconds ago. The last packet sent successfully to the server was 0 milliseconds ago.; at sun.reflect.GeneratedConstructorAccessor102.newInstance(Unknown Source) ~[na:na]; at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[na:1.8.0_72]; at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[na:1.8.0_72]; at com.mysql.jdbc.Util.handleNewInstance(Util.java:400) ~[cromwell.jar:0.19]; at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1038) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3434) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3334) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3774) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2447) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2594) ~[cromwell.jar:0.19]; at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2541) ~[cromwell.jar:0.19]; at com.mysql.jdbc.ConnectionImpl.setAutoCommit(ConnectionImpl.java:4882) ~[cromwell.jar:0.19]; at com.zaxxer.hikari.proxy.ConnectionProxy.setAutoCommit(ConnectionProxy.java:334) ~[cromwell.jar:0.19]; at com.zaxxer.hikari.proxy.ConnectionJavassistProxy.setAutoCommit(ConnectionJavassistProxy.java) ~[cromwell.jar:0.19]; at slick.jdbc.JdbcBackend$BaseSession.startInTransaction(JdbcBackend",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/742
https://github.com/broadinstitute/cromwell/issues/742:481,Availability,failure,failure,481,"Post task success processing failed with a Communications link failure. ```; 2016-04-26 14:06:36,930 cromwell-system-akka.actor.default-dispatcher-8 INFO - JES Run [UUID(143681e1):GatherBqsrReports]: Status change from Running to Success; 2016-04-26 14:06:37,506 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(143681e1)]: Completion work failed for call GatherBqsrReports.; com.mysql.jdbc.exceptions.jdbc4.CommunicationsException: Communications link failure. The last packet successfully received from the server was 324 milliseconds ago. The last packet sent successfully to the server was 0 milliseconds ago.; at sun.reflect.GeneratedConstructorAccessor102.newInstance(Unknown Source) ~[na:na]; at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[na:1.8.0_72]; at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[na:1.8.0_72]; at com.mysql.jdbc.Util.handleNewInstance(Util.java:400) ~[cromwell.jar:0.19]; at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1038) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3434) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3334) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3774) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2447) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2594) ~[cromwell.jar:0.19]; at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2541) ~[cromwell.jar:0.19]; at com.mysql.jdbc.ConnectionImpl.setAutoCommit(ConnectionImpl.java:4882) ~[cromwell.jar:0.19]; at com.zaxxer.hikari.proxy.ConnectionProxy.setAutoCommit(ConnectionProxy.java:334) ~[cromwell.jar:0.19]; at com.zaxxer.hikari.proxy.ConnectionJavassistProxy.setAutoCommit(ConnectionJavassistProxy.java) ~[cromwell.jar:0.19]; at slick.jdbc.JdbcBackend$BaseSession.startInTransaction(JdbcBackend",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/742
https://github.com/broadinstitute/cromwell/issues/742:3318,Availability,ERROR,ERROR,3318,"avassistProxy.setAutoCommit(ConnectionJavassistProxy.java) ~[cromwell.jar:0.19]; at slick.jdbc.JdbcBackend$BaseSession.startInTransaction(JdbcBackend.scala:437) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$StartTransaction$.run(JdbcActionComponent.scala:41) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$StartTransaction$.run(JdbcActionComponent.scala:38) ~[cromwell.jar:0.19]; at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.liftedTree1$1(DatabaseComponent.scala:237) ~[cromwell.jar:0.19]; at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.run(DatabaseComponent.scala:237) ~[cromwell.jar:0.19]; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_72]; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_72]; at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_72]; Caused by: java.io.EOFException: Can not read response from server. Expected to read 4 bytes, read 0 bytes before connection was unexpectedly lost.; at com.mysql.jdbc.MysqlIO.readFully(MysqlIO.java:2926) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3344) ~[cromwell.jar:0.19]; ... 16 common frames omitted; 2016-04-26 14:06:37,506 cromwell-system-akka.actor.default-dispatcher-15 INFO - WorkflowActor [UUID(143681e1)]: persisting status of GatherBqsrReports to Failed.; 2016-04-26 14:06:37,506 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(143681e1)]: Communications link failure. The last packet successfully received from the server was 324 milliseconds ago. The last packet sent successfully to the server was 0 milliseconds ago.; 2016-04-26 14:06:37,741 cromwell-system-akka.actor.default-dispatcher-10 INFO - WorkflowActor [UUID(143681e1)]: Beginning transition from Running to Failed.; 2016-04-26 14:06:39,456 cromwell-system-akka.actor.default-dispatcher-15 INFO - WorkflowActor [UUID(143681e1)]: transitioning from Running to Failed.; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/742
https://github.com/broadinstitute/cromwell/issues/742:3378,Availability,failure,failure,3378,"avassistProxy.setAutoCommit(ConnectionJavassistProxy.java) ~[cromwell.jar:0.19]; at slick.jdbc.JdbcBackend$BaseSession.startInTransaction(JdbcBackend.scala:437) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$StartTransaction$.run(JdbcActionComponent.scala:41) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$StartTransaction$.run(JdbcActionComponent.scala:38) ~[cromwell.jar:0.19]; at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.liftedTree1$1(DatabaseComponent.scala:237) ~[cromwell.jar:0.19]; at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.run(DatabaseComponent.scala:237) ~[cromwell.jar:0.19]; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_72]; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_72]; at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_72]; Caused by: java.io.EOFException: Can not read response from server. Expected to read 4 bytes, read 0 bytes before connection was unexpectedly lost.; at com.mysql.jdbc.MysqlIO.readFully(MysqlIO.java:2926) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3344) ~[cromwell.jar:0.19]; ... 16 common frames omitted; 2016-04-26 14:06:37,506 cromwell-system-akka.actor.default-dispatcher-15 INFO - WorkflowActor [UUID(143681e1)]: persisting status of GatherBqsrReports to Failed.; 2016-04-26 14:06:37,506 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(143681e1)]: Communications link failure. The last packet successfully received from the server was 324 milliseconds ago. The last packet sent successfully to the server was 0 milliseconds ago.; 2016-04-26 14:06:37,741 cromwell-system-akka.actor.default-dispatcher-10 INFO - WorkflowActor [UUID(143681e1)]: Beginning transition from Running to Failed.; 2016-04-26 14:06:39,456 cromwell-system-akka.actor.default-dispatcher-15 INFO - WorkflowActor [UUID(143681e1)]: transitioning from Running to Failed.; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/742
https://github.com/broadinstitute/cromwell/issues/742:2498,Performance,concurren,concurrent,2498,"~[cromwell.jar:0.19]; at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2541) ~[cromwell.jar:0.19]; at com.mysql.jdbc.ConnectionImpl.setAutoCommit(ConnectionImpl.java:4882) ~[cromwell.jar:0.19]; at com.zaxxer.hikari.proxy.ConnectionProxy.setAutoCommit(ConnectionProxy.java:334) ~[cromwell.jar:0.19]; at com.zaxxer.hikari.proxy.ConnectionJavassistProxy.setAutoCommit(ConnectionJavassistProxy.java) ~[cromwell.jar:0.19]; at slick.jdbc.JdbcBackend$BaseSession.startInTransaction(JdbcBackend.scala:437) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$StartTransaction$.run(JdbcActionComponent.scala:41) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$StartTransaction$.run(JdbcActionComponent.scala:38) ~[cromwell.jar:0.19]; at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.liftedTree1$1(DatabaseComponent.scala:237) ~[cromwell.jar:0.19]; at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.run(DatabaseComponent.scala:237) ~[cromwell.jar:0.19]; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_72]; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_72]; at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_72]; Caused by: java.io.EOFException: Can not read response from server. Expected to read 4 bytes, read 0 bytes before connection was unexpectedly lost.; at com.mysql.jdbc.MysqlIO.readFully(MysqlIO.java:2926) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3344) ~[cromwell.jar:0.19]; ... 16 common frames omitted; 2016-04-26 14:06:37,506 cromwell-system-akka.actor.default-dispatcher-15 INFO - WorkflowActor [UUID(143681e1)]: persisting status of GatherBqsrReports to Failed.; 2016-04-26 14:06:37,506 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(143681e1)]: Communications link failure. The last packet successfully received from the server was 324 milliseconds ago. The last packet sent successfully to ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/742
https://github.com/broadinstitute/cromwell/issues/742:2597,Performance,concurren,concurrent,2597,".jar:0.19]; at com.mysql.jdbc.ConnectionImpl.setAutoCommit(ConnectionImpl.java:4882) ~[cromwell.jar:0.19]; at com.zaxxer.hikari.proxy.ConnectionProxy.setAutoCommit(ConnectionProxy.java:334) ~[cromwell.jar:0.19]; at com.zaxxer.hikari.proxy.ConnectionJavassistProxy.setAutoCommit(ConnectionJavassistProxy.java) ~[cromwell.jar:0.19]; at slick.jdbc.JdbcBackend$BaseSession.startInTransaction(JdbcBackend.scala:437) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$StartTransaction$.run(JdbcActionComponent.scala:41) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$StartTransaction$.run(JdbcActionComponent.scala:38) ~[cromwell.jar:0.19]; at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.liftedTree1$1(DatabaseComponent.scala:237) ~[cromwell.jar:0.19]; at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.run(DatabaseComponent.scala:237) ~[cromwell.jar:0.19]; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_72]; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_72]; at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_72]; Caused by: java.io.EOFException: Can not read response from server. Expected to read 4 bytes, read 0 bytes before connection was unexpectedly lost.; at com.mysql.jdbc.MysqlIO.readFully(MysqlIO.java:2926) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.reuseAndReadPacket(MysqlIO.java:3344) ~[cromwell.jar:0.19]; ... 16 common frames omitted; 2016-04-26 14:06:37,506 cromwell-system-akka.actor.default-dispatcher-15 INFO - WorkflowActor [UUID(143681e1)]: persisting status of GatherBqsrReports to Failed.; 2016-04-26 14:06:37,506 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(143681e1)]: Communications link failure. The last packet successfully received from the server was 324 milliseconds ago. The last packet sent successfully to the server was 0 milliseconds ago.; 2016-04-26 14:06:37,741 cromwell-system-akka.actor.default-disp",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/742
https://github.com/broadinstitute/cromwell/pull/743:1043,Integrability,depend,dependent,1043,"Changes are related only to the Shadow world. The expectations of this PR is to extend the current state of things in Workflow Execution (i.e currently we only run a single call workflow) to allow arbitrarily sized workflows (i.e. an N-call workflow). The intention is _not_ to support scatters in this PR, but allow it to be extensible for scatters (or Inception-esque nested scatters, which I hope to take up as my next ticket). ~~The original WA used Data Access and symbol store to pass around information between tasks. I am not quite sure how that would work with the shadow world, also considering we don't (yet) have engine functions at that level. So I have used a little different algorithm to orchestrate the calls in a workflow (preparing a small call graph and sorting that graph to obtain the logical ordering among tasks, and then orchestrate that via information in the FSM state data).~~. ~~I might wait for @Horneth for getting the engine functions in and have thoughts from you guys on plugging in outputs of a task to it's dependent task.~~. ~~I talked with Thibault about this and I honestly don't mind if this PR does't get merged at all if we see a problem with this, just need a fresh pair of eyes to look through it.~~. ~~Currently, I'm adding tests for all this new code.~~",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/743
https://github.com/broadinstitute/cromwell/pull/743:80,Modifiability,extend,extend,80,"Changes are related only to the Shadow world. The expectations of this PR is to extend the current state of things in Workflow Execution (i.e currently we only run a single call workflow) to allow arbitrarily sized workflows (i.e. an N-call workflow). The intention is _not_ to support scatters in this PR, but allow it to be extensible for scatters (or Inception-esque nested scatters, which I hope to take up as my next ticket). ~~The original WA used Data Access and symbol store to pass around information between tasks. I am not quite sure how that would work with the shadow world, also considering we don't (yet) have engine functions at that level. So I have used a little different algorithm to orchestrate the calls in a workflow (preparing a small call graph and sorting that graph to obtain the logical ordering among tasks, and then orchestrate that via information in the FSM state data).~~. ~~I might wait for @Horneth for getting the engine functions in and have thoughts from you guys on plugging in outputs of a task to it's dependent task.~~. ~~I talked with Thibault about this and I honestly don't mind if this PR does't get merged at all if we see a problem with this, just need a fresh pair of eyes to look through it.~~. ~~Currently, I'm adding tests for all this new code.~~",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/743
https://github.com/broadinstitute/cromwell/pull/743:459,Security,Access,Access,459,"Changes are related only to the Shadow world. The expectations of this PR is to extend the current state of things in Workflow Execution (i.e currently we only run a single call workflow) to allow arbitrarily sized workflows (i.e. an N-call workflow). The intention is _not_ to support scatters in this PR, but allow it to be extensible for scatters (or Inception-esque nested scatters, which I hope to take up as my next ticket). ~~The original WA used Data Access and symbol store to pass around information between tasks. I am not quite sure how that would work with the shadow world, also considering we don't (yet) have engine functions at that level. So I have used a little different algorithm to orchestrate the calls in a workflow (preparing a small call graph and sorting that graph to obtain the logical ordering among tasks, and then orchestrate that via information in the FSM state data).~~. ~~I might wait for @Horneth for getting the engine functions in and have thoughts from you guys on plugging in outputs of a task to it's dependent task.~~. ~~I talked with Thibault about this and I honestly don't mind if this PR does't get merged at all if we see a problem with this, just need a fresh pair of eyes to look through it.~~. ~~Currently, I'm adding tests for all this new code.~~",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/743
https://github.com/broadinstitute/cromwell/pull/743:807,Testability,log,logical,807,"Changes are related only to the Shadow world. The expectations of this PR is to extend the current state of things in Workflow Execution (i.e currently we only run a single call workflow) to allow arbitrarily sized workflows (i.e. an N-call workflow). The intention is _not_ to support scatters in this PR, but allow it to be extensible for scatters (or Inception-esque nested scatters, which I hope to take up as my next ticket). ~~The original WA used Data Access and symbol store to pass around information between tasks. I am not quite sure how that would work with the shadow world, also considering we don't (yet) have engine functions at that level. So I have used a little different algorithm to orchestrate the calls in a workflow (preparing a small call graph and sorting that graph to obtain the logical ordering among tasks, and then orchestrate that via information in the FSM state data).~~. ~~I might wait for @Horneth for getting the engine functions in and have thoughts from you guys on plugging in outputs of a task to it's dependent task.~~. ~~I talked with Thibault about this and I honestly don't mind if this PR does't get merged at all if we see a problem with this, just need a fresh pair of eyes to look through it.~~. ~~Currently, I'm adding tests for all this new code.~~",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/743
https://github.com/broadinstitute/cromwell/pull/743:1269,Testability,test,tests,1269,"Changes are related only to the Shadow world. The expectations of this PR is to extend the current state of things in Workflow Execution (i.e currently we only run a single call workflow) to allow arbitrarily sized workflows (i.e. an N-call workflow). The intention is _not_ to support scatters in this PR, but allow it to be extensible for scatters (or Inception-esque nested scatters, which I hope to take up as my next ticket). ~~The original WA used Data Access and symbol store to pass around information between tasks. I am not quite sure how that would work with the shadow world, also considering we don't (yet) have engine functions at that level. So I have used a little different algorithm to orchestrate the calls in a workflow (preparing a small call graph and sorting that graph to obtain the logical ordering among tasks, and then orchestrate that via information in the FSM state data).~~. ~~I might wait for @Horneth for getting the engine functions in and have thoughts from you guys on plugging in outputs of a task to it's dependent task.~~. ~~I talked with Thibault about this and I honestly don't mind if this PR does't get merged at all if we see a problem with this, just need a fresh pair of eyes to look through it.~~. ~~Currently, I'm adding tests for all this new code.~~",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/743
https://github.com/broadinstitute/cromwell/issues/744:75,Availability,error,error,75,"As of right now, when using preemptible instances, Google has two types of error messages: 13 & 14. We want to to be able to retry when receiving Error Code 13 in the same way we currently retry for Error Code 14.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/744
https://github.com/broadinstitute/cromwell/issues/744:146,Availability,Error,Error,146,"As of right now, when using preemptible instances, Google has two types of error messages: 13 & 14. We want to to be able to retry when receiving Error Code 13 in the same way we currently retry for Error Code 14.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/744
https://github.com/broadinstitute/cromwell/issues/744:199,Availability,Error,Error,199,"As of right now, when using preemptible instances, Google has two types of error messages: 13 & 14. We want to to be able to retry when receiving Error Code 13 in the same way we currently retry for Error Code 14.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/744
https://github.com/broadinstitute/cromwell/issues/744:81,Integrability,message,messages,81,"As of right now, when using preemptible instances, Google has two types of error messages: 13 & 14. We want to to be able to retry when receiving Error Code 13 in the same way we currently retry for Error Code 14.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/744
https://github.com/broadinstitute/cromwell/pull/746:30,Security,validat,validate,30,"Main purpose of this PR is to validate the idea of ""Runtime Attributes validation"" at Backend **initialization** an **execution** level. [x] LocalBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] JesBackend; - Initialization => Validate Docker key is present and warn for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] HtCondorBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] SgeBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. The idea is to have this public while I implement this functionality so we all are in the same page.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/746
https://github.com/broadinstitute/cromwell/pull/746:71,Security,validat,validation,71,"Main purpose of this PR is to validate the idea of ""Runtime Attributes validation"" at Backend **initialization** an **execution** level. [x] LocalBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] JesBackend; - Initialization => Validate Docker key is present and warn for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] HtCondorBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] SgeBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. The idea is to have this public while I implement this functionality so we all are in the same page.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/746
https://github.com/broadinstitute/cromwell/pull/746:201,Security,validat,validation,201,"Main purpose of this PR is to validate the idea of ""Runtime Attributes validation"" at Backend **initialization** an **execution** level. [x] LocalBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] JesBackend; - Initialization => Validate Docker key is present and warn for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] HtCondorBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] SgeBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. The idea is to have this public while I implement this functionality so we all are in the same page.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/746
https://github.com/broadinstitute/cromwell/pull/746:289,Security,Validat,Validate,289,"Main purpose of this PR is to validate the idea of ""Runtime Attributes validation"" at Backend **initialization** an **execution** level. [x] LocalBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] JesBackend; - Initialization => Validate Docker key is present and warn for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] HtCondorBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] SgeBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. The idea is to have this public while I implement this functionality so we all are in the same page.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/746
https://github.com/broadinstitute/cromwell/pull/746:374,Security,Validat,Validate,374,"Main purpose of this PR is to validate the idea of ""Runtime Attributes validation"" at Backend **initialization** an **execution** level. [x] LocalBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] JesBackend; - Initialization => Validate Docker key is present and warn for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] HtCondorBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] SgeBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. The idea is to have this public while I implement this functionality so we all are in the same page.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/746
https://github.com/broadinstitute/cromwell/pull/746:475,Security,Validat,Validate,475,"Main purpose of this PR is to validate the idea of ""Runtime Attributes validation"" at Backend **initialization** an **execution** level. [x] LocalBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] JesBackend; - Initialization => Validate Docker key is present and warn for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] HtCondorBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] SgeBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. The idea is to have this public while I implement this functionality so we all are in the same page.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/746
https://github.com/broadinstitute/cromwell/pull/746:591,Security,validat,validation,591,"Main purpose of this PR is to validate the idea of ""Runtime Attributes validation"" at Backend **initialization** an **execution** level. [x] LocalBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] JesBackend; - Initialization => Validate Docker key is present and warn for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] HtCondorBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] SgeBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. The idea is to have this public while I implement this functionality so we all are in the same page.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/746
https://github.com/broadinstitute/cromwell/pull/746:679,Security,Validat,Validate,679,"Main purpose of this PR is to validate the idea of ""Runtime Attributes validation"" at Backend **initialization** an **execution** level. [x] LocalBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] JesBackend; - Initialization => Validate Docker key is present and warn for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] HtCondorBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] SgeBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. The idea is to have this public while I implement this functionality so we all are in the same page.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/746
https://github.com/broadinstitute/cromwell/pull/746:790,Security,validat,validation,790,"Main purpose of this PR is to validate the idea of ""Runtime Attributes validation"" at Backend **initialization** an **execution** level. [x] LocalBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] JesBackend; - Initialization => Validate Docker key is present and warn for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] HtCondorBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] SgeBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. The idea is to have this public while I implement this functionality so we all are in the same page.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/746
https://github.com/broadinstitute/cromwell/pull/746:878,Security,Validat,Validate,878,"Main purpose of this PR is to validate the idea of ""Runtime Attributes validation"" at Backend **initialization** an **execution** level. [x] LocalBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] JesBackend; - Initialization => Validate Docker key is present and warn for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] HtCondorBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. [x] SgeBackend; - Initialization => No runtime attribute keys validation. Just a warning for those attributes that are not supported.; - Execution => Validate values of supported runtime attributes. The idea is to have this public while I implement this functionality so we all are in the same page.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/746
https://github.com/broadinstitute/cromwell/issues/755:30,Safety,detect,detects,30,When Cromwell comes online it detects if there are any unfinished workflows in the system and will pick those back up.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/755
https://github.com/broadinstitute/cromwell/issues/756:37,Availability,failure,failures,37,Local PBE should return retryable on failures (which should always be false in this PBE),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/756
https://github.com/broadinstitute/cromwell/issues/757:299,Availability,error,error,299,"Apologies if this is the wrong space for this. I've got a workflow written up and running locally in WDL, and I'm getting started with the JES backend. I've done a fair amount of work in google genomics before this, but this is my first use of cromwell/WDL. Some details first. I first noticed this error on 0.19.2, but went back to check 0.19 and HEAD of the develop branch. where it occurs as well. For completeness, here's my WDL file:. ```; cat ~/workflows/hello-jes.wdl ; task jes_task {; command {; echo ""Hello JES!""; }; runtime {; docker: ""ubuntu:latest""; memory: ""4G""; cpu: ""3""; zones: ""us-central1-c us-central1-a""; disks: ""/mnt/mnt1 3 SSD, /mnt/mnt2 500 HDD""; }; }; workflow jes_workflow {; call jes_task; }; ```. and the console output:. ```; [2016-04-28 15:35:51,218] [info] JesBackend [1cb9c1d2:jes_task]: echo ""Hello JES!""; Apr 28, 2016 3:35:51 PM com.google.api.client.googleapis.services.AbstractGoogleClient <init>; WARNING: Application name is not set. Call Builder#setApplicationName.; [2016-04-28 15:35:51,646] [info] JES Pipeline [1cb9c1d2:jes_task]: Inputs:; exec -> disk:local-disk relpath:exec.sh; [2016-04-28 15:35:51,647] [info] JES Pipeline [1cb9c1d2:jes_task]: Outputs:; jes_task-rc.txt -> disk:local-disk relpath:jes_task-rc.txt; [2016-04-28 15:35:51,648] [info] JES Pipeline [1cb9c1d2:jes_task]: Mounts:; c98942d68bf4c33728f1adef1bfd9ccc -> /mnt/mnt1 (3GB PERSISTENT_SSD); 4fd1d1e01455dfdd4eabcf02c1abaf55 -> /mnt/mnt2 (500GB PERSISTENT_HDD); local-disk -> /cromwell_root (10GB PERSISTENT_SSD); [2016-04-28 15:35:51,728] [warn] JesBackend [1cb9c1d2:jes_task]: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest""; } ],; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names mus",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:505,Availability,echo,echo,505,"Apologies if this is the wrong space for this. I've got a workflow written up and running locally in WDL, and I'm getting started with the JES backend. I've done a fair amount of work in google genomics before this, but this is my first use of cromwell/WDL. Some details first. I first noticed this error on 0.19.2, but went back to check 0.19 and HEAD of the develop branch. where it occurs as well. For completeness, here's my WDL file:. ```; cat ~/workflows/hello-jes.wdl ; task jes_task {; command {; echo ""Hello JES!""; }; runtime {; docker: ""ubuntu:latest""; memory: ""4G""; cpu: ""3""; zones: ""us-central1-c us-central1-a""; disks: ""/mnt/mnt1 3 SSD, /mnt/mnt2 500 HDD""; }; }; workflow jes_workflow {; call jes_task; }; ```. and the console output:. ```; [2016-04-28 15:35:51,218] [info] JesBackend [1cb9c1d2:jes_task]: echo ""Hello JES!""; Apr 28, 2016 3:35:51 PM com.google.api.client.googleapis.services.AbstractGoogleClient <init>; WARNING: Application name is not set. Call Builder#setApplicationName.; [2016-04-28 15:35:51,646] [info] JES Pipeline [1cb9c1d2:jes_task]: Inputs:; exec -> disk:local-disk relpath:exec.sh; [2016-04-28 15:35:51,647] [info] JES Pipeline [1cb9c1d2:jes_task]: Outputs:; jes_task-rc.txt -> disk:local-disk relpath:jes_task-rc.txt; [2016-04-28 15:35:51,648] [info] JES Pipeline [1cb9c1d2:jes_task]: Mounts:; c98942d68bf4c33728f1adef1bfd9ccc -> /mnt/mnt1 (3GB PERSISTENT_SSD); 4fd1d1e01455dfdd4eabcf02c1abaf55 -> /mnt/mnt2 (500GB PERSISTENT_HDD); local-disk -> /cromwell_root (10GB PERSISTENT_SSD); [2016-04-28 15:35:51,728] [warn] JesBackend [1cb9c1d2:jes_task]: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest""; } ],; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names mus",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:819,Availability,echo,echo,819,"Apologies if this is the wrong space for this. I've got a workflow written up and running locally in WDL, and I'm getting started with the JES backend. I've done a fair amount of work in google genomics before this, but this is my first use of cromwell/WDL. Some details first. I first noticed this error on 0.19.2, but went back to check 0.19 and HEAD of the develop branch. where it occurs as well. For completeness, here's my WDL file:. ```; cat ~/workflows/hello-jes.wdl ; task jes_task {; command {; echo ""Hello JES!""; }; runtime {; docker: ""ubuntu:latest""; memory: ""4G""; cpu: ""3""; zones: ""us-central1-c us-central1-a""; disks: ""/mnt/mnt1 3 SSD, /mnt/mnt2 500 HDD""; }; }; workflow jes_workflow {; call jes_task; }; ```. and the console output:. ```; [2016-04-28 15:35:51,218] [info] JesBackend [1cb9c1d2:jes_task]: echo ""Hello JES!""; Apr 28, 2016 3:35:51 PM com.google.api.client.googleapis.services.AbstractGoogleClient <init>; WARNING: Application name is not set. Call Builder#setApplicationName.; [2016-04-28 15:35:51,646] [info] JES Pipeline [1cb9c1d2:jes_task]: Inputs:; exec -> disk:local-disk relpath:exec.sh; [2016-04-28 15:35:51,647] [info] JES Pipeline [1cb9c1d2:jes_task]: Outputs:; jes_task-rc.txt -> disk:local-disk relpath:jes_task-rc.txt; [2016-04-28 15:35:51,648] [info] JES Pipeline [1cb9c1d2:jes_task]: Mounts:; c98942d68bf4c33728f1adef1bfd9ccc -> /mnt/mnt1 (3GB PERSISTENT_SSD); 4fd1d1e01455dfdd4eabcf02c1abaf55 -> /mnt/mnt2 (500GB PERSISTENT_HDD); local-disk -> /cromwell_root (10GB PERSISTENT_SSD); [2016-04-28 15:35:51,728] [warn] JesBackend [1cb9c1d2:jes_task]: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest""; } ],; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names mus",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:1626,Availability,error,errors,1626,"es_task {; command {; echo ""Hello JES!""; }; runtime {; docker: ""ubuntu:latest""; memory: ""4G""; cpu: ""3""; zones: ""us-central1-c us-central1-a""; disks: ""/mnt/mnt1 3 SSD, /mnt/mnt2 500 HDD""; }; }; workflow jes_workflow {; call jes_task; }; ```. and the console output:. ```; [2016-04-28 15:35:51,218] [info] JesBackend [1cb9c1d2:jes_task]: echo ""Hello JES!""; Apr 28, 2016 3:35:51 PM com.google.api.client.googleapis.services.AbstractGoogleClient <init>; WARNING: Application name is not set. Call Builder#setApplicationName.; [2016-04-28 15:35:51,646] [info] JES Pipeline [1cb9c1d2:jes_task]: Inputs:; exec -> disk:local-disk relpath:exec.sh; [2016-04-28 15:35:51,647] [info] JES Pipeline [1cb9c1d2:jes_task]: Outputs:; jes_task-rc.txt -> disk:local-disk relpath:jes_task-rc.txt; [2016-04-28 15:35:51,648] [info] JES Pipeline [1cb9c1d2:jes_task]: Mounts:; c98942d68bf4c33728f1adef1bfd9ccc -> /mnt/mnt1 (3GB PERSISTENT_SSD); 4fd1d1e01455dfdd4eabcf02c1abaf55 -> /mnt/mnt2 (500GB PERSISTENT_HDD); local-disk -> /cromwell_root (10GB PERSISTENT_SSD); [2016-04-28 15:35:51,728] [warn] JesBackend [1cb9c1d2:jes_task]: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest""; } ],; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""status"" : ""INVALID_ARGUMENT""; }; com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest"";",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:2225,Availability,error,errors,2225,"elpath:jes_task-rc.txt; [2016-04-28 15:35:51,648] [info] JES Pipeline [1cb9c1d2:jes_task]: Mounts:; c98942d68bf4c33728f1adef1bfd9ccc -> /mnt/mnt1 (3GB PERSISTENT_SSD); 4fd1d1e01455dfdd4eabcf02c1abaf55 -> /mnt/mnt2 (500GB PERSISTENT_HDD); local-disk -> /cromwell_root (10GB PERSISTENT_SSD); [2016-04-28 15:35:51,728] [warn] JesBackend [1cb9c1d2:jes_task]: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest""; } ],; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""status"" : ""INVALID_ARGUMENT""; }; com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest""; } ],; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""status"" : ""INVALID_ARGUMENT""; }; at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClient",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:1042,Deployability,Pipeline,Pipeline,1042,"rkflow written up and running locally in WDL, and I'm getting started with the JES backend. I've done a fair amount of work in google genomics before this, but this is my first use of cromwell/WDL. Some details first. I first noticed this error on 0.19.2, but went back to check 0.19 and HEAD of the develop branch. where it occurs as well. For completeness, here's my WDL file:. ```; cat ~/workflows/hello-jes.wdl ; task jes_task {; command {; echo ""Hello JES!""; }; runtime {; docker: ""ubuntu:latest""; memory: ""4G""; cpu: ""3""; zones: ""us-central1-c us-central1-a""; disks: ""/mnt/mnt1 3 SSD, /mnt/mnt2 500 HDD""; }; }; workflow jes_workflow {; call jes_task; }; ```. and the console output:. ```; [2016-04-28 15:35:51,218] [info] JesBackend [1cb9c1d2:jes_task]: echo ""Hello JES!""; Apr 28, 2016 3:35:51 PM com.google.api.client.googleapis.services.AbstractGoogleClient <init>; WARNING: Application name is not set. Call Builder#setApplicationName.; [2016-04-28 15:35:51,646] [info] JES Pipeline [1cb9c1d2:jes_task]: Inputs:; exec -> disk:local-disk relpath:exec.sh; [2016-04-28 15:35:51,647] [info] JES Pipeline [1cb9c1d2:jes_task]: Outputs:; jes_task-rc.txt -> disk:local-disk relpath:jes_task-rc.txt; [2016-04-28 15:35:51,648] [info] JES Pipeline [1cb9c1d2:jes_task]: Mounts:; c98942d68bf4c33728f1adef1bfd9ccc -> /mnt/mnt1 (3GB PERSISTENT_SSD); 4fd1d1e01455dfdd4eabcf02c1abaf55 -> /mnt/mnt2 (500GB PERSISTENT_HDD); local-disk -> /cromwell_root (10GB PERSISTENT_SSD); [2016-04-28 15:35:51,728] [warn] JesBackend [1cb9c1d2:jes_task]: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest""; } ],; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/refe",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:1159,Deployability,Pipeline,Pipeline,1159,"fair amount of work in google genomics before this, but this is my first use of cromwell/WDL. Some details first. I first noticed this error on 0.19.2, but went back to check 0.19 and HEAD of the develop branch. where it occurs as well. For completeness, here's my WDL file:. ```; cat ~/workflows/hello-jes.wdl ; task jes_task {; command {; echo ""Hello JES!""; }; runtime {; docker: ""ubuntu:latest""; memory: ""4G""; cpu: ""3""; zones: ""us-central1-c us-central1-a""; disks: ""/mnt/mnt1 3 SSD, /mnt/mnt2 500 HDD""; }; }; workflow jes_workflow {; call jes_task; }; ```. and the console output:. ```; [2016-04-28 15:35:51,218] [info] JesBackend [1cb9c1d2:jes_task]: echo ""Hello JES!""; Apr 28, 2016 3:35:51 PM com.google.api.client.googleapis.services.AbstractGoogleClient <init>; WARNING: Application name is not set. Call Builder#setApplicationName.; [2016-04-28 15:35:51,646] [info] JES Pipeline [1cb9c1d2:jes_task]: Inputs:; exec -> disk:local-disk relpath:exec.sh; [2016-04-28 15:35:51,647] [info] JES Pipeline [1cb9c1d2:jes_task]: Outputs:; jes_task-rc.txt -> disk:local-disk relpath:jes_task-rc.txt; [2016-04-28 15:35:51,648] [info] JES Pipeline [1cb9c1d2:jes_task]: Mounts:; c98942d68bf4c33728f1adef1bfd9ccc -> /mnt/mnt1 (3GB PERSISTENT_SSD); 4fd1d1e01455dfdd4eabcf02c1abaf55 -> /mnt/mnt2 (500GB PERSISTENT_HDD); local-disk -> /cromwell_root (10GB PERSISTENT_SSD); [2016-04-28 15:35:51,728] [warn] JesBackend [1cb9c1d2:jes_task]: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest""; } ],; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""status"" : ""INVALID_ARGUMENT""; }; com.google.api.client.googleapis.json.Googl",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:1296,Deployability,Pipeline,Pipeline,1296,"es_task {; command {; echo ""Hello JES!""; }; runtime {; docker: ""ubuntu:latest""; memory: ""4G""; cpu: ""3""; zones: ""us-central1-c us-central1-a""; disks: ""/mnt/mnt1 3 SSD, /mnt/mnt2 500 HDD""; }; }; workflow jes_workflow {; call jes_task; }; ```. and the console output:. ```; [2016-04-28 15:35:51,218] [info] JesBackend [1cb9c1d2:jes_task]: echo ""Hello JES!""; Apr 28, 2016 3:35:51 PM com.google.api.client.googleapis.services.AbstractGoogleClient <init>; WARNING: Application name is not set. Call Builder#setApplicationName.; [2016-04-28 15:35:51,646] [info] JES Pipeline [1cb9c1d2:jes_task]: Inputs:; exec -> disk:local-disk relpath:exec.sh; [2016-04-28 15:35:51,647] [info] JES Pipeline [1cb9c1d2:jes_task]: Outputs:; jes_task-rc.txt -> disk:local-disk relpath:jes_task-rc.txt; [2016-04-28 15:35:51,648] [info] JES Pipeline [1cb9c1d2:jes_task]: Mounts:; c98942d68bf4c33728f1adef1bfd9ccc -> /mnt/mnt1 (3GB PERSISTENT_SSD); 4fd1d1e01455dfdd4eabcf02c1abaf55 -> /mnt/mnt2 (500GB PERSISTENT_HDD); local-disk -> /cromwell_root (10GB PERSISTENT_SSD); [2016-04-28 15:35:51,728] [warn] JesBackend [1cb9c1d2:jes_task]: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest""; } ],; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""status"" : ""INVALID_ARGUMENT""; }; com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest"";",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:3736,Deployability,Pipeline,Pipeline,3736,ient.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321); at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at cromwell.engine.backend.jes.Pipeline$.createPipeline$1(Pipeline.scala:43); at cromwell.engine.backend.jes.Pipeline$.apply(Pipeline.scala:59); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$attemptToCreateJesRun$1(JesBackend.scala:563); at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$createJesRun$1.apply(JesBackend.scala:573); at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$createJesRun$1.apply(JesBackend.scala:573); at cromwell.util.TryUtil$$anonfun$5.apply(TryUtil.scala:79); at scala.util.Try$.apply(Try.scala:192); at cromwell.util.TryUtil$.retryBlock(TryUtil.scala:79); at cromwell.engine.backend.jes.JesBackend$.withRetry(JesBackend.scala:123); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$createJesRun(JesBackend.scala:573); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scala:707); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.app,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:3763,Deployability,Pipeline,Pipeline,3763,on.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321); at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at cromwell.engine.backend.jes.Pipeline$.createPipeline$1(Pipeline.scala:43); at cromwell.engine.backend.jes.Pipeline$.apply(Pipeline.scala:59); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$attemptToCreateJesRun$1(JesBackend.scala:563); at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$createJesRun$1.apply(JesBackend.scala:573); at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$createJesRun$1.apply(JesBackend.scala:573); at cromwell.util.TryUtil$$anonfun$5.apply(TryUtil.scala:79); at scala.util.Try$.apply(Try.scala:192); at cromwell.util.TryUtil$.retryBlock(TryUtil.scala:79); at cromwell.engine.backend.jes.JesBackend$.withRetry(JesBackend.scala:123); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$createJesRun(JesBackend.scala:573); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scala:707); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scal,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:3814,Deployability,Pipeline,Pipeline,3814,ion.java:145); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321); at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at cromwell.engine.backend.jes.Pipeline$.createPipeline$1(Pipeline.scala:43); at cromwell.engine.backend.jes.Pipeline$.apply(Pipeline.scala:59); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$attemptToCreateJesRun$1(JesBackend.scala:563); at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$createJesRun$1.apply(JesBackend.scala:573); at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$createJesRun$1.apply(JesBackend.scala:573); at cromwell.util.TryUtil$$anonfun$5.apply(TryUtil.scala:79); at scala.util.Try$.apply(Try.scala:192); at cromwell.util.TryUtil$.retryBlock(TryUtil.scala:79); at cromwell.engine.backend.jes.JesBackend$.withRetry(JesBackend.scala:123); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$createJesRun(JesBackend.scala:573); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scala:707); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scala:706); at scala.util.Success.flatMap(Try.scala:231); at cro,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:3830,Deployability,Pipeline,Pipeline,3830,); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321); at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at cromwell.engine.backend.jes.Pipeline$.createPipeline$1(Pipeline.scala:43); at cromwell.engine.backend.jes.Pipeline$.apply(Pipeline.scala:59); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$attemptToCreateJesRun$1(JesBackend.scala:563); at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$createJesRun$1.apply(JesBackend.scala:573); at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$createJesRun$1.apply(JesBackend.scala:573); at cromwell.util.TryUtil$$anonfun$5.apply(TryUtil.scala:79); at scala.util.Try$.apply(Try.scala:192); at cromwell.util.TryUtil$.retryBlock(TryUtil.scala:79); at cromwell.engine.backend.jes.JesBackend$.withRetry(JesBackend.scala:123); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$createJesRun(JesBackend.scala:573); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scala:707); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scala:706); at scala.util.Success.flatMap(Try.scala:231); at cromwell.engine.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:6283,Deployability,pipeline,pipelines,6283,"JesBackend.scala:123); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$createJesRun(JesBackend.scala:573); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scala:707); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scala:706); at scala.util.Success.flatMap(Try.scala:231); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$runWithJes(JesBackend.scala:706); at cromwell.engine.backend.jes.JesBackend$$anonfun$executeOrResume$1.apply(JesBackend.scala:362); at cromwell.engine.backend.jes.JesBackend$$anonfun$executeOrResume$1.apply(JesBackend.scala:350); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2016-04-28 15:35:51,730] [warn] JesBackend [1cb9c1d2:jes_task]: Exception occurred while creating JES Run. Retrying in 4742 (9 more retries)...; ```. I've walked through the stacktrace and can't see anything obviously wrong with the JesAttachedDisk.scala code, which is just running an md5sum on the params of the disk, so that should always result in a string of characters that is legal to use for a disk name, according to the provided link. I have the sense that the problem may lie in the google pipelines api code, after the params are handed off to create a pipeline. The particular disk name that's causing a problem in this example is `4fd1d1e01455dfdd4eabcf02c1abaf55`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:6347,Deployability,pipeline,pipeline,6347,"JesBackend.scala:123); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$createJesRun(JesBackend.scala:573); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scala:707); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scala:706); at scala.util.Success.flatMap(Try.scala:231); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$runWithJes(JesBackend.scala:706); at cromwell.engine.backend.jes.JesBackend$$anonfun$executeOrResume$1.apply(JesBackend.scala:362); at cromwell.engine.backend.jes.JesBackend$$anonfun$executeOrResume$1.apply(JesBackend.scala:350); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2016-04-28 15:35:51,730] [warn] JesBackend [1cb9c1d2:jes_task]: Exception occurred while creating JES Run. Retrying in 4742 (9 more retries)...; ```. I've walked through the stacktrace and can't see anything obviously wrong with the JesAttachedDisk.scala code, which is just running an md5sum on the params of the disk, so that should always result in a string of characters that is legal to use for a disk name, according to the provided link. I have the sense that the problem may lie in the google pipelines api code, after the params are handed off to create a pipeline. The particular disk name that's causing a problem in this example is `4fd1d1e01455dfdd4eabcf02c1abaf55`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:1664,Integrability,message,message,1664,"es_task {; command {; echo ""Hello JES!""; }; runtime {; docker: ""ubuntu:latest""; memory: ""4G""; cpu: ""3""; zones: ""us-central1-c us-central1-a""; disks: ""/mnt/mnt1 3 SSD, /mnt/mnt2 500 HDD""; }; }; workflow jes_workflow {; call jes_task; }; ```. and the console output:. ```; [2016-04-28 15:35:51,218] [info] JesBackend [1cb9c1d2:jes_task]: echo ""Hello JES!""; Apr 28, 2016 3:35:51 PM com.google.api.client.googleapis.services.AbstractGoogleClient <init>; WARNING: Application name is not set. Call Builder#setApplicationName.; [2016-04-28 15:35:51,646] [info] JES Pipeline [1cb9c1d2:jes_task]: Inputs:; exec -> disk:local-disk relpath:exec.sh; [2016-04-28 15:35:51,647] [info] JES Pipeline [1cb9c1d2:jes_task]: Outputs:; jes_task-rc.txt -> disk:local-disk relpath:jes_task-rc.txt; [2016-04-28 15:35:51,648] [info] JES Pipeline [1cb9c1d2:jes_task]: Mounts:; c98942d68bf4c33728f1adef1bfd9ccc -> /mnt/mnt1 (3GB PERSISTENT_SSD); 4fd1d1e01455dfdd4eabcf02c1abaf55 -> /mnt/mnt2 (500GB PERSISTENT_HDD); local-disk -> /cromwell_root (10GB PERSISTENT_SSD); [2016-04-28 15:35:51,728] [warn] JesBackend [1cb9c1d2:jes_task]: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest""; } ],; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""status"" : ""INVALID_ARGUMENT""; }; com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest"";",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:1892,Integrability,message,message,1892,".client.googleapis.services.AbstractGoogleClient <init>; WARNING: Application name is not set. Call Builder#setApplicationName.; [2016-04-28 15:35:51,646] [info] JES Pipeline [1cb9c1d2:jes_task]: Inputs:; exec -> disk:local-disk relpath:exec.sh; [2016-04-28 15:35:51,647] [info] JES Pipeline [1cb9c1d2:jes_task]: Outputs:; jes_task-rc.txt -> disk:local-disk relpath:jes_task-rc.txt; [2016-04-28 15:35:51,648] [info] JES Pipeline [1cb9c1d2:jes_task]: Mounts:; c98942d68bf4c33728f1adef1bfd9ccc -> /mnt/mnt1 (3GB PERSISTENT_SSD); 4fd1d1e01455dfdd4eabcf02c1abaf55 -> /mnt/mnt2 (500GB PERSISTENT_HDD); local-disk -> /cromwell_root (10GB PERSISTENT_SSD); [2016-04-28 15:35:51,728] [warn] JesBackend [1cb9c1d2:jes_task]: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest""; } ],; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""status"" : ""INVALID_ARGUMENT""; }; com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest""; } ],; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""status"" : ""INVALID_ARGUMENT""; }; at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); at com.google.api.client.googleapis.servic",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:2263,Integrability,message,message,2263,"elpath:jes_task-rc.txt; [2016-04-28 15:35:51,648] [info] JES Pipeline [1cb9c1d2:jes_task]: Mounts:; c98942d68bf4c33728f1adef1bfd9ccc -> /mnt/mnt1 (3GB PERSISTENT_SSD); 4fd1d1e01455dfdd4eabcf02c1abaf55 -> /mnt/mnt2 (500GB PERSISTENT_HDD); local-disk -> /cromwell_root (10GB PERSISTENT_SSD); [2016-04-28 15:35:51,728] [warn] JesBackend [1cb9c1d2:jes_task]: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest""; } ],; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""status"" : ""INVALID_ARGUMENT""; }; com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest""; } ],; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""status"" : ""INVALID_ARGUMENT""; }; at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClient",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:2491,Integrability,message,message,2491,"cal-disk -> /cromwell_root (10GB PERSISTENT_SSD); [2016-04-28 15:35:51,728] [warn] JesBackend [1cb9c1d2:jes_task]: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest""; } ],; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""status"" : ""INVALID_ARGUMENT""; }; com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest""; } ],; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""status"" : ""INVALID_ARGUMENT""; }; at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321); at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at com.google.api.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:5134,Performance,concurren,concurrent,5134,"d.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$createJesRun$1.apply(JesBackend.scala:573); at cromwell.util.TryUtil$$anonfun$5.apply(TryUtil.scala:79); at scala.util.Try$.apply(Try.scala:192); at cromwell.util.TryUtil$.retryBlock(TryUtil.scala:79); at cromwell.engine.backend.jes.JesBackend$.withRetry(JesBackend.scala:123); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$createJesRun(JesBackend.scala:573); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scala:707); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scala:706); at scala.util.Success.flatMap(Try.scala:231); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$runWithJes(JesBackend.scala:706); at cromwell.engine.backend.jes.JesBackend$$anonfun$executeOrResume$1.apply(JesBackend.scala:362); at cromwell.engine.backend.jes.JesBackend$$anonfun$executeOrResume$1.apply(JesBackend.scala:350); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2016-04-28 15:35:51,730] [warn] JesBackend [1cb9c1d2:jes_task]: Exception occurred while creating JES Run. Retrying in 4742 (9 more retries)...; ```. I've walked through the stacktrace and can't see anything obviously wrong with the JesAttachedDisk.scala code, which is just running an md5sum on the params of the disk, so that should always result in a stri",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:5224,Performance,concurren,concurrent,5224,"Backend.scala:573); at cromwell.util.TryUtil$$anonfun$5.apply(TryUtil.scala:79); at scala.util.Try$.apply(Try.scala:192); at cromwell.util.TryUtil$.retryBlock(TryUtil.scala:79); at cromwell.engine.backend.jes.JesBackend$.withRetry(JesBackend.scala:123); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$createJesRun(JesBackend.scala:573); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scala:707); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scala:706); at scala.util.Success.flatMap(Try.scala:231); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$runWithJes(JesBackend.scala:706); at cromwell.engine.backend.jes.JesBackend$$anonfun$executeOrResume$1.apply(JesBackend.scala:362); at cromwell.engine.backend.jes.JesBackend$$anonfun$executeOrResume$1.apply(JesBackend.scala:350); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2016-04-28 15:35:51,730] [warn] JesBackend [1cb9c1d2:jes_task]: Exception occurred while creating JES Run. Retrying in 4742 (9 more retries)...; ```. I've walked through the stacktrace and can't see anything obviously wrong with the JesAttachedDisk.scala code, which is just running an md5sum on the params of the disk, so that should always result in a string of characters that is legal to use for a disk name, according to the provided link. I h",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:5469,Performance,concurren,concurrent,5469,"JesBackend.scala:123); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$createJesRun(JesBackend.scala:573); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scala:707); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scala:706); at scala.util.Success.flatMap(Try.scala:231); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$runWithJes(JesBackend.scala:706); at cromwell.engine.backend.jes.JesBackend$$anonfun$executeOrResume$1.apply(JesBackend.scala:362); at cromwell.engine.backend.jes.JesBackend$$anonfun$executeOrResume$1.apply(JesBackend.scala:350); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2016-04-28 15:35:51,730] [warn] JesBackend [1cb9c1d2:jes_task]: Exception occurred while creating JES Run. Retrying in 4742 (9 more retries)...; ```. I've walked through the stacktrace and can't see anything obviously wrong with the JesAttachedDisk.scala code, which is just running an md5sum on the params of the disk, so that should always result in a string of characters that is legal to use for a disk name, according to the provided link. I have the sense that the problem may lie in the google pipelines api code, after the params are handed off to create a pipeline. The particular disk name that's causing a problem in this example is `4fd1d1e01455dfdd4eabcf02c1abaf55`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:5542,Performance,concurren,concurrent,5542,"JesBackend.scala:123); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$createJesRun(JesBackend.scala:573); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scala:707); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scala:706); at scala.util.Success.flatMap(Try.scala:231); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$runWithJes(JesBackend.scala:706); at cromwell.engine.backend.jes.JesBackend$$anonfun$executeOrResume$1.apply(JesBackend.scala:362); at cromwell.engine.backend.jes.JesBackend$$anonfun$executeOrResume$1.apply(JesBackend.scala:350); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2016-04-28 15:35:51,730] [warn] JesBackend [1cb9c1d2:jes_task]: Exception occurred while creating JES Run. Retrying in 4742 (9 more retries)...; ```. I've walked through the stacktrace and can't see anything obviously wrong with the JesAttachedDisk.scala code, which is just running an md5sum on the params of the disk, so that should always result in a string of characters that is legal to use for a disk name, according to the provided link. I have the sense that the problem may lie in the google pipelines api code, after the params are handed off to create a pipeline. The particular disk name that's causing a problem in this example is `4fd1d1e01455dfdd4eabcf02c1abaf55`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:5627,Performance,concurren,concurrent,5627,"JesBackend.scala:123); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$createJesRun(JesBackend.scala:573); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scala:707); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scala:706); at scala.util.Success.flatMap(Try.scala:231); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$runWithJes(JesBackend.scala:706); at cromwell.engine.backend.jes.JesBackend$$anonfun$executeOrResume$1.apply(JesBackend.scala:362); at cromwell.engine.backend.jes.JesBackend$$anonfun$executeOrResume$1.apply(JesBackend.scala:350); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2016-04-28 15:35:51,730] [warn] JesBackend [1cb9c1d2:jes_task]: Exception occurred while creating JES Run. Retrying in 4742 (9 more retries)...; ```. I've walked through the stacktrace and can't see anything obviously wrong with the JesAttachedDisk.scala code, which is just running an md5sum on the params of the disk, so that should always result in a string of characters that is legal to use for a disk name, according to the provided link. I have the sense that the problem may lie in the google pipelines api code, after the params are handed off to create a pipeline. The particular disk name that's causing a problem in this example is `4fd1d1e01455dfdd4eabcf02c1abaf55`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/issues/757:5704,Performance,concurren,concurrent,5704,"JesBackend.scala:123); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$createJesRun(JesBackend.scala:573); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scala:707); at cromwell.engine.backend.jes.JesBackend$$anonfun$35.apply(JesBackend.scala:706); at scala.util.Success.flatMap(Try.scala:231); at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$runWithJes(JesBackend.scala:706); at cromwell.engine.backend.jes.JesBackend$$anonfun$executeOrResume$1.apply(JesBackend.scala:362); at cromwell.engine.backend.jes.JesBackend$$anonfun$executeOrResume$1.apply(JesBackend.scala:350); at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2016-04-28 15:35:51,730] [warn] JesBackend [1cb9c1d2:jes_task]: Exception occurred while creating JES Run. Retrying in 4742 (9 more retries)...; ```. I've walked through the stacktrace and can't see anything obviously wrong with the JesAttachedDisk.scala code, which is just running an md5sum on the params of the disk, so that should always result in a string of characters that is legal to use for a disk name, according to the provided link. I have the sense that the problem may lie in the google pipelines api code, after the params are handed off to create a pipeline. The particular disk name that's causing a problem in this example is `4fd1d1e01455dfdd4eabcf02c1abaf55`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757
https://github.com/broadinstitute/cromwell/pull/759:249,Availability,Failure,Failure,249,"The idea being, sending an abort message does not get an `AbortSuccess` or `AbortFailed` response directly. Instead, the actor being aborted will cause its operation to fail and the parent should expect an ""Aborted"" response instead of a Success or Failure (although a Success or Failure may still be returned anyway). In this way, it's acceptable for a backend implementor to simply do nothing when `abort` is received. The parent will just continue waiting for a result of some sort.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/759
https://github.com/broadinstitute/cromwell/pull/759:280,Availability,Failure,Failure,280,"The idea being, sending an abort message does not get an `AbortSuccess` or `AbortFailed` response directly. Instead, the actor being aborted will cause its operation to fail and the parent should expect an ""Aborted"" response instead of a Success or Failure (although a Success or Failure may still be returned anyway). In this way, it's acceptable for a backend implementor to simply do nothing when `abort` is received. The parent will just continue waiting for a result of some sort.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/759
https://github.com/broadinstitute/cromwell/pull/759:33,Integrability,message,message,33,"The idea being, sending an abort message does not get an `AbortSuccess` or `AbortFailed` response directly. Instead, the actor being aborted will cause its operation to fail and the parent should expect an ""Aborted"" response instead of a Success or Failure (although a Success or Failure may still be returned anyway). In this way, it's acceptable for a backend implementor to simply do nothing when `abort` is received. The parent will just continue waiting for a result of some sort.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/759
https://github.com/broadinstitute/cromwell/pull/759:27,Safety,abort,abort,27,"The idea being, sending an abort message does not get an `AbortSuccess` or `AbortFailed` response directly. Instead, the actor being aborted will cause its operation to fail and the parent should expect an ""Aborted"" response instead of a Success or Failure (although a Success or Failure may still be returned anyway). In this way, it's acceptable for a backend implementor to simply do nothing when `abort` is received. The parent will just continue waiting for a result of some sort.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/759
https://github.com/broadinstitute/cromwell/pull/759:58,Safety,Abort,AbortSuccess,58,"The idea being, sending an abort message does not get an `AbortSuccess` or `AbortFailed` response directly. Instead, the actor being aborted will cause its operation to fail and the parent should expect an ""Aborted"" response instead of a Success or Failure (although a Success or Failure may still be returned anyway). In this way, it's acceptable for a backend implementor to simply do nothing when `abort` is received. The parent will just continue waiting for a result of some sort.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/759
https://github.com/broadinstitute/cromwell/pull/759:76,Safety,Abort,AbortFailed,76,"The idea being, sending an abort message does not get an `AbortSuccess` or `AbortFailed` response directly. Instead, the actor being aborted will cause its operation to fail and the parent should expect an ""Aborted"" response instead of a Success or Failure (although a Success or Failure may still be returned anyway). In this way, it's acceptable for a backend implementor to simply do nothing when `abort` is received. The parent will just continue waiting for a result of some sort.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/759
https://github.com/broadinstitute/cromwell/pull/759:133,Safety,abort,aborted,133,"The idea being, sending an abort message does not get an `AbortSuccess` or `AbortFailed` response directly. Instead, the actor being aborted will cause its operation to fail and the parent should expect an ""Aborted"" response instead of a Success or Failure (although a Success or Failure may still be returned anyway). In this way, it's acceptable for a backend implementor to simply do nothing when `abort` is received. The parent will just continue waiting for a result of some sort.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/759
https://github.com/broadinstitute/cromwell/pull/759:207,Safety,Abort,Aborted,207,"The idea being, sending an abort message does not get an `AbortSuccess` or `AbortFailed` response directly. Instead, the actor being aborted will cause its operation to fail and the parent should expect an ""Aborted"" response instead of a Success or Failure (although a Success or Failure may still be returned anyway). In this way, it's acceptable for a backend implementor to simply do nothing when `abort` is received. The parent will just continue waiting for a result of some sort.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/759
https://github.com/broadinstitute/cromwell/pull/759:401,Safety,abort,abort,401,"The idea being, sending an abort message does not get an `AbortSuccess` or `AbortFailed` response directly. Instead, the actor being aborted will cause its operation to fail and the parent should expect an ""Aborted"" response instead of a Success or Failure (although a Success or Failure may still be returned anyway). In this way, it's acceptable for a backend implementor to simply do nothing when `abort` is received. The parent will just continue waiting for a result of some sort.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/759
https://github.com/broadinstitute/cromwell/pull/759:377,Usability,simpl,simply,377,"The idea being, sending an abort message does not get an `AbortSuccess` or `AbortFailed` response directly. Instead, the actor being aborted will cause its operation to fail and the parent should expect an ""Aborted"" response instead of a Success or Failure (although a Success or Failure may still be returned anyway). In this way, it's acceptable for a backend implementor to simply do nothing when `abort` is received. The parent will just continue waiting for a result of some sort.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/759
https://github.com/broadinstitute/cromwell/issues/760:126,Usability,simpl,simply,126,"We're now at a point where instead of keeping both workflow actor's, we're going to be rid of the old/original (OG) WFA's and simply keep the Shadow WFA. Please delete the files related to old WFA.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/760
https://github.com/broadinstitute/cromwell/pull/766:6,Deployability,update,update,6,"- [x] update README; - [x] let everybody know they need to update their configs; - [x] create ticket describing surprising `src` + `test` config overlay, not to be fixed as part of this work! (https://github.com/broadinstitute/cromwell/issues/768)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/766
https://github.com/broadinstitute/cromwell/pull/766:59,Deployability,update,update,59,"- [x] update README; - [x] let everybody know they need to update their configs; - [x] create ticket describing surprising `src` + `test` config overlay, not to be fixed as part of this work! (https://github.com/broadinstitute/cromwell/issues/768)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/766
https://github.com/broadinstitute/cromwell/pull/766:72,Modifiability,config,configs,72,"- [x] update README; - [x] let everybody know they need to update their configs; - [x] create ticket describing surprising `src` + `test` config overlay, not to be fixed as part of this work! (https://github.com/broadinstitute/cromwell/issues/768)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/766
https://github.com/broadinstitute/cromwell/pull/766:138,Modifiability,config,config,138,"- [x] update README; - [x] let everybody know they need to update their configs; - [x] create ticket describing surprising `src` + `test` config overlay, not to be fixed as part of this work! (https://github.com/broadinstitute/cromwell/issues/768)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/766
https://github.com/broadinstitute/cromwell/pull/766:132,Testability,test,test,132,"- [x] update README; - [x] let everybody know they need to update their configs; - [x] create ticket describing surprising `src` + `test` config overlay, not to be fixed as part of this work! (https://github.com/broadinstitute/cromwell/issues/768)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/766
https://github.com/broadinstitute/cromwell/issues/768:240,Deployability,configurat,configuration,240,"Cromwell tests have an application.conf file... and the main source code has a default application.conf file. The test application.conf overwrites values in the main one, but this has caused confusion in the past. It'd be nicer if only one configuration file were used during tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/768
https://github.com/broadinstitute/cromwell/issues/768:240,Modifiability,config,configuration,240,"Cromwell tests have an application.conf file... and the main source code has a default application.conf file. The test application.conf overwrites values in the main one, but this has caused confusion in the past. It'd be nicer if only one configuration file were used during tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/768
https://github.com/broadinstitute/cromwell/issues/768:9,Testability,test,tests,9,"Cromwell tests have an application.conf file... and the main source code has a default application.conf file. The test application.conf overwrites values in the main one, but this has caused confusion in the past. It'd be nicer if only one configuration file were used during tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/768
https://github.com/broadinstitute/cromwell/issues/768:114,Testability,test,test,114,"Cromwell tests have an application.conf file... and the main source code has a default application.conf file. The test application.conf overwrites values in the main one, but this has caused confusion in the past. It'd be nicer if only one configuration file were used during tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/768
https://github.com/broadinstitute/cromwell/issues/768:276,Testability,test,tests,276,"Cromwell tests have an application.conf file... and the main source code has a default application.conf file. The test application.conf overwrites values in the main one, but this has caused confusion in the past. It'd be nicer if only one configuration file were used during tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/768
https://github.com/broadinstitute/cromwell/pull/769:117,Deployability,patch,patch,117,~~TODO~~ DONE:; - [x] Confirm existing spec TODOs are ok; - [x] Confirm reviewers are ok with naming; - [x] Add same patch to develop,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/769
https://github.com/broadinstitute/cromwell/issues/773:14,Performance,perform,perform,14,"Find a way to perform FinalCalls as functions with a WorkflowActor State . WorkflowActor uses some state to run various final file copies: ; - Possibly use the existing Finalizing state; - Possibly create another state that means the workflow is in this phase of running this specific group operations. If the process dies during this state, upon restart, the workflow would retry copying all of the files, meaning the final actions: ; - Do not need to be a CallKey or other JobKey/ExecutionStoreKey; - Do not need to be tracked in the WorkflowActor ExecutionStore; - Do not need to be individually tracked with state in the database’s Execution table; - Will possibly use more IO than strictly necessary on restart, as we don’t know what copies succeeded and what failed",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/773
https://github.com/broadinstitute/cromwell/pull/774:588,Testability,test,tests,588,"This PR removes the option of using the OldeStyle mode. OldeStyle classes remain because it's still too painful to remove them but I've instead deprecated almost anything which isn't currently part of the shadow workflow lifecycle. Note to reviewers: If something is deprecated but you believe it will be useful **in its current form** then I should un-deprecate it. If you believe it will be useful **in a heavily modified form** then I will leave it deprecated. Likewise, if there are un-deprecated things which would match the above criteria, that's a valid comment too!; - [x] Remove tests which are failing",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/774
https://github.com/broadinstitute/cromwell/issues/775:20,Availability,error,errors,20,GreenTeam saw 3 406 errors when polling our workflows for status. These occurred on 5/3/2016. Error hitting REST API: https://<REDACTED>/api/workflows/v1/ca25d78b-3d4c-4336-b9b8-c64e8ea0dc43/status => Unexpected response code: 406; Error hitting REST API: https://<REDACTED>/api/workflows/v1/ca25d78b-3d4c-4336-b9b8-c64e8ea0dc43/status => Unexpected response code: 406; Error hitting REST API: https://<REDACTED>/api/workflows/v1/ca25d78b-3d4c-4336-b9b8-c64e8ea0dc43/status => Unexpected response code: 406,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/775
https://github.com/broadinstitute/cromwell/issues/775:94,Availability,Error,Error,94,GreenTeam saw 3 406 errors when polling our workflows for status. These occurred on 5/3/2016. Error hitting REST API: https://<REDACTED>/api/workflows/v1/ca25d78b-3d4c-4336-b9b8-c64e8ea0dc43/status => Unexpected response code: 406; Error hitting REST API: https://<REDACTED>/api/workflows/v1/ca25d78b-3d4c-4336-b9b8-c64e8ea0dc43/status => Unexpected response code: 406; Error hitting REST API: https://<REDACTED>/api/workflows/v1/ca25d78b-3d4c-4336-b9b8-c64e8ea0dc43/status => Unexpected response code: 406,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/775
https://github.com/broadinstitute/cromwell/issues/775:232,Availability,Error,Error,232,GreenTeam saw 3 406 errors when polling our workflows for status. These occurred on 5/3/2016. Error hitting REST API: https://<REDACTED>/api/workflows/v1/ca25d78b-3d4c-4336-b9b8-c64e8ea0dc43/status => Unexpected response code: 406; Error hitting REST API: https://<REDACTED>/api/workflows/v1/ca25d78b-3d4c-4336-b9b8-c64e8ea0dc43/status => Unexpected response code: 406; Error hitting REST API: https://<REDACTED>/api/workflows/v1/ca25d78b-3d4c-4336-b9b8-c64e8ea0dc43/status => Unexpected response code: 406,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/775
https://github.com/broadinstitute/cromwell/issues/775:370,Availability,Error,Error,370,GreenTeam saw 3 406 errors when polling our workflows for status. These occurred on 5/3/2016. Error hitting REST API: https://<REDACTED>/api/workflows/v1/ca25d78b-3d4c-4336-b9b8-c64e8ea0dc43/status => Unexpected response code: 406; Error hitting REST API: https://<REDACTED>/api/workflows/v1/ca25d78b-3d4c-4336-b9b8-c64e8ea0dc43/status => Unexpected response code: 406; Error hitting REST API: https://<REDACTED>/api/workflows/v1/ca25d78b-3d4c-4336-b9b8-c64e8ea0dc43/status => Unexpected response code: 406,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/775
https://github.com/broadinstitute/cromwell/issues/775:0,Energy Efficiency,Green,GreenTeam,0,GreenTeam saw 3 406 errors when polling our workflows for status. These occurred on 5/3/2016. Error hitting REST API: https://<REDACTED>/api/workflows/v1/ca25d78b-3d4c-4336-b9b8-c64e8ea0dc43/status => Unexpected response code: 406; Error hitting REST API: https://<REDACTED>/api/workflows/v1/ca25d78b-3d4c-4336-b9b8-c64e8ea0dc43/status => Unexpected response code: 406; Error hitting REST API: https://<REDACTED>/api/workflows/v1/ca25d78b-3d4c-4336-b9b8-c64e8ea0dc43/status => Unexpected response code: 406,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/775
https://github.com/broadinstitute/cromwell/issues/776:50,Deployability,deploy,deploy,50,"Upon a commit to ""a branch"" (TBD, develop, maybe) deploy centaur-cromwell-mysql infrastructure and run ""short"" tests",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/776
https://github.com/broadinstitute/cromwell/issues/776:111,Testability,test,tests,111,"Upon a commit to ""a branch"" (TBD, develop, maybe) deploy centaur-cromwell-mysql infrastructure and run ""short"" tests",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/776
https://github.com/broadinstitute/cromwell/issues/778:538,Availability,error,error,538,"This is more of an epic and not a right now thing, but I wanted to capture the thought for future consideration. In the author's not-so-humble opinion we log way too much stuff, to the point that logs aren't particularly useful unless you know exactly what you're looking for. We also know that Cromwell's logs are blowing apart loggly and stuff like that. We also manage to log some stuff (e.g. stacktraces) multiple times for one incident. We also have many issues where logs would be super helpful yet all we see is something like ""an error occurred"" without any context. We should sit down as a group and with focus groups of downstream clients (e.g. firecloud, gotc) and go through what we're logging and look for ways to both massively debulk our logs as well as making sure that we're logging the most useful stuff.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/778
https://github.com/broadinstitute/cromwell/issues/778:589,Availability,down,down,589,"This is more of an epic and not a right now thing, but I wanted to capture the thought for future consideration. In the author's not-so-humble opinion we log way too much stuff, to the point that logs aren't particularly useful unless you know exactly what you're looking for. We also know that Cromwell's logs are blowing apart loggly and stuff like that. We also manage to log some stuff (e.g. stacktraces) multiple times for one incident. We also have many issues where logs would be super helpful yet all we see is something like ""an error occurred"" without any context. We should sit down as a group and with focus groups of downstream clients (e.g. firecloud, gotc) and go through what we're logging and look for ways to both massively debulk our logs as well as making sure that we're logging the most useful stuff.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/778
https://github.com/broadinstitute/cromwell/issues/778:630,Availability,down,downstream,630,"This is more of an epic and not a right now thing, but I wanted to capture the thought for future consideration. In the author's not-so-humble opinion we log way too much stuff, to the point that logs aren't particularly useful unless you know exactly what you're looking for. We also know that Cromwell's logs are blowing apart loggly and stuff like that. We also manage to log some stuff (e.g. stacktraces) multiple times for one incident. We also have many issues where logs would be super helpful yet all we see is something like ""an error occurred"" without any context. We should sit down as a group and with focus groups of downstream clients (e.g. firecloud, gotc) and go through what we're logging and look for ways to both massively debulk our logs as well as making sure that we're logging the most useful stuff.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/778
https://github.com/broadinstitute/cromwell/issues/778:154,Testability,log,log,154,"This is more of an epic and not a right now thing, but I wanted to capture the thought for future consideration. In the author's not-so-humble opinion we log way too much stuff, to the point that logs aren't particularly useful unless you know exactly what you're looking for. We also know that Cromwell's logs are blowing apart loggly and stuff like that. We also manage to log some stuff (e.g. stacktraces) multiple times for one incident. We also have many issues where logs would be super helpful yet all we see is something like ""an error occurred"" without any context. We should sit down as a group and with focus groups of downstream clients (e.g. firecloud, gotc) and go through what we're logging and look for ways to both massively debulk our logs as well as making sure that we're logging the most useful stuff.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/778
https://github.com/broadinstitute/cromwell/issues/778:196,Testability,log,logs,196,"This is more of an epic and not a right now thing, but I wanted to capture the thought for future consideration. In the author's not-so-humble opinion we log way too much stuff, to the point that logs aren't particularly useful unless you know exactly what you're looking for. We also know that Cromwell's logs are blowing apart loggly and stuff like that. We also manage to log some stuff (e.g. stacktraces) multiple times for one incident. We also have many issues where logs would be super helpful yet all we see is something like ""an error occurred"" without any context. We should sit down as a group and with focus groups of downstream clients (e.g. firecloud, gotc) and go through what we're logging and look for ways to both massively debulk our logs as well as making sure that we're logging the most useful stuff.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/778
https://github.com/broadinstitute/cromwell/issues/778:306,Testability,log,logs,306,"This is more of an epic and not a right now thing, but I wanted to capture the thought for future consideration. In the author's not-so-humble opinion we log way too much stuff, to the point that logs aren't particularly useful unless you know exactly what you're looking for. We also know that Cromwell's logs are blowing apart loggly and stuff like that. We also manage to log some stuff (e.g. stacktraces) multiple times for one incident. We also have many issues where logs would be super helpful yet all we see is something like ""an error occurred"" without any context. We should sit down as a group and with focus groups of downstream clients (e.g. firecloud, gotc) and go through what we're logging and look for ways to both massively debulk our logs as well as making sure that we're logging the most useful stuff.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/778
https://github.com/broadinstitute/cromwell/issues/778:329,Testability,log,loggly,329,"This is more of an epic and not a right now thing, but I wanted to capture the thought for future consideration. In the author's not-so-humble opinion we log way too much stuff, to the point that logs aren't particularly useful unless you know exactly what you're looking for. We also know that Cromwell's logs are blowing apart loggly and stuff like that. We also manage to log some stuff (e.g. stacktraces) multiple times for one incident. We also have many issues where logs would be super helpful yet all we see is something like ""an error occurred"" without any context. We should sit down as a group and with focus groups of downstream clients (e.g. firecloud, gotc) and go through what we're logging and look for ways to both massively debulk our logs as well as making sure that we're logging the most useful stuff.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/778
https://github.com/broadinstitute/cromwell/issues/778:375,Testability,log,log,375,"This is more of an epic and not a right now thing, but I wanted to capture the thought for future consideration. In the author's not-so-humble opinion we log way too much stuff, to the point that logs aren't particularly useful unless you know exactly what you're looking for. We also know that Cromwell's logs are blowing apart loggly and stuff like that. We also manage to log some stuff (e.g. stacktraces) multiple times for one incident. We also have many issues where logs would be super helpful yet all we see is something like ""an error occurred"" without any context. We should sit down as a group and with focus groups of downstream clients (e.g. firecloud, gotc) and go through what we're logging and look for ways to both massively debulk our logs as well as making sure that we're logging the most useful stuff.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/778
https://github.com/broadinstitute/cromwell/issues/778:473,Testability,log,logs,473,"This is more of an epic and not a right now thing, but I wanted to capture the thought for future consideration. In the author's not-so-humble opinion we log way too much stuff, to the point that logs aren't particularly useful unless you know exactly what you're looking for. We also know that Cromwell's logs are blowing apart loggly and stuff like that. We also manage to log some stuff (e.g. stacktraces) multiple times for one incident. We also have many issues where logs would be super helpful yet all we see is something like ""an error occurred"" without any context. We should sit down as a group and with focus groups of downstream clients (e.g. firecloud, gotc) and go through what we're logging and look for ways to both massively debulk our logs as well as making sure that we're logging the most useful stuff.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/778
https://github.com/broadinstitute/cromwell/issues/778:698,Testability,log,logging,698,"This is more of an epic and not a right now thing, but I wanted to capture the thought for future consideration. In the author's not-so-humble opinion we log way too much stuff, to the point that logs aren't particularly useful unless you know exactly what you're looking for. We also know that Cromwell's logs are blowing apart loggly and stuff like that. We also manage to log some stuff (e.g. stacktraces) multiple times for one incident. We also have many issues where logs would be super helpful yet all we see is something like ""an error occurred"" without any context. We should sit down as a group and with focus groups of downstream clients (e.g. firecloud, gotc) and go through what we're logging and look for ways to both massively debulk our logs as well as making sure that we're logging the most useful stuff.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/778
https://github.com/broadinstitute/cromwell/issues/778:753,Testability,log,logs,753,"This is more of an epic and not a right now thing, but I wanted to capture the thought for future consideration. In the author's not-so-humble opinion we log way too much stuff, to the point that logs aren't particularly useful unless you know exactly what you're looking for. We also know that Cromwell's logs are blowing apart loggly and stuff like that. We also manage to log some stuff (e.g. stacktraces) multiple times for one incident. We also have many issues where logs would be super helpful yet all we see is something like ""an error occurred"" without any context. We should sit down as a group and with focus groups of downstream clients (e.g. firecloud, gotc) and go through what we're logging and look for ways to both massively debulk our logs as well as making sure that we're logging the most useful stuff.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/778
https://github.com/broadinstitute/cromwell/issues/778:792,Testability,log,logging,792,"This is more of an epic and not a right now thing, but I wanted to capture the thought for future consideration. In the author's not-so-humble opinion we log way too much stuff, to the point that logs aren't particularly useful unless you know exactly what you're looking for. We also know that Cromwell's logs are blowing apart loggly and stuff like that. We also manage to log some stuff (e.g. stacktraces) multiple times for one incident. We also have many issues where logs would be super helpful yet all we see is something like ""an error occurred"" without any context. We should sit down as a group and with focus groups of downstream clients (e.g. firecloud, gotc) and go through what we're logging and look for ways to both massively debulk our logs as well as making sure that we're logging the most useful stuff.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/778
https://github.com/broadinstitute/cromwell/issues/781:701,Availability,error,error,701,"While using Jes + call caching enabled, if you call on a task with a new name, then when Jes will copy the outputs from the previously performed task but will not rename the files to the new name. For example, my WDL has a task two, and in the workflow I ""call two as four"". ; - When I check within the google bucket for call four, all the files are named as ""two-stdout.log"", ""call two-stderr.log"". ; - When I check within the google bucket for call two, there are a group of files named call two and a group of files named call four. It appears that although the appropriate files for call four are created, they aren't moved into the call four directory in google. So when I run the WF, I get this error: ; ""failure"": ""Item not found: cloud-cromwell-dev/cromwell-executions/cacheWithinWF/c972cace-b423-4c1c-87e4-01356163757f/call-four/four-stdout.log"". Because although the file four-stdout.log actually exists, it exists under the directory call-two instead of call-four.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/781
https://github.com/broadinstitute/cromwell/issues/781:711,Availability,failure,failure,711,"While using Jes + call caching enabled, if you call on a task with a new name, then when Jes will copy the outputs from the previously performed task but will not rename the files to the new name. For example, my WDL has a task two, and in the workflow I ""call two as four"". ; - When I check within the google bucket for call four, all the files are named as ""two-stdout.log"", ""call two-stderr.log"". ; - When I check within the google bucket for call two, there are a group of files named call two and a group of files named call four. It appears that although the appropriate files for call four are created, they aren't moved into the call four directory in google. So when I run the WF, I get this error: ; ""failure"": ""Item not found: cloud-cromwell-dev/cromwell-executions/cacheWithinWF/c972cace-b423-4c1c-87e4-01356163757f/call-four/four-stdout.log"". Because although the file four-stdout.log actually exists, it exists under the directory call-two instead of call-four.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/781
https://github.com/broadinstitute/cromwell/issues/781:135,Performance,perform,performed,135,"While using Jes + call caching enabled, if you call on a task with a new name, then when Jes will copy the outputs from the previously performed task but will not rename the files to the new name. For example, my WDL has a task two, and in the workflow I ""call two as four"". ; - When I check within the google bucket for call four, all the files are named as ""two-stdout.log"", ""call two-stderr.log"". ; - When I check within the google bucket for call two, there are a group of files named call two and a group of files named call four. It appears that although the appropriate files for call four are created, they aren't moved into the call four directory in google. So when I run the WF, I get this error: ; ""failure"": ""Item not found: cloud-cromwell-dev/cromwell-executions/cacheWithinWF/c972cace-b423-4c1c-87e4-01356163757f/call-four/four-stdout.log"". Because although the file four-stdout.log actually exists, it exists under the directory call-two instead of call-four.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/781
https://github.com/broadinstitute/cromwell/issues/781:777,Performance,cache,cacheWithinWF,777,"While using Jes + call caching enabled, if you call on a task with a new name, then when Jes will copy the outputs from the previously performed task but will not rename the files to the new name. For example, my WDL has a task two, and in the workflow I ""call two as four"". ; - When I check within the google bucket for call four, all the files are named as ""two-stdout.log"", ""call two-stderr.log"". ; - When I check within the google bucket for call two, there are a group of files named call two and a group of files named call four. It appears that although the appropriate files for call four are created, they aren't moved into the call four directory in google. So when I run the WF, I get this error: ; ""failure"": ""Item not found: cloud-cromwell-dev/cromwell-executions/cacheWithinWF/c972cace-b423-4c1c-87e4-01356163757f/call-four/four-stdout.log"". Because although the file four-stdout.log actually exists, it exists under the directory call-two instead of call-four.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/781
https://github.com/broadinstitute/cromwell/issues/781:371,Testability,log,log,371,"While using Jes + call caching enabled, if you call on a task with a new name, then when Jes will copy the outputs from the previously performed task but will not rename the files to the new name. For example, my WDL has a task two, and in the workflow I ""call two as four"". ; - When I check within the google bucket for call four, all the files are named as ""two-stdout.log"", ""call two-stderr.log"". ; - When I check within the google bucket for call two, there are a group of files named call two and a group of files named call four. It appears that although the appropriate files for call four are created, they aren't moved into the call four directory in google. So when I run the WF, I get this error: ; ""failure"": ""Item not found: cloud-cromwell-dev/cromwell-executions/cacheWithinWF/c972cace-b423-4c1c-87e4-01356163757f/call-four/four-stdout.log"". Because although the file four-stdout.log actually exists, it exists under the directory call-two instead of call-four.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/781
https://github.com/broadinstitute/cromwell/issues/781:394,Testability,log,log,394,"While using Jes + call caching enabled, if you call on a task with a new name, then when Jes will copy the outputs from the previously performed task but will not rename the files to the new name. For example, my WDL has a task two, and in the workflow I ""call two as four"". ; - When I check within the google bucket for call four, all the files are named as ""two-stdout.log"", ""call two-stderr.log"". ; - When I check within the google bucket for call two, there are a group of files named call two and a group of files named call four. It appears that although the appropriate files for call four are created, they aren't moved into the call four directory in google. So when I run the WF, I get this error: ; ""failure"": ""Item not found: cloud-cromwell-dev/cromwell-executions/cacheWithinWF/c972cace-b423-4c1c-87e4-01356163757f/call-four/four-stdout.log"". Because although the file four-stdout.log actually exists, it exists under the directory call-two instead of call-four.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/781
https://github.com/broadinstitute/cromwell/issues/781:850,Testability,log,log,850,"While using Jes + call caching enabled, if you call on a task with a new name, then when Jes will copy the outputs from the previously performed task but will not rename the files to the new name. For example, my WDL has a task two, and in the workflow I ""call two as four"". ; - When I check within the google bucket for call four, all the files are named as ""two-stdout.log"", ""call two-stderr.log"". ; - When I check within the google bucket for call two, there are a group of files named call two and a group of files named call four. It appears that although the appropriate files for call four are created, they aren't moved into the call four directory in google. So when I run the WF, I get this error: ; ""failure"": ""Item not found: cloud-cromwell-dev/cromwell-executions/cacheWithinWF/c972cace-b423-4c1c-87e4-01356163757f/call-four/four-stdout.log"". Because although the file four-stdout.log actually exists, it exists under the directory call-two instead of call-four.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/781
https://github.com/broadinstitute/cromwell/issues/781:894,Testability,log,log,894,"While using Jes + call caching enabled, if you call on a task with a new name, then when Jes will copy the outputs from the previously performed task but will not rename the files to the new name. For example, my WDL has a task two, and in the workflow I ""call two as four"". ; - When I check within the google bucket for call four, all the files are named as ""two-stdout.log"", ""call two-stderr.log"". ; - When I check within the google bucket for call two, there are a group of files named call two and a group of files named call four. It appears that although the appropriate files for call four are created, they aren't moved into the call four directory in google. So when I run the WF, I get this error: ; ""failure"": ""Item not found: cloud-cromwell-dev/cromwell-executions/cacheWithinWF/c972cace-b423-4c1c-87e4-01356163757f/call-four/four-stdout.log"". Because although the file four-stdout.log actually exists, it exists under the directory call-two instead of call-four.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/781
https://github.com/broadinstitute/cromwell/issues/782:13,Deployability,update,updated,13,deliverable: updated design document; deliverable: case classes,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/782
https://github.com/broadinstitute/cromwell/issues/783:26,Deployability,update,updated,26,deliverable: google doc / updated scaladocs on Metadata Service API,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/783
https://github.com/broadinstitute/cromwell/issues/786:250,Availability,robust,robust,250,"input evaluation is currently done synchronously when starting a job, this is dangerous because it can involve IO when executing engine functions. It's also executing code from the backend jar as they provide their own engine functions, we should be robust to arbitrary ""bad code"" executing from the backend.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/786
https://github.com/broadinstitute/cromwell/issues/788:0,Integrability,depend,depends,0,depends on #784,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/788
https://github.com/broadinstitute/cromwell/issues/789:0,Integrability,depend,depends,0,depends on #788 . This is really important for our users so they don't lose all their metadata!,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/789
https://github.com/broadinstitute/cromwell/pull/792:16,Integrability,depend,dependencies,16,"Fixed duplicate dependencies for core module.; Added tighter yaml validation, including looking for duplicate yaml keys.; Added swagger validation to swagger spec.; Fixed broken cromwell.yaml.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/792
https://github.com/broadinstitute/cromwell/pull/792:66,Security,validat,validation,66,"Fixed duplicate dependencies for core module.; Added tighter yaml validation, including looking for duplicate yaml keys.; Added swagger validation to swagger spec.; Fixed broken cromwell.yaml.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/792
https://github.com/broadinstitute/cromwell/pull/792:136,Security,validat,validation,136,"Fixed duplicate dependencies for core module.; Added tighter yaml validation, including looking for duplicate yaml keys.; Added swagger validation to swagger spec.; Fixed broken cromwell.yaml.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/792
https://github.com/broadinstitute/cromwell/pull/793:132,Deployability,a/b,a/broadinstitute,132,Please consider the description of data flow and interpretation in this doc to be an equal part of this PR: https://docs.google.com/a/broadinstitute.com/document/d/1xXfnMCJMoBUUaU-l81Ljqr_yt1ApLmDOGkt6AA-QTT4/edit?usp=sharing,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/793
https://github.com/broadinstitute/cromwell/issues/794:423,Availability,error,errors,423,"We have a workflow that scatters 95 wide as its first step. When running with `read_from_cache=false` the workflow chugs along normally. When we allow the same workflow to read from the cache, Cromwell seems to lock up after the first handful of cache hits(~30). Cromwell will stop responding to api requests and after some time with logs being written the workflow that was getting the cache hits will hit 503 and timeout errors. When running the workflow with `read_from_cache=false` we run into none of these errors. Timeout Error. ```; 2016-05-05 17:37:02,285 cromwell-system-akka.actor.default-dispatcher-25 WARN - Configured registration timeout of 1 second expired, stoppingw; ```. 503 Error. ```; Exception occurred while attempting to copy outputs from gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/ccba2c79-c998-4f03-b736-af097391db66/call-SplitGvcf/shard-50 to gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/7164dc88-af61-4ea6-8a73-f0b79594ae9a/call-SplitGvcf/shard-50. com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable. {. ""code"" : 503,. ""errors"" : [ {. ""domain"" : ""global"",. ""message"" : ""Backend Error"",. ""reason"" : ""backendError"". } ],. ""message"" : ""Backend Error"". }. at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19]. at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19]. at com.google.api.client.google",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/issues/794:512,Availability,error,errors,512,"We have a workflow that scatters 95 wide as its first step. When running with `read_from_cache=false` the workflow chugs along normally. When we allow the same workflow to read from the cache, Cromwell seems to lock up after the first handful of cache hits(~30). Cromwell will stop responding to api requests and after some time with logs being written the workflow that was getting the cache hits will hit 503 and timeout errors. When running the workflow with `read_from_cache=false` we run into none of these errors. Timeout Error. ```; 2016-05-05 17:37:02,285 cromwell-system-akka.actor.default-dispatcher-25 WARN - Configured registration timeout of 1 second expired, stoppingw; ```. 503 Error. ```; Exception occurred while attempting to copy outputs from gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/ccba2c79-c998-4f03-b736-af097391db66/call-SplitGvcf/shard-50 to gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/7164dc88-af61-4ea6-8a73-f0b79594ae9a/call-SplitGvcf/shard-50. com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable. {. ""code"" : 503,. ""errors"" : [ {. ""domain"" : ""global"",. ""message"" : ""Backend Error"",. ""reason"" : ""backendError"". } ],. ""message"" : ""Backend Error"". }. at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19]. at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19]. at com.google.api.client.google",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/issues/794:528,Availability,Error,Error,528,"We have a workflow that scatters 95 wide as its first step. When running with `read_from_cache=false` the workflow chugs along normally. When we allow the same workflow to read from the cache, Cromwell seems to lock up after the first handful of cache hits(~30). Cromwell will stop responding to api requests and after some time with logs being written the workflow that was getting the cache hits will hit 503 and timeout errors. When running the workflow with `read_from_cache=false` we run into none of these errors. Timeout Error. ```; 2016-05-05 17:37:02,285 cromwell-system-akka.actor.default-dispatcher-25 WARN - Configured registration timeout of 1 second expired, stoppingw; ```. 503 Error. ```; Exception occurred while attempting to copy outputs from gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/ccba2c79-c998-4f03-b736-af097391db66/call-SplitGvcf/shard-50 to gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/7164dc88-af61-4ea6-8a73-f0b79594ae9a/call-SplitGvcf/shard-50. com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable. {. ""code"" : 503,. ""errors"" : [ {. ""domain"" : ""global"",. ""message"" : ""Backend Error"",. ""reason"" : ""backendError"". } ],. ""message"" : ""Backend Error"". }. at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19]. at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19]. at com.google.api.client.google",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/issues/794:693,Availability,Error,Error,693,"We have a workflow that scatters 95 wide as its first step. When running with `read_from_cache=false` the workflow chugs along normally. When we allow the same workflow to read from the cache, Cromwell seems to lock up after the first handful of cache hits(~30). Cromwell will stop responding to api requests and after some time with logs being written the workflow that was getting the cache hits will hit 503 and timeout errors. When running the workflow with `read_from_cache=false` we run into none of these errors. Timeout Error. ```; 2016-05-05 17:37:02,285 cromwell-system-akka.actor.default-dispatcher-25 WARN - Configured registration timeout of 1 second expired, stoppingw; ```. 503 Error. ```; Exception occurred while attempting to copy outputs from gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/ccba2c79-c998-4f03-b736-af097391db66/call-SplitGvcf/shard-50 to gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/7164dc88-af61-4ea6-8a73-f0b79594ae9a/call-SplitGvcf/shard-50. com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable. {. ""code"" : 503,. ""errors"" : [ {. ""domain"" : ""global"",. ""message"" : ""Backend Error"",. ""reason"" : ""backendError"". } ],. ""message"" : ""Backend Error"". }. at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19]. at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19]. at com.google.api.client.google",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/issues/794:1125,Availability,error,errors,1125,"ally. When we allow the same workflow to read from the cache, Cromwell seems to lock up after the first handful of cache hits(~30). Cromwell will stop responding to api requests and after some time with logs being written the workflow that was getting the cache hits will hit 503 and timeout errors. When running the workflow with `read_from_cache=false` we run into none of these errors. Timeout Error. ```; 2016-05-05 17:37:02,285 cromwell-system-akka.actor.default-dispatcher-25 WARN - Configured registration timeout of 1 second expired, stoppingw; ```. 503 Error. ```; Exception occurred while attempting to copy outputs from gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/ccba2c79-c998-4f03-b736-af097391db66/call-SplitGvcf/shard-50 to gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/7164dc88-af61-4ea6-8a73-f0b79594ae9a/call-SplitGvcf/shard-50. com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable. {. ""code"" : 503,. ""errors"" : [ {. ""domain"" : ""global"",. ""message"" : ""Backend Error"",. ""reason"" : ""backendError"". } ],. ""message"" : ""Backend Error"". }. at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19]. at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19]. at com.googl",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/issues/794:1183,Availability,Error,Error,1183," from the cache, Cromwell seems to lock up after the first handful of cache hits(~30). Cromwell will stop responding to api requests and after some time with logs being written the workflow that was getting the cache hits will hit 503 and timeout errors. When running the workflow with `read_from_cache=false` we run into none of these errors. Timeout Error. ```; 2016-05-05 17:37:02,285 cromwell-system-akka.actor.default-dispatcher-25 WARN - Configured registration timeout of 1 second expired, stoppingw; ```. 503 Error. ```; Exception occurred while attempting to copy outputs from gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/ccba2c79-c998-4f03-b736-af097391db66/call-SplitGvcf/shard-50 to gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/7164dc88-af61-4ea6-8a73-f0b79594ae9a/call-SplitGvcf/shard-50. com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable. {. ""code"" : 503,. ""errors"" : [ {. ""domain"" : ""global"",. ""message"" : ""Backend Error"",. ""reason"" : ""backendError"". } ],. ""message"" : ""Backend Error"". }. at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19]. at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoog",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/issues/794:1246,Availability,Error,Error,1246,"dful of cache hits(~30). Cromwell will stop responding to api requests and after some time with logs being written the workflow that was getting the cache hits will hit 503 and timeout errors. When running the workflow with `read_from_cache=false` we run into none of these errors. Timeout Error. ```; 2016-05-05 17:37:02,285 cromwell-system-akka.actor.default-dispatcher-25 WARN - Configured registration timeout of 1 second expired, stoppingw; ```. 503 Error. ```; Exception occurred while attempting to copy outputs from gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/ccba2c79-c998-4f03-b736-af097391db66/call-SplitGvcf/shard-50 to gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/7164dc88-af61-4ea6-8a73-f0b79594ae9a/call-SplitGvcf/shard-50. com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable. {. ""code"" : 503,. ""errors"" : [ {. ""domain"" : ""global"",. ""message"" : ""Backend Error"",. ""reason"" : ""backendError"". } ],. ""message"" : ""Backend Error"". }. at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19]. at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.jav",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/issues/794:1163,Integrability,message,message,1163," from the cache, Cromwell seems to lock up after the first handful of cache hits(~30). Cromwell will stop responding to api requests and after some time with logs being written the workflow that was getting the cache hits will hit 503 and timeout errors. When running the workflow with `read_from_cache=false` we run into none of these errors. Timeout Error. ```; 2016-05-05 17:37:02,285 cromwell-system-akka.actor.default-dispatcher-25 WARN - Configured registration timeout of 1 second expired, stoppingw; ```. 503 Error. ```; Exception occurred while attempting to copy outputs from gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/ccba2c79-c998-4f03-b736-af097391db66/call-SplitGvcf/shard-50 to gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/7164dc88-af61-4ea6-8a73-f0b79594ae9a/call-SplitGvcf/shard-50. com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable. {. ""code"" : 503,. ""errors"" : [ {. ""domain"" : ""global"",. ""message"" : ""Backend Error"",. ""reason"" : ""backendError"". } ],. ""message"" : ""Backend Error"". }. at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19]. at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoog",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/issues/794:1226,Integrability,message,message,1226,"dful of cache hits(~30). Cromwell will stop responding to api requests and after some time with logs being written the workflow that was getting the cache hits will hit 503 and timeout errors. When running the workflow with `read_from_cache=false` we run into none of these errors. Timeout Error. ```; 2016-05-05 17:37:02,285 cromwell-system-akka.actor.default-dispatcher-25 WARN - Configured registration timeout of 1 second expired, stoppingw; ```. 503 Error. ```; Exception occurred while attempting to copy outputs from gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/ccba2c79-c998-4f03-b736-af097391db66/call-SplitGvcf/shard-50 to gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/7164dc88-af61-4ea6-8a73-f0b79594ae9a/call-SplitGvcf/shard-50. com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable. {. ""code"" : 503,. ""errors"" : [ {. ""domain"" : ""global"",. ""message"" : ""Backend Error"",. ""reason"" : ""backendError"". } ],. ""message"" : ""Backend Error"". }. at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19]. at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.jav",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/issues/794:620,Modifiability,Config,Configured,620,"We have a workflow that scatters 95 wide as its first step. When running with `read_from_cache=false` the workflow chugs along normally. When we allow the same workflow to read from the cache, Cromwell seems to lock up after the first handful of cache hits(~30). Cromwell will stop responding to api requests and after some time with logs being written the workflow that was getting the cache hits will hit 503 and timeout errors. When running the workflow with `read_from_cache=false` we run into none of these errors. Timeout Error. ```; 2016-05-05 17:37:02,285 cromwell-system-akka.actor.default-dispatcher-25 WARN - Configured registration timeout of 1 second expired, stoppingw; ```. 503 Error. ```; Exception occurred while attempting to copy outputs from gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/ccba2c79-c998-4f03-b736-af097391db66/call-SplitGvcf/shard-50 to gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/7164dc88-af61-4ea6-8a73-f0b79594ae9a/call-SplitGvcf/shard-50. com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable. {. ""code"" : 503,. ""errors"" : [ {. ""domain"" : ""global"",. ""message"" : ""Backend Error"",. ""reason"" : ""backendError"". } ],. ""message"" : ""Backend Error"". }. at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19]. at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19]. at com.google.api.client.google",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/issues/794:186,Performance,cache,cache,186,"We have a workflow that scatters 95 wide as its first step. When running with `read_from_cache=false` the workflow chugs along normally. When we allow the same workflow to read from the cache, Cromwell seems to lock up after the first handful of cache hits(~30). Cromwell will stop responding to api requests and after some time with logs being written the workflow that was getting the cache hits will hit 503 and timeout errors. When running the workflow with `read_from_cache=false` we run into none of these errors. Timeout Error. ```; 2016-05-05 17:37:02,285 cromwell-system-akka.actor.default-dispatcher-25 WARN - Configured registration timeout of 1 second expired, stoppingw; ```. 503 Error. ```; Exception occurred while attempting to copy outputs from gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/ccba2c79-c998-4f03-b736-af097391db66/call-SplitGvcf/shard-50 to gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/7164dc88-af61-4ea6-8a73-f0b79594ae9a/call-SplitGvcf/shard-50. com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable. {. ""code"" : 503,. ""errors"" : [ {. ""domain"" : ""global"",. ""message"" : ""Backend Error"",. ""reason"" : ""backendError"". } ],. ""message"" : ""Backend Error"". }. at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19]. at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19]. at com.google.api.client.google",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/issues/794:246,Performance,cache,cache,246,"We have a workflow that scatters 95 wide as its first step. When running with `read_from_cache=false` the workflow chugs along normally. When we allow the same workflow to read from the cache, Cromwell seems to lock up after the first handful of cache hits(~30). Cromwell will stop responding to api requests and after some time with logs being written the workflow that was getting the cache hits will hit 503 and timeout errors. When running the workflow with `read_from_cache=false` we run into none of these errors. Timeout Error. ```; 2016-05-05 17:37:02,285 cromwell-system-akka.actor.default-dispatcher-25 WARN - Configured registration timeout of 1 second expired, stoppingw; ```. 503 Error. ```; Exception occurred while attempting to copy outputs from gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/ccba2c79-c998-4f03-b736-af097391db66/call-SplitGvcf/shard-50 to gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/7164dc88-af61-4ea6-8a73-f0b79594ae9a/call-SplitGvcf/shard-50. com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable. {. ""code"" : 503,. ""errors"" : [ {. ""domain"" : ""global"",. ""message"" : ""Backend Error"",. ""reason"" : ""backendError"". } ],. ""message"" : ""Backend Error"". }. at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19]. at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19]. at com.google.api.client.google",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/issues/794:387,Performance,cache,cache,387,"We have a workflow that scatters 95 wide as its first step. When running with `read_from_cache=false` the workflow chugs along normally. When we allow the same workflow to read from the cache, Cromwell seems to lock up after the first handful of cache hits(~30). Cromwell will stop responding to api requests and after some time with logs being written the workflow that was getting the cache hits will hit 503 and timeout errors. When running the workflow with `read_from_cache=false` we run into none of these errors. Timeout Error. ```; 2016-05-05 17:37:02,285 cromwell-system-akka.actor.default-dispatcher-25 WARN - Configured registration timeout of 1 second expired, stoppingw; ```. 503 Error. ```; Exception occurred while attempting to copy outputs from gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/ccba2c79-c998-4f03-b736-af097391db66/call-SplitGvcf/shard-50 to gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/7164dc88-af61-4ea6-8a73-f0b79594ae9a/call-SplitGvcf/shard-50. com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable. {. ""code"" : 503,. ""errors"" : [ {. ""domain"" : ""global"",. ""message"" : ""Backend Error"",. ""reason"" : ""backendError"". } ],. ""message"" : ""Backend Error"". }. at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19]. at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19]. at com.google.api.client.google",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/issues/794:4519,Performance,concurren,concurrent,4519,ll.jar:0.19]. at java.nio.file.Files.copy(Files.java:1274) ~[na:1.8.0_72]. at better.files.File$$anon$1.visitFile(File.scala:327) ~[cromwell.jar:0.19]. at better.files.File$$anon$1.visitFile(File.scala:318) ~[cromwell.jar:0.19]. at java.nio.file.Files.walkFileTree(Files.java:2670) ~[na:1.8.0_72]. at java.nio.file.Files.walkFileTree(Files.java:2742) ~[na:1.8.0_72]. at better.files.File.copyTo(File.scala:318) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$copyingWork$1$1.apply(JesBackend.scala:403) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$copyingWork$1$1.apply(JesBackend.scala:403) ~[cromwell.jar:0.19]. at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$copyingWork$1(JesBackend.scala:403) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:409) [cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:407) [cromwell.jar:0.19]. at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) [cromwell.jar:0.19]. at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) [cromwell.jar:0.19]. at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) [cromwell.jar:0.19]. at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/issues/794:4629,Performance,concurren,concurrent,4629,ll.jar:0.19]. at java.nio.file.Files.copy(Files.java:1274) ~[na:1.8.0_72]. at better.files.File$$anon$1.visitFile(File.scala:327) ~[cromwell.jar:0.19]. at better.files.File$$anon$1.visitFile(File.scala:318) ~[cromwell.jar:0.19]. at java.nio.file.Files.walkFileTree(Files.java:2670) ~[na:1.8.0_72]. at java.nio.file.Files.walkFileTree(Files.java:2742) ~[na:1.8.0_72]. at better.files.File.copyTo(File.scala:318) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$copyingWork$1$1.apply(JesBackend.scala:403) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$copyingWork$1$1.apply(JesBackend.scala:403) ~[cromwell.jar:0.19]. at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$copyingWork$1(JesBackend.scala:403) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:409) [cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:407) [cromwell.jar:0.19]. at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) [cromwell.jar:0.19]. at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) [cromwell.jar:0.19]. at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) [cromwell.jar:0.19]. at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/issues/794:4934,Performance,concurren,concurrent,4934,ll.jar:0.19]. at java.nio.file.Files.copy(Files.java:1274) ~[na:1.8.0_72]. at better.files.File$$anon$1.visitFile(File.scala:327) ~[cromwell.jar:0.19]. at better.files.File$$anon$1.visitFile(File.scala:318) ~[cromwell.jar:0.19]. at java.nio.file.Files.walkFileTree(Files.java:2670) ~[na:1.8.0_72]. at java.nio.file.Files.walkFileTree(Files.java:2742) ~[na:1.8.0_72]. at better.files.File.copyTo(File.scala:318) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$copyingWork$1$1.apply(JesBackend.scala:403) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$copyingWork$1$1.apply(JesBackend.scala:403) ~[cromwell.jar:0.19]. at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$copyingWork$1(JesBackend.scala:403) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:409) [cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:407) [cromwell.jar:0.19]. at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) [cromwell.jar:0.19]. at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) [cromwell.jar:0.19]. at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) [cromwell.jar:0.19]. at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/issues/794:5027,Performance,concurren,concurrent,5027,ll.jar:0.19]. at java.nio.file.Files.copy(Files.java:1274) ~[na:1.8.0_72]. at better.files.File$$anon$1.visitFile(File.scala:327) ~[cromwell.jar:0.19]. at better.files.File$$anon$1.visitFile(File.scala:318) ~[cromwell.jar:0.19]. at java.nio.file.Files.walkFileTree(Files.java:2670) ~[na:1.8.0_72]. at java.nio.file.Files.walkFileTree(Files.java:2742) ~[na:1.8.0_72]. at better.files.File.copyTo(File.scala:318) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$copyingWork$1$1.apply(JesBackend.scala:403) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$copyingWork$1$1.apply(JesBackend.scala:403) ~[cromwell.jar:0.19]. at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$copyingWork$1(JesBackend.scala:403) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:409) [cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:407) [cromwell.jar:0.19]. at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) [cromwell.jar:0.19]. at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) [cromwell.jar:0.19]. at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) [cromwell.jar:0.19]. at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/issues/794:5132,Performance,concurren,concurrent,5132,ll.jar:0.19]. at java.nio.file.Files.copy(Files.java:1274) ~[na:1.8.0_72]. at better.files.File$$anon$1.visitFile(File.scala:327) ~[cromwell.jar:0.19]. at better.files.File$$anon$1.visitFile(File.scala:318) ~[cromwell.jar:0.19]. at java.nio.file.Files.walkFileTree(Files.java:2670) ~[na:1.8.0_72]. at java.nio.file.Files.walkFileTree(Files.java:2742) ~[na:1.8.0_72]. at better.files.File.copyTo(File.scala:318) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$copyingWork$1$1.apply(JesBackend.scala:403) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$copyingWork$1$1.apply(JesBackend.scala:403) ~[cromwell.jar:0.19]. at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$copyingWork$1(JesBackend.scala:403) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:409) [cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:407) [cromwell.jar:0.19]. at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) [cromwell.jar:0.19]. at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) [cromwell.jar:0.19]. at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) [cromwell.jar:0.19]. at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/issues/794:5229,Performance,concurren,concurrent,5229,ll.jar:0.19]. at java.nio.file.Files.copy(Files.java:1274) ~[na:1.8.0_72]. at better.files.File$$anon$1.visitFile(File.scala:327) ~[cromwell.jar:0.19]. at better.files.File$$anon$1.visitFile(File.scala:318) ~[cromwell.jar:0.19]. at java.nio.file.Files.walkFileTree(Files.java:2670) ~[na:1.8.0_72]. at java.nio.file.Files.walkFileTree(Files.java:2742) ~[na:1.8.0_72]. at better.files.File.copyTo(File.scala:318) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$copyingWork$1$1.apply(JesBackend.scala:403) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$cromwell$engine$backend$jes$JesBackend$$copyingWork$1$1.apply(JesBackend.scala:403) ~[cromwell.jar:0.19]. at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend.cromwell$engine$backend$jes$JesBackend$$copyingWork$1(JesBackend.scala:403) ~[cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:409) [cromwell.jar:0.19]. at cromwell.engine.backend.jes.JesBackend$$anonfun$useCachedCall$1.apply(JesBackend.scala:407) [cromwell.jar:0.19]. at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) [cromwell.jar:0.19]. at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) [cromwell.jar:0.19]. at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) [cromwell.jar:0.19]. at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]. at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/issues/794:415,Safety,timeout,timeout,415,"We have a workflow that scatters 95 wide as its first step. When running with `read_from_cache=false` the workflow chugs along normally. When we allow the same workflow to read from the cache, Cromwell seems to lock up after the first handful of cache hits(~30). Cromwell will stop responding to api requests and after some time with logs being written the workflow that was getting the cache hits will hit 503 and timeout errors. When running the workflow with `read_from_cache=false` we run into none of these errors. Timeout Error. ```; 2016-05-05 17:37:02,285 cromwell-system-akka.actor.default-dispatcher-25 WARN - Configured registration timeout of 1 second expired, stoppingw; ```. 503 Error. ```; Exception occurred while attempting to copy outputs from gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/ccba2c79-c998-4f03-b736-af097391db66/call-SplitGvcf/shard-50 to gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/7164dc88-af61-4ea6-8a73-f0b79594ae9a/call-SplitGvcf/shard-50. com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable. {. ""code"" : 503,. ""errors"" : [ {. ""domain"" : ""global"",. ""message"" : ""Backend Error"",. ""reason"" : ""backendError"". } ],. ""message"" : ""Backend Error"". }. at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19]. at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19]. at com.google.api.client.google",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/issues/794:520,Safety,Timeout,Timeout,520,"We have a workflow that scatters 95 wide as its first step. When running with `read_from_cache=false` the workflow chugs along normally. When we allow the same workflow to read from the cache, Cromwell seems to lock up after the first handful of cache hits(~30). Cromwell will stop responding to api requests and after some time with logs being written the workflow that was getting the cache hits will hit 503 and timeout errors. When running the workflow with `read_from_cache=false` we run into none of these errors. Timeout Error. ```; 2016-05-05 17:37:02,285 cromwell-system-akka.actor.default-dispatcher-25 WARN - Configured registration timeout of 1 second expired, stoppingw; ```. 503 Error. ```; Exception occurred while attempting to copy outputs from gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/ccba2c79-c998-4f03-b736-af097391db66/call-SplitGvcf/shard-50 to gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/7164dc88-af61-4ea6-8a73-f0b79594ae9a/call-SplitGvcf/shard-50. com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable. {. ""code"" : 503,. ""errors"" : [ {. ""domain"" : ""global"",. ""message"" : ""Backend Error"",. ""reason"" : ""backendError"". } ],. ""message"" : ""Backend Error"". }. at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19]. at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19]. at com.google.api.client.google",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/issues/794:644,Safety,timeout,timeout,644,"We have a workflow that scatters 95 wide as its first step. When running with `read_from_cache=false` the workflow chugs along normally. When we allow the same workflow to read from the cache, Cromwell seems to lock up after the first handful of cache hits(~30). Cromwell will stop responding to api requests and after some time with logs being written the workflow that was getting the cache hits will hit 503 and timeout errors. When running the workflow with `read_from_cache=false` we run into none of these errors. Timeout Error. ```; 2016-05-05 17:37:02,285 cromwell-system-akka.actor.default-dispatcher-25 WARN - Configured registration timeout of 1 second expired, stoppingw; ```. 503 Error. ```; Exception occurred while attempting to copy outputs from gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/ccba2c79-c998-4f03-b736-af097391db66/call-SplitGvcf/shard-50 to gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/7164dc88-af61-4ea6-8a73-f0b79594ae9a/call-SplitGvcf/shard-50. com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable. {. ""code"" : 503,. ""errors"" : [ {. ""domain"" : ""global"",. ""message"" : ""Backend Error"",. ""reason"" : ""backendError"". } ],. ""message"" : ""Backend Error"". }. at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19]. at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19]. at com.google.api.client.google",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/issues/794:334,Testability,log,logs,334,"We have a workflow that scatters 95 wide as its first step. When running with `read_from_cache=false` the workflow chugs along normally. When we allow the same workflow to read from the cache, Cromwell seems to lock up after the first handful of cache hits(~30). Cromwell will stop responding to api requests and after some time with logs being written the workflow that was getting the cache hits will hit 503 and timeout errors. When running the workflow with `read_from_cache=false` we run into none of these errors. Timeout Error. ```; 2016-05-05 17:37:02,285 cromwell-system-akka.actor.default-dispatcher-25 WARN - Configured registration timeout of 1 second expired, stoppingw; ```. 503 Error. ```; Exception occurred while attempting to copy outputs from gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/ccba2c79-c998-4f03-b736-af097391db66/call-SplitGvcf/shard-50 to gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/7164dc88-af61-4ea6-8a73-f0b79594ae9a/call-SplitGvcf/shard-50. com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable. {. ""code"" : 503,. ""errors"" : [ {. ""domain"" : ""global"",. ""message"" : ""Backend Error"",. ""reason"" : ""backendError"". } ],. ""message"" : ""Backend Error"". }. at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19]. at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19]. at com.google.api.client.google",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794
https://github.com/broadinstitute/cromwell/pull/795:70,Availability,failure,failure,70,Adds an event handler for a backend job that failed with a retry able failure. The engine attempts to restart the failed job again on the same backend for a `max` number of times (where that number is configurable and controlled by the engine),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/795
https://github.com/broadinstitute/cromwell/pull/795:201,Modifiability,config,configurable,201,Adds an event handler for a backend job that failed with a retry able failure. The engine attempts to restart the failed job again on the same backend for a `max` number of times (where that number is configurable and controlled by the engine),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/795
https://github.com/broadinstitute/cromwell/issues/796:77,Deployability,configurat,configuration,77,"One possible solution: We should probably create a trait which loads all the configuration (once per application), and let classes mix it in to avoid doing ConfigFactory.load() at multiple places",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/796
https://github.com/broadinstitute/cromwell/issues/796:77,Modifiability,config,configuration,77,"One possible solution: We should probably create a trait which loads all the configuration (once per application), and let classes mix it in to avoid doing ConfigFactory.load() at multiple places",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/796
https://github.com/broadinstitute/cromwell/issues/796:156,Modifiability,Config,ConfigFactory,156,"One possible solution: We should probably create a trait which loads all the configuration (once per application), and let classes mix it in to avoid doing ConfigFactory.load() at multiple places",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/796
https://github.com/broadinstitute/cromwell/issues/796:63,Performance,load,loads,63,"One possible solution: We should probably create a trait which loads all the configuration (once per application), and let classes mix it in to avoid doing ConfigFactory.load() at multiple places",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/796
https://github.com/broadinstitute/cromwell/issues/796:170,Performance,load,load,170,"One possible solution: We should probably create a trait which loads all the configuration (once per application), and let classes mix it in to avoid doing ConfigFactory.load() at multiple places",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/796
https://github.com/broadinstitute/cromwell/issues/796:144,Safety,avoid,avoid,144,"One possible solution: We should probably create a trait which loads all the configuration (once per application), and let classes mix it in to avoid doing ConfigFactory.load() at multiple places",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/796
https://github.com/broadinstitute/cromwell/pull/797:242,Availability,Recover,Recover,242,"Some light reading for @Horneth and @kshakir. This is largely Frankensteining of ""Olde Style"" code. Known missing or broken, I need to confirm that appropriate tickets exist for the restoration of the following:; - [x] #753 Abort; - [x] #751 Recover; - [x] #749 Preemptibility; - [x] #785 Persistence of any data (note this would not be a ticket to create a KV / metadata service, but to integrate this backend with such a service); - [x] #809 Hashing (prereq for #750); - [x] #750 Caching; - [x] #806 implement Firecloud style auth upload / deletion (the code is not present here); - [x] #808 Retries were removed from command script upload and JES run creation. Lessons learned:; - [x] #811 #812 Actor Factories should be responsible for sanity-checking configs .; - [x] #813 Initialization actors should have the ability to create workflow-level resources that can be shared by the other actors collaborating in the workflow execution. e.g. GCS Filesystems need only be created once per workflow, not for every call.; - [x] It's not clear how workflow logging (or logging in general) should work.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/797
https://github.com/broadinstitute/cromwell/pull/797:388,Deployability,integrat,integrate,388,"Some light reading for @Horneth and @kshakir. This is largely Frankensteining of ""Olde Style"" code. Known missing or broken, I need to confirm that appropriate tickets exist for the restoration of the following:; - [x] #753 Abort; - [x] #751 Recover; - [x] #749 Preemptibility; - [x] #785 Persistence of any data (note this would not be a ticket to create a KV / metadata service, but to integrate this backend with such a service); - [x] #809 Hashing (prereq for #750); - [x] #750 Caching; - [x] #806 implement Firecloud style auth upload / deletion (the code is not present here); - [x] #808 Retries were removed from command script upload and JES run creation. Lessons learned:; - [x] #811 #812 Actor Factories should be responsible for sanity-checking configs .; - [x] #813 Initialization actors should have the ability to create workflow-level resources that can be shared by the other actors collaborating in the workflow execution. e.g. GCS Filesystems need only be created once per workflow, not for every call.; - [x] It's not clear how workflow logging (or logging in general) should work.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/797
https://github.com/broadinstitute/cromwell/pull/797:388,Integrability,integrat,integrate,388,"Some light reading for @Horneth and @kshakir. This is largely Frankensteining of ""Olde Style"" code. Known missing or broken, I need to confirm that appropriate tickets exist for the restoration of the following:; - [x] #753 Abort; - [x] #751 Recover; - [x] #749 Preemptibility; - [x] #785 Persistence of any data (note this would not be a ticket to create a KV / metadata service, but to integrate this backend with such a service); - [x] #809 Hashing (prereq for #750); - [x] #750 Caching; - [x] #806 implement Firecloud style auth upload / deletion (the code is not present here); - [x] #808 Retries were removed from command script upload and JES run creation. Lessons learned:; - [x] #811 #812 Actor Factories should be responsible for sanity-checking configs .; - [x] #813 Initialization actors should have the ability to create workflow-level resources that can be shared by the other actors collaborating in the workflow execution. e.g. GCS Filesystems need only be created once per workflow, not for every call.; - [x] It's not clear how workflow logging (or logging in general) should work.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/797
https://github.com/broadinstitute/cromwell/pull/797:756,Modifiability,config,configs,756,"Some light reading for @Horneth and @kshakir. This is largely Frankensteining of ""Olde Style"" code. Known missing or broken, I need to confirm that appropriate tickets exist for the restoration of the following:; - [x] #753 Abort; - [x] #751 Recover; - [x] #749 Preemptibility; - [x] #785 Persistence of any data (note this would not be a ticket to create a KV / metadata service, but to integrate this backend with such a service); - [x] #809 Hashing (prereq for #750); - [x] #750 Caching; - [x] #806 implement Firecloud style auth upload / deletion (the code is not present here); - [x] #808 Retries were removed from command script upload and JES run creation. Lessons learned:; - [x] #811 #812 Actor Factories should be responsible for sanity-checking configs .; - [x] #813 Initialization actors should have the ability to create workflow-level resources that can be shared by the other actors collaborating in the workflow execution. e.g. GCS Filesystems need only be created once per workflow, not for every call.; - [x] It's not clear how workflow logging (or logging in general) should work.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/797
https://github.com/broadinstitute/cromwell/pull/797:224,Safety,Abort,Abort,224,"Some light reading for @Horneth and @kshakir. This is largely Frankensteining of ""Olde Style"" code. Known missing or broken, I need to confirm that appropriate tickets exist for the restoration of the following:; - [x] #753 Abort; - [x] #751 Recover; - [x] #749 Preemptibility; - [x] #785 Persistence of any data (note this would not be a ticket to create a KV / metadata service, but to integrate this backend with such a service); - [x] #809 Hashing (prereq for #750); - [x] #750 Caching; - [x] #806 implement Firecloud style auth upload / deletion (the code is not present here); - [x] #808 Retries were removed from command script upload and JES run creation. Lessons learned:; - [x] #811 #812 Actor Factories should be responsible for sanity-checking configs .; - [x] #813 Initialization actors should have the ability to create workflow-level resources that can be shared by the other actors collaborating in the workflow execution. e.g. GCS Filesystems need only be created once per workflow, not for every call.; - [x] It's not clear how workflow logging (or logging in general) should work.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/797
https://github.com/broadinstitute/cromwell/pull/797:242,Safety,Recover,Recover,242,"Some light reading for @Horneth and @kshakir. This is largely Frankensteining of ""Olde Style"" code. Known missing or broken, I need to confirm that appropriate tickets exist for the restoration of the following:; - [x] #753 Abort; - [x] #751 Recover; - [x] #749 Preemptibility; - [x] #785 Persistence of any data (note this would not be a ticket to create a KV / metadata service, but to integrate this backend with such a service); - [x] #809 Hashing (prereq for #750); - [x] #750 Caching; - [x] #806 implement Firecloud style auth upload / deletion (the code is not present here); - [x] #808 Retries were removed from command script upload and JES run creation. Lessons learned:; - [x] #811 #812 Actor Factories should be responsible for sanity-checking configs .; - [x] #813 Initialization actors should have the ability to create workflow-level resources that can be shared by the other actors collaborating in the workflow execution. e.g. GCS Filesystems need only be created once per workflow, not for every call.; - [x] It's not clear how workflow logging (or logging in general) should work.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/797
https://github.com/broadinstitute/cromwell/pull/797:444,Security,Hash,Hashing,444,"Some light reading for @Horneth and @kshakir. This is largely Frankensteining of ""Olde Style"" code. Known missing or broken, I need to confirm that appropriate tickets exist for the restoration of the following:; - [x] #753 Abort; - [x] #751 Recover; - [x] #749 Preemptibility; - [x] #785 Persistence of any data (note this would not be a ticket to create a KV / metadata service, but to integrate this backend with such a service); - [x] #809 Hashing (prereq for #750); - [x] #750 Caching; - [x] #806 implement Firecloud style auth upload / deletion (the code is not present here); - [x] #808 Retries were removed from command script upload and JES run creation. Lessons learned:; - [x] #811 #812 Actor Factories should be responsible for sanity-checking configs .; - [x] #813 Initialization actors should have the ability to create workflow-level resources that can be shared by the other actors collaborating in the workflow execution. e.g. GCS Filesystems need only be created once per workflow, not for every call.; - [x] It's not clear how workflow logging (or logging in general) should work.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/797
https://github.com/broadinstitute/cromwell/pull/797:1055,Testability,log,logging,1055,"Some light reading for @Horneth and @kshakir. This is largely Frankensteining of ""Olde Style"" code. Known missing or broken, I need to confirm that appropriate tickets exist for the restoration of the following:; - [x] #753 Abort; - [x] #751 Recover; - [x] #749 Preemptibility; - [x] #785 Persistence of any data (note this would not be a ticket to create a KV / metadata service, but to integrate this backend with such a service); - [x] #809 Hashing (prereq for #750); - [x] #750 Caching; - [x] #806 implement Firecloud style auth upload / deletion (the code is not present here); - [x] #808 Retries were removed from command script upload and JES run creation. Lessons learned:; - [x] #811 #812 Actor Factories should be responsible for sanity-checking configs .; - [x] #813 Initialization actors should have the ability to create workflow-level resources that can be shared by the other actors collaborating in the workflow execution. e.g. GCS Filesystems need only be created once per workflow, not for every call.; - [x] It's not clear how workflow logging (or logging in general) should work.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/797
https://github.com/broadinstitute/cromwell/pull/797:1067,Testability,log,logging,1067,"Some light reading for @Horneth and @kshakir. This is largely Frankensteining of ""Olde Style"" code. Known missing or broken, I need to confirm that appropriate tickets exist for the restoration of the following:; - [x] #753 Abort; - [x] #751 Recover; - [x] #749 Preemptibility; - [x] #785 Persistence of any data (note this would not be a ticket to create a KV / metadata service, but to integrate this backend with such a service); - [x] #809 Hashing (prereq for #750); - [x] #750 Caching; - [x] #806 implement Firecloud style auth upload / deletion (the code is not present here); - [x] #808 Retries were removed from command script upload and JES run creation. Lessons learned:; - [x] #811 #812 Actor Factories should be responsible for sanity-checking configs .; - [x] #813 Initialization actors should have the ability to create workflow-level resources that can be shared by the other actors collaborating in the workflow execution. e.g. GCS Filesystems need only be created once per workflow, not for every call.; - [x] It's not clear how workflow logging (or logging in general) should work.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/797
https://github.com/broadinstitute/cromwell/pull/797:672,Usability,learn,learned,672,"Some light reading for @Horneth and @kshakir. This is largely Frankensteining of ""Olde Style"" code. Known missing or broken, I need to confirm that appropriate tickets exist for the restoration of the following:; - [x] #753 Abort; - [x] #751 Recover; - [x] #749 Preemptibility; - [x] #785 Persistence of any data (note this would not be a ticket to create a KV / metadata service, but to integrate this backend with such a service); - [x] #809 Hashing (prereq for #750); - [x] #750 Caching; - [x] #806 implement Firecloud style auth upload / deletion (the code is not present here); - [x] #808 Retries were removed from command script upload and JES run creation. Lessons learned:; - [x] #811 #812 Actor Factories should be responsible for sanity-checking configs .; - [x] #813 Initialization actors should have the ability to create workflow-level resources that can be shared by the other actors collaborating in the workflow execution. e.g. GCS Filesystems need only be created once per workflow, not for every call.; - [x] It's not clear how workflow logging (or logging in general) should work.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/797
https://github.com/broadinstitute/cromwell/pull/797:1036,Usability,clear,clear,1036,"Some light reading for @Horneth and @kshakir. This is largely Frankensteining of ""Olde Style"" code. Known missing or broken, I need to confirm that appropriate tickets exist for the restoration of the following:; - [x] #753 Abort; - [x] #751 Recover; - [x] #749 Preemptibility; - [x] #785 Persistence of any data (note this would not be a ticket to create a KV / metadata service, but to integrate this backend with such a service); - [x] #809 Hashing (prereq for #750); - [x] #750 Caching; - [x] #806 implement Firecloud style auth upload / deletion (the code is not present here); - [x] #808 Retries were removed from command script upload and JES run creation. Lessons learned:; - [x] #811 #812 Actor Factories should be responsible for sanity-checking configs .; - [x] #813 Initialization actors should have the ability to create workflow-level resources that can be shared by the other actors collaborating in the workflow execution. e.g. GCS Filesystems need only be created once per workflow, not for every call.; - [x] It's not clear how workflow logging (or logging in general) should work.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/797
https://github.com/broadinstitute/cromwell/issues/800:119,Deployability,update,updates,119,"We've been seeing some instances where the JES Run fails or succeeds, but cromwell either stays stuck in ""Starting"" or updates to an incorrect status (i.e. ""Failed"" when the JES Run evidently succeeded). Run into 3 or 4 different iterations of it so far.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/800
https://github.com/broadinstitute/cromwell/issues/801:172,Availability,error,error,172,"For Workflow ID: 5541d851-10bb-455d-a6bc-051e85574b74. We're getting nothing back when we try to look at timing or metadata, the metadata curl call returns:. {; ""status"": ""error"",; ""message"": ""None.get""; }. No clue what's going on here, the cromwell logs don't indicate anything unusual for this workflow. Seemingly it ran normally, just some typical preemption messages.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/801
https://github.com/broadinstitute/cromwell/issues/801:182,Integrability,message,message,182,"For Workflow ID: 5541d851-10bb-455d-a6bc-051e85574b74. We're getting nothing back when we try to look at timing or metadata, the metadata curl call returns:. {; ""status"": ""error"",; ""message"": ""None.get""; }. No clue what's going on here, the cromwell logs don't indicate anything unusual for this workflow. Seemingly it ran normally, just some typical preemption messages.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/801
https://github.com/broadinstitute/cromwell/issues/801:362,Integrability,message,messages,362,"For Workflow ID: 5541d851-10bb-455d-a6bc-051e85574b74. We're getting nothing back when we try to look at timing or metadata, the metadata curl call returns:. {; ""status"": ""error"",; ""message"": ""None.get""; }. No clue what's going on here, the cromwell logs don't indicate anything unusual for this workflow. Seemingly it ran normally, just some typical preemption messages.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/801
https://github.com/broadinstitute/cromwell/issues/801:250,Testability,log,logs,250,"For Workflow ID: 5541d851-10bb-455d-a6bc-051e85574b74. We're getting nothing back when we try to look at timing or metadata, the metadata curl call returns:. {; ""status"": ""error"",; ""message"": ""None.get""; }. No clue what's going on here, the cromwell logs don't indicate anything unusual for this workflow. Seemingly it ran normally, just some typical preemption messages.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/801
https://github.com/broadinstitute/cromwell/issues/806:4,Testability,Test,Test,4,AC: Test that the FireCloud style auth upload works,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/806
https://github.com/broadinstitute/cromwell/issues/810:173,Availability,error,errors,173,"We had two workflows fail with the following message:. ```; ""com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable; { ; ""code"" : 503,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Backend Error"",; ""reason"" : ""backendError""; } ],; ""message"" : ""Backend Error""; }""; ```. JES indicated that the rate of unavailability is below what they consider a problem, and suggested retries. I showed the stacktrace below to Miguel, who says there is a retry around this call, but that it is fairly short. ```; {;   ""code"" : 503,;   ""errors"" : [ {;     ""domain"" : ""global"",;     ""message"" : ""Backend Error"",;     ""reason"" : ""backendError"";   } ],;   ""message"" : ""Backend Error""; };   at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19];   at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:231,Availability,Error,Error,231,"We had two workflows fail with the following message:. ```; ""com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable; { ; ""code"" : 503,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Backend Error"",; ""reason"" : ""backendError""; } ],; ""message"" : ""Backend Error""; }""; ```. JES indicated that the rate of unavailability is below what they consider a problem, and suggested retries. I showed the stacktrace below to Miguel, who says there is a retry around this call, but that it is fairly short. ```; {;   ""code"" : 503,;   ""errors"" : [ {;     ""domain"" : ""global"",;     ""message"" : ""Backend Error"",;     ""reason"" : ""backendError"";   } ],;   ""message"" : ""Backend Error""; };   at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19];   at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:294,Availability,Error,Error,294,"We had two workflows fail with the following message:. ```; ""com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable; { ; ""code"" : 503,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Backend Error"",; ""reason"" : ""backendError""; } ],; ""message"" : ""Backend Error""; }""; ```. JES indicated that the rate of unavailability is below what they consider a problem, and suggested retries. I showed the stacktrace below to Miguel, who says there is a retry around this call, but that it is fairly short. ```; {;   ""code"" : 503,;   ""errors"" : [ {;     ""domain"" : ""global"",;     ""message"" : ""Backend Error"",;     ""reason"" : ""backendError"";   } ],;   ""message"" : ""Backend Error""; };   at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19];   at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:561,Availability,error,errors,561,"We had two workflows fail with the following message:. ```; ""com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable; { ; ""code"" : 503,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Backend Error"",; ""reason"" : ""backendError""; } ],; ""message"" : ""Backend Error""; }""; ```. JES indicated that the rate of unavailability is below what they consider a problem, and suggested retries. I showed the stacktrace below to Miguel, who says there is a retry around this call, but that it is fairly short. ```; {;   ""code"" : 503,;   ""errors"" : [ {;     ""domain"" : ""global"",;     ""message"" : ""Backend Error"",;     ""reason"" : ""backendError"";   } ],;   ""message"" : ""Backend Error""; };   at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19];   at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:627,Availability,Error,Error,627,"We had two workflows fail with the following message:. ```; ""com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable; { ; ""code"" : 503,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Backend Error"",; ""reason"" : ""backendError""; } ],; ""message"" : ""Backend Error""; }""; ```. JES indicated that the rate of unavailability is below what they consider a problem, and suggested retries. I showed the stacktrace below to Miguel, who says there is a retry around this call, but that it is fairly short. ```; {;   ""code"" : 503,;   ""errors"" : [ {;     ""domain"" : ""global"",;     ""message"" : ""Backend Error"",;     ""reason"" : ""backendError"";   } ],;   ""message"" : ""Backend Error""; };   at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19];   at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:698,Availability,Error,Error,698,"We had two workflows fail with the following message:. ```; ""com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable; { ; ""code"" : 503,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Backend Error"",; ""reason"" : ""backendError""; } ],; ""message"" : ""Backend Error""; }""; ```. JES indicated that the rate of unavailability is below what they consider a problem, and suggested retries. I showed the stacktrace below to Miguel, who says there is a retry around this call, but that it is fairly short. ```; {;   ""code"" : 503,;   ""errors"" : [ {;     ""domain"" : ""global"",;     ""message"" : ""Backend Error"",;     ""reason"" : ""backendError"";   } ],;   ""message"" : ""Backend Error""; };   at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19];   at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:6233,Energy Efficiency,Adapt,AdaptedForkJoinTask,6233,.map(Traversable.scala:104) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:569) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:568) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:45,Integrability,message,message,45,"We had two workflows fail with the following message:. ```; ""com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable; { ; ""code"" : 503,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Backend Error"",; ""reason"" : ""backendError""; } ],; ""message"" : ""Backend Error""; }""; ```. JES indicated that the rate of unavailability is below what they consider a problem, and suggested retries. I showed the stacktrace below to Miguel, who says there is a retry around this call, but that it is fairly short. ```; {;   ""code"" : 503,;   ""errors"" : [ {;     ""domain"" : ""global"",;     ""message"" : ""Backend Error"",;     ""reason"" : ""backendError"";   } ],;   ""message"" : ""Backend Error""; };   at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19];   at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:211,Integrability,message,message,211,"We had two workflows fail with the following message:. ```; ""com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable; { ; ""code"" : 503,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Backend Error"",; ""reason"" : ""backendError""; } ],; ""message"" : ""Backend Error""; }""; ```. JES indicated that the rate of unavailability is below what they consider a problem, and suggested retries. I showed the stacktrace below to Miguel, who says there is a retry around this call, but that it is fairly short. ```; {;   ""code"" : 503,;   ""errors"" : [ {;     ""domain"" : ""global"",;     ""message"" : ""Backend Error"",;     ""reason"" : ""backendError"";   } ],;   ""message"" : ""Backend Error""; };   at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19];   at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:274,Integrability,message,message,274,"We had two workflows fail with the following message:. ```; ""com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable; { ; ""code"" : 503,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Backend Error"",; ""reason"" : ""backendError""; } ],; ""message"" : ""Backend Error""; }""; ```. JES indicated that the rate of unavailability is below what they consider a problem, and suggested retries. I showed the stacktrace below to Miguel, who says there is a retry around this call, but that it is fairly short. ```; {;   ""code"" : 503,;   ""errors"" : [ {;     ""domain"" : ""global"",;     ""message"" : ""Backend Error"",;     ""reason"" : ""backendError"";   } ],;   ""message"" : ""Backend Error""; };   at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19];   at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:607,Integrability,message,message,607,"We had two workflows fail with the following message:. ```; ""com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable; { ; ""code"" : 503,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Backend Error"",; ""reason"" : ""backendError""; } ],; ""message"" : ""Backend Error""; }""; ```. JES indicated that the rate of unavailability is below what they consider a problem, and suggested retries. I showed the stacktrace below to Miguel, who says there is a retry around this call, but that it is fairly short. ```; {;   ""code"" : 503,;   ""errors"" : [ {;     ""domain"" : ""global"",;     ""message"" : ""Backend Error"",;     ""reason"" : ""backendError"";   } ],;   ""message"" : ""Backend Error""; };   at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19];   at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:678,Integrability,message,message,678,"We had two workflows fail with the following message:. ```; ""com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable; { ; ""code"" : 503,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Backend Error"",; ""reason"" : ""backendError""; } ],; ""message"" : ""Backend Error""; }""; ```. JES indicated that the rate of unavailability is below what they consider a problem, and suggested retries. I showed the stacktrace below to Miguel, who says there is a retry around this call, but that it is fairly short. ```; {;   ""code"" : 503,;   ""errors"" : [ {;     ""domain"" : ""global"",;     ""message"" : ""Backend Error"",;     ""reason"" : ""backendError"";   } ],;   ""message"" : ""Backend Error""; };   at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19];   at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:6233,Modifiability,Adapt,AdaptedForkJoinTask,6233,.map(Traversable.scala:104) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:569) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:568) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:5271,Performance,concurren,concurrent,5271,cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:569) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:568) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImp,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:5365,Performance,concurren,concurrent,5365,omwell.jar:0.19];   at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:569) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:568) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoin,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:5459,Performance,concurren,concurrent,5459,la:777) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:569) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:568) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runT,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:5559,Performance,concurren,concurrent,5559,~[cromwell.jar:0.19];   at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:569) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:568) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWork,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:6108,Performance,concurren,concurrent,6108,.map(Traversable.scala:104) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:569) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:568) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:6196,Performance,concurren,concurrent,6196,.map(Traversable.scala:104) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:569) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:568) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:6323,Performance,concurren,concurrent,6323,.map(Traversable.scala:104) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:569) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:568) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:6418,Performance,concurren,concurrent,6418,.map(Traversable.scala:104) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:569) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:568) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:6525,Performance,concurren,concurrent,6525,.map(Traversable.scala:104) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:569) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:568) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:6624,Performance,concurren,concurrent,6624,.map(Traversable.scala:104) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:569) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:568) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:2568,Security,hash,hash,2568,9];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala:191) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala:191) ~[cromwell.jar:0.19];   at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$.withRetry(GcsFileSystemProvider.scala:44) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider.crc32cHash(GcsFileSystemProvider.scala:191) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.package$PathEnhanced$.hash$extension(package.scala:32) ~[cromwell.jar:0.19];   at cromwell.engine.backend.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:65) ~[cromwell.jar:0.19];   at cromwell.engine.backend.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:63) ~[cromwell.jar:0.19];   at wdl4s.values.WdlValue$class.computeHash(WdlValue.scala:63) ~[cromwell.jar:0.19];   at wdl4s.values.WdlSingleFile.computeHash(WdlFile.scala:39) ~[cromwell.jar:0.19];   at cromwell.engine.backend.WorkflowDescriptor.hash(WorkflowDescriptor.scala:229) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$postProcess$1$$anonfun$apply$14.apply(JesBackend.scala:627) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$postProcess$1$$anonfun$apply$14.apply(JesBackend.scala:626) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues$$anonf,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/issues/810:3095,Security,hash,hash,3095,crc32cHash$1.apply(GcsFileSystemProvider.scala:191) ~[cromwell.jar:0.19];   at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$.withRetry(GcsFileSystemProvider.scala:44) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider.crc32cHash(GcsFileSystemProvider.scala:191) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.package$PathEnhanced$.hash$extension(package.scala:32) ~[cromwell.jar:0.19];   at cromwell.engine.backend.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:65) ~[cromwell.jar:0.19];   at cromwell.engine.backend.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:63) ~[cromwell.jar:0.19];   at wdl4s.values.WdlValue$class.computeHash(WdlValue.scala:63) ~[cromwell.jar:0.19];   at wdl4s.values.WdlSingleFile.computeHash(WdlFile.scala:39) ~[cromwell.jar:0.19];   at cromwell.engine.backend.WorkflowDescriptor.hash(WorkflowDescriptor.scala:229) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$postProcess$1$$anonfun$apply$14.apply(JesBackend.scala:627) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$postProcess$1$$anonfun$apply$14.apply(JesBackend.scala:626) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778) ~[cromwell.jar:0.19];   a,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810
https://github.com/broadinstitute/cromwell/pull/817:73,Testability,test,tests,73,helpful when not everything is passing. Specifically -- all the disabled tests we have now are easier to identify so we can find the right time to re-enable them!,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/817
https://github.com/broadinstitute/cromwell/pull/818:95,Testability,test,test,95,Implement scatter execution and re-organize Execution related code; - [x] Write engine scatter test; - [ ] Write more ?,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/818
https://github.com/broadinstitute/cromwell/issues/819:21,Modifiability,refactor,refactored,21,"Support for this was refactored out of the Pluggable Backend Experience, in particular from LocalRuntimeAttributes and JesRuntimeAttributes.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/819
https://github.com/broadinstitute/cromwell/issues/820:1779,Performance,cache,cache,1779,"When running the following example wdl task: . ```; task SplitGvcfTouch {; File interval_list; String sample_name. command <<<; # cut -f1-3 returns <chromosome> <start> <stop>; cat ${interval_list} | grep -v ""@"" | cut -f1-3 > regions.txt; mkdir split_gvcfs; piece=0; while read -r chrom start stop; do; OUT_GVCF=""printf ${sample_name}.%04d.g.vcf.gz $piece""; OUT_GVCF_INDEX=""printf ${sample_name}.%04d.g.vcf.gz.tbi $piece""; touch split_gvcfs/$($OUT_GVCF); touch split_gvcfs/$($OUT_GVCF_INDEX); piece=$(($piece+1)); done < regions.txt. >>>; runtime {; docker: ""broadinstitute/genomes-in-the-cloud:1.1044_with_gatk4""; memory: ""3 GB""; cpu: ""1""; disks: ""local-disk 50 HDD""; #preemptible: 3; }; output {; Array[File] gvcf_list = glob(""split_gvcfs/*.gz""); Array[File] gvcf_index_list = glob(""split_gvcfs/*.tbi""); }; }; ```. where `SplitGvcfTouch` is called like:. ```; scatter (idx in indexing_list) {; call SplitGvcfTouch {; input:; sample_name = sub(sub(gvcf_list[idx], ""gs://.*/"",""""), "".g.vcf.gz$"", """"),; interval_list = split_interval_list; }; }; ```. `indexing_list` is an array of integers 0-94, `sample_name` can be any string, and `interval_list` is attached; [wgs_split_10000000_tiledb.intervalist.txt](https://github.com/broadinstitute/cromwell/files/259842/wgs_split_10000000_tiledb.intervalist.txt). with these inputs, each scattered task should be globbing an array of 901 elements for both `gvcf_list` and `gvcf_index_list`. When this is run on JES backend, according to the timing diagram it is taking 25-30 min of ""cromwell final overhead"" which is much longer than ever previously seen. Once all of the scatter tasks are completed, the implicit gatherer starts but never finishes(at least I haven't seen it finish yet). This task also causes issues when trying to call cache previous results.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/820
https://github.com/broadinstitute/cromwell/issues/821:28,Availability,avail,available,28,"Currently, the file systems available to the engine for functions like read_\* are statically defined. GCS, Local, etc. This issue is to make that driven by the config file. The reason this is important is because if you are running a cromwell server and can not disable the ""Local Shared Filesystem"" from the engine... someone could write a WDL that does a read_ on any file that the cromwell server has access to (e.g. read_lines(""./cromwell.conf"")... which is bad",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/821
https://github.com/broadinstitute/cromwell/issues/821:161,Modifiability,config,config,161,"Currently, the file systems available to the engine for functions like read_\* are statically defined. GCS, Local, etc. This issue is to make that driven by the config file. The reason this is important is because if you are running a cromwell server and can not disable the ""Local Shared Filesystem"" from the engine... someone could write a WDL that does a read_ on any file that the cromwell server has access to (e.g. read_lines(""./cromwell.conf"")... which is bad",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/821
https://github.com/broadinstitute/cromwell/issues/821:405,Security,access,access,405,"Currently, the file systems available to the engine for functions like read_\* are statically defined. GCS, Local, etc. This issue is to make that driven by the config file. The reason this is important is because if you are running a cromwell server and can not disable the ""Local Shared Filesystem"" from the engine... someone could write a WDL that does a read_ on any file that the cromwell server has access to (e.g. read_lines(""./cromwell.conf"")... which is bad",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/821
https://github.com/broadinstitute/cromwell/pull/822:81,Availability,down,down,81,"Okay. So initially, I was passing the `ServiceRegistryActor` reference via props down the chain of actors, and each of the actors needed to follow a pattern of steps to insert into the metadata (e.g. create a `MetadataEvent` with a `MetadataPutAction` within which the `Metadata[Key, Value]` resided, send this message over to the the service registry, and handle failures, if any. It did not look good by any stretch IMO. All the metadata generating entities needed to be aware of the `MetadataService` (the erstwhile dataAcess). Currently, what I've done below is create a single instance of the `ServiceRegistryActor` in the `WorkflowManagerActor`and then create a `WorkflowProfilerActor` (one per workflow) which is supposed to handle all the metadata information coming from the engine side for a particular workflow. The way it happens is based on the presumption that almost all the information that we needed was present in the `StateName` and `StateData` of our FSMs. Unfortunately, with Akka's `SubscribeTransitionalCallback` we can only monitor the FSM states, and not the data. So I've created a trait (which the Engine's FSMs can extend from) which provide the semantics of wrapping up the state and data of the FSM in a message, and publish it into Akka's event stream. The ProfilerActor is the listener of these events and handles them appropriately. With this, I was able to make the FSMs unaware of the MetadataServices, and simply publish it's state and data in the event stream while performing any transitions. . Let me know if you guys have any (other?) ideas / suggestions. Edit: Names of new actors might be pretty bad IMO. Please suggest better ones if you have any. _P.S. : Currently based out of the Chris's branch since his metadata changes were needed._; _P.P.S. : Still a WIP for improving some stuff._",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/822
https://github.com/broadinstitute/cromwell/pull/822:364,Availability,failure,failures,364,"Okay. So initially, I was passing the `ServiceRegistryActor` reference via props down the chain of actors, and each of the actors needed to follow a pattern of steps to insert into the metadata (e.g. create a `MetadataEvent` with a `MetadataPutAction` within which the `Metadata[Key, Value]` resided, send this message over to the the service registry, and handle failures, if any. It did not look good by any stretch IMO. All the metadata generating entities needed to be aware of the `MetadataService` (the erstwhile dataAcess). Currently, what I've done below is create a single instance of the `ServiceRegistryActor` in the `WorkflowManagerActor`and then create a `WorkflowProfilerActor` (one per workflow) which is supposed to handle all the metadata information coming from the engine side for a particular workflow. The way it happens is based on the presumption that almost all the information that we needed was present in the `StateName` and `StateData` of our FSMs. Unfortunately, with Akka's `SubscribeTransitionalCallback` we can only monitor the FSM states, and not the data. So I've created a trait (which the Engine's FSMs can extend from) which provide the semantics of wrapping up the state and data of the FSM in a message, and publish it into Akka's event stream. The ProfilerActor is the listener of these events and handles them appropriately. With this, I was able to make the FSMs unaware of the MetadataServices, and simply publish it's state and data in the event stream while performing any transitions. . Let me know if you guys have any (other?) ideas / suggestions. Edit: Names of new actors might be pretty bad IMO. Please suggest better ones if you have any. _P.S. : Currently based out of the Chris's branch since his metadata changes were needed._; _P.P.S. : Still a WIP for improving some stuff._",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/822
https://github.com/broadinstitute/cromwell/pull/822:1048,Energy Efficiency,monitor,monitor,1048,"Okay. So initially, I was passing the `ServiceRegistryActor` reference via props down the chain of actors, and each of the actors needed to follow a pattern of steps to insert into the metadata (e.g. create a `MetadataEvent` with a `MetadataPutAction` within which the `Metadata[Key, Value]` resided, send this message over to the the service registry, and handle failures, if any. It did not look good by any stretch IMO. All the metadata generating entities needed to be aware of the `MetadataService` (the erstwhile dataAcess). Currently, what I've done below is create a single instance of the `ServiceRegistryActor` in the `WorkflowManagerActor`and then create a `WorkflowProfilerActor` (one per workflow) which is supposed to handle all the metadata information coming from the engine side for a particular workflow. The way it happens is based on the presumption that almost all the information that we needed was present in the `StateName` and `StateData` of our FSMs. Unfortunately, with Akka's `SubscribeTransitionalCallback` we can only monitor the FSM states, and not the data. So I've created a trait (which the Engine's FSMs can extend from) which provide the semantics of wrapping up the state and data of the FSM in a message, and publish it into Akka's event stream. The ProfilerActor is the listener of these events and handles them appropriately. With this, I was able to make the FSMs unaware of the MetadataServices, and simply publish it's state and data in the event stream while performing any transitions. . Let me know if you guys have any (other?) ideas / suggestions. Edit: Names of new actors might be pretty bad IMO. Please suggest better ones if you have any. _P.S. : Currently based out of the Chris's branch since his metadata changes were needed._; _P.P.S. : Still a WIP for improving some stuff._",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/822
https://github.com/broadinstitute/cromwell/pull/822:311,Integrability,message,message,311,"Okay. So initially, I was passing the `ServiceRegistryActor` reference via props down the chain of actors, and each of the actors needed to follow a pattern of steps to insert into the metadata (e.g. create a `MetadataEvent` with a `MetadataPutAction` within which the `Metadata[Key, Value]` resided, send this message over to the the service registry, and handle failures, if any. It did not look good by any stretch IMO. All the metadata generating entities needed to be aware of the `MetadataService` (the erstwhile dataAcess). Currently, what I've done below is create a single instance of the `ServiceRegistryActor` in the `WorkflowManagerActor`and then create a `WorkflowProfilerActor` (one per workflow) which is supposed to handle all the metadata information coming from the engine side for a particular workflow. The way it happens is based on the presumption that almost all the information that we needed was present in the `StateName` and `StateData` of our FSMs. Unfortunately, with Akka's `SubscribeTransitionalCallback` we can only monitor the FSM states, and not the data. So I've created a trait (which the Engine's FSMs can extend from) which provide the semantics of wrapping up the state and data of the FSM in a message, and publish it into Akka's event stream. The ProfilerActor is the listener of these events and handles them appropriately. With this, I was able to make the FSMs unaware of the MetadataServices, and simply publish it's state and data in the event stream while performing any transitions. . Let me know if you guys have any (other?) ideas / suggestions. Edit: Names of new actors might be pretty bad IMO. Please suggest better ones if you have any. _P.S. : Currently based out of the Chris's branch since his metadata changes were needed._; _P.P.S. : Still a WIP for improving some stuff._",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/822
https://github.com/broadinstitute/cromwell/pull/822:1187,Integrability,wrap,wrapping,1187,"Okay. So initially, I was passing the `ServiceRegistryActor` reference via props down the chain of actors, and each of the actors needed to follow a pattern of steps to insert into the metadata (e.g. create a `MetadataEvent` with a `MetadataPutAction` within which the `Metadata[Key, Value]` resided, send this message over to the the service registry, and handle failures, if any. It did not look good by any stretch IMO. All the metadata generating entities needed to be aware of the `MetadataService` (the erstwhile dataAcess). Currently, what I've done below is create a single instance of the `ServiceRegistryActor` in the `WorkflowManagerActor`and then create a `WorkflowProfilerActor` (one per workflow) which is supposed to handle all the metadata information coming from the engine side for a particular workflow. The way it happens is based on the presumption that almost all the information that we needed was present in the `StateName` and `StateData` of our FSMs. Unfortunately, with Akka's `SubscribeTransitionalCallback` we can only monitor the FSM states, and not the data. So I've created a trait (which the Engine's FSMs can extend from) which provide the semantics of wrapping up the state and data of the FSM in a message, and publish it into Akka's event stream. The ProfilerActor is the listener of these events and handles them appropriately. With this, I was able to make the FSMs unaware of the MetadataServices, and simply publish it's state and data in the event stream while performing any transitions. . Let me know if you guys have any (other?) ideas / suggestions. Edit: Names of new actors might be pretty bad IMO. Please suggest better ones if you have any. _P.S. : Currently based out of the Chris's branch since his metadata changes were needed._; _P.P.S. : Still a WIP for improving some stuff._",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/822
https://github.com/broadinstitute/cromwell/pull/822:1234,Integrability,message,message,1234,"Okay. So initially, I was passing the `ServiceRegistryActor` reference via props down the chain of actors, and each of the actors needed to follow a pattern of steps to insert into the metadata (e.g. create a `MetadataEvent` with a `MetadataPutAction` within which the `Metadata[Key, Value]` resided, send this message over to the the service registry, and handle failures, if any. It did not look good by any stretch IMO. All the metadata generating entities needed to be aware of the `MetadataService` (the erstwhile dataAcess). Currently, what I've done below is create a single instance of the `ServiceRegistryActor` in the `WorkflowManagerActor`and then create a `WorkflowProfilerActor` (one per workflow) which is supposed to handle all the metadata information coming from the engine side for a particular workflow. The way it happens is based on the presumption that almost all the information that we needed was present in the `StateName` and `StateData` of our FSMs. Unfortunately, with Akka's `SubscribeTransitionalCallback` we can only monitor the FSM states, and not the data. So I've created a trait (which the Engine's FSMs can extend from) which provide the semantics of wrapping up the state and data of the FSM in a message, and publish it into Akka's event stream. The ProfilerActor is the listener of these events and handles them appropriately. With this, I was able to make the FSMs unaware of the MetadataServices, and simply publish it's state and data in the event stream while performing any transitions. . Let me know if you guys have any (other?) ideas / suggestions. Edit: Names of new actors might be pretty bad IMO. Please suggest better ones if you have any. _P.S. : Currently based out of the Chris's branch since his metadata changes were needed._; _P.P.S. : Still a WIP for improving some stuff._",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/822
https://github.com/broadinstitute/cromwell/pull/822:1143,Modifiability,extend,extend,1143,"Okay. So initially, I was passing the `ServiceRegistryActor` reference via props down the chain of actors, and each of the actors needed to follow a pattern of steps to insert into the metadata (e.g. create a `MetadataEvent` with a `MetadataPutAction` within which the `Metadata[Key, Value]` resided, send this message over to the the service registry, and handle failures, if any. It did not look good by any stretch IMO. All the metadata generating entities needed to be aware of the `MetadataService` (the erstwhile dataAcess). Currently, what I've done below is create a single instance of the `ServiceRegistryActor` in the `WorkflowManagerActor`and then create a `WorkflowProfilerActor` (one per workflow) which is supposed to handle all the metadata information coming from the engine side for a particular workflow. The way it happens is based on the presumption that almost all the information that we needed was present in the `StateName` and `StateData` of our FSMs. Unfortunately, with Akka's `SubscribeTransitionalCallback` we can only monitor the FSM states, and not the data. So I've created a trait (which the Engine's FSMs can extend from) which provide the semantics of wrapping up the state and data of the FSM in a message, and publish it into Akka's event stream. The ProfilerActor is the listener of these events and handles them appropriately. With this, I was able to make the FSMs unaware of the MetadataServices, and simply publish it's state and data in the event stream while performing any transitions. . Let me know if you guys have any (other?) ideas / suggestions. Edit: Names of new actors might be pretty bad IMO. Please suggest better ones if you have any. _P.S. : Currently based out of the Chris's branch since his metadata changes were needed._; _P.P.S. : Still a WIP for improving some stuff._",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/822
https://github.com/broadinstitute/cromwell/pull/822:1503,Performance,perform,performing,1503,"Okay. So initially, I was passing the `ServiceRegistryActor` reference via props down the chain of actors, and each of the actors needed to follow a pattern of steps to insert into the metadata (e.g. create a `MetadataEvent` with a `MetadataPutAction` within which the `Metadata[Key, Value]` resided, send this message over to the the service registry, and handle failures, if any. It did not look good by any stretch IMO. All the metadata generating entities needed to be aware of the `MetadataService` (the erstwhile dataAcess). Currently, what I've done below is create a single instance of the `ServiceRegistryActor` in the `WorkflowManagerActor`and then create a `WorkflowProfilerActor` (one per workflow) which is supposed to handle all the metadata information coming from the engine side for a particular workflow. The way it happens is based on the presumption that almost all the information that we needed was present in the `StateName` and `StateData` of our FSMs. Unfortunately, with Akka's `SubscribeTransitionalCallback` we can only monitor the FSM states, and not the data. So I've created a trait (which the Engine's FSMs can extend from) which provide the semantics of wrapping up the state and data of the FSM in a message, and publish it into Akka's event stream. The ProfilerActor is the listener of these events and handles them appropriately. With this, I was able to make the FSMs unaware of the MetadataServices, and simply publish it's state and data in the event stream while performing any transitions. . Let me know if you guys have any (other?) ideas / suggestions. Edit: Names of new actors might be pretty bad IMO. Please suggest better ones if you have any. _P.S. : Currently based out of the Chris's branch since his metadata changes were needed._; _P.P.S. : Still a WIP for improving some stuff._",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/822
https://github.com/broadinstitute/cromwell/pull/822:1442,Usability,simpl,simply,1442,"Okay. So initially, I was passing the `ServiceRegistryActor` reference via props down the chain of actors, and each of the actors needed to follow a pattern of steps to insert into the metadata (e.g. create a `MetadataEvent` with a `MetadataPutAction` within which the `Metadata[Key, Value]` resided, send this message over to the the service registry, and handle failures, if any. It did not look good by any stretch IMO. All the metadata generating entities needed to be aware of the `MetadataService` (the erstwhile dataAcess). Currently, what I've done below is create a single instance of the `ServiceRegistryActor` in the `WorkflowManagerActor`and then create a `WorkflowProfilerActor` (one per workflow) which is supposed to handle all the metadata information coming from the engine side for a particular workflow. The way it happens is based on the presumption that almost all the information that we needed was present in the `StateName` and `StateData` of our FSMs. Unfortunately, with Akka's `SubscribeTransitionalCallback` we can only monitor the FSM states, and not the data. So I've created a trait (which the Engine's FSMs can extend from) which provide the semantics of wrapping up the state and data of the FSM in a message, and publish it into Akka's event stream. The ProfilerActor is the listener of these events and handles them appropriately. With this, I was able to make the FSMs unaware of the MetadataServices, and simply publish it's state and data in the event stream while performing any transitions. . Let me know if you guys have any (other?) ideas / suggestions. Edit: Names of new actors might be pretty bad IMO. Please suggest better ones if you have any. _P.S. : Currently based out of the Chris's branch since his metadata changes were needed._; _P.P.S. : Still a WIP for improving some stuff._",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/822
https://github.com/broadinstitute/cromwell/pull/823:333,Deployability,update,update,333,"Made a small change to the preStart method of WFMA, it only tries to re-start incomplete workflows when the config ""workflow-restart"" is set to true. I don't know if I loved how I named that field, and I'm open to suggestions. . Since we don't have restarts configured right now, I didn't have a chance to test this change. I didn't update the Readme yet either, since this is not a change users can use yet, I'm realizing now we do need some way to keep track of all the documentation changes we'll need to make.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/823
https://github.com/broadinstitute/cromwell/pull/823:108,Modifiability,config,config,108,"Made a small change to the preStart method of WFMA, it only tries to re-start incomplete workflows when the config ""workflow-restart"" is set to true. I don't know if I loved how I named that field, and I'm open to suggestions. . Since we don't have restarts configured right now, I didn't have a chance to test this change. I didn't update the Readme yet either, since this is not a change users can use yet, I'm realizing now we do need some way to keep track of all the documentation changes we'll need to make.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/823
https://github.com/broadinstitute/cromwell/pull/823:258,Modifiability,config,configured,258,"Made a small change to the preStart method of WFMA, it only tries to re-start incomplete workflows when the config ""workflow-restart"" is set to true. I don't know if I loved how I named that field, and I'm open to suggestions. . Since we don't have restarts configured right now, I didn't have a chance to test this change. I didn't update the Readme yet either, since this is not a change users can use yet, I'm realizing now we do need some way to keep track of all the documentation changes we'll need to make.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/823
https://github.com/broadinstitute/cromwell/pull/823:306,Testability,test,test,306,"Made a small change to the preStart method of WFMA, it only tries to re-start incomplete workflows when the config ""workflow-restart"" is set to true. I don't know if I loved how I named that field, and I'm open to suggestions. . Since we don't have restarts configured right now, I didn't have a chance to test this change. I didn't update the Readme yet either, since this is not a change users can use yet, I'm realizing now we do need some way to keep track of all the documentation changes we'll need to make.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/823
https://github.com/broadinstitute/cromwell/pull/824:76,Availability,echo,echo,76,"This allows this workflow to run:. ```; task t {; Array[String] s; command {echo ${sep=',' s}}; output {String o = read_string(stdout())}; }. workflow w {; Array[String] x = read_lines(""gs://sfrazer-dev/array.txt""); call t {input: s=x}; }. ```. So this is the minimum implementation I could come up with... looking for design feedback too, this could be simple or become full-blown pluggable filesystems",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/824
https://github.com/broadinstitute/cromwell/pull/824:326,Usability,feedback,feedback,326,"This allows this workflow to run:. ```; task t {; Array[String] s; command {echo ${sep=',' s}}; output {String o = read_string(stdout())}; }. workflow w {; Array[String] x = read_lines(""gs://sfrazer-dev/array.txt""); call t {input: s=x}; }. ```. So this is the minimum implementation I could come up with... looking for design feedback too, this could be simple or become full-blown pluggable filesystems",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/824
https://github.com/broadinstitute/cromwell/pull/824:354,Usability,simpl,simple,354,"This allows this workflow to run:. ```; task t {; Array[String] s; command {echo ${sep=',' s}}; output {String o = read_string(stdout())}; }. workflow w {; Array[String] x = read_lines(""gs://sfrazer-dev/array.txt""); call t {input: s=x}; }. ```. So this is the minimum implementation I could come up with... looking for design feedback too, this could be simple or become full-blown pluggable filesystems",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/824
https://github.com/broadinstitute/cromwell/issues/826:44,Availability,error,error,44,"We've seen several workflows fail with this error:. 2016-05-10 11:38:08,737 cromwell-system-akka.actor.default-dispatcher-3 ERROR - WorkflowActor [UUID(972b838f)]: Completion work failed for call CollectUnsortedReadgroupBamQualityMetrics:10.; java.net.SocketTimeoutException: Read timed out;   at java.net.SocketInputStream.socketRead0(Native Method) ~[na:1.8.0_72];   at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[na:1.8.0_72];   at java.net.SocketInputStream.read(SocketInputStream.java:170) ~[na:1.8.0_72];   at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72];   at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72];   at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72];   at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72];   at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_72];   at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37) ~[cromwell.jar:0.19];   at ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:124,Availability,ERROR,ERROR,124,"We've seen several workflows fail with this error:. 2016-05-10 11:38:08,737 cromwell-system-akka.actor.default-dispatcher-3 ERROR - WorkflowActor [UUID(972b838f)]: Completion work failed for call CollectUnsortedReadgroupBamQualityMetrics:10.; java.net.SocketTimeoutException: Read timed out;   at java.net.SocketInputStream.socketRead0(Native Method) ~[na:1.8.0_72];   at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[na:1.8.0_72];   at java.net.SocketInputStream.read(SocketInputStream.java:170) ~[na:1.8.0_72];   at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72];   at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72];   at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72];   at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72];   at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_72];   at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37) ~[cromwell.jar:0.19];   at ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:8753,Availability,ERROR,ERROR,8753,"DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-05-10 11:38:08,737 cromwell-system-akka.actor.default-dispatcher-3 INFO  - WorkflowActor [UUID(972b838f)]: persisting status of CollectUnsortedReadgroupBamQualityMetrics:10 to Failed.; 2016-05-10 11:38:08,738 cromwell-system-akka.actor.default-dispatcher-3 ERROR - WorkflowActor [UUID(972b838f)]: Read timed out",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:8003,Energy Efficiency,Adapt,AdaptedForkJoinTask,8003,"DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-05-10 11:38:08,737 cromwell-system-akka.actor.default-dispatcher-3 INFO  - WorkflowActor [UUID(972b838f)]: persisting status of CollectUnsortedReadgroupBamQualityMetrics:10 to Failed.; 2016-05-10 11:38:08,738 cromwell-system-akka.actor.default-dispatcher-3 ERROR - WorkflowActor [UUID(972b838f)]: Read timed out",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:1472,Integrability,protocol,protocol,1472,putStream.read(SocketInputStream.java:170) ~[na:1.8.0_72];   at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72];   at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72];   at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72];   at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72];   at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_72];   at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37) ~[cromwell.jar:0.19];   at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94) ~[cromwell.jar:0.19];   at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:3,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:1582,Integrability,protocol,protocol,1582,eam.java:141) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72];   at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72];   at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72];   at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72];   at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_72];   at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37) ~[cromwell.jar:0.19];   at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94) ~[cromwell.jar:0.19];   at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(A,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:1783,Integrability,protocol,protocol,1783,urity.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72];   at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72];   at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72];   at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72];   at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_72];   at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37) ~[cromwell.jar:0.19];   at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94) ~[cromwell.jar:0.19];   at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala:191) ~[cromwell.j,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:8003,Modifiability,Adapt,AdaptedForkJoinTask,8003,"DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-05-10 11:38:08,737 cromwell-system-akka.actor.default-dispatcher-3 INFO  - WorkflowActor [UUID(972b838f)]: persisting status of CollectUnsortedReadgroupBamQualityMetrics:10 to Failed.; 2016-05-10 11:38:08,738 cromwell-system-akka.actor.default-dispatcher-3 ERROR - WorkflowActor [UUID(972b838f)]: Read timed out",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:7041,Performance,concurren,concurrent,7041,cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:569) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:568) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImp,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:7135,Performance,concurren,concurrent,7135,omwell.jar:0.19];   at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:777) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:569) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:568) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoin,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:7229,Performance,concurren,concurrent,7229,la:777) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues.foreach(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:569) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:568) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runT,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:7329,Performance,concurren,concurrent,7329,~[cromwell.jar:0.19];   at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.AbstractTraversable.map(Traversable.scala:104) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:569) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:568) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWork,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:7878,Performance,concurren,concurrent,7878,"DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-05-10 11:38:08,737 cromwell-system-akka.actor.default-dispatcher-3 INFO  - WorkflowActor [UUID(972b838f)]: persisting status of CollectUnsortedReadgroupBamQualityMetrics:10 to Failed.; 2016-05-10 11:38:08,738 cromwell-system-akka.actor.default-dispatcher-3 ERROR - WorkflowActor [UUID(972b838f)]: Read timed out",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:7966,Performance,concurren,concurrent,7966,"DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-05-10 11:38:08,737 cromwell-system-akka.actor.default-dispatcher-3 INFO  - WorkflowActor [UUID(972b838f)]: persisting status of CollectUnsortedReadgroupBamQualityMetrics:10 to Failed.; 2016-05-10 11:38:08,738 cromwell-system-akka.actor.default-dispatcher-3 ERROR - WorkflowActor [UUID(972b838f)]: Read timed out",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:8093,Performance,concurren,concurrent,8093,"DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-05-10 11:38:08,737 cromwell-system-akka.actor.default-dispatcher-3 INFO  - WorkflowActor [UUID(972b838f)]: persisting status of CollectUnsortedReadgroupBamQualityMetrics:10 to Failed.; 2016-05-10 11:38:08,738 cromwell-system-akka.actor.default-dispatcher-3 ERROR - WorkflowActor [UUID(972b838f)]: Read timed out",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:8188,Performance,concurren,concurrent,8188,"DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-05-10 11:38:08,737 cromwell-system-akka.actor.default-dispatcher-3 INFO  - WorkflowActor [UUID(972b838f)]: persisting status of CollectUnsortedReadgroupBamQualityMetrics:10 to Failed.; 2016-05-10 11:38:08,738 cromwell-system-akka.actor.default-dispatcher-3 ERROR - WorkflowActor [UUID(972b838f)]: Read timed out",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:8295,Performance,concurren,concurrent,8295,"DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-05-10 11:38:08,737 cromwell-system-akka.actor.default-dispatcher-3 INFO  - WorkflowActor [UUID(972b838f)]: persisting status of CollectUnsortedReadgroupBamQualityMetrics:10 to Failed.; 2016-05-10 11:38:08,738 cromwell-system-akka.actor.default-dispatcher-3 ERROR - WorkflowActor [UUID(972b838f)]: Read timed out",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:8394,Performance,concurren,concurrent,8394,"DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-05-10 11:38:08,737 cromwell-system-akka.actor.default-dispatcher-3 INFO  - WorkflowActor [UUID(972b838f)]: persisting status of CollectUnsortedReadgroupBamQualityMetrics:10 to Failed.; 2016-05-10 11:38:08,738 cromwell-system-akka.actor.default-dispatcher-3 ERROR - WorkflowActor [UUID(972b838f)]: Read timed out",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:625,Security,secur,security,625,"We've seen several workflows fail with this error:. 2016-05-10 11:38:08,737 cromwell-system-akka.actor.default-dispatcher-3 ERROR - WorkflowActor [UUID(972b838f)]: Completion work failed for call CollectUnsortedReadgroupBamQualityMetrics:10.; java.net.SocketTimeoutException: Read timed out;   at java.net.SocketInputStream.socketRead0(Native Method) ~[na:1.8.0_72];   at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[na:1.8.0_72];   at java.net.SocketInputStream.read(SocketInputStream.java:170) ~[na:1.8.0_72];   at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72];   at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72];   at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72];   at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72];   at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_72];   at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37) ~[cromwell.jar:0.19];   at ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:707,Security,secur,security,707,"We've seen several workflows fail with this error:. 2016-05-10 11:38:08,737 cromwell-system-akka.actor.default-dispatcher-3 ERROR - WorkflowActor [UUID(972b838f)]: Completion work failed for call CollectUnsortedReadgroupBamQualityMetrics:10.; java.net.SocketTimeoutException: Read timed out;   at java.net.SocketInputStream.socketRead0(Native Method) ~[na:1.8.0_72];   at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[na:1.8.0_72];   at java.net.SocketInputStream.read(SocketInputStream.java:170) ~[na:1.8.0_72];   at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72];   at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72];   at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72];   at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72];   at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_72];   at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37) ~[cromwell.jar:0.19];   at ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:784,Security,secur,security,784,"We've seen several workflows fail with this error:. 2016-05-10 11:38:08,737 cromwell-system-akka.actor.default-dispatcher-3 ERROR - WorkflowActor [UUID(972b838f)]: Completion work failed for call CollectUnsortedReadgroupBamQualityMetrics:10.; java.net.SocketTimeoutException: Read timed out;   at java.net.SocketInputStream.socketRead0(Native Method) ~[na:1.8.0_72];   at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[na:1.8.0_72];   at java.net.SocketInputStream.read(SocketInputStream.java:170) ~[na:1.8.0_72];   at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72];   at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72];   at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72];   at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72];   at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_72];   at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37) ~[cromwell.jar:0.19];   at ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:871,Security,secur,security,871,"We've seen several workflows fail with this error:. 2016-05-10 11:38:08,737 cromwell-system-akka.actor.default-dispatcher-3 ERROR - WorkflowActor [UUID(972b838f)]: Completion work failed for call CollectUnsortedReadgroupBamQualityMetrics:10.; java.net.SocketTimeoutException: Read timed out;   at java.net.SocketInputStream.socketRead0(Native Method) ~[na:1.8.0_72];   at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[na:1.8.0_72];   at java.net.SocketInputStream.read(SocketInputStream.java:170) ~[na:1.8.0_72];   at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72];   at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72];   at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72];   at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72];   at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_72];   at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37) ~[cromwell.jar:0.19];   at ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:962,Security,secur,security,962,"We've seen several workflows fail with this error:. 2016-05-10 11:38:08,737 cromwell-system-akka.actor.default-dispatcher-3 ERROR - WorkflowActor [UUID(972b838f)]: Completion work failed for call CollectUnsortedReadgroupBamQualityMetrics:10.; java.net.SocketTimeoutException: Read timed out;   at java.net.SocketInputStream.socketRead0(Native Method) ~[na:1.8.0_72];   at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[na:1.8.0_72];   at java.net.SocketInputStream.read(SocketInputStream.java:170) ~[na:1.8.0_72];   at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72];   at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72];   at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72];   at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72];   at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_72];   at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37) ~[cromwell.jar:0.19];   at ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:3337,Security,hash,hash,3337,9];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala:191) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala:191) ~[cromwell.jar:0.19];   at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$.withRetry(GcsFileSystemProvider.scala:44) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider.crc32cHash(GcsFileSystemProvider.scala:191) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.package$PathEnhanced$.hash$extension(package.scala:32) ~[cromwell.jar:0.19];   at cromwell.engine.backend.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:65) ~[cromwell.jar:0.19];   at cromwell.engine.backend.WorkflowDescriptor$$anonfun$fileHasher$1.apply(WorkflowDescriptor.scala:63) ~[cromwell.jar:0.19];   at wdl4s.values.WdlValue$class.computeHash(WdlValue.scala:63) ~[cromwell.jar:0.19];   at wdl4s.values.WdlSingleFile.computeHash(WdlFile.scala:39) ~[cromwell.jar:0.19];   at wdl4s.values.WdlValue$$anonfun$computeHash$3.apply(WdlValue.scala:62) ~[cromwell.jar:0.19];   at wdl4s.values.WdlValue$$anonfun$computeHash$3.apply(WdlValue.scala:62) ~[cromwell.jar:0.19];   at scala.collection.immutable.Stream$$anonfun$map$1.apply(Stream.scala:418) ~[cromwell.jar:0.19];   at scala.collection.immutable.Stream$$anonfun$map$1.apply(Stream.scala:418) ~[cromwell.jar:0.19];   at scala.collection.immutable.Stream$Cons.tail(Stream.scala:1233) ~[cromwell.jar:0.19];   at scala.collection.immutable.Stream$Cons.tail(,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/826:4865,Security,hash,hash,4865,lue.scala:62) ~[cromwell.jar:0.19];   at wdl4s.values.WdlValue$$anonfun$computeHash$3.apply(WdlValue.scala:62) ~[cromwell.jar:0.19];   at scala.collection.immutable.Stream$$anonfun$map$1.apply(Stream.scala:418) ~[cromwell.jar:0.19];   at scala.collection.immutable.Stream$$anonfun$map$1.apply(Stream.scala:418) ~[cromwell.jar:0.19];   at scala.collection.immutable.Stream$Cons.tail(Stream.scala:1233) ~[cromwell.jar:0.19];   at scala.collection.immutable.Stream$Cons.tail(Stream.scala:1223) ~[cromwell.jar:0.19];   at scala.collection.immutable.Stream.force(Stream.scala:272) ~[cromwell.jar:0.19];   at scala.collection.immutable.Stream.mkString(Stream.scala:820) ~[cromwell.jar:0.19];   at scala.collection.immutable.Stream.mkString(Stream.scala:817) ~[cromwell.jar:0.19];   at wdl4s.values.WdlValue$class.computeHash(WdlValue.scala:62) ~[cromwell.jar:0.19];   at wdl4s.values.WdlArray.computeHash(WdlArray.scala:17) ~[cromwell.jar:0.19];   at cromwell.engine.backend.WorkflowDescriptor.hash(WorkflowDescriptor.scala:229) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$postProcess$1$$anonfun$apply$14.apply(JesBackend.scala:627) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$postProcess$1$$anonfun$apply$14.apply(JesBackend.scala:626) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.MapLike$MappedValues$$anonfun$foreach$3.apply(MapLike.scala:245) ~[cromwell.jar:0.19];   at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:778) ~[cromwell.jar:0.19];   a,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826
https://github.com/broadinstitute/cromwell/issues/828:218,Availability,echo,echo,218,"The following workflow should produce an output array containing a single string. Instead it produces an empty array. This problem occurs when using the JES backend but not the local backend. ```; task x {; command {; echo hello > hello; }; output {; Array[String] a = glob(""hello""); }; runtime {; docker: ""ubuntu:latest""; }; }; workflow w {; call x; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/828
https://github.com/broadinstitute/cromwell/pull/829:81,Availability,down,down,81,"Okay. So initially, I was passing the `ServiceRegistryActor` reference via props down the chain of actors, and each of the actors needed to follow a pattern of steps to insert into the metadata (e.g. create a `MetadataEvent` with a `MetadataPutAction` within which the `Metadata[Key, Value]` resided, send this message over to the the service registry, and handle failures, if any. It did not look good by any stretch IMO. All the metadata generating entities needed to be aware of the `MetadataService` (the erstwhile dataAcess). **Edit:** Using the above design in-fact now. ~~Currently, what I've done below is create a single instance of the `ServiceRegistryActor` in the `WorkflowManagerActor`and then create a `WorkflowProfilerActor` (one per workflow) which is supposed to handle all the metadata information coming from the engine side for a particular workflow. The way it happens is based on the presumption that almost all the information that we needed was present in the `StateName` and `StateData` of our FSMs. Unfortunately, with Akka's `SubscribeTransitionalCallback` we can only monitor the FSM states, and not the data. So I've created a trait (which the Engine's FSMs can extend from) which provide the semantics of wrapping up the state and data of the FSM in a message, and publish it into Akka's event stream. The ProfilerActor is the listener of these events and handles them appropriately. With this, I was able to make the FSMs unaware of the MetadataServices, and simply publish it's state and data in the event stream while performing any transitions.~~. ~~Let me know if you guys have any (other?) ideas / suggestions.~~. Contents added to metadata with this PR:; - [x] workflowName; - [ ] calls (To come from the backends); - [x] outputs ; - [x] id; - [x] inputs; - [x] submission; - [x] status; - [x] end; - [x] start",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/829
https://github.com/broadinstitute/cromwell/pull/829:364,Availability,failure,failures,364,"Okay. So initially, I was passing the `ServiceRegistryActor` reference via props down the chain of actors, and each of the actors needed to follow a pattern of steps to insert into the metadata (e.g. create a `MetadataEvent` with a `MetadataPutAction` within which the `Metadata[Key, Value]` resided, send this message over to the the service registry, and handle failures, if any. It did not look good by any stretch IMO. All the metadata generating entities needed to be aware of the `MetadataService` (the erstwhile dataAcess). **Edit:** Using the above design in-fact now. ~~Currently, what I've done below is create a single instance of the `ServiceRegistryActor` in the `WorkflowManagerActor`and then create a `WorkflowProfilerActor` (one per workflow) which is supposed to handle all the metadata information coming from the engine side for a particular workflow. The way it happens is based on the presumption that almost all the information that we needed was present in the `StateName` and `StateData` of our FSMs. Unfortunately, with Akka's `SubscribeTransitionalCallback` we can only monitor the FSM states, and not the data. So I've created a trait (which the Engine's FSMs can extend from) which provide the semantics of wrapping up the state and data of the FSM in a message, and publish it into Akka's event stream. The ProfilerActor is the listener of these events and handles them appropriately. With this, I was able to make the FSMs unaware of the MetadataServices, and simply publish it's state and data in the event stream while performing any transitions.~~. ~~Let me know if you guys have any (other?) ideas / suggestions.~~. Contents added to metadata with this PR:; - [x] workflowName; - [ ] calls (To come from the backends); - [x] outputs ; - [x] id; - [x] inputs; - [x] submission; - [x] status; - [x] end; - [x] start",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/829
https://github.com/broadinstitute/cromwell/pull/829:1096,Energy Efficiency,monitor,monitor,1096,"Okay. So initially, I was passing the `ServiceRegistryActor` reference via props down the chain of actors, and each of the actors needed to follow a pattern of steps to insert into the metadata (e.g. create a `MetadataEvent` with a `MetadataPutAction` within which the `Metadata[Key, Value]` resided, send this message over to the the service registry, and handle failures, if any. It did not look good by any stretch IMO. All the metadata generating entities needed to be aware of the `MetadataService` (the erstwhile dataAcess). **Edit:** Using the above design in-fact now. ~~Currently, what I've done below is create a single instance of the `ServiceRegistryActor` in the `WorkflowManagerActor`and then create a `WorkflowProfilerActor` (one per workflow) which is supposed to handle all the metadata information coming from the engine side for a particular workflow. The way it happens is based on the presumption that almost all the information that we needed was present in the `StateName` and `StateData` of our FSMs. Unfortunately, with Akka's `SubscribeTransitionalCallback` we can only monitor the FSM states, and not the data. So I've created a trait (which the Engine's FSMs can extend from) which provide the semantics of wrapping up the state and data of the FSM in a message, and publish it into Akka's event stream. The ProfilerActor is the listener of these events and handles them appropriately. With this, I was able to make the FSMs unaware of the MetadataServices, and simply publish it's state and data in the event stream while performing any transitions.~~. ~~Let me know if you guys have any (other?) ideas / suggestions.~~. Contents added to metadata with this PR:; - [x] workflowName; - [ ] calls (To come from the backends); - [x] outputs ; - [x] id; - [x] inputs; - [x] submission; - [x] status; - [x] end; - [x] start",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/829
https://github.com/broadinstitute/cromwell/pull/829:311,Integrability,message,message,311,"Okay. So initially, I was passing the `ServiceRegistryActor` reference via props down the chain of actors, and each of the actors needed to follow a pattern of steps to insert into the metadata (e.g. create a `MetadataEvent` with a `MetadataPutAction` within which the `Metadata[Key, Value]` resided, send this message over to the the service registry, and handle failures, if any. It did not look good by any stretch IMO. All the metadata generating entities needed to be aware of the `MetadataService` (the erstwhile dataAcess). **Edit:** Using the above design in-fact now. ~~Currently, what I've done below is create a single instance of the `ServiceRegistryActor` in the `WorkflowManagerActor`and then create a `WorkflowProfilerActor` (one per workflow) which is supposed to handle all the metadata information coming from the engine side for a particular workflow. The way it happens is based on the presumption that almost all the information that we needed was present in the `StateName` and `StateData` of our FSMs. Unfortunately, with Akka's `SubscribeTransitionalCallback` we can only monitor the FSM states, and not the data. So I've created a trait (which the Engine's FSMs can extend from) which provide the semantics of wrapping up the state and data of the FSM in a message, and publish it into Akka's event stream. The ProfilerActor is the listener of these events and handles them appropriately. With this, I was able to make the FSMs unaware of the MetadataServices, and simply publish it's state and data in the event stream while performing any transitions.~~. ~~Let me know if you guys have any (other?) ideas / suggestions.~~. Contents added to metadata with this PR:; - [x] workflowName; - [ ] calls (To come from the backends); - [x] outputs ; - [x] id; - [x] inputs; - [x] submission; - [x] status; - [x] end; - [x] start",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/829
https://github.com/broadinstitute/cromwell/pull/829:1235,Integrability,wrap,wrapping,1235,"Okay. So initially, I was passing the `ServiceRegistryActor` reference via props down the chain of actors, and each of the actors needed to follow a pattern of steps to insert into the metadata (e.g. create a `MetadataEvent` with a `MetadataPutAction` within which the `Metadata[Key, Value]` resided, send this message over to the the service registry, and handle failures, if any. It did not look good by any stretch IMO. All the metadata generating entities needed to be aware of the `MetadataService` (the erstwhile dataAcess). **Edit:** Using the above design in-fact now. ~~Currently, what I've done below is create a single instance of the `ServiceRegistryActor` in the `WorkflowManagerActor`and then create a `WorkflowProfilerActor` (one per workflow) which is supposed to handle all the metadata information coming from the engine side for a particular workflow. The way it happens is based on the presumption that almost all the information that we needed was present in the `StateName` and `StateData` of our FSMs. Unfortunately, with Akka's `SubscribeTransitionalCallback` we can only monitor the FSM states, and not the data. So I've created a trait (which the Engine's FSMs can extend from) which provide the semantics of wrapping up the state and data of the FSM in a message, and publish it into Akka's event stream. The ProfilerActor is the listener of these events and handles them appropriately. With this, I was able to make the FSMs unaware of the MetadataServices, and simply publish it's state and data in the event stream while performing any transitions.~~. ~~Let me know if you guys have any (other?) ideas / suggestions.~~. Contents added to metadata with this PR:; - [x] workflowName; - [ ] calls (To come from the backends); - [x] outputs ; - [x] id; - [x] inputs; - [x] submission; - [x] status; - [x] end; - [x] start",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/829
https://github.com/broadinstitute/cromwell/pull/829:1282,Integrability,message,message,1282,"Okay. So initially, I was passing the `ServiceRegistryActor` reference via props down the chain of actors, and each of the actors needed to follow a pattern of steps to insert into the metadata (e.g. create a `MetadataEvent` with a `MetadataPutAction` within which the `Metadata[Key, Value]` resided, send this message over to the the service registry, and handle failures, if any. It did not look good by any stretch IMO. All the metadata generating entities needed to be aware of the `MetadataService` (the erstwhile dataAcess). **Edit:** Using the above design in-fact now. ~~Currently, what I've done below is create a single instance of the `ServiceRegistryActor` in the `WorkflowManagerActor`and then create a `WorkflowProfilerActor` (one per workflow) which is supposed to handle all the metadata information coming from the engine side for a particular workflow. The way it happens is based on the presumption that almost all the information that we needed was present in the `StateName` and `StateData` of our FSMs. Unfortunately, with Akka's `SubscribeTransitionalCallback` we can only monitor the FSM states, and not the data. So I've created a trait (which the Engine's FSMs can extend from) which provide the semantics of wrapping up the state and data of the FSM in a message, and publish it into Akka's event stream. The ProfilerActor is the listener of these events and handles them appropriately. With this, I was able to make the FSMs unaware of the MetadataServices, and simply publish it's state and data in the event stream while performing any transitions.~~. ~~Let me know if you guys have any (other?) ideas / suggestions.~~. Contents added to metadata with this PR:; - [x] workflowName; - [ ] calls (To come from the backends); - [x] outputs ; - [x] id; - [x] inputs; - [x] submission; - [x] status; - [x] end; - [x] start",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/829
https://github.com/broadinstitute/cromwell/pull/829:1191,Modifiability,extend,extend,1191,"Okay. So initially, I was passing the `ServiceRegistryActor` reference via props down the chain of actors, and each of the actors needed to follow a pattern of steps to insert into the metadata (e.g. create a `MetadataEvent` with a `MetadataPutAction` within which the `Metadata[Key, Value]` resided, send this message over to the the service registry, and handle failures, if any. It did not look good by any stretch IMO. All the metadata generating entities needed to be aware of the `MetadataService` (the erstwhile dataAcess). **Edit:** Using the above design in-fact now. ~~Currently, what I've done below is create a single instance of the `ServiceRegistryActor` in the `WorkflowManagerActor`and then create a `WorkflowProfilerActor` (one per workflow) which is supposed to handle all the metadata information coming from the engine side for a particular workflow. The way it happens is based on the presumption that almost all the information that we needed was present in the `StateName` and `StateData` of our FSMs. Unfortunately, with Akka's `SubscribeTransitionalCallback` we can only monitor the FSM states, and not the data. So I've created a trait (which the Engine's FSMs can extend from) which provide the semantics of wrapping up the state and data of the FSM in a message, and publish it into Akka's event stream. The ProfilerActor is the listener of these events and handles them appropriately. With this, I was able to make the FSMs unaware of the MetadataServices, and simply publish it's state and data in the event stream while performing any transitions.~~. ~~Let me know if you guys have any (other?) ideas / suggestions.~~. Contents added to metadata with this PR:; - [x] workflowName; - [ ] calls (To come from the backends); - [x] outputs ; - [x] id; - [x] inputs; - [x] submission; - [x] status; - [x] end; - [x] start",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/829
https://github.com/broadinstitute/cromwell/pull/829:1551,Performance,perform,performing,1551,"Okay. So initially, I was passing the `ServiceRegistryActor` reference via props down the chain of actors, and each of the actors needed to follow a pattern of steps to insert into the metadata (e.g. create a `MetadataEvent` with a `MetadataPutAction` within which the `Metadata[Key, Value]` resided, send this message over to the the service registry, and handle failures, if any. It did not look good by any stretch IMO. All the metadata generating entities needed to be aware of the `MetadataService` (the erstwhile dataAcess). **Edit:** Using the above design in-fact now. ~~Currently, what I've done below is create a single instance of the `ServiceRegistryActor` in the `WorkflowManagerActor`and then create a `WorkflowProfilerActor` (one per workflow) which is supposed to handle all the metadata information coming from the engine side for a particular workflow. The way it happens is based on the presumption that almost all the information that we needed was present in the `StateName` and `StateData` of our FSMs. Unfortunately, with Akka's `SubscribeTransitionalCallback` we can only monitor the FSM states, and not the data. So I've created a trait (which the Engine's FSMs can extend from) which provide the semantics of wrapping up the state and data of the FSM in a message, and publish it into Akka's event stream. The ProfilerActor is the listener of these events and handles them appropriately. With this, I was able to make the FSMs unaware of the MetadataServices, and simply publish it's state and data in the event stream while performing any transitions.~~. ~~Let me know if you guys have any (other?) ideas / suggestions.~~. Contents added to metadata with this PR:; - [x] workflowName; - [ ] calls (To come from the backends); - [x] outputs ; - [x] id; - [x] inputs; - [x] submission; - [x] status; - [x] end; - [x] start",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/829
https://github.com/broadinstitute/cromwell/pull/829:1490,Usability,simpl,simply,1490,"Okay. So initially, I was passing the `ServiceRegistryActor` reference via props down the chain of actors, and each of the actors needed to follow a pattern of steps to insert into the metadata (e.g. create a `MetadataEvent` with a `MetadataPutAction` within which the `Metadata[Key, Value]` resided, send this message over to the the service registry, and handle failures, if any. It did not look good by any stretch IMO. All the metadata generating entities needed to be aware of the `MetadataService` (the erstwhile dataAcess). **Edit:** Using the above design in-fact now. ~~Currently, what I've done below is create a single instance of the `ServiceRegistryActor` in the `WorkflowManagerActor`and then create a `WorkflowProfilerActor` (one per workflow) which is supposed to handle all the metadata information coming from the engine side for a particular workflow. The way it happens is based on the presumption that almost all the information that we needed was present in the `StateName` and `StateData` of our FSMs. Unfortunately, with Akka's `SubscribeTransitionalCallback` we can only monitor the FSM states, and not the data. So I've created a trait (which the Engine's FSMs can extend from) which provide the semantics of wrapping up the state and data of the FSM in a message, and publish it into Akka's event stream. The ProfilerActor is the listener of these events and handles them appropriately. With this, I was able to make the FSMs unaware of the MetadataServices, and simply publish it's state and data in the event stream while performing any transitions.~~. ~~Let me know if you guys have any (other?) ideas / suggestions.~~. Contents added to metadata with this PR:; - [x] workflowName; - [ ] calls (To come from the backends); - [x] outputs ; - [x] id; - [x] inputs; - [x] submission; - [x] status; - [x] end; - [x] start",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/829
https://github.com/broadinstitute/cromwell/issues/832:88,Performance,cache,cache,88,"If you run the workflow described in #820 and then run it a second time which will call cache from the first workflow run, Cromwell will become unresponsive for an unknown amount of time (I usually kill Cromwell after a couple of minutes). If the first workflow succeeded completely, this second workflow will try to grab the results from the cache for 95 jobs, each with 2 arrays of outputs with 901 elements in each array. Cromwell becomes unreachable by the swagger page or any APIs.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/832
https://github.com/broadinstitute/cromwell/issues/832:343,Performance,cache,cache,343,"If you run the workflow described in #820 and then run it a second time which will call cache from the first workflow run, Cromwell will become unresponsive for an unknown amount of time (I usually kill Cromwell after a couple of minutes). If the first workflow succeeded completely, this second workflow will try to grab the results from the cache for 95 jobs, each with 2 arrays of outputs with 901 elements in each array. Cromwell becomes unreachable by the swagger page or any APIs.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/832
https://github.com/broadinstitute/cromwell/issues/839:645,Deployability,integrat,integrates,645,"The spec allows for a workflow to be called from within another workflow. This feature would be tremendously beneficial for when we would like to run a workflow on more than a single sample, but still retain the ability to run a single sample through a single sample workflow. The real benefit would be post-workflow tasks that could be imported to further interrogate the array of single sample workflow outputs. I understand something similar could be achieved using a scatter block. Unfortunately, nested scatter blocks are not functional yet (see [#838](https://github.com/broadinstitute/cromwell/issues/838)). Additionally, a solution that integrates modular workflow definitions would be cleaner, more user friendly, maintainable etc. ```; call namespace.workflow {; input: foo=bar; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/839
https://github.com/broadinstitute/cromwell/issues/839:645,Integrability,integrat,integrates,645,"The spec allows for a workflow to be called from within another workflow. This feature would be tremendously beneficial for when we would like to run a workflow on more than a single sample, but still retain the ability to run a single sample through a single sample workflow. The real benefit would be post-workflow tasks that could be imported to further interrogate the array of single sample workflow outputs. I understand something similar could be achieved using a scatter block. Unfortunately, nested scatter blocks are not functional yet (see [#838](https://github.com/broadinstitute/cromwell/issues/838)). Additionally, a solution that integrates modular workflow definitions would be cleaner, more user friendly, maintainable etc. ```; call namespace.workflow {; input: foo=bar; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/839
https://github.com/broadinstitute/cromwell/issues/839:723,Modifiability,maintainab,maintainable,723,"The spec allows for a workflow to be called from within another workflow. This feature would be tremendously beneficial for when we would like to run a workflow on more than a single sample, but still retain the ability to run a single sample through a single sample workflow. The real benefit would be post-workflow tasks that could be imported to further interrogate the array of single sample workflow outputs. I understand something similar could be achieved using a scatter block. Unfortunately, nested scatter blocks are not functional yet (see [#838](https://github.com/broadinstitute/cromwell/issues/838)). Additionally, a solution that integrates modular workflow definitions would be cleaner, more user friendly, maintainable etc. ```; call namespace.workflow {; input: foo=bar; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/839
https://github.com/broadinstitute/cromwell/pull/841:173,Deployability,update,update,173,"When the workflow-restart config option is set to false, incomplete workflows will not be restarted, and instead all incomplete workflows are aborted. . Note: Still need to update ReadMe. Questions: The sys.addShutdownHook takes about a minute to start startup (there's a minute long wait between the logs) which seems too long?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/841
https://github.com/broadinstitute/cromwell/pull/841:26,Modifiability,config,config,26,"When the workflow-restart config option is set to false, incomplete workflows will not be restarted, and instead all incomplete workflows are aborted. . Note: Still need to update ReadMe. Questions: The sys.addShutdownHook takes about a minute to start startup (there's a minute long wait between the logs) which seems too long?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/841
https://github.com/broadinstitute/cromwell/pull/841:142,Safety,abort,aborted,142,"When the workflow-restart config option is set to false, incomplete workflows will not be restarted, and instead all incomplete workflows are aborted. . Note: Still need to update ReadMe. Questions: The sys.addShutdownHook takes about a minute to start startup (there's a minute long wait between the logs) which seems too long?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/841
https://github.com/broadinstitute/cromwell/pull/841:301,Testability,log,logs,301,"When the workflow-restart config option is set to false, incomplete workflows will not be restarted, and instead all incomplete workflows are aborted. . Note: Still need to update ReadMe. Questions: The sys.addShutdownHook takes about a minute to start startup (there's a minute long wait between the logs) which seems too long?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/841
https://github.com/broadinstitute/cromwell/pull/842:151,Deployability,Update,Update,151,This is model after github's pagination https://developer.github.com/v3/#pagination and Link Header RFC https://tools.ietf.org/html/rfc5988#section-5. Update README.md and made review changes from https://github.com/broadinstitute/cromwell/pull/830,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/842
https://github.com/broadinstitute/cromwell/issues/843:266,Availability,down,down,266,"When running the workflow in #820 , the output arrays should each have 901 elements. It seems that randomly the array outputs for some of the shards have less than 901 elements even though the output glob buckets have 901 elements in them. This causes tasks further down in the workflow to fail. This is not repeatable in terms of the same shards running into the issue but at this scale it seems to affect at least one shard per workflow. 351dd737-fe83-4e86-bc5b-19d4c7d2fbf7 - gotc dev",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/843
https://github.com/broadinstitute/cromwell/issues/844:41892,Energy Efficiency,Schedul,ScheduledThreadPoolExecutor,41892,"kedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Hikari Housekeeping Timer (pool db)"" #24 daemon prio=5 os_prio=31 tid=0x00007fb76d88f000 nid=0x7503 waiting on condition [0x000000012cebb000]; java.lang.Thread.State: TIMED_WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0623fc0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.io.pinned-dispatcher-7"" #23 prio=5 os_prio=31 tid=0x00007fb76b450800 nid=0x7303 runnable [0x000000012cdb8000]; java.lang.Thread.State: RUNNABLE; at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method); at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198); at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:103); at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86); - locked <0x00000006c0612e70> (a sun.nio.ch.Util$2); - locked <0x00000006c0612e80> (a java.util.Collections$UnmodifiableSet",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:41942,Energy Efficiency,Schedul,ScheduledThreadPoolExecutor,41942,"eue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Hikari Housekeeping Timer (pool db)"" #24 daemon prio=5 os_prio=31 tid=0x00007fb76d88f000 nid=0x7503 waiting on condition [0x000000012cebb000]; java.lang.Thread.State: TIMED_WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0623fc0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.io.pinned-dispatcher-7"" #23 prio=5 os_prio=31 tid=0x00007fb76b450800 nid=0x7303 runnable [0x000000012cdb8000]; java.lang.Thread.State: RUNNABLE; at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method); at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198); at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:103); at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86); - locked <0x00000006c0612e70> (a sun.nio.ch.Util$2); - locked <0x00000006c0612e80> (a java.util.Collections$UnmodifiableSet); - locked <0x00000006c0612e20> (a sun",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:42006,Energy Efficiency,Schedul,ScheduledThreadPoolExecutor,42006,"ockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Hikari Housekeeping Timer (pool db)"" #24 daemon prio=5 os_prio=31 tid=0x00007fb76d88f000 nid=0x7503 waiting on condition [0x000000012cebb000]; java.lang.Thread.State: TIMED_WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0623fc0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.io.pinned-dispatcher-7"" #23 prio=5 os_prio=31 tid=0x00007fb76b450800 nid=0x7303 runnable [0x000000012cdb8000]; java.lang.Thread.State: RUNNABLE; at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method); at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198); at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:103); at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86); - locked <0x00000006c0612e70> (a sun.nio.ch.Util$2); - locked <0x00000006c0612e80> (a java.util.Collections$UnmodifiableSet); - locked <0x00000006c0612e20> (a sun.nio.ch.KQueueSelectorImpl); at sun.nio.ch.SelectorImpl.select(SelectorImpl",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:42056,Energy Efficiency,Schedul,ScheduledThreadPoolExecutor,42056,"ncurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Hikari Housekeeping Timer (pool db)"" #24 daemon prio=5 os_prio=31 tid=0x00007fb76d88f000 nid=0x7503 waiting on condition [0x000000012cebb000]; java.lang.Thread.State: TIMED_WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0623fc0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.io.pinned-dispatcher-7"" #23 prio=5 os_prio=31 tid=0x00007fb76b450800 nid=0x7303 runnable [0x000000012cdb8000]; java.lang.Thread.State: RUNNABLE; at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method); at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198); at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:103); at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86); - locked <0x00000006c0612e70> (a sun.nio.ch.Util$2); - locked <0x00000006c0612e80> (a java.util.Collections$UnmodifiableSet); - locked <0x00000006c0612e20> (a sun.nio.ch.KQueueSelectorImpl); at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97); at sun.nio.ch.SelectorImpl.s",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:43994,Energy Efficiency,monitor,monitor,43994,"un.nio.ch.SelectorImpl.select(SelectorImpl.java:97); at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101); at akka.io.SelectionHandler$ChannelRegistryImpl$$anon$3.tryRun(SelectionHandler.scala:114); at akka.io.SelectionHandler$ChannelRegistryImpl$Task.run(SelectionHandler.scala:215); at akka.io.SelectionHandler$ChannelRegistryImpl$$anon$3.run(SelectionHandler.scala:147); at akka.util.SerializedSuspendableExecutionContext.run$1(SerializedSuspendableExecutionContext.scala:64); at akka.util.SerializedSuspendableExecutionContext.run(SerializedSuspendableExecutionContext.scala); at akka.dispatch.TaskInvocation.run(Redefined); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Abandoned connection cleanup thread"" #22 daemon prio=5 os_prio=31 tid=0x00007fb76a4f5800 nid=0x7103 in Object.wait() [0x000000012ccb5000]; java.lang.Thread.State: TIMED_WAITING (on object monitor); at java.lang.Object.wait(Native Method); at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143); - locked <0x00000006c0624180> (a java.lang.ref.ReferenceQueue$Lock); at com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43). ""ForkJoinPool-3-worker-15"" #19 daemon prio=5 os_prio=31 tid=0x00007fb76abaa800 nid=0x6b03 waiting on condition [0x000000012a1e3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0060ab0> (a java.util.concurrent.CountDownLatch$Sync); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchro",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:46244,Energy Efficiency,Adapt,AdaptedForkJoinTask,46244,"onfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2$$anon$4.block(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinPool.managedBlock(Redefined); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2.blockOn(ExecutionContextImpl.scala:44); at scala.concurrent.Await$.ready(package.scala:169); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala:29); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:433); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala); at scala.concurrent.impl.CallbackRunnable.run(Redefined); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #14 prio=5 os_prio=31 tid=0x00007fb76aa14800 nid=0x6103 runnable [0x00000001295b3000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.actor.LightArrayRevolverScheduler.clock(Scheduler.scala:213); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Redefined); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Redefined); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.actor.default-dispatcher-4"" #13 prio=5 os_prio=31 tid=0x00007fb76b38c000 nid=",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:46610,Energy Efficiency,schedul,scheduler-,46610,"concurrent.Await$.ready(package.scala:169); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala:29); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:433); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala); at scala.concurrent.impl.CallbackRunnable.run(Redefined); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #14 prio=5 os_prio=31 tid=0x00007fb76aa14800 nid=0x6103 runnable [0x00000001295b3000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.actor.LightArrayRevolverScheduler.clock(Scheduler.scala:213); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Redefined); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Redefined); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.actor.default-dispatcher-4"" #13 prio=5 os_prio=31 tid=0x00007fb76b38c000 nid=0x5f03 waiting on condition [0x000000012ac3d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c002f9e0> (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(Redefined); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:46950,Energy Efficiency,Schedul,Scheduler,46950,"$anonfun$run$1.applyOrElse(CromwellServer.scala); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:433); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala); at scala.concurrent.impl.CallbackRunnable.run(Redefined); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #14 prio=5 os_prio=31 tid=0x00007fb76aa14800 nid=0x6103 runnable [0x00000001295b3000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.actor.LightArrayRevolverScheduler.clock(Scheduler.scala:213); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Redefined); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Redefined); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.actor.default-dispatcher-4"" #13 prio=5 os_prio=31 tid=0x00007fb76b38c000 nid=0x5f03 waiting on condition [0x000000012ac3d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c002f9e0> (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(Redefined); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #10 prio=5 os_prio=31 tid=0x00007fb76b20f000 nid=0x5a07 runnable [0x000000012a0e1000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.Instrume",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:47707,Energy Efficiency,schedul,scheduler-,47707,".jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.actor.LightArrayRevolverScheduler.clock(Scheduler.scala:213); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Redefined); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Redefined); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.actor.default-dispatcher-4"" #13 prio=5 os_prio=31 tid=0x00007fb76b38c000 nid=0x5f03 waiting on condition [0x000000012ac3d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c002f9e0> (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(Redefined); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #10 prio=5 os_prio=31 tid=0x00007fb76b20f000 nid=0x5a07 runnable [0x000000012a0e1000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.dispatch.AbstractNodeQueue$Node.next(AbstractNodeQueue.java:124); at akka.dispatch.AbstractNodeQueue.pollNode(AbstractNodeQueue.java:86); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:411); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Redefined); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Redefined); at java.lang.Thread.run(Redefined). ""Service Thread"" #9 daemon prio=9 os_prio=31 tid=0x00007fb76a82e000 nid=0x5103 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""C1 CompilerThread3"" #8 daemon prio=9 os_prio=31 tid=0x00007fb76a060000 nid=0x4f03 waiting on condition [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""C2 CompilerThread2"" #7 daemon prio=9 os_",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:48211,Energy Efficiency,Schedul,Scheduler,48211,"_prio=31 tid=0x00007fb76b38c000 nid=0x5f03 waiting on condition [0x000000012ac3d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c002f9e0> (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(Redefined); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #10 prio=5 os_prio=31 tid=0x00007fb76b20f000 nid=0x5a07 runnable [0x000000012a0e1000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.dispatch.AbstractNodeQueue$Node.next(AbstractNodeQueue.java:124); at akka.dispatch.AbstractNodeQueue.pollNode(AbstractNodeQueue.java:86); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:411); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Redefined); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Redefined); at java.lang.Thread.run(Redefined). ""Service Thread"" #9 daemon prio=9 os_prio=31 tid=0x00007fb76a82e000 nid=0x5103 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""C1 CompilerThread3"" #8 daemon prio=9 os_prio=31 tid=0x00007fb76a060000 nid=0x4f03 waiting on condition [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""C2 CompilerThread2"" #7 daemon prio=9 os_prio=31 tid=0x00007fb76b011000 nid=0x4d03 waiting on condition [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""C2 CompilerThread1"" #6 daemon prio=9 os_prio=31 tid=0x00007fb76a815000 nid=0x4b03 waiting on condition [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""C2 CompilerThread0"" #5 daemon prio=9 os_prio=31 tid=0x00007fb76b810000 nid=0x4903 waiting on condition [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""Signal Dispatcher",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:49505,Energy Efficiency,monitor,monitor,49505,"000000000000]; java.lang.Thread.State: RUNNABLE. ""C1 CompilerThread3"" #8 daemon prio=9 os_prio=31 tid=0x00007fb76a060000 nid=0x4f03 waiting on condition [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""C2 CompilerThread2"" #7 daemon prio=9 os_prio=31 tid=0x00007fb76b011000 nid=0x4d03 waiting on condition [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""C2 CompilerThread1"" #6 daemon prio=9 os_prio=31 tid=0x00007fb76a815000 nid=0x4b03 waiting on condition [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""C2 CompilerThread0"" #5 daemon prio=9 os_prio=31 tid=0x00007fb76b810000 nid=0x4903 waiting on condition [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""Signal Dispatcher"" #4 daemon prio=9 os_prio=31 tid=0x00007fb76b80c000 nid=0x3d0b waiting on condition [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""Finalizer"" #3 daemon prio=8 os_prio=31 tid=0x00007fb76a05e000 nid=0x3503 in Object.wait() [0x0000000126bc7000]; java.lang.Thread.State: WAITING (on object monitor); at java.lang.Object.wait(Native Method); at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143); - locked <0x00000006c00371c0> (a java.lang.ref.ReferenceQueue$Lock); at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164); at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209). ""Reference Handler"" #2 daemon prio=10 os_prio=31 tid=0x00007fb76b005800 nid=0x3303 in Object.wait() [0x0000000126ac4000]; java.lang.Thread.State: WAITING (on object monitor); at java.lang.Object.wait(Native Method); at java.lang.Object.wait(Object.java:502); at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:157); - locked <0x00000006c00301d8> (a java.lang.ref.Reference$Lock). ""main"" #1 prio=5 os_prio=31 tid=0x00007fb76a803000 nid=0xf07 waiting on condition [0x000000010b088000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c061d308> (a scala.concurrent.impl.Promise$CompletionLatch); at ja",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:49988,Energy Efficiency,monitor,monitor,49988,"000000000]; java.lang.Thread.State: RUNNABLE. ""C2 CompilerThread0"" #5 daemon prio=9 os_prio=31 tid=0x00007fb76b810000 nid=0x4903 waiting on condition [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""Signal Dispatcher"" #4 daemon prio=9 os_prio=31 tid=0x00007fb76b80c000 nid=0x3d0b waiting on condition [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""Finalizer"" #3 daemon prio=8 os_prio=31 tid=0x00007fb76a05e000 nid=0x3503 in Object.wait() [0x0000000126bc7000]; java.lang.Thread.State: WAITING (on object monitor); at java.lang.Object.wait(Native Method); at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143); - locked <0x00000006c00371c0> (a java.lang.ref.ReferenceQueue$Lock); at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164); at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209). ""Reference Handler"" #2 daemon prio=10 os_prio=31 tid=0x00007fb76b005800 nid=0x3303 in Object.wait() [0x0000000126ac4000]; java.lang.Thread.State: WAITING (on object monitor); at java.lang.Object.wait(Native Method); at java.lang.Object.wait(Object.java:502); at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:157); - locked <0x00000006c00301d8> (a java.lang.ref.Reference$Lock). ""main"" #1 prio=5 os_prio=31 tid=0x00007fb76a803000 nid=0xf07 waiting on condition [0x000000010b088000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c061d308> (a scala.concurrent.impl.Promise$CompletionLatch); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:46244,Modifiability,Adapt,AdaptedForkJoinTask,46244,"onfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2$$anon$4.block(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinPool.managedBlock(Redefined); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2.blockOn(ExecutionContextImpl.scala:44); at scala.concurrent.Await$.ready(package.scala:169); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala:29); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:433); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala); at scala.concurrent.impl.CallbackRunnable.run(Redefined); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #14 prio=5 os_prio=31 tid=0x00007fb76aa14800 nid=0x6103 runnable [0x00000001295b3000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.actor.LightArrayRevolverScheduler.clock(Scheduler.scala:213); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Redefined); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Redefined); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.actor.default-dispatcher-4"" #13 prio=5 os_prio=31 tid=0x00007fb76b38c000 nid=",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:598,Performance,concurren,concurrent,598,"A bunch of jobs were finished which Cromwell didn't detect. The context: ; - Trying to run jprofiler to get a profile of the run described in #820. Full stack dump:. ```; Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode):. ""cromwell-system-akka.actor.default-dispatcher-27"" #115 prio=5 os_prio=31 tid=0x00007fb76d052800 nid=0xf503 waiting on condition [0x0000000135d74000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0021d00> (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""ForkJoinPool-3-worker-5"" #82 daemon prio=5 os_prio=31 tid=0x00007fb76cc73800 nid=0xcd03 waiting on condition [0x0000000134661000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0041f30> (a scala.concurrent.forkjoin.ForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""pool-1-thread-20"" #81 prio=5 os_prio=31 tid=0x00007fb76cc5b800 nid=0xcb03 waiting on condition [0x000000013455e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(Th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:670,Performance,concurren,concurrent,670,"A bunch of jobs were finished which Cromwell didn't detect. The context: ; - Trying to run jprofiler to get a profile of the run described in #820. Full stack dump:. ```; Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode):. ""cromwell-system-akka.actor.default-dispatcher-27"" #115 prio=5 os_prio=31 tid=0x00007fb76d052800 nid=0xf503 waiting on condition [0x0000000135d74000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0021d00> (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""ForkJoinPool-3-worker-5"" #82 daemon prio=5 os_prio=31 tid=0x00007fb76cc73800 nid=0xcd03 waiting on condition [0x0000000134661000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0041f30> (a scala.concurrent.forkjoin.ForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""pool-1-thread-20"" #81 prio=5 os_prio=31 tid=0x00007fb76cc5b800 nid=0xcb03 waiting on condition [0x000000013455e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(Th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:747,Performance,concurren,concurrent,747,"A bunch of jobs were finished which Cromwell didn't detect. The context: ; - Trying to run jprofiler to get a profile of the run described in #820. Full stack dump:. ```; Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode):. ""cromwell-system-akka.actor.default-dispatcher-27"" #115 prio=5 os_prio=31 tid=0x00007fb76d052800 nid=0xf503 waiting on condition [0x0000000135d74000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0021d00> (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""ForkJoinPool-3-worker-5"" #82 daemon prio=5 os_prio=31 tid=0x00007fb76cc73800 nid=0xcd03 waiting on condition [0x0000000134661000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0041f30> (a scala.concurrent.forkjoin.ForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""pool-1-thread-20"" #81 prio=5 os_prio=31 tid=0x00007fb76cc5b800 nid=0xcb03 waiting on condition [0x000000013455e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(Th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:1091,Performance,concurren,concurrent,1091,"iler to get a profile of the run described in #820. Full stack dump:. ```; Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode):. ""cromwell-system-akka.actor.default-dispatcher-27"" #115 prio=5 os_prio=31 tid=0x00007fb76d052800 nid=0xf503 waiting on condition [0x0000000135d74000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0021d00> (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""ForkJoinPool-3-worker-5"" #82 daemon prio=5 os_prio=31 tid=0x00007fb76cc73800 nid=0xcd03 waiting on condition [0x0000000134661000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0041f30> (a scala.concurrent.forkjoin.ForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""pool-1-thread-20"" #81 prio=5 os_prio=31 tid=0x00007fb76cc5b800 nid=0xcb03 waiting on condition [0x000000013455e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExec",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:1135,Performance,concurren,concurrent,1135,"n #820. Full stack dump:. ```; Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode):. ""cromwell-system-akka.actor.default-dispatcher-27"" #115 prio=5 os_prio=31 tid=0x00007fb76d052800 nid=0xf503 waiting on condition [0x0000000135d74000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0021d00> (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""ForkJoinPool-3-worker-5"" #82 daemon prio=5 os_prio=31 tid=0x00007fb76cc73800 nid=0xcd03 waiting on condition [0x0000000134661000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0041f30> (a scala.concurrent.forkjoin.ForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""pool-1-thread-20"" #81 prio=5 os_prio=31 tid=0x00007fb76cc5b800 nid=0xcb03 waiting on condition [0x000000013455e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.Thr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:1207,Performance,concurren,concurrent,1207,"Server VM (25.60-b23 mixed mode):. ""cromwell-system-akka.actor.default-dispatcher-27"" #115 prio=5 os_prio=31 tid=0x00007fb76d052800 nid=0xf503 waiting on condition [0x0000000135d74000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0021d00> (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""ForkJoinPool-3-worker-5"" #82 daemon prio=5 os_prio=31 tid=0x00007fb76cc73800 nid=0xcd03 waiting on condition [0x0000000134661000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0041f30> (a scala.concurrent.forkjoin.ForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""pool-1-thread-20"" #81 prio=5 os_prio=31 tid=0x00007fb76cc5b800 nid=0xcb03 waiting on condition [0x000000013455e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:1284,Performance,concurren,concurrent,1284,"cher-27"" #115 prio=5 os_prio=31 tid=0x00007fb76d052800 nid=0xf503 waiting on condition [0x0000000135d74000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0021d00> (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""ForkJoinPool-3-worker-5"" #82 daemon prio=5 os_prio=31 tid=0x00007fb76cc73800 nid=0xcd03 waiting on condition [0x0000000134661000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0041f30> (a scala.concurrent.forkjoin.ForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""pool-1-thread-20"" #81 prio=5 os_prio=31 tid=0x00007fb76cc5b800 nid=0xcb03 waiting on condition [0x000000013455e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-19"" #80 prio=5 os_prio=31 tid=0x000",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:1618,Performance,concurren,concurrent,1618,"oinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""ForkJoinPool-3-worker-5"" #82 daemon prio=5 os_prio=31 tid=0x00007fb76cc73800 nid=0xcd03 waiting on condition [0x0000000134661000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0041f30> (a scala.concurrent.forkjoin.ForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""pool-1-thread-20"" #81 prio=5 os_prio=31 tid=0x00007fb76cc5b800 nid=0xcb03 waiting on condition [0x000000013455e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-19"" #80 prio=5 os_prio=31 tid=0x00007fb76cc59800 nid=0xc903 waiting on condition [0x0000000134093000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:1693,Performance,concurren,concurrent,1693,"Pool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""ForkJoinPool-3-worker-5"" #82 daemon prio=5 os_prio=31 tid=0x00007fb76cc73800 nid=0xcd03 waiting on condition [0x0000000134661000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0041f30> (a scala.concurrent.forkjoin.ForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""pool-1-thread-20"" #81 prio=5 os_prio=31 tid=0x00007fb76cc5b800 nid=0xcb03 waiting on condition [0x000000013455e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-19"" #80 prio=5 os_prio=31 tid=0x00007fb76cc59800 nid=0xc903 waiting on condition [0x0000000134093000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObje",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:1763,Performance,concurren,concurrent,1763,"orkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""ForkJoinPool-3-worker-5"" #82 daemon prio=5 os_prio=31 tid=0x00007fb76cc73800 nid=0xcd03 waiting on condition [0x0000000134661000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0041f30> (a scala.concurrent.forkjoin.ForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""pool-1-thread-20"" #81 prio=5 os_prio=31 tid=0x00007fb76cc5b800 nid=0xcb03 waiting on condition [0x000000013455e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-19"" #80 prio=5 os_prio=31 tid=0x00007fb76cc59800 nid=0xc903 waiting on condition [0x0000000134093000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurren",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:1881,Performance,concurren,concurrent,1881,"0007fb76cc73800 nid=0xcd03 waiting on condition [0x0000000134661000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0041f30> (a scala.concurrent.forkjoin.ForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""pool-1-thread-20"" #81 prio=5 os_prio=31 tid=0x00007fb76cc5b800 nid=0xcb03 waiting on condition [0x000000013455e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-19"" #80 prio=5 os_prio=31 tid=0x00007fb76cc59800 nid=0xc903 waiting on condition [0x0000000134093000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:1961,Performance,concurren,concurrent,1961,"Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0041f30> (a scala.concurrent.forkjoin.ForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""pool-1-thread-20"" #81 prio=5 os_prio=31 tid=0x00007fb76cc5b800 nid=0xcb03 waiting on condition [0x000000013455e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-19"" #80 prio=5 os_prio=31 tid=0x00007fb76cc59800 nid=0xc903 waiting on condition [0x0000000134093000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Threa",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:2043,Performance,concurren,concurrent,2043," to wait for <0x00000006c0041f30> (a scala.concurrent.forkjoin.ForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""pool-1-thread-20"" #81 prio=5 os_prio=31 tid=0x00007fb76cc5b800 nid=0xcb03 waiting on condition [0x000000013455e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-19"" #80 prio=5 os_prio=31 tid=0x00007fb76cc59800 nid=0xc903 waiting on condition [0x0000000134093000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(Th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:2127,Performance,concurren,concurrent,2127,"la.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""pool-1-thread-20"" #81 prio=5 os_prio=31 tid=0x00007fb76cc5b800 nid=0xcb03 waiting on condition [0x000000013455e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-19"" #80 prio=5 os_prio=31 tid=0x00007fb76cc59800 nid=0xc903 waiting on condition [0x0000000134093000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:2497,Performance,concurren,concurrent,2497," WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-19"" #80 prio=5 os_prio=31 tid=0x00007fb76cc59800 nid=0xc903 waiting on condition [0x0000000134093000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-18"" #79 prio=5 os_prio=31 tid=0x00007fb76d1d1000 nid=0xc703 waiting on condition [0x0000000133f90000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:2572,Performance,concurren,concurrent,2572,"it for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-19"" #80 prio=5 os_prio=31 tid=0x00007fb76cc59800 nid=0xc903 waiting on condition [0x0000000134093000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-18"" #79 prio=5 os_prio=31 tid=0x00007fb76d1d1000 nid=0xc703 waiting on condition [0x0000000133f90000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObje",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:2642,Performance,concurren,concurrent,2642,"edSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-19"" #80 prio=5 os_prio=31 tid=0x00007fb76cc59800 nid=0xc903 waiting on condition [0x0000000134093000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-18"" #79 prio=5 os_prio=31 tid=0x00007fb76d1d1000 nid=0xc703 waiting on condition [0x0000000133f90000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurren",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:2760,Performance,concurren,concurrent,2760,"ncurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-19"" #80 prio=5 os_prio=31 tid=0x00007fb76cc59800 nid=0xc903 waiting on condition [0x0000000134093000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-18"" #79 prio=5 os_prio=31 tid=0x00007fb76d1d1000 nid=0xc703 waiting on condition [0x0000000133f90000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:2840,Performance,concurren,concurrent,2840,"nchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-19"" #80 prio=5 os_prio=31 tid=0x00007fb76cc59800 nid=0xc903 waiting on condition [0x0000000134093000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-18"" #79 prio=5 os_prio=31 tid=0x00007fb76d1d1000 nid=0xc703 waiting on condition [0x0000000133f90000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Threa",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:2922,Performance,concurren,concurrent,2922,"kingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-19"" #80 prio=5 os_prio=31 tid=0x00007fb76cc59800 nid=0xc903 waiting on condition [0x0000000134093000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-18"" #79 prio=5 os_prio=31 tid=0x00007fb76d1d1000 nid=0xc703 waiting on condition [0x0000000133f90000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(Th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:3006,Performance,concurren,concurrent,3006,"ecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-19"" #80 prio=5 os_prio=31 tid=0x00007fb76cc59800 nid=0xc903 waiting on condition [0x0000000134093000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-18"" #79 prio=5 os_prio=31 tid=0x00007fb76d1d1000 nid=0xc703 waiting on condition [0x0000000133f90000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:3376,Performance,concurren,concurrent,3376," WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-18"" #79 prio=5 os_prio=31 tid=0x00007fb76d1d1000 nid=0xc703 waiting on condition [0x0000000133f90000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-17"" #78 prio=5 os_prio=31 tid=0x00007fb76de1b800 nid=0xc503 waiting on condition [0x0000000133df7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:3451,Performance,concurren,concurrent,3451,"it for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-18"" #79 prio=5 os_prio=31 tid=0x00007fb76d1d1000 nid=0xc703 waiting on condition [0x0000000133f90000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-17"" #78 prio=5 os_prio=31 tid=0x00007fb76de1b800 nid=0xc503 waiting on condition [0x0000000133df7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObje",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:3521,Performance,concurren,concurrent,3521,"edSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-18"" #79 prio=5 os_prio=31 tid=0x00007fb76d1d1000 nid=0xc703 waiting on condition [0x0000000133f90000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-17"" #78 prio=5 os_prio=31 tid=0x00007fb76de1b800 nid=0xc503 waiting on condition [0x0000000133df7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurren",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:3639,Performance,concurren,concurrent,3639,"ncurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-18"" #79 prio=5 os_prio=31 tid=0x00007fb76d1d1000 nid=0xc703 waiting on condition [0x0000000133f90000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-17"" #78 prio=5 os_prio=31 tid=0x00007fb76de1b800 nid=0xc503 waiting on condition [0x0000000133df7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:3719,Performance,concurren,concurrent,3719,"nchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-18"" #79 prio=5 os_prio=31 tid=0x00007fb76d1d1000 nid=0xc703 waiting on condition [0x0000000133f90000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-17"" #78 prio=5 os_prio=31 tid=0x00007fb76de1b800 nid=0xc503 waiting on condition [0x0000000133df7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Threa",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:3801,Performance,concurren,concurrent,3801,"kingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-18"" #79 prio=5 os_prio=31 tid=0x00007fb76d1d1000 nid=0xc703 waiting on condition [0x0000000133f90000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-17"" #78 prio=5 os_prio=31 tid=0x00007fb76de1b800 nid=0xc503 waiting on condition [0x0000000133df7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(Th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:3885,Performance,concurren,concurrent,3885,"ecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-18"" #79 prio=5 os_prio=31 tid=0x00007fb76d1d1000 nid=0xc703 waiting on condition [0x0000000133f90000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-17"" #78 prio=5 os_prio=31 tid=0x00007fb76de1b800 nid=0xc503 waiting on condition [0x0000000133df7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:4255,Performance,concurren,concurrent,4255," WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-17"" #78 prio=5 os_prio=31 tid=0x00007fb76de1b800 nid=0xc503 waiting on condition [0x0000000133df7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-16"" #77 prio=5 os_prio=31 tid=0x00007fb76a6e9800 nid=0xc303 waiting on condition [0x000000013399d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:4330,Performance,concurren,concurrent,4330,"it for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-17"" #78 prio=5 os_prio=31 tid=0x00007fb76de1b800 nid=0xc503 waiting on condition [0x0000000133df7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-16"" #77 prio=5 os_prio=31 tid=0x00007fb76a6e9800 nid=0xc303 waiting on condition [0x000000013399d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObje",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:4400,Performance,concurren,concurrent,4400,"edSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-17"" #78 prio=5 os_prio=31 tid=0x00007fb76de1b800 nid=0xc503 waiting on condition [0x0000000133df7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-16"" #77 prio=5 os_prio=31 tid=0x00007fb76a6e9800 nid=0xc303 waiting on condition [0x000000013399d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurren",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:4518,Performance,concurren,concurrent,4518,"ncurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-17"" #78 prio=5 os_prio=31 tid=0x00007fb76de1b800 nid=0xc503 waiting on condition [0x0000000133df7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-16"" #77 prio=5 os_prio=31 tid=0x00007fb76a6e9800 nid=0xc303 waiting on condition [0x000000013399d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:4598,Performance,concurren,concurrent,4598,"nchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-17"" #78 prio=5 os_prio=31 tid=0x00007fb76de1b800 nid=0xc503 waiting on condition [0x0000000133df7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-16"" #77 prio=5 os_prio=31 tid=0x00007fb76a6e9800 nid=0xc303 waiting on condition [0x000000013399d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Threa",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:4680,Performance,concurren,concurrent,4680,"kingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-17"" #78 prio=5 os_prio=31 tid=0x00007fb76de1b800 nid=0xc503 waiting on condition [0x0000000133df7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-16"" #77 prio=5 os_prio=31 tid=0x00007fb76a6e9800 nid=0xc303 waiting on condition [0x000000013399d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(Th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:4764,Performance,concurren,concurrent,4764,"ecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-17"" #78 prio=5 os_prio=31 tid=0x00007fb76de1b800 nid=0xc503 waiting on condition [0x0000000133df7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-16"" #77 prio=5 os_prio=31 tid=0x00007fb76a6e9800 nid=0xc303 waiting on condition [0x000000013399d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:5134,Performance,concurren,concurrent,5134," WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-16"" #77 prio=5 os_prio=31 tid=0x00007fb76a6e9800 nid=0xc303 waiting on condition [0x000000013399d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-15"" #75 prio=5 os_prio=31 tid=0x00007fb76e11d000 nid=0xbf03 waiting on condition [0x0000000133797000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:5209,Performance,concurren,concurrent,5209,"it for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-16"" #77 prio=5 os_prio=31 tid=0x00007fb76a6e9800 nid=0xc303 waiting on condition [0x000000013399d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-15"" #75 prio=5 os_prio=31 tid=0x00007fb76e11d000 nid=0xbf03 waiting on condition [0x0000000133797000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObje",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:5279,Performance,concurren,concurrent,5279,"edSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-16"" #77 prio=5 os_prio=31 tid=0x00007fb76a6e9800 nid=0xc303 waiting on condition [0x000000013399d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-15"" #75 prio=5 os_prio=31 tid=0x00007fb76e11d000 nid=0xbf03 waiting on condition [0x0000000133797000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurren",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:5397,Performance,concurren,concurrent,5397,"ncurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-16"" #77 prio=5 os_prio=31 tid=0x00007fb76a6e9800 nid=0xc303 waiting on condition [0x000000013399d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-15"" #75 prio=5 os_prio=31 tid=0x00007fb76e11d000 nid=0xbf03 waiting on condition [0x0000000133797000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:5477,Performance,concurren,concurrent,5477,"nchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-16"" #77 prio=5 os_prio=31 tid=0x00007fb76a6e9800 nid=0xc303 waiting on condition [0x000000013399d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-15"" #75 prio=5 os_prio=31 tid=0x00007fb76e11d000 nid=0xbf03 waiting on condition [0x0000000133797000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Threa",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:5559,Performance,concurren,concurrent,5559,"kingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-16"" #77 prio=5 os_prio=31 tid=0x00007fb76a6e9800 nid=0xc303 waiting on condition [0x000000013399d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-15"" #75 prio=5 os_prio=31 tid=0x00007fb76e11d000 nid=0xbf03 waiting on condition [0x0000000133797000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(Th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:5643,Performance,concurren,concurrent,5643,"ecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-16"" #77 prio=5 os_prio=31 tid=0x00007fb76a6e9800 nid=0xc303 waiting on condition [0x000000013399d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-15"" #75 prio=5 os_prio=31 tid=0x00007fb76e11d000 nid=0xbf03 waiting on condition [0x0000000133797000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:6013,Performance,concurren,concurrent,6013," WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-15"" #75 prio=5 os_prio=31 tid=0x00007fb76e11d000 nid=0xbf03 waiting on condition [0x0000000133797000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-14"" #74 prio=5 os_prio=31 tid=0x00007fb76dd8e800 nid=0xbd03 waiting on condition [0x0000000133694000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:6088,Performance,concurren,concurrent,6088,"it for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-15"" #75 prio=5 os_prio=31 tid=0x00007fb76e11d000 nid=0xbf03 waiting on condition [0x0000000133797000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-14"" #74 prio=5 os_prio=31 tid=0x00007fb76dd8e800 nid=0xbd03 waiting on condition [0x0000000133694000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObje",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:6158,Performance,concurren,concurrent,6158,"edSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-15"" #75 prio=5 os_prio=31 tid=0x00007fb76e11d000 nid=0xbf03 waiting on condition [0x0000000133797000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-14"" #74 prio=5 os_prio=31 tid=0x00007fb76dd8e800 nid=0xbd03 waiting on condition [0x0000000133694000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurren",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:6276,Performance,concurren,concurrent,6276,"ncurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-15"" #75 prio=5 os_prio=31 tid=0x00007fb76e11d000 nid=0xbf03 waiting on condition [0x0000000133797000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-14"" #74 prio=5 os_prio=31 tid=0x00007fb76dd8e800 nid=0xbd03 waiting on condition [0x0000000133694000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:6356,Performance,concurren,concurrent,6356,"nchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-15"" #75 prio=5 os_prio=31 tid=0x00007fb76e11d000 nid=0xbf03 waiting on condition [0x0000000133797000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-14"" #74 prio=5 os_prio=31 tid=0x00007fb76dd8e800 nid=0xbd03 waiting on condition [0x0000000133694000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Threa",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:6438,Performance,concurren,concurrent,6438,"kingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-15"" #75 prio=5 os_prio=31 tid=0x00007fb76e11d000 nid=0xbf03 waiting on condition [0x0000000133797000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-14"" #74 prio=5 os_prio=31 tid=0x00007fb76dd8e800 nid=0xbd03 waiting on condition [0x0000000133694000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(Th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:6522,Performance,concurren,concurrent,6522,"ecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-15"" #75 prio=5 os_prio=31 tid=0x00007fb76e11d000 nid=0xbf03 waiting on condition [0x0000000133797000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-14"" #74 prio=5 os_prio=31 tid=0x00007fb76dd8e800 nid=0xbd03 waiting on condition [0x0000000133694000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:6892,Performance,concurren,concurrent,6892," WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-14"" #74 prio=5 os_prio=31 tid=0x00007fb76dd8e800 nid=0xbd03 waiting on condition [0x0000000133694000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-13"" #73 prio=5 os_prio=31 tid=0x00007fb76a458800 nid=0xbb03 waiting on condition [0x0000000133591000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:6967,Performance,concurren,concurrent,6967,"it for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-14"" #74 prio=5 os_prio=31 tid=0x00007fb76dd8e800 nid=0xbd03 waiting on condition [0x0000000133694000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-13"" #73 prio=5 os_prio=31 tid=0x00007fb76a458800 nid=0xbb03 waiting on condition [0x0000000133591000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObje",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:7037,Performance,concurren,concurrent,7037,"edSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-14"" #74 prio=5 os_prio=31 tid=0x00007fb76dd8e800 nid=0xbd03 waiting on condition [0x0000000133694000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-13"" #73 prio=5 os_prio=31 tid=0x00007fb76a458800 nid=0xbb03 waiting on condition [0x0000000133591000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurren",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:7155,Performance,concurren,concurrent,7155,"ncurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-14"" #74 prio=5 os_prio=31 tid=0x00007fb76dd8e800 nid=0xbd03 waiting on condition [0x0000000133694000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-13"" #73 prio=5 os_prio=31 tid=0x00007fb76a458800 nid=0xbb03 waiting on condition [0x0000000133591000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:7235,Performance,concurren,concurrent,7235,"nchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-14"" #74 prio=5 os_prio=31 tid=0x00007fb76dd8e800 nid=0xbd03 waiting on condition [0x0000000133694000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-13"" #73 prio=5 os_prio=31 tid=0x00007fb76a458800 nid=0xbb03 waiting on condition [0x0000000133591000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Threa",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:7317,Performance,concurren,concurrent,7317,"kingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-14"" #74 prio=5 os_prio=31 tid=0x00007fb76dd8e800 nid=0xbd03 waiting on condition [0x0000000133694000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-13"" #73 prio=5 os_prio=31 tid=0x00007fb76a458800 nid=0xbb03 waiting on condition [0x0000000133591000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(Th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:7401,Performance,concurren,concurrent,7401,"ecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-14"" #74 prio=5 os_prio=31 tid=0x00007fb76dd8e800 nid=0xbd03 waiting on condition [0x0000000133694000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-13"" #73 prio=5 os_prio=31 tid=0x00007fb76a458800 nid=0xbb03 waiting on condition [0x0000000133591000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:7771,Performance,concurren,concurrent,7771," WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-13"" #73 prio=5 os_prio=31 tid=0x00007fb76a458800 nid=0xbb03 waiting on condition [0x0000000133591000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-12"" #72 prio=5 os_prio=31 tid=0x00007fb76f1b0800 nid=0xb903 waiting on condition [0x00000001332cc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:7846,Performance,concurren,concurrent,7846,"it for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-13"" #73 prio=5 os_prio=31 tid=0x00007fb76a458800 nid=0xbb03 waiting on condition [0x0000000133591000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-12"" #72 prio=5 os_prio=31 tid=0x00007fb76f1b0800 nid=0xb903 waiting on condition [0x00000001332cc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObje",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:7916,Performance,concurren,concurrent,7916,"edSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-13"" #73 prio=5 os_prio=31 tid=0x00007fb76a458800 nid=0xbb03 waiting on condition [0x0000000133591000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-12"" #72 prio=5 os_prio=31 tid=0x00007fb76f1b0800 nid=0xb903 waiting on condition [0x00000001332cc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurren",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:8034,Performance,concurren,concurrent,8034,"ncurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-13"" #73 prio=5 os_prio=31 tid=0x00007fb76a458800 nid=0xbb03 waiting on condition [0x0000000133591000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-12"" #72 prio=5 os_prio=31 tid=0x00007fb76f1b0800 nid=0xb903 waiting on condition [0x00000001332cc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:8114,Performance,concurren,concurrent,8114,"nchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-13"" #73 prio=5 os_prio=31 tid=0x00007fb76a458800 nid=0xbb03 waiting on condition [0x0000000133591000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-12"" #72 prio=5 os_prio=31 tid=0x00007fb76f1b0800 nid=0xb903 waiting on condition [0x00000001332cc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Threa",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:8196,Performance,concurren,concurrent,8196,"kingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-13"" #73 prio=5 os_prio=31 tid=0x00007fb76a458800 nid=0xbb03 waiting on condition [0x0000000133591000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-12"" #72 prio=5 os_prio=31 tid=0x00007fb76f1b0800 nid=0xb903 waiting on condition [0x00000001332cc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(Th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:8280,Performance,concurren,concurrent,8280,"ecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-13"" #73 prio=5 os_prio=31 tid=0x00007fb76a458800 nid=0xbb03 waiting on condition [0x0000000133591000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-12"" #72 prio=5 os_prio=31 tid=0x00007fb76f1b0800 nid=0xb903 waiting on condition [0x00000001332cc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:8650,Performance,concurren,concurrent,8650," WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-12"" #72 prio=5 os_prio=31 tid=0x00007fb76f1b0800 nid=0xb903 waiting on condition [0x00000001332cc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-11"" #71 prio=5 os_prio=31 tid=0x00007fb76b05a800 nid=0xb703 waiting on condition [0x00000001331c9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:8725,Performance,concurren,concurrent,8725,"it for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-12"" #72 prio=5 os_prio=31 tid=0x00007fb76f1b0800 nid=0xb903 waiting on condition [0x00000001332cc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-11"" #71 prio=5 os_prio=31 tid=0x00007fb76b05a800 nid=0xb703 waiting on condition [0x00000001331c9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObje",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:8795,Performance,concurren,concurrent,8795,"edSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-12"" #72 prio=5 os_prio=31 tid=0x00007fb76f1b0800 nid=0xb903 waiting on condition [0x00000001332cc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-11"" #71 prio=5 os_prio=31 tid=0x00007fb76b05a800 nid=0xb703 waiting on condition [0x00000001331c9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurren",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:8913,Performance,concurren,concurrent,8913,"ncurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-12"" #72 prio=5 os_prio=31 tid=0x00007fb76f1b0800 nid=0xb903 waiting on condition [0x00000001332cc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-11"" #71 prio=5 os_prio=31 tid=0x00007fb76b05a800 nid=0xb703 waiting on condition [0x00000001331c9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:8993,Performance,concurren,concurrent,8993,"nchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-12"" #72 prio=5 os_prio=31 tid=0x00007fb76f1b0800 nid=0xb903 waiting on condition [0x00000001332cc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-11"" #71 prio=5 os_prio=31 tid=0x00007fb76b05a800 nid=0xb703 waiting on condition [0x00000001331c9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Threa",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:9075,Performance,concurren,concurrent,9075,"kingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-12"" #72 prio=5 os_prio=31 tid=0x00007fb76f1b0800 nid=0xb903 waiting on condition [0x00000001332cc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-11"" #71 prio=5 os_prio=31 tid=0x00007fb76b05a800 nid=0xb703 waiting on condition [0x00000001331c9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(Th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:9159,Performance,concurren,concurrent,9159,"ecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-12"" #72 prio=5 os_prio=31 tid=0x00007fb76f1b0800 nid=0xb903 waiting on condition [0x00000001332cc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-11"" #71 prio=5 os_prio=31 tid=0x00007fb76b05a800 nid=0xb703 waiting on condition [0x00000001331c9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:9529,Performance,concurren,concurrent,9529," WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-11"" #71 prio=5 os_prio=31 tid=0x00007fb76b05a800 nid=0xb703 waiting on condition [0x00000001331c9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-10"" #70 prio=5 os_prio=31 tid=0x00007fb76bac5800 nid=0xb503 waiting on condition [0x0000000132fa6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:9604,Performance,concurren,concurrent,9604,"it for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-11"" #71 prio=5 os_prio=31 tid=0x00007fb76b05a800 nid=0xb703 waiting on condition [0x00000001331c9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-10"" #70 prio=5 os_prio=31 tid=0x00007fb76bac5800 nid=0xb503 waiting on condition [0x0000000132fa6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObje",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:9674,Performance,concurren,concurrent,9674,"edSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-11"" #71 prio=5 os_prio=31 tid=0x00007fb76b05a800 nid=0xb703 waiting on condition [0x00000001331c9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-10"" #70 prio=5 os_prio=31 tid=0x00007fb76bac5800 nid=0xb503 waiting on condition [0x0000000132fa6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurren",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:9792,Performance,concurren,concurrent,9792,"ncurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-11"" #71 prio=5 os_prio=31 tid=0x00007fb76b05a800 nid=0xb703 waiting on condition [0x00000001331c9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-10"" #70 prio=5 os_prio=31 tid=0x00007fb76bac5800 nid=0xb503 waiting on condition [0x0000000132fa6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:9872,Performance,concurren,concurrent,9872,"nchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-11"" #71 prio=5 os_prio=31 tid=0x00007fb76b05a800 nid=0xb703 waiting on condition [0x00000001331c9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-10"" #70 prio=5 os_prio=31 tid=0x00007fb76bac5800 nid=0xb503 waiting on condition [0x0000000132fa6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Threa",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:9954,Performance,concurren,concurrent,9954,"kingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-11"" #71 prio=5 os_prio=31 tid=0x00007fb76b05a800 nid=0xb703 waiting on condition [0x00000001331c9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-10"" #70 prio=5 os_prio=31 tid=0x00007fb76bac5800 nid=0xb503 waiting on condition [0x0000000132fa6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(Th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:10038,Performance,concurren,concurrent,10038,"ecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-11"" #71 prio=5 os_prio=31 tid=0x00007fb76b05a800 nid=0xb703 waiting on condition [0x00000001331c9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-10"" #70 prio=5 os_prio=31 tid=0x00007fb76bac5800 nid=0xb503 waiting on condition [0x0000000132fa6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:10408,Performance,concurren,concurrent,10408," WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-10"" #70 prio=5 os_prio=31 tid=0x00007fb76bac5800 nid=0xb503 waiting on condition [0x0000000132fa6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-9"" #69 prio=5 os_prio=31 tid=0x00007fb76f36d800 nid=0xb303 waiting on condition [0x000000012c1b6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:17",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:10483,Performance,concurren,concurrent,10483,"it for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-10"" #70 prio=5 os_prio=31 tid=0x00007fb76bac5800 nid=0xb503 waiting on condition [0x0000000132fa6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-9"" #69 prio=5 os_prio=31 tid=0x00007fb76f36d800 nid=0xb303 waiting on condition [0x000000012c1b6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObjec",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:10553,Performance,concurren,concurrent,10553,"edSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-10"" #70 prio=5 os_prio=31 tid=0x00007fb76bac5800 nid=0xb503 waiting on condition [0x0000000132fa6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-9"" #69 prio=5 os_prio=31 tid=0x00007fb76f36d800 nid=0xb303 waiting on condition [0x000000012c1b6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:10671,Performance,concurren,concurrent,10671,"ncurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-10"" #70 prio=5 os_prio=31 tid=0x00007fb76bac5800 nid=0xb503 waiting on condition [0x0000000132fa6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-9"" #69 prio=5 os_prio=31 tid=0x00007fb76f36d800 nid=0xb303 waiting on condition [0x000000012c1b6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPool",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:10751,Performance,concurren,concurrent,10751,"nchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-10"" #70 prio=5 os_prio=31 tid=0x00007fb76bac5800 nid=0xb503 waiting on condition [0x0000000132fa6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-9"" #69 prio=5 os_prio=31 tid=0x00007fb76f36d800 nid=0xb303 waiting on condition [0x000000012c1b6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Thread",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:10833,Performance,concurren,concurrent,10833,"kingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-10"" #70 prio=5 os_prio=31 tid=0x00007fb76bac5800 nid=0xb503 waiting on condition [0x0000000132fa6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-9"" #69 prio=5 os_prio=31 tid=0x00007fb76f36d800 nid=0xb303 waiting on condition [0x000000012c1b6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(Thr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:10917,Performance,concurren,concurrent,10917,"ecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-10"" #70 prio=5 os_prio=31 tid=0x00007fb76bac5800 nid=0xb503 waiting on condition [0x0000000132fa6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-9"" #69 prio=5 os_prio=31 tid=0x00007fb76f36d800 nid=0xb303 waiting on condition [0x000000012c1b6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:11286,Performance,concurren,concurrent,11286,": WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-9"" #69 prio=5 os_prio=31 tid=0x00007fb76f36d800 nid=0xb303 waiting on condition [0x000000012c1b6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-8"" #68 prio=5 os_prio=31 tid=0x00007fb76ef84000 nid=0xb103 waiting on condition [0x0000000132bf1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:17",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:11361,Performance,concurren,concurrent,11361,"ait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-9"" #69 prio=5 os_prio=31 tid=0x00007fb76f36d800 nid=0xb303 waiting on condition [0x000000012c1b6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-8"" #68 prio=5 os_prio=31 tid=0x00007fb76ef84000 nid=0xb103 waiting on condition [0x0000000132bf1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObjec",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:11431,Performance,concurren,concurrent,11431,"uedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-9"" #69 prio=5 os_prio=31 tid=0x00007fb76f36d800 nid=0xb303 waiting on condition [0x000000012c1b6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-8"" #68 prio=5 os_prio=31 tid=0x00007fb76ef84000 nid=0xb103 waiting on condition [0x0000000132bf1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:11549,Performance,concurren,concurrent,11549,"oncurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-9"" #69 prio=5 os_prio=31 tid=0x00007fb76f36d800 nid=0xb303 waiting on condition [0x000000012c1b6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-8"" #68 prio=5 os_prio=31 tid=0x00007fb76ef84000 nid=0xb103 waiting on condition [0x0000000132bf1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPool",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:11629,Performance,concurren,concurrent,11629,"ynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-9"" #69 prio=5 os_prio=31 tid=0x00007fb76f36d800 nid=0xb303 waiting on condition [0x000000012c1b6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-8"" #68 prio=5 os_prio=31 tid=0x00007fb76ef84000 nid=0xb103 waiting on condition [0x0000000132bf1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Thread",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:11711,Performance,concurren,concurrent,11711,"ckingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-9"" #69 prio=5 os_prio=31 tid=0x00007fb76f36d800 nid=0xb303 waiting on condition [0x000000012c1b6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-8"" #68 prio=5 os_prio=31 tid=0x00007fb76ef84000 nid=0xb103 waiting on condition [0x0000000132bf1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(Thr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:11795,Performance,concurren,concurrent,11795,"xecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-9"" #69 prio=5 os_prio=31 tid=0x00007fb76f36d800 nid=0xb303 waiting on condition [0x000000012c1b6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-8"" #68 prio=5 os_prio=31 tid=0x00007fb76ef84000 nid=0xb103 waiting on condition [0x0000000132bf1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:12164,Performance,concurren,concurrent,12164,": WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-8"" #68 prio=5 os_prio=31 tid=0x00007fb76ef84000 nid=0xb103 waiting on condition [0x0000000132bf1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-7"" #67 prio=5 os_prio=31 tid=0x00007fb7705a3000 nid=0xaf03 waiting on condition [0x00000001330c6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:17",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:12239,Performance,concurren,concurrent,12239,"ait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-8"" #68 prio=5 os_prio=31 tid=0x00007fb76ef84000 nid=0xb103 waiting on condition [0x0000000132bf1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-7"" #67 prio=5 os_prio=31 tid=0x00007fb7705a3000 nid=0xaf03 waiting on condition [0x00000001330c6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObjec",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:12309,Performance,concurren,concurrent,12309,"uedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-8"" #68 prio=5 os_prio=31 tid=0x00007fb76ef84000 nid=0xb103 waiting on condition [0x0000000132bf1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-7"" #67 prio=5 os_prio=31 tid=0x00007fb7705a3000 nid=0xaf03 waiting on condition [0x00000001330c6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:12427,Performance,concurren,concurrent,12427,"oncurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-8"" #68 prio=5 os_prio=31 tid=0x00007fb76ef84000 nid=0xb103 waiting on condition [0x0000000132bf1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-7"" #67 prio=5 os_prio=31 tid=0x00007fb7705a3000 nid=0xaf03 waiting on condition [0x00000001330c6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPool",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:12507,Performance,concurren,concurrent,12507,"ynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-8"" #68 prio=5 os_prio=31 tid=0x00007fb76ef84000 nid=0xb103 waiting on condition [0x0000000132bf1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-7"" #67 prio=5 os_prio=31 tid=0x00007fb7705a3000 nid=0xaf03 waiting on condition [0x00000001330c6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Thread",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:12589,Performance,concurren,concurrent,12589,"ckingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-8"" #68 prio=5 os_prio=31 tid=0x00007fb76ef84000 nid=0xb103 waiting on condition [0x0000000132bf1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-7"" #67 prio=5 os_prio=31 tid=0x00007fb7705a3000 nid=0xaf03 waiting on condition [0x00000001330c6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(Thr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:12673,Performance,concurren,concurrent,12673,"xecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-8"" #68 prio=5 os_prio=31 tid=0x00007fb76ef84000 nid=0xb103 waiting on condition [0x0000000132bf1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-7"" #67 prio=5 os_prio=31 tid=0x00007fb7705a3000 nid=0xaf03 waiting on condition [0x00000001330c6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:13042,Performance,concurren,concurrent,13042,": WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-7"" #67 prio=5 os_prio=31 tid=0x00007fb7705a3000 nid=0xaf03 waiting on condition [0x00000001330c6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-6"" #66 prio=5 os_prio=31 tid=0x00007fb7705ef800 nid=0xad03 waiting on condition [0x0000000132aee000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:17",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:13117,Performance,concurren,concurrent,13117,"ait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-7"" #67 prio=5 os_prio=31 tid=0x00007fb7705a3000 nid=0xaf03 waiting on condition [0x00000001330c6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-6"" #66 prio=5 os_prio=31 tid=0x00007fb7705ef800 nid=0xad03 waiting on condition [0x0000000132aee000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObjec",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:13187,Performance,concurren,concurrent,13187,"uedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-7"" #67 prio=5 os_prio=31 tid=0x00007fb7705a3000 nid=0xaf03 waiting on condition [0x00000001330c6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-6"" #66 prio=5 os_prio=31 tid=0x00007fb7705ef800 nid=0xad03 waiting on condition [0x0000000132aee000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:13305,Performance,concurren,concurrent,13305,"oncurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-7"" #67 prio=5 os_prio=31 tid=0x00007fb7705a3000 nid=0xaf03 waiting on condition [0x00000001330c6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-6"" #66 prio=5 os_prio=31 tid=0x00007fb7705ef800 nid=0xad03 waiting on condition [0x0000000132aee000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPool",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:13385,Performance,concurren,concurrent,13385,"ynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-7"" #67 prio=5 os_prio=31 tid=0x00007fb7705a3000 nid=0xaf03 waiting on condition [0x00000001330c6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-6"" #66 prio=5 os_prio=31 tid=0x00007fb7705ef800 nid=0xad03 waiting on condition [0x0000000132aee000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Thread",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:13467,Performance,concurren,concurrent,13467,"ckingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-7"" #67 prio=5 os_prio=31 tid=0x00007fb7705a3000 nid=0xaf03 waiting on condition [0x00000001330c6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-6"" #66 prio=5 os_prio=31 tid=0x00007fb7705ef800 nid=0xad03 waiting on condition [0x0000000132aee000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(Thr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:13551,Performance,concurren,concurrent,13551,"xecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-7"" #67 prio=5 os_prio=31 tid=0x00007fb7705a3000 nid=0xaf03 waiting on condition [0x00000001330c6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-6"" #66 prio=5 os_prio=31 tid=0x00007fb7705ef800 nid=0xad03 waiting on condition [0x0000000132aee000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:13920,Performance,concurren,concurrent,13920,": WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-6"" #66 prio=5 os_prio=31 tid=0x00007fb7705ef800 nid=0xad03 waiting on condition [0x0000000132aee000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-5"" #65 prio=5 os_prio=31 tid=0x00007fb7706d2800 nid=0xab03 waiting on condition [0x00000001329eb000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:17",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:13995,Performance,concurren,concurrent,13995,"ait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-6"" #66 prio=5 os_prio=31 tid=0x00007fb7705ef800 nid=0xad03 waiting on condition [0x0000000132aee000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-5"" #65 prio=5 os_prio=31 tid=0x00007fb7706d2800 nid=0xab03 waiting on condition [0x00000001329eb000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObjec",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:14065,Performance,concurren,concurrent,14065,"uedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-6"" #66 prio=5 os_prio=31 tid=0x00007fb7705ef800 nid=0xad03 waiting on condition [0x0000000132aee000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-5"" #65 prio=5 os_prio=31 tid=0x00007fb7706d2800 nid=0xab03 waiting on condition [0x00000001329eb000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:14183,Performance,concurren,concurrent,14183,"oncurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-6"" #66 prio=5 os_prio=31 tid=0x00007fb7705ef800 nid=0xad03 waiting on condition [0x0000000132aee000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-5"" #65 prio=5 os_prio=31 tid=0x00007fb7706d2800 nid=0xab03 waiting on condition [0x00000001329eb000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPool",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:14263,Performance,concurren,concurrent,14263,"ynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-6"" #66 prio=5 os_prio=31 tid=0x00007fb7705ef800 nid=0xad03 waiting on condition [0x0000000132aee000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-5"" #65 prio=5 os_prio=31 tid=0x00007fb7706d2800 nid=0xab03 waiting on condition [0x00000001329eb000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Thread",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:14345,Performance,concurren,concurrent,14345,"ckingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-6"" #66 prio=5 os_prio=31 tid=0x00007fb7705ef800 nid=0xad03 waiting on condition [0x0000000132aee000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-5"" #65 prio=5 os_prio=31 tid=0x00007fb7706d2800 nid=0xab03 waiting on condition [0x00000001329eb000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(Thr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:14429,Performance,concurren,concurrent,14429,"xecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-6"" #66 prio=5 os_prio=31 tid=0x00007fb7705ef800 nid=0xad03 waiting on condition [0x0000000132aee000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-5"" #65 prio=5 os_prio=31 tid=0x00007fb7706d2800 nid=0xab03 waiting on condition [0x00000001329eb000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-20"" #61 dae",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:14798,Performance,concurren,concurrent,14798,": WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-5"" #65 prio=5 os_prio=31 tid=0x00007fb7706d2800 nid=0xab03 waiting on condition [0x00000001329eb000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-20"" #61 daemon prio=5 os_prio=31 tid=0x00007fb76b1f9000 nid=0xa303 waiting on condition [0x00000001325df000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175);",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:14873,Performance,concurren,concurrent,14873,"ait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-5"" #65 prio=5 os_prio=31 tid=0x00007fb7706d2800 nid=0xab03 waiting on condition [0x00000001329eb000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-20"" #61 daemon prio=5 os_prio=31 tid=0x00007fb76b1f9000 nid=0xa303 waiting on condition [0x00000001325df000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:14943,Performance,concurren,concurrent,14943,"uedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-5"" #65 prio=5 os_prio=31 tid=0x00007fb7706d2800 nid=0xab03 waiting on condition [0x00000001329eb000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-20"" #61 daemon prio=5 os_prio=31 tid=0x00007fb76b1f9000 nid=0xa303 waiting on condition [0x00000001325df000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArray",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:15061,Performance,concurren,concurrent,15061,"oncurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-5"" #65 prio=5 os_prio=31 tid=0x00007fb7706d2800 nid=0xab03 waiting on condition [0x00000001329eb000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-20"" #61 daemon prio=5 os_prio=31 tid=0x00007fb76b1f9000 nid=0xa303 waiting on condition [0x00000001325df000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lock",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:15141,Performance,concurren,concurrent,15141,"ynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-5"" #65 prio=5 os_prio=31 tid=0x00007fb7706d2800 nid=0xab03 waiting on condition [0x00000001329eb000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-20"" #61 daemon prio=5 os_prio=31 tid=0x00007fb76b1f9000 nid=0xa303 waiting on condition [0x00000001325df000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArray",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:15223,Performance,concurren,concurrent,15223,"ckingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-5"" #65 prio=5 os_prio=31 tid=0x00007fb7706d2800 nid=0xab03 waiting on condition [0x00000001329eb000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-20"" #61 daemon prio=5 os_prio=31 tid=0x00007fb76b1f9000 nid=0xa303 waiting on condition [0x00000001325df000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.T",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:15307,Performance,concurren,concurrent,15307,"xecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-5"" #65 prio=5 os_prio=31 tid=0x00007fb7706d2800 nid=0xab03 waiting on condition [0x00000001329eb000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-20"" #61 daemon prio=5 os_prio=31 tid=0x00007fb76b1f9000 nid=0xa303 waiting on condition [0x00000001325df000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.Thr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:15673,Performance,concurren,concurrent,15673,"ate: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-20"" #61 daemon prio=5 os_prio=31 tid=0x00007fb76b1f9000 nid=0xa303 waiting on condition [0x00000001325df000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-4"" #60 prio=5 os_prio=31 tid=0x00007fb76d42b000 nid=0xa103 waiting on condition [0x0000000132168000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:15748,Performance,concurren,concurrent,15748,"o wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-20"" #61 daemon prio=5 os_prio=31 tid=0x00007fb76b1f9000 nid=0xa303 waiting on condition [0x00000001325df000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-4"" #60 prio=5 os_prio=31 tid=0x00007fb76d42b000 nid=0xa103 waiting on condition [0x0000000132168000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.co",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:15818,Performance,concurren,concurrent,15818,"QueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-20"" #61 daemon prio=5 os_prio=31 tid=0x00007fb76b1f9000 nid=0xa303 waiting on condition [0x00000001325df000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-4"" #60 prio=5 os_prio=31 tid=0x00007fb76d42b000 nid=0xa103 waiting on condition [0x0000000132168000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.ut",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:16217,Performance,concurren,concurrent,16217,".concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-20"" #61 daemon prio=5 os_prio=31 tid=0x00007fb76b1f9000 nid=0xa303 waiting on condition [0x00000001325df000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-4"" #60 prio=5 os_prio=31 tid=0x00007fb76d42b000 nid=0xa103 waiting on condition [0x0000000132168000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Thread",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:16299,Performance,concurren,concurrent,16299,"il.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-20"" #61 daemon prio=5 os_prio=31 tid=0x00007fb76b1f9000 nid=0xa303 waiting on condition [0x00000001325df000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-4"" #60 prio=5 os_prio=31 tid=0x00007fb76d42b000 nid=0xa103 waiting on condition [0x0000000132168000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(Thr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:16383,Performance,concurren,concurrent,16383,"ng.Thread.run(Thread.java:745). ""db-20"" #61 daemon prio=5 os_prio=31 tid=0x00007fb76b1f9000 nid=0xa303 waiting on condition [0x00000001325df000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-4"" #60 prio=5 os_prio=31 tid=0x00007fb76d42b000 nid=0xa103 waiting on condition [0x0000000132168000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-19"" #59 dae",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:16752,Performance,concurren,concurrent,16752,"t.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-4"" #60 prio=5 os_prio=31 tid=0x00007fb76d42b000 nid=0xa103 waiting on condition [0x0000000132168000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-19"" #59 daemon prio=5 os_prio=31 tid=0x00007fb770631000 nid=0x9f03 waiting on condition [0x00000001324dc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175);",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:16827,Performance,concurren,concurrent,16827,"ks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-4"" #60 prio=5 os_prio=31 tid=0x00007fb76d42b000 nid=0xa103 waiting on condition [0x0000000132168000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-19"" #59 daemon prio=5 os_prio=31 tid=0x00007fb770631000 nid=0x9f03 waiting on condition [0x00000001324dc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:16897,Performance,concurren,concurrent,16897,"hronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-4"" #60 prio=5 os_prio=31 tid=0x00007fb76d42b000 nid=0xa103 waiting on condition [0x0000000132168000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-19"" #59 daemon prio=5 os_prio=31 tid=0x00007fb770631000 nid=0x9f03 waiting on condition [0x00000001324dc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArray",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:17015,Performance,concurren,concurrent,17015,"); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-4"" #60 prio=5 os_prio=31 tid=0x00007fb76d42b000 nid=0xa103 waiting on condition [0x0000000132168000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-19"" #59 daemon prio=5 os_prio=31 tid=0x00007fb770631000 nid=0x9f03 waiting on condition [0x00000001324dc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lock",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:17095,Performance,concurren,concurrent,17095,"ingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-4"" #60 prio=5 os_prio=31 tid=0x00007fb76d42b000 nid=0xa103 waiting on condition [0x0000000132168000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-19"" #59 daemon prio=5 os_prio=31 tid=0x00007fb770631000 nid=0x9f03 waiting on condition [0x00000001324dc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArray",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:17177,Performance,concurren,concurrent,17177,"kingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-4"" #60 prio=5 os_prio=31 tid=0x00007fb76d42b000 nid=0xa103 waiting on condition [0x0000000132168000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-19"" #59 daemon prio=5 os_prio=31 tid=0x00007fb770631000 nid=0x9f03 waiting on condition [0x00000001324dc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.T",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:17261,Performance,concurren,concurrent,17261,"xecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-4"" #60 prio=5 os_prio=31 tid=0x00007fb76d42b000 nid=0xa103 waiting on condition [0x0000000132168000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-19"" #59 daemon prio=5 os_prio=31 tid=0x00007fb770631000 nid=0x9f03 waiting on condition [0x00000001324dc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.Thr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:17627,Performance,concurren,concurrent,17627,"ate: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-19"" #59 daemon prio=5 os_prio=31 tid=0x00007fb770631000 nid=0x9f03 waiting on condition [0x00000001324dc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-18"" #58 daemon prio=5 os_prio=31 tid=0x00007fb770630800 nid=0x9d03 waiting on condition [0x00000001323d9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Na",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:17702,Performance,concurren,concurrent,17702,"o wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-19"" #59 daemon prio=5 os_prio=31 tid=0x00007fb770631000 nid=0x9f03 waiting on condition [0x00000001324dc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-18"" #58 daemon prio=5 os_prio=31 tid=0x00007fb770630800 nid=0x9d03 waiting on condition [0x00000001323d9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:17772,Performance,concurren,concurrent,17772,"QueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-19"" #59 daemon prio=5 os_prio=31 tid=0x00007fb770631000 nid=0x9f03 waiting on condition [0x00000001324dc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-18"" #58 daemon prio=5 os_prio=31 tid=0x00007fb770630800 nid=0x9d03 waiting on condition [0x00000001323d9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:18171,Performance,concurren,concurrent,18171,".concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-19"" #59 daemon prio=5 os_prio=31 tid=0x00007fb770631000 nid=0x9f03 waiting on condition [0x00000001324dc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-18"" #58 daemon prio=5 os_prio=31 tid=0x00007fb770630800 nid=0x9d03 waiting on condition [0x00000001323d9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArray",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:18253,Performance,concurren,concurrent,18253,"il.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-19"" #59 daemon prio=5 os_prio=31 tid=0x00007fb770631000 nid=0x9f03 waiting on condition [0x00000001324dc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-18"" #58 daemon prio=5 os_prio=31 tid=0x00007fb770630800 nid=0x9d03 waiting on condition [0x00000001323d9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.T",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:18337,Performance,concurren,concurrent,18337,"ng.Thread.run(Thread.java:745). ""db-19"" #59 daemon prio=5 os_prio=31 tid=0x00007fb770631000 nid=0x9f03 waiting on condition [0x00000001324dc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-18"" #58 daemon prio=5 os_prio=31 tid=0x00007fb770630800 nid=0x9d03 waiting on condition [0x00000001323d9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.Thr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:18703,Performance,concurren,concurrent,18703,"rent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-18"" #58 daemon prio=5 os_prio=31 tid=0x00007fb770630800 nid=0x9d03 waiting on condition [0x00000001323d9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-3"" #57 prio=5 os_prio=31 tid=0x00007fb76e95e000 nid=0x9b03 waiting on condition [0x00000001322d6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:18778,Performance,concurren,concurrent,18778,"locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-18"" #58 daemon prio=5 os_prio=31 tid=0x00007fb770630800 nid=0x9d03 waiting on condition [0x00000001323d9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-3"" #57 prio=5 os_prio=31 tid=0x00007fb76e95e000 nid=0x9b03 waiting on condition [0x00000001322d6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.co",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:18848,Performance,concurren,concurrent,18848,"ynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-18"" #58 daemon prio=5 os_prio=31 tid=0x00007fb770630800 nid=0x9d03 waiting on condition [0x00000001323d9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-3"" #57 prio=5 os_prio=31 tid=0x00007fb76e95e000 nid=0x9b03 waiting on condition [0x00000001322d6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.ut",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:19247,Performance,concurren,concurrent,19247,".concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-18"" #58 daemon prio=5 os_prio=31 tid=0x00007fb770630800 nid=0x9d03 waiting on condition [0x00000001323d9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-3"" #57 prio=5 os_prio=31 tid=0x00007fb76e95e000 nid=0x9b03 waiting on condition [0x00000001322d6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Thread",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:19329,Performance,concurren,concurrent,19329,"il.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-18"" #58 daemon prio=5 os_prio=31 tid=0x00007fb770630800 nid=0x9d03 waiting on condition [0x00000001323d9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-3"" #57 prio=5 os_prio=31 tid=0x00007fb76e95e000 nid=0x9b03 waiting on condition [0x00000001322d6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(Thr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:19413,Performance,concurren,concurrent,19413,"ng.Thread.run(Thread.java:745). ""db-18"" #58 daemon prio=5 os_prio=31 tid=0x00007fb770630800 nid=0x9d03 waiting on condition [0x00000001323d9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-3"" #57 prio=5 os_prio=31 tid=0x00007fb76e95e000 nid=0x9b03 waiting on condition [0x00000001322d6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-17"" #56 dae",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:19782,Performance,concurren,concurrent,19782,"t.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-3"" #57 prio=5 os_prio=31 tid=0x00007fb76e95e000 nid=0x9b03 waiting on condition [0x00000001322d6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-17"" #56 daemon prio=5 os_prio=31 tid=0x00007fb76b6b6000 nid=0x9903 waiting on condition [0x0000000131db9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175);",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:19857,Performance,concurren,concurrent,19857,"ks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-3"" #57 prio=5 os_prio=31 tid=0x00007fb76e95e000 nid=0x9b03 waiting on condition [0x00000001322d6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-17"" #56 daemon prio=5 os_prio=31 tid=0x00007fb76b6b6000 nid=0x9903 waiting on condition [0x0000000131db9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:19927,Performance,concurren,concurrent,19927,"hronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-3"" #57 prio=5 os_prio=31 tid=0x00007fb76e95e000 nid=0x9b03 waiting on condition [0x00000001322d6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-17"" #56 daemon prio=5 os_prio=31 tid=0x00007fb76b6b6000 nid=0x9903 waiting on condition [0x0000000131db9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArray",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:20045,Performance,concurren,concurrent,20045,"); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-3"" #57 prio=5 os_prio=31 tid=0x00007fb76e95e000 nid=0x9b03 waiting on condition [0x00000001322d6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-17"" #56 daemon prio=5 os_prio=31 tid=0x00007fb76b6b6000 nid=0x9903 waiting on condition [0x0000000131db9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lock",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:20125,Performance,concurren,concurrent,20125,"ingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-3"" #57 prio=5 os_prio=31 tid=0x00007fb76e95e000 nid=0x9b03 waiting on condition [0x00000001322d6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-17"" #56 daemon prio=5 os_prio=31 tid=0x00007fb76b6b6000 nid=0x9903 waiting on condition [0x0000000131db9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArray",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:20207,Performance,concurren,concurrent,20207,"kingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-3"" #57 prio=5 os_prio=31 tid=0x00007fb76e95e000 nid=0x9b03 waiting on condition [0x00000001322d6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-17"" #56 daemon prio=5 os_prio=31 tid=0x00007fb76b6b6000 nid=0x9903 waiting on condition [0x0000000131db9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.T",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:20291,Performance,concurren,concurrent,20291,"xecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-3"" #57 prio=5 os_prio=31 tid=0x00007fb76e95e000 nid=0x9b03 waiting on condition [0x00000001322d6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-17"" #56 daemon prio=5 os_prio=31 tid=0x00007fb76b6b6000 nid=0x9903 waiting on condition [0x0000000131db9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.Thr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:20657,Performance,concurren,concurrent,20657,"ate: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-17"" #56 daemon prio=5 os_prio=31 tid=0x00007fb76b6b6000 nid=0x9903 waiting on condition [0x0000000131db9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-16"" #55 daemon prio=5 os_prio=31 tid=0x00007fb76e92f000 nid=0x9703 waiting on condition [0x0000000131cb6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Na",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:20732,Performance,concurren,concurrent,20732,"o wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-17"" #56 daemon prio=5 os_prio=31 tid=0x00007fb76b6b6000 nid=0x9903 waiting on condition [0x0000000131db9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-16"" #55 daemon prio=5 os_prio=31 tid=0x00007fb76e92f000 nid=0x9703 waiting on condition [0x0000000131cb6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:20802,Performance,concurren,concurrent,20802,"QueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-17"" #56 daemon prio=5 os_prio=31 tid=0x00007fb76b6b6000 nid=0x9903 waiting on condition [0x0000000131db9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-16"" #55 daemon prio=5 os_prio=31 tid=0x00007fb76e92f000 nid=0x9703 waiting on condition [0x0000000131cb6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:21201,Performance,concurren,concurrent,21201,".concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-17"" #56 daemon prio=5 os_prio=31 tid=0x00007fb76b6b6000 nid=0x9903 waiting on condition [0x0000000131db9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-16"" #55 daemon prio=5 os_prio=31 tid=0x00007fb76e92f000 nid=0x9703 waiting on condition [0x0000000131cb6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArray",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:21283,Performance,concurren,concurrent,21283,"il.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-17"" #56 daemon prio=5 os_prio=31 tid=0x00007fb76b6b6000 nid=0x9903 waiting on condition [0x0000000131db9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-16"" #55 daemon prio=5 os_prio=31 tid=0x00007fb76e92f000 nid=0x9703 waiting on condition [0x0000000131cb6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.T",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:21367,Performance,concurren,concurrent,21367,"ng.Thread.run(Thread.java:745). ""db-17"" #56 daemon prio=5 os_prio=31 tid=0x00007fb76b6b6000 nid=0x9903 waiting on condition [0x0000000131db9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-16"" #55 daemon prio=5 os_prio=31 tid=0x00007fb76e92f000 nid=0x9703 waiting on condition [0x0000000131cb6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.Thr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:21733,Performance,concurren,concurrent,21733,"rent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-16"" #55 daemon prio=5 os_prio=31 tid=0x00007fb76e92f000 nid=0x9703 waiting on condition [0x0000000131cb6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-15"" #54 daemon prio=5 os_prio=31 tid=0x00007fb76b6b4000 nid=0x9503 waiting on condition [0x0000000131bb3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Na",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:21808,Performance,concurren,concurrent,21808,"locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-16"" #55 daemon prio=5 os_prio=31 tid=0x00007fb76e92f000 nid=0x9703 waiting on condition [0x0000000131cb6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-15"" #54 daemon prio=5 os_prio=31 tid=0x00007fb76b6b4000 nid=0x9503 waiting on condition [0x0000000131bb3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:21878,Performance,concurren,concurrent,21878,"ynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-16"" #55 daemon prio=5 os_prio=31 tid=0x00007fb76e92f000 nid=0x9703 waiting on condition [0x0000000131cb6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-15"" #54 daemon prio=5 os_prio=31 tid=0x00007fb76b6b4000 nid=0x9503 waiting on condition [0x0000000131bb3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:22277,Performance,concurren,concurrent,22277,".concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-16"" #55 daemon prio=5 os_prio=31 tid=0x00007fb76e92f000 nid=0x9703 waiting on condition [0x0000000131cb6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-15"" #54 daemon prio=5 os_prio=31 tid=0x00007fb76b6b4000 nid=0x9503 waiting on condition [0x0000000131bb3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArray",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:22359,Performance,concurren,concurrent,22359,"il.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-16"" #55 daemon prio=5 os_prio=31 tid=0x00007fb76e92f000 nid=0x9703 waiting on condition [0x0000000131cb6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-15"" #54 daemon prio=5 os_prio=31 tid=0x00007fb76b6b4000 nid=0x9503 waiting on condition [0x0000000131bb3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.T",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:22443,Performance,concurren,concurrent,22443,"ng.Thread.run(Thread.java:745). ""db-16"" #55 daemon prio=5 os_prio=31 tid=0x00007fb76e92f000 nid=0x9703 waiting on condition [0x0000000131cb6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-15"" #54 daemon prio=5 os_prio=31 tid=0x00007fb76b6b4000 nid=0x9503 waiting on condition [0x0000000131bb3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.Thr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:22809,Performance,concurren,concurrent,22809,"rent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-15"" #54 daemon prio=5 os_prio=31 tid=0x00007fb76b6b4000 nid=0x9503 waiting on condition [0x0000000131bb3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-14"" #53 daemon prio=5 os_prio=31 tid=0x00007fb77061e000 nid=0x9303 waiting on condition [0x0000000131ab0000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Na",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:22884,Performance,concurren,concurrent,22884,"locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-15"" #54 daemon prio=5 os_prio=31 tid=0x00007fb76b6b4000 nid=0x9503 waiting on condition [0x0000000131bb3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-14"" #53 daemon prio=5 os_prio=31 tid=0x00007fb77061e000 nid=0x9303 waiting on condition [0x0000000131ab0000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:22954,Performance,concurren,concurrent,22954,"ynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-15"" #54 daemon prio=5 os_prio=31 tid=0x00007fb76b6b4000 nid=0x9503 waiting on condition [0x0000000131bb3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-14"" #53 daemon prio=5 os_prio=31 tid=0x00007fb77061e000 nid=0x9303 waiting on condition [0x0000000131ab0000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:23353,Performance,concurren,concurrent,23353,".concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-15"" #54 daemon prio=5 os_prio=31 tid=0x00007fb76b6b4000 nid=0x9503 waiting on condition [0x0000000131bb3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-14"" #53 daemon prio=5 os_prio=31 tid=0x00007fb77061e000 nid=0x9303 waiting on condition [0x0000000131ab0000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArray",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:23435,Performance,concurren,concurrent,23435,"il.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-15"" #54 daemon prio=5 os_prio=31 tid=0x00007fb76b6b4000 nid=0x9503 waiting on condition [0x0000000131bb3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-14"" #53 daemon prio=5 os_prio=31 tid=0x00007fb77061e000 nid=0x9303 waiting on condition [0x0000000131ab0000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.T",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:23519,Performance,concurren,concurrent,23519,"ng.Thread.run(Thread.java:745). ""db-15"" #54 daemon prio=5 os_prio=31 tid=0x00007fb76b6b4000 nid=0x9503 waiting on condition [0x0000000131bb3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-14"" #53 daemon prio=5 os_prio=31 tid=0x00007fb77061e000 nid=0x9303 waiting on condition [0x0000000131ab0000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.Thr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:23885,Performance,concurren,concurrent,23885,"rent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-14"" #53 daemon prio=5 os_prio=31 tid=0x00007fb77061e000 nid=0x9303 waiting on condition [0x0000000131ab0000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-13"" #52 daemon prio=5 os_prio=31 tid=0x00007fb76e96e000 nid=0x9103 waiting on condition [0x00000001319ad000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Na",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:23960,Performance,concurren,concurrent,23960,"locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-14"" #53 daemon prio=5 os_prio=31 tid=0x00007fb77061e000 nid=0x9303 waiting on condition [0x0000000131ab0000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-13"" #52 daemon prio=5 os_prio=31 tid=0x00007fb76e96e000 nid=0x9103 waiting on condition [0x00000001319ad000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:24030,Performance,concurren,concurrent,24030,"ynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-14"" #53 daemon prio=5 os_prio=31 tid=0x00007fb77061e000 nid=0x9303 waiting on condition [0x0000000131ab0000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-13"" #52 daemon prio=5 os_prio=31 tid=0x00007fb76e96e000 nid=0x9103 waiting on condition [0x00000001319ad000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:24429,Performance,concurren,concurrent,24429,".concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-14"" #53 daemon prio=5 os_prio=31 tid=0x00007fb77061e000 nid=0x9303 waiting on condition [0x0000000131ab0000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-13"" #52 daemon prio=5 os_prio=31 tid=0x00007fb76e96e000 nid=0x9103 waiting on condition [0x00000001319ad000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArray",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:24511,Performance,concurren,concurrent,24511,"il.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-14"" #53 daemon prio=5 os_prio=31 tid=0x00007fb77061e000 nid=0x9303 waiting on condition [0x0000000131ab0000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-13"" #52 daemon prio=5 os_prio=31 tid=0x00007fb76e96e000 nid=0x9103 waiting on condition [0x00000001319ad000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.T",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:24595,Performance,concurren,concurrent,24595,"ng.Thread.run(Thread.java:745). ""db-14"" #53 daemon prio=5 os_prio=31 tid=0x00007fb77061e000 nid=0x9303 waiting on condition [0x0000000131ab0000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-13"" #52 daemon prio=5 os_prio=31 tid=0x00007fb76e96e000 nid=0x9103 waiting on condition [0x00000001319ad000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.Thr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:24961,Performance,concurren,concurrent,24961,"rent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-13"" #52 daemon prio=5 os_prio=31 tid=0x00007fb76e96e000 nid=0x9103 waiting on condition [0x00000001319ad000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-12"" #51 daemon prio=5 os_prio=31 tid=0x00007fb7720cf000 nid=0x8f03 waiting on condition [0x00000001318aa000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Na",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:25036,Performance,concurren,concurrent,25036,"locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-13"" #52 daemon prio=5 os_prio=31 tid=0x00007fb76e96e000 nid=0x9103 waiting on condition [0x00000001319ad000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-12"" #51 daemon prio=5 os_prio=31 tid=0x00007fb7720cf000 nid=0x8f03 waiting on condition [0x00000001318aa000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:25106,Performance,concurren,concurrent,25106,"ynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-13"" #52 daemon prio=5 os_prio=31 tid=0x00007fb76e96e000 nid=0x9103 waiting on condition [0x00000001319ad000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-12"" #51 daemon prio=5 os_prio=31 tid=0x00007fb7720cf000 nid=0x8f03 waiting on condition [0x00000001318aa000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:25505,Performance,concurren,concurrent,25505,".concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-13"" #52 daemon prio=5 os_prio=31 tid=0x00007fb76e96e000 nid=0x9103 waiting on condition [0x00000001319ad000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-12"" #51 daemon prio=5 os_prio=31 tid=0x00007fb7720cf000 nid=0x8f03 waiting on condition [0x00000001318aa000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArray",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:25587,Performance,concurren,concurrent,25587,"il.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-13"" #52 daemon prio=5 os_prio=31 tid=0x00007fb76e96e000 nid=0x9103 waiting on condition [0x00000001319ad000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-12"" #51 daemon prio=5 os_prio=31 tid=0x00007fb7720cf000 nid=0x8f03 waiting on condition [0x00000001318aa000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.T",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:25671,Performance,concurren,concurrent,25671,"ng.Thread.run(Thread.java:745). ""db-13"" #52 daemon prio=5 os_prio=31 tid=0x00007fb76e96e000 nid=0x9103 waiting on condition [0x00000001319ad000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-12"" #51 daemon prio=5 os_prio=31 tid=0x00007fb7720cf000 nid=0x8f03 waiting on condition [0x00000001318aa000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.Thr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:26037,Performance,concurren,concurrent,26037,"rent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-12"" #51 daemon prio=5 os_prio=31 tid=0x00007fb7720cf000 nid=0x8f03 waiting on condition [0x00000001318aa000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-11"" #50 daemon prio=5 os_prio=31 tid=0x00007fb7720ce800 nid=0x8d03 waiting on condition [0x00000001317a7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Na",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:26112,Performance,concurren,concurrent,26112,"locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-12"" #51 daemon prio=5 os_prio=31 tid=0x00007fb7720cf000 nid=0x8f03 waiting on condition [0x00000001318aa000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-11"" #50 daemon prio=5 os_prio=31 tid=0x00007fb7720ce800 nid=0x8d03 waiting on condition [0x00000001317a7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:26182,Performance,concurren,concurrent,26182,"ynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-12"" #51 daemon prio=5 os_prio=31 tid=0x00007fb7720cf000 nid=0x8f03 waiting on condition [0x00000001318aa000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-11"" #50 daemon prio=5 os_prio=31 tid=0x00007fb7720ce800 nid=0x8d03 waiting on condition [0x00000001317a7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:26581,Performance,concurren,concurrent,26581,".concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-12"" #51 daemon prio=5 os_prio=31 tid=0x00007fb7720cf000 nid=0x8f03 waiting on condition [0x00000001318aa000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-11"" #50 daemon prio=5 os_prio=31 tid=0x00007fb7720ce800 nid=0x8d03 waiting on condition [0x00000001317a7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArray",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:26663,Performance,concurren,concurrent,26663,"il.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-12"" #51 daemon prio=5 os_prio=31 tid=0x00007fb7720cf000 nid=0x8f03 waiting on condition [0x00000001318aa000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-11"" #50 daemon prio=5 os_prio=31 tid=0x00007fb7720ce800 nid=0x8d03 waiting on condition [0x00000001317a7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.T",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:26747,Performance,concurren,concurrent,26747,"ng.Thread.run(Thread.java:745). ""db-12"" #51 daemon prio=5 os_prio=31 tid=0x00007fb7720cf000 nid=0x8f03 waiting on condition [0x00000001318aa000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-11"" #50 daemon prio=5 os_prio=31 tid=0x00007fb7720ce800 nid=0x8d03 waiting on condition [0x00000001317a7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.Thr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:27113,Performance,concurren,concurrent,27113,"rent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-11"" #50 daemon prio=5 os_prio=31 tid=0x00007fb7720ce800 nid=0x8d03 waiting on condition [0x00000001317a7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-10"" #49 daemon prio=5 os_prio=31 tid=0x00007fb7720cd800 nid=0x8b03 waiting on condition [0x00000001316a4000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Na",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:27188,Performance,concurren,concurrent,27188,"locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-11"" #50 daemon prio=5 os_prio=31 tid=0x00007fb7720ce800 nid=0x8d03 waiting on condition [0x00000001317a7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-10"" #49 daemon prio=5 os_prio=31 tid=0x00007fb7720cd800 nid=0x8b03 waiting on condition [0x00000001316a4000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:27258,Performance,concurren,concurrent,27258,"ynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-11"" #50 daemon prio=5 os_prio=31 tid=0x00007fb7720ce800 nid=0x8d03 waiting on condition [0x00000001317a7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-10"" #49 daemon prio=5 os_prio=31 tid=0x00007fb7720cd800 nid=0x8b03 waiting on condition [0x00000001316a4000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:27657,Performance,concurren,concurrent,27657,".concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-11"" #50 daemon prio=5 os_prio=31 tid=0x00007fb7720ce800 nid=0x8d03 waiting on condition [0x00000001317a7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-10"" #49 daemon prio=5 os_prio=31 tid=0x00007fb7720cd800 nid=0x8b03 waiting on condition [0x00000001316a4000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArray",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:27739,Performance,concurren,concurrent,27739,"il.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-11"" #50 daemon prio=5 os_prio=31 tid=0x00007fb7720ce800 nid=0x8d03 waiting on condition [0x00000001317a7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-10"" #49 daemon prio=5 os_prio=31 tid=0x00007fb7720cd800 nid=0x8b03 waiting on condition [0x00000001316a4000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.T",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:27823,Performance,concurren,concurrent,27823,"ng.Thread.run(Thread.java:745). ""db-11"" #50 daemon prio=5 os_prio=31 tid=0x00007fb7720ce800 nid=0x8d03 waiting on condition [0x00000001317a7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-10"" #49 daemon prio=5 os_prio=31 tid=0x00007fb7720cd800 nid=0x8b03 waiting on condition [0x00000001316a4000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.Thr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:28189,Performance,concurren,concurrent,28189,"rent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-10"" #49 daemon prio=5 os_prio=31 tid=0x00007fb7720cd800 nid=0x8b03 waiting on condition [0x00000001316a4000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-9"" #48 daemon prio=5 os_prio=31 tid=0x00007fb76b529800 nid=0x8903 waiting on condition [0x00000001315a1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Nat",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:28264,Performance,concurren,concurrent,28264,"locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-10"" #49 daemon prio=5 os_prio=31 tid=0x00007fb7720cd800 nid=0x8b03 waiting on condition [0x00000001316a4000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-9"" #48 daemon prio=5 os_prio=31 tid=0x00007fb76b529800 nid=0x8903 waiting on condition [0x00000001315a1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concur",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:28334,Performance,concurren,concurrent,28334,"ynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-10"" #49 daemon prio=5 os_prio=31 tid=0x00007fb7720cd800 nid=0x8b03 waiting on condition [0x00000001316a4000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-9"" #48 daemon prio=5 os_prio=31 tid=0x00007fb76b529800 nid=0x8903 waiting on condition [0x00000001315a1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:28733,Performance,concurren,concurrent,28733,".concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-10"" #49 daemon prio=5 os_prio=31 tid=0x00007fb7720cd800 nid=0x8b03 waiting on condition [0x00000001316a4000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-9"" #48 daemon prio=5 os_prio=31 tid=0x00007fb76b529800 nid=0x8903 waiting on condition [0x00000001315a1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayB",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:28815,Performance,concurren,concurrent,28815,"il.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-10"" #49 daemon prio=5 os_prio=31 tid=0x00007fb7720cd800 nid=0x8b03 waiting on condition [0x00000001316a4000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-9"" #48 daemon prio=5 os_prio=31 tid=0x00007fb76b529800 nid=0x8903 waiting on condition [0x00000001315a1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.Th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:28899,Performance,concurren,concurrent,28899,"ng.Thread.run(Thread.java:745). ""db-10"" #49 daemon prio=5 os_prio=31 tid=0x00007fb7720cd800 nid=0x8b03 waiting on condition [0x00000001316a4000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-9"" #48 daemon prio=5 os_prio=31 tid=0x00007fb76b529800 nid=0x8903 waiting on condition [0x00000001315a1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.Thre",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:29264,Performance,concurren,concurrent,29264,"rrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-9"" #48 daemon prio=5 os_prio=31 tid=0x00007fb76b529800 nid=0x8903 waiting on condition [0x00000001315a1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-8"" #47 daemon prio=5 os_prio=31 tid=0x00007fb76b518000 nid=0x8703 waiting on condition [0x000000013149e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Nat",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:29339,Performance,concurren,concurrent,29339,".locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-9"" #48 daemon prio=5 os_prio=31 tid=0x00007fb76b529800 nid=0x8903 waiting on condition [0x00000001315a1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-8"" #47 daemon prio=5 os_prio=31 tid=0x00007fb76b518000 nid=0x8703 waiting on condition [0x000000013149e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concur",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:29409,Performance,concurren,concurrent,29409,"Synchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-9"" #48 daemon prio=5 os_prio=31 tid=0x00007fb76b529800 nid=0x8903 waiting on condition [0x00000001315a1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-8"" #47 daemon prio=5 os_prio=31 tid=0x00007fb76b518000 nid=0x8703 waiting on condition [0x000000013149e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:29808,Performance,concurren,concurrent,29808,"l.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-9"" #48 daemon prio=5 os_prio=31 tid=0x00007fb76b529800 nid=0x8903 waiting on condition [0x00000001315a1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-8"" #47 daemon prio=5 os_prio=31 tid=0x00007fb76b518000 nid=0x8703 waiting on condition [0x000000013149e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayB",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:29890,Performance,concurren,concurrent,29890,"til.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-9"" #48 daemon prio=5 os_prio=31 tid=0x00007fb76b529800 nid=0x8903 waiting on condition [0x00000001315a1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-8"" #47 daemon prio=5 os_prio=31 tid=0x00007fb76b518000 nid=0x8703 waiting on condition [0x000000013149e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.Th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:29974,Performance,concurren,concurrent,29974,"ang.Thread.run(Thread.java:745). ""db-9"" #48 daemon prio=5 os_prio=31 tid=0x00007fb76b529800 nid=0x8903 waiting on condition [0x00000001315a1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-8"" #47 daemon prio=5 os_prio=31 tid=0x00007fb76b518000 nid=0x8703 waiting on condition [0x000000013149e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.Thre",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:30339,Performance,concurren,concurrent,30339,"rrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-8"" #47 daemon prio=5 os_prio=31 tid=0x00007fb76b518000 nid=0x8703 waiting on condition [0x000000013149e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-7"" #46 daemon prio=5 os_prio=31 tid=0x00007fb76e8f5000 nid=0x5807 waiting on condition [0x000000013139b000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Nat",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:30414,Performance,concurren,concurrent,30414,".locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-8"" #47 daemon prio=5 os_prio=31 tid=0x00007fb76b518000 nid=0x8703 waiting on condition [0x000000013149e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-7"" #46 daemon prio=5 os_prio=31 tid=0x00007fb76e8f5000 nid=0x5807 waiting on condition [0x000000013139b000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concur",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:30484,Performance,concurren,concurrent,30484,"Synchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-8"" #47 daemon prio=5 os_prio=31 tid=0x00007fb76b518000 nid=0x8703 waiting on condition [0x000000013149e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-7"" #46 daemon prio=5 os_prio=31 tid=0x00007fb76e8f5000 nid=0x5807 waiting on condition [0x000000013139b000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:30883,Performance,concurren,concurrent,30883,"l.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-8"" #47 daemon prio=5 os_prio=31 tid=0x00007fb76b518000 nid=0x8703 waiting on condition [0x000000013149e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-7"" #46 daemon prio=5 os_prio=31 tid=0x00007fb76e8f5000 nid=0x5807 waiting on condition [0x000000013139b000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayB",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:30965,Performance,concurren,concurrent,30965,"til.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-8"" #47 daemon prio=5 os_prio=31 tid=0x00007fb76b518000 nid=0x8703 waiting on condition [0x000000013149e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-7"" #46 daemon prio=5 os_prio=31 tid=0x00007fb76e8f5000 nid=0x5807 waiting on condition [0x000000013139b000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.Th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:31049,Performance,concurren,concurrent,31049,"ang.Thread.run(Thread.java:745). ""db-8"" #47 daemon prio=5 os_prio=31 tid=0x00007fb76b518000 nid=0x8703 waiting on condition [0x000000013149e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-7"" #46 daemon prio=5 os_prio=31 tid=0x00007fb76e8f5000 nid=0x5807 waiting on condition [0x000000013139b000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.Thre",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:31414,Performance,concurren,concurrent,31414,"rrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-7"" #46 daemon prio=5 os_prio=31 tid=0x00007fb76e8f5000 nid=0x5807 waiting on condition [0x000000013139b000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-6"" #45 daemon prio=5 os_prio=31 tid=0x00007fb76e8dd000 nid=0x5507 waiting on condition [0x0000000131298000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Nat",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:31489,Performance,concurren,concurrent,31489,".locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-7"" #46 daemon prio=5 os_prio=31 tid=0x00007fb76e8f5000 nid=0x5807 waiting on condition [0x000000013139b000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-6"" #45 daemon prio=5 os_prio=31 tid=0x00007fb76e8dd000 nid=0x5507 waiting on condition [0x0000000131298000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concur",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:31559,Performance,concurren,concurrent,31559,"Synchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-7"" #46 daemon prio=5 os_prio=31 tid=0x00007fb76e8f5000 nid=0x5807 waiting on condition [0x000000013139b000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-6"" #45 daemon prio=5 os_prio=31 tid=0x00007fb76e8dd000 nid=0x5507 waiting on condition [0x0000000131298000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:31958,Performance,concurren,concurrent,31958,"l.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-7"" #46 daemon prio=5 os_prio=31 tid=0x00007fb76e8f5000 nid=0x5807 waiting on condition [0x000000013139b000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-6"" #45 daemon prio=5 os_prio=31 tid=0x00007fb76e8dd000 nid=0x5507 waiting on condition [0x0000000131298000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayB",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:32040,Performance,concurren,concurrent,32040,"til.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-7"" #46 daemon prio=5 os_prio=31 tid=0x00007fb76e8f5000 nid=0x5807 waiting on condition [0x000000013139b000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-6"" #45 daemon prio=5 os_prio=31 tid=0x00007fb76e8dd000 nid=0x5507 waiting on condition [0x0000000131298000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.Th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:32124,Performance,concurren,concurrent,32124,"ang.Thread.run(Thread.java:745). ""db-7"" #46 daemon prio=5 os_prio=31 tid=0x00007fb76e8f5000 nid=0x5807 waiting on condition [0x000000013139b000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-6"" #45 daemon prio=5 os_prio=31 tid=0x00007fb76e8dd000 nid=0x5507 waiting on condition [0x0000000131298000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.Thre",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:32489,Performance,concurren,concurrent,32489,"rrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-6"" #45 daemon prio=5 os_prio=31 tid=0x00007fb76e8dd000 nid=0x5507 waiting on condition [0x0000000131298000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-5"" #44 daemon prio=5 os_prio=31 tid=0x00007fb76b517800 nid=0x3b0b waiting on condition [0x0000000131195000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Nat",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:32564,Performance,concurren,concurrent,32564,".locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-6"" #45 daemon prio=5 os_prio=31 tid=0x00007fb76e8dd000 nid=0x5507 waiting on condition [0x0000000131298000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-5"" #44 daemon prio=5 os_prio=31 tid=0x00007fb76b517800 nid=0x3b0b waiting on condition [0x0000000131195000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concur",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:32634,Performance,concurren,concurrent,32634,"Synchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-6"" #45 daemon prio=5 os_prio=31 tid=0x00007fb76e8dd000 nid=0x5507 waiting on condition [0x0000000131298000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-5"" #44 daemon prio=5 os_prio=31 tid=0x00007fb76b517800 nid=0x3b0b waiting on condition [0x0000000131195000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:33033,Performance,concurren,concurrent,33033,"l.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-6"" #45 daemon prio=5 os_prio=31 tid=0x00007fb76e8dd000 nid=0x5507 waiting on condition [0x0000000131298000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-5"" #44 daemon prio=5 os_prio=31 tid=0x00007fb76b517800 nid=0x3b0b waiting on condition [0x0000000131195000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayB",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:33115,Performance,concurren,concurrent,33115,"til.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-6"" #45 daemon prio=5 os_prio=31 tid=0x00007fb76e8dd000 nid=0x5507 waiting on condition [0x0000000131298000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-5"" #44 daemon prio=5 os_prio=31 tid=0x00007fb76b517800 nid=0x3b0b waiting on condition [0x0000000131195000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.Th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:33199,Performance,concurren,concurrent,33199,"ang.Thread.run(Thread.java:745). ""db-6"" #45 daemon prio=5 os_prio=31 tid=0x00007fb76e8dd000 nid=0x5507 waiting on condition [0x0000000131298000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-5"" #44 daemon prio=5 os_prio=31 tid=0x00007fb76b517800 nid=0x3b0b waiting on condition [0x0000000131195000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.Thre",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:33564,Performance,concurren,concurrent,33564,"rrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-5"" #44 daemon prio=5 os_prio=31 tid=0x00007fb76b517800 nid=0x3b0b waiting on condition [0x0000000131195000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-2"" #43 prio=5 os_prio=31 tid=0x00007fb76e8ee000 nid=0x3f0b waiting on condition [0x000000012ee35000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:33639,Performance,concurren,concurrent,33639,".locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-5"" #44 daemon prio=5 os_prio=31 tid=0x00007fb76b517800 nid=0x3b0b waiting on condition [0x0000000131195000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-2"" #43 prio=5 os_prio=31 tid=0x00007fb76e8ee000 nid=0x3f0b waiting on condition [0x000000012ee35000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.co",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:33709,Performance,concurren,concurrent,33709,"Synchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-5"" #44 daemon prio=5 os_prio=31 tid=0x00007fb76b517800 nid=0x3b0b waiting on condition [0x0000000131195000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-2"" #43 prio=5 os_prio=31 tid=0x00007fb76e8ee000 nid=0x3f0b waiting on condition [0x000000012ee35000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.ut",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:34108,Performance,concurren,concurrent,34108,"l.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-5"" #44 daemon prio=5 os_prio=31 tid=0x00007fb76b517800 nid=0x3b0b waiting on condition [0x0000000131195000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-2"" #43 prio=5 os_prio=31 tid=0x00007fb76e8ee000 nid=0x3f0b waiting on condition [0x000000012ee35000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Thread",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:34190,Performance,concurren,concurrent,34190,"til.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-5"" #44 daemon prio=5 os_prio=31 tid=0x00007fb76b517800 nid=0x3b0b waiting on condition [0x0000000131195000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-2"" #43 prio=5 os_prio=31 tid=0x00007fb76e8ee000 nid=0x3f0b waiting on condition [0x000000012ee35000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(Thr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:34274,Performance,concurren,concurrent,34274,"ang.Thread.run(Thread.java:745). ""db-5"" #44 daemon prio=5 os_prio=31 tid=0x00007fb76b517800 nid=0x3b0b waiting on condition [0x0000000131195000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-2"" #43 prio=5 os_prio=31 tid=0x00007fb76e8ee000 nid=0x3f0b waiting on condition [0x000000012ee35000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""_jprofiler_con",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:34643,Performance,concurren,concurrent,34643,"t.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-2"" #43 prio=5 os_prio=31 tid=0x00007fb76e8ee000 nid=0x3f0b waiting on condition [0x000000012ee35000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""_jprofiler_control_sampler"" #34 daemon prio=9 os_prio=31 tid=0x00007fb771044800 nid=0x6307 waiting on condition [0x000000012ab3a000]; java.lang.Thread.State: TIMED_WAITING (sleeping); at java.lang.Thread.sleep(Native Method); at com.jprofiler.agent.probe.y.run(ejt:1030). ""_jprofiler_native_sampler"" #37 daemon prio=10 os_prio=31 tid=0x00007fb76d269000 nid=0x5d07 runnable [0x0000000",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:34718,Performance,concurren,concurrent,34718,"ks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-2"" #43 prio=5 os_prio=31 tid=0x00007fb76e8ee000 nid=0x3f0b waiting on condition [0x000000012ee35000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""_jprofiler_control_sampler"" #34 daemon prio=9 os_prio=31 tid=0x00007fb771044800 nid=0x6307 waiting on condition [0x000000012ab3a000]; java.lang.Thread.State: TIMED_WAITING (sleeping); at java.lang.Thread.sleep(Native Method); at com.jprofiler.agent.probe.y.run(ejt:1030). ""_jprofiler_native_sampler"" #37 daemon prio=10 os_prio=31 tid=0x00007fb76d269000 nid=0x5d07 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""_jprofiler_native_comm"" #36 ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:34788,Performance,concurren,concurrent,34788,"hronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-2"" #43 prio=5 os_prio=31 tid=0x00007fb76e8ee000 nid=0x3f0b waiting on condition [0x000000012ee35000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""_jprofiler_control_sampler"" #34 daemon prio=9 os_prio=31 tid=0x00007fb771044800 nid=0x6307 waiting on condition [0x000000012ab3a000]; java.lang.Thread.State: TIMED_WAITING (sleeping); at java.lang.Thread.sleep(Native Method); at com.jprofiler.agent.probe.y.run(ejt:1030). ""_jprofiler_native_sampler"" #37 daemon prio=10 os_prio=31 tid=0x00007fb76d269000 nid=0x5d07 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""_jprofiler_native_comm"" #36 daemon prio=5 os_prio=31 tid=0x00007fb770d7d000 nid=0x3707 runnable [0",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:34906,Performance,concurren,concurrent,34906,"); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-2"" #43 prio=5 os_prio=31 tid=0x00007fb76e8ee000 nid=0x3f0b waiting on condition [0x000000012ee35000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""_jprofiler_control_sampler"" #34 daemon prio=9 os_prio=31 tid=0x00007fb771044800 nid=0x6307 waiting on condition [0x000000012ab3a000]; java.lang.Thread.State: TIMED_WAITING (sleeping); at java.lang.Thread.sleep(Native Method); at com.jprofiler.agent.probe.y.run(ejt:1030). ""_jprofiler_native_sampler"" #37 daemon prio=10 os_prio=31 tid=0x00007fb76d269000 nid=0x5d07 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""_jprofiler_native_comm"" #36 daemon prio=5 os_prio=31 tid=0x00007fb770d7d000 nid=0x3707 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""_jprofiler_sampler"" #35 daemon prio=10 os_prio=31 tid=0x00007fb",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:34986,Performance,concurren,concurrent,34986,"ingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-2"" #43 prio=5 os_prio=31 tid=0x00007fb76e8ee000 nid=0x3f0b waiting on condition [0x000000012ee35000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""_jprofiler_control_sampler"" #34 daemon prio=9 os_prio=31 tid=0x00007fb771044800 nid=0x6307 waiting on condition [0x000000012ab3a000]; java.lang.Thread.State: TIMED_WAITING (sleeping); at java.lang.Thread.sleep(Native Method); at com.jprofiler.agent.probe.y.run(ejt:1030). ""_jprofiler_native_sampler"" #37 daemon prio=10 os_prio=31 tid=0x00007fb76d269000 nid=0x5d07 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""_jprofiler_native_comm"" #36 daemon prio=5 os_prio=31 tid=0x00007fb770d7d000 nid=0x3707 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""_jprofiler_sampler"" #35 daemon prio=10 os_prio=31 tid=0x00007fb771027000 nid=0x7707 waiting on condition [0x000000012cb95000]; java.lang.Thread",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:35068,Performance,concurren,concurrent,35068,"kingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-2"" #43 prio=5 os_prio=31 tid=0x00007fb76e8ee000 nid=0x3f0b waiting on condition [0x000000012ee35000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""_jprofiler_control_sampler"" #34 daemon prio=9 os_prio=31 tid=0x00007fb771044800 nid=0x6307 waiting on condition [0x000000012ab3a000]; java.lang.Thread.State: TIMED_WAITING (sleeping); at java.lang.Thread.sleep(Native Method); at com.jprofiler.agent.probe.y.run(ejt:1030). ""_jprofiler_native_sampler"" #37 daemon prio=10 os_prio=31 tid=0x00007fb76d269000 nid=0x5d07 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""_jprofiler_native_comm"" #36 daemon prio=5 os_prio=31 tid=0x00007fb770d7d000 nid=0x3707 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""_jprofiler_sampler"" #35 daemon prio=10 os_prio=31 tid=0x00007fb771027000 nid=0x7707 waiting on condition [0x000000012cb95000]; java.lang.Thread.State: TIMED_WAITING (sleeping); at java.lang.Thread.sleep(Native Method); at com",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:35152,Performance,concurren,concurrent,35152,"xecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-2"" #43 prio=5 os_prio=31 tid=0x00007fb76e8ee000 nid=0x3f0b waiting on condition [0x000000012ee35000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""_jprofiler_control_sampler"" #34 daemon prio=9 os_prio=31 tid=0x00007fb771044800 nid=0x6307 waiting on condition [0x000000012ab3a000]; java.lang.Thread.State: TIMED_WAITING (sleeping); at java.lang.Thread.sleep(Native Method); at com.jprofiler.agent.probe.y.run(ejt:1030). ""_jprofiler_native_sampler"" #37 daemon prio=10 os_prio=31 tid=0x00007fb76d269000 nid=0x5d07 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""_jprofiler_native_comm"" #36 daemon prio=5 os_prio=31 tid=0x00007fb770d7d000 nid=0x3707 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""_jprofiler_sampler"" #35 daemon prio=10 os_prio=31 tid=0x00007fb771027000 nid=0x7707 waiting on condition [0x000000012cb95000]; java.lang.Thread.State: TIMED_WAITING (sleeping); at java.lang.Thread.sleep(Native Method); at com.jprofiler.agent.sampler.Sampler.run(ejt:84). ""Attach Listener"" #33 daemon prio=9 os",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:36518,Performance,concurren,concurrent,36518,"run(ejt:1030). ""_jprofiler_native_sampler"" #37 daemon prio=10 os_prio=31 tid=0x00007fb76d269000 nid=0x5d07 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""_jprofiler_native_comm"" #36 daemon prio=5 os_prio=31 tid=0x00007fb770d7d000 nid=0x3707 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""_jprofiler_sampler"" #35 daemon prio=10 os_prio=31 tid=0x00007fb771027000 nid=0x7707 waiting on condition [0x000000012cb95000]; java.lang.Thread.State: TIMED_WAITING (sleeping); at java.lang.Thread.sleep(Native Method); at com.jprofiler.agent.sampler.Sampler.run(ejt:84). ""Attach Listener"" #33 daemon prio=9 os_prio=31 tid=0x00007fb76e3e7800 nid=0x8507 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""db-4"" #31 daemon prio=5 os_prio=31 tid=0x00007fb7706e2000 nid=0x8303 waiting on condition [0x000000012ca92000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-3"" #29 daemon prio=5 os_prio=31 tid=0x00007fb76f4b7000 nid=0x7f03 waiting on condition [0x000000012c88c000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:36593,Performance,concurren,concurrent,36593,"d=0x00007fb76d269000 nid=0x5d07 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""_jprofiler_native_comm"" #36 daemon prio=5 os_prio=31 tid=0x00007fb770d7d000 nid=0x3707 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""_jprofiler_sampler"" #35 daemon prio=10 os_prio=31 tid=0x00007fb771027000 nid=0x7707 waiting on condition [0x000000012cb95000]; java.lang.Thread.State: TIMED_WAITING (sleeping); at java.lang.Thread.sleep(Native Method); at com.jprofiler.agent.sampler.Sampler.run(ejt:84). ""Attach Listener"" #33 daemon prio=9 os_prio=31 tid=0x00007fb76e3e7800 nid=0x8507 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""db-4"" #31 daemon prio=5 os_prio=31 tid=0x00007fb7706e2000 nid=0x8303 waiting on condition [0x000000012ca92000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-3"" #29 daemon prio=5 os_prio=31 tid=0x00007fb76f4b7000 nid=0x7f03 waiting on condition [0x000000012c88c000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueued",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:36663,Performance,concurren,concurrent,36663,"ng.Thread.State: RUNNABLE. ""_jprofiler_native_comm"" #36 daemon prio=5 os_prio=31 tid=0x00007fb770d7d000 nid=0x3707 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""_jprofiler_sampler"" #35 daemon prio=10 os_prio=31 tid=0x00007fb771027000 nid=0x7707 waiting on condition [0x000000012cb95000]; java.lang.Thread.State: TIMED_WAITING (sleeping); at java.lang.Thread.sleep(Native Method); at com.jprofiler.agent.sampler.Sampler.run(ejt:84). ""Attach Listener"" #33 daemon prio=9 os_prio=31 tid=0x00007fb76e3e7800 nid=0x8507 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""db-4"" #31 daemon prio=5 os_prio=31 tid=0x00007fb7706e2000 nid=0x8303 waiting on condition [0x000000012ca92000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-3"" #29 daemon prio=5 os_prio=31 tid=0x00007fb76f4b7000 nid=0x7f03 waiting on condition [0x000000012c88c000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSuppo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:37062,Performance,concurren,concurrent,37062," at com.jprofiler.agent.sampler.Sampler.run(ejt:84). ""Attach Listener"" #33 daemon prio=9 os_prio=31 tid=0x00007fb76e3e7800 nid=0x8507 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""db-4"" #31 daemon prio=5 os_prio=31 tid=0x00007fb7706e2000 nid=0x8303 waiting on condition [0x000000012ca92000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-3"" #29 daemon prio=5 os_prio=31 tid=0x00007fb76f4b7000 nid=0x7f03 waiting on condition [0x000000012c88c000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(Managed",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:37144,Performance,concurren,concurrent,37144,"prio=9 os_prio=31 tid=0x00007fb76e3e7800 nid=0x8507 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""db-4"" #31 daemon prio=5 os_prio=31 tid=0x00007fb7706e2000 nid=0x8303 waiting on condition [0x000000012ca92000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-3"" #29 daemon prio=5 os_prio=31 tid=0x00007fb76f4b7000 nid=0x7f03 waiting on condition [0x000000012c88c000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:37209,Performance,concurren,concurrent,37209,"000000000000000]; java.lang.Thread.State: RUNNABLE. ""db-4"" #31 daemon prio=5 os_prio=31 tid=0x00007fb7706e2000 nid=0x8303 waiting on condition [0x000000012ca92000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-3"" #29 daemon prio=5 os_prio=31 tid=0x00007fb76f4b7000 nid=0x7f03 waiting on condition [0x000000012c88c000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPool",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:37568,Performance,concurren,concurrent,37568,"ject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-3"" #29 daemon prio=5 os_prio=31 tid=0x00007fb76f4b7000 nid=0x7f03 waiting on condition [0x000000012c88c000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-2"" #28 daemon prio=5 os_prio=31 tid=0x00007fb7708d7800 nid=0x7d03 waiting on condition [0x000000012c789000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:37643,Performance,concurren,concurrent,37643,"; at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-3"" #29 daemon prio=5 os_prio=31 tid=0x00007fb76f4b7000 nid=0x7f03 waiting on condition [0x000000012c88c000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-2"" #28 daemon prio=5 os_prio=31 tid=0x00007fb7708d7800 nid=0x7d03 waiting on condition [0x000000012c789000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueued",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:37713,Performance,concurren,concurrent,37713,"ject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-3"" #29 daemon prio=5 os_prio=31 tid=0x00007fb76f4b7000 nid=0x7f03 waiting on condition [0x000000012c88c000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-2"" #28 daemon prio=5 os_prio=31 tid=0x00007fb7708d7800 nid=0x7d03 waiting on condition [0x000000012c789000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSuppo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:38112,Performance,concurren,concurrent,38112,"r.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-3"" #29 daemon prio=5 os_prio=31 tid=0x00007fb76f4b7000 nid=0x7f03 waiting on condition [0x000000012c88c000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-2"" #28 daemon prio=5 os_prio=31 tid=0x00007fb7708d7800 nid=0x7d03 waiting on condition [0x000000012c789000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(Managed",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:38194,Performance,concurren,concurrent,38194,"java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-3"" #29 daemon prio=5 os_prio=31 tid=0x00007fb76f4b7000 nid=0x7f03 waiting on condition [0x000000012c88c000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-2"" #28 daemon prio=5 os_prio=31 tid=0x00007fb7708d7800 nid=0x7d03 waiting on condition [0x000000012c789000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:38259,Performance,concurren,concurrent,38259,"utor.java:617); at java.lang.Thread.run(Redefined). ""db-3"" #29 daemon prio=5 os_prio=31 tid=0x00007fb76f4b7000 nid=0x7f03 waiting on condition [0x000000012c88c000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-2"" #28 daemon prio=5 os_prio=31 tid=0x00007fb7708d7800 nid=0x7d03 waiting on condition [0x000000012c789000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPool",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:38618,Performance,concurren,concurrent,38618,"ject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-2"" #28 daemon prio=5 os_prio=31 tid=0x00007fb7708d7800 nid=0x7d03 waiting on condition [0x000000012c789000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""pool-1-thread-1"" #27 prio=5 os_prio=31 tid=0x00007fb76f4b6000 nid=0x7b03 waiting on condition [0x000000012b643000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parkin",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:38693,Performance,concurren,concurrent,38693,"; at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-2"" #28 daemon prio=5 os_prio=31 tid=0x00007fb7708d7800 nid=0x7d03 waiting on condition [0x000000012c789000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""pool-1-thread-1"" #27 prio=5 os_prio=31 tid=0x00007fb76f4b6000 nid=0x7b03 waiting on condition [0x000000012b643000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:38763,Performance,concurren,concurrent,38763,"ject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-2"" #28 daemon prio=5 os_prio=31 tid=0x00007fb7708d7800 nid=0x7d03 waiting on condition [0x000000012c789000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""pool-1-thread-1"" #27 prio=5 os_prio=31 tid=0x00007fb76f4b6000 nid=0x7b03 waiting on condition [0x000000012b643000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockS",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:39162,Performance,concurren,concurrent,39162,"r.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-2"" #28 daemon prio=5 os_prio=31 tid=0x00007fb7708d7800 nid=0x7d03 waiting on condition [0x000000012c789000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""pool-1-thread-1"" #27 prio=5 os_prio=31 tid=0x00007fb76f4b6000 nid=0x7b03 waiting on condition [0x000000012b643000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concur",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:39244,Performance,concurren,concurrent,39244,"java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-2"" #28 daemon prio=5 os_prio=31 tid=0x00007fb7708d7800 nid=0x7d03 waiting on condition [0x000000012c789000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""pool-1-thread-1"" #27 prio=5 os_prio=31 tid=0x00007fb76f4b6000 nid=0x7b03 waiting on condition [0x000000012b643000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thre",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:39309,Performance,concurren,concurrent,39309,"utor.java:617); at java.lang.Thread.run(Redefined). ""db-2"" #28 daemon prio=5 os_prio=31 tid=0x00007fb7708d7800 nid=0x7d03 waiting on condition [0x000000012c789000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""pool-1-thread-1"" #27 prio=5 os_prio=31 tid=0x00007fb76f4b6000 nid=0x7b03 waiting on condition [0x000000012b643000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-1"" #26 daemon prio=5 os_prio=31 tid=0x0000",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:39672,Performance,concurren,concurrent,39672,"); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""pool-1-thread-1"" #27 prio=5 os_prio=31 tid=0x00007fb76f4b6000 nid=0x7b03 waiting on condition [0x000000012b643000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-1"" #26 daemon prio=5 os_prio=31 tid=0x00007fb76b442000 nid=0x7903 waiting on condition [0x000000012d905000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.l",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:39747,Performance,concurren,concurrent,39747," java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""pool-1-thread-1"" #27 prio=5 os_prio=31 tid=0x00007fb76f4b6000 nid=0x7b03 waiting on condition [0x000000012b643000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-1"" #26 daemon prio=5 os_prio=31 tid=0x00007fb76b442000 nid=0x7903 waiting on condition [0x000000012d905000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchro",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:39817,Performance,concurren,concurrent,39817,".await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""pool-1-thread-1"" #27 prio=5 os_prio=31 tid=0x00007fb76f4b6000 nid=0x7b03 waiting on condition [0x000000012b643000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-1"" #26 daemon prio=5 os_prio=31 tid=0x00007fb76b442000 nid=0x7903 waiting on condition [0x000000012d905000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$tak",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:39935,Performance,concurren,concurrent,39935,"ayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""pool-1-thread-1"" #27 prio=5 os_prio=31 tid=0x00007fb76f4b6000 nid=0x7b03 waiting on condition [0x000000012b643000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-1"" #26 daemon prio=5 os_prio=31 tid=0x00007fb76b442000 nid=0x7903 waiting on condition [0x000000012d905000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:40015,Performance,concurren,concurrent,40015,"uptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""pool-1-thread-1"" #27 prio=5 os_prio=31 tid=0x00007fb76f4b6000 nid=0x7b03 waiting on condition [0x000000012b643000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-1"" #26 daemon prio=5 os_prio=31 tid=0x00007fb76b442000 nid=0x7903 waiting on condition [0x000000012d905000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(Managed",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:40097,Performance,concurren,concurrent,40097,"eue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""pool-1-thread-1"" #27 prio=5 os_prio=31 tid=0x00007fb76f4b6000 nid=0x7b03 waiting on condition [0x000000012b643000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-1"" #26 daemon prio=5 os_prio=31 tid=0x00007fb76b442000 nid=0x7903 waiting on condition [0x000000012d905000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:40162,Performance,concurren,concurrent,40162,"rrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""pool-1-thread-1"" #27 prio=5 os_prio=31 tid=0x00007fb76f4b6000 nid=0x7b03 waiting on condition [0x000000012b643000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-1"" #26 daemon prio=5 os_prio=31 tid=0x00007fb76b442000 nid=0x7903 waiting on condition [0x000000012d905000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPool",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:40521,Performance,concurren,concurrent,40521,"3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-1"" #26 daemon prio=5 os_prio=31 tid=0x00007fb76b442000 nid=0x7903 waiting on condition [0x000000012d905000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Hikari Housekeeping Timer (pool db)"" #24 daemon prio=5 os_prio=31 tid=0x00007fb76d88f000 nid=0x7503 waiting on condition [0x000000012cebb000]; java.lang.Thread.State: TIMED_WAITING (parking); at sun.misc.Uns",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:40596,Performance,concurren,concurrent,40596,"ative Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-1"" #26 daemon prio=5 os_prio=31 tid=0x00007fb76b442000 nid=0x7903 waiting on condition [0x000000012d905000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Hikari Housekeeping Timer (pool db)"" #24 daemon prio=5 os_prio=31 tid=0x00007fb76d88f000 nid=0x7503 waiting on condition [0x000000012cebb000]; java.lang.Thread.State: TIMED_WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0623fc0> (a java",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:40666,Performance,concurren,concurrent,40666,".concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-1"" #26 daemon prio=5 os_prio=31 tid=0x00007fb76b442000 nid=0x7903 waiting on condition [0x000000012d905000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Hikari Housekeeping Timer (pool db)"" #24 daemon prio=5 os_prio=31 tid=0x00007fb76d88f000 nid=0x7503 waiting on condition [0x000000012cebb000]; java.lang.Thread.State: TIMED_WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0623fc0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:41065,Performance,concurren,concurrent,41065,"r.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-1"" #26 daemon prio=5 os_prio=31 tid=0x00007fb76b442000 nid=0x7903 waiting on condition [0x000000012d905000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Hikari Housekeeping Timer (pool db)"" #24 daemon prio=5 os_prio=31 tid=0x00007fb76d88f000 nid=0x7503 waiting on condition [0x000000012cebb000]; java.lang.Thread.State: TIMED_WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0623fc0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThread",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:41147,Performance,concurren,concurrent,41147,"java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-1"" #26 daemon prio=5 os_prio=31 tid=0x00007fb76b442000 nid=0x7903 waiting on condition [0x000000012d905000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Hikari Housekeeping Timer (pool db)"" #24 daemon prio=5 os_prio=31 tid=0x00007fb76d88f000 nid=0x7503 waiting on condition [0x000000012cebb000]; java.lang.Thread.State: TIMED_WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0623fc0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadP",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:41212,Performance,concurren,concurrent,41212,"utor.java:617); at java.lang.Thread.run(Redefined). ""db-1"" #26 daemon prio=5 os_prio=31 tid=0x00007fb76b442000 nid=0x7903 waiting on condition [0x000000012d905000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Hikari Housekeeping Timer (pool db)"" #24 daemon prio=5 os_prio=31 tid=0x00007fb76d88f000 nid=0x7503 waiting on condition [0x000000012cebb000]; java.lang.Thread.State: TIMED_WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0623fc0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecuto",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:41608,Performance,concurren,concurrent,41608,"LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Hikari Housekeeping Timer (pool db)"" #24 daemon prio=5 os_prio=31 tid=0x00007fb76d88f000 nid=0x7503 waiting on condition [0x000000012cebb000]; java.lang.Thread.State: TIMED_WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0623fc0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.io.pinned-dispatcher-7"" #23 prio=5 os_prio=31 tid=0x00007fb76b450800 nid=0x7303 runnable [0x000000012cdb8000]; java.lang.Thread.State: RUNNABLE; at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method); at sun.nio.ch.KQueueArrayWra",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:41683,Performance,concurren,concurrent,41683,"actQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Hikari Housekeeping Timer (pool db)"" #24 daemon prio=5 os_prio=31 tid=0x00007fb76d88f000 nid=0x7503 waiting on condition [0x000000012cebb000]; java.lang.Thread.State: TIMED_WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0623fc0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.io.pinned-dispatcher-7"" #23 prio=5 os_prio=31 tid=0x00007fb76b450800 nid=0x7303 runnable [0x000000012cdb8000]; java.lang.Thread.State: RUNNABLE; at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method); at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198); at sun.nio.ch.KQueueSelectorImpl.do",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:41758,Performance,concurren,concurrent,41758,":2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Hikari Housekeeping Timer (pool db)"" #24 daemon prio=5 os_prio=31 tid=0x00007fb76d88f000 nid=0x7503 waiting on condition [0x000000012cebb000]; java.lang.Thread.State: TIMED_WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0623fc0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.io.pinned-dispatcher-7"" #23 prio=5 os_prio=31 tid=0x00007fb76b450800 nid=0x7303 runnable [0x000000012cdb8000]; java.lang.Thread.State: RUNNABLE; at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method); at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198); at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:103); at sun.nio.ch.SelectorImpl.lockAndDoSe",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:41881,Performance,concurren,concurrent,41881,"anagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Hikari Housekeeping Timer (pool db)"" #24 daemon prio=5 os_prio=31 tid=0x00007fb76d88f000 nid=0x7503 waiting on condition [0x000000012cebb000]; java.lang.Thread.State: TIMED_WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0623fc0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.io.pinned-dispatcher-7"" #23 prio=5 os_prio=31 tid=0x00007fb76b450800 nid=0x7303 runnable [0x000000012cdb8000]; java.lang.Thread.State: RUNNABLE; at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method); at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198); at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:103); at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86); - locked <0x00000006c0612e70> (a sun.nio.ch.Util$2); - locked <0x00000006c0612e80> (a java.util",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:41995,Performance,concurren,concurrent,41995,"ingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Hikari Housekeeping Timer (pool db)"" #24 daemon prio=5 os_prio=31 tid=0x00007fb76d88f000 nid=0x7503 waiting on condition [0x000000012cebb000]; java.lang.Thread.State: TIMED_WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0623fc0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.io.pinned-dispatcher-7"" #23 prio=5 os_prio=31 tid=0x00007fb76b450800 nid=0x7303 runnable [0x000000012cdb8000]; java.lang.Thread.State: RUNNABLE; at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method); at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198); at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:103); at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86); - locked <0x00000006c0612e70> (a sun.nio.ch.Util$2); - locked <0x00000006c0612e80> (a java.util.Collections$UnmodifiableSet); - locked <0x00000006c0612e20> (a sun.nio.ch.KQueueSelectorImpl); at sun.nio.ch.Sele",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:42108,Performance,concurren,concurrent,42108,"Executor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Hikari Housekeeping Timer (pool db)"" #24 daemon prio=5 os_prio=31 tid=0x00007fb76d88f000 nid=0x7503 waiting on condition [0x000000012cebb000]; java.lang.Thread.State: TIMED_WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0623fc0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.io.pinned-dispatcher-7"" #23 prio=5 os_prio=31 tid=0x00007fb76b450800 nid=0x7303 runnable [0x000000012cdb8000]; java.lang.Thread.State: RUNNABLE; at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method); at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198); at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:103); at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86); - locked <0x00000006c0612e70> (a sun.nio.ch.Util$2); - locked <0x00000006c0612e80> (a java.util.Collections$UnmodifiableSet); - locked <0x00000006c0612e20> (a sun.nio.ch.KQueueSelectorImpl); at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97); at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101); at akka.io.Selec",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:42190,Performance,concurren,concurrent,42190,"d); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Hikari Housekeeping Timer (pool db)"" #24 daemon prio=5 os_prio=31 tid=0x00007fb76d88f000 nid=0x7503 waiting on condition [0x000000012cebb000]; java.lang.Thread.State: TIMED_WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0623fc0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.io.pinned-dispatcher-7"" #23 prio=5 os_prio=31 tid=0x00007fb76b450800 nid=0x7303 runnable [0x000000012cdb8000]; java.lang.Thread.State: RUNNABLE; at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method); at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198); at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:103); at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86); - locked <0x00000006c0612e70> (a sun.nio.ch.Util$2); - locked <0x00000006c0612e80> (a java.util.Collections$UnmodifiableSet); - locked <0x00000006c0612e20> (a sun.nio.ch.KQueueSelectorImpl); at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97); at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101); at akka.io.SelectionHandler$ChannelRegistryImpl$$anon$3.tryRun(SelectionHandler.scala:114); at akk",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:42255,Performance,concurren,concurrent,42255,"oolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Hikari Housekeeping Timer (pool db)"" #24 daemon prio=5 os_prio=31 tid=0x00007fb76d88f000 nid=0x7503 waiting on condition [0x000000012cebb000]; java.lang.Thread.State: TIMED_WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0623fc0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.io.pinned-dispatcher-7"" #23 prio=5 os_prio=31 tid=0x00007fb76b450800 nid=0x7303 runnable [0x000000012cdb8000]; java.lang.Thread.State: RUNNABLE; at sun.nio.ch.KQueueArrayWrapper.kevent0(Native Method); at sun.nio.ch.KQueueArrayWrapper.poll(KQueueArrayWrapper.java:198); at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:103); at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86); - locked <0x00000006c0612e70> (a sun.nio.ch.Util$2); - locked <0x00000006c0612e80> (a java.util.Collections$UnmodifiableSet); - locked <0x00000006c0612e20> (a sun.nio.ch.KQueueSelectorImpl); at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97); at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101); at akka.io.SelectionHandler$ChannelRegistryImpl$$anon$3.tryRun(SelectionHandler.scala:114); at akka.io.SelectionHandler$ChannelRegistryImpl$Task.run(SelectionHandl",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:43633,Performance,concurren,concurrent,43633,"pper.java:198); at sun.nio.ch.KQueueSelectorImpl.doSelect(KQueueSelectorImpl.java:103); at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86); - locked <0x00000006c0612e70> (a sun.nio.ch.Util$2); - locked <0x00000006c0612e80> (a java.util.Collections$UnmodifiableSet); - locked <0x00000006c0612e20> (a sun.nio.ch.KQueueSelectorImpl); at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97); at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101); at akka.io.SelectionHandler$ChannelRegistryImpl$$anon$3.tryRun(SelectionHandler.scala:114); at akka.io.SelectionHandler$ChannelRegistryImpl$Task.run(SelectionHandler.scala:215); at akka.io.SelectionHandler$ChannelRegistryImpl$$anon$3.run(SelectionHandler.scala:147); at akka.util.SerializedSuspendableExecutionContext.run$1(SerializedSuspendableExecutionContext.scala:64); at akka.util.SerializedSuspendableExecutionContext.run(SerializedSuspendableExecutionContext.scala); at akka.dispatch.TaskInvocation.run(Redefined); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Abandoned connection cleanup thread"" #22 daemon prio=5 os_prio=31 tid=0x00007fb76a4f5800 nid=0x7103 in Object.wait() [0x000000012ccb5000]; java.lang.Thread.State: TIMED_WAITING (on object monitor); at java.lang.Object.wait(Native Method); at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143); - locked <0x00000006c0624180> (a java.lang.ref.ReferenceQueue$Lock); at com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43). ""ForkJoinPool-3-worker-15"" #19 daemon prio=5 os_prio=31 tid=0x00007fb76abaa800 nid=0x6b03 waiting on condition [0x000000012a1e3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0060ab0> (a java.util.concurrent.CountDownLatch$Sync); at java.util.concurrent.locks.LockSupport.park(Redefined)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:43698,Performance,concurren,concurrent,43698,"electorImpl.java:103); at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86); - locked <0x00000006c0612e70> (a sun.nio.ch.Util$2); - locked <0x00000006c0612e80> (a java.util.Collections$UnmodifiableSet); - locked <0x00000006c0612e20> (a sun.nio.ch.KQueueSelectorImpl); at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97); at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:101); at akka.io.SelectionHandler$ChannelRegistryImpl$$anon$3.tryRun(SelectionHandler.scala:114); at akka.io.SelectionHandler$ChannelRegistryImpl$Task.run(SelectionHandler.scala:215); at akka.io.SelectionHandler$ChannelRegistryImpl$$anon$3.run(SelectionHandler.scala:147); at akka.util.SerializedSuspendableExecutionContext.run$1(SerializedSuspendableExecutionContext.scala:64); at akka.util.SerializedSuspendableExecutionContext.run(SerializedSuspendableExecutionContext.scala); at akka.dispatch.TaskInvocation.run(Redefined); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Abandoned connection cleanup thread"" #22 daemon prio=5 os_prio=31 tid=0x00007fb76a4f5800 nid=0x7103 in Object.wait() [0x000000012ccb5000]; java.lang.Thread.State: TIMED_WAITING (on object monitor); at java.lang.Object.wait(Native Method); at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143); - locked <0x00000006c0624180> (a java.lang.ref.ReferenceQueue$Lock); at com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43). ""ForkJoinPool-3-worker-15"" #19 daemon prio=5 os_prio=31 tid=0x00007fb76abaa800 nid=0x6b03 waiting on condition [0x000000012a1e3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0060ab0> (a java.util.concurrent.CountDownLatch$Sync); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAn",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:44549,Performance,concurren,concurrent,44549,"onContext.scala); at akka.dispatch.TaskInvocation.run(Redefined); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Abandoned connection cleanup thread"" #22 daemon prio=5 os_prio=31 tid=0x00007fb76a4f5800 nid=0x7103 in Object.wait() [0x000000012ccb5000]; java.lang.Thread.State: TIMED_WAITING (on object monitor); at java.lang.Object.wait(Native Method); at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143); - locked <0x00000006c0624180> (a java.lang.ref.ReferenceQueue$Lock); at com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43). ""ForkJoinPool-3-worker-15"" #19 daemon prio=5 os_prio=31 tid=0x00007fb76abaa800 nid=0x6b03 waiting on condition [0x000000012a1e3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0060ab0> (a java.util.concurrent.CountDownLatch$Sync); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2$$anon$4.block(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinPool.managedBlock(Redefined); at scala.concurrent.impl.E",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:44595,Performance,concurren,concurrent,44595,"ion.run(Redefined); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Abandoned connection cleanup thread"" #22 daemon prio=5 os_prio=31 tid=0x00007fb76a4f5800 nid=0x7103 in Object.wait() [0x000000012ccb5000]; java.lang.Thread.State: TIMED_WAITING (on object monitor); at java.lang.Object.wait(Native Method); at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143); - locked <0x00000006c0624180> (a java.lang.ref.ReferenceQueue$Lock); at com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43). ""ForkJoinPool-3-worker-15"" #19 daemon prio=5 os_prio=31 tid=0x00007fb76abaa800 nid=0x6b03 waiting on condition [0x000000012a1e3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0060ab0> (a java.util.concurrent.CountDownLatch$Sync); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2$$anon$4.block(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinPool.managedBlock(Redefined); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:44654,Performance,concurren,concurrent,44654,"tor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Abandoned connection cleanup thread"" #22 daemon prio=5 os_prio=31 tid=0x00007fb76a4f5800 nid=0x7103 in Object.wait() [0x000000012ccb5000]; java.lang.Thread.State: TIMED_WAITING (on object monitor); at java.lang.Object.wait(Native Method); at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143); - locked <0x00000006c0624180> (a java.lang.ref.ReferenceQueue$Lock); at com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43). ""ForkJoinPool-3-worker-15"" #19 daemon prio=5 os_prio=31 tid=0x00007fb76abaa800 nid=0x6b03 waiting on condition [0x000000012a1e3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0060ab0> (a java.util.concurrent.CountDownLatch$Sync); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2$$anon$4.block(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinPool.managedBlock(Redefined); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2.blockOn(ExecutionContextImpl.scala:44); at scala.concurr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:44771,Performance,concurren,concurrent,44771,".lang.Thread.run(Redefined). ""Abandoned connection cleanup thread"" #22 daemon prio=5 os_prio=31 tid=0x00007fb76a4f5800 nid=0x7103 in Object.wait() [0x000000012ccb5000]; java.lang.Thread.State: TIMED_WAITING (on object monitor); at java.lang.Object.wait(Native Method); at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143); - locked <0x00000006c0624180> (a java.lang.ref.ReferenceQueue$Lock); at com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43). ""ForkJoinPool-3-worker-15"" #19 daemon prio=5 os_prio=31 tid=0x00007fb76abaa800 nid=0x6b03 waiting on condition [0x000000012a1e3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0060ab0> (a java.util.concurrent.CountDownLatch$Sync); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2$$anon$4.block(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinPool.managedBlock(Redefined); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2.blockOn(ExecutionContextImpl.scala:44); at scala.concurrent.Await$.ready(package.scala:169); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at akka.actor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:44895,Performance,concurren,concurrent,44895,"x7103 in Object.wait() [0x000000012ccb5000]; java.lang.Thread.State: TIMED_WAITING (on object monitor); at java.lang.Object.wait(Native Method); at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143); - locked <0x00000006c0624180> (a java.lang.ref.ReferenceQueue$Lock); at com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43). ""ForkJoinPool-3-worker-15"" #19 daemon prio=5 os_prio=31 tid=0x00007fb76abaa800 nid=0x6b03 waiting on condition [0x000000012a1e3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0060ab0> (a java.util.concurrent.CountDownLatch$Sync); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2$$anon$4.block(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinPool.managedBlock(Redefined); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2.blockOn(ExecutionContextImpl.scala:44); at scala.concurrent.Await$.ready(package.scala:169); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellS",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:45018,Performance,concurren,concurrent,45018,".wait(Native Method); at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143); - locked <0x00000006c0624180> (a java.lang.ref.ReferenceQueue$Lock); at com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43). ""ForkJoinPool-3-worker-15"" #19 daemon prio=5 os_prio=31 tid=0x00007fb76abaa800 nid=0x6b03 waiting on condition [0x000000012a1e3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0060ab0> (a java.util.concurrent.CountDownLatch$Sync); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2$$anon$4.block(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinPool.managedBlock(Redefined); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2.blockOn(ExecutionContextImpl.scala:44); at scala.concurrent.Await$.ready(package.scala:169); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala:29); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala); at scala.concurrent.Fu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:45223,Performance,concurren,concurrent,45223,"d.run(AbandonedConnectionCleanupThread.java:43). ""ForkJoinPool-3-worker-15"" #19 daemon prio=5 os_prio=31 tid=0x00007fb76abaa800 nid=0x6b03 waiting on condition [0x000000012a1e3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0060ab0> (a java.util.concurrent.CountDownLatch$Sync); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2$$anon$4.block(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinPool.managedBlock(Redefined); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2.blockOn(ExecutionContextImpl.scala:44); at scala.concurrent.Await$.ready(package.scala:169); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala:29); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:433); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala); at scala.concurrent.impl.CallbackRunnable.run(Redefined); at scala.concurrent.impl.Execut",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:45288,Performance,concurren,concurrent,45288,"worker-15"" #19 daemon prio=5 os_prio=31 tid=0x00007fb76abaa800 nid=0x6b03 waiting on condition [0x000000012a1e3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0060ab0> (a java.util.concurrent.CountDownLatch$Sync); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2$$anon$4.block(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinPool.managedBlock(Redefined); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2.blockOn(ExecutionContextImpl.scala:44); at scala.concurrent.Await$.ready(package.scala:169); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala:29); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:433); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala); at scala.concurrent.impl.CallbackRunnable.run(Redefined); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scal",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:45353,Performance,concurren,concurrent,45353,d=0x6b03 waiting on condition [0x000000012a1e3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0060ab0> (a java.util.concurrent.CountDownLatch$Sync); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2$$anon$4.block(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinPool.managedBlock(Redefined); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2.blockOn(ExecutionContextImpl.scala:44); at scala.concurrent.Await$.ready(package.scala:169); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala:29); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:433); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala); at scala.concurrent.impl.CallbackRunnable.run(Redefined); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:45471,Performance,concurren,concurrent,45471,(Native Method); - parking to wait for <0x00000006c0060ab0> (a java.util.concurrent.CountDownLatch$Sync); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2$$anon$4.block(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinPool.managedBlock(Redefined); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2.blockOn(ExecutionContextImpl.scala:44); at scala.concurrent.Await$.ready(package.scala:169); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala:29); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:433); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala); at scala.concurrent.impl.CallbackRunnable.run(Redefined); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java); at scala.concurrent.forkjoin.F,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:45538,Performance,concurren,concurrent,45538,.util.concurrent.CountDownLatch$Sync); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2$$anon$4.block(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinPool.managedBlock(Redefined); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2.blockOn(ExecutionContextImpl.scala:44); at scala.concurrent.Await$.ready(package.scala:169); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala:29); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:433); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala); at scala.concurrent.impl.CallbackRunnable.run(Redefined); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.Fork,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:45653,Performance,concurren,concurrent,45653,"urrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2$$anon$4.block(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinPool.managedBlock(Redefined); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2.blockOn(ExecutionContextImpl.scala:44); at scala.concurrent.Await$.ready(package.scala:169); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala:29); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:433); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala); at scala.concurrent.impl.CallbackRunnable.run(Redefined); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #14 prio=5 os_prio=31 tid=0x00007fb7",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:46011,Performance,concurren,concurrent,46011,"l.concurrent.CountDownLatch.await(CountDownLatch.java:231); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2$$anon$4.block(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinPool.managedBlock(Redefined); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2.blockOn(ExecutionContextImpl.scala:44); at scala.concurrent.Await$.ready(package.scala:169); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala:29); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:433); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala); at scala.concurrent.impl.CallbackRunnable.run(Redefined); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #14 prio=5 os_prio=31 tid=0x00007fb76aa14800 nid=0x6103 runnable [0x00000001295b3000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.actor.LightArrayRevolverScheduler.clock(Scheduler.scala:213); at akka.actor.LightArrayRevolverScheduler$$an",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:46082,Performance,concurren,concurrent,46082,"or.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2$$anon$4.block(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinPool.managedBlock(Redefined); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2.blockOn(ExecutionContextImpl.scala:44); at scala.concurrent.Await$.ready(package.scala:169); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala:29); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:433); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala); at scala.concurrent.impl.CallbackRunnable.run(Redefined); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #14 prio=5 os_prio=31 tid=0x00007fb76aa14800 nid=0x6103 runnable [0x00000001295b3000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.actor.LightArrayRevolverScheduler.clock(Scheduler.scala:213); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Redefined); at akka.actor.LightArrayRevolverScheduler$$an",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:46149,Performance,concurren,concurrent,46149,"ctor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2$$anon$4.block(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinPool.managedBlock(Redefined); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2.blockOn(ExecutionContextImpl.scala:44); at scala.concurrent.Await$.ready(package.scala:169); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala:29); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:433); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala); at scala.concurrent.impl.CallbackRunnable.run(Redefined); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #14 prio=5 os_prio=31 tid=0x00007fb76aa14800 nid=0x6103 runnable [0x00000001295b3000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.actor.LightArrayRevolverScheduler.clock(Scheduler.scala:213); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Redefined); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Redefined); at java.lang.Thread.run(Redefined). ""cromwell-",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:46207,Performance,concurren,concurrent,46207,"; at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2$$anon$4.block(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinPool.managedBlock(Redefined); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2.blockOn(ExecutionContextImpl.scala:44); at scala.concurrent.Await$.ready(package.scala:169); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala:29); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:433); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala); at scala.concurrent.impl.CallbackRunnable.run(Redefined); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #14 prio=5 os_prio=31 tid=0x00007fb76aa14800 nid=0x6103 runnable [0x00000001295b3000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.actor.LightArrayRevolverScheduler.clock(Scheduler.scala:213); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Redefined); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Redefined); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.actor.default-dispatcher-4"" #13 prio=5 os_prio",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:46307,Performance,concurren,concurrent,46307,"n$ready$1.apply(package.scala); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2$$anon$4.block(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinPool.managedBlock(Redefined); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2.blockOn(ExecutionContextImpl.scala:44); at scala.concurrent.Await$.ready(package.scala:169); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala:29); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:433); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala); at scala.concurrent.impl.CallbackRunnable.run(Redefined); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #14 prio=5 os_prio=31 tid=0x00007fb76aa14800 nid=0x6103 runnable [0x00000001295b3000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.actor.LightArrayRevolverScheduler.clock(Scheduler.scala:213); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Redefined); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Redefined); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.actor.default-dispatcher-4"" #13 prio=5 os_prio=31 tid=0x00007fb76b38c000 nid=0x5f03 waiting on condition [0x000000012ac3d000]; java.lang.Thread.St",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:46376,Performance,concurren,concurrent,46376,"textImpl$DefaultThreadFactory$$anon$2$$anon$4.block(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinPool.managedBlock(Redefined); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2.blockOn(ExecutionContextImpl.scala:44); at scala.concurrent.Await$.ready(package.scala:169); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala:29); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:433); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala); at scala.concurrent.impl.CallbackRunnable.run(Redefined); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #14 prio=5 os_prio=31 tid=0x00007fb76aa14800 nid=0x6103 runnable [0x00000001295b3000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.actor.LightArrayRevolverScheduler.clock(Scheduler.scala:213); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Redefined); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Redefined); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.actor.default-dispatcher-4"" #13 prio=5 os_prio=31 tid=0x00007fb76b38c000 nid=0x5f03 waiting on condition [0x000000012ac3d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - par",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:46456,Performance,concurren,concurrent,46456," at scala.concurrent.forkjoin.ForkJoinPool.managedBlock(Redefined); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2.blockOn(ExecutionContextImpl.scala:44); at scala.concurrent.Await$.ready(package.scala:169); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala:29); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:433); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala); at scala.concurrent.impl.CallbackRunnable.run(Redefined); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #14 prio=5 os_prio=31 tid=0x00007fb76aa14800 nid=0x6103 runnable [0x00000001295b3000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.actor.LightArrayRevolverScheduler.clock(Scheduler.scala:213); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Redefined); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Redefined); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.actor.default-dispatcher-4"" #13 prio=5 os_prio=31 tid=0x00007fb76b38c000 nid=0x5f03 waiting on condition [0x000000012ac3d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c002f9e0> (a akka.dispatch.ForkJoinExecutorConfigura",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:46520,Performance,concurren,concurrent,46520,"d); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2.blockOn(ExecutionContextImpl.scala:44); at scala.concurrent.Await$.ready(package.scala:169); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at akka.actor.ActorSystemImpl.awaitTermination(ActorSystem.scala); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala:29); at cromwell.server.CromwellServer$$anonfun$run$1.applyOrElse(CromwellServer.scala); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala:433); at scala.concurrent.Future$$anonfun$andThen$1.apply(Future.scala); at scala.concurrent.impl.CallbackRunnable.run(Redefined); at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #14 prio=5 os_prio=31 tid=0x00007fb76aa14800 nid=0x6103 runnable [0x00000001295b3000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.actor.LightArrayRevolverScheduler.clock(Scheduler.scala:213); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Redefined); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Redefined); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.actor.default-dispatcher-4"" #13 prio=5 os_prio=31 tid=0x00007fb76b38c000 nid=0x5f03 waiting on condition [0x000000012ac3d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c002f9e0> (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:47494,Performance,concurren,concurrent,47494,"Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #14 prio=5 os_prio=31 tid=0x00007fb76aa14800 nid=0x6103 runnable [0x00000001295b3000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.actor.LightArrayRevolverScheduler.clock(Scheduler.scala:213); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Redefined); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Redefined); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.actor.default-dispatcher-4"" #13 prio=5 os_prio=31 tid=0x00007fb76b38c000 nid=0x5f03 waiting on condition [0x000000012ac3d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c002f9e0> (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(Redefined); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #10 prio=5 os_prio=31 tid=0x00007fb76b20f000 nid=0x5a07 runnable [0x000000012a0e1000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.dispatch.AbstractNodeQueue$Node.next(AbstractNodeQueue.java:124); at akka.dispatch.AbstractNodeQueue.pollNode(AbstractNodeQueue.java:86); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:411); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Redefined); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Redefined); at java.lang.Thread.run(Redefined). ""Service Thread"" #9 daemon prio=9 os_prio=31 tid=0x00007fb76a82e000 nid=0x5103 runnable [0x000",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:47553,Performance,concurren,concurrent,47553,"ad.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #14 prio=5 os_prio=31 tid=0x00007fb76aa14800 nid=0x6103 runnable [0x00000001295b3000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.actor.LightArrayRevolverScheduler.clock(Scheduler.scala:213); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Redefined); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Redefined); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.actor.default-dispatcher-4"" #13 prio=5 os_prio=31 tid=0x00007fb76b38c000 nid=0x5f03 waiting on condition [0x000000012ac3d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c002f9e0> (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(Redefined); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #10 prio=5 os_prio=31 tid=0x00007fb76b20f000 nid=0x5a07 runnable [0x000000012a0e1000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.dispatch.AbstractNodeQueue$Node.next(AbstractNodeQueue.java:124); at akka.dispatch.AbstractNodeQueue.pollNode(AbstractNodeQueue.java:86); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:411); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Redefined); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Redefined); at java.lang.Thread.run(Redefined). ""Service Thread"" #9 daemon prio=9 os_prio=31 tid=0x00007fb76a82e000 nid=0x5103 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""C1 Compi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:47617,Performance,concurren,concurrent,47617," #14 prio=5 os_prio=31 tid=0x00007fb76aa14800 nid=0x6103 runnable [0x00000001295b3000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.actor.LightArrayRevolverScheduler.clock(Scheduler.scala:213); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Redefined); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Redefined); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.actor.default-dispatcher-4"" #13 prio=5 os_prio=31 tid=0x00007fb76b38c000 nid=0x5f03 waiting on condition [0x000000012ac3d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c002f9e0> (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(Redefined); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #10 prio=5 os_prio=31 tid=0x00007fb76b20f000 nid=0x5a07 runnable [0x000000012a0e1000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.dispatch.AbstractNodeQueue$Node.next(AbstractNodeQueue.java:124); at akka.dispatch.AbstractNodeQueue.pollNode(AbstractNodeQueue.java:86); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:411); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Redefined); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Redefined); at java.lang.Thread.run(Redefined). ""Service Thread"" #9 daemon prio=9 os_prio=31 tid=0x00007fb76a82e000 nid=0x5103 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""C1 CompilerThread3"" #8 daemon prio=9 os_prio=31 tid=0x00007fb76a060000 n",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:50454,Performance,concurren,concurrent,50454,"]; java.lang.Thread.State: WAITING (on object monitor); at java.lang.Object.wait(Native Method); at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143); - locked <0x00000006c00371c0> (a java.lang.ref.ReferenceQueue$Lock); at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164); at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209). ""Reference Handler"" #2 daemon prio=10 os_prio=31 tid=0x00007fb76b005800 nid=0x3303 in Object.wait() [0x0000000126ac4000]; java.lang.Thread.State: WAITING (on object monitor); at java.lang.Object.wait(Native Method); at java.lang.Object.wait(Object.java:502); at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:157); - locked <0x00000006c00301d8> (a java.lang.ref.Reference$Lock). ""main"" #1 prio=5 os_prio=31 tid=0x00007fb76a803000 nid=0xf07 waiting on condition [0x000000010b088000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c061d308> (a scala.concurrent.impl.Promise$CompletionLatch); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:199); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala); at scala.concurrent.Await$.ready(package.scala:169); at cromwell.Main.cromwell$Main$$waitAndExit(Main.scala); a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:50509,Performance,concurren,concurrent,50509," at java.lang.Object.wait(Native Method); at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143); - locked <0x00000006c00371c0> (a java.lang.ref.ReferenceQueue$Lock); at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164); at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209). ""Reference Handler"" #2 daemon prio=10 os_prio=31 tid=0x00007fb76b005800 nid=0x3303 in Object.wait() [0x0000000126ac4000]; java.lang.Thread.State: WAITING (on object monitor); at java.lang.Object.wait(Native Method); at java.lang.Object.wait(Object.java:502); at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:157); - locked <0x00000006c00301d8> (a java.lang.ref.Reference$Lock). ""main"" #1 prio=5 os_prio=31 tid=0x00007fb76a803000 nid=0xf07 waiting on condition [0x000000010b088000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c061d308> (a scala.concurrent.impl.Promise$CompletionLatch); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:199); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala); at scala.concurrent.Await$.ready(package.scala:169); at cromwell.Main.cromwell$Main$$waitAndExit(Main.scala); at cromwell.Main$$anonfun$runServer$2.apply$mcI$sp(Main.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:50568,Performance,concurren,concurrent,50568,"ReferenceQueue.remove(ReferenceQueue.java:143); - locked <0x00000006c00371c0> (a java.lang.ref.ReferenceQueue$Lock); at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164); at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209). ""Reference Handler"" #2 daemon prio=10 os_prio=31 tid=0x00007fb76b005800 nid=0x3303 in Object.wait() [0x0000000126ac4000]; java.lang.Thread.State: WAITING (on object monitor); at java.lang.Object.wait(Native Method); at java.lang.Object.wait(Object.java:502); at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:157); - locked <0x00000006c00301d8> (a java.lang.ref.Reference$Lock). ""main"" #1 prio=5 os_prio=31 tid=0x00007fb76a803000 nid=0xf07 waiting on condition [0x000000010b088000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c061d308> (a scala.concurrent.impl.Promise$CompletionLatch); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:199); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala); at scala.concurrent.Await$.ready(package.scala:169); at cromwell.Main.cromwell$Main$$waitAndExit(Main.scala); at cromwell.Main$$anonfun$runServer$2.apply$mcI$sp(Main.scala:109); at cromwell.Main.continueIf(Main.scala); at cro",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:50685,Performance,concurren,concurrent,50685,"at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164); at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209). ""Reference Handler"" #2 daemon prio=10 os_prio=31 tid=0x00007fb76b005800 nid=0x3303 in Object.wait() [0x0000000126ac4000]; java.lang.Thread.State: WAITING (on object monitor); at java.lang.Object.wait(Native Method); at java.lang.Object.wait(Object.java:502); at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:157); - locked <0x00000006c00301d8> (a java.lang.ref.Reference$Lock). ""main"" #1 prio=5 os_prio=31 tid=0x00007fb76a803000 nid=0xf07 waiting on condition [0x000000010b088000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c061d308> (a scala.concurrent.impl.Promise$CompletionLatch); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:199); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala); at scala.concurrent.Await$.ready(package.scala:169); at cromwell.Main.cromwell$Main$$waitAndExit(Main.scala); at cromwell.Main$$anonfun$runServer$2.apply$mcI$sp(Main.scala:109); at cromwell.Main.continueIf(Main.scala); at cromwell.Main.runServer(Main.scala:109); at cromwell.Main.runAction(Main.scala:103); at cromwell.Main$.delayedEndpoint$c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:50809,Performance,concurren,concurrent,50809,"va:209). ""Reference Handler"" #2 daemon prio=10 os_prio=31 tid=0x00007fb76b005800 nid=0x3303 in Object.wait() [0x0000000126ac4000]; java.lang.Thread.State: WAITING (on object monitor); at java.lang.Object.wait(Native Method); at java.lang.Object.wait(Object.java:502); at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:157); - locked <0x00000006c00301d8> (a java.lang.ref.Reference$Lock). ""main"" #1 prio=5 os_prio=31 tid=0x00007fb76a803000 nid=0xf07 waiting on condition [0x000000010b088000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c061d308> (a scala.concurrent.impl.Promise$CompletionLatch); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:199); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala); at scala.concurrent.Await$.ready(package.scala:169); at cromwell.Main.cromwell$Main$$waitAndExit(Main.scala); at cromwell.Main$$anonfun$runServer$2.apply$mcI$sp(Main.scala:109); at cromwell.Main.continueIf(Main.scala); at cromwell.Main.runServer(Main.scala:109); at cromwell.Main.runAction(Main.scala:103); at cromwell.Main$.delayedEndpoint$cromwell$Main$1(Main.scala:49); at cromwell.Main$delayedInit$body.apply(Main.scala); at scala.Function0$class.apply$mcV$sp(Fu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:50928,Performance,concurren,concurrent,50928,"126ac4000]; java.lang.Thread.State: WAITING (on object monitor); at java.lang.Object.wait(Native Method); at java.lang.Object.wait(Object.java:502); at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:157); - locked <0x00000006c00301d8> (a java.lang.ref.Reference$Lock). ""main"" #1 prio=5 os_prio=31 tid=0x00007fb76a803000 nid=0xf07 waiting on condition [0x000000010b088000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c061d308> (a scala.concurrent.impl.Promise$CompletionLatch); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:199); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala); at scala.concurrent.Await$.ready(package.scala:169); at cromwell.Main.cromwell$Main$$waitAndExit(Main.scala); at cromwell.Main$$anonfun$runServer$2.apply$mcI$sp(Main.scala:109); at cromwell.Main.continueIf(Main.scala); at cromwell.Main.runServer(Main.scala:109); at cromwell.Main.runAction(Main.scala:103); at cromwell.Main$.delayedEndpoint$cromwell$Main$1(Main.scala:49); at cromwell.Main$delayedInit$body.apply(Main.scala); at scala.Function0$class.apply$mcV$sp(Function0.scala); at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala); at scala.App$$anonfun$main$1.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:51005,Performance,concurren,concurrent,51005,".Object.wait(Native Method); at java.lang.Object.wait(Object.java:502); at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:157); - locked <0x00000006c00301d8> (a java.lang.ref.Reference$Lock). ""main"" #1 prio=5 os_prio=31 tid=0x00007fb76a803000 nid=0xf07 waiting on condition [0x000000010b088000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c061d308> (a scala.concurrent.impl.Promise$CompletionLatch); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:199); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala); at scala.concurrent.Await$.ready(package.scala:169); at cromwell.Main.cromwell$Main$$waitAndExit(Main.scala); at cromwell.Main$$anonfun$runServer$2.apply$mcI$sp(Main.scala:109); at cromwell.Main.continueIf(Main.scala); at cromwell.Main.runServer(Main.scala:109); at cromwell.Main.runAction(Main.scala:103); at cromwell.Main$.delayedEndpoint$cromwell$Main$1(Main.scala:49); at cromwell.Main$delayedInit$body.apply(Main.scala); at scala.Function0$class.apply$mcV$sp(Function0.scala); at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala); at scala.App$$anonfun$main$1.apply(App.scala); at scala.App$$anonfun$main$1.apply(App.scala); at scala.col",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:51075,Performance,concurren,concurrent,51075,"; at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:157); - locked <0x00000006c00301d8> (a java.lang.ref.Reference$Lock). ""main"" #1 prio=5 os_prio=31 tid=0x00007fb76a803000 nid=0xf07 waiting on condition [0x000000010b088000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c061d308> (a scala.concurrent.impl.Promise$CompletionLatch); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:199); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala); at scala.concurrent.Await$.ready(package.scala:169); at cromwell.Main.cromwell$Main$$waitAndExit(Main.scala); at cromwell.Main$$anonfun$runServer$2.apply$mcI$sp(Main.scala:109); at cromwell.Main.continueIf(Main.scala); at cromwell.Main.runServer(Main.scala:109); at cromwell.Main.runAction(Main.scala:103); at cromwell.Main$.delayedEndpoint$cromwell$Main$1(Main.scala:49); at cromwell.Main$delayedInit$body.apply(Main.scala); at scala.Function0$class.apply$mcV$sp(Function0.scala); at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala); at scala.App$$anonfun$main$1.apply(App.scala); at scala.App$$anonfun$main$1.apply(App.scala); at scala.collection.immutable.List.foreach(List.scala:380); at scala.collection.ge",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:51145,Performance,concurren,concurrent,51145," - locked <0x00000006c00301d8> (a java.lang.ref.Reference$Lock). ""main"" #1 prio=5 os_prio=31 tid=0x00007fb76a803000 nid=0xf07 waiting on condition [0x000000010b088000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c061d308> (a scala.concurrent.impl.Promise$CompletionLatch); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:199); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala); at scala.concurrent.Await$.ready(package.scala:169); at cromwell.Main.cromwell$Main$$waitAndExit(Main.scala); at cromwell.Main$$anonfun$runServer$2.apply$mcI$sp(Main.scala:109); at cromwell.Main.continueIf(Main.scala); at cromwell.Main.runServer(Main.scala:109); at cromwell.Main.runAction(Main.scala:103); at cromwell.Main$.delayedEndpoint$cromwell$Main$1(Main.scala:49); at cromwell.Main$delayedInit$body.apply(Main.scala); at scala.Function0$class.apply$mcV$sp(Function0.scala); at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala); at scala.App$$anonfun$main$1.apply(App.scala); at scala.App$$anonfun$main$1.apply(App.scala); at scala.collection.immutable.List.foreach(List.scala:380); at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala); ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:51210,Performance,concurren,concurrent,51210,"""main"" #1 prio=5 os_prio=31 tid=0x00007fb76a803000 nid=0xf07 waiting on condition [0x000000010b088000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c061d308> (a scala.concurrent.impl.Promise$CompletionLatch); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:199); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala); at scala.concurrent.Await$.ready(package.scala:169); at cromwell.Main.cromwell$Main$$waitAndExit(Main.scala); at cromwell.Main$$anonfun$runServer$2.apply$mcI$sp(Main.scala:109); at cromwell.Main.continueIf(Main.scala); at cromwell.Main.runServer(Main.scala:109); at cromwell.Main.runAction(Main.scala:103); at cromwell.Main$.delayedEndpoint$cromwell$Main$1(Main.scala:49); at cromwell.Main$delayedInit$body.apply(Main.scala); at scala.Function0$class.apply$mcV$sp(Function0.scala); at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala); at scala.App$$anonfun$main$1.apply(App.scala); at scala.App$$anonfun$main$1.apply(App.scala); at scala.collection.immutable.List.foreach(List.scala:380); at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala); at scala.App$class.main(App.scala:76); at cromwell.Main$.main(Mai",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:51275,Performance,concurren,concurrent,51275,"ing on condition [0x000000010b088000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c061d308> (a scala.concurrent.impl.Promise$CompletionLatch); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:199); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala); at scala.concurrent.Await$.ready(package.scala:169); at cromwell.Main.cromwell$Main$$waitAndExit(Main.scala); at cromwell.Main$$anonfun$runServer$2.apply$mcI$sp(Main.scala:109); at cromwell.Main.continueIf(Main.scala); at cromwell.Main.runServer(Main.scala:109); at cromwell.Main.runAction(Main.scala:103); at cromwell.Main$.delayedEndpoint$cromwell$Main$1(Main.scala:49); at cromwell.Main$delayedInit$body.apply(Main.scala); at scala.Function0$class.apply$mcV$sp(Function0.scala); at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala); at scala.App$$anonfun$main$1.apply(App.scala); at scala.App$$anonfun$main$1.apply(App.scala); at scala.collection.immutable.List.foreach(List.scala:380); at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala); at scala.App$class.main(App.scala:76); at cromwell.Main$.main(Main.scala); at cromwell.Main.main(Main.scala). ""VM Thread"" os_prio=",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:51358,Performance,concurren,concurrent,51358,"t sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c061d308> (a scala.concurrent.impl.Promise$CompletionLatch); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:199); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala); at scala.concurrent.Await$.ready(package.scala:169); at cromwell.Main.cromwell$Main$$waitAndExit(Main.scala); at cromwell.Main$$anonfun$runServer$2.apply$mcI$sp(Main.scala:109); at cromwell.Main.continueIf(Main.scala); at cromwell.Main.runServer(Main.scala:109); at cromwell.Main.runAction(Main.scala:103); at cromwell.Main$.delayedEndpoint$cromwell$Main$1(Main.scala:49); at cromwell.Main$delayedInit$body.apply(Main.scala); at scala.Function0$class.apply$mcV$sp(Function0.scala); at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala); at scala.App$$anonfun$main$1.apply(App.scala); at scala.App$$anonfun$main$1.apply(App.scala); at scala.collection.immutable.List.foreach(List.scala:380); at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala); at scala.App$class.main(App.scala:76); at cromwell.Main$.main(Main.scala); at cromwell.Main.main(Main.scala). ""VM Thread"" os_prio=31 tid=0x00007fb76a05d800 nid=0x3103 runnable. ""GC task thread#0 (ParallelGC)"" os_p",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:52,Safety,detect,detect,52,"A bunch of jobs were finished which Cromwell didn't detect. The context: ; - Trying to run jprofiler to get a profile of the run described in #820. Full stack dump:. ```; Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode):. ""cromwell-system-akka.actor.default-dispatcher-27"" #115 prio=5 os_prio=31 tid=0x00007fb76d052800 nid=0xf503 waiting on condition [0x0000000135d74000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0021d00> (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""ForkJoinPool-3-worker-5"" #82 daemon prio=5 os_prio=31 tid=0x00007fb76cc73800 nid=0xcd03 waiting on condition [0x0000000134661000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0041f30> (a scala.concurrent.forkjoin.ForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""pool-1-thread-20"" #81 prio=5 os_prio=31 tid=0x00007fb76cc5b800 nid=0xcb03 waiting on condition [0x000000013455e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(Th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:453,Safety,Unsafe,Unsafe,453,"A bunch of jobs were finished which Cromwell didn't detect. The context: ; - Trying to run jprofiler to get a profile of the run described in #820. Full stack dump:. ```; Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode):. ""cromwell-system-akka.actor.default-dispatcher-27"" #115 prio=5 os_prio=31 tid=0x00007fb76d052800 nid=0xf503 waiting on condition [0x0000000135d74000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0021d00> (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""ForkJoinPool-3-worker-5"" #82 daemon prio=5 os_prio=31 tid=0x00007fb76cc73800 nid=0xcd03 waiting on condition [0x0000000134661000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0041f30> (a scala.concurrent.forkjoin.ForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""pool-1-thread-20"" #81 prio=5 os_prio=31 tid=0x00007fb76cc5b800 nid=0xcb03 waiting on condition [0x000000013455e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(Th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:1011,Safety,Unsafe,Unsafe,1011,"s were finished which Cromwell didn't detect. The context: ; - Trying to run jprofiler to get a profile of the run described in #820. Full stack dump:. ```; Full thread dump Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode):. ""cromwell-system-akka.actor.default-dispatcher-27"" #115 prio=5 os_prio=31 tid=0x00007fb76d052800 nid=0xf503 waiting on condition [0x0000000135d74000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0021d00> (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""ForkJoinPool-3-worker-5"" #82 daemon prio=5 os_prio=31 tid=0x00007fb76cc73800 nid=0xcd03 waiting on condition [0x0000000134661000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0041f30> (a scala.concurrent.forkjoin.ForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""pool-1-thread-20"" #81 prio=5 os_prio=31 tid=0x00007fb76cc5b800 nid=0xcb03 waiting on condition [0x000000013455e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecut",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:1534,Safety,Unsafe,Unsafe,1534,"tch.ForkJoinExecutorConfigurator$AkkaForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""ForkJoinPool-3-worker-5"" #82 daemon prio=5 os_prio=31 tid=0x00007fb76cc73800 nid=0xcd03 waiting on condition [0x0000000134661000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0041f30> (a scala.concurrent.forkjoin.ForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(ForkJoinPool.java:2075); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ""pool-1-thread-20"" #81 prio=5 os_prio=31 tid=0x00007fb76cc5b800 nid=0xcb03 waiting on condition [0x000000013455e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-19"" #80 prio=5 os_prio=31 tid=0x00007fb76cc59800 nid=0xc903 waiting on condition [0x0000000134093000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchroniz",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:2413,Safety,Unsafe,Unsafe,2413,"6cc5b800 nid=0xcb03 waiting on condition [0x000000013455e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-19"" #80 prio=5 os_prio=31 tid=0x00007fb76cc59800 nid=0xc903 waiting on condition [0x0000000134093000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-18"" #79 prio=5 os_prio=31 tid=0x00007fb76d1d1000 nid=0xc703 waiting on condition [0x0000000133f90000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchroniz",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:3292,Safety,Unsafe,Unsafe,3292,"6cc59800 nid=0xc903 waiting on condition [0x0000000134093000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-18"" #79 prio=5 os_prio=31 tid=0x00007fb76d1d1000 nid=0xc703 waiting on condition [0x0000000133f90000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-17"" #78 prio=5 os_prio=31 tid=0x00007fb76de1b800 nid=0xc503 waiting on condition [0x0000000133df7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchroniz",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:4171,Safety,Unsafe,Unsafe,4171,"6d1d1000 nid=0xc703 waiting on condition [0x0000000133f90000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-17"" #78 prio=5 os_prio=31 tid=0x00007fb76de1b800 nid=0xc503 waiting on condition [0x0000000133df7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-16"" #77 prio=5 os_prio=31 tid=0x00007fb76a6e9800 nid=0xc303 waiting on condition [0x000000013399d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchroniz",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:5050,Safety,Unsafe,Unsafe,5050,"6de1b800 nid=0xc503 waiting on condition [0x0000000133df7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-16"" #77 prio=5 os_prio=31 tid=0x00007fb76a6e9800 nid=0xc303 waiting on condition [0x000000013399d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-15"" #75 prio=5 os_prio=31 tid=0x00007fb76e11d000 nid=0xbf03 waiting on condition [0x0000000133797000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchroniz",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:5929,Safety,Unsafe,Unsafe,5929,"6a6e9800 nid=0xc303 waiting on condition [0x000000013399d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-15"" #75 prio=5 os_prio=31 tid=0x00007fb76e11d000 nid=0xbf03 waiting on condition [0x0000000133797000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-14"" #74 prio=5 os_prio=31 tid=0x00007fb76dd8e800 nid=0xbd03 waiting on condition [0x0000000133694000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchroniz",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:6808,Safety,Unsafe,Unsafe,6808,"6e11d000 nid=0xbf03 waiting on condition [0x0000000133797000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-14"" #74 prio=5 os_prio=31 tid=0x00007fb76dd8e800 nid=0xbd03 waiting on condition [0x0000000133694000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-13"" #73 prio=5 os_prio=31 tid=0x00007fb76a458800 nid=0xbb03 waiting on condition [0x0000000133591000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchroniz",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:7687,Safety,Unsafe,Unsafe,7687,"6dd8e800 nid=0xbd03 waiting on condition [0x0000000133694000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-13"" #73 prio=5 os_prio=31 tid=0x00007fb76a458800 nid=0xbb03 waiting on condition [0x0000000133591000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-12"" #72 prio=5 os_prio=31 tid=0x00007fb76f1b0800 nid=0xb903 waiting on condition [0x00000001332cc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchroniz",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:8566,Safety,Unsafe,Unsafe,8566,"6a458800 nid=0xbb03 waiting on condition [0x0000000133591000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-12"" #72 prio=5 os_prio=31 tid=0x00007fb76f1b0800 nid=0xb903 waiting on condition [0x00000001332cc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-11"" #71 prio=5 os_prio=31 tid=0x00007fb76b05a800 nid=0xb703 waiting on condition [0x00000001331c9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchroniz",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:9445,Safety,Unsafe,Unsafe,9445,"6f1b0800 nid=0xb903 waiting on condition [0x00000001332cc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-11"" #71 prio=5 os_prio=31 tid=0x00007fb76b05a800 nid=0xb703 waiting on condition [0x00000001331c9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-10"" #70 prio=5 os_prio=31 tid=0x00007fb76bac5800 nid=0xb503 waiting on condition [0x0000000132fa6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchroniz",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:10324,Safety,Unsafe,Unsafe,10324,"6b05a800 nid=0xb703 waiting on condition [0x00000001331c9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-10"" #70 prio=5 os_prio=31 tid=0x00007fb76bac5800 nid=0xb503 waiting on condition [0x0000000132fa6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-9"" #69 prio=5 os_prio=31 tid=0x00007fb76f36d800 nid=0xb303 waiting on condition [0x000000012c1b6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronize",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:11202,Safety,Unsafe,Unsafe,11202,"76bac5800 nid=0xb503 waiting on condition [0x0000000132fa6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-9"" #69 prio=5 os_prio=31 tid=0x00007fb76f36d800 nid=0xb303 waiting on condition [0x000000012c1b6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-8"" #68 prio=5 os_prio=31 tid=0x00007fb76ef84000 nid=0xb103 waiting on condition [0x0000000132bf1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronize",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:12080,Safety,Unsafe,Unsafe,12080,"76f36d800 nid=0xb303 waiting on condition [0x000000012c1b6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-8"" #68 prio=5 os_prio=31 tid=0x00007fb76ef84000 nid=0xb103 waiting on condition [0x0000000132bf1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-7"" #67 prio=5 os_prio=31 tid=0x00007fb7705a3000 nid=0xaf03 waiting on condition [0x00000001330c6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronize",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:12958,Safety,Unsafe,Unsafe,12958,"76ef84000 nid=0xb103 waiting on condition [0x0000000132bf1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-7"" #67 prio=5 os_prio=31 tid=0x00007fb7705a3000 nid=0xaf03 waiting on condition [0x00000001330c6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-6"" #66 prio=5 os_prio=31 tid=0x00007fb7705ef800 nid=0xad03 waiting on condition [0x0000000132aee000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronize",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:13836,Safety,Unsafe,Unsafe,13836,"7705a3000 nid=0xaf03 waiting on condition [0x00000001330c6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-6"" #66 prio=5 os_prio=31 tid=0x00007fb7705ef800 nid=0xad03 waiting on condition [0x0000000132aee000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-5"" #65 prio=5 os_prio=31 tid=0x00007fb7706d2800 nid=0xab03 waiting on condition [0x00000001329eb000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronize",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:14714,Safety,Unsafe,Unsafe,14714,"7705ef800 nid=0xad03 waiting on condition [0x0000000132aee000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-5"" #65 prio=5 os_prio=31 tid=0x00007fb7706d2800 nid=0xab03 waiting on condition [0x00000001329eb000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-20"" #61 daemon prio=5 os_prio=31 tid=0x00007fb76b1f9000 nid=0xa303 waiting on condition [0x00000001325df000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$C",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:15589,Safety,Unsafe,Unsafe,15589,"7fb7706d2800 nid=0xab03 waiting on condition [0x00000001329eb000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-20"" #61 daemon prio=5 os_prio=31 tid=0x00007fb76b1f9000 nid=0xa303 waiting on condition [0x00000001325df000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-4"" #60 prio=5 os_prio=31 tid=0x00007fb76d42b000 nid=0xa103 waiting on condition [0",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:16668,Safety,Unsafe,Unsafe,16668,"l.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-4"" #60 prio=5 os_prio=31 tid=0x00007fb76d42b000 nid=0xa103 waiting on condition [0x0000000132168000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-19"" #59 daemon prio=5 os_prio=31 tid=0x00007fb770631000 nid=0x9f03 waiting on condition [0x00000001324dc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$C",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:17543,Safety,Unsafe,Unsafe,17543,"7fb76d42b000 nid=0xa103 waiting on condition [0x0000000132168000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-19"" #59 daemon prio=5 os_prio=31 tid=0x00007fb770631000 nid=0x9f03 waiting on condition [0x00000001324dc000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-18"" #58 daemon prio=5 os_prio=31 tid=0x00007fb770630800 nid=0x9d03 waiting on condition [0x00",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:18619,Safety,Unsafe,Unsafe,18619,"util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-18"" #58 daemon prio=5 os_prio=31 tid=0x00007fb770630800 nid=0x9d03 waiting on condition [0x00000001323d9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-3"" #57 prio=5 os_prio=31 tid=0x00007fb76e95e000 nid=0x9b03 waiting on condition [0",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:19698,Safety,Unsafe,Unsafe,19698,"l.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-3"" #57 prio=5 os_prio=31 tid=0x00007fb76e95e000 nid=0x9b03 waiting on condition [0x00000001322d6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-17"" #56 daemon prio=5 os_prio=31 tid=0x00007fb76b6b6000 nid=0x9903 waiting on condition [0x0000000131db9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$C",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:20573,Safety,Unsafe,Unsafe,20573,"7fb76e95e000 nid=0x9b03 waiting on condition [0x00000001322d6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-17"" #56 daemon prio=5 os_prio=31 tid=0x00007fb76b6b6000 nid=0x9903 waiting on condition [0x0000000131db9000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-16"" #55 daemon prio=5 os_prio=31 tid=0x00007fb76e92f000 nid=0x9703 waiting on condition [0x00",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:21649,Safety,Unsafe,Unsafe,21649,"util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-16"" #55 daemon prio=5 os_prio=31 tid=0x00007fb76e92f000 nid=0x9703 waiting on condition [0x0000000131cb6000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-15"" #54 daemon prio=5 os_prio=31 tid=0x00007fb76b6b4000 nid=0x9503 waiting on condition [0x00",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:22725,Safety,Unsafe,Unsafe,22725,"util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-15"" #54 daemon prio=5 os_prio=31 tid=0x00007fb76b6b4000 nid=0x9503 waiting on condition [0x0000000131bb3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-14"" #53 daemon prio=5 os_prio=31 tid=0x00007fb77061e000 nid=0x9303 waiting on condition [0x00",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:23801,Safety,Unsafe,Unsafe,23801,"util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-14"" #53 daemon prio=5 os_prio=31 tid=0x00007fb77061e000 nid=0x9303 waiting on condition [0x0000000131ab0000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-13"" #52 daemon prio=5 os_prio=31 tid=0x00007fb76e96e000 nid=0x9103 waiting on condition [0x00",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:24877,Safety,Unsafe,Unsafe,24877,"util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-13"" #52 daemon prio=5 os_prio=31 tid=0x00007fb76e96e000 nid=0x9103 waiting on condition [0x00000001319ad000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-12"" #51 daemon prio=5 os_prio=31 tid=0x00007fb7720cf000 nid=0x8f03 waiting on condition [0x00",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:25953,Safety,Unsafe,Unsafe,25953,"util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-12"" #51 daemon prio=5 os_prio=31 tid=0x00007fb7720cf000 nid=0x8f03 waiting on condition [0x00000001318aa000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-11"" #50 daemon prio=5 os_prio=31 tid=0x00007fb7720ce800 nid=0x8d03 waiting on condition [0x00",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:27029,Safety,Unsafe,Unsafe,27029,"util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-11"" #50 daemon prio=5 os_prio=31 tid=0x00007fb7720ce800 nid=0x8d03 waiting on condition [0x00000001317a7000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-10"" #49 daemon prio=5 os_prio=31 tid=0x00007fb7720cd800 nid=0x8b03 waiting on condition [0x00",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:28105,Safety,Unsafe,Unsafe,28105,"util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-10"" #49 daemon prio=5 os_prio=31 tid=0x00007fb7720cd800 nid=0x8b03 waiting on condition [0x00000001316a4000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-9"" #48 daemon prio=5 os_prio=31 tid=0x00007fb76b529800 nid=0x8903 waiting on condition [0x000",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:29180,Safety,Unsafe,Unsafe,29180,".util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-9"" #48 daemon prio=5 os_prio=31 tid=0x00007fb76b529800 nid=0x8903 waiting on condition [0x00000001315a1000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-8"" #47 daemon prio=5 os_prio=31 tid=0x00007fb76b518000 nid=0x8703 waiting on condition [0x000",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:30255,Safety,Unsafe,Unsafe,30255,".util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-8"" #47 daemon prio=5 os_prio=31 tid=0x00007fb76b518000 nid=0x8703 waiting on condition [0x000000013149e000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-7"" #46 daemon prio=5 os_prio=31 tid=0x00007fb76e8f5000 nid=0x5807 waiting on condition [0x000",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:31330,Safety,Unsafe,Unsafe,31330,".util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-7"" #46 daemon prio=5 os_prio=31 tid=0x00007fb76e8f5000 nid=0x5807 waiting on condition [0x000000013139b000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-6"" #45 daemon prio=5 os_prio=31 tid=0x00007fb76e8dd000 nid=0x5507 waiting on condition [0x000",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:32405,Safety,Unsafe,Unsafe,32405,".util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-6"" #45 daemon prio=5 os_prio=31 tid=0x00007fb76e8dd000 nid=0x5507 waiting on condition [0x0000000131298000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-5"" #44 daemon prio=5 os_prio=31 tid=0x00007fb76b517800 nid=0x3b0b waiting on condition [0x000",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:33480,Safety,Unsafe,Unsafe,33480,".util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""db-5"" #44 daemon prio=5 os_prio=31 tid=0x00007fb76b517800 nid=0x3b0b waiting on condition [0x0000000131195000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-2"" #43 prio=5 os_prio=31 tid=0x00007fb76e8ee000 nid=0x3f0b waiting on condition [0",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:34559,Safety,Unsafe,Unsafe,34559,"l.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""pool-1-thread-2"" #43 prio=5 os_prio=31 tid=0x00007fb76e8ee000 nid=0x3f0b waiting on condition [0x000000012ee35000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1127); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ""_jprofiler_control_sampler"" #34 daemon prio=9 os_prio=31 tid=0x00007fb771044800 nid=0x6307 waiting on condition [0x000000012ab3a000]; java.lang.Thread.State: TIMED_WAITING (sleeping); at java.lang.Thread.sleep(Native Method); at com.jprofiler.agent.probe.y.run(ejt:1030). ""_jprofiler_native_sample",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:36434,Safety,Unsafe,Unsafe,36434," (sleeping); at java.lang.Thread.sleep(Native Method); at com.jprofiler.agent.probe.y.run(ejt:1030). ""_jprofiler_native_sampler"" #37 daemon prio=10 os_prio=31 tid=0x00007fb76d269000 nid=0x5d07 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""_jprofiler_native_comm"" #36 daemon prio=5 os_prio=31 tid=0x00007fb770d7d000 nid=0x3707 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""_jprofiler_sampler"" #35 daemon prio=10 os_prio=31 tid=0x00007fb771027000 nid=0x7707 waiting on condition [0x000000012cb95000]; java.lang.Thread.State: TIMED_WAITING (sleeping); at java.lang.Thread.sleep(Native Method); at com.jprofiler.agent.sampler.Sampler.run(ejt:84). ""Attach Listener"" #33 daemon prio=9 os_prio=31 tid=0x00007fb76e3e7800 nid=0x8507 runnable [0x0000000000000000]; java.lang.Thread.State: RUNNABLE. ""db-4"" #31 daemon prio=5 os_prio=31 tid=0x00007fb7706e2000 nid=0x8303 waiting on condition [0x000000012ca92000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-3"" #29 daemon prio=5 os_prio=31 tid=0x00007fb76f4b7000 nid=0x7f03 waiting on condition [0x000000012c88c000]; java.lang",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:37484,Safety,Unsafe,Unsafe,37484,"00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-3"" #29 daemon prio=5 os_prio=31 tid=0x00007fb76f4b7000 nid=0x7f03 waiting on condition [0x000000012c88c000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-2"" #28 daemon prio=5 os_prio=31 tid=0x00007fb7708d7800 nid=0x7d03 waiting on condition [0x000000012c789000]; java.lang",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:38534,Safety,Unsafe,Unsafe,38534,"00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-2"" #28 daemon prio=5 os_prio=31 tid=0x00007fb7708d7800 nid=0x7d03 waiting on condition [0x000000012c789000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""pool-1-thread-1"" #27 prio=5 os_prio=31 tid=0x00007fb76f4b6000 nid=0x7b03 waiting on condition [0x000000012b643000]; java.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:39588,Safety,Unsafe,Unsafe,39588,"0006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""pool-1-thread-1"" #27 prio=5 os_prio=31 tid=0x00007fb76f4b6000 nid=0x7b03 waiting on condition [0x000000012b643000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-1"" #26 daemon prio=5 os_prio=31 tid=0x00007fb76b442000 nid=0x7903 waiting on condition [0x000000012d905000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.u",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:40437,Safety,Unsafe,Unsafe,40437,"io=5 os_prio=31 tid=0x00007fb76f4b6000 nid=0x7b03 waiting on condition [0x000000012b643000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c1476660> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""db-1"" #26 daemon prio=5 os_prio=31 tid=0x00007fb76b442000 nid=0x7903 waiting on condition [0x000000012d905000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0751828> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Hikari Housekeeping Timer (pool db)"" #24 daemon prio=5 os_prio=31 tid=0x00007fb76d88f000 nid=0x7503 waiting on condition ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:41524,Safety,Unsafe,Unsafe,41524,"rent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039); at slick.util.ManagedArrayBlockingQueue$$anonfun$take$1.apply(ManagedArrayBlockingQueue.scala:105); at slick.util.ManagedArrayBlockingQueue.lockedInterruptibly(ManagedArrayBlockingQueue.scala:265); at slick.util.ManagedArrayBlockingQueue.take(ManagedArrayBlockingQueue.scala:104); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Hikari Housekeeping Timer (pool db)"" #24 daemon prio=5 os_prio=31 tid=0x00007fb76d88f000 nid=0x7503 waiting on condition [0x000000012cebb000]; java.lang.Thread.State: TIMED_WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0623fc0> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject); at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215); at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:1093); at java.util.concurrent.ScheduledThreadPoolExecutor$DelayedWorkQueue.take(ScheduledThreadPoolExecutor.java:809); at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1067); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.io.pinned-dispatcher-7"" #23 prio=5 os_prio=31 tid=0x00007fb76b450800 nid=0x7303 runnable [0x000000012cdb8000]; java.lang.Thread.State: RUNNABLE;",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:44465,Safety,Unsafe,Unsafe,44465,"); at akka.util.SerializedSuspendableExecutionContext.run(SerializedSuspendableExecutionContext.scala); at akka.dispatch.TaskInvocation.run(Redefined); at java.util.concurrent.ThreadPoolExecutor.runWorker(Redefined); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Redefined). ""Abandoned connection cleanup thread"" #22 daemon prio=5 os_prio=31 tid=0x00007fb76a4f5800 nid=0x7103 in Object.wait() [0x000000012ccb5000]; java.lang.Thread.State: TIMED_WAITING (on object monitor); at java.lang.Object.wait(Native Method); at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143); - locked <0x00000006c0624180> (a java.lang.ref.ReferenceQueue$Lock); at com.mysql.jdbc.AbandonedConnectionCleanupThread.run(AbandonedConnectionCleanupThread.java:43). ""ForkJoinPool-3-worker-15"" #19 daemon prio=5 os_prio=31 tid=0x00007fb76abaa800 nid=0x6b03 waiting on condition [0x000000012a1e3000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c0060ab0> (a java.util.concurrent.CountDownLatch$Sync); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at akka.actor.ActorSystemImpl$TerminationCallbacks.ready(Redefined); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.impl.ExecutionContextImpl$DefaultThreadFactory$$anon$2$$anon$4.block(ExecutionContextImpl.scala); at scal",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:47349,Safety,Unsafe,Unsafe,47349,"oinTask.java); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #14 prio=5 os_prio=31 tid=0x00007fb76aa14800 nid=0x6103 runnable [0x00000001295b3000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.actor.LightArrayRevolverScheduler.clock(Scheduler.scala:213); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Redefined); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Redefined); at java.lang.Thread.run(Redefined). ""cromwell-system-akka.actor.default-dispatcher-4"" #13 prio=5 os_prio=31 tid=0x00007fb76b38c000 nid=0x5f03 waiting on condition [0x000000012ac3d000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c002f9e0> (a akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinPool); at scala.concurrent.forkjoin.ForkJoinPool.scan(Redefined); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(Redefined); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java). ""cromwell-system-scheduler-1"" #10 prio=5 os_prio=31 tid=0x00007fb76b20f000 nid=0x5a07 runnable [0x000000012a0e1000]; java.lang.Thread.State: RUNNABLE; at com.jprofiler.agent.InstrumentationCallee.exitFilteredMethod(Native Method); at com.jprofiler.agent.InstrumentationCallee.__ejt_filter_exitMethod(ejt:86); at akka.dispatch.AbstractNodeQueue$Node.next(AbstractNodeQueue.java:124); at akka.dispatch.AbstractNodeQueue.pollNode(AbstractNodeQueue.java:86); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:411); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Redefined); at akka.actor.LightArrayRevolverScheduler$$anon$8",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/844:50374,Safety,Unsafe,Unsafe,50374," os_prio=31 tid=0x00007fb76a05e000 nid=0x3503 in Object.wait() [0x0000000126bc7000]; java.lang.Thread.State: WAITING (on object monitor); at java.lang.Object.wait(Native Method); at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:143); - locked <0x00000006c00371c0> (a java.lang.ref.ReferenceQueue$Lock); at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:164); at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:209). ""Reference Handler"" #2 daemon prio=10 os_prio=31 tid=0x00007fb76b005800 nid=0x3303 in Object.wait() [0x0000000126ac4000]; java.lang.Thread.State: WAITING (on object monitor); at java.lang.Object.wait(Native Method); at java.lang.Object.wait(Object.java:502); at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:157); - locked <0x00000006c00301d8> (a java.lang.ref.Reference$Lock). ""main"" #1 prio=5 os_prio=31 tid=0x00007fb76a803000 nid=0xf07 waiting on condition [0x000000010b088000]; java.lang.Thread.State: WAITING (parking); at sun.misc.Unsafe.park(Native Method); - parking to wait for <0x00000006c061d308> (a scala.concurrent.impl.Promise$CompletionLatch); at java.util.concurrent.locks.LockSupport.park(Redefined); at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836); at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997); at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304); at scala.concurrent.impl.Promise$DefaultPromise.tryAwait(Promise.scala:199); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.Await$$anonfun$ready$1.apply(package.scala); at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala); at scala.concurrent.Await$.re",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/844
https://github.com/broadinstitute/cromwell/issues/845:64,Deployability,configurat,configuration,64,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:29,Modifiability,config,config,29,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:36,Modifiability,Config,ConfigException,36,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:64,Modifiability,config,configuration,64,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:143,Modifiability,config,config,143,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:207,Modifiability,config,config-,207,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:245,Modifiability,config,config,245,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:306,Modifiability,config,config-,306,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:344,Modifiability,config,config,344,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:405,Modifiability,config,config-,405,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:443,Modifiability,config,config,443,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:498,Modifiability,config,config-,498,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:536,Modifiability,config,config,536,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:591,Modifiability,config,config-,591,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:629,Modifiability,config,config,629,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:690,Modifiability,config,config-,690,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:155,Usability,Simpl,SimpleConfig,155,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:182,Usability,Simpl,SimpleConfig,182,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:257,Usability,Simpl,SimpleConfig,257,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:281,Usability,Simpl,SimpleConfig,281,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:356,Usability,Simpl,SimpleConfig,356,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:380,Usability,Simpl,SimpleConfig,380,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:455,Usability,Simpl,SimpleConfig,455,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:473,Usability,Simpl,SimpleConfig,473,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:548,Usability,Simpl,SimpleConfig,548,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:566,Usability,Simpl,SimpleConfig,566,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:641,Usability,Simpl,SimpleConfig,641,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/issues/845:665,Usability,Simpl,SimpleConfig,665,```; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'system.workflow-restart'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:176) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189) ~[config-1.3.0.jar:na]; at com.typesafe.config.impl.SimpleConfig.getBoolean(SimpleConfig.java:214) ~[config-1.3.0.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.preStart(WorkflowManagerActor.scala:83) ~[classes/:na]; at akka.actor.Actor$class.aroundPreStart(Actor.scala:472) ~[akka-actor_2.11-2.3.12.jar:na]; at cromwell.engine.workflow.WorkflowManagerActor.aroundPreStart(WorkflowManagerActor.scala:69) ~[classes/:na]; at akka.actor.ActorCell.create(ActorCell.scala:580) ~[akka-actor_2.11-2.3.12.jar:na]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/845
https://github.com/broadinstitute/cromwell/pull/846:6,Testability,Test,Test,6,- [ ] Test it,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/846
https://github.com/broadinstitute/cromwell/issues/850:26,Testability,test,tests,26,often need to run all the tests with:. sbt test,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/850
https://github.com/broadinstitute/cromwell/issues/850:43,Testability,test,test,43,often need to run all the tests with:. sbt test,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/850
https://github.com/broadinstitute/cromwell/issues/854:35,Testability,test,test,35,These files now get left behind on test runs.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/854
https://github.com/broadinstitute/cromwell/issues/856:40,Deployability,Pipeline,Pipeline,40,"From Dion, regarding how we construct a Pipeline for every Run:. Could you convert that into the ephemeral Run version? RunPipelineRequest.ephemeral_pipeline instead of pipeline_id. Will save you one RPC call too.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/856
https://github.com/broadinstitute/cromwell/issues/857:154,Modifiability,plugin,plugin,154,"Note to PO/scrumlords - I'm not asking for this to be prioritized. I just wanted a reminder for myself. I believe that sbt-native-publisher w/ the docker plugin could automate some of our docker-y cromwell stuff. Figure out if that's true or not, if so do it and/or write a new ticket",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/857
https://github.com/broadinstitute/cromwell/pull/860:62,Deployability,hotfix,hotfix,62,@mcovarr @Horneth . I haven't looked but I'm guessing the non-hotfix will be nearly (if not fully) identical so I'll wait until this is done before proceeding on the real one.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/860
https://github.com/broadinstitute/cromwell/pull/861:118,Availability,recover,recovery,118,Also creates #852. Following things need to be done (separate stories?) :; - [ ] Add docker support (#884); - [ ] Add recovery and abort (#885); - [x] Add continueOnErrorCode support; - [ ] Find a way to add condor specific runtime attributes to Condor ClassAds (#886). Anything more to support?,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/861
https://github.com/broadinstitute/cromwell/pull/861:118,Safety,recover,recovery,118,Also creates #852. Following things need to be done (separate stories?) :; - [ ] Add docker support (#884); - [ ] Add recovery and abort (#885); - [x] Add continueOnErrorCode support; - [ ] Find a way to add condor specific runtime attributes to Condor ClassAds (#886). Anything more to support?,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/861
https://github.com/broadinstitute/cromwell/pull/861:131,Safety,abort,abort,131,Also creates #852. Following things need to be done (separate stories?) :; - [ ] Add docker support (#884); - [ ] Add recovery and abort (#885); - [x] Add continueOnErrorCode support; - [ ] Find a way to add condor specific runtime attributes to Condor ClassAds (#886). Anything more to support?,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/861
https://github.com/broadinstitute/cromwell/pull/868:57,Deployability,update,updated,57,"… all moving in the right direction. Test Infrastructure updated to handle the test re-enabled here, including ThreeStep",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/868
https://github.com/broadinstitute/cromwell/pull/868:37,Testability,Test,Test,37,"… all moving in the right direction. Test Infrastructure updated to handle the test re-enabled here, including ThreeStep",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/868
https://github.com/broadinstitute/cromwell/pull/868:79,Testability,test,test,79,"… all moving in the right direction. Test Infrastructure updated to handle the test re-enabled here, including ThreeStep",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/868
https://github.com/broadinstitute/cromwell/issues/869:882,Availability,ERROR,ERROR,882,"- branch 0.19_hotfix a6f7c00b71dd22485d5e95c9a30f3dedd2ddeaba; - running with default application.conf. If I abort a running job via POST to the API endpoint `worflows/v1/<uuid>/abort`, this appears in the server logs:. > 2016-05-23 10:21:55,192 cromwell-system-akka.actor.default-dispatcher-6 INFO - CallActor [UUID(87ebf02f):Godot]: Abort function called.; > 2016-05-23 10:21:55,201 cromwell-system-akka.actor.default-dispatcher-5 INFO - WorkflowActor [UUID(87ebf02f)]: Beginning transition from Running to Aborting.; > 2016-05-23 10:21:55,201 cromwell-system-akka.actor.default-dispatcher-5 INFO - WorkflowActor [UUID(87ebf02f)]: transitioning from Running to Aborting.; > 2016-05-23 10:22:00,175 cromwell-system-akka.actor.default-dispatcher-8 INFO - LocalBackend [UUID(87ebf02f):Godot]: Return code: 0; > 2016-05-23 10:22:00,313 cromwell-system-akka.actor.default-dispatcher-2 ERROR - WorkflowActor [UUID(87ebf02f)]: Completion work failed for call Godot.; > java.sql.SQLIntegrityConstraintViolationException: integrity constraint violation: unique constraint or index violation; UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO table: SYMBOL; > at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCPreparedStatement.fetchResult(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCPreparedStatement.executeUpdate(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at com.zaxxer.hikari.proxy.PreparedStatementProxy.executeUpdate(PreparedStatementProxy.java:61) ~[cromwell-0.19.jar:0.19]; > at com.zaxxer.hikari.proxy.PreparedStatementJavassistProxy.executeUpdate(PreparedStatementJavassistProxy.java) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction$$anonfun$run$8$$anonfun$apply$1.apply(JdbcActionComponent.scala:520) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponen",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/869
https://github.com/broadinstitute/cromwell/issues/869:4273,Availability,error,error,4273,cActionComponent.scala:522) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:32) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:29) ~[cromwell-0.19.jar:0.19]; > at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.liftedTree1$1(DatabaseComponent.scala:237) ~[cromwell-0.19.jar:0.19]; > at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.run(DatabaseComponent.scala:237) ~[cromwell-0.19.jar:0.19]; > at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_74]; > at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_74]; > at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_74]; > Caused by: org.hsqldb.HsqlException: integrity constraint violation: unique constraint or index violation; UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO table: SYMBOL; > at org.hsqldb.error.Error.error(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Constraint.getException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.index.IndexAVLMemory.insert(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.persist.RowStoreAVL.indexRow(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.TransactionManagerMVCC.addInsertAction(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Session.addInsertAction(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Table.insertSingleRow(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.StatementDML.insertRowSet(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.StatementInsert.getResult(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.StatementDMQL.execute(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Session.executeCompiledStatement(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Session.execute(Unknown Source) ~[cromwell-0.19.jar:0.19]; > ..,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/869
https://github.com/broadinstitute/cromwell/issues/869:4279,Availability,Error,Error,4279,nComponent.scala:522) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:32) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:29) ~[cromwell-0.19.jar:0.19]; > at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.liftedTree1$1(DatabaseComponent.scala:237) ~[cromwell-0.19.jar:0.19]; > at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.run(DatabaseComponent.scala:237) ~[cromwell-0.19.jar:0.19]; > at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_74]; > at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_74]; > at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_74]; > Caused by: org.hsqldb.HsqlException: integrity constraint violation: unique constraint or index violation; UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO table: SYMBOL; > at org.hsqldb.error.Error.error(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Constraint.getException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.index.IndexAVLMemory.insert(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.persist.RowStoreAVL.indexRow(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.TransactionManagerMVCC.addInsertAction(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Session.addInsertAction(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Table.insertSingleRow(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.StatementDML.insertRowSet(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.StatementInsert.getResult(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.StatementDMQL.execute(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Session.executeCompiledStatement(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Session.execute(Unknown Source) ~[cromwell-0.19.jar:0.19]; > ... 23 c,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/869
https://github.com/broadinstitute/cromwell/issues/869:4285,Availability,error,error,4285,) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:32) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:29) ~[cromwell-0.19.jar:0.19]; > at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.liftedTree1$1(DatabaseComponent.scala:237) ~[cromwell-0.19.jar:0.19]; > at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.run(DatabaseComponent.scala:237) ~[cromwell-0.19.jar:0.19]; > at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_74]; > at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_74]; > at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_74]; > Caused by: org.hsqldb.HsqlException: integrity constraint violation: unique constraint or index violation; UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO table: SYMBOL; > at org.hsqldb.error.Error.error(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Constraint.getException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.index.IndexAVLMemory.insert(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.persist.RowStoreAVL.indexRow(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.TransactionManagerMVCC.addInsertAction(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Session.addInsertAction(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Table.insertSingleRow(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.StatementDML.insertRowSet(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.StatementInsert.getResult(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.StatementDMQL.execute(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Session.executeCompiledStatement(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Session.execute(Unknown Source) ~[cromwell-0.19.jar:0.19]; > ... 23 common frames omitted,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/869
https://github.com/broadinstitute/cromwell/issues/869:3834,Performance,concurren,concurrent,3834,$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell-0.19.jar:0.19]; > at scala.collection.immutable.List.foreach(List.scala:381) ~[cromwell-0.19.jar:0.19]; > at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell-0.19.jar:0.19]; > at scala.collection.immutable.List.map(List.scala:285) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction.run(JdbcActionComponent.scala:522) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:32) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:29) ~[cromwell-0.19.jar:0.19]; > at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.liftedTree1$1(DatabaseComponent.scala:237) ~[cromwell-0.19.jar:0.19]; > at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.run(DatabaseComponent.scala:237) ~[cromwell-0.19.jar:0.19]; > at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_74]; > at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_74]; > at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_74]; > Caused by: org.hsqldb.HsqlException: integrity constraint violation: unique constraint or index violation; UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO table: SYMBOL; > at org.hsqldb.error.Error.error(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Constraint.getException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.index.IndexAVLMemory.insert(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.persist.RowStoreAVL.indexRow(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.TransactionManagerMVCC.addInsertAction(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Session.addInsertAction(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Table.insertSingleRow(Unknown Source) ~[cromwell-0.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/869
https://github.com/broadinstitute/cromwell/issues/869:3935,Performance,concurren,concurrent,3935,table.List.foreach(List.scala:381) ~[cromwell-0.19.jar:0.19]; > at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell-0.19.jar:0.19]; > at scala.collection.immutable.List.map(List.scala:285) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction.run(JdbcActionComponent.scala:522) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:32) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:29) ~[cromwell-0.19.jar:0.19]; > at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.liftedTree1$1(DatabaseComponent.scala:237) ~[cromwell-0.19.jar:0.19]; > at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.run(DatabaseComponent.scala:237) ~[cromwell-0.19.jar:0.19]; > at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_74]; > at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_74]; > at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_74]; > Caused by: org.hsqldb.HsqlException: integrity constraint violation: unique constraint or index violation; UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO table: SYMBOL; > at org.hsqldb.error.Error.error(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Constraint.getException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.index.IndexAVLMemory.insert(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.persist.RowStoreAVL.indexRow(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.TransactionManagerMVCC.addInsertAction(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Session.addInsertAction(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Table.insertSingleRow(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.StatementDML.insertRowSet(Unknown Source) ~[cromwell-0.19.jar:0.19]; > ,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/869
https://github.com/broadinstitute/cromwell/issues/869:109,Safety,abort,abort,109,"- branch 0.19_hotfix a6f7c00b71dd22485d5e95c9a30f3dedd2ddeaba; - running with default application.conf. If I abort a running job via POST to the API endpoint `worflows/v1/<uuid>/abort`, this appears in the server logs:. > 2016-05-23 10:21:55,192 cromwell-system-akka.actor.default-dispatcher-6 INFO - CallActor [UUID(87ebf02f):Godot]: Abort function called.; > 2016-05-23 10:21:55,201 cromwell-system-akka.actor.default-dispatcher-5 INFO - WorkflowActor [UUID(87ebf02f)]: Beginning transition from Running to Aborting.; > 2016-05-23 10:21:55,201 cromwell-system-akka.actor.default-dispatcher-5 INFO - WorkflowActor [UUID(87ebf02f)]: transitioning from Running to Aborting.; > 2016-05-23 10:22:00,175 cromwell-system-akka.actor.default-dispatcher-8 INFO - LocalBackend [UUID(87ebf02f):Godot]: Return code: 0; > 2016-05-23 10:22:00,313 cromwell-system-akka.actor.default-dispatcher-2 ERROR - WorkflowActor [UUID(87ebf02f)]: Completion work failed for call Godot.; > java.sql.SQLIntegrityConstraintViolationException: integrity constraint violation: unique constraint or index violation; UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO table: SYMBOL; > at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCPreparedStatement.fetchResult(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCPreparedStatement.executeUpdate(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at com.zaxxer.hikari.proxy.PreparedStatementProxy.executeUpdate(PreparedStatementProxy.java:61) ~[cromwell-0.19.jar:0.19]; > at com.zaxxer.hikari.proxy.PreparedStatementJavassistProxy.executeUpdate(PreparedStatementJavassistProxy.java) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction$$anonfun$run$8$$anonfun$apply$1.apply(JdbcActionComponent.scala:520) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponen",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/869
https://github.com/broadinstitute/cromwell/issues/869:178,Safety,abort,abort,178,"- branch 0.19_hotfix a6f7c00b71dd22485d5e95c9a30f3dedd2ddeaba; - running with default application.conf. If I abort a running job via POST to the API endpoint `worflows/v1/<uuid>/abort`, this appears in the server logs:. > 2016-05-23 10:21:55,192 cromwell-system-akka.actor.default-dispatcher-6 INFO - CallActor [UUID(87ebf02f):Godot]: Abort function called.; > 2016-05-23 10:21:55,201 cromwell-system-akka.actor.default-dispatcher-5 INFO - WorkflowActor [UUID(87ebf02f)]: Beginning transition from Running to Aborting.; > 2016-05-23 10:21:55,201 cromwell-system-akka.actor.default-dispatcher-5 INFO - WorkflowActor [UUID(87ebf02f)]: transitioning from Running to Aborting.; > 2016-05-23 10:22:00,175 cromwell-system-akka.actor.default-dispatcher-8 INFO - LocalBackend [UUID(87ebf02f):Godot]: Return code: 0; > 2016-05-23 10:22:00,313 cromwell-system-akka.actor.default-dispatcher-2 ERROR - WorkflowActor [UUID(87ebf02f)]: Completion work failed for call Godot.; > java.sql.SQLIntegrityConstraintViolationException: integrity constraint violation: unique constraint or index violation; UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO table: SYMBOL; > at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCPreparedStatement.fetchResult(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCPreparedStatement.executeUpdate(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at com.zaxxer.hikari.proxy.PreparedStatementProxy.executeUpdate(PreparedStatementProxy.java:61) ~[cromwell-0.19.jar:0.19]; > at com.zaxxer.hikari.proxy.PreparedStatementJavassistProxy.executeUpdate(PreparedStatementJavassistProxy.java) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction$$anonfun$run$8$$anonfun$apply$1.apply(JdbcActionComponent.scala:520) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponen",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/869
https://github.com/broadinstitute/cromwell/issues/869:335,Safety,Abort,Abort,335,"- branch 0.19_hotfix a6f7c00b71dd22485d5e95c9a30f3dedd2ddeaba; - running with default application.conf. If I abort a running job via POST to the API endpoint `worflows/v1/<uuid>/abort`, this appears in the server logs:. > 2016-05-23 10:21:55,192 cromwell-system-akka.actor.default-dispatcher-6 INFO - CallActor [UUID(87ebf02f):Godot]: Abort function called.; > 2016-05-23 10:21:55,201 cromwell-system-akka.actor.default-dispatcher-5 INFO - WorkflowActor [UUID(87ebf02f)]: Beginning transition from Running to Aborting.; > 2016-05-23 10:21:55,201 cromwell-system-akka.actor.default-dispatcher-5 INFO - WorkflowActor [UUID(87ebf02f)]: transitioning from Running to Aborting.; > 2016-05-23 10:22:00,175 cromwell-system-akka.actor.default-dispatcher-8 INFO - LocalBackend [UUID(87ebf02f):Godot]: Return code: 0; > 2016-05-23 10:22:00,313 cromwell-system-akka.actor.default-dispatcher-2 ERROR - WorkflowActor [UUID(87ebf02f)]: Completion work failed for call Godot.; > java.sql.SQLIntegrityConstraintViolationException: integrity constraint violation: unique constraint or index violation; UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO table: SYMBOL; > at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCPreparedStatement.fetchResult(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCPreparedStatement.executeUpdate(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at com.zaxxer.hikari.proxy.PreparedStatementProxy.executeUpdate(PreparedStatementProxy.java:61) ~[cromwell-0.19.jar:0.19]; > at com.zaxxer.hikari.proxy.PreparedStatementJavassistProxy.executeUpdate(PreparedStatementJavassistProxy.java) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction$$anonfun$run$8$$anonfun$apply$1.apply(JdbcActionComponent.scala:520) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponen",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/869
https://github.com/broadinstitute/cromwell/issues/869:509,Safety,Abort,Aborting,509,"- branch 0.19_hotfix a6f7c00b71dd22485d5e95c9a30f3dedd2ddeaba; - running with default application.conf. If I abort a running job via POST to the API endpoint `worflows/v1/<uuid>/abort`, this appears in the server logs:. > 2016-05-23 10:21:55,192 cromwell-system-akka.actor.default-dispatcher-6 INFO - CallActor [UUID(87ebf02f):Godot]: Abort function called.; > 2016-05-23 10:21:55,201 cromwell-system-akka.actor.default-dispatcher-5 INFO - WorkflowActor [UUID(87ebf02f)]: Beginning transition from Running to Aborting.; > 2016-05-23 10:21:55,201 cromwell-system-akka.actor.default-dispatcher-5 INFO - WorkflowActor [UUID(87ebf02f)]: transitioning from Running to Aborting.; > 2016-05-23 10:22:00,175 cromwell-system-akka.actor.default-dispatcher-8 INFO - LocalBackend [UUID(87ebf02f):Godot]: Return code: 0; > 2016-05-23 10:22:00,313 cromwell-system-akka.actor.default-dispatcher-2 ERROR - WorkflowActor [UUID(87ebf02f)]: Completion work failed for call Godot.; > java.sql.SQLIntegrityConstraintViolationException: integrity constraint violation: unique constraint or index violation; UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO table: SYMBOL; > at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCPreparedStatement.fetchResult(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCPreparedStatement.executeUpdate(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at com.zaxxer.hikari.proxy.PreparedStatementProxy.executeUpdate(PreparedStatementProxy.java:61) ~[cromwell-0.19.jar:0.19]; > at com.zaxxer.hikari.proxy.PreparedStatementJavassistProxy.executeUpdate(PreparedStatementJavassistProxy.java) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction$$anonfun$run$8$$anonfun$apply$1.apply(JdbcActionComponent.scala:520) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponen",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/869
https://github.com/broadinstitute/cromwell/issues/869:663,Safety,Abort,Aborting,663,"- branch 0.19_hotfix a6f7c00b71dd22485d5e95c9a30f3dedd2ddeaba; - running with default application.conf. If I abort a running job via POST to the API endpoint `worflows/v1/<uuid>/abort`, this appears in the server logs:. > 2016-05-23 10:21:55,192 cromwell-system-akka.actor.default-dispatcher-6 INFO - CallActor [UUID(87ebf02f):Godot]: Abort function called.; > 2016-05-23 10:21:55,201 cromwell-system-akka.actor.default-dispatcher-5 INFO - WorkflowActor [UUID(87ebf02f)]: Beginning transition from Running to Aborting.; > 2016-05-23 10:21:55,201 cromwell-system-akka.actor.default-dispatcher-5 INFO - WorkflowActor [UUID(87ebf02f)]: transitioning from Running to Aborting.; > 2016-05-23 10:22:00,175 cromwell-system-akka.actor.default-dispatcher-8 INFO - LocalBackend [UUID(87ebf02f):Godot]: Return code: 0; > 2016-05-23 10:22:00,313 cromwell-system-akka.actor.default-dispatcher-2 ERROR - WorkflowActor [UUID(87ebf02f)]: Completion work failed for call Godot.; > java.sql.SQLIntegrityConstraintViolationException: integrity constraint violation: unique constraint or index violation; UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO table: SYMBOL; > at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCPreparedStatement.fetchResult(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCPreparedStatement.executeUpdate(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at com.zaxxer.hikari.proxy.PreparedStatementProxy.executeUpdate(PreparedStatementProxy.java:61) ~[cromwell-0.19.jar:0.19]; > at com.zaxxer.hikari.proxy.PreparedStatementJavassistProxy.executeUpdate(PreparedStatementJavassistProxy.java) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction$$anonfun$run$8$$anonfun$apply$1.apply(JdbcActionComponent.scala:520) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponen",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/869
https://github.com/broadinstitute/cromwell/issues/869:1015,Security,integrity,integrity,1015,"nning with default application.conf. If I abort a running job via POST to the API endpoint `worflows/v1/<uuid>/abort`, this appears in the server logs:. > 2016-05-23 10:21:55,192 cromwell-system-akka.actor.default-dispatcher-6 INFO - CallActor [UUID(87ebf02f):Godot]: Abort function called.; > 2016-05-23 10:21:55,201 cromwell-system-akka.actor.default-dispatcher-5 INFO - WorkflowActor [UUID(87ebf02f)]: Beginning transition from Running to Aborting.; > 2016-05-23 10:21:55,201 cromwell-system-akka.actor.default-dispatcher-5 INFO - WorkflowActor [UUID(87ebf02f)]: transitioning from Running to Aborting.; > 2016-05-23 10:22:00,175 cromwell-system-akka.actor.default-dispatcher-8 INFO - LocalBackend [UUID(87ebf02f):Godot]: Return code: 0; > 2016-05-23 10:22:00,313 cromwell-system-akka.actor.default-dispatcher-2 ERROR - WorkflowActor [UUID(87ebf02f)]: Completion work failed for call Godot.; > java.sql.SQLIntegrityConstraintViolationException: integrity constraint violation: unique constraint or index violation; UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO table: SYMBOL; > at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCPreparedStatement.fetchResult(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCPreparedStatement.executeUpdate(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at com.zaxxer.hikari.proxy.PreparedStatementProxy.executeUpdate(PreparedStatementProxy.java:61) ~[cromwell-0.19.jar:0.19]; > at com.zaxxer.hikari.proxy.PreparedStatementJavassistProxy.executeUpdate(PreparedStatementJavassistProxy.java) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction$$anonfun$run$8$$anonfun$apply$1.apply(JdbcActionComponent.scala:520) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction$$anonfun$run$8$$anonfu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/869
https://github.com/broadinstitute/cromwell/issues/869:4119,Security,integrity,integrity,4119,]; > at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction.run(JdbcActionComponent.scala:522) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:32) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:29) ~[cromwell-0.19.jar:0.19]; > at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.liftedTree1$1(DatabaseComponent.scala:237) ~[cromwell-0.19.jar:0.19]; > at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.run(DatabaseComponent.scala:237) ~[cromwell-0.19.jar:0.19]; > at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_74]; > at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_74]; > at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_74]; > Caused by: org.hsqldb.HsqlException: integrity constraint violation: unique constraint or index violation; UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO table: SYMBOL; > at org.hsqldb.error.Error.error(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Constraint.getException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.index.IndexAVLMemory.insert(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.persist.RowStoreAVL.indexRow(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.TransactionManagerMVCC.addInsertAction(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Session.addInsertAction(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Table.insertSingleRow(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.StatementDML.insertRowSet(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.StatementInsert.getResult(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.StatementDMQL.execute(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Session.executeCompiledStatement(Unknown Source) ~[cromwell-0.19,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/869
https://github.com/broadinstitute/cromwell/issues/869:213,Testability,log,logs,213,"- branch 0.19_hotfix a6f7c00b71dd22485d5e95c9a30f3dedd2ddeaba; - running with default application.conf. If I abort a running job via POST to the API endpoint `worflows/v1/<uuid>/abort`, this appears in the server logs:. > 2016-05-23 10:21:55,192 cromwell-system-akka.actor.default-dispatcher-6 INFO - CallActor [UUID(87ebf02f):Godot]: Abort function called.; > 2016-05-23 10:21:55,201 cromwell-system-akka.actor.default-dispatcher-5 INFO - WorkflowActor [UUID(87ebf02f)]: Beginning transition from Running to Aborting.; > 2016-05-23 10:21:55,201 cromwell-system-akka.actor.default-dispatcher-5 INFO - WorkflowActor [UUID(87ebf02f)]: transitioning from Running to Aborting.; > 2016-05-23 10:22:00,175 cromwell-system-akka.actor.default-dispatcher-8 INFO - LocalBackend [UUID(87ebf02f):Godot]: Return code: 0; > 2016-05-23 10:22:00,313 cromwell-system-akka.actor.default-dispatcher-2 ERROR - WorkflowActor [UUID(87ebf02f)]: Completion work failed for call Godot.; > java.sql.SQLIntegrityConstraintViolationException: integrity constraint violation: unique constraint or index violation; UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO table: SYMBOL; > at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCPreparedStatement.fetchResult(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.jdbc.JDBCPreparedStatement.executeUpdate(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at com.zaxxer.hikari.proxy.PreparedStatementProxy.executeUpdate(PreparedStatementProxy.java:61) ~[cromwell-0.19.jar:0.19]; > at com.zaxxer.hikari.proxy.PreparedStatementJavassistProxy.executeUpdate(PreparedStatementJavassistProxy.java) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction$$anonfun$run$8$$anonfun$apply$1.apply(JdbcActionComponent.scala:520) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponen",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/869
https://github.com/broadinstitute/cromwell/issues/869:3369,Usability,Simpl,SimpleJdbcDriverAction,3369,9.jar:0.19]; > at slick.driver.JdbcActionComponent$ReturningInsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:636) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction$$anonfun$run$8.apply(JdbcActionComponent.scala:517) ~[cromwell-0.19.jar:0.19]; > at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell-0.19.jar:0.19]; > at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell-0.19.jar:0.19]; > at scala.collection.immutable.List.foreach(List.scala:381) ~[cromwell-0.19.jar:0.19]; > at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell-0.19.jar:0.19]; > at scala.collection.immutable.List.map(List.scala:285) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction.run(JdbcActionComponent.scala:522) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:32) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:29) ~[cromwell-0.19.jar:0.19]; > at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.liftedTree1$1(DatabaseComponent.scala:237) ~[cromwell-0.19.jar:0.19]; > at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.run(DatabaseComponent.scala:237) ~[cromwell-0.19.jar:0.19]; > at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_74]; > at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_74]; > at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_74]; > Caused by: org.hsqldb.HsqlException: integrity constraint violation: unique constraint or index violation; UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO table: SYMBOL; > at org.hsqldb.error.Error.error(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Constraint.getExcepti,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/869
https://github.com/broadinstitute/cromwell/issues/869:3491,Usability,Simpl,SimpleJdbcDriverAction,3491,ala:636) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction$$anonfun$run$8.apply(JdbcActionComponent.scala:517) ~[cromwell-0.19.jar:0.19]; > at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell-0.19.jar:0.19]; > at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell-0.19.jar:0.19]; > at scala.collection.immutable.List.foreach(List.scala:381) ~[cromwell-0.19.jar:0.19]; > at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell-0.19.jar:0.19]; > at scala.collection.immutable.List.map(List.scala:285) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction.run(JdbcActionComponent.scala:522) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:32) ~[cromwell-0.19.jar:0.19]; > at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:29) ~[cromwell-0.19.jar:0.19]; > at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.liftedTree1$1(DatabaseComponent.scala:237) ~[cromwell-0.19.jar:0.19]; > at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.run(DatabaseComponent.scala:237) ~[cromwell-0.19.jar:0.19]; > at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_74]; > at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_74]; > at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_74]; > Caused by: org.hsqldb.HsqlException: integrity constraint violation: unique constraint or index violation; UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO table: SYMBOL; > at org.hsqldb.error.Error.error(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.Constraint.getException(Unknown Source) ~[cromwell-0.19.jar:0.19]; > at org.hsqldb.index.IndexAVLMemory.insert(Unknown Source) ~[cromwell-0.19.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/869
https://github.com/broadinstitute/cromwell/issues/870:49,Testability,test,test,49,"As an example, re-enable the ScatterWorkflowSpec test (""A workflow with scatter blocks and File inputs/outputs""). The output ""sc_test.do_prepare.split_files "" renders itself in the output metadata json as:. ""sc_test.do_prepare.split_files"":""[\""/Users/kcibul/projects/cromwell/cromwell-executions/sc_test/c9b50f6c-050f-4314-a7ab-bd6cdb5d344d/call-do_prepare/temp_aa\"", \""/Users/kcibul/projects/cromwell/cromwell-executions/sc_test/c9b50f6c-050f-4314-a7ab-bd6cdb5d344d/call-do_prepare/temp_ab\"", \""/Users/kcibul/projects/cromwell/cromwell-executions/sc_test/c9b50f6c-050f-4314-a7ab-bd6cdb5d344d/call-do_prepare/temp_ac\"", \""/Users/kcibul/projects/cromwell/cromwell-executions/sc_test/c9b50f6c-050f-4314-a7ab-bd6cdb5d344d/call-do_prepare/temp_ad\""]""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/870
https://github.com/broadinstitute/cromwell/issues/871:16,Deployability,configurat,configuration,16,"If your service configuration is missing or invalid, Cromwell should fail to start up. Currently, nothing is seen until workflows are submitted and immediately fail",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/871
https://github.com/broadinstitute/cromwell/issues/871:16,Modifiability,config,configuration,16,"If your service configuration is missing or invalid, Cromwell should fail to start up. Currently, nothing is seen until workflows are submitted and immediately fail",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/871
https://github.com/broadinstitute/cromwell/pull/874:25,Testability,test,testing,25,This works on Kristian's testing branch without Thibault's #873 fixes and will also be useful for the forthcoming Query API work.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/874
https://github.com/broadinstitute/cromwell/pull/875:42,Deployability,patch,patch,42,"Hi, . I was wondering if I could submit a patch to Cromwell to support Broad's internal queue UGER, . Currently, the GridEngine job submission backend (qsub) for Cromwell doesn't take a queue argument (-q) nor a project id (-P); both of these arguments are necessary for my group to be able to submit jobs to UGER queue successfully. . I realize that I'm submitting this patch under 0.19_hotfix and not dev branch; and also not sure how the Cromwell team wants to organize the application.conf file to accommodate UGER arguments. . So putting this forth initial pull request to get feedback/instructions to add this patch, . Thanks,; Paul",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/875
https://github.com/broadinstitute/cromwell/pull/875:371,Deployability,patch,patch,371,"Hi, . I was wondering if I could submit a patch to Cromwell to support Broad's internal queue UGER, . Currently, the GridEngine job submission backend (qsub) for Cromwell doesn't take a queue argument (-q) nor a project id (-P); both of these arguments are necessary for my group to be able to submit jobs to UGER queue successfully. . I realize that I'm submitting this patch under 0.19_hotfix and not dev branch; and also not sure how the Cromwell team wants to organize the application.conf file to accommodate UGER arguments. . So putting this forth initial pull request to get feedback/instructions to add this patch, . Thanks,; Paul",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/875
https://github.com/broadinstitute/cromwell/pull/875:616,Deployability,patch,patch,616,"Hi, . I was wondering if I could submit a patch to Cromwell to support Broad's internal queue UGER, . Currently, the GridEngine job submission backend (qsub) for Cromwell doesn't take a queue argument (-q) nor a project id (-P); both of these arguments are necessary for my group to be able to submit jobs to UGER queue successfully. . I realize that I'm submitting this patch under 0.19_hotfix and not dev branch; and also not sure how the Cromwell team wants to organize the application.conf file to accommodate UGER arguments. . So putting this forth initial pull request to get feedback/instructions to add this patch, . Thanks,; Paul",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/875
https://github.com/broadinstitute/cromwell/pull/875:88,Performance,queue,queue,88,"Hi, . I was wondering if I could submit a patch to Cromwell to support Broad's internal queue UGER, . Currently, the GridEngine job submission backend (qsub) for Cromwell doesn't take a queue argument (-q) nor a project id (-P); both of these arguments are necessary for my group to be able to submit jobs to UGER queue successfully. . I realize that I'm submitting this patch under 0.19_hotfix and not dev branch; and also not sure how the Cromwell team wants to organize the application.conf file to accommodate UGER arguments. . So putting this forth initial pull request to get feedback/instructions to add this patch, . Thanks,; Paul",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/875
https://github.com/broadinstitute/cromwell/pull/875:186,Performance,queue,queue,186,"Hi, . I was wondering if I could submit a patch to Cromwell to support Broad's internal queue UGER, . Currently, the GridEngine job submission backend (qsub) for Cromwell doesn't take a queue argument (-q) nor a project id (-P); both of these arguments are necessary for my group to be able to submit jobs to UGER queue successfully. . I realize that I'm submitting this patch under 0.19_hotfix and not dev branch; and also not sure how the Cromwell team wants to organize the application.conf file to accommodate UGER arguments. . So putting this forth initial pull request to get feedback/instructions to add this patch, . Thanks,; Paul",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/875
https://github.com/broadinstitute/cromwell/pull/875:314,Performance,queue,queue,314,"Hi, . I was wondering if I could submit a patch to Cromwell to support Broad's internal queue UGER, . Currently, the GridEngine job submission backend (qsub) for Cromwell doesn't take a queue argument (-q) nor a project id (-P); both of these arguments are necessary for my group to be able to submit jobs to UGER queue successfully. . I realize that I'm submitting this patch under 0.19_hotfix and not dev branch; and also not sure how the Cromwell team wants to organize the application.conf file to accommodate UGER arguments. . So putting this forth initial pull request to get feedback/instructions to add this patch, . Thanks,; Paul",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/875
https://github.com/broadinstitute/cromwell/pull/875:582,Usability,feedback,feedback,582,"Hi, . I was wondering if I could submit a patch to Cromwell to support Broad's internal queue UGER, . Currently, the GridEngine job submission backend (qsub) for Cromwell doesn't take a queue argument (-q) nor a project id (-P); both of these arguments are necessary for my group to be able to submit jobs to UGER queue successfully. . I realize that I'm submitting this patch under 0.19_hotfix and not dev branch; and also not sure how the Cromwell team wants to organize the application.conf file to accommodate UGER arguments. . So putting this forth initial pull request to get feedback/instructions to add this patch, . Thanks,; Paul",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/875
https://github.com/broadinstitute/cromwell/issues/876:20,Testability,test,tests,20,need to run all the tests with 'sbt test' but this will flake out regularly,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/876
https://github.com/broadinstitute/cromwell/issues/876:36,Testability,test,test,36,need to run all the tests with 'sbt test' but this will flake out regularly,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/876
https://github.com/broadinstitute/cromwell/issues/877:305,Integrability,message,message,305,"I noticed that WorkflowActorSpec is a bit flakey, specifically ""transition to InitializingWorkflowState with correct call assignments given workflow options"".  It fails with ""WorkflowFailedState was not equal to InitializingWorkflowState"".  I think the problem is that the test set the FSM state, fires a message and then checks the new state.  The FSM when it gets that message transitions to the right state (Initializing) and then transitions to the next state (failed) and sometimes the test misses the initializing. but all that might be because the runtime options aren't actually valid?  (sge backend) but I'm missing the purpose of that specific setting so I don't want to change it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/877
https://github.com/broadinstitute/cromwell/issues/877:371,Integrability,message,message,371,"I noticed that WorkflowActorSpec is a bit flakey, specifically ""transition to InitializingWorkflowState with correct call assignments given workflow options"".  It fails with ""WorkflowFailedState was not equal to InitializingWorkflowState"".  I think the problem is that the test set the FSM state, fires a message and then checks the new state.  The FSM when it gets that message transitions to the right state (Initializing) and then transitions to the next state (failed) and sometimes the test misses the initializing. but all that might be because the runtime options aren't actually valid?  (sge backend) but I'm missing the purpose of that specific setting so I don't want to change it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/877
https://github.com/broadinstitute/cromwell/issues/877:273,Testability,test,test,273,"I noticed that WorkflowActorSpec is a bit flakey, specifically ""transition to InitializingWorkflowState with correct call assignments given workflow options"".  It fails with ""WorkflowFailedState was not equal to InitializingWorkflowState"".  I think the problem is that the test set the FSM state, fires a message and then checks the new state.  The FSM when it gets that message transitions to the right state (Initializing) and then transitions to the next state (failed) and sometimes the test misses the initializing. but all that might be because the runtime options aren't actually valid?  (sge backend) but I'm missing the purpose of that specific setting so I don't want to change it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/877
https://github.com/broadinstitute/cromwell/issues/877:491,Testability,test,test,491,"I noticed that WorkflowActorSpec is a bit flakey, specifically ""transition to InitializingWorkflowState with correct call assignments given workflow options"".  It fails with ""WorkflowFailedState was not equal to InitializingWorkflowState"".  I think the problem is that the test set the FSM state, fires a message and then checks the new state.  The FSM when it gets that message transitions to the right state (Initializing) and then transitions to the next state (failed) and sometimes the test misses the initializing. but all that might be because the runtime options aren't actually valid?  (sge backend) but I'm missing the purpose of that specific setting so I don't want to change it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/877
https://github.com/broadinstitute/cromwell/pull/878:156,Availability,failure,failures,156,"… all moving in the right direction. Test Infrastructure updated to handle the test re-enabled here, including ThreeStep. There are a few intermittent test failures, bugged as #850 #876 #877",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/878
https://github.com/broadinstitute/cromwell/pull/878:57,Deployability,update,updated,57,"… all moving in the right direction. Test Infrastructure updated to handle the test re-enabled here, including ThreeStep. There are a few intermittent test failures, bugged as #850 #876 #877",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/878
https://github.com/broadinstitute/cromwell/pull/878:37,Testability,Test,Test,37,"… all moving in the right direction. Test Infrastructure updated to handle the test re-enabled here, including ThreeStep. There are a few intermittent test failures, bugged as #850 #876 #877",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/878
https://github.com/broadinstitute/cromwell/pull/878:79,Testability,test,test,79,"… all moving in the right direction. Test Infrastructure updated to handle the test re-enabled here, including ThreeStep. There are a few intermittent test failures, bugged as #850 #876 #877",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/878
https://github.com/broadinstitute/cromwell/pull/878:151,Testability,test,test,151,"… all moving in the right direction. Test Infrastructure updated to handle the test re-enabled here, including ThreeStep. There are a few intermittent test failures, bugged as #850 #876 #877",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/878
https://github.com/broadinstitute/cromwell/issues/880:98,Availability,error,errors,98,"This task failed after a restart of Cromwell with the following stack trace. We have seen similar errors before - #588. This was only after one restart though. ```; 2016-05-24 16:59:43,266 cromwell-system-akka.actor.default-dispatcher-6 INFO - JesBackend [UUID(fd62961b):ApplyBQSR:11]: Starting call with pre-emptible VM. 2016-05-24 16:59:43,431 cromwell-system-akka.actor.default-dispatcher-17 INFO - WorkflowActor [UUID(fd62961b)]: persisting status of ApplyBQSR:11 to Running. 2016-05-24 16:59:43,526 cromwell-system-akka.actor.default-dispatcher-6 INFO - JES Run [UUID(fd62961b):ApplyBQSR:11]: Status change from - to Success. 2016-05-24 16:59:44,173 cromwell-system-akka.actor.default-dispatcher-13 ERROR - WorkflowActor [UUID(fd62961b)]: Completion work failed for call ApplyBQSR:11.; com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException: Duplicate entry '741-PairedEndSingleSampleWorkflow.ApplyBQSR-recalibrated_bam-11-' for key 'UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO'; at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[na:1.8.0_72]; at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[na:1.8.0_72]; at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[na:1.8.0_72]; at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[na:1.8.0_72]; at com.mysql.jdbc.Util.handleNewInstance(Util.java:400) ~[cromwell.jar:0.19]; at com.mysql.jdbc.Util.getInstance(Util.java:383) ~[cromwell.jar:0.19]; at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:973) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3847) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3783) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2447) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2594) ~[cromwell.jar:0.19]; at com.mysql.jdbc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/880
https://github.com/broadinstitute/cromwell/issues/880:704,Availability,ERROR,ERROR,704,"This task failed after a restart of Cromwell with the following stack trace. We have seen similar errors before - #588. This was only after one restart though. ```; 2016-05-24 16:59:43,266 cromwell-system-akka.actor.default-dispatcher-6 INFO - JesBackend [UUID(fd62961b):ApplyBQSR:11]: Starting call with pre-emptible VM. 2016-05-24 16:59:43,431 cromwell-system-akka.actor.default-dispatcher-17 INFO - WorkflowActor [UUID(fd62961b)]: persisting status of ApplyBQSR:11 to Running. 2016-05-24 16:59:43,526 cromwell-system-akka.actor.default-dispatcher-6 INFO - JES Run [UUID(fd62961b):ApplyBQSR:11]: Status change from - to Success. 2016-05-24 16:59:44,173 cromwell-system-akka.actor.default-dispatcher-13 ERROR - WorkflowActor [UUID(fd62961b)]: Completion work failed for call ApplyBQSR:11.; com.mysql.jdbc.exceptions.jdbc4.MySQLIntegrityConstraintViolationException: Duplicate entry '741-PairedEndSingleSampleWorkflow.ApplyBQSR-recalibrated_bam-11-' for key 'UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO'; at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[na:1.8.0_72]; at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[na:1.8.0_72]; at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[na:1.8.0_72]; at java.lang.reflect.Constructor.newInstance(Constructor.java:423) ~[na:1.8.0_72]; at com.mysql.jdbc.Util.handleNewInstance(Util.java:400) ~[cromwell.jar:0.19]; at com.mysql.jdbc.Util.getInstance(Util.java:383) ~[cromwell.jar:0.19]; at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:973) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3847) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3783) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:2447) ~[cromwell.jar:0.19]; at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2594) ~[cromwell.jar:0.19]; at com.mysql.jdbc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/880
https://github.com/broadinstitute/cromwell/issues/880:5305,Availability,ERROR,ERROR,5305,"ableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.foreach(List.scala:381) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.map(List.scala:285) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction.run(JdbcActionComponent.scala:522) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:32) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:29) ~[cromwell.jar:0.19]; at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.liftedTree1$1(DatabaseComponent.scala:237) ~[cromwell.jar:0.19]; at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.run(DatabaseComponent.scala:237) ~[cromwell.jar:0.19]; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_72]; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_72]; at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_72]; 2016-05-24 16:59:44,174 cromwell-system-akka.actor.default-dispatcher-12 INFO - JesBackend [UUID(fd62961b):ApplyBQSRToUnmappedReads]: Starting call with pre-emptible VM; 2016-05-24 16:59:44,175 cromwell-system-akka.actor.default-dispatcher-22 INFO - WorkflowActor [UUID(fd62961b)]: persisting status of ApplyBQSR:11 to Failed.; 2016-05-24 16:59:44,180 cromwell-system-akka.actor.default-dispatcher-13 ERROR - WorkflowActor [UUID(fd62961b)]: Duplicate entry '741-PairedEndSingleSampleWorkflow.ApplyBQSR-recalibrated_bam-11-' for key 'UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO'. 2016-05-24 16:59:44,175 cromwell-system-akka.actor.default-dispatcher-22 INFO - WorkflowActor [UUID(fd62961b)]: persisting status of ApplyBQSR:11 to Failed. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/880
https://github.com/broadinstitute/cromwell/issues/880:4662,Performance,concurren,concurrent,4662,"ableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.foreach(List.scala:381) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.map(List.scala:285) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction.run(JdbcActionComponent.scala:522) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:32) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:29) ~[cromwell.jar:0.19]; at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.liftedTree1$1(DatabaseComponent.scala:237) ~[cromwell.jar:0.19]; at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.run(DatabaseComponent.scala:237) ~[cromwell.jar:0.19]; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_72]; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_72]; at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_72]; 2016-05-24 16:59:44,174 cromwell-system-akka.actor.default-dispatcher-12 INFO - JesBackend [UUID(fd62961b):ApplyBQSRToUnmappedReads]: Starting call with pre-emptible VM; 2016-05-24 16:59:44,175 cromwell-system-akka.actor.default-dispatcher-22 INFO - WorkflowActor [UUID(fd62961b)]: persisting status of ApplyBQSR:11 to Failed.; 2016-05-24 16:59:44,180 cromwell-system-akka.actor.default-dispatcher-13 ERROR - WorkflowActor [UUID(fd62961b)]: Duplicate entry '741-PairedEndSingleSampleWorkflow.ApplyBQSR-recalibrated_bam-11-' for key 'UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO'. 2016-05-24 16:59:44,175 cromwell-system-akka.actor.default-dispatcher-22 INFO - WorkflowActor [UUID(fd62961b)]: persisting status of ApplyBQSR:11 to Failed. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/880
https://github.com/broadinstitute/cromwell/issues/880:4761,Performance,concurren,concurrent,4761,"ableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.foreach(List.scala:381) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.map(List.scala:285) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction.run(JdbcActionComponent.scala:522) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:32) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:29) ~[cromwell.jar:0.19]; at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.liftedTree1$1(DatabaseComponent.scala:237) ~[cromwell.jar:0.19]; at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.run(DatabaseComponent.scala:237) ~[cromwell.jar:0.19]; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_72]; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_72]; at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_72]; 2016-05-24 16:59:44,174 cromwell-system-akka.actor.default-dispatcher-12 INFO - JesBackend [UUID(fd62961b):ApplyBQSRToUnmappedReads]: Starting call with pre-emptible VM; 2016-05-24 16:59:44,175 cromwell-system-akka.actor.default-dispatcher-22 INFO - WorkflowActor [UUID(fd62961b)]: persisting status of ApplyBQSR:11 to Failed.; 2016-05-24 16:59:44,180 cromwell-system-akka.actor.default-dispatcher-13 ERROR - WorkflowActor [UUID(fd62961b)]: Duplicate entry '741-PairedEndSingleSampleWorkflow.ApplyBQSR-recalibrated_bam-11-' for key 'UK_SYM_WORKFLOW_EXECUTION_ID_SCOPE_NAME_ITERATION_IO'. 2016-05-24 16:59:44,175 cromwell-system-akka.actor.default-dispatcher-22 INFO - WorkflowActor [UUID(fd62961b)]: persisting status of ApplyBQSR:11 to Failed. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/880
https://github.com/broadinstitute/cromwell/issues/880:4225,Usability,Simpl,SimpleJdbcDriverAction,4225,"thPreparedInsertStatement(JdbcBackend.scala:407) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$ReturningInsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:636) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction$$anonfun$run$8.apply(JdbcActionComponent.scala:517) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.foreach(List.scala:381) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.map(List.scala:285) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction.run(JdbcActionComponent.scala:522) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:32) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:29) ~[cromwell.jar:0.19]; at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.liftedTree1$1(DatabaseComponent.scala:237) ~[cromwell.jar:0.19]; at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.run(DatabaseComponent.scala:237) ~[cromwell.jar:0.19]; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_72]; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_72]; at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_72]; 2016-05-24 16:59:44,174 cromwell-system-akka.actor.default-dispatcher-12 INFO - JesBackend [UUID(fd62961b):ApplyBQSRToUnmappedReads]: Starting call with pre-emptible VM; 2016-05-24 16:59:44,175 cromwell-system-akka.actor.default-dispatcher-22 INFO - WorkflowActor [UUID(fd62961b)]: persisting status of ApplyBQSR:11 to Fail",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/880
https://github.com/broadinstitute/cromwell/issues/880:4340,Usability,Simpl,SimpleJdbcDriverAction,4340,"gInsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:636) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction$$anonfun$run$8.apply(JdbcActionComponent.scala:517) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.foreach(List.scala:381) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$class.map(TraversableLike.scala:245) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.map(List.scala:285) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction.run(JdbcActionComponent.scala:522) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:32) ~[cromwell.jar:0.19]; at slick.driver.JdbcActionComponent$SimpleJdbcDriverAction.run(JdbcActionComponent.scala:29) ~[cromwell.jar:0.19]; at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.liftedTree1$1(DatabaseComponent.scala:237) ~[cromwell.jar:0.19]; at slick.backend.DatabaseComponent$DatabaseDef$$anon$2.run(DatabaseComponent.scala:237) ~[cromwell.jar:0.19]; at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_72]; at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_72]; at java.lang.Thread.run(Thread.java:745) ~[na:1.8.0_72]; 2016-05-24 16:59:44,174 cromwell-system-akka.actor.default-dispatcher-12 INFO - JesBackend [UUID(fd62961b):ApplyBQSRToUnmappedReads]: Starting call with pre-emptible VM; 2016-05-24 16:59:44,175 cromwell-system-akka.actor.default-dispatcher-22 INFO - WorkflowActor [UUID(fd62961b)]: persisting status of ApplyBQSR:11 to Failed.; 2016-05-24 16:59:44,180 cromwell-system-akka.actor.default-dispatcher-13 ERROR - WorkflowActor [UUID(fd62961b)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/880
https://github.com/broadinstitute/cromwell/issues/882:89,Availability,ERROR,ERROR,89,"Much sad:. ```; 2016-05-24 14:11:46,501 cromwell-system-akka.actor.default-dispatcher-23 ERROR - Workflow d539eabc-3e74-4f06-85ca-0f52ac1f8a2b failed (during ExecutingWorkflowState): java.lang.Throwable: Failed post processing of outputs: ; Workflow d539eabc-3e74-4f06-85ca-0f52ac1f8a2b post processing failedglob function is not supported by this implementation; ```. ```; glob function is not supported by this implementation; ```. ```; 2016-05-24 14:11:46,501 cromwell-system-akka.actor.default-dispatcher-23 ERROR - Workflow d539eabc-3e74-4f06-85ca-0f52ac1f8a2b failed (during ExecutingWorkflowState): ; ```. ```; 2016-05-24 14:11:46,501 cromwell-system-akka.actor.default-dispatcher-23 INFO - WorkflowActor-d539eabc-3e74-4f06-85ca-0f52ac1f8a2b has gone terminal; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/882
https://github.com/broadinstitute/cromwell/issues/882:512,Availability,ERROR,ERROR,512,"Much sad:. ```; 2016-05-24 14:11:46,501 cromwell-system-akka.actor.default-dispatcher-23 ERROR - Workflow d539eabc-3e74-4f06-85ca-0f52ac1f8a2b failed (during ExecutingWorkflowState): java.lang.Throwable: Failed post processing of outputs: ; Workflow d539eabc-3e74-4f06-85ca-0f52ac1f8a2b post processing failedglob function is not supported by this implementation; ```. ```; glob function is not supported by this implementation; ```. ```; 2016-05-24 14:11:46,501 cromwell-system-akka.actor.default-dispatcher-23 ERROR - Workflow d539eabc-3e74-4f06-85ca-0f52ac1f8a2b failed (during ExecutingWorkflowState): ; ```. ```; 2016-05-24 14:11:46,501 cromwell-system-akka.actor.default-dispatcher-23 INFO - WorkflowActor-d539eabc-3e74-4f06-85ca-0f52ac1f8a2b has gone terminal; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/882
https://github.com/broadinstitute/cromwell/issues/887:33,Integrability,depend,depends,33,"The engine sub-project currently depends on the services sub-project. But some services still living in `cromwell.services` depend on engine-specific database code: [[1]](https://github.com/broadinstitute/cromwell/blob/0ff86c409d2e5dac4b766fceb89f47ba3c304f99/engine/src/main/scala/cromwell/services/MetadataServiceActor.scala#L51), [[2]](https://github.com/broadinstitute/cromwell/blob/0ff86c409d2e5dac4b766fceb89f47ba3c304f99/engine/src/main/scala/cromwell/services/KeyValueServiceActor.scala#L51-L56). (NOTE: these links are from a snapshot of develop. As the services continue to become more flushed out, one may find additional engine dependencies have been added.). Our current way of talking to the database is to use the database singleton. The class itself contains utility methods that receive engine specific classes and map them to the database layer: [[3]](https://github.com/broadinstitute/cromwell/blob/0ff86c409d2e5dac4b766fceb89f47ba3c304f99/engine/src/main/scala/cromwell/engine/db/DataAccess.scala#L58-L61), [[4]](https://github.com/broadinstitute/cromwell/blob/0ff86c409d2e5dac4b766fceb89f47ba3c304f99/engine/src/main/scala/cromwell/engine/db/DataAccess.scala#L156-L157), [[5]](https://github.com/broadinstitute/cromwell/blob/0ff86c409d2e5dac4b766fceb89f47ba3c304f99/engine/src/main/scala/cromwell/engine/db/DataAccess.scala#L577-L578), etc. The goal of this ticket is to not have any classes in the package `cromwell.services` living in the engine sub-project. It's possible this may be achieved by a number of different ways:; - Move the affected classes to `cromwell.engine.services`; - Talk directly to the [lower database layer](https://github.com/broadinstitute/cromwell/blob/0ff86c409d2e5dac4b766fceb89f47ba3c304f99/database/src/main/scala/cromwell/database/SqlDatabase.scala) that doesn't provide engine utility mappings; - Further separate out `core` code from `engine` _(ExecutionIndex, I'm looking at you)_; - etc.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/887
https://github.com/broadinstitute/cromwell/issues/887:124,Integrability,depend,depend,124,"The engine sub-project currently depends on the services sub-project. But some services still living in `cromwell.services` depend on engine-specific database code: [[1]](https://github.com/broadinstitute/cromwell/blob/0ff86c409d2e5dac4b766fceb89f47ba3c304f99/engine/src/main/scala/cromwell/services/MetadataServiceActor.scala#L51), [[2]](https://github.com/broadinstitute/cromwell/blob/0ff86c409d2e5dac4b766fceb89f47ba3c304f99/engine/src/main/scala/cromwell/services/KeyValueServiceActor.scala#L51-L56). (NOTE: these links are from a snapshot of develop. As the services continue to become more flushed out, one may find additional engine dependencies have been added.). Our current way of talking to the database is to use the database singleton. The class itself contains utility methods that receive engine specific classes and map them to the database layer: [[3]](https://github.com/broadinstitute/cromwell/blob/0ff86c409d2e5dac4b766fceb89f47ba3c304f99/engine/src/main/scala/cromwell/engine/db/DataAccess.scala#L58-L61), [[4]](https://github.com/broadinstitute/cromwell/blob/0ff86c409d2e5dac4b766fceb89f47ba3c304f99/engine/src/main/scala/cromwell/engine/db/DataAccess.scala#L156-L157), [[5]](https://github.com/broadinstitute/cromwell/blob/0ff86c409d2e5dac4b766fceb89f47ba3c304f99/engine/src/main/scala/cromwell/engine/db/DataAccess.scala#L577-L578), etc. The goal of this ticket is to not have any classes in the package `cromwell.services` living in the engine sub-project. It's possible this may be achieved by a number of different ways:; - Move the affected classes to `cromwell.engine.services`; - Talk directly to the [lower database layer](https://github.com/broadinstitute/cromwell/blob/0ff86c409d2e5dac4b766fceb89f47ba3c304f99/database/src/main/scala/cromwell/database/SqlDatabase.scala) that doesn't provide engine utility mappings; - Further separate out `core` code from `engine` _(ExecutionIndex, I'm looking at you)_; - etc.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/887
https://github.com/broadinstitute/cromwell/issues/887:640,Integrability,depend,dependencies,640,"The engine sub-project currently depends on the services sub-project. But some services still living in `cromwell.services` depend on engine-specific database code: [[1]](https://github.com/broadinstitute/cromwell/blob/0ff86c409d2e5dac4b766fceb89f47ba3c304f99/engine/src/main/scala/cromwell/services/MetadataServiceActor.scala#L51), [[2]](https://github.com/broadinstitute/cromwell/blob/0ff86c409d2e5dac4b766fceb89f47ba3c304f99/engine/src/main/scala/cromwell/services/KeyValueServiceActor.scala#L51-L56). (NOTE: these links are from a snapshot of develop. As the services continue to become more flushed out, one may find additional engine dependencies have been added.). Our current way of talking to the database is to use the database singleton. The class itself contains utility methods that receive engine specific classes and map them to the database layer: [[3]](https://github.com/broadinstitute/cromwell/blob/0ff86c409d2e5dac4b766fceb89f47ba3c304f99/engine/src/main/scala/cromwell/engine/db/DataAccess.scala#L58-L61), [[4]](https://github.com/broadinstitute/cromwell/blob/0ff86c409d2e5dac4b766fceb89f47ba3c304f99/engine/src/main/scala/cromwell/engine/db/DataAccess.scala#L156-L157), [[5]](https://github.com/broadinstitute/cromwell/blob/0ff86c409d2e5dac4b766fceb89f47ba3c304f99/engine/src/main/scala/cromwell/engine/db/DataAccess.scala#L577-L578), etc. The goal of this ticket is to not have any classes in the package `cromwell.services` living in the engine sub-project. It's possible this may be achieved by a number of different ways:; - Move the affected classes to `cromwell.engine.services`; - Talk directly to the [lower database layer](https://github.com/broadinstitute/cromwell/blob/0ff86c409d2e5dac4b766fceb89f47ba3c304f99/database/src/main/scala/cromwell/database/SqlDatabase.scala) that doesn't provide engine utility mappings; - Further separate out `core` code from `engine` _(ExecutionIndex, I'm looking at you)_; - etc.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/887
https://github.com/broadinstitute/cromwell/issues/888:150,Availability,error,error,150,"We had a situation where develop was broken (grab commit 0ff86c409d2e5dac4b766fceb89f47ba3c304f99). If you run ""sbt test"" it fails with a compilation error about HtCondorInitializationActorSpec.scala. However, Travis for this is green. Travis is running:. sbt -Dbackend.providers.Local.config.filesystems.local.localization.0=copy clean coverage nointegration:test coverageReport && sbt coverageAggregate && sbt assembly. Which if you run it locally yields a successful test. First thought was that it was because this test was flagged as ""nointegration"" but that's not even the case. However even if it were, we should be checking that things compile even if we don't run a certain class of tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/888
https://github.com/broadinstitute/cromwell/issues/888:229,Energy Efficiency,green,green,229,"We had a situation where develop was broken (grab commit 0ff86c409d2e5dac4b766fceb89f47ba3c304f99). If you run ""sbt test"" it fails with a compilation error about HtCondorInitializationActorSpec.scala. However, Travis for this is green. Travis is running:. sbt -Dbackend.providers.Local.config.filesystems.local.localization.0=copy clean coverage nointegration:test coverageReport && sbt coverageAggregate && sbt assembly. Which if you run it locally yields a successful test. First thought was that it was because this test was flagged as ""nointegration"" but that's not even the case. However even if it were, we should be checking that things compile even if we don't run a certain class of tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/888
https://github.com/broadinstitute/cromwell/issues/888:286,Modifiability,config,config,286,"We had a situation where develop was broken (grab commit 0ff86c409d2e5dac4b766fceb89f47ba3c304f99). If you run ""sbt test"" it fails with a compilation error about HtCondorInitializationActorSpec.scala. However, Travis for this is green. Travis is running:. sbt -Dbackend.providers.Local.config.filesystems.local.localization.0=copy clean coverage nointegration:test coverageReport && sbt coverageAggregate && sbt assembly. Which if you run it locally yields a successful test. First thought was that it was because this test was flagged as ""nointegration"" but that's not even the case. However even if it were, we should be checking that things compile even if we don't run a certain class of tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/888
https://github.com/broadinstitute/cromwell/issues/888:116,Testability,test,test,116,"We had a situation where develop was broken (grab commit 0ff86c409d2e5dac4b766fceb89f47ba3c304f99). If you run ""sbt test"" it fails with a compilation error about HtCondorInitializationActorSpec.scala. However, Travis for this is green. Travis is running:. sbt -Dbackend.providers.Local.config.filesystems.local.localization.0=copy clean coverage nointegration:test coverageReport && sbt coverageAggregate && sbt assembly. Which if you run it locally yields a successful test. First thought was that it was because this test was flagged as ""nointegration"" but that's not even the case. However even if it were, we should be checking that things compile even if we don't run a certain class of tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/888
https://github.com/broadinstitute/cromwell/issues/888:360,Testability,test,test,360,"We had a situation where develop was broken (grab commit 0ff86c409d2e5dac4b766fceb89f47ba3c304f99). If you run ""sbt test"" it fails with a compilation error about HtCondorInitializationActorSpec.scala. However, Travis for this is green. Travis is running:. sbt -Dbackend.providers.Local.config.filesystems.local.localization.0=copy clean coverage nointegration:test coverageReport && sbt coverageAggregate && sbt assembly. Which if you run it locally yields a successful test. First thought was that it was because this test was flagged as ""nointegration"" but that's not even the case. However even if it were, we should be checking that things compile even if we don't run a certain class of tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/888
https://github.com/broadinstitute/cromwell/issues/888:470,Testability,test,test,470,"We had a situation where develop was broken (grab commit 0ff86c409d2e5dac4b766fceb89f47ba3c304f99). If you run ""sbt test"" it fails with a compilation error about HtCondorInitializationActorSpec.scala. However, Travis for this is green. Travis is running:. sbt -Dbackend.providers.Local.config.filesystems.local.localization.0=copy clean coverage nointegration:test coverageReport && sbt coverageAggregate && sbt assembly. Which if you run it locally yields a successful test. First thought was that it was because this test was flagged as ""nointegration"" but that's not even the case. However even if it were, we should be checking that things compile even if we don't run a certain class of tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/888
https://github.com/broadinstitute/cromwell/issues/888:519,Testability,test,test,519,"We had a situation where develop was broken (grab commit 0ff86c409d2e5dac4b766fceb89f47ba3c304f99). If you run ""sbt test"" it fails with a compilation error about HtCondorInitializationActorSpec.scala. However, Travis for this is green. Travis is running:. sbt -Dbackend.providers.Local.config.filesystems.local.localization.0=copy clean coverage nointegration:test coverageReport && sbt coverageAggregate && sbt assembly. Which if you run it locally yields a successful test. First thought was that it was because this test was flagged as ""nointegration"" but that's not even the case. However even if it were, we should be checking that things compile even if we don't run a certain class of tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/888
https://github.com/broadinstitute/cromwell/issues/888:692,Testability,test,tests,692,"We had a situation where develop was broken (grab commit 0ff86c409d2e5dac4b766fceb89f47ba3c304f99). If you run ""sbt test"" it fails with a compilation error about HtCondorInitializationActorSpec.scala. However, Travis for this is green. Travis is running:. sbt -Dbackend.providers.Local.config.filesystems.local.localization.0=copy clean coverage nointegration:test coverageReport && sbt coverageAggregate && sbt assembly. Which if you run it locally yields a successful test. First thought was that it was because this test was flagged as ""nointegration"" but that's not even the case. However even if it were, we should be checking that things compile even if we don't run a certain class of tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/888
https://github.com/broadinstitute/cromwell/pull/889:366,Deployability,patch,patch,366,"Closed the previous Pull Request (#841) since I ended up moving things to a new branch, but I'll address previous comments here:. Q: ""Is the system section [of application.conf] mandatory? It looks like this would throw if it's missing"" ; A: I don't think the section is mandatory in 0.19_hotfix, but looking back, it is mandatory in develop, something that needs a patch surely. Q: ""How can this [val serverMode = CromwellServer.isServerMode] be false ?"" ; A: You're right, it wasn't wired to be false ever in my previous PR. I've since changed it, please review it!. Documentation for this config change has also been updated and ready for review. Question for the reviewers: I arbitrarily moved the config to the backend stanza of the config file, since the system stanza doesn't exist anymore and the ""abortJobsOnTerminate"" config is also within the backends stanza. Is there a better place for it?. **MainSpec tests failing--it must be my changes, checking that out now, but hopefully the remaining changes can be examined in parallel**",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/889
https://github.com/broadinstitute/cromwell/pull/889:620,Deployability,update,updated,620,"Closed the previous Pull Request (#841) since I ended up moving things to a new branch, but I'll address previous comments here:. Q: ""Is the system section [of application.conf] mandatory? It looks like this would throw if it's missing"" ; A: I don't think the section is mandatory in 0.19_hotfix, but looking back, it is mandatory in develop, something that needs a patch surely. Q: ""How can this [val serverMode = CromwellServer.isServerMode] be false ?"" ; A: You're right, it wasn't wired to be false ever in my previous PR. I've since changed it, please review it!. Documentation for this config change has also been updated and ready for review. Question for the reviewers: I arbitrarily moved the config to the backend stanza of the config file, since the system stanza doesn't exist anymore and the ""abortJobsOnTerminate"" config is also within the backends stanza. Is there a better place for it?. **MainSpec tests failing--it must be my changes, checking that out now, but hopefully the remaining changes can be examined in parallel**",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/889
https://github.com/broadinstitute/cromwell/pull/889:592,Modifiability,config,config,592,"Closed the previous Pull Request (#841) since I ended up moving things to a new branch, but I'll address previous comments here:. Q: ""Is the system section [of application.conf] mandatory? It looks like this would throw if it's missing"" ; A: I don't think the section is mandatory in 0.19_hotfix, but looking back, it is mandatory in develop, something that needs a patch surely. Q: ""How can this [val serverMode = CromwellServer.isServerMode] be false ?"" ; A: You're right, it wasn't wired to be false ever in my previous PR. I've since changed it, please review it!. Documentation for this config change has also been updated and ready for review. Question for the reviewers: I arbitrarily moved the config to the backend stanza of the config file, since the system stanza doesn't exist anymore and the ""abortJobsOnTerminate"" config is also within the backends stanza. Is there a better place for it?. **MainSpec tests failing--it must be my changes, checking that out now, but hopefully the remaining changes can be examined in parallel**",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/889
https://github.com/broadinstitute/cromwell/pull/889:702,Modifiability,config,config,702,"Closed the previous Pull Request (#841) since I ended up moving things to a new branch, but I'll address previous comments here:. Q: ""Is the system section [of application.conf] mandatory? It looks like this would throw if it's missing"" ; A: I don't think the section is mandatory in 0.19_hotfix, but looking back, it is mandatory in develop, something that needs a patch surely. Q: ""How can this [val serverMode = CromwellServer.isServerMode] be false ?"" ; A: You're right, it wasn't wired to be false ever in my previous PR. I've since changed it, please review it!. Documentation for this config change has also been updated and ready for review. Question for the reviewers: I arbitrarily moved the config to the backend stanza of the config file, since the system stanza doesn't exist anymore and the ""abortJobsOnTerminate"" config is also within the backends stanza. Is there a better place for it?. **MainSpec tests failing--it must be my changes, checking that out now, but hopefully the remaining changes can be examined in parallel**",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/889
https://github.com/broadinstitute/cromwell/pull/889:738,Modifiability,config,config,738,"Closed the previous Pull Request (#841) since I ended up moving things to a new branch, but I'll address previous comments here:. Q: ""Is the system section [of application.conf] mandatory? It looks like this would throw if it's missing"" ; A: I don't think the section is mandatory in 0.19_hotfix, but looking back, it is mandatory in develop, something that needs a patch surely. Q: ""How can this [val serverMode = CromwellServer.isServerMode] be false ?"" ; A: You're right, it wasn't wired to be false ever in my previous PR. I've since changed it, please review it!. Documentation for this config change has also been updated and ready for review. Question for the reviewers: I arbitrarily moved the config to the backend stanza of the config file, since the system stanza doesn't exist anymore and the ""abortJobsOnTerminate"" config is also within the backends stanza. Is there a better place for it?. **MainSpec tests failing--it must be my changes, checking that out now, but hopefully the remaining changes can be examined in parallel**",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/889
https://github.com/broadinstitute/cromwell/pull/889:828,Modifiability,config,config,828,"Closed the previous Pull Request (#841) since I ended up moving things to a new branch, but I'll address previous comments here:. Q: ""Is the system section [of application.conf] mandatory? It looks like this would throw if it's missing"" ; A: I don't think the section is mandatory in 0.19_hotfix, but looking back, it is mandatory in develop, something that needs a patch surely. Q: ""How can this [val serverMode = CromwellServer.isServerMode] be false ?"" ; A: You're right, it wasn't wired to be false ever in my previous PR. I've since changed it, please review it!. Documentation for this config change has also been updated and ready for review. Question for the reviewers: I arbitrarily moved the config to the backend stanza of the config file, since the system stanza doesn't exist anymore and the ""abortJobsOnTerminate"" config is also within the backends stanza. Is there a better place for it?. **MainSpec tests failing--it must be my changes, checking that out now, but hopefully the remaining changes can be examined in parallel**",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/889
https://github.com/broadinstitute/cromwell/pull/889:806,Safety,abort,abortJobsOnTerminate,806,"Closed the previous Pull Request (#841) since I ended up moving things to a new branch, but I'll address previous comments here:. Q: ""Is the system section [of application.conf] mandatory? It looks like this would throw if it's missing"" ; A: I don't think the section is mandatory in 0.19_hotfix, but looking back, it is mandatory in develop, something that needs a patch surely. Q: ""How can this [val serverMode = CromwellServer.isServerMode] be false ?"" ; A: You're right, it wasn't wired to be false ever in my previous PR. I've since changed it, please review it!. Documentation for this config change has also been updated and ready for review. Question for the reviewers: I arbitrarily moved the config to the backend stanza of the config file, since the system stanza doesn't exist anymore and the ""abortJobsOnTerminate"" config is also within the backends stanza. Is there a better place for it?. **MainSpec tests failing--it must be my changes, checking that out now, but hopefully the remaining changes can be examined in parallel**",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/889
https://github.com/broadinstitute/cromwell/pull/889:915,Testability,test,tests,915,"Closed the previous Pull Request (#841) since I ended up moving things to a new branch, but I'll address previous comments here:. Q: ""Is the system section [of application.conf] mandatory? It looks like this would throw if it's missing"" ; A: I don't think the section is mandatory in 0.19_hotfix, but looking back, it is mandatory in develop, something that needs a patch surely. Q: ""How can this [val serverMode = CromwellServer.isServerMode] be false ?"" ; A: You're right, it wasn't wired to be false ever in my previous PR. I've since changed it, please review it!. Documentation for this config change has also been updated and ready for review. Question for the reviewers: I arbitrarily moved the config to the backend stanza of the config file, since the system stanza doesn't exist anymore and the ""abortJobsOnTerminate"" config is also within the backends stanza. Is there a better place for it?. **MainSpec tests failing--it must be my changes, checking that out now, but hopefully the remaining changes can be examined in parallel**",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/889
https://github.com/broadinstitute/cromwell/issues/891:91,Availability,echo,echo,91,"The following workflow fails:. This workflow fails:. ```; task MakeMeAFile {; command <<<; echo FILECONTENT > output.txt; >>>. runtime {; docker: ""ubuntu:latest""; memory: ""1 GB""; preemptible: 3; }. output {; String out = read_string(""output.txt""); }; }. task ReadMeAFile {; File infile. command <<<; cat ${infile}; >>>. runtime {; docker: ""ubuntu:latest""; memory: ""1 GB""; preemptible: 3; }. output {; File out = read_string(stdout()); }; }. workflow FileMakeAndRead {; call MakeMeAFile; call ReadMeAFile { input: infile = MakeMeAFile.out }; }; ```. Because:. ```; ""failures"": [; ""Could not find suitable filesystem to parse output.txt""; ]; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/891
https://github.com/broadinstitute/cromwell/issues/891:565,Availability,failure,failures,565,"The following workflow fails:. This workflow fails:. ```; task MakeMeAFile {; command <<<; echo FILECONTENT > output.txt; >>>. runtime {; docker: ""ubuntu:latest""; memory: ""1 GB""; preemptible: 3; }. output {; String out = read_string(""output.txt""); }; }. task ReadMeAFile {; File infile. command <<<; cat ${infile}; >>>. runtime {; docker: ""ubuntu:latest""; memory: ""1 GB""; preemptible: 3; }. output {; File out = read_string(stdout()); }; }. workflow FileMakeAndRead {; call MakeMeAFile; call ReadMeAFile { input: infile = MakeMeAFile.out }; }; ```. Because:. ```; ""failures"": [; ""Could not find suitable filesystem to parse output.txt""; ]; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/891
https://github.com/broadinstitute/cromwell/issues/892:235,Availability,echo,echo,235,"I added a workaround since #891. The output block now makes a File output and then reads from it. Unfortunately, this version still doesn't work!. Here's a slightly different workflow:. ```; task MakeMeAFile {; Int c = 6. command <<<; echo FILECONTENT > output.txt; >>>. runtime {; docker: ""ubuntu:latest""; memory: ""1 GB""; preemptible: 3; }. output {; File outFile = ""output.txt""; String out = read_string(outFile); }; }. task ReadMeAFile {; File infile. command <<<; cat ${infile}; >>>. runtime {; docker: ""ubuntu:latest""; memory: ""1 GB""; preemptible: 3; }. output {; File out = read_string(stdout()); }; }. workflow FileMakeAndRead {; Int a = 5; call MakeMeAFile; call ReadMeAFile { input: infile = MakeMeAFile.out }; }; ```. And the new failure:. ```; ""failures"": [; ""Item not found: cromwell-dev/cromwell_execution/chrisl/FileMakeAndRead/000adc78-7dc7-4073-b5f6-83e499c13706/call-MakeMeAFile/cromwell-dev/cromwell_execution/chrisl/FileMakeAndRead/000adc78-7dc7-4073-b5f6-83e499c13706/call-MakeMeAFile/output.txt""; ],; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/892
https://github.com/broadinstitute/cromwell/issues/892:740,Availability,failure,failure,740,"I added a workaround since #891. The output block now makes a File output and then reads from it. Unfortunately, this version still doesn't work!. Here's a slightly different workflow:. ```; task MakeMeAFile {; Int c = 6. command <<<; echo FILECONTENT > output.txt; >>>. runtime {; docker: ""ubuntu:latest""; memory: ""1 GB""; preemptible: 3; }. output {; File outFile = ""output.txt""; String out = read_string(outFile); }; }. task ReadMeAFile {; File infile. command <<<; cat ${infile}; >>>. runtime {; docker: ""ubuntu:latest""; memory: ""1 GB""; preemptible: 3; }. output {; File out = read_string(stdout()); }; }. workflow FileMakeAndRead {; Int a = 5; call MakeMeAFile; call ReadMeAFile { input: infile = MakeMeAFile.out }; }; ```. And the new failure:. ```; ""failures"": [; ""Item not found: cromwell-dev/cromwell_execution/chrisl/FileMakeAndRead/000adc78-7dc7-4073-b5f6-83e499c13706/call-MakeMeAFile/cromwell-dev/cromwell_execution/chrisl/FileMakeAndRead/000adc78-7dc7-4073-b5f6-83e499c13706/call-MakeMeAFile/output.txt""; ],; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/892
https://github.com/broadinstitute/cromwell/issues/892:756,Availability,failure,failures,756,"I added a workaround since #891. The output block now makes a File output and then reads from it. Unfortunately, this version still doesn't work!. Here's a slightly different workflow:. ```; task MakeMeAFile {; Int c = 6. command <<<; echo FILECONTENT > output.txt; >>>. runtime {; docker: ""ubuntu:latest""; memory: ""1 GB""; preemptible: 3; }. output {; File outFile = ""output.txt""; String out = read_string(outFile); }; }. task ReadMeAFile {; File infile. command <<<; cat ${infile}; >>>. runtime {; docker: ""ubuntu:latest""; memory: ""1 GB""; preemptible: 3; }. output {; File out = read_string(stdout()); }; }. workflow FileMakeAndRead {; Int a = 5; call MakeMeAFile; call ReadMeAFile { input: infile = MakeMeAFile.out }; }; ```. And the new failure:. ```; ""failures"": [; ""Item not found: cromwell-dev/cromwell_execution/chrisl/FileMakeAndRead/000adc78-7dc7-4073-b5f6-83e499c13706/call-MakeMeAFile/cromwell-dev/cromwell_execution/chrisl/FileMakeAndRead/000adc78-7dc7-4073-b5f6-83e499c13706/call-MakeMeAFile/output.txt""; ],; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/892
https://github.com/broadinstitute/cromwell/pull/893:216,Safety,abort,aborts,216,"Don't flog me yet, I will clean this up. There's about a week of cruft from trying various things in here... _Diagram Disclaimer: the below diagrams are now obsolete!_. FAQ:. Q: Why did you change stuff unrelated to aborts?; A: Probably because I had a hard time debugging and it facilitated debugging.; A: Bug fixes; A: Probably no good reason, and it might just be cruft changes. This is how workflow aborts work for the LOCAL backend!. ![workflow aborts local - new page](https://cloud.githubusercontent.com/assets/58551/15552622/4698923c-2289-11e6-9435-3860675d4bf0.png). This is how workflow aborts work for the JES backend!. ![workflow aborts jes - new page](https://cloud.githubusercontent.com/assets/58551/15552644/620972d4-2289-11e6-900f-d2998ebe5544.png). :-D",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/893
https://github.com/broadinstitute/cromwell/pull/893:403,Safety,abort,aborts,403,"Don't flog me yet, I will clean this up. There's about a week of cruft from trying various things in here... _Diagram Disclaimer: the below diagrams are now obsolete!_. FAQ:. Q: Why did you change stuff unrelated to aborts?; A: Probably because I had a hard time debugging and it facilitated debugging.; A: Bug fixes; A: Probably no good reason, and it might just be cruft changes. This is how workflow aborts work for the LOCAL backend!. ![workflow aborts local - new page](https://cloud.githubusercontent.com/assets/58551/15552622/4698923c-2289-11e6-9435-3860675d4bf0.png). This is how workflow aborts work for the JES backend!. ![workflow aborts jes - new page](https://cloud.githubusercontent.com/assets/58551/15552644/620972d4-2289-11e6-900f-d2998ebe5544.png). :-D",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/893
https://github.com/broadinstitute/cromwell/pull/893:450,Safety,abort,aborts,450,"Don't flog me yet, I will clean this up. There's about a week of cruft from trying various things in here... _Diagram Disclaimer: the below diagrams are now obsolete!_. FAQ:. Q: Why did you change stuff unrelated to aborts?; A: Probably because I had a hard time debugging and it facilitated debugging.; A: Bug fixes; A: Probably no good reason, and it might just be cruft changes. This is how workflow aborts work for the LOCAL backend!. ![workflow aborts local - new page](https://cloud.githubusercontent.com/assets/58551/15552622/4698923c-2289-11e6-9435-3860675d4bf0.png). This is how workflow aborts work for the JES backend!. ![workflow aborts jes - new page](https://cloud.githubusercontent.com/assets/58551/15552644/620972d4-2289-11e6-900f-d2998ebe5544.png). :-D",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/893
https://github.com/broadinstitute/cromwell/pull/893:597,Safety,abort,aborts,597,"Don't flog me yet, I will clean this up. There's about a week of cruft from trying various things in here... _Diagram Disclaimer: the below diagrams are now obsolete!_. FAQ:. Q: Why did you change stuff unrelated to aborts?; A: Probably because I had a hard time debugging and it facilitated debugging.; A: Bug fixes; A: Probably no good reason, and it might just be cruft changes. This is how workflow aborts work for the LOCAL backend!. ![workflow aborts local - new page](https://cloud.githubusercontent.com/assets/58551/15552622/4698923c-2289-11e6-9435-3860675d4bf0.png). This is how workflow aborts work for the JES backend!. ![workflow aborts jes - new page](https://cloud.githubusercontent.com/assets/58551/15552644/620972d4-2289-11e6-900f-d2998ebe5544.png). :-D",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/893
https://github.com/broadinstitute/cromwell/pull/893:642,Safety,abort,aborts,642,"Don't flog me yet, I will clean this up. There's about a week of cruft from trying various things in here... _Diagram Disclaimer: the below diagrams are now obsolete!_. FAQ:. Q: Why did you change stuff unrelated to aborts?; A: Probably because I had a hard time debugging and it facilitated debugging.; A: Bug fixes; A: Probably no good reason, and it might just be cruft changes. This is how workflow aborts work for the LOCAL backend!. ![workflow aborts local - new page](https://cloud.githubusercontent.com/assets/58551/15552622/4698923c-2289-11e6-9435-3860675d4bf0.png). This is how workflow aborts work for the JES backend!. ![workflow aborts jes - new page](https://cloud.githubusercontent.com/assets/58551/15552644/620972d4-2289-11e6-900f-d2998ebe5544.png). :-D",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/893
https://github.com/broadinstitute/cromwell/pull/895:104,Integrability,message,messages,104,The metadata should now be complete for all calls. ; Also a small tidy-up in JES land due to duplicated messages.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/895
https://github.com/broadinstitute/cromwell/issues/896:160,Availability,avail,available,160,"If the service registry fails to get instantiated (wrong service classpath in the conf...), an exception is thrown but Cromwell still starts and an ActorRef is available in the `serviceRegistryActor` field, although the actor itself doesn't exist. All messages to the service registry are then lost.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/896
https://github.com/broadinstitute/cromwell/issues/896:252,Integrability,message,messages,252,"If the service registry fails to get instantiated (wrong service classpath in the conf...), an exception is thrown but Cromwell still starts and an ActorRef is available in the `serviceRegistryActor` field, although the actor itself doesn't exist. All messages to the service registry are then lost.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/896
https://github.com/broadinstitute/cromwell/issues/901:261,Availability,error,error,261,"Using this wdl, call caching takes a very long time for each task in the scatter to go from success to done. This is labeled ""cromwell final overhead"" in the timing diagram. This task scatters 100 wide and outputs 2 arrays of 901 elements each. It is also more error prone with call caching on than off. ```; task FileSpam {; String sample_name = ""DeliciousFileSpam""; Int index. command <<<; mkdir ${sample_name}_${index}; for i in `seq 0 900`; do; echo $i > ${sample_name}_${index}_$i.txt; echo $i > ${sample_name}_${index}/$i.txt; done; >>>; runtime {; docker: ""ubuntu:latest""; memory: ""3 GB""; cpu: ""1""; disks: ""local-disk 5 HDD""; }; output {; Array[File] outer = glob(""${sample_name}_${index}_*""); Array[File] inner = glob(""${sample_name}_${index}/*""); }; }. workflow DeliciousFileSpam {; Array[Int] indexing_list = [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,; 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,; 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,; 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,; 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,; 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,; 61, 62, 63, 64, 65, 66, 67, 68, 69, 70,; 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,; 81, 82, 83, 84, 85, 86, 87, 88, 89, 90,; 91, 92, 93, 94, 95, 96, 97, 98, 99, 100 ]. scatter (idx in indexing_list) {; call FileSpam { input: index = idx }; }; output {; None; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/901
https://github.com/broadinstitute/cromwell/issues/901:449,Availability,echo,echo,449,"Using this wdl, call caching takes a very long time for each task in the scatter to go from success to done. This is labeled ""cromwell final overhead"" in the timing diagram. This task scatters 100 wide and outputs 2 arrays of 901 elements each. It is also more error prone with call caching on than off. ```; task FileSpam {; String sample_name = ""DeliciousFileSpam""; Int index. command <<<; mkdir ${sample_name}_${index}; for i in `seq 0 900`; do; echo $i > ${sample_name}_${index}_$i.txt; echo $i > ${sample_name}_${index}/$i.txt; done; >>>; runtime {; docker: ""ubuntu:latest""; memory: ""3 GB""; cpu: ""1""; disks: ""local-disk 5 HDD""; }; output {; Array[File] outer = glob(""${sample_name}_${index}_*""); Array[File] inner = glob(""${sample_name}_${index}/*""); }; }. workflow DeliciousFileSpam {; Array[Int] indexing_list = [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,; 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,; 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,; 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,; 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,; 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,; 61, 62, 63, 64, 65, 66, 67, 68, 69, 70,; 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,; 81, 82, 83, 84, 85, 86, 87, 88, 89, 90,; 91, 92, 93, 94, 95, 96, 97, 98, 99, 100 ]. scatter (idx in indexing_list) {; call FileSpam { input: index = idx }; }; output {; None; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/901
https://github.com/broadinstitute/cromwell/issues/901:491,Availability,echo,echo,491,"Using this wdl, call caching takes a very long time for each task in the scatter to go from success to done. This is labeled ""cromwell final overhead"" in the timing diagram. This task scatters 100 wide and outputs 2 arrays of 901 elements each. It is also more error prone with call caching on than off. ```; task FileSpam {; String sample_name = ""DeliciousFileSpam""; Int index. command <<<; mkdir ${sample_name}_${index}; for i in `seq 0 900`; do; echo $i > ${sample_name}_${index}_$i.txt; echo $i > ${sample_name}_${index}/$i.txt; done; >>>; runtime {; docker: ""ubuntu:latest""; memory: ""3 GB""; cpu: ""1""; disks: ""local-disk 5 HDD""; }; output {; Array[File] outer = glob(""${sample_name}_${index}_*""); Array[File] inner = glob(""${sample_name}_${index}/*""); }; }. workflow DeliciousFileSpam {; Array[Int] indexing_list = [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,; 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,; 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,; 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,; 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,; 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,; 61, 62, 63, 64, 65, 66, 67, 68, 69, 70,; 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,; 81, 82, 83, 84, 85, 86, 87, 88, 89, 90,; 91, 92, 93, 94, 95, 96, 97, 98, 99, 100 ]. scatter (idx in indexing_list) {; call FileSpam { input: index = idx }; }; output {; None; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/901
https://github.com/broadinstitute/cromwell/issues/903:287,Availability,error,errors,287,"Brought this up with Dion, suggested we have a backoff for transient issues like this on their end. Seems very transient, but needed to have it documented. Looks like this:. ""com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable; { ; ""code"" : 503,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Backend Error"",; ""reason"" : ""backendError""; } ],; ""message"" : ""Backend Error""; }"". timestamp:""2016-05-06T22:39:17.321Z""; jobId:""operations/EOiv78DIKhjQhqv9q_TfliEgn6KQ6Z4NKg9wcm9kdWN0aW9uUXVldWU""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/903
https://github.com/broadinstitute/cromwell/issues/903:345,Availability,Error,Error,345,"Brought this up with Dion, suggested we have a backoff for transient issues like this on their end. Seems very transient, but needed to have it documented. Looks like this:. ""com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable; { ; ""code"" : 503,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Backend Error"",; ""reason"" : ""backendError""; } ],; ""message"" : ""Backend Error""; }"". timestamp:""2016-05-06T22:39:17.321Z""; jobId:""operations/EOiv78DIKhjQhqv9q_TfliEgn6KQ6Z4NKg9wcm9kdWN0aW9uUXVldWU""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/903
https://github.com/broadinstitute/cromwell/issues/903:408,Availability,Error,Error,408,"Brought this up with Dion, suggested we have a backoff for transient issues like this on their end. Seems very transient, but needed to have it documented. Looks like this:. ""com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable; { ; ""code"" : 503,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Backend Error"",; ""reason"" : ""backendError""; } ],; ""message"" : ""Backend Error""; }"". timestamp:""2016-05-06T22:39:17.321Z""; jobId:""operations/EOiv78DIKhjQhqv9q_TfliEgn6KQ6Z4NKg9wcm9kdWN0aW9uUXVldWU""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/903
https://github.com/broadinstitute/cromwell/issues/903:325,Integrability,message,message,325,"Brought this up with Dion, suggested we have a backoff for transient issues like this on their end. Seems very transient, but needed to have it documented. Looks like this:. ""com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable; { ; ""code"" : 503,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Backend Error"",; ""reason"" : ""backendError""; } ],; ""message"" : ""Backend Error""; }"". timestamp:""2016-05-06T22:39:17.321Z""; jobId:""operations/EOiv78DIKhjQhqv9q_TfliEgn6KQ6Z4NKg9wcm9kdWN0aW9uUXVldWU""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/903
https://github.com/broadinstitute/cromwell/issues/903:388,Integrability,message,message,388,"Brought this up with Dion, suggested we have a backoff for transient issues like this on their end. Seems very transient, but needed to have it documented. Looks like this:. ""com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable; { ; ""code"" : 503,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Backend Error"",; ""reason"" : ""backendError""; } ],; ""message"" : ""Backend Error""; }"". timestamp:""2016-05-06T22:39:17.321Z""; jobId:""operations/EOiv78DIKhjQhqv9q_TfliEgn6KQ6Z4NKg9wcm9kdWN0aW9uUXVldWU""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/903
https://github.com/broadinstitute/cromwell/issues/904:383,Security,Validat,ValidateAggregatedSamFile,383,"We have several cromwell jobs that appear to be running, but are done with a task that should have been recognized as complete. An example is f86ff9ef-ea1c-47f3-a513-8d6311a27c7b - running on gotc prod; https://cromwell.gotc-prod.broadinstitute.org/api/workflows/v1/f86ff9ef-ea1c-47f3-a513-8d6311a27c7b/metadata; The workflow was launched on May 15 and ran normally until; A task - 'ValidateAggregatedSamFile' was preempted. A retry was then attempted, and that retry is stuck in status 'Running' although the job appeared to have executed correctly:; see expected/normal output in:; https://console.cloud.google.com/storage/browser/broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/f86ff9ef-ea1c-47f3-a513-8d6311a27c7b/call-ValidateAggregatedSamFile/. Looking at the logs on gotc-cromwell-prod201 (/local/cromwell_logs/20160516-cromwell.log). It looks like the retried job never switched to 'Initializing' (the log says it was changing the jobs status but the database does not reflect that); i.e. this line:; 2016-05-16 20:17:22,463 cromwell-system-akka.actor.default-dispatcher-22 INFO - JES Run [UUID(f86ff9ef):ValidateAggregatedSamFile:2]: JES Run ID is operations/EPaL3dnLKhiY9KCP1rC04ekBIJ-ikOmeDSoPcHJvZHVjdGlvblF1ZXVl; 2016-05-16 20:17:22,484 cromwell-system-akka.actor.default-dispatcher-17 INFO - JES Run [UUID(f86ff9ef):ValidateAggregatedSamFile:2]: Status change from - to Initializing. But the database says the job is still 'Running'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/904
https://github.com/broadinstitute/cromwell/issues/904:748,Security,Validat,ValidateAggregatedSamFile,748,"We have several cromwell jobs that appear to be running, but are done with a task that should have been recognized as complete. An example is f86ff9ef-ea1c-47f3-a513-8d6311a27c7b - running on gotc prod; https://cromwell.gotc-prod.broadinstitute.org/api/workflows/v1/f86ff9ef-ea1c-47f3-a513-8d6311a27c7b/metadata; The workflow was launched on May 15 and ran normally until; A task - 'ValidateAggregatedSamFile' was preempted. A retry was then attempted, and that retry is stuck in status 'Running' although the job appeared to have executed correctly:; see expected/normal output in:; https://console.cloud.google.com/storage/browser/broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/f86ff9ef-ea1c-47f3-a513-8d6311a27c7b/call-ValidateAggregatedSamFile/. Looking at the logs on gotc-cromwell-prod201 (/local/cromwell_logs/20160516-cromwell.log). It looks like the retried job never switched to 'Initializing' (the log says it was changing the jobs status but the database does not reflect that); i.e. this line:; 2016-05-16 20:17:22,463 cromwell-system-akka.actor.default-dispatcher-22 INFO - JES Run [UUID(f86ff9ef):ValidateAggregatedSamFile:2]: JES Run ID is operations/EPaL3dnLKhiY9KCP1rC04ekBIJ-ikOmeDSoPcHJvZHVjdGlvblF1ZXVl; 2016-05-16 20:17:22,484 cromwell-system-akka.actor.default-dispatcher-17 INFO - JES Run [UUID(f86ff9ef):ValidateAggregatedSamFile:2]: Status change from - to Initializing. But the database says the job is still 'Running'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/904
https://github.com/broadinstitute/cromwell/issues/904:1138,Security,Validat,ValidateAggregatedSamFile,1138,"We have several cromwell jobs that appear to be running, but are done with a task that should have been recognized as complete. An example is f86ff9ef-ea1c-47f3-a513-8d6311a27c7b - running on gotc prod; https://cromwell.gotc-prod.broadinstitute.org/api/workflows/v1/f86ff9ef-ea1c-47f3-a513-8d6311a27c7b/metadata; The workflow was launched on May 15 and ran normally until; A task - 'ValidateAggregatedSamFile' was preempted. A retry was then attempted, and that retry is stuck in status 'Running' although the job appeared to have executed correctly:; see expected/normal output in:; https://console.cloud.google.com/storage/browser/broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/f86ff9ef-ea1c-47f3-a513-8d6311a27c7b/call-ValidateAggregatedSamFile/. Looking at the logs on gotc-cromwell-prod201 (/local/cromwell_logs/20160516-cromwell.log). It looks like the retried job never switched to 'Initializing' (the log says it was changing the jobs status but the database does not reflect that); i.e. this line:; 2016-05-16 20:17:22,463 cromwell-system-akka.actor.default-dispatcher-22 INFO - JES Run [UUID(f86ff9ef):ValidateAggregatedSamFile:2]: JES Run ID is operations/EPaL3dnLKhiY9KCP1rC04ekBIJ-ikOmeDSoPcHJvZHVjdGlvblF1ZXVl; 2016-05-16 20:17:22,484 cromwell-system-akka.actor.default-dispatcher-17 INFO - JES Run [UUID(f86ff9ef):ValidateAggregatedSamFile:2]: Status change from - to Initializing. But the database says the job is still 'Running'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/904
https://github.com/broadinstitute/cromwell/issues/904:1355,Security,Validat,ValidateAggregatedSamFile,1355,"We have several cromwell jobs that appear to be running, but are done with a task that should have been recognized as complete. An example is f86ff9ef-ea1c-47f3-a513-8d6311a27c7b - running on gotc prod; https://cromwell.gotc-prod.broadinstitute.org/api/workflows/v1/f86ff9ef-ea1c-47f3-a513-8d6311a27c7b/metadata; The workflow was launched on May 15 and ran normally until; A task - 'ValidateAggregatedSamFile' was preempted. A retry was then attempted, and that retry is stuck in status 'Running' although the job appeared to have executed correctly:; see expected/normal output in:; https://console.cloud.google.com/storage/browser/broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/f86ff9ef-ea1c-47f3-a513-8d6311a27c7b/call-ValidateAggregatedSamFile/. Looking at the logs on gotc-cromwell-prod201 (/local/cromwell_logs/20160516-cromwell.log). It looks like the retried job never switched to 'Initializing' (the log says it was changing the jobs status but the database does not reflect that); i.e. this line:; 2016-05-16 20:17:22,463 cromwell-system-akka.actor.default-dispatcher-22 INFO - JES Run [UUID(f86ff9ef):ValidateAggregatedSamFile:2]: JES Run ID is operations/EPaL3dnLKhiY9KCP1rC04ekBIJ-ikOmeDSoPcHJvZHVjdGlvblF1ZXVl; 2016-05-16 20:17:22,484 cromwell-system-akka.actor.default-dispatcher-17 INFO - JES Run [UUID(f86ff9ef):ValidateAggregatedSamFile:2]: Status change from - to Initializing. But the database says the job is still 'Running'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/904
https://github.com/broadinstitute/cromwell/issues/904:791,Testability,log,logs,791,"We have several cromwell jobs that appear to be running, but are done with a task that should have been recognized as complete. An example is f86ff9ef-ea1c-47f3-a513-8d6311a27c7b - running on gotc prod; https://cromwell.gotc-prod.broadinstitute.org/api/workflows/v1/f86ff9ef-ea1c-47f3-a513-8d6311a27c7b/metadata; The workflow was launched on May 15 and ran normally until; A task - 'ValidateAggregatedSamFile' was preempted. A retry was then attempted, and that retry is stuck in status 'Running' although the job appeared to have executed correctly:; see expected/normal output in:; https://console.cloud.google.com/storage/browser/broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/f86ff9ef-ea1c-47f3-a513-8d6311a27c7b/call-ValidateAggregatedSamFile/. Looking at the logs on gotc-cromwell-prod201 (/local/cromwell_logs/20160516-cromwell.log). It looks like the retried job never switched to 'Initializing' (the log says it was changing the jobs status but the database does not reflect that); i.e. this line:; 2016-05-16 20:17:22,463 cromwell-system-akka.actor.default-dispatcher-22 INFO - JES Run [UUID(f86ff9ef):ValidateAggregatedSamFile:2]: JES Run ID is operations/EPaL3dnLKhiY9KCP1rC04ekBIJ-ikOmeDSoPcHJvZHVjdGlvblF1ZXVl; 2016-05-16 20:17:22,484 cromwell-system-akka.actor.default-dispatcher-17 INFO - JES Run [UUID(f86ff9ef):ValidateAggregatedSamFile:2]: Status change from - to Initializing. But the database says the job is still 'Running'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/904
https://github.com/broadinstitute/cromwell/issues/904:861,Testability,log,log,861,"We have several cromwell jobs that appear to be running, but are done with a task that should have been recognized as complete. An example is f86ff9ef-ea1c-47f3-a513-8d6311a27c7b - running on gotc prod; https://cromwell.gotc-prod.broadinstitute.org/api/workflows/v1/f86ff9ef-ea1c-47f3-a513-8d6311a27c7b/metadata; The workflow was launched on May 15 and ran normally until; A task - 'ValidateAggregatedSamFile' was preempted. A retry was then attempted, and that retry is stuck in status 'Running' although the job appeared to have executed correctly:; see expected/normal output in:; https://console.cloud.google.com/storage/browser/broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/f86ff9ef-ea1c-47f3-a513-8d6311a27c7b/call-ValidateAggregatedSamFile/. Looking at the logs on gotc-cromwell-prod201 (/local/cromwell_logs/20160516-cromwell.log). It looks like the retried job never switched to 'Initializing' (the log says it was changing the jobs status but the database does not reflect that); i.e. this line:; 2016-05-16 20:17:22,463 cromwell-system-akka.actor.default-dispatcher-22 INFO - JES Run [UUID(f86ff9ef):ValidateAggregatedSamFile:2]: JES Run ID is operations/EPaL3dnLKhiY9KCP1rC04ekBIJ-ikOmeDSoPcHJvZHVjdGlvblF1ZXVl; 2016-05-16 20:17:22,484 cromwell-system-akka.actor.default-dispatcher-17 INFO - JES Run [UUID(f86ff9ef):ValidateAggregatedSamFile:2]: Status change from - to Initializing. But the database says the job is still 'Running'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/904
https://github.com/broadinstitute/cromwell/issues/904:935,Testability,log,log,935,"We have several cromwell jobs that appear to be running, but are done with a task that should have been recognized as complete. An example is f86ff9ef-ea1c-47f3-a513-8d6311a27c7b - running on gotc prod; https://cromwell.gotc-prod.broadinstitute.org/api/workflows/v1/f86ff9ef-ea1c-47f3-a513-8d6311a27c7b/metadata; The workflow was launched on May 15 and ran normally until; A task - 'ValidateAggregatedSamFile' was preempted. A retry was then attempted, and that retry is stuck in status 'Running' although the job appeared to have executed correctly:; see expected/normal output in:; https://console.cloud.google.com/storage/browser/broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/f86ff9ef-ea1c-47f3-a513-8d6311a27c7b/call-ValidateAggregatedSamFile/. Looking at the logs on gotc-cromwell-prod201 (/local/cromwell_logs/20160516-cromwell.log). It looks like the retried job never switched to 'Initializing' (the log says it was changing the jobs status but the database does not reflect that); i.e. this line:; 2016-05-16 20:17:22,463 cromwell-system-akka.actor.default-dispatcher-22 INFO - JES Run [UUID(f86ff9ef):ValidateAggregatedSamFile:2]: JES Run ID is operations/EPaL3dnLKhiY9KCP1rC04ekBIJ-ikOmeDSoPcHJvZHVjdGlvblF1ZXVl; 2016-05-16 20:17:22,484 cromwell-system-akka.actor.default-dispatcher-17 INFO - JES Run [UUID(f86ff9ef):ValidateAggregatedSamFile:2]: Status change from - to Initializing. But the database says the job is still 'Running'.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/904
https://github.com/broadinstitute/cromwell/issues/906:12,Testability,Test,TestKit,12,"When using `TestKit`, there is a [note](https://github.com/akka/akka/blob/v2.3.12/akka-testkit/src/main/scala/akka/testkit/TestKit.scala#L705-L706):. > the ActorSystem passed into the constructor needs to be shutdown, otherwise thread pools and memory will be leaked. We have dozens of specs that use an `ActorSystem`, but recently in PBE specs have not been cleaning up after themselves. It's possible that this is the reason we suddenly need 2GB of memory to run tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/906
https://github.com/broadinstitute/cromwell/issues/906:87,Testability,test,testkit,87,"When using `TestKit`, there is a [note](https://github.com/akka/akka/blob/v2.3.12/akka-testkit/src/main/scala/akka/testkit/TestKit.scala#L705-L706):. > the ActorSystem passed into the constructor needs to be shutdown, otherwise thread pools and memory will be leaked. We have dozens of specs that use an `ActorSystem`, but recently in PBE specs have not been cleaning up after themselves. It's possible that this is the reason we suddenly need 2GB of memory to run tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/906
https://github.com/broadinstitute/cromwell/issues/906:115,Testability,test,testkit,115,"When using `TestKit`, there is a [note](https://github.com/akka/akka/blob/v2.3.12/akka-testkit/src/main/scala/akka/testkit/TestKit.scala#L705-L706):. > the ActorSystem passed into the constructor needs to be shutdown, otherwise thread pools and memory will be leaked. We have dozens of specs that use an `ActorSystem`, but recently in PBE specs have not been cleaning up after themselves. It's possible that this is the reason we suddenly need 2GB of memory to run tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/906
https://github.com/broadinstitute/cromwell/issues/906:123,Testability,Test,TestKit,123,"When using `TestKit`, there is a [note](https://github.com/akka/akka/blob/v2.3.12/akka-testkit/src/main/scala/akka/testkit/TestKit.scala#L705-L706):. > the ActorSystem passed into the constructor needs to be shutdown, otherwise thread pools and memory will be leaked. We have dozens of specs that use an `ActorSystem`, but recently in PBE specs have not been cleaning up after themselves. It's possible that this is the reason we suddenly need 2GB of memory to run tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/906
https://github.com/broadinstitute/cromwell/issues/906:465,Testability,test,tests,465,"When using `TestKit`, there is a [note](https://github.com/akka/akka/blob/v2.3.12/akka-testkit/src/main/scala/akka/testkit/TestKit.scala#L705-L706):. > the ActorSystem passed into the constructor needs to be shutdown, otherwise thread pools and memory will be leaked. We have dozens of specs that use an `ActorSystem`, but recently in PBE specs have not been cleaning up after themselves. It's possible that this is the reason we suddenly need 2GB of memory to run tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/906
https://github.com/broadinstitute/cromwell/issues/907:85,Security,hash,hash,85,"The engine doesn't want to see this. The engine shouldn't see this. Dont'send back a hash code!. If this breaks legacy code, comment out until it compiles again!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/907
https://github.com/broadinstitute/cromwell/issues/908:245,Modifiability,config,config,245,"While users can override runtime attributes on the task and workflow level, if they don't do either of those things Cromwell uses compiled-in hardcoded strings. For the engine and our bundled backends (local, jes) these should be drawn from the config file via a global 'runtime attributes' defaults",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/908
https://github.com/broadinstitute/cromwell/pull/909:371,Integrability,depend,dependency,371,"More use (and naming) of `OffsetDateTime`, less of `Timestamp`.; Replaced use of `java.util.Date` with `OffsetDateTime`.; Removed use of `OffsetDateTime.toInstant` & `.toEpochSecond`.; Using `OffsetDateTime.now` instead of the `KnowsWhatTimeItIs` trait.; Using `OffsetDateTime.toString` instead of `DateTimeFormatter.ISO_OFFSET_DATE_TIME`.; Removed unused `joda-convert` dependency, plus relying on transitive project dependencies.; `TestableJesJobExecutionActor` no longer tries to interact with the services in the engine.; Cleaned up a few more places where `MetadataValue.apply` was called with an extra `.toString`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/909
https://github.com/broadinstitute/cromwell/pull/909:418,Integrability,depend,dependencies,418,"More use (and naming) of `OffsetDateTime`, less of `Timestamp`.; Replaced use of `java.util.Date` with `OffsetDateTime`.; Removed use of `OffsetDateTime.toInstant` & `.toEpochSecond`.; Using `OffsetDateTime.now` instead of the `KnowsWhatTimeItIs` trait.; Using `OffsetDateTime.toString` instead of `DateTimeFormatter.ISO_OFFSET_DATE_TIME`.; Removed unused `joda-convert` dependency, plus relying on transitive project dependencies.; `TestableJesJobExecutionActor` no longer tries to interact with the services in the engine.; Cleaned up a few more places where `MetadataValue.apply` was called with an extra `.toString`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/909
https://github.com/broadinstitute/cromwell/pull/909:434,Testability,Test,TestableJesJobExecutionActor,434,"More use (and naming) of `OffsetDateTime`, less of `Timestamp`.; Replaced use of `java.util.Date` with `OffsetDateTime`.; Removed use of `OffsetDateTime.toInstant` & `.toEpochSecond`.; Using `OffsetDateTime.now` instead of the `KnowsWhatTimeItIs` trait.; Using `OffsetDateTime.toString` instead of `DateTimeFormatter.ISO_OFFSET_DATE_TIME`.; Removed unused `joda-convert` dependency, plus relying on transitive project dependencies.; `TestableJesJobExecutionActor` no longer tries to interact with the services in the engine.; Cleaned up a few more places where `MetadataValue.apply` was called with an extra `.toString`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/909
https://github.com/broadinstitute/cromwell/issues/910:98,Availability,error,error,98,"Running this WDL (with a wider scatter count... start with 250) fails with a database persistence error like:. > The size of BLOB/TEXT data inserted in one transaction is greater than 10% of redo log size. Increase the redo log size using innodb_log_file_size. On Google, the redo size is fixed at 536,870,912 bytes, which means the maximum BLOB/TEXT size is ~53mb. ```; task FileSpam {; String sample_name = ""DeliciousFileSpam""; Int index. command <<<; mkdir ${sample_name}_${index}; for i in `seq 0 900`; do; echo $i > ${sample_name}_${index}_$i.txt; echo $i > ${sample_name}_${index}/$i.txt; done; >>>; runtime {; docker: ""ubuntu:latest""; memory: ""3 GB""; cpu: ""1""; disks: ""local-disk 5 HDD""; preemptible: 3; }; output {; Array[File] outer = glob(""${sample_name}_${index}_*""); Array[File] inner = glob(""${sample_name}_${index}/*""); }; }. task MatrixRotation {; Array[Array[String]] input_matrix. command <<<; python <<CODE; import csv; import sys; with open('${write_tsv(input_matrix)}') as tsv_in:; input_matrix = [line.strip().split('\t') for line in tsv_in]; final_matrix = [["""" for x in range(len(input_matrix))] for y in range(len(input_matrix[0]))]; for x in range(len(input_matrix)):; for y in range(len(input_matrix[0])):; final_matrix[y][x] = input_matrix[x][y]; with open(""output.tsv"", ""w"") as tsv_out:; # lineterminator is a workaround for a cromwell bug that doesnt allow for '\r\n' line endings which this outputs by default; writer = csv.writer(tsv_out, delimiter='\t', lineterminator='\n'); writer.writerows(final_matrix); CODE; >>>. runtime {; docker: ""python:2.7""; memory: ""1 GB""; preemptible: 3; }. output {; File out = ""output.tsv""; Array[Array[String]] output_matrix = read_tsv(out); }; }. workflow DeliciousFileSpam {; Array[Int] indexing_list = [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,; 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,; 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,; 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,; 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,; 51, 52, 53, 54, 55, 56, 57, 58, 59",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/910
https://github.com/broadinstitute/cromwell/issues/910:511,Availability,echo,echo,511,"Running this WDL (with a wider scatter count... start with 250) fails with a database persistence error like:. > The size of BLOB/TEXT data inserted in one transaction is greater than 10% of redo log size. Increase the redo log size using innodb_log_file_size. On Google, the redo size is fixed at 536,870,912 bytes, which means the maximum BLOB/TEXT size is ~53mb. ```; task FileSpam {; String sample_name = ""DeliciousFileSpam""; Int index. command <<<; mkdir ${sample_name}_${index}; for i in `seq 0 900`; do; echo $i > ${sample_name}_${index}_$i.txt; echo $i > ${sample_name}_${index}/$i.txt; done; >>>; runtime {; docker: ""ubuntu:latest""; memory: ""3 GB""; cpu: ""1""; disks: ""local-disk 5 HDD""; preemptible: 3; }; output {; Array[File] outer = glob(""${sample_name}_${index}_*""); Array[File] inner = glob(""${sample_name}_${index}/*""); }; }. task MatrixRotation {; Array[Array[String]] input_matrix. command <<<; python <<CODE; import csv; import sys; with open('${write_tsv(input_matrix)}') as tsv_in:; input_matrix = [line.strip().split('\t') for line in tsv_in]; final_matrix = [["""" for x in range(len(input_matrix))] for y in range(len(input_matrix[0]))]; for x in range(len(input_matrix)):; for y in range(len(input_matrix[0])):; final_matrix[y][x] = input_matrix[x][y]; with open(""output.tsv"", ""w"") as tsv_out:; # lineterminator is a workaround for a cromwell bug that doesnt allow for '\r\n' line endings which this outputs by default; writer = csv.writer(tsv_out, delimiter='\t', lineterminator='\n'); writer.writerows(final_matrix); CODE; >>>. runtime {; docker: ""python:2.7""; memory: ""1 GB""; preemptible: 3; }. output {; File out = ""output.tsv""; Array[Array[String]] output_matrix = read_tsv(out); }; }. workflow DeliciousFileSpam {; Array[Int] indexing_list = [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,; 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,; 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,; 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,; 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,; 51, 52, 53, 54, 55, 56, 57, 58, 59",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/910
https://github.com/broadinstitute/cromwell/issues/910:553,Availability,echo,echo,553,"Running this WDL (with a wider scatter count... start with 250) fails with a database persistence error like:. > The size of BLOB/TEXT data inserted in one transaction is greater than 10% of redo log size. Increase the redo log size using innodb_log_file_size. On Google, the redo size is fixed at 536,870,912 bytes, which means the maximum BLOB/TEXT size is ~53mb. ```; task FileSpam {; String sample_name = ""DeliciousFileSpam""; Int index. command <<<; mkdir ${sample_name}_${index}; for i in `seq 0 900`; do; echo $i > ${sample_name}_${index}_$i.txt; echo $i > ${sample_name}_${index}/$i.txt; done; >>>; runtime {; docker: ""ubuntu:latest""; memory: ""3 GB""; cpu: ""1""; disks: ""local-disk 5 HDD""; preemptible: 3; }; output {; Array[File] outer = glob(""${sample_name}_${index}_*""); Array[File] inner = glob(""${sample_name}_${index}/*""); }; }. task MatrixRotation {; Array[Array[String]] input_matrix. command <<<; python <<CODE; import csv; import sys; with open('${write_tsv(input_matrix)}') as tsv_in:; input_matrix = [line.strip().split('\t') for line in tsv_in]; final_matrix = [["""" for x in range(len(input_matrix))] for y in range(len(input_matrix[0]))]; for x in range(len(input_matrix)):; for y in range(len(input_matrix[0])):; final_matrix[y][x] = input_matrix[x][y]; with open(""output.tsv"", ""w"") as tsv_out:; # lineterminator is a workaround for a cromwell bug that doesnt allow for '\r\n' line endings which this outputs by default; writer = csv.writer(tsv_out, delimiter='\t', lineterminator='\n'); writer.writerows(final_matrix); CODE; >>>. runtime {; docker: ""python:2.7""; memory: ""1 GB""; preemptible: 3; }. output {; File out = ""output.tsv""; Array[Array[String]] output_matrix = read_tsv(out); }; }. workflow DeliciousFileSpam {; Array[Int] indexing_list = [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,; 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,; 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,; 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,; 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,; 51, 52, 53, 54, 55, 56, 57, 58, 59",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/910
https://github.com/broadinstitute/cromwell/issues/910:196,Testability,log,log,196,"Running this WDL (with a wider scatter count... start with 250) fails with a database persistence error like:. > The size of BLOB/TEXT data inserted in one transaction is greater than 10% of redo log size. Increase the redo log size using innodb_log_file_size. On Google, the redo size is fixed at 536,870,912 bytes, which means the maximum BLOB/TEXT size is ~53mb. ```; task FileSpam {; String sample_name = ""DeliciousFileSpam""; Int index. command <<<; mkdir ${sample_name}_${index}; for i in `seq 0 900`; do; echo $i > ${sample_name}_${index}_$i.txt; echo $i > ${sample_name}_${index}/$i.txt; done; >>>; runtime {; docker: ""ubuntu:latest""; memory: ""3 GB""; cpu: ""1""; disks: ""local-disk 5 HDD""; preemptible: 3; }; output {; Array[File] outer = glob(""${sample_name}_${index}_*""); Array[File] inner = glob(""${sample_name}_${index}/*""); }; }. task MatrixRotation {; Array[Array[String]] input_matrix. command <<<; python <<CODE; import csv; import sys; with open('${write_tsv(input_matrix)}') as tsv_in:; input_matrix = [line.strip().split('\t') for line in tsv_in]; final_matrix = [["""" for x in range(len(input_matrix))] for y in range(len(input_matrix[0]))]; for x in range(len(input_matrix)):; for y in range(len(input_matrix[0])):; final_matrix[y][x] = input_matrix[x][y]; with open(""output.tsv"", ""w"") as tsv_out:; # lineterminator is a workaround for a cromwell bug that doesnt allow for '\r\n' line endings which this outputs by default; writer = csv.writer(tsv_out, delimiter='\t', lineterminator='\n'); writer.writerows(final_matrix); CODE; >>>. runtime {; docker: ""python:2.7""; memory: ""1 GB""; preemptible: 3; }. output {; File out = ""output.tsv""; Array[Array[String]] output_matrix = read_tsv(out); }; }. workflow DeliciousFileSpam {; Array[Int] indexing_list = [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,; 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,; 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,; 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,; 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,; 51, 52, 53, 54, 55, 56, 57, 58, 59",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/910
https://github.com/broadinstitute/cromwell/issues/910:224,Testability,log,log,224,"Running this WDL (with a wider scatter count... start with 250) fails with a database persistence error like:. > The size of BLOB/TEXT data inserted in one transaction is greater than 10% of redo log size. Increase the redo log size using innodb_log_file_size. On Google, the redo size is fixed at 536,870,912 bytes, which means the maximum BLOB/TEXT size is ~53mb. ```; task FileSpam {; String sample_name = ""DeliciousFileSpam""; Int index. command <<<; mkdir ${sample_name}_${index}; for i in `seq 0 900`; do; echo $i > ${sample_name}_${index}_$i.txt; echo $i > ${sample_name}_${index}/$i.txt; done; >>>; runtime {; docker: ""ubuntu:latest""; memory: ""3 GB""; cpu: ""1""; disks: ""local-disk 5 HDD""; preemptible: 3; }; output {; Array[File] outer = glob(""${sample_name}_${index}_*""); Array[File] inner = glob(""${sample_name}_${index}/*""); }; }. task MatrixRotation {; Array[Array[String]] input_matrix. command <<<; python <<CODE; import csv; import sys; with open('${write_tsv(input_matrix)}') as tsv_in:; input_matrix = [line.strip().split('\t') for line in tsv_in]; final_matrix = [["""" for x in range(len(input_matrix))] for y in range(len(input_matrix[0]))]; for x in range(len(input_matrix)):; for y in range(len(input_matrix[0])):; final_matrix[y][x] = input_matrix[x][y]; with open(""output.tsv"", ""w"") as tsv_out:; # lineterminator is a workaround for a cromwell bug that doesnt allow for '\r\n' line endings which this outputs by default; writer = csv.writer(tsv_out, delimiter='\t', lineterminator='\n'); writer.writerows(final_matrix); CODE; >>>. runtime {; docker: ""python:2.7""; memory: ""1 GB""; preemptible: 3; }. output {; File out = ""output.tsv""; Array[Array[String]] output_matrix = read_tsv(out); }; }. workflow DeliciousFileSpam {; Array[Int] indexing_list = [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,; 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,; 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,; 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,; 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,; 51, 52, 53, 54, 55, 56, 57, 58, 59",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/910
https://github.com/broadinstitute/cromwell/issues/911:98,Availability,error,error,98,"Running this WDL (with a wider scatter count... start with 250) fails with a database persistence error like:. > The size of BLOB/TEXT data inserted in one transaction is greater than 10% of redo log size. Increase the redo log size using innodb_log_file_size. Which we can't do with CloudSQL on Google. task FileSpam {; String sample_name = ""DeliciousFileSpam""; Int index. command <<<; mkdir ${sample_name}_${index}; for i in `seq 0 900`; do; echo $i > ${sample_name}_${index}_$i.txt; echo $i > ${sample_name}_${index}/$i.txt; done. > > > runtime {; > > > docker: ""ubuntu:latest""; > > > memory: ""3 GB""; > > > cpu: ""1""; > > > disks: ""local-disk 5 HDD""; > > > preemptible: 3; > > > }; > > > output {; > > > Array[File] outer = glob(""${sample_name}_${index}__""); > > > Array[File] inner = glob(""${sample_name}_${index}/_""); > > > }; > > > }. task MatrixRotation {; Array[Array[String]] input_matrix. ```; command <<<; python <<CODE; import csv; import sys; with open('${write_tsv(input_matrix)}') as tsv_in:; input_matrix = [line.strip().split('\t') for line in tsv_in]; final_matrix = [["""" for x in range(len(input_matrix))] for y in range(len(input_matrix[0]))]; for x in range(len(input_matrix)):; for y in range(len(input_matrix[0])):; final_matrix[y][x] = input_matrix[x][y]; with open(""output.tsv"", ""w"") as tsv_out:; # lineterminator is a workaround for a cromwell bug that doesnt allow for '\r\n' line endings which this outputs by default; writer = csv.writer(tsv_out, delimiter='\t', lineterminator='\n'); writer.writerows(final_matrix); CODE; >>>. runtime {; docker: ""python:2.7""; memory: ""1 GB""; preemptible: 3; }. output {; File out = ""output.tsv""; Array[Array[String]] output_matrix = read_tsv(out); }; ```. }. workflow DeliciousFileSpam {; Array[Int] indexing_list = [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,; 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,; 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,; 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,; 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,; 51, 52, 53, 54, 55, 56, ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/911
https://github.com/broadinstitute/cromwell/issues/911:444,Availability,echo,echo,444,"Running this WDL (with a wider scatter count... start with 250) fails with a database persistence error like:. > The size of BLOB/TEXT data inserted in one transaction is greater than 10% of redo log size. Increase the redo log size using innodb_log_file_size. Which we can't do with CloudSQL on Google. task FileSpam {; String sample_name = ""DeliciousFileSpam""; Int index. command <<<; mkdir ${sample_name}_${index}; for i in `seq 0 900`; do; echo $i > ${sample_name}_${index}_$i.txt; echo $i > ${sample_name}_${index}/$i.txt; done. > > > runtime {; > > > docker: ""ubuntu:latest""; > > > memory: ""3 GB""; > > > cpu: ""1""; > > > disks: ""local-disk 5 HDD""; > > > preemptible: 3; > > > }; > > > output {; > > > Array[File] outer = glob(""${sample_name}_${index}__""); > > > Array[File] inner = glob(""${sample_name}_${index}/_""); > > > }; > > > }. task MatrixRotation {; Array[Array[String]] input_matrix. ```; command <<<; python <<CODE; import csv; import sys; with open('${write_tsv(input_matrix)}') as tsv_in:; input_matrix = [line.strip().split('\t') for line in tsv_in]; final_matrix = [["""" for x in range(len(input_matrix))] for y in range(len(input_matrix[0]))]; for x in range(len(input_matrix)):; for y in range(len(input_matrix[0])):; final_matrix[y][x] = input_matrix[x][y]; with open(""output.tsv"", ""w"") as tsv_out:; # lineterminator is a workaround for a cromwell bug that doesnt allow for '\r\n' line endings which this outputs by default; writer = csv.writer(tsv_out, delimiter='\t', lineterminator='\n'); writer.writerows(final_matrix); CODE; >>>. runtime {; docker: ""python:2.7""; memory: ""1 GB""; preemptible: 3; }. output {; File out = ""output.tsv""; Array[Array[String]] output_matrix = read_tsv(out); }; ```. }. workflow DeliciousFileSpam {; Array[Int] indexing_list = [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,; 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,; 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,; 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,; 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,; 51, 52, 53, 54, 55, 56, ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/911
https://github.com/broadinstitute/cromwell/issues/911:486,Availability,echo,echo,486,"Running this WDL (with a wider scatter count... start with 250) fails with a database persistence error like:. > The size of BLOB/TEXT data inserted in one transaction is greater than 10% of redo log size. Increase the redo log size using innodb_log_file_size. Which we can't do with CloudSQL on Google. task FileSpam {; String sample_name = ""DeliciousFileSpam""; Int index. command <<<; mkdir ${sample_name}_${index}; for i in `seq 0 900`; do; echo $i > ${sample_name}_${index}_$i.txt; echo $i > ${sample_name}_${index}/$i.txt; done. > > > runtime {; > > > docker: ""ubuntu:latest""; > > > memory: ""3 GB""; > > > cpu: ""1""; > > > disks: ""local-disk 5 HDD""; > > > preemptible: 3; > > > }; > > > output {; > > > Array[File] outer = glob(""${sample_name}_${index}__""); > > > Array[File] inner = glob(""${sample_name}_${index}/_""); > > > }; > > > }. task MatrixRotation {; Array[Array[String]] input_matrix. ```; command <<<; python <<CODE; import csv; import sys; with open('${write_tsv(input_matrix)}') as tsv_in:; input_matrix = [line.strip().split('\t') for line in tsv_in]; final_matrix = [["""" for x in range(len(input_matrix))] for y in range(len(input_matrix[0]))]; for x in range(len(input_matrix)):; for y in range(len(input_matrix[0])):; final_matrix[y][x] = input_matrix[x][y]; with open(""output.tsv"", ""w"") as tsv_out:; # lineterminator is a workaround for a cromwell bug that doesnt allow for '\r\n' line endings which this outputs by default; writer = csv.writer(tsv_out, delimiter='\t', lineterminator='\n'); writer.writerows(final_matrix); CODE; >>>. runtime {; docker: ""python:2.7""; memory: ""1 GB""; preemptible: 3; }. output {; File out = ""output.tsv""; Array[Array[String]] output_matrix = read_tsv(out); }; ```. }. workflow DeliciousFileSpam {; Array[Int] indexing_list = [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,; 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,; 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,; 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,; 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,; 51, 52, 53, 54, 55, 56, ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/911
https://github.com/broadinstitute/cromwell/issues/911:196,Testability,log,log,196,"Running this WDL (with a wider scatter count... start with 250) fails with a database persistence error like:. > The size of BLOB/TEXT data inserted in one transaction is greater than 10% of redo log size. Increase the redo log size using innodb_log_file_size. Which we can't do with CloudSQL on Google. task FileSpam {; String sample_name = ""DeliciousFileSpam""; Int index. command <<<; mkdir ${sample_name}_${index}; for i in `seq 0 900`; do; echo $i > ${sample_name}_${index}_$i.txt; echo $i > ${sample_name}_${index}/$i.txt; done. > > > runtime {; > > > docker: ""ubuntu:latest""; > > > memory: ""3 GB""; > > > cpu: ""1""; > > > disks: ""local-disk 5 HDD""; > > > preemptible: 3; > > > }; > > > output {; > > > Array[File] outer = glob(""${sample_name}_${index}__""); > > > Array[File] inner = glob(""${sample_name}_${index}/_""); > > > }; > > > }. task MatrixRotation {; Array[Array[String]] input_matrix. ```; command <<<; python <<CODE; import csv; import sys; with open('${write_tsv(input_matrix)}') as tsv_in:; input_matrix = [line.strip().split('\t') for line in tsv_in]; final_matrix = [["""" for x in range(len(input_matrix))] for y in range(len(input_matrix[0]))]; for x in range(len(input_matrix)):; for y in range(len(input_matrix[0])):; final_matrix[y][x] = input_matrix[x][y]; with open(""output.tsv"", ""w"") as tsv_out:; # lineterminator is a workaround for a cromwell bug that doesnt allow for '\r\n' line endings which this outputs by default; writer = csv.writer(tsv_out, delimiter='\t', lineterminator='\n'); writer.writerows(final_matrix); CODE; >>>. runtime {; docker: ""python:2.7""; memory: ""1 GB""; preemptible: 3; }. output {; File out = ""output.tsv""; Array[Array[String]] output_matrix = read_tsv(out); }; ```. }. workflow DeliciousFileSpam {; Array[Int] indexing_list = [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,; 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,; 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,; 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,; 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,; 51, 52, 53, 54, 55, 56, ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/911
https://github.com/broadinstitute/cromwell/issues/911:224,Testability,log,log,224,"Running this WDL (with a wider scatter count... start with 250) fails with a database persistence error like:. > The size of BLOB/TEXT data inserted in one transaction is greater than 10% of redo log size. Increase the redo log size using innodb_log_file_size. Which we can't do with CloudSQL on Google. task FileSpam {; String sample_name = ""DeliciousFileSpam""; Int index. command <<<; mkdir ${sample_name}_${index}; for i in `seq 0 900`; do; echo $i > ${sample_name}_${index}_$i.txt; echo $i > ${sample_name}_${index}/$i.txt; done. > > > runtime {; > > > docker: ""ubuntu:latest""; > > > memory: ""3 GB""; > > > cpu: ""1""; > > > disks: ""local-disk 5 HDD""; > > > preemptible: 3; > > > }; > > > output {; > > > Array[File] outer = glob(""${sample_name}_${index}__""); > > > Array[File] inner = glob(""${sample_name}_${index}/_""); > > > }; > > > }. task MatrixRotation {; Array[Array[String]] input_matrix. ```; command <<<; python <<CODE; import csv; import sys; with open('${write_tsv(input_matrix)}') as tsv_in:; input_matrix = [line.strip().split('\t') for line in tsv_in]; final_matrix = [["""" for x in range(len(input_matrix))] for y in range(len(input_matrix[0]))]; for x in range(len(input_matrix)):; for y in range(len(input_matrix[0])):; final_matrix[y][x] = input_matrix[x][y]; with open(""output.tsv"", ""w"") as tsv_out:; # lineterminator is a workaround for a cromwell bug that doesnt allow for '\r\n' line endings which this outputs by default; writer = csv.writer(tsv_out, delimiter='\t', lineterminator='\n'); writer.writerows(final_matrix); CODE; >>>. runtime {; docker: ""python:2.7""; memory: ""1 GB""; preemptible: 3; }. output {; File out = ""output.tsv""; Array[Array[String]] output_matrix = read_tsv(out); }; ```. }. workflow DeliciousFileSpam {; Array[Int] indexing_list = [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10,; 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,; 21, 22, 23, 24, 25, 26, 27, 28, 29, 30,; 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,; 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,; 51, 52, 53, 54, 55, 56, ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/911
https://github.com/broadinstitute/cromwell/pull/913:145,Testability,test,tests,145,This is awkward. Some code which looks like it's designed to handle a special case was breaking a common case. Ho Hum... I want to make some JES tests.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/913
https://github.com/broadinstitute/cromwell/pull/916:175,Availability,failure,failure,175,"- Removes the ability to abort Finalization Actor; - Ensures that the finalization actor runs if the Workflow reaches the `Initialize` state, regardless of what happens next (failure, success, abort), or when it happens (initialization, execution).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/916
https://github.com/broadinstitute/cromwell/pull/916:25,Safety,abort,abort,25,"- Removes the ability to abort Finalization Actor; - Ensures that the finalization actor runs if the Workflow reaches the `Initialize` state, regardless of what happens next (failure, success, abort), or when it happens (initialization, execution).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/916
https://github.com/broadinstitute/cromwell/pull/916:193,Safety,abort,abort,193,"- Removes the ability to abort Finalization Actor; - Ensures that the finalization actor runs if the Workflow reaches the `Initialize` state, regardless of what happens next (failure, success, abort), or when it happens (initialization, execution).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/916
https://github.com/broadinstitute/cromwell/issues/922:138,Availability,error,error-become-immortal,138,"Find the original post [here](http://gatkforums.broadinstitute.org/wdl/discussion/7690/running-in-server-mode-jobs-that-have-localization-error-become-immortal#latest). ---. **User Report**. Running cromwell in server mode, with default configuration in each case, I can reproduce the following behaviour in 0.18, 0.19 and 0.19_hotfix (HEAD):. Submit a workflow that has non-existent file as input to a task, e.g.:. ```; task BillyBob {; File bbInput; command { echo ""done"" }; }; workflow badLocalization {; call BillyBob { input: bbInput=""/foo/bar/baz"" }; }; ```. The server log shows ""Failures during localization"" error (below) - as expected initially, I guess - but then _repeats_ the error every 30 seconds or so, forever, and hitting the API `<workflowId>/status` endpoint shows the job in a ""Running"" state, forever. I would expect this error to cause the task, and then the workflow, to die. example of a single block of the server log error: . ```; 2016-05-27 11:08:57,269 cromwell-system-akka.actor.default-dispatcher-5 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localize$1(SharedFileSystem.scala:242) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustFile$1(SharedFileSystem.scala:264) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localizeWdlValue(SharedFileSystem.scala:271) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:462,Availability,echo,echo,462,"Find the original post [here](http://gatkforums.broadinstitute.org/wdl/discussion/7690/running-in-server-mode-jobs-that-have-localization-error-become-immortal#latest). ---. **User Report**. Running cromwell in server mode, with default configuration in each case, I can reproduce the following behaviour in 0.18, 0.19 and 0.19_hotfix (HEAD):. Submit a workflow that has non-existent file as input to a task, e.g.:. ```; task BillyBob {; File bbInput; command { echo ""done"" }; }; workflow badLocalization {; call BillyBob { input: bbInput=""/foo/bar/baz"" }; }; ```. The server log shows ""Failures during localization"" error (below) - as expected initially, I guess - but then _repeats_ the error every 30 seconds or so, forever, and hitting the API `<workflowId>/status` endpoint shows the job in a ""Running"" state, forever. I would expect this error to cause the task, and then the workflow, to die. example of a single block of the server log error: . ```; 2016-05-27 11:08:57,269 cromwell-system-akka.actor.default-dispatcher-5 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localize$1(SharedFileSystem.scala:242) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustFile$1(SharedFileSystem.scala:264) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localizeWdlValue(SharedFileSystem.scala:271) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:587,Availability,Failure,Failures,587,"Find the original post [here](http://gatkforums.broadinstitute.org/wdl/discussion/7690/running-in-server-mode-jobs-that-have-localization-error-become-immortal#latest). ---. **User Report**. Running cromwell in server mode, with default configuration in each case, I can reproduce the following behaviour in 0.18, 0.19 and 0.19_hotfix (HEAD):. Submit a workflow that has non-existent file as input to a task, e.g.:. ```; task BillyBob {; File bbInput; command { echo ""done"" }; }; workflow badLocalization {; call BillyBob { input: bbInput=""/foo/bar/baz"" }; }; ```. The server log shows ""Failures during localization"" error (below) - as expected initially, I guess - but then _repeats_ the error every 30 seconds or so, forever, and hitting the API `<workflowId>/status` endpoint shows the job in a ""Running"" state, forever. I would expect this error to cause the task, and then the workflow, to die. example of a single block of the server log error: . ```; 2016-05-27 11:08:57,269 cromwell-system-akka.actor.default-dispatcher-5 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localize$1(SharedFileSystem.scala:242) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustFile$1(SharedFileSystem.scala:264) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localizeWdlValue(SharedFileSystem.scala:271) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:617,Availability,error,error,617,"Find the original post [here](http://gatkforums.broadinstitute.org/wdl/discussion/7690/running-in-server-mode-jobs-that-have-localization-error-become-immortal#latest). ---. **User Report**. Running cromwell in server mode, with default configuration in each case, I can reproduce the following behaviour in 0.18, 0.19 and 0.19_hotfix (HEAD):. Submit a workflow that has non-existent file as input to a task, e.g.:. ```; task BillyBob {; File bbInput; command { echo ""done"" }; }; workflow badLocalization {; call BillyBob { input: bbInput=""/foo/bar/baz"" }; }; ```. The server log shows ""Failures during localization"" error (below) - as expected initially, I guess - but then _repeats_ the error every 30 seconds or so, forever, and hitting the API `<workflowId>/status` endpoint shows the job in a ""Running"" state, forever. I would expect this error to cause the task, and then the workflow, to die. example of a single block of the server log error: . ```; 2016-05-27 11:08:57,269 cromwell-system-akka.actor.default-dispatcher-5 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localize$1(SharedFileSystem.scala:242) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustFile$1(SharedFileSystem.scala:264) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localizeWdlValue(SharedFileSystem.scala:271) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:689,Availability,error,error,689,"Find the original post [here](http://gatkforums.broadinstitute.org/wdl/discussion/7690/running-in-server-mode-jobs-that-have-localization-error-become-immortal#latest). ---. **User Report**. Running cromwell in server mode, with default configuration in each case, I can reproduce the following behaviour in 0.18, 0.19 and 0.19_hotfix (HEAD):. Submit a workflow that has non-existent file as input to a task, e.g.:. ```; task BillyBob {; File bbInput; command { echo ""done"" }; }; workflow badLocalization {; call BillyBob { input: bbInput=""/foo/bar/baz"" }; }; ```. The server log shows ""Failures during localization"" error (below) - as expected initially, I guess - but then _repeats_ the error every 30 seconds or so, forever, and hitting the API `<workflowId>/status` endpoint shows the job in a ""Running"" state, forever. I would expect this error to cause the task, and then the workflow, to die. example of a single block of the server log error: . ```; 2016-05-27 11:08:57,269 cromwell-system-akka.actor.default-dispatcher-5 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localize$1(SharedFileSystem.scala:242) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustFile$1(SharedFileSystem.scala:264) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localizeWdlValue(SharedFileSystem.scala:271) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:844,Availability,error,error,844,"Find the original post [here](http://gatkforums.broadinstitute.org/wdl/discussion/7690/running-in-server-mode-jobs-that-have-localization-error-become-immortal#latest). ---. **User Report**. Running cromwell in server mode, with default configuration in each case, I can reproduce the following behaviour in 0.18, 0.19 and 0.19_hotfix (HEAD):. Submit a workflow that has non-existent file as input to a task, e.g.:. ```; task BillyBob {; File bbInput; command { echo ""done"" }; }; workflow badLocalization {; call BillyBob { input: bbInput=""/foo/bar/baz"" }; }; ```. The server log shows ""Failures during localization"" error (below) - as expected initially, I guess - but then _repeats_ the error every 30 seconds or so, forever, and hitting the API `<workflowId>/status` endpoint shows the job in a ""Running"" state, forever. I would expect this error to cause the task, and then the workflow, to die. example of a single block of the server log error: . ```; 2016-05-27 11:08:57,269 cromwell-system-akka.actor.default-dispatcher-5 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localize$1(SharedFileSystem.scala:242) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustFile$1(SharedFileSystem.scala:264) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localizeWdlValue(SharedFileSystem.scala:271) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:944,Availability,error,error,944,"Find the original post [here](http://gatkforums.broadinstitute.org/wdl/discussion/7690/running-in-server-mode-jobs-that-have-localization-error-become-immortal#latest). ---. **User Report**. Running cromwell in server mode, with default configuration in each case, I can reproduce the following behaviour in 0.18, 0.19 and 0.19_hotfix (HEAD):. Submit a workflow that has non-existent file as input to a task, e.g.:. ```; task BillyBob {; File bbInput; command { echo ""done"" }; }; workflow badLocalization {; call BillyBob { input: bbInput=""/foo/bar/baz"" }; }; ```. The server log shows ""Failures during localization"" error (below) - as expected initially, I guess - but then _repeats_ the error every 30 seconds or so, forever, and hitting the API `<workflowId>/status` endpoint shows the job in a ""Running"" state, forever. I would expect this error to cause the task, and then the workflow, to die. example of a single block of the server log error: . ```; 2016-05-27 11:08:57,269 cromwell-system-akka.actor.default-dispatcher-5 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localize$1(SharedFileSystem.scala:242) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustFile$1(SharedFileSystem.scala:264) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localizeWdlValue(SharedFileSystem.scala:271) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:1030,Availability,ERROR,ERROR,1030,"forums.broadinstitute.org/wdl/discussion/7690/running-in-server-mode-jobs-that-have-localization-error-become-immortal#latest). ---. **User Report**. Running cromwell in server mode, with default configuration in each case, I can reproduce the following behaviour in 0.18, 0.19 and 0.19_hotfix (HEAD):. Submit a workflow that has non-existent file as input to a task, e.g.:. ```; task BillyBob {; File bbInput; command { echo ""done"" }; }; workflow badLocalization {; call BillyBob { input: bbInput=""/foo/bar/baz"" }; }; ```. The server log shows ""Failures during localization"" error (below) - as expected initially, I guess - but then _repeats_ the error every 30 seconds or so, forever, and hitting the API `<workflowId>/status` endpoint shows the job in a ""Running"" state, forever. I would expect this error to cause the task, and then the workflow, to die. example of a single block of the server log error: . ```; 2016-05-27 11:08:57,269 cromwell-system-akka.actor.default-dispatcher-5 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localize$1(SharedFileSystem.scala:242) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustFile$1(SharedFileSystem.scala:264) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localizeWdlValue(SharedFileSystem.scala:271) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.localizeWdlValue(LocalBack",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:1038,Availability,Failure,Failures,1038,"forums.broadinstitute.org/wdl/discussion/7690/running-in-server-mode-jobs-that-have-localization-error-become-immortal#latest). ---. **User Report**. Running cromwell in server mode, with default configuration in each case, I can reproduce the following behaviour in 0.18, 0.19 and 0.19_hotfix (HEAD):. Submit a workflow that has non-existent file as input to a task, e.g.:. ```; task BillyBob {; File bbInput; command { echo ""done"" }; }; workflow badLocalization {; call BillyBob { input: bbInput=""/foo/bar/baz"" }; }; ```. The server log shows ""Failures during localization"" error (below) - as expected initially, I guess - but then _repeats_ the error every 30 seconds or so, forever, and hitting the API `<workflowId>/status` endpoint shows the job in a ""Running"" state, forever. I would expect this error to cause the task, and then the workflow, to die. example of a single block of the server log error: . ```; 2016-05-27 11:08:57,269 cromwell-system-akka.actor.default-dispatcher-5 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localize$1(SharedFileSystem.scala:242) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustFile$1(SharedFileSystem.scala:264) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localizeWdlValue(SharedFileSystem.scala:271) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.localizeWdlValue(LocalBack",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:5107,Availability,ERROR,ERROR,5107,"1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) [cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,270 cromwell-system-akka.actor.default-dispatcher-5 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localize$1(SharedFileSystem.scala:242) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustFile$1(SharedFileSystem.scala:264) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localizeWdlValue(SharedFileSystem.scala:271) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.localizeWdlValue(LocalBack",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:5115,Availability,Failure,Failures,5115,"1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) [cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,270 cromwell-system-akka.actor.default-dispatcher-5 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localize$1(SharedFileSystem.scala:242) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustFile$1(SharedFileSystem.scala:264) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localizeWdlValue(SharedFileSystem.scala:271) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.localizeWdlValue(LocalBack",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:9184,Availability,ERROR,ERROR,9184,"1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) [cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,270 cromwell-system-akka.actor.default-dispatcher-4 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localize$1(SharedFileSystem.scala:242) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustFile$1(SharedFileSystem.scala:264) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localizeWdlValue(SharedFileSystem.scala:271) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.localizeWdlValue(LocalBack",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:9192,Availability,Failure,Failures,9192,"1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) [cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,270 cromwell-system-akka.actor.default-dispatcher-4 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localize$1(SharedFileSystem.scala:242) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustFile$1(SharedFileSystem.scala:264) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localizeWdlValue(SharedFileSystem.scala:271) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.localizeWdlValue(LocalBack",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:13262,Availability,ERROR,ERROR,13262,"etingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,271 cromwell-system-akka.actor.default-dispatcher-4 ERROR - BackendCallExecutionActor [UUID(8c7774be):BillyBob]: Failures during localizationCould not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; cromwell.util.AggregatedException: Failures during localizationCould not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:118) ~[cromwell-0.19.jar:0.19]; at cromwell.util.TryUtil$.sequence(TryUtil.scala:125) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustSharedInputPaths(SharedFileSystem.scala:228) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustSharedInputPaths(LocalBackend.scala:94) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustInputPaths(LocalBackend.scala:96) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.instantiateCommand(LocalBackend.scala:246) ~[cromwell-0.19.jar:0.19]; at cromwell",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:13323,Availability,Failure,Failures,13323,"etingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,271 cromwell-system-akka.actor.default-dispatcher-4 ERROR - BackendCallExecutionActor [UUID(8c7774be):BillyBob]: Failures during localizationCould not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; cromwell.util.AggregatedException: Failures during localizationCould not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:118) ~[cromwell-0.19.jar:0.19]; at cromwell.util.TryUtil$.sequence(TryUtil.scala:125) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustSharedInputPaths(SharedFileSystem.scala:228) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustSharedInputPaths(LocalBackend.scala:94) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustInputPaths(LocalBackend.scala:96) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.instantiateCommand(LocalBackend.scala:246) ~[cromwell-0.19.jar:0.19]; at cromwell",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:13535,Availability,Failure,Failures,13535,"[cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,271 cromwell-system-akka.actor.default-dispatcher-4 ERROR - BackendCallExecutionActor [UUID(8c7774be):BillyBob]: Failures during localizationCould not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; cromwell.util.AggregatedException: Failures during localizationCould not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:118) ~[cromwell-0.19.jar:0.19]; at cromwell.util.TryUtil$.sequence(TryUtil.scala:125) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustSharedInputPaths(SharedFileSystem.scala:228) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustSharedInputPaths(LocalBackend.scala:94) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustInputPaths(LocalBackend.scala:96) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.instantiateCommand(LocalBackend.scala:246) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand$lzycompute(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:237,Deployability,configurat,configuration,237,"Find the original post [here](http://gatkforums.broadinstitute.org/wdl/discussion/7690/running-in-server-mode-jobs-that-have-localization-error-become-immortal#latest). ---. **User Report**. Running cromwell in server mode, with default configuration in each case, I can reproduce the following behaviour in 0.18, 0.19 and 0.19_hotfix (HEAD):. Submit a workflow that has non-existent file as input to a task, e.g.:. ```; task BillyBob {; File bbInput; command { echo ""done"" }; }; workflow badLocalization {; call BillyBob { input: bbInput=""/foo/bar/baz"" }; }; ```. The server log shows ""Failures during localization"" error (below) - as expected initially, I guess - but then _repeats_ the error every 30 seconds or so, forever, and hitting the API `<workflowId>/status` endpoint shows the job in a ""Running"" state, forever. I would expect this error to cause the task, and then the workflow, to die. example of a single block of the server log error: . ```; 2016-05-27 11:08:57,269 cromwell-system-akka.actor.default-dispatcher-5 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localize$1(SharedFileSystem.scala:242) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustFile$1(SharedFileSystem.scala:264) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localizeWdlValue(SharedFileSystem.scala:271) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:237,Modifiability,config,configuration,237,"Find the original post [here](http://gatkforums.broadinstitute.org/wdl/discussion/7690/running-in-server-mode-jobs-that-have-localization-error-become-immortal#latest). ---. **User Report**. Running cromwell in server mode, with default configuration in each case, I can reproduce the following behaviour in 0.18, 0.19 and 0.19_hotfix (HEAD):. Submit a workflow that has non-existent file as input to a task, e.g.:. ```; task BillyBob {; File bbInput; command { echo ""done"" }; }; workflow badLocalization {; call BillyBob { input: bbInput=""/foo/bar/baz"" }; }; ```. The server log shows ""Failures during localization"" error (below) - as expected initially, I guess - but then _repeats_ the error every 30 seconds or so, forever, and hitting the API `<workflowId>/status` endpoint shows the job in a ""Running"" state, forever. I would expect this error to cause the task, and then the workflow, to die. example of a single block of the server log error: . ```; 2016-05-27 11:08:57,269 cromwell-system-akka.actor.default-dispatcher-5 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localize$1(SharedFileSystem.scala:242) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustFile$1(SharedFileSystem.scala:264) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localizeWdlValue(SharedFileSystem.scala:271) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:4186,Performance,concurren,concurrent,4186,"19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustSharedInputPaths(SharedFileSystem.scala:224) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustSharedInputPaths(LocalBackend.scala:94) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustInputPaths(LocalBackend.scala:96) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.instantiateCommand(LocalBackend.scala:246) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand$lzycompute(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) [cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,270 cromwell-system-akka.actor.default-dispatcher-5 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:4302,Performance,concurren,concurrent,4302,"omwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustSharedInputPaths(LocalBackend.scala:94) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustInputPaths(LocalBackend.scala:96) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.instantiateCommand(LocalBackend.scala:246) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand$lzycompute(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) [cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,270 cromwell-system-akka.actor.default-dispatcher-5 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:4623,Performance,concurren,concurrent,4623,"ocalBackend.scala:246) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand$lzycompute(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) [cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,270 cromwell-system-akka.actor.default-dispatcher-5 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Op",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:4721,Performance,concurren,concurrent,4721,"tor.instantiateCommand$lzycompute(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) [cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,270 cromwell-system-akka.actor.default-dispatcher-5 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:4831,Performance,concurren,concurrent,4831,"d.BackendCallJobDescriptor.instantiateCommand(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) [cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,270 cromwell-system-akka.actor.default-dispatcher-5 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localize$1(SharedFileSystem.scala:242) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFile",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:4933,Performance,concurren,concurrent,4933,"omwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) [cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,270 cromwell-system-akka.actor.default-dispatcher-5 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localize$1(SharedFileSystem.scala:242) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustFile$1(SharedFileSystem.scala:264) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.ba",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:8263,Performance,concurren,concurrent,8263,"19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustSharedInputPaths(SharedFileSystem.scala:224) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustSharedInputPaths(LocalBackend.scala:94) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustInputPaths(LocalBackend.scala:96) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.instantiateCommand(LocalBackend.scala:246) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand$lzycompute(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) [cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,270 cromwell-system-akka.actor.default-dispatcher-4 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:8379,Performance,concurren,concurrent,8379,"omwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustSharedInputPaths(LocalBackend.scala:94) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustInputPaths(LocalBackend.scala:96) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.instantiateCommand(LocalBackend.scala:246) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand$lzycompute(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) [cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,270 cromwell-system-akka.actor.default-dispatcher-4 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:8700,Performance,concurren,concurrent,8700,"ocalBackend.scala:246) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand$lzycompute(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) [cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,270 cromwell-system-akka.actor.default-dispatcher-4 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Op",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:8798,Performance,concurren,concurrent,8798,"tor.instantiateCommand$lzycompute(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) [cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,270 cromwell-system-akka.actor.default-dispatcher-4 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:8908,Performance,concurren,concurrent,8908,"d.BackendCallJobDescriptor.instantiateCommand(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) [cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,270 cromwell-system-akka.actor.default-dispatcher-4 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localize$1(SharedFileSystem.scala:242) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFile",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:9010,Performance,concurren,concurrent,9010,"omwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) [cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,270 cromwell-system-akka.actor.default-dispatcher-4 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localize$1(SharedFileSystem.scala:242) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustFile$1(SharedFileSystem.scala:264) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.ba",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:12340,Performance,concurren,concurrent,12340,"19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustSharedInputPaths(SharedFileSystem.scala:224) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustSharedInputPaths(LocalBackend.scala:94) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustInputPaths(LocalBackend.scala:96) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.instantiateCommand(LocalBackend.scala:246) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand$lzycompute(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,271 cromwell-system-akka.actor.default-dispatcher-4 ERROR - BackendCallExecutionActor [UUID(8c7774be):BillyBob]: Failures during localiz",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:12456,Performance,concurren,concurrent,12456,"omwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustSharedInputPaths(LocalBackend.scala:94) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustInputPaths(LocalBackend.scala:96) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.instantiateCommand(LocalBackend.scala:246) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand$lzycompute(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,271 cromwell-system-akka.actor.default-dispatcher-4 ERROR - BackendCallExecutionActor [UUID(8c7774be):BillyBob]: Failures during localizationCould not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:12778,Performance,concurren,concurrent,12778,"calBackend.scala:246) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand$lzycompute(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,271 cromwell-system-akka.actor.default-dispatcher-4 ERROR - BackendCallExecutionActor [UUID(8c7774be):BillyBob]: Failures during localizationCould not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; cromwell.util.AggregatedException: Failures during localizationCould not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:118) ~[cromwell",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:12876,Performance,concurren,concurrent,12876,"or.instantiateCommand$lzycompute(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,271 cromwell-system-akka.actor.default-dispatcher-4 ERROR - BackendCallExecutionActor [UUID(8c7774be):BillyBob]: Failures during localizationCould not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; cromwell.util.AggregatedException: Failures during localizationCould not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:118) ~[cromwell-0.19.jar:0.19]; at cromwell.util.TryUtil$.sequence(TryUtil.scala:125) ~[cromwell-0.19.jar:0.19]; ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:12986,Performance,concurren,concurrent,12986,".BackendCallJobDescriptor.instantiateCommand(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,271 cromwell-system-akka.actor.default-dispatcher-4 ERROR - BackendCallExecutionActor [UUID(8c7774be):BillyBob]: Failures during localizationCould not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; cromwell.util.AggregatedException: Failures during localizationCould not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:118) ~[cromwell-0.19.jar:0.19]; at cromwell.util.TryUtil$.sequence(TryUtil.scala:125) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustSharedInputPaths(SharedFileSystem.scala:228) ~[c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:13088,Performance,concurren,concurrent,13088,"mwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; 2016-05-27 11:08:57,271 cromwell-system-akka.actor.default-dispatcher-4 ERROR - BackendCallExecutionActor [UUID(8c7774be):BillyBob]: Failures during localizationCould not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; cromwell.util.AggregatedException: Failures during localizationCould not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:118) ~[cromwell-0.19.jar:0.19]; at cromwell.util.TryUtil$.sequence(TryUtil.scala:125) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustSharedInputPaths(SharedFileSystem.scala:228) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustSharedInputPaths(LocalBack",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:14872,Performance,concurren,concurrent,14872,til.TryUtil$.sequenceIterable(TryUtil.scala:118) ~[cromwell-0.19.jar:0.19]; at cromwell.util.TryUtil$.sequence(TryUtil.scala:125) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustSharedInputPaths(SharedFileSystem.scala:228) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustSharedInputPaths(LocalBackend.scala:94) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustInputPaths(LocalBackend.scala:96) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.instantiateCommand(LocalBackend.scala:246) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand$lzycompute(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:14988,Performance,concurren,concurrent,14988,til.TryUtil$.sequenceIterable(TryUtil.scala:118) ~[cromwell-0.19.jar:0.19]; at cromwell.util.TryUtil$.sequence(TryUtil.scala:125) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustSharedInputPaths(SharedFileSystem.scala:228) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustSharedInputPaths(LocalBackend.scala:94) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustInputPaths(LocalBackend.scala:96) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.instantiateCommand(LocalBackend.scala:246) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand$lzycompute(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:15310,Performance,concurren,concurrent,15310,til.TryUtil$.sequenceIterable(TryUtil.scala:118) ~[cromwell-0.19.jar:0.19]; at cromwell.util.TryUtil$.sequence(TryUtil.scala:125) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustSharedInputPaths(SharedFileSystem.scala:228) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustSharedInputPaths(LocalBackend.scala:94) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustInputPaths(LocalBackend.scala:96) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.instantiateCommand(LocalBackend.scala:246) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand$lzycompute(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:15408,Performance,concurren,concurrent,15408,til.TryUtil$.sequenceIterable(TryUtil.scala:118) ~[cromwell-0.19.jar:0.19]; at cromwell.util.TryUtil$.sequence(TryUtil.scala:125) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustSharedInputPaths(SharedFileSystem.scala:228) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustSharedInputPaths(LocalBackend.scala:94) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustInputPaths(LocalBackend.scala:96) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.instantiateCommand(LocalBackend.scala:246) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand$lzycompute(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:15518,Performance,concurren,concurrent,15518,til.TryUtil$.sequenceIterable(TryUtil.scala:118) ~[cromwell-0.19.jar:0.19]; at cromwell.util.TryUtil$.sequence(TryUtil.scala:125) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustSharedInputPaths(SharedFileSystem.scala:228) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustSharedInputPaths(LocalBackend.scala:94) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustInputPaths(LocalBackend.scala:96) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.instantiateCommand(LocalBackend.scala:246) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand$lzycompute(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:15620,Performance,concurren,concurrent,15620,til.TryUtil$.sequenceIterable(TryUtil.scala:118) ~[cromwell-0.19.jar:0.19]; at cromwell.util.TryUtil$.sequence(TryUtil.scala:125) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustSharedInputPaths(SharedFileSystem.scala:228) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustSharedInputPaths(LocalBackend.scala:94) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.adjustInputPaths(LocalBackend.scala:96) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend.instantiateCommand(LocalBackend.scala:246) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand$lzycompute(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.BackendCallJobDescriptor.instantiateCommand(JobDescriptor.scala:52) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:115) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.LocalBackend$$anonfun$execute$1.apply(LocalBackend.scala:113) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell-0.19.jar:0.19]; at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell-0.19.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell-0.19.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:576,Testability,log,log,576,"Find the original post [here](http://gatkforums.broadinstitute.org/wdl/discussion/7690/running-in-server-mode-jobs-that-have-localization-error-become-immortal#latest). ---. **User Report**. Running cromwell in server mode, with default configuration in each case, I can reproduce the following behaviour in 0.18, 0.19 and 0.19_hotfix (HEAD):. Submit a workflow that has non-existent file as input to a task, e.g.:. ```; task BillyBob {; File bbInput; command { echo ""done"" }; }; workflow badLocalization {; call BillyBob { input: bbInput=""/foo/bar/baz"" }; }; ```. The server log shows ""Failures during localization"" error (below) - as expected initially, I guess - but then _repeats_ the error every 30 seconds or so, forever, and hitting the API `<workflowId>/status` endpoint shows the job in a ""Running"" state, forever. I would expect this error to cause the task, and then the workflow, to die. example of a single block of the server log error: . ```; 2016-05-27 11:08:57,269 cromwell-system-akka.actor.default-dispatcher-5 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localize$1(SharedFileSystem.scala:242) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustFile$1(SharedFileSystem.scala:264) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localizeWdlValue(SharedFileSystem.scala:271) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/issues/922:940,Testability,log,log,940,"Find the original post [here](http://gatkforums.broadinstitute.org/wdl/discussion/7690/running-in-server-mode-jobs-that-have-localization-error-become-immortal#latest). ---. **User Report**. Running cromwell in server mode, with default configuration in each case, I can reproduce the following behaviour in 0.18, 0.19 and 0.19_hotfix (HEAD):. Submit a workflow that has non-existent file as input to a task, e.g.:. ```; task BillyBob {; File bbInput; command { echo ""done"" }; }; workflow badLocalization {; call BillyBob { input: bbInput=""/foo/bar/baz"" }; }; ```. The server log shows ""Failures during localization"" error (below) - as expected initially, I guess - but then _repeats_ the error every 30 seconds or so, forever, and hitting the API `<workflowId>/status` endpoint shows the job in a ""Running"" state, forever. I would expect this error to cause the task, and then the workflow, to die. example of a single block of the server log error: . ```; 2016-05-27 11:08:57,269 cromwell-system-akka.actor.default-dispatcher-5 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localize$1(SharedFileSystem.scala:242) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustFile$1(SharedFileSystem.scala:264) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localizeWdlValue(SharedFileSystem.scala:271) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922
https://github.com/broadinstitute/cromwell/pull/924:42,Testability,test,test,42,…verifies workflow outputs exist (and the test didn't produce them before),MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/924
https://github.com/broadinstitute/cromwell/issues/927:58,Availability,error,error,58,"After workflow succesffuly ran this failed with the below error when trying to copy the final outputs. ```; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(88b21d2d)]: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log.; java.util.NoSuchElementException: None.get; at scala.None$.get(Option.scala:347) ~[cromwell.jar:0.19]; at scala.None$.get(Option.scala:345) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:156) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter$$anonfun$map$2.apply(TraversableLike.scala:728) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter.map(TraversableLike.scala:727) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:153) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:233) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.foldLeft(List.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:181,Availability,ERROR,ERROR,181,"After workflow succesffuly ran this failed with the below error when trying to copy the final outputs. ```; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(88b21d2d)]: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log.; java.util.NoSuchElementException: None.get; at scala.None$.get(Option.scala:347) ~[cromwell.jar:0.19]; at scala.None$.get(Option.scala:345) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:156) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter$$anonfun$map$2.apply(TraversableLike.scala:728) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter.map(TraversableLike.scala:727) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:153) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:233) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.foldLeft(List.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:4353,Availability,ERROR,ERROR,4353,"235) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.pollAndExecAll(ForkJoinPool.java:1253) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1346) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(88b21d2d)]: Call failed to initialize: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log: None.get; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 INFO - WorkflowActor [UUID(88b21d2d)]: persisting status of PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log to Failed.; 2016-06-01 16:10:15,230 cromwell-system-akka.actor.default-dispatcher-20 INFO - WorkflowActor [UUID(88b21d2d)]: Beginning transition from Running to Failed.; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:3685,Energy Efficiency,Adapt,AdaptedForkJoinTask,3685,"a.util.Success.map(Try.scala:237) ~[cromwell.jar:0.19]; at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235) ~[cromwell.jar:0.19]; at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.pollAndExecAll(ForkJoinPool.java:1253) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1346) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(88b21d2d)]: Call failed to initialize: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log: None.get; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 INFO - WorkflowActor [UUID(88b21d2d)]: persisting status of PairedEndSingleSampleWorkflow",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:3685,Modifiability,Adapt,AdaptedForkJoinTask,3685,"a.util.Success.map(Try.scala:237) ~[cromwell.jar:0.19]; at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235) ~[cromwell.jar:0.19]; at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.pollAndExecAll(ForkJoinPool.java:1253) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1346) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(88b21d2d)]: Call failed to initialize: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log: None.get; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 INFO - WorkflowActor [UUID(88b21d2d)]: persisting status of PairedEndSingleSampleWorkflow",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:2749,Performance,concurren,concurrent,2749,.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.foldLeft(List.scala:84) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$.build(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowMetadataBuilder$$anonfun$cromwell$engine$workflow$WorkflowMetadataBuilder$$buildWorkflowMetadata$2.apply(WorkflowMetadataBuilder.scala:95) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowMetadataBuilder$$anonfun$cromwell$engine$workflow$WorkflowMetadataBuilder$$buildWorkflowMetadata$2.apply(WorkflowMetadataBuilder.scala:85) ~[cromwell.jar:0.19]; at scala.util.Success$$anonfun$map$1.apply(Try.scala:237) ~[cromwell.jar:0.19]; at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]; at scala.util.Success.map(Try.scala:237) ~[cromwell.jar:0.19]; at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235) ~[cromwell.jar:0.19]; at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.ja,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:2837,Performance,concurren,concurrent,2837,9]; at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.foldLeft(List.scala:84) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$.build(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowMetadataBuilder$$anonfun$cromwell$engine$workflow$WorkflowMetadataBuilder$$buildWorkflowMetadata$2.apply(WorkflowMetadataBuilder.scala:95) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowMetadataBuilder$$anonfun$cromwell$engine$workflow$WorkflowMetadataBuilder$$buildWorkflowMetadata$2.apply(WorkflowMetadataBuilder.scala:85) ~[cromwell.jar:0.19]; at scala.util.Success$$anonfun$map$1.apply(Try.scala:237) ~[cromwell.jar:0.19]; at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]; at scala.util.Success.map(Try.scala:237) ~[cromwell.jar:0.19]; at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235) ~[cromwell.jar:0.19]; at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[cromw,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:2925,Performance,concurren,concurrent,2925,~[cromwell.jar:0.19]; at scala.collection.immutable.List.foldLeft(List.scala:84) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$.build(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowMetadataBuilder$$anonfun$cromwell$engine$workflow$WorkflowMetadataBuilder$$buildWorkflowMetadata$2.apply(WorkflowMetadataBuilder.scala:95) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowMetadataBuilder$$anonfun$cromwell$engine$workflow$WorkflowMetadataBuilder$$buildWorkflowMetadata$2.apply(WorkflowMetadataBuilder.scala:85) ~[cromwell.jar:0.19]; at scala.util.Success$$anonfun$map$1.apply(Try.scala:237) ~[cromwell.jar:0.19]; at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]; at scala.util.Success.map(Try.scala:237) ~[cromwell.jar:0.19]; at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235) ~[cromwell.jar:0.19]; at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.pollAndExecAll(ForkJo,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:3023,Performance,concurren,concurrent,3023,19]; at cromwell.engine.workflow.CallMetadataBuilder$.build(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowMetadataBuilder$$anonfun$cromwell$engine$workflow$WorkflowMetadataBuilder$$buildWorkflowMetadata$2.apply(WorkflowMetadataBuilder.scala:95) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.WorkflowMetadataBuilder$$anonfun$cromwell$engine$workflow$WorkflowMetadataBuilder$$buildWorkflowMetadata$2.apply(WorkflowMetadataBuilder.scala:85) ~[cromwell.jar:0.19]; at scala.util.Success$$anonfun$map$1.apply(Try.scala:237) ~[cromwell.jar:0.19]; at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]; at scala.util.Success.map(Try.scala:237) ~[cromwell.jar:0.19]; at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235) ~[cromwell.jar:0.19]; at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.pollAndExecAll(ForkJoinPool.java:1253) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTas,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:3562,Performance,concurren,concurrent,3562,"ap$1.apply(Try.scala:237) ~[cromwell.jar:0.19]; at scala.util.Try$.apply(Try.scala:192) ~[cromwell.jar:0.19]; at scala.util.Success.map(Try.scala:237) ~[cromwell.jar:0.19]; at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235) ~[cromwell.jar:0.19]; at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.pollAndExecAll(ForkJoinPool.java:1253) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1346) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(88b21d2d)]: Call failed to initialize: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log: None.get; 2016-06-01 16:10:15,093 cromwell-system-akka.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:3648,Performance,concurren,concurrent,3648,") ~[cromwell.jar:0.19]; at scala.util.Success.map(Try.scala:237) ~[cromwell.jar:0.19]; at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235) ~[cromwell.jar:0.19]; at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.pollAndExecAll(ForkJoinPool.java:1253) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1346) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(88b21d2d)]: Call failed to initialize: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log: None.get; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 INFO - WorkflowActor [UUID(88b21d2d)]: persisting status o",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:3773,Performance,concurren,concurrent,3773,"p$1.apply(Future.scala:235) ~[cromwell.jar:0.19]; at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:235) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.pollAndExecAll(ForkJoinPool.java:1253) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1346) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(88b21d2d)]: Call failed to initialize: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log: None.get; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 INFO - WorkflowActor [UUID(88b21d2d)]: persisting status of PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log to Failed.; 2016-06-01 16:10:15,230 cromwell-system-akka.actor.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:3867,Performance,concurren,concurrent,3867,"ply(Future.scala:235) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.pollAndExecAll(ForkJoinPool.java:1253) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1346) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(88b21d2d)]: Call failed to initialize: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log: None.get; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 INFO - WorkflowActor [UUID(88b21d2d)]: persisting status of PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log to Failed.; 2016-06-01 16:10:15,230 cromwell-system-akka.actor.default-dispatcher-20 INFO - WorkflowActor [UUID(88b21d2d)]: Beginning transition from Running",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:3980,Performance,concurren,concurrent,3980,"235) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.pollAndExecAll(ForkJoinPool.java:1253) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1346) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(88b21d2d)]: Call failed to initialize: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log: None.get; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 INFO - WorkflowActor [UUID(88b21d2d)]: persisting status of PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log to Failed.; 2016-06-01 16:10:15,230 cromwell-system-akka.actor.default-dispatcher-20 INFO - WorkflowActor [UUID(88b21d2d)]: Beginning transition from Running to Failed.; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:4086,Performance,concurren,concurrent,4086,"235) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.pollAndExecAll(ForkJoinPool.java:1253) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1346) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(88b21d2d)]: Call failed to initialize: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log: None.get; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 INFO - WorkflowActor [UUID(88b21d2d)]: persisting status of PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log to Failed.; 2016-06-01 16:10:15,230 cromwell-system-akka.actor.default-dispatcher-20 INFO - WorkflowActor [UUID(88b21d2d)]: Beginning transition from Running to Failed.; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:4183,Performance,concurren,concurrent,4183,"235) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19]; at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19]; at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19]; at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19]; at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.pollAndExecAll(ForkJoinPool.java:1253) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1346) ~[cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(88b21d2d)]: Call failed to initialize: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log: None.get; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 INFO - WorkflowActor [UUID(88b21d2d)]: persisting status of PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log to Failed.; 2016-06-01 16:10:15,230 cromwell-system-akka.actor.default-dispatcher-20 INFO - WorkflowActor [UUID(88b21d2d)]: Beginning transition from Running to Failed.; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:952,Security,Hash,HashMap,952,"After workflow succesffuly ran this failed with the below error when trying to copy the final outputs. ```; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(88b21d2d)]: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log.; java.util.NoSuchElementException: None.get; at scala.None$.get(Option.scala:347) ~[cromwell.jar:0.19]; at scala.None$.get(Option.scala:345) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:156) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter$$anonfun$map$2.apply(TraversableLike.scala:728) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter.map(TraversableLike.scala:727) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:153) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:233) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.foldLeft(List.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:977,Security,Hash,HashMap,977,"After workflow succesffuly ran this failed with the below error when trying to copy the final outputs. ```; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(88b21d2d)]: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log.; java.util.NoSuchElementException: None.get; at scala.None$.get(Option.scala:347) ~[cromwell.jar:0.19]; at scala.None$.get(Option.scala:345) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:156) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter$$anonfun$map$2.apply(TraversableLike.scala:728) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter.map(TraversableLike.scala:727) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:153) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:233) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.foldLeft(List.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:1048,Security,Hash,HashMap,1048,"error when trying to copy the final outputs. ```; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(88b21d2d)]: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log.; java.util.NoSuchElementException: None.get; at scala.None$.get(Option.scala:347) ~[cromwell.jar:0.19]; at scala.None$.get(Option.scala:345) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:156) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter$$anonfun$map$2.apply(TraversableLike.scala:728) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter.map(TraversableLike.scala:727) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:153) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:233) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.foldLeft(List.scala:84) ~[cromwell.jar:0.19]; at cromwell.engine.workfl",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:1056,Security,Hash,HashTrieMap,1056,"error when trying to copy the final outputs. ```; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(88b21d2d)]: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log.; java.util.NoSuchElementException: None.get; at scala.None$.get(Option.scala:347) ~[cromwell.jar:0.19]; at scala.None$.get(Option.scala:345) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:156) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter$$anonfun$map$2.apply(TraversableLike.scala:728) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter.map(TraversableLike.scala:727) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:153) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:233) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.foldLeft(List.scala:84) ~[cromwell.jar:0.19]; at cromwell.engine.workfl",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:1076,Security,Hash,HashMap,1076,"to copy the final outputs. ```; 2016-06-01 16:10:15,093 cromwell-system-akka.actor.default-dispatcher-15 ERROR - WorkflowActor [UUID(88b21d2d)]: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log.; java.util.NoSuchElementException: None.get; at scala.None$.get(Option.scala:347) ~[cromwell.jar:0.19]; at scala.None$.get(Option.scala:345) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:156) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter$$anonfun$map$2.apply(TraversableLike.scala:728) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter.map(TraversableLike.scala:727) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:153) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:233) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.foldLeft(List.scala:84) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBui",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:1147,Security,Hash,HashMap,1147,r.default-dispatcher-15 ERROR - WorkflowActor [UUID(88b21d2d)]: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log.; java.util.NoSuchElementException: None.get; at scala.None$.get(Option.scala:347) ~[cromwell.jar:0.19]; at scala.None$.get(Option.scala:345) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:156) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter$$anonfun$map$2.apply(TraversableLike.scala:728) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter.map(TraversableLike.scala:727) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:153) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:233) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.foldLeft(List.scala:84) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$.build(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at cromwell.engi,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:1155,Security,Hash,HashTrieMap,1155,r.default-dispatcher-15 ERROR - WorkflowActor [UUID(88b21d2d)]: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log.; java.util.NoSuchElementException: None.get; at scala.None$.get(Option.scala:347) ~[cromwell.jar:0.19]; at scala.None$.get(Option.scala:345) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:156) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter$$anonfun$map$2.apply(TraversableLike.scala:728) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter.map(TraversableLike.scala:727) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:153) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:233) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.foldLeft(List.scala:84) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$.build(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at cromwell.engi,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/927:1175,Security,Hash,HashMap,1175,er-15 ERROR - WorkflowActor [UUID(88b21d2d)]: failed to create call actor for PairedEndSingleSampleWorkflow.$final_call$copy_workflow_log.; java.util.NoSuchElementException: None.get; at scala.None$.get(Option.scala:347) ~[cromwell.jar:0.19]; at scala.None$.get(Option.scala:345) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:156) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1$$anonfun$apply$26.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter$$anonfun$map$2.apply(TraversableLike.scala:728) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashMap1.foreach(HashMap.scala:221) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.immutable.HashMap$HashTrieMap.foreach(HashMap.scala:428) ~[cromwell.jar:0.19]; at scala.collection.TraversableLike$WithFilter.map(TraversableLike.scala:727) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:155) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$buildCallFailureTransformer$1.apply(CallMetadataBuilder.scala:153) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:233) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$$anonfun$15.apply(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124) ~[cromwell.jar:0.19]; at scala.collection.immutable.List.foldLeft(List.scala:84) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.CallMetadataBuilder$.build(CallMetadataBuilder.scala:232) ~[cromwell.jar:0.19]; at cromwell.engine.workflow.Workfl,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/927
https://github.com/broadinstitute/cromwell/issues/928:355,Availability,ERROR,ERROR,355,"The file it was trying to read is gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/9a7a405c-6b14-48cc-87e8-84ee4e7ef074/call-PreBqsrCheckContamination/PreBqsrCheckContamination-stdout.log. The task uses `read_float (stdout)` in its output block. . ```; 2016-06-01 09:47:17,888 cromwell-system-akka.actor.default-dispatcher-16 ERROR - CallActor [UUID(9a7a405c):PreBqsrCheckContamination]: Failing call: Error reading gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/9a7a405c-6b14-48cc-87e... at position 0; cromwell.util.AggregatedException: Error reading gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/9a7a405c-6b14-48cc-87e... at position 0;   at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:118) ~[cromwell.jar:0.19];   at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:130) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:625) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:664) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:659) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/928
https://github.com/broadinstitute/cromwell/issues/928:431,Availability,Error,Error,431,"The file it was trying to read is gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/9a7a405c-6b14-48cc-87e8-84ee4e7ef074/call-PreBqsrCheckContamination/PreBqsrCheckContamination-stdout.log. The task uses `read_float (stdout)` in its output block. . ```; 2016-06-01 09:47:17,888 cromwell-system-akka.actor.default-dispatcher-16 ERROR - CallActor [UUID(9a7a405c):PreBqsrCheckContamination]: Failing call: Error reading gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/9a7a405c-6b14-48cc-87e... at position 0; cromwell.util.AggregatedException: Error reading gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/9a7a405c-6b14-48cc-87e... at position 0;   at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:118) ~[cromwell.jar:0.19];   at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:130) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:625) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:664) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:659) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/928
https://github.com/broadinstitute/cromwell/issues/928:599,Availability,Error,Error,599,"The file it was trying to read is gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/9a7a405c-6b14-48cc-87e8-84ee4e7ef074/call-PreBqsrCheckContamination/PreBqsrCheckContamination-stdout.log. The task uses `read_float (stdout)` in its output block. . ```; 2016-06-01 09:47:17,888 cromwell-system-akka.actor.default-dispatcher-16 ERROR - CallActor [UUID(9a7a405c):PreBqsrCheckContamination]: Failing call: Error reading gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/9a7a405c-6b14-48cc-87e... at position 0; cromwell.util.AggregatedException: Error reading gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/9a7a405c-6b14-48cc-87e... at position 0;   at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:118) ~[cromwell.jar:0.19];   at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:130) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:625) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:664) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:659) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/928
https://github.com/broadinstitute/cromwell/issues/928:1252,Performance,concurren,concurrent,1252,"its output block. . ```; 2016-06-01 09:47:17,888 cromwell-system-akka.actor.default-dispatcher-16 ERROR - CallActor [UUID(9a7a405c):PreBqsrCheckContamination]: Failing call: Error reading gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/9a7a405c-6b14-48cc-87e... at position 0; cromwell.util.AggregatedException: Error reading gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/9a7a405c-6b14-48cc-87e... at position 0;   at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:118) ~[cromwell.jar:0.19];   at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:130) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:625) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:664) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:659) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:23) ~[cromwell.jar:0.19];   at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell.jar:0.19];   at akka.dispatch.ForkJoinExecut",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/928
https://github.com/broadinstitute/cromwell/issues/928:1365,Performance,concurren,concurrent,1365,or [UUID(9a7a405c):PreBqsrCheckContamination]: Failing call: Error reading gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/9a7a405c-6b14-48cc-87e... at position 0; cromwell.util.AggregatedException: Error reading gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/9a7a405c-6b14-48cc-87e... at position 0;   at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:118) ~[cromwell.jar:0.19];   at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:130) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:625) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:664) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:659) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:23) ~[cromwell.jar:0.19];   at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell.jar:0.19];   at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19];   at scala.concurrent.for,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/928
https://github.com/broadinstitute/cromwell/issues/928:1480,Performance,concurren,concurrent,1480,ecution/PairedEndSingleSampleWorkflow/9a7a405c-6b14-48cc-87e... at position 0; cromwell.util.AggregatedException: Error reading gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/9a7a405c-6b14-48cc-87e... at position 0;   at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:118) ~[cromwell.jar:0.19];   at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:130) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:625) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:664) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:659) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:23) ~[cromwell.jar:0.19];   at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell.jar:0.19];   at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$W,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/928
https://github.com/broadinstitute/cromwell/issues/928:2044,Performance,concurren,concurrent,2044,$.sequenceIterable(TryUtil.scala:118) ~[cromwell.jar:0.19];   at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:130) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:625) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:664) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:659) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:23) ~[cromwell.jar:0.19];   at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell.jar:0.19];   at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/928
https://github.com/broadinstitute/cromwell/issues/928:2357,Performance,concurren,concurrent,2357,$.sequenceIterable(TryUtil.scala:118) ~[cromwell.jar:0.19];   at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:130) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:625) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:664) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:659) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:23) ~[cromwell.jar:0.19];   at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell.jar:0.19];   at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/928
https://github.com/broadinstitute/cromwell/issues/928:2452,Performance,concurren,concurrent,2452,$.sequenceIterable(TryUtil.scala:118) ~[cromwell.jar:0.19];   at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:130) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:625) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:664) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:659) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:23) ~[cromwell.jar:0.19];   at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell.jar:0.19];   at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/928
https://github.com/broadinstitute/cromwell/issues/928:2559,Performance,concurren,concurrent,2559,$.sequenceIterable(TryUtil.scala:118) ~[cromwell.jar:0.19];   at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:130) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:625) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:664) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:659) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:23) ~[cromwell.jar:0.19];   at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell.jar:0.19];   at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/928
https://github.com/broadinstitute/cromwell/issues/928:2658,Performance,concurren,concurrent,2658,$.sequenceIterable(TryUtil.scala:118) ~[cromwell.jar:0.19];   at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:130) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:625) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:664) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:659) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:23) ~[cromwell.jar:0.19];   at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40) ~[cromwell.jar:0.19];   at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/928
https://github.com/broadinstitute/cromwell/issues/928:213,Testability,log,log,213,"The file it was trying to read is gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/9a7a405c-6b14-48cc-87e8-84ee4e7ef074/call-PreBqsrCheckContamination/PreBqsrCheckContamination-stdout.log. The task uses `read_float (stdout)` in its output block. . ```; 2016-06-01 09:47:17,888 cromwell-system-akka.actor.default-dispatcher-16 ERROR - CallActor [UUID(9a7a405c):PreBqsrCheckContamination]: Failing call: Error reading gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/9a7a405c-6b14-48cc-87e... at position 0; cromwell.util.AggregatedException: Error reading gs://broad-gotc-prod-storage/cromwell_execution/PairedEndSingleSampleWorkflow/9a7a405c-6b14-48cc-87e... at position 0;   at cromwell.util.TryUtil$.sequenceIterable(TryUtil.scala:118) ~[cromwell.jar:0.19];   at cromwell.util.TryUtil$.sequenceMap(TryUtil.scala:130) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend.postProcess(JesBackend.scala:625) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:664) ~[cromwell.jar:0.19];   at cromwell.engine.backend.jes.JesBackend$$anonfun$executionResult$1.apply(JesBackend.scala:659) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable.run_aroundBody0(Future.scala:24) ~[cromwell.jar:0.19];   at scala.concurrent.impl.Future$PromiseCompletingRunnable$AjcClosure1.run(Future.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/928
https://github.com/broadinstitute/cromwell/issues/930:645,Availability,down,downstream,645,"During the testing hackathon, we discovered a number of problems caused by the eventual consistency of the metadata service. One specific case of this is the granularity of the events. . On one side, we have a publisher who has a whole collection of events that they would like to push. They push them one event at a time to the MD service. Because even things like array elements are pushed one update at a time because of MD format, we run into the situation where a consumer can see half of an array. Taken to the extreme, we could push every char of a string as a separate event. The fundamental problem with these partial updates is that a downstream consumer can not tell if an update is complete. Do they wait? How long? Can they check if the data is done?. While this touches on a larger problem in distributed computing, I think we are shooting ourselves in the foot by making every piece of a single update an async, isolated event. Taken to the extreme, we could push every char of a string as a separate event. The proposal is to extend the PutMetadataAction to take in a Seq/Varargs of MetadataEvents with the contract that these will be made available atomically (e.g. in a single Slick transaction for our implementation). Then in places where we basically unrolling a bundle of events to publish, we should use this API (e.g. WorkflowExecutionActor) to do that atomically. . In theory, this should also help with the scalability as the MD service can persist things with batchinserts in single transaction. For larger workflows, currently this would be hundreds or thousands of transactions.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/930
https://github.com/broadinstitute/cromwell/issues/930:1156,Availability,avail,available,1156,"During the testing hackathon, we discovered a number of problems caused by the eventual consistency of the metadata service. One specific case of this is the granularity of the events. . On one side, we have a publisher who has a whole collection of events that they would like to push. They push them one event at a time to the MD service. Because even things like array elements are pushed one update at a time because of MD format, we run into the situation where a consumer can see half of an array. Taken to the extreme, we could push every char of a string as a separate event. The fundamental problem with these partial updates is that a downstream consumer can not tell if an update is complete. Do they wait? How long? Can they check if the data is done?. While this touches on a larger problem in distributed computing, I think we are shooting ourselves in the foot by making every piece of a single update an async, isolated event. Taken to the extreme, we could push every char of a string as a separate event. The proposal is to extend the PutMetadataAction to take in a Seq/Varargs of MetadataEvents with the contract that these will be made available atomically (e.g. in a single Slick transaction for our implementation). Then in places where we basically unrolling a bundle of events to publish, we should use this API (e.g. WorkflowExecutionActor) to do that atomically. . In theory, this should also help with the scalability as the MD service can persist things with batchinserts in single transaction. For larger workflows, currently this would be hundreds or thousands of transactions.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/930
https://github.com/broadinstitute/cromwell/issues/930:396,Deployability,update,update,396,"During the testing hackathon, we discovered a number of problems caused by the eventual consistency of the metadata service. One specific case of this is the granularity of the events. . On one side, we have a publisher who has a whole collection of events that they would like to push. They push them one event at a time to the MD service. Because even things like array elements are pushed one update at a time because of MD format, we run into the situation where a consumer can see half of an array. Taken to the extreme, we could push every char of a string as a separate event. The fundamental problem with these partial updates is that a downstream consumer can not tell if an update is complete. Do they wait? How long? Can they check if the data is done?. While this touches on a larger problem in distributed computing, I think we are shooting ourselves in the foot by making every piece of a single update an async, isolated event. Taken to the extreme, we could push every char of a string as a separate event. The proposal is to extend the PutMetadataAction to take in a Seq/Varargs of MetadataEvents with the contract that these will be made available atomically (e.g. in a single Slick transaction for our implementation). Then in places where we basically unrolling a bundle of events to publish, we should use this API (e.g. WorkflowExecutionActor) to do that atomically. . In theory, this should also help with the scalability as the MD service can persist things with batchinserts in single transaction. For larger workflows, currently this would be hundreds or thousands of transactions.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/930
https://github.com/broadinstitute/cromwell/issues/930:627,Deployability,update,updates,627,"During the testing hackathon, we discovered a number of problems caused by the eventual consistency of the metadata service. One specific case of this is the granularity of the events. . On one side, we have a publisher who has a whole collection of events that they would like to push. They push them one event at a time to the MD service. Because even things like array elements are pushed one update at a time because of MD format, we run into the situation where a consumer can see half of an array. Taken to the extreme, we could push every char of a string as a separate event. The fundamental problem with these partial updates is that a downstream consumer can not tell if an update is complete. Do they wait? How long? Can they check if the data is done?. While this touches on a larger problem in distributed computing, I think we are shooting ourselves in the foot by making every piece of a single update an async, isolated event. Taken to the extreme, we could push every char of a string as a separate event. The proposal is to extend the PutMetadataAction to take in a Seq/Varargs of MetadataEvents with the contract that these will be made available atomically (e.g. in a single Slick transaction for our implementation). Then in places where we basically unrolling a bundle of events to publish, we should use this API (e.g. WorkflowExecutionActor) to do that atomically. . In theory, this should also help with the scalability as the MD service can persist things with batchinserts in single transaction. For larger workflows, currently this would be hundreds or thousands of transactions.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/930
https://github.com/broadinstitute/cromwell/issues/930:684,Deployability,update,update,684,"During the testing hackathon, we discovered a number of problems caused by the eventual consistency of the metadata service. One specific case of this is the granularity of the events. . On one side, we have a publisher who has a whole collection of events that they would like to push. They push them one event at a time to the MD service. Because even things like array elements are pushed one update at a time because of MD format, we run into the situation where a consumer can see half of an array. Taken to the extreme, we could push every char of a string as a separate event. The fundamental problem with these partial updates is that a downstream consumer can not tell if an update is complete. Do they wait? How long? Can they check if the data is done?. While this touches on a larger problem in distributed computing, I think we are shooting ourselves in the foot by making every piece of a single update an async, isolated event. Taken to the extreme, we could push every char of a string as a separate event. The proposal is to extend the PutMetadataAction to take in a Seq/Varargs of MetadataEvents with the contract that these will be made available atomically (e.g. in a single Slick transaction for our implementation). Then in places where we basically unrolling a bundle of events to publish, we should use this API (e.g. WorkflowExecutionActor) to do that atomically. . In theory, this should also help with the scalability as the MD service can persist things with batchinserts in single transaction. For larger workflows, currently this would be hundreds or thousands of transactions.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/930
https://github.com/broadinstitute/cromwell/issues/930:910,Deployability,update,update,910,"During the testing hackathon, we discovered a number of problems caused by the eventual consistency of the metadata service. One specific case of this is the granularity of the events. . On one side, we have a publisher who has a whole collection of events that they would like to push. They push them one event at a time to the MD service. Because even things like array elements are pushed one update at a time because of MD format, we run into the situation where a consumer can see half of an array. Taken to the extreme, we could push every char of a string as a separate event. The fundamental problem with these partial updates is that a downstream consumer can not tell if an update is complete. Do they wait? How long? Can they check if the data is done?. While this touches on a larger problem in distributed computing, I think we are shooting ourselves in the foot by making every piece of a single update an async, isolated event. Taken to the extreme, we could push every char of a string as a separate event. The proposal is to extend the PutMetadataAction to take in a Seq/Varargs of MetadataEvents with the contract that these will be made available atomically (e.g. in a single Slick transaction for our implementation). Then in places where we basically unrolling a bundle of events to publish, we should use this API (e.g. WorkflowExecutionActor) to do that atomically. . In theory, this should also help with the scalability as the MD service can persist things with batchinserts in single transaction. For larger workflows, currently this would be hundreds or thousands of transactions.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/930
https://github.com/broadinstitute/cromwell/issues/930:1123,Integrability,contract,contract,1123,"During the testing hackathon, we discovered a number of problems caused by the eventual consistency of the metadata service. One specific case of this is the granularity of the events. . On one side, we have a publisher who has a whole collection of events that they would like to push. They push them one event at a time to the MD service. Because even things like array elements are pushed one update at a time because of MD format, we run into the situation where a consumer can see half of an array. Taken to the extreme, we could push every char of a string as a separate event. The fundamental problem with these partial updates is that a downstream consumer can not tell if an update is complete. Do they wait? How long? Can they check if the data is done?. While this touches on a larger problem in distributed computing, I think we are shooting ourselves in the foot by making every piece of a single update an async, isolated event. Taken to the extreme, we could push every char of a string as a separate event. The proposal is to extend the PutMetadataAction to take in a Seq/Varargs of MetadataEvents with the contract that these will be made available atomically (e.g. in a single Slick transaction for our implementation). Then in places where we basically unrolling a bundle of events to publish, we should use this API (e.g. WorkflowExecutionActor) to do that atomically. . In theory, this should also help with the scalability as the MD service can persist things with batchinserts in single transaction. For larger workflows, currently this would be hundreds or thousands of transactions.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/930
https://github.com/broadinstitute/cromwell/issues/930:1042,Modifiability,extend,extend,1042,"During the testing hackathon, we discovered a number of problems caused by the eventual consistency of the metadata service. One specific case of this is the granularity of the events. . On one side, we have a publisher who has a whole collection of events that they would like to push. They push them one event at a time to the MD service. Because even things like array elements are pushed one update at a time because of MD format, we run into the situation where a consumer can see half of an array. Taken to the extreme, we could push every char of a string as a separate event. The fundamental problem with these partial updates is that a downstream consumer can not tell if an update is complete. Do they wait? How long? Can they check if the data is done?. While this touches on a larger problem in distributed computing, I think we are shooting ourselves in the foot by making every piece of a single update an async, isolated event. Taken to the extreme, we could push every char of a string as a separate event. The proposal is to extend the PutMetadataAction to take in a Seq/Varargs of MetadataEvents with the contract that these will be made available atomically (e.g. in a single Slick transaction for our implementation). Then in places where we basically unrolling a bundle of events to publish, we should use this API (e.g. WorkflowExecutionActor) to do that atomically. . In theory, this should also help with the scalability as the MD service can persist things with batchinserts in single transaction. For larger workflows, currently this would be hundreds or thousands of transactions.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/930
https://github.com/broadinstitute/cromwell/issues/930:1433,Performance,scalab,scalability,1433,"During the testing hackathon, we discovered a number of problems caused by the eventual consistency of the metadata service. One specific case of this is the granularity of the events. . On one side, we have a publisher who has a whole collection of events that they would like to push. They push them one event at a time to the MD service. Because even things like array elements are pushed one update at a time because of MD format, we run into the situation where a consumer can see half of an array. Taken to the extreme, we could push every char of a string as a separate event. The fundamental problem with these partial updates is that a downstream consumer can not tell if an update is complete. Do they wait? How long? Can they check if the data is done?. While this touches on a larger problem in distributed computing, I think we are shooting ourselves in the foot by making every piece of a single update an async, isolated event. Taken to the extreme, we could push every char of a string as a separate event. The proposal is to extend the PutMetadataAction to take in a Seq/Varargs of MetadataEvents with the contract that these will be made available atomically (e.g. in a single Slick transaction for our implementation). Then in places where we basically unrolling a bundle of events to publish, we should use this API (e.g. WorkflowExecutionActor) to do that atomically. . In theory, this should also help with the scalability as the MD service can persist things with batchinserts in single transaction. For larger workflows, currently this would be hundreds or thousands of transactions.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/930
https://github.com/broadinstitute/cromwell/issues/930:11,Testability,test,testing,11,"During the testing hackathon, we discovered a number of problems caused by the eventual consistency of the metadata service. One specific case of this is the granularity of the events. . On one side, we have a publisher who has a whole collection of events that they would like to push. They push them one event at a time to the MD service. Because even things like array elements are pushed one update at a time because of MD format, we run into the situation where a consumer can see half of an array. Taken to the extreme, we could push every char of a string as a separate event. The fundamental problem with these partial updates is that a downstream consumer can not tell if an update is complete. Do they wait? How long? Can they check if the data is done?. While this touches on a larger problem in distributed computing, I think we are shooting ourselves in the foot by making every piece of a single update an async, isolated event. Taken to the extreme, we could push every char of a string as a separate event. The proposal is to extend the PutMetadataAction to take in a Seq/Varargs of MetadataEvents with the contract that these will be made available atomically (e.g. in a single Slick transaction for our implementation). Then in places where we basically unrolling a bundle of events to publish, we should use this API (e.g. WorkflowExecutionActor) to do that atomically. . In theory, this should also help with the scalability as the MD service can persist things with batchinserts in single transaction. For larger workflows, currently this would be hundreds or thousands of transactions.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/930
https://github.com/broadinstitute/cromwell/issues/932:1668,Availability,Failure,Failure,1668,"ows(final_matrix); CODE; >>>. runtime {; docker: ""python:2.7""; memory: ""1 GB""; }. output {; File output_tsv = ""output.tsv""; Array[Array[String]] output_matrix = read_tsv(""output.tsv""); }; }; ```. It seems that if you give it an `input_matrix` that is greater than 85 MB worth of data, you get the stack trace below. I reached this size of data with an inputs Array of Arrays that had dimensions 500x901 where each element was a gcs path like ""gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/cab6dea2-8a01-4130-8973-96023637de29/call-SplitGvcf/shard-100/split_gvcfs/11C118416.7ca5a79a-1369-4dc1-8f41-4180d7b3c1ab.0000.g.vcf.gz.tbi"". Whoever picks up this ticket can talk to me about specifics and why we think its an 85MB issue. ```; 2016-06-02 00:18:27,540 cromwell-system-akka.actor.default-dispatcher-341 INFO - WorkflowActor [UUID(fa18fa5f)]: persisting status of RotateGVCFIndex to Running.; 2016-06-01T20:19:00.527-0400: 104257.028: [GC (Allocation Failure) [PSYoungGen: 1821155K->270322K(1864192K)] 4006446K->2894561K(7456768K), 0.1718483 secs] [Times: user=1.22 sys=0.01, real=0.17 secs] ; 2016-06-02 00:19:39,491 ForkJoinPool-3-worker-7 ERROR - Exception not convertible into handled response; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method) ~[na:1.8.0_72]; at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[na:1.8.0_72]; at java.net.SocketInputStream.read(SocketInputStream.java:170) ~[na:1.8.0_72]; at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72]; at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72]; at java.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932
https://github.com/broadinstitute/cromwell/issues/932:1859,Availability,ERROR,ERROR,1859,"read_tsv(""output.tsv""); }; }; ```. It seems that if you give it an `input_matrix` that is greater than 85 MB worth of data, you get the stack trace below. I reached this size of data with an inputs Array of Arrays that had dimensions 500x901 where each element was a gcs path like ""gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/cab6dea2-8a01-4130-8973-96023637de29/call-SplitGvcf/shard-100/split_gvcfs/11C118416.7ca5a79a-1369-4dc1-8f41-4180d7b3c1ab.0000.g.vcf.gz.tbi"". Whoever picks up this ticket can talk to me about specifics and why we think its an 85MB issue. ```; 2016-06-02 00:18:27,540 cromwell-system-akka.actor.default-dispatcher-341 INFO - WorkflowActor [UUID(fa18fa5f)]: persisting status of RotateGVCFIndex to Running.; 2016-06-01T20:19:00.527-0400: 104257.028: [GC (Allocation Failure) [PSYoungGen: 1821155K->270322K(1864192K)] 4006446K->2894561K(7456768K), 0.1718483 secs] [Times: user=1.22 sys=0.01, real=0.17 secs] ; 2016-06-02 00:19:39,491 ForkJoinPool-3-worker-7 ERROR - Exception not convertible into handled response; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method) ~[na:1.8.0_72]; at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[na:1.8.0_72]; at java.net.SocketInputStream.read(SocketInputStream.java:170) ~[na:1.8.0_72]; at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72]; at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72]; at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72]; at ja",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932
https://github.com/broadinstitute/cromwell/issues/932:5596,Availability,Failure,Failure,5596,"mwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19]; at com.google.cloud.hadoop.util.AbstractGoogleAsyncWriteChannel$UploadOperation.call(AbstractGoogleAsyncWriteChannel.java:357) ~[cromwell.jar:0.19]; at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_72]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-06-01T20:19:40.362-0400: 104296.863: [GC (Allocation Failure) [PSYoungGen: 1130870K->235812K(1864192K)] 3755109K->2861554K(7456768K), 0.0464226 secs] [Times: user=0.25 sys=0.00, real=0.04 secs] ; 2016-06-01T20:19:42.554-0400: 104299.055: [GC (Allocation Failure) [PSYoungGen: 1052454K->177588K(1864192K)] 3678197K->2815074K(7456768K), 0.0805924 secs] [Times: user=0.59 sys=0.00, real=0.08 secs] ; 2016-06-01T20:20:06.449-0400: 104322.950: [GC (Allocation Failure) [PSYoungGen: 1109940K->381765K(1864192K)] 3747426K->3196632K(7456768K), 0.1380993 secs] [Times: user=1.00 sys=0.01, real=0.14 secs] ; 2016-06-01T20:20:06.832-0400: 104323.333: [GC (Allocation Failure) [PSYoungGen: 1157703K->173892K(1864192K)] 3972570K->3267545K(7456768K), 0.0688009 secs] [Times: user=0.50 sys=0.00, real=0.07 secs] ; 2016-06-02 00:20:07,325 cromwell-system-akka.actor.default-dispatcher-332 INFO - JesBackend [UUID(fa18fa5f):RotateGVCF]: `python <<CODE; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932
https://github.com/broadinstitute/cromwell/issues/932:5797,Availability,Failure,Failure,5797,"mwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19]; at com.google.cloud.hadoop.util.AbstractGoogleAsyncWriteChannel$UploadOperation.call(AbstractGoogleAsyncWriteChannel.java:357) ~[cromwell.jar:0.19]; at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_72]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-06-01T20:19:40.362-0400: 104296.863: [GC (Allocation Failure) [PSYoungGen: 1130870K->235812K(1864192K)] 3755109K->2861554K(7456768K), 0.0464226 secs] [Times: user=0.25 sys=0.00, real=0.04 secs] ; 2016-06-01T20:19:42.554-0400: 104299.055: [GC (Allocation Failure) [PSYoungGen: 1052454K->177588K(1864192K)] 3678197K->2815074K(7456768K), 0.0805924 secs] [Times: user=0.59 sys=0.00, real=0.08 secs] ; 2016-06-01T20:20:06.449-0400: 104322.950: [GC (Allocation Failure) [PSYoungGen: 1109940K->381765K(1864192K)] 3747426K->3196632K(7456768K), 0.1380993 secs] [Times: user=1.00 sys=0.01, real=0.14 secs] ; 2016-06-01T20:20:06.832-0400: 104323.333: [GC (Allocation Failure) [PSYoungGen: 1157703K->173892K(1864192K)] 3972570K->3267545K(7456768K), 0.0688009 secs] [Times: user=0.50 sys=0.00, real=0.07 secs] ; 2016-06-02 00:20:07,325 cromwell-system-akka.actor.default-dispatcher-332 INFO - JesBackend [UUID(fa18fa5f):RotateGVCF]: `python <<CODE; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932
https://github.com/broadinstitute/cromwell/issues/932:5998,Availability,Failure,Failure,5998,"mwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19]; at com.google.cloud.hadoop.util.AbstractGoogleAsyncWriteChannel$UploadOperation.call(AbstractGoogleAsyncWriteChannel.java:357) ~[cromwell.jar:0.19]; at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_72]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-06-01T20:19:40.362-0400: 104296.863: [GC (Allocation Failure) [PSYoungGen: 1130870K->235812K(1864192K)] 3755109K->2861554K(7456768K), 0.0464226 secs] [Times: user=0.25 sys=0.00, real=0.04 secs] ; 2016-06-01T20:19:42.554-0400: 104299.055: [GC (Allocation Failure) [PSYoungGen: 1052454K->177588K(1864192K)] 3678197K->2815074K(7456768K), 0.0805924 secs] [Times: user=0.59 sys=0.00, real=0.08 secs] ; 2016-06-01T20:20:06.449-0400: 104322.950: [GC (Allocation Failure) [PSYoungGen: 1109940K->381765K(1864192K)] 3747426K->3196632K(7456768K), 0.1380993 secs] [Times: user=1.00 sys=0.01, real=0.14 secs] ; 2016-06-01T20:20:06.832-0400: 104323.333: [GC (Allocation Failure) [PSYoungGen: 1157703K->173892K(1864192K)] 3972570K->3267545K(7456768K), 0.0688009 secs] [Times: user=0.50 sys=0.00, real=0.07 secs] ; 2016-06-02 00:20:07,325 cromwell-system-akka.actor.default-dispatcher-332 INFO - JesBackend [UUID(fa18fa5f):RotateGVCF]: `python <<CODE; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932
https://github.com/broadinstitute/cromwell/issues/932:6199,Availability,Failure,Failure,6199,"mwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19]; at com.google.cloud.hadoop.util.AbstractGoogleAsyncWriteChannel$UploadOperation.call(AbstractGoogleAsyncWriteChannel.java:357) ~[cromwell.jar:0.19]; at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_72]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-06-01T20:19:40.362-0400: 104296.863: [GC (Allocation Failure) [PSYoungGen: 1130870K->235812K(1864192K)] 3755109K->2861554K(7456768K), 0.0464226 secs] [Times: user=0.25 sys=0.00, real=0.04 secs] ; 2016-06-01T20:19:42.554-0400: 104299.055: [GC (Allocation Failure) [PSYoungGen: 1052454K->177588K(1864192K)] 3678197K->2815074K(7456768K), 0.0805924 secs] [Times: user=0.59 sys=0.00, real=0.08 secs] ; 2016-06-01T20:20:06.449-0400: 104322.950: [GC (Allocation Failure) [PSYoungGen: 1109940K->381765K(1864192K)] 3747426K->3196632K(7456768K), 0.1380993 secs] [Times: user=1.00 sys=0.01, real=0.14 secs] ; 2016-06-01T20:20:06.832-0400: 104323.333: [GC (Allocation Failure) [PSYoungGen: 1157703K->173892K(1864192K)] 3972570K->3267545K(7456768K), 0.0688009 secs] [Times: user=0.50 sys=0.00, real=0.07 secs] ; 2016-06-02 00:20:07,325 cromwell-system-akka.actor.default-dispatcher-332 INFO - JesBackend [UUID(fa18fa5f):RotateGVCF]: `python <<CODE; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932
https://github.com/broadinstitute/cromwell/issues/932:5059,Energy Efficiency,Adapt,AdaptedForkJoinTask,5059,"ediaHttpUploader.java:562) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.media.MediaHttpUploader.resumableUpload(MediaHttpUploader.java:419) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.media.MediaHttpUploader.upload(MediaHttpUploader.java:336) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:427) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19]; at com.google.cloud.hadoop.util.AbstractGoogleAsyncWriteChannel$UploadOperation.call(AbstractGoogleAsyncWriteChannel.java:357) ~[cromwell.jar:0.19]; at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_72]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-06-01T20:19:40.362-0400: 104296.863: [GC (Allocation Failure) [PSYoungGen: 1130870K->235812K(1864192K)] 3755109K->2861554K(7456768K), 0.0464226 secs] [Times: user=0.25 sys=0.00, real=0.04 secs] ; 2016-06-01T20:19:42.554-0400: 104299.055: [GC (Allocation Failure) [PSYoungGen: 1052454K->177588K(1864192K)] 3678197K->2815074K(7456768K), 0.0805924 secs] [Times: user=0.59 sys=0.00, real=0.08 secs] ; 2016-06-01T20:20:06.449-0400: 104322.950: [GC (Allocation Failure) [PSYoungGen: 1109940K->381765K(1864192K)] 3747426K->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932
https://github.com/broadinstitute/cromwell/issues/932:3115,Integrability,protocol,protocol,3115,2]; at java.net.SocketInputStream.read(SocketInputStream.java:170) ~[na:1.8.0_72]; at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72]; at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72]; at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72]; at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72]; at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72]; at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72]; at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72]; at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72]; at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_72]; at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37) ~[cromwell.jar:0.19]; at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94) ~[cromwell.jar:0.19]; at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.media.MediaHttpUploader.executeCurrentRequestWithoutGZip(MediaHttpUploader.java:545) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.media.MediaHttpUploader.executeCurrentRequest(MediaHttpUploader.java:562) ~[cromwell.jar:0.19]; at com.google,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932
https://github.com/broadinstitute/cromwell/issues/932:3223,Integrability,protocol,protocol,3223,ream.read(SocketInputStream.java:141) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72]; at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72]; at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72]; at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72]; at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72]; at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72]; at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72]; at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72]; at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_72]; at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37) ~[cromwell.jar:0.19]; at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94) ~[cromwell.jar:0.19]; at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.media.MediaHttpUploader.executeCurrentRequestWithoutGZip(MediaHttpUploader.java:545) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.media.MediaHttpUploader.executeCurrentRequest(MediaHttpUploader.java:562) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.media.MediaHttpUploader.resumableUpload(MediaHttpUploader.java:419) ~[cromwell.jar:0.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932
https://github.com/broadinstitute/cromwell/issues/932:3420,Integrability,protocol,protocol,3420,:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72]; at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72]; at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72]; at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72]; at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72]; at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72]; at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72]; at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72]; at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_72]; at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37) ~[cromwell.jar:0.19]; at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94) ~[cromwell.jar:0.19]; at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.media.MediaHttpUploader.executeCurrentRequestWithoutGZip(MediaHttpUploader.java:545) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.media.MediaHttpUploader.executeCurrentRequest(MediaHttpUploader.java:562) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.media.MediaHttpUploader.resumableUpload(MediaHttpUploader.java:419) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.media.MediaHttpUploader.upload(MediaHttpUploader.java:336) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.ex,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932
https://github.com/broadinstitute/cromwell/issues/932:5059,Modifiability,Adapt,AdaptedForkJoinTask,5059,"ediaHttpUploader.java:562) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.media.MediaHttpUploader.resumableUpload(MediaHttpUploader.java:419) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.media.MediaHttpUploader.upload(MediaHttpUploader.java:336) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:427) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19]; at com.google.cloud.hadoop.util.AbstractGoogleAsyncWriteChannel$UploadOperation.call(AbstractGoogleAsyncWriteChannel.java:357) ~[cromwell.jar:0.19]; at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_72]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-06-01T20:19:40.362-0400: 104296.863: [GC (Allocation Failure) [PSYoungGen: 1130870K->235812K(1864192K)] 3755109K->2861554K(7456768K), 0.0464226 secs] [Times: user=0.25 sys=0.00, real=0.04 secs] ; 2016-06-01T20:19:42.554-0400: 104299.055: [GC (Allocation Failure) [PSYoungGen: 1052454K->177588K(1864192K)] 3678197K->2815074K(7456768K), 0.0805924 secs] [Times: user=0.59 sys=0.00, real=0.08 secs] ; 2016-06-01T20:20:06.449-0400: 104322.950: [GC (Allocation Failure) [PSYoungGen: 1109940K->381765K(1864192K)] 3747426K->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932
https://github.com/broadinstitute/cromwell/issues/932:4951,Performance,concurren,concurrent,4951,"romwell.jar:0.19]; at com.google.api.client.googleapis.media.MediaHttpUploader.executeCurrentRequest(MediaHttpUploader.java:562) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.media.MediaHttpUploader.resumableUpload(MediaHttpUploader.java:419) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.media.MediaHttpUploader.upload(MediaHttpUploader.java:336) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:427) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19]; at com.google.cloud.hadoop.util.AbstractGoogleAsyncWriteChannel$UploadOperation.call(AbstractGoogleAsyncWriteChannel.java:357) ~[cromwell.jar:0.19]; at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_72]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-06-01T20:19:40.362-0400: 104296.863: [GC (Allocation Failure) [PSYoungGen: 1130870K->235812K(1864192K)] 3755109K->2861554K(7456768K), 0.0464226 secs] [Times: user=0.25 sys=0.00, real=0.04 secs] ; 2016-06-01T20:19:42.554-0400: 104299.055: [GC (Allocation Failure) [PSYoungGen: 1052454K->177588K(1864192K)] 3678197K->2815074K(7456768K), 0.0805924 secs] [Times: user=0.59 sys=0.00, real=0.08 secs] ; 2016-06-01T20:20:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932
https://github.com/broadinstitute/cromwell/issues/932:5022,Performance,concurren,concurrent,5022,"ploader.executeCurrentRequest(MediaHttpUploader.java:562) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.media.MediaHttpUploader.resumableUpload(MediaHttpUploader.java:419) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.media.MediaHttpUploader.upload(MediaHttpUploader.java:336) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:427) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19]; at com.google.cloud.hadoop.util.AbstractGoogleAsyncWriteChannel$UploadOperation.call(AbstractGoogleAsyncWriteChannel.java:357) ~[cromwell.jar:0.19]; at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_72]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-06-01T20:19:40.362-0400: 104296.863: [GC (Allocation Failure) [PSYoungGen: 1130870K->235812K(1864192K)] 3755109K->2861554K(7456768K), 0.0464226 secs] [Times: user=0.25 sys=0.00, real=0.04 secs] ; 2016-06-01T20:19:42.554-0400: 104299.055: [GC (Allocation Failure) [PSYoungGen: 1052454K->177588K(1864192K)] 3678197K->2815074K(7456768K), 0.0805924 secs] [Times: user=0.59 sys=0.00, real=0.08 secs] ; 2016-06-01T20:20:06.449-0400: 104322.950: [GC (Allocation Failure) [PSYoungGen: 1109940K",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932
https://github.com/broadinstitute/cromwell/issues/932:5146,Performance,concurren,concurrent,5146,"diaHttpUploader.resumableUpload(MediaHttpUploader.java:419) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.media.MediaHttpUploader.upload(MediaHttpUploader.java:336) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:427) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19]; at com.google.cloud.hadoop.util.AbstractGoogleAsyncWriteChannel$UploadOperation.call(AbstractGoogleAsyncWriteChannel.java:357) ~[cromwell.jar:0.19]; at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_72]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-06-01T20:19:40.362-0400: 104296.863: [GC (Allocation Failure) [PSYoungGen: 1130870K->235812K(1864192K)] 3755109K->2861554K(7456768K), 0.0464226 secs] [Times: user=0.25 sys=0.00, real=0.04 secs] ; 2016-06-01T20:19:42.554-0400: 104299.055: [GC (Allocation Failure) [PSYoungGen: 1052454K->177588K(1864192K)] 3678197K->2815074K(7456768K), 0.0805924 secs] [Times: user=0.59 sys=0.00, real=0.08 secs] ; 2016-06-01T20:20:06.449-0400: 104322.950: [GC (Allocation Failure) [PSYoungGen: 1109940K->381765K(1864192K)] 3747426K->3196632K(7456768K), 0.1380993 secs] [Times: user=1.00 sys=0.01, real=0.14 secs] ; 2016-06-01T",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932
https://github.com/broadinstitute/cromwell/issues/932:5239,Performance,concurren,concurrent,5239,"le.api.client.googleapis.media.MediaHttpUploader.upload(MediaHttpUploader.java:336) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:427) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19]; at com.google.cloud.hadoop.util.AbstractGoogleAsyncWriteChannel$UploadOperation.call(AbstractGoogleAsyncWriteChannel.java:357) ~[cromwell.jar:0.19]; at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_72]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-06-01T20:19:40.362-0400: 104296.863: [GC (Allocation Failure) [PSYoungGen: 1130870K->235812K(1864192K)] 3755109K->2861554K(7456768K), 0.0464226 secs] [Times: user=0.25 sys=0.00, real=0.04 secs] ; 2016-06-01T20:19:42.554-0400: 104299.055: [GC (Allocation Failure) [PSYoungGen: 1052454K->177588K(1864192K)] 3678197K->2815074K(7456768K), 0.0805924 secs] [Times: user=0.59 sys=0.00, real=0.08 secs] ; 2016-06-01T20:20:06.449-0400: 104322.950: [GC (Allocation Failure) [PSYoungGen: 1109940K->381765K(1864192K)] 3747426K->3196632K(7456768K), 0.1380993 secs] [Times: user=1.00 sys=0.01, real=0.14 secs] ; 2016-06-01T20:20:06.832-0400: 104323.333: [GC (Allocation Failure) [PSYoungGen: 1157703K->173892K(186419",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932
https://github.com/broadinstitute/cromwell/issues/932:5344,Performance,concurren,concurrent,5344," at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:427) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19]; at com.google.cloud.hadoop.util.AbstractGoogleAsyncWriteChannel$UploadOperation.call(AbstractGoogleAsyncWriteChannel.java:357) ~[cromwell.jar:0.19]; at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_72]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-06-01T20:19:40.362-0400: 104296.863: [GC (Allocation Failure) [PSYoungGen: 1130870K->235812K(1864192K)] 3755109K->2861554K(7456768K), 0.0464226 secs] [Times: user=0.25 sys=0.00, real=0.04 secs] ; 2016-06-01T20:19:42.554-0400: 104299.055: [GC (Allocation Failure) [PSYoungGen: 1052454K->177588K(1864192K)] 3678197K->2815074K(7456768K), 0.0805924 secs] [Times: user=0.59 sys=0.00, real=0.08 secs] ; 2016-06-01T20:20:06.449-0400: 104322.950: [GC (Allocation Failure) [PSYoungGen: 1109940K->381765K(1864192K)] 3747426K->3196632K(7456768K), 0.1380993 secs] [Times: user=1.00 sys=0.01, real=0.14 secs] ; 2016-06-01T20:20:06.832-0400: 104323.333: [GC (Allocation Failure) [PSYoungGen: 1157703K->173892K(1864192K)] 3972570K->3267545K(7456768K), 0.0688009 secs] [Times: user=0.50 sys=0.00, real=0.07 secs] ; 2016-06-",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932
https://github.com/broadinstitute/cromwell/issues/932:5441,Performance,concurren,concurrent,5441,"tGoogleClientRequest.java:427) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19]; at com.google.cloud.hadoop.util.AbstractGoogleAsyncWriteChannel$UploadOperation.call(AbstractGoogleAsyncWriteChannel.java:357) ~[cromwell.jar:0.19]; at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_72]; at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19]; at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-06-01T20:19:40.362-0400: 104296.863: [GC (Allocation Failure) [PSYoungGen: 1130870K->235812K(1864192K)] 3755109K->2861554K(7456768K), 0.0464226 secs] [Times: user=0.25 sys=0.00, real=0.04 secs] ; 2016-06-01T20:19:42.554-0400: 104299.055: [GC (Allocation Failure) [PSYoungGen: 1052454K->177588K(1864192K)] 3678197K->2815074K(7456768K), 0.0805924 secs] [Times: user=0.59 sys=0.00, real=0.08 secs] ; 2016-06-01T20:20:06.449-0400: 104322.950: [GC (Allocation Failure) [PSYoungGen: 1109940K->381765K(1864192K)] 3747426K->3196632K(7456768K), 0.1380993 secs] [Times: user=1.00 sys=0.01, real=0.14 secs] ; 2016-06-01T20:20:06.832-0400: 104323.333: [GC (Allocation Failure) [PSYoungGen: 1157703K->173892K(1864192K)] 3972570K->3267545K(7456768K), 0.0688009 secs] [Times: user=0.50 sys=0.00, real=0.07 secs] ; 2016-06-02 00:20:07,325 cromwell-system-akka.actor.default-dispatcher-332 INFO - JesBackend [UUID(fa18fa5",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932
https://github.com/broadinstitute/cromwell/issues/932:2288,Security,secur,security,2288,"5a79a-1369-4dc1-8f41-4180d7b3c1ab.0000.g.vcf.gz.tbi"". Whoever picks up this ticket can talk to me about specifics and why we think its an 85MB issue. ```; 2016-06-02 00:18:27,540 cromwell-system-akka.actor.default-dispatcher-341 INFO - WorkflowActor [UUID(fa18fa5f)]: persisting status of RotateGVCFIndex to Running.; 2016-06-01T20:19:00.527-0400: 104257.028: [GC (Allocation Failure) [PSYoungGen: 1821155K->270322K(1864192K)] 4006446K->2894561K(7456768K), 0.1718483 secs] [Times: user=1.22 sys=0.01, real=0.17 secs] ; 2016-06-02 00:19:39,491 ForkJoinPool-3-worker-7 ERROR - Exception not convertible into handled response; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method) ~[na:1.8.0_72]; at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[na:1.8.0_72]; at java.net.SocketInputStream.read(SocketInputStream.java:170) ~[na:1.8.0_72]; at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72]; at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72]; at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72]; at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72]; at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72]; at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72]; at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932
https://github.com/broadinstitute/cromwell/issues/932:2368,Security,secur,security,2368,"et can talk to me about specifics and why we think its an 85MB issue. ```; 2016-06-02 00:18:27,540 cromwell-system-akka.actor.default-dispatcher-341 INFO - WorkflowActor [UUID(fa18fa5f)]: persisting status of RotateGVCFIndex to Running.; 2016-06-01T20:19:00.527-0400: 104257.028: [GC (Allocation Failure) [PSYoungGen: 1821155K->270322K(1864192K)] 4006446K->2894561K(7456768K), 0.1718483 secs] [Times: user=1.22 sys=0.01, real=0.17 secs] ; 2016-06-02 00:19:39,491 ForkJoinPool-3-worker-7 ERROR - Exception not convertible into handled response; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method) ~[na:1.8.0_72]; at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[na:1.8.0_72]; at java.net.SocketInputStream.read(SocketInputStream.java:170) ~[na:1.8.0_72]; at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72]; at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72]; at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72]; at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72]; at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72]; at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72]; at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72]; at java.net.HttpURLConnection.getResponseCode(HttpURLConne",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932
https://github.com/broadinstitute/cromwell/issues/932:2443,Security,secur,security,2443,"2016-06-02 00:18:27,540 cromwell-system-akka.actor.default-dispatcher-341 INFO - WorkflowActor [UUID(fa18fa5f)]: persisting status of RotateGVCFIndex to Running.; 2016-06-01T20:19:00.527-0400: 104257.028: [GC (Allocation Failure) [PSYoungGen: 1821155K->270322K(1864192K)] 4006446K->2894561K(7456768K), 0.1718483 secs] [Times: user=1.22 sys=0.01, real=0.17 secs] ; 2016-06-02 00:19:39,491 ForkJoinPool-3-worker-7 ERROR - Exception not convertible into handled response; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method) ~[na:1.8.0_72]; at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[na:1.8.0_72]; at java.net.SocketInputStream.read(SocketInputStream.java:170) ~[na:1.8.0_72]; at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72]; at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72]; at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72]; at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72]; at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72]; at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72]; at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72]; at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72]; at sun.net.www.protocol.https.HttpsURLConne",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932
https://github.com/broadinstitute/cromwell/issues/932:2528,Security,secur,security,2528,"flowActor [UUID(fa18fa5f)]: persisting status of RotateGVCFIndex to Running.; 2016-06-01T20:19:00.527-0400: 104257.028: [GC (Allocation Failure) [PSYoungGen: 1821155K->270322K(1864192K)] 4006446K->2894561K(7456768K), 0.1718483 secs] [Times: user=1.22 sys=0.01, real=0.17 secs] ; 2016-06-02 00:19:39,491 ForkJoinPool-3-worker-7 ERROR - Exception not convertible into handled response; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method) ~[na:1.8.0_72]; at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[na:1.8.0_72]; at java.net.SocketInputStream.read(SocketInputStream.java:170) ~[na:1.8.0_72]; at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72]; at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72]; at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72]; at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72]; at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72]; at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72]; at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72]; at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72]; at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_72]; at com.goo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932
https://github.com/broadinstitute/cromwell/issues/932:2617,Security,secur,security,2617,"20:19:00.527-0400: 104257.028: [GC (Allocation Failure) [PSYoungGen: 1821155K->270322K(1864192K)] 4006446K->2894561K(7456768K), 0.1718483 secs] [Times: user=1.22 sys=0.01, real=0.17 secs] ; 2016-06-02 00:19:39,491 ForkJoinPool-3-worker-7 ERROR - Exception not convertible into handled response; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method) ~[na:1.8.0_72]; at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[na:1.8.0_72]; at java.net.SocketInputStream.read(SocketInputStream.java:170) ~[na:1.8.0_72]; at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72]; at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72]; at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72]; at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72]; at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72]; at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72]; at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72]; at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72]; at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_72]; at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37) ~[cromwell.ja",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932
https://github.com/broadinstitute/cromwell/issues/933:579,Availability,down,down,579,"```; [INFO] [06/02/2016 19:49:46.376] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a: Call-to-Backend assignments: hello.hello -> local; [INFO] [06/02/2016 19:49:46.376] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$ib] $$ib transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [INFO] [06/02/2016 19:49:46.377] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to Mater",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:959,Availability,down,down,959,"```; [INFO] [06/02/2016 19:49:46.376] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a: Call-to-Backend assignments: hello.hello -> local; [INFO] [06/02/2016 19:49:46.376] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$ib] $$ib transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [INFO] [06/02/2016 19:49:46.377] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to Mater",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:1172,Availability,down,down,1172,"al; [INFO] [06/02/2016 19:49:46.376] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$ib] $$ib transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [INFO] [06/02/2016 19:49:46.377] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:1822,Availability,down,down,1822,"INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitial",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:2640,Availability,down,down,2640,"ep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unh",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:2853,Availability,down,down,2853,"49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transitioning from In",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:3271,Availability,down,down,3271,"workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb/WorkflowInitial",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:4089,Availability,down,down,4089,"b-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb/WorkflowInitializationActor-93102a71-3bff-432b-beb6-5506dcc13159] State is now terminal. Shutting down.; [info] WorkflowActorSpec:; [info] ShadowWorkflowActor; [info] - should move from WorkflowUnstartedState to MaterializingWorkflowDescriptorState *** FAILED ***; [info] WorkflowFailedState was not equal to MaterializingWorkflowDescriptorState (WorkflowActorSpec.scala:45); [info] - should transition to InitializingWorkflowState with correct call assignments given workflow options; [info] - should transition to InitializingWorkflowState with correct call assignments given runtime-attributes; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:4302,Availability,down,down,4302,"b-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb/WorkflowInitializationActor-93102a71-3bff-432b-beb6-5506dcc13159] State is now terminal. Shutting down.; [info] WorkflowActorSpec:; [info] ShadowWorkflowActor; [info] - should move from WorkflowUnstartedState to MaterializingWorkflowDescriptorState *** FAILED ***; [info] WorkflowFailedState was not equal to MaterializingWorkflowDescriptorState (WorkflowActorSpec.scala:45); [info] - should transition to InitializingWorkflowState with correct call assignments given workflow options; [info] - should transition to InitializingWorkflowState with correct call assignments given runtime-attributes; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:1294,Integrability,message,message,1294,"transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [INFO] [06/02/2016 19:49:46.377] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:2149,Integrability,message,message,2149,"w terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:3598,Integrability,message,message,3598,"wState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb/WorkflowInitializationActor-93102a71-3bff-432b-beb6-5506dcc13159] State is now terminal. Shutting down.; [info] WorkflowActorSpec:; [info] ShadowWorkflowActor; [info] - should move from WorkflowUnstartedState to MaterializingWorkflowDescriptorState *** FAILED ***; [info] WorkflowFailedState was not equal to MaterializingWorkflowDescriptorState (WorkflowActorSpec.scala:45); [info] - should trans",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:39,Testability,test,test-system-akka,39,"```; [INFO] [06/02/2016 19:49:46.376] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a: Call-to-Backend assignments: hello.hello -> local; [INFO] [06/02/2016 19:49:46.376] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$ib] $$ib transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [INFO] [06/02/2016 19:49:46.377] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to Mater",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:92,Testability,test,test-system,92,"```; [INFO] [06/02/2016 19:49:46.376] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a: Call-to-Backend assignments: hello.hello -> local; [INFO] [06/02/2016 19:49:46.376] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$ib] $$ib transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [INFO] [06/02/2016 19:49:46.377] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to Mater",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:268,Testability,test,test-system,268,"```; [INFO] [06/02/2016 19:49:46.376] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a: Call-to-Backend assignments: hello.hello -> local; [INFO] [06/02/2016 19:49:46.376] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$ib] $$ib transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [INFO] [06/02/2016 19:49:46.377] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to Mater",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:413,Testability,test,test-system-akka,413,"```; [INFO] [06/02/2016 19:49:46.376] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a: Call-to-Backend assignments: hello.hello -> local; [INFO] [06/02/2016 19:49:46.376] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$ib] $$ib transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [INFO] [06/02/2016 19:49:46.377] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to Mater",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:466,Testability,test,test-system,466,"```; [INFO] [06/02/2016 19:49:46.376] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a: Call-to-Backend assignments: hello.hello -> local; [INFO] [06/02/2016 19:49:46.376] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$ib] $$ib transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [INFO] [06/02/2016 19:49:46.377] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to Mater",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:619,Testability,test,test-system-akka,619,"```; [INFO] [06/02/2016 19:49:46.376] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a: Call-to-Backend assignments: hello.hello -> local; [INFO] [06/02/2016 19:49:46.376] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$ib] $$ib transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [INFO] [06/02/2016 19:49:46.377] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to Mater",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:672,Testability,test,test-system,672,"```; [INFO] [06/02/2016 19:49:46.376] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a: Call-to-Backend assignments: hello.hello -> local; [INFO] [06/02/2016 19:49:46.376] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$ib] $$ib transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [INFO] [06/02/2016 19:49:46.377] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to Mater",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:803,Testability,test,test-system-akka,803,"```; [INFO] [06/02/2016 19:49:46.376] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a: Call-to-Backend assignments: hello.hello -> local; [INFO] [06/02/2016 19:49:46.376] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$ib] $$ib transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [INFO] [06/02/2016 19:49:46.377] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to Mater",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:856,Testability,test,test-system,856,"```; [INFO] [06/02/2016 19:49:46.376] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a: Call-to-Backend assignments: hello.hello -> local; [INFO] [06/02/2016 19:49:46.376] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$ib] $$ib transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [INFO] [06/02/2016 19:49:46.377] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to Mater",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:999,Testability,test,test-system-akka,999," [INFO] [06/02/2016 19:49:46.376] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a: Call-to-Backend assignments: hello.hello -> local; [INFO] [06/02/2016 19:49:46.376] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$ib] $$ib transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [INFO] [06/02/2016 19:49:46.377] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to Materiali",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:1052,Testability,test,test-system,1052,"test-system/user/$$ib/$a] $a: Call-to-Backend assignments: hello.hello -> local; [INFO] [06/02/2016 19:49:46.376] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$ib] $$ib transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [INFO] [06/02/2016 19:49:46.377] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.d",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:1213,Testability,test,test-system-akka,1213,"ad-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$ib] $$ib transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [INFO] [06/02/2016 19:49:46.377] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:1266,Testability,test,test-system,1266,"transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [INFO] [06/02/2016 19:49:46.377] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:1307,Testability,Test,TestActor,1307,"transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [INFO] [06/02/2016 19:49:46.377] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:1324,Testability,test,test-system,1324,"transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [INFO] [06/02/2016 19:49:46.377] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:1445,Testability,test,test-system-akka,1445,"cher-6] [akka://test-system/user/$$ib/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:1498,Testability,test,test-system,1498,"yToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-d",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:1661,Testability,test,test-system-akka,1661,"kka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:1714,Testability,test,test-system,1714,"INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitial",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:1923,Testability,test,test-system,1923,"down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:2068,Testability,test,test-system-akka,2068,"/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:2121,Testability,test,test-system,2121,"w terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:2162,Testability,Test,TestActor,2162,"w terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:2179,Testability,test,test-system,2179,"w terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:2300,Testability,test,test-system-akka,2300,"m TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.5",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:2353,Testability,test,test-system,2353,"dResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb t",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:2484,Testability,test,test-system-akka,2484," [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:2537,Testability,test,test-system,2537,"ep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unh",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:2680,Testability,test,test-system-akka,2680,"efault-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowA",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:2733,Testability,test,test-system,2733,"tate to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.d",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:2894,Testability,test,test-system-akka,2894,"kflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transitioning from InitializingWorkflowState to WorkflowFailedState; [",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:2947,Testability,test,test-system,2947," from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-d",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:3110,Testability,test,test-system-akka,3110,"kka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:3163,Testability,test,test-system,3163,"workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb/WorkflowInitial",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:3372,Testability,test,test-system,3372,"zingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb/WorkflowInitializationActor-93102a71-3bff-432b-beb6-5506dcc13159] State is now terminal. Shutting down.; [info] WorkflowActorSpec:; [info] ShadowWorkflowActor; [info] - should move from WorkflowUnstartedS",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:3517,Testability,test,test-system-akka,3517,"her-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb/WorkflowInitializationActor-93102a71-3bff-432b-beb6-5506dcc13159] State is now terminal. Shutting down.; [info] WorkflowActorSpec:; [info] ShadowWorkflowActor; [info] - should move from WorkflowUnstartedState to MaterializingWorkflowDescriptorState *** FAILED ***; [info] WorkflowFailedState was not equal to Materializ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:3570,Testability,test,test-system,3570,"wState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb/WorkflowInitializationActor-93102a71-3bff-432b-beb6-5506dcc13159] State is now terminal. Shutting down.; [info] WorkflowActorSpec:; [info] ShadowWorkflowActor; [info] - should move from WorkflowUnstartedState to MaterializingWorkflowDescriptorState *** FAILED ***; [info] WorkflowFailedState was not equal to MaterializingWorkflowDescriptorState (WorkflowActorSpec.scala:45); [info] - should trans",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:3611,Testability,Test,TestActor,3611,"wState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb/WorkflowInitializationActor-93102a71-3bff-432b-beb6-5506dcc13159] State is now terminal. Shutting down.; [info] WorkflowActorSpec:; [info] ShadowWorkflowActor; [info] - should move from WorkflowUnstartedState to MaterializingWorkflowDescriptorState *** FAILED ***; [info] WorkflowFailedState was not equal to MaterializingWorkflowDescriptorState (WorkflowActorSpec.scala:45); [info] - should trans",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:3628,Testability,test,test-system,3628,"wState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb/WorkflowInitializationActor-93102a71-3bff-432b-beb6-5506dcc13159] State is now terminal. Shutting down.; [info] WorkflowActorSpec:; [info] ShadowWorkflowActor; [info] - should move from WorkflowUnstartedState to MaterializingWorkflowDescriptorState *** FAILED ***; [info] WorkflowFailedState was not equal to MaterializingWorkflowDescriptorState (WorkflowActorSpec.scala:45); [info] - should trans",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:3749,Testability,test,test-system-akka,3749,"/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb/WorkflowInitializationActor-93102a71-3bff-432b-beb6-5506dcc13159] State is now terminal. Shutting down.; [info] WorkflowActorSpec:; [info] ShadowWorkflowActor; [info] - should move from WorkflowUnstartedState to MaterializingWorkflowDescriptorState *** FAILED ***; [info] WorkflowFailedState was not equal to MaterializingWorkflowDescriptorState (WorkflowActorSpec.scala:45); [info] - should transition to InitializingWorkflowState with correct call assignments given workflow options; [info] - should transition to InitializingWorkflowState with corr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:3802,Testability,test,test-system,3802,"b-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb/WorkflowInitializationActor-93102a71-3bff-432b-beb6-5506dcc13159] State is now terminal. Shutting down.; [info] WorkflowActorSpec:; [info] ShadowWorkflowActor; [info] - should move from WorkflowUnstartedState to MaterializingWorkflowDescriptorState *** FAILED ***; [info] WorkflowFailedState was not equal to MaterializingWorkflowDescriptorState (WorkflowActorSpec.scala:45); [info] - should transition to InitializingWorkflowState with correct call assignments given workflow options; [info] - should transition to InitializingWorkflowState with correct call assignments given runtime-attributes; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:3933,Testability,test,test-system-akka,3933,"b-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb/WorkflowInitializationActor-93102a71-3bff-432b-beb6-5506dcc13159] State is now terminal. Shutting down.; [info] WorkflowActorSpec:; [info] ShadowWorkflowActor; [info] - should move from WorkflowUnstartedState to MaterializingWorkflowDescriptorState *** FAILED ***; [info] WorkflowFailedState was not equal to MaterializingWorkflowDescriptorState (WorkflowActorSpec.scala:45); [info] - should transition to InitializingWorkflowState with correct call assignments given workflow options; [info] - should transition to InitializingWorkflowState with correct call assignments given runtime-attributes; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:3986,Testability,test,test-system,3986,"b-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb/WorkflowInitializationActor-93102a71-3bff-432b-beb6-5506dcc13159] State is now terminal. Shutting down.; [info] WorkflowActorSpec:; [info] ShadowWorkflowActor; [info] - should move from WorkflowUnstartedState to MaterializingWorkflowDescriptorState *** FAILED ***; [info] WorkflowFailedState was not equal to MaterializingWorkflowDescriptorState (WorkflowActorSpec.scala:45); [info] - should transition to InitializingWorkflowState with correct call assignments given workflow options; [info] - should transition to InitializingWorkflowState with correct call assignments given runtime-attributes; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:4129,Testability,test,test-system-akka,4129,"b-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb/WorkflowInitializationActor-93102a71-3bff-432b-beb6-5506dcc13159] State is now terminal. Shutting down.; [info] WorkflowActorSpec:; [info] ShadowWorkflowActor; [info] - should move from WorkflowUnstartedState to MaterializingWorkflowDescriptorState *** FAILED ***; [info] WorkflowFailedState was not equal to MaterializingWorkflowDescriptorState (WorkflowActorSpec.scala:45); [info] - should transition to InitializingWorkflowState with correct call assignments given workflow options; [info] - should transition to InitializingWorkflowState with correct call assignments given runtime-attributes; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/issues/933:4182,Testability,test,test-system,4182,"b-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb/WorkflowInitializationActor-93102a71-3bff-432b-beb6-5506dcc13159] State is now terminal. Shutting down.; [info] WorkflowActorSpec:; [info] ShadowWorkflowActor; [info] - should move from WorkflowUnstartedState to MaterializingWorkflowDescriptorState *** FAILED ***; [info] WorkflowFailedState was not equal to MaterializingWorkflowDescriptorState (WorkflowActorSpec.scala:45); [info] - should transition to InitializingWorkflowState with correct call assignments given workflow options; [info] - should transition to InitializingWorkflowState with correct call assignments given runtime-attributes; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933
https://github.com/broadinstitute/cromwell/pull/938:45,Integrability,wrap,wrapping,45,"This removes the awkward `""workflowId"": { }` wrapping around single workflow metadata responses.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/938
https://github.com/broadinstitute/cromwell/issues/940:139,Energy Efficiency,monitor,monitor,139,"@abaumann said that they're having a serious issue (due to BBQ) with workflows which have become stuck in non-terminal states. Set up some monitor which runs at a configurable period to look through all non-terminal workflows/calls and make sure that things are actually non-terminal, switching to terminal states as appropriate. This solution is viewed as a relatively painless (vs fixing it For Real) way of solving the problem, but if one sees an easier way of doing it that's even better.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/940
https://github.com/broadinstitute/cromwell/issues/940:163,Modifiability,config,configurable,163,"@abaumann said that they're having a serious issue (due to BBQ) with workflows which have become stuck in non-terminal states. Set up some monitor which runs at a configurable period to look through all non-terminal workflows/calls and make sure that things are actually non-terminal, switching to terminal states as appropriate. This solution is viewed as a relatively painless (vs fixing it For Real) way of solving the problem, but if one sees an easier way of doing it that's even better.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/940
https://github.com/broadinstitute/cromwell/pull/941:47,Deployability,patch,patches,47,"Fixes to `SlickDataAccessSpec` plus some other patches.; `SlickDataAccessSpec` should talk to the currently tested `SlickDatabase with DataAccess`, NOT the `service` layer, that in turn talks to the global singleton.; The `root` project was not aggregating `database`.; The `root` project with `Main` only actually depends on `engine` and `core` tests.; More tests fixed that were waiting for the wrong message.; Changed waiting for `start` to `Starting`.; Changed waiting for `call.name` to `call.name:NA:1`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/941
https://github.com/broadinstitute/cromwell/pull/941:315,Integrability,depend,depends,315,"Fixes to `SlickDataAccessSpec` plus some other patches.; `SlickDataAccessSpec` should talk to the currently tested `SlickDatabase with DataAccess`, NOT the `service` layer, that in turn talks to the global singleton.; The `root` project was not aggregating `database`.; The `root` project with `Main` only actually depends on `engine` and `core` tests.; More tests fixed that were waiting for the wrong message.; Changed waiting for `start` to `Starting`.; Changed waiting for `call.name` to `call.name:NA:1`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/941
https://github.com/broadinstitute/cromwell/pull/941:403,Integrability,message,message,403,"Fixes to `SlickDataAccessSpec` plus some other patches.; `SlickDataAccessSpec` should talk to the currently tested `SlickDatabase with DataAccess`, NOT the `service` layer, that in turn talks to the global singleton.; The `root` project was not aggregating `database`.; The `root` project with `Main` only actually depends on `engine` and `core` tests.; More tests fixed that were waiting for the wrong message.; Changed waiting for `start` to `Starting`.; Changed waiting for `call.name` to `call.name:NA:1`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/941
https://github.com/broadinstitute/cromwell/pull/941:108,Testability,test,tested,108,"Fixes to `SlickDataAccessSpec` plus some other patches.; `SlickDataAccessSpec` should talk to the currently tested `SlickDatabase with DataAccess`, NOT the `service` layer, that in turn talks to the global singleton.; The `root` project was not aggregating `database`.; The `root` project with `Main` only actually depends on `engine` and `core` tests.; More tests fixed that were waiting for the wrong message.; Changed waiting for `start` to `Starting`.; Changed waiting for `call.name` to `call.name:NA:1`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/941
https://github.com/broadinstitute/cromwell/pull/941:346,Testability,test,tests,346,"Fixes to `SlickDataAccessSpec` plus some other patches.; `SlickDataAccessSpec` should talk to the currently tested `SlickDatabase with DataAccess`, NOT the `service` layer, that in turn talks to the global singleton.; The `root` project was not aggregating `database`.; The `root` project with `Main` only actually depends on `engine` and `core` tests.; More tests fixed that were waiting for the wrong message.; Changed waiting for `start` to `Starting`.; Changed waiting for `call.name` to `call.name:NA:1`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/941
https://github.com/broadinstitute/cromwell/pull/941:359,Testability,test,tests,359,"Fixes to `SlickDataAccessSpec` plus some other patches.; `SlickDataAccessSpec` should talk to the currently tested `SlickDatabase with DataAccess`, NOT the `service` layer, that in turn talks to the global singleton.; The `root` project was not aggregating `database`.; The `root` project with `Main` only actually depends on `engine` and `core` tests.; More tests fixed that were waiting for the wrong message.; Changed waiting for `start` to `Starting`.; Changed waiting for `call.name` to `call.name:NA:1`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/941
https://github.com/broadinstitute/cromwell/pull/942:142,Availability,Recover,Recover,142,"This enables tests on a lot of Slick code that's not actually used yet in the New Worlde (nothing writes to the core engine tables since only Recover needs that and Recover hasn't been implemented). So these changes are valuable iff the New Worlde ultimately uses an engine Slick API that looks a lot like that in the Olde Worlde. My guess is that will end up being true, but at this point that's only a guess. Some things here will certainly be nixed (ExecutionEvents) or are likely to be heavily modified (anything caching-related).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/942
https://github.com/broadinstitute/cromwell/pull/942:165,Availability,Recover,Recover,165,"This enables tests on a lot of Slick code that's not actually used yet in the New Worlde (nothing writes to the core engine tables since only Recover needs that and Recover hasn't been implemented). So these changes are valuable iff the New Worlde ultimately uses an engine Slick API that looks a lot like that in the Olde Worlde. My guess is that will end up being true, but at this point that's only a guess. Some things here will certainly be nixed (ExecutionEvents) or are likely to be heavily modified (anything caching-related).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/942
https://github.com/broadinstitute/cromwell/pull/942:142,Safety,Recover,Recover,142,"This enables tests on a lot of Slick code that's not actually used yet in the New Worlde (nothing writes to the core engine tables since only Recover needs that and Recover hasn't been implemented). So these changes are valuable iff the New Worlde ultimately uses an engine Slick API that looks a lot like that in the Olde Worlde. My guess is that will end up being true, but at this point that's only a guess. Some things here will certainly be nixed (ExecutionEvents) or are likely to be heavily modified (anything caching-related).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/942
https://github.com/broadinstitute/cromwell/pull/942:165,Safety,Recover,Recover,165,"This enables tests on a lot of Slick code that's not actually used yet in the New Worlde (nothing writes to the core engine tables since only Recover needs that and Recover hasn't been implemented). So these changes are valuable iff the New Worlde ultimately uses an engine Slick API that looks a lot like that in the Olde Worlde. My guess is that will end up being true, but at this point that's only a guess. Some things here will certainly be nixed (ExecutionEvents) or are likely to be heavily modified (anything caching-related).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/942
https://github.com/broadinstitute/cromwell/pull/942:13,Testability,test,tests,13,"This enables tests on a lot of Slick code that's not actually used yet in the New Worlde (nothing writes to the core engine tables since only Recover needs that and Recover hasn't been implemented). So these changes are valuable iff the New Worlde ultimately uses an engine Slick API that looks a lot like that in the Olde Worlde. My guess is that will end up being true, but at this point that's only a guess. Some things here will certainly be nixed (ExecutionEvents) or are likely to be heavily modified (anything caching-related).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/942
https://github.com/broadinstitute/cromwell/issues/945:152,Modifiability,flexible,flexible,152,"This is just a subset of the metadata REST API data... as a first pass, reuse as much as possible. As a future path this could all be flavors of query (flexible filtering and column selection)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/945
https://github.com/broadinstitute/cromwell/issues/946:152,Modifiability,flexible,flexible,152,"This is just a subset of the metadata REST API data... as a first pass, reuse as much as possible. As a future path this could all be flavors of query (flexible filtering and column selection)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/946
https://github.com/broadinstitute/cromwell/issues/947:30,Availability,error,errors,30,"It would be easier to consume errors if they were wrapped in JSON. I believe 400 errors are already represented this way already, but a 500 response timeout returns with Content-Type:`text/plain`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/947
https://github.com/broadinstitute/cromwell/issues/947:81,Availability,error,errors,81,"It would be easier to consume errors if they were wrapped in JSON. I believe 400 errors are already represented this way already, but a 500 response timeout returns with Content-Type:`text/plain`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/947
https://github.com/broadinstitute/cromwell/issues/947:50,Integrability,wrap,wrapped,50,"It would be easier to consume errors if they were wrapped in JSON. I believe 400 errors are already represented this way already, but a 500 response timeout returns with Content-Type:`text/plain`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/947
https://github.com/broadinstitute/cromwell/issues/947:140,Performance,response time,response timeout,140,"It would be easier to consume errors if they were wrapped in JSON. I believe 400 errors are already represented this way already, but a 500 response timeout returns with Content-Type:`text/plain`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/947
https://github.com/broadinstitute/cromwell/issues/947:149,Safety,timeout,timeout,149,"It would be easier to consume errors if they were wrapped in JSON. I believe 400 errors are already represented this way already, but a 500 response timeout returns with Content-Type:`text/plain`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/947
https://github.com/broadinstitute/cromwell/issues/949:205,Availability,error,error,205,"The centaur test `custom_mount_point` is failing on JES. That's very sad. Make it work again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n custom_mount_point""; ```. The error:. ```; - should successfully run custom_mount_point *** FAILED *** (2 minutes, 1 second); java.lang.Exception: Unexpected terminal status Failed but was waiting for Succeeded; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/949
https://github.com/broadinstitute/cromwell/issues/949:12,Testability,test,test,12,"The centaur test `custom_mount_point` is failing on JES. That's very sad. Make it work again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n custom_mount_point""; ```. The error:. ```; - should successfully run custom_mount_point *** FAILED *** (2 minutes, 1 second); java.lang.Exception: Unexpected terminal status Failed but was waiting for Succeeded; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/949
https://github.com/broadinstitute/cromwell/issues/949:157,Testability,test,test-only,157,"The centaur test `custom_mount_point` is failing on JES. That's very sad. Make it work again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n custom_mount_point""; ```. The error:. ```; - should successfully run custom_mount_point *** FAILED *** (2 minutes, 1 second); java.lang.Exception: Unexpected terminal status Failed but was waiting for Succeeded; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/949
https://github.com/broadinstitute/cromwell/issues/950:193,Availability,error,error,193,"The centaur test `passingfiles` is failing on JES. That's very sad. Make it work again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n passingfiles""; ```. The error:. ```; - should successfully run passingfiles *** FAILED *** (3 minutes, 30 seconds); java.lang.Exception: Unexpected terminal status Failed but was waiting for Succeeded; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/950
https://github.com/broadinstitute/cromwell/issues/950:12,Testability,test,test,12,"The centaur test `passingfiles` is failing on JES. That's very sad. Make it work again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n passingfiles""; ```. The error:. ```; - should successfully run passingfiles *** FAILED *** (3 minutes, 30 seconds); java.lang.Exception: Unexpected terminal status Failed but was waiting for Succeeded; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/950
https://github.com/broadinstitute/cromwell/issues/950:151,Testability,test,test-only,151,"The centaur test `passingfiles` is failing on JES. That's very sad. Make it work again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n passingfiles""; ```. The error:. ```; - should successfully run passingfiles *** FAILED *** (3 minutes, 30 seconds); java.lang.Exception: Unexpected terminal status Failed but was waiting for Succeeded; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/950
https://github.com/broadinstitute/cromwell/issues/951:193,Availability,error,error,193,"The centaur test `jesexercises` is failing on JES. That's very sad. Make it work again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n jesexercises""; ```. The error:. ```; - should successfully run jesexercises *** FAILED *** (4 minutes, 40 seconds); java.lang.Exception: Unexpected terminal status Failed but was waiting for Succeeded; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/951
https://github.com/broadinstitute/cromwell/issues/951:12,Testability,test,test,12,"The centaur test `jesexercises` is failing on JES. That's very sad. Make it work again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n jesexercises""; ```. The error:. ```; - should successfully run jesexercises *** FAILED *** (4 minutes, 40 seconds); java.lang.Exception: Unexpected terminal status Failed but was waiting for Succeeded; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/951
https://github.com/broadinstitute/cromwell/issues/951:151,Testability,test,test-only,151,"The centaur test `jesexercises` is failing on JES. That's very sad. Make it work again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n jesexercises""; ```. The error:. ```; - should successfully run jesexercises *** FAILED *** (4 minutes, 40 seconds); java.lang.Exception: Unexpected terminal status Failed but was waiting for Succeeded; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/951
https://github.com/broadinstitute/cromwell/issues/952:205,Availability,error,error,205,"The centaur test `sizeenginefunction` is failing on JES. That's very sad. Make it work again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n sizeenginefunction""; ```. The error:. ```; - should successfully run sizeenginefunction *** FAILED *** (1 minute, 30 seconds); java.lang.Exception: Unexpected terminal status Failed but was waiting for Succeeded; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/952
https://github.com/broadinstitute/cromwell/issues/952:12,Testability,test,test,12,"The centaur test `sizeenginefunction` is failing on JES. That's very sad. Make it work again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n sizeenginefunction""; ```. The error:. ```; - should successfully run sizeenginefunction *** FAILED *** (1 minute, 30 seconds); java.lang.Exception: Unexpected terminal status Failed but was waiting for Succeeded; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/952
https://github.com/broadinstitute/cromwell/issues/952:157,Testability,test,test-only,157,"The centaur test `sizeenginefunction` is failing on JES. That's very sad. Make it work again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n sizeenginefunction""; ```. The error:. ```; - should successfully run sizeenginefunction *** FAILED *** (1 minute, 30 seconds); java.lang.Exception: Unexpected terminal status Failed but was waiting for Succeeded; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/952
https://github.com/broadinstitute/cromwell/issues/953:217,Availability,error,error,217,"The centaur test `workspaceenginefunctions` is failing on JES. That's very sad. Make it work again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n workspaceenginefunctions""; ```. The error:. ```; - should successfully run workspaceenginefunctions *** FAILED *** (10 seconds, 11 milliseconds); java.lang.Exception: Unexpected terminal status Failed but was waiting for Succeeded; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/953
https://github.com/broadinstitute/cromwell/issues/953:12,Testability,test,test,12,"The centaur test `workspaceenginefunctions` is failing on JES. That's very sad. Make it work again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n workspaceenginefunctions""; ```. The error:. ```; - should successfully run workspaceenginefunctions *** FAILED *** (10 seconds, 11 milliseconds); java.lang.Exception: Unexpected terminal status Failed but was waiting for Succeeded; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/953
https://github.com/broadinstitute/cromwell/issues/953:163,Testability,test,test-only,163,"The centaur test `workspaceenginefunctions` is failing on JES. That's very sad. Make it work again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n workspaceenginefunctions""; ```. The error:. ```; - should successfully run workspaceenginefunctions *** FAILED *** (10 seconds, 11 milliseconds); java.lang.Exception: Unexpected terminal status Failed but was waiting for Succeeded; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/953
https://github.com/broadinstitute/cromwell/issues/954:187,Availability,error,error,187,"The centaur test `write_tsv` is failing on JES. That's very sad. Make it work again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n write_tsv""; ```. The error:. ```; - should successfully run write_tsv *** FAILED *** (2 minutes); java.lang.Exception: Unexpected terminal status Failed but was waiting for Succeeded; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/954
https://github.com/broadinstitute/cromwell/issues/954:12,Testability,test,test,12,"The centaur test `write_tsv` is failing on JES. That's very sad. Make it work again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n write_tsv""; ```. The error:. ```; - should successfully run write_tsv *** FAILED *** (2 minutes); java.lang.Exception: Unexpected terminal status Failed but was waiting for Succeeded; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/954
https://github.com/broadinstitute/cromwell/issues/954:148,Testability,test,test-only,148,"The centaur test `write_tsv` is failing on JES. That's very sad. Make it work again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n write_tsv""; ```. The error:. ```; - should successfully run write_tsv *** FAILED *** (2 minutes); java.lang.Exception: Unexpected terminal status Failed but was waiting for Succeeded; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/954
https://github.com/broadinstitute/cromwell/issues/955:191,Availability,error,error,191,"The centaur test `write_lines` is failing on JES. That's very sad. Make it work again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n write_lines""; ```. The error:. ```; - should fail during execution write_lines *** FAILED *** (6 minutes, 0 seconds); java.lang.Exception: Unexpected terminal status Succeeded but was waiting for Failed; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/955
https://github.com/broadinstitute/cromwell/issues/955:12,Testability,test,test,12,"The centaur test `write_lines` is failing on JES. That's very sad. Make it work again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n write_lines""; ```. The error:. ```; - should fail during execution write_lines *** FAILED *** (6 minutes, 0 seconds); java.lang.Exception: Unexpected terminal status Succeeded but was waiting for Failed; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/955
https://github.com/broadinstitute/cromwell/issues/955:150,Testability,test,test-only,150,"The centaur test `write_lines` is failing on JES. That's very sad. Make it work again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n write_lines""; ```. The error:. ```; - should fail during execution write_lines *** FAILED *** (6 minutes, 0 seconds); java.lang.Exception: Unexpected terminal status Succeeded but was waiting for Failed; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/955
https://github.com/broadinstitute/cromwell/issues/956:186,Availability,error,error,186,"The centaur test `lots_of_inputs` is failing on JES. Sad! Make it great again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n lots_of_inputs""; ```. The error:. ```; - should successfully run lots_of_inputs *** FAILED *** (53 minutes, 12 seconds); java.lang.Exception: Unexpected terminal status Failed but was waiting for Succeeded; ```. WARNING! It's also taking almost an hour to run...",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/956
https://github.com/broadinstitute/cromwell/issues/956:12,Testability,test,test,12,"The centaur test `lots_of_inputs` is failing on JES. Sad! Make it great again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n lots_of_inputs""; ```. The error:. ```; - should successfully run lots_of_inputs *** FAILED *** (53 minutes, 12 seconds); java.lang.Exception: Unexpected terminal status Failed but was waiting for Succeeded; ```. WARNING! It's also taking almost an hour to run...",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/956
https://github.com/broadinstitute/cromwell/issues/956:142,Testability,test,test-only,142,"The centaur test `lots_of_inputs` is failing on JES. Sad! Make it great again! You can run it by checking out centaur and running:. ```; sbt ""test-only * -- -n lots_of_inputs""; ```. The error:. ```; - should successfully run lots_of_inputs *** FAILED *** (53 minutes, 12 seconds); java.lang.Exception: Unexpected terminal status Failed but was waiting for Succeeded; ```. WARNING! It's also taking almost an hour to run...",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/956
https://github.com/broadinstitute/cromwell/issues/960:105,Deployability,pipeline,pipeline,105,"When I run. `java -jar -jar target/scala-2.11/cromwell-0.20.jar run 3step.original.wdl inputs.json`. the pipeline completes, but cromwell just sits there. Previously, it would exit on completion",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/960
https://github.com/broadinstitute/cromwell/issues/962:206,Availability,error,error,206,"Given the eventually consistent scheme in place for deriving workflow status, it's likely that a status check soon after workflow submission will fail with a 404 response. From a UX perspective a bogus 404 error due to eventual consistency feels wrong; a lag in status update is one thing, but Cromwell probably shouldn't disavow the existence of the workflow.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/962
https://github.com/broadinstitute/cromwell/issues/962:269,Deployability,update,update,269,"Given the eventually consistent scheme in place for deriving workflow status, it's likely that a status check soon after workflow submission will fail with a 404 response. From a UX perspective a bogus 404 error due to eventual consistency feels wrong; a lag in status update is one thing, but Cromwell probably shouldn't disavow the existence of the workflow.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/962
https://github.com/broadinstitute/cromwell/issues/962:179,Usability,UX,UX,179,"Given the eventually consistent scheme in place for deriving workflow status, it's likely that a status check soon after workflow submission will fail with a 404 response. From a UX perspective a bogus 404 error due to eventual consistency feels wrong; a lag in status update is one thing, but Cromwell probably shouldn't disavow the existence of the workflow.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/962
https://github.com/broadinstitute/cromwell/pull/964:26,Availability,Failure,Failure,26,This is like #957 but for Failure Events. Failure Events are published as metadata but no longer rate their own separate table.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/964
https://github.com/broadinstitute/cromwell/pull/964:42,Availability,Failure,Failure,42,This is like #957 but for Failure Events. Failure Events are published as metadata but no longer rate their own separate table.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/964
https://github.com/broadinstitute/cromwell/issues/966:14,Availability,failure,failure,14,"If there is a failure in the `WorkflowMaterialiserActor` phase, there is no external way to debug the error. Allow the `WorkflowMaterialiserActor` to send failure messages to the metadata service in this instance, so that it's possible to debug errors!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/966
https://github.com/broadinstitute/cromwell/issues/966:102,Availability,error,error,102,"If there is a failure in the `WorkflowMaterialiserActor` phase, there is no external way to debug the error. Allow the `WorkflowMaterialiserActor` to send failure messages to the metadata service in this instance, so that it's possible to debug errors!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/966
https://github.com/broadinstitute/cromwell/issues/966:155,Availability,failure,failure,155,"If there is a failure in the `WorkflowMaterialiserActor` phase, there is no external way to debug the error. Allow the `WorkflowMaterialiserActor` to send failure messages to the metadata service in this instance, so that it's possible to debug errors!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/966
https://github.com/broadinstitute/cromwell/issues/966:245,Availability,error,errors,245,"If there is a failure in the `WorkflowMaterialiserActor` phase, there is no external way to debug the error. Allow the `WorkflowMaterialiserActor` to send failure messages to the metadata service in this instance, so that it's possible to debug errors!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/966
https://github.com/broadinstitute/cromwell/issues/966:163,Integrability,message,messages,163,"If there is a failure in the `WorkflowMaterialiserActor` phase, there is no external way to debug the error. Allow the `WorkflowMaterialiserActor` to send failure messages to the metadata service in this instance, so that it's possible to debug errors!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/966
https://github.com/broadinstitute/cromwell/issues/967:4,Testability,test,tests,4,"Two tests in the SingleWorkflowRunnerActorSpec 0.19_hotfix have been ignored because the Workflows don't stop running when the test ends. The reason they are ignored is because they break the WorkflowManagerActorSpec tests when workflow restarts are being tested, the WFMA expects 0 wofklows to be restartable but finds that singleWorkflowRunnerActor workflows show up as being ""restartable"" since they never completed initially. The test behaviors that have been ignored are: ; ""successfully terminate the system on an exception; ""successfully warn about unexpected output"". AC: They both require cleanup so that the workflows end up with a terminal state when the test spec end.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/967
https://github.com/broadinstitute/cromwell/issues/967:127,Testability,test,test,127,"Two tests in the SingleWorkflowRunnerActorSpec 0.19_hotfix have been ignored because the Workflows don't stop running when the test ends. The reason they are ignored is because they break the WorkflowManagerActorSpec tests when workflow restarts are being tested, the WFMA expects 0 wofklows to be restartable but finds that singleWorkflowRunnerActor workflows show up as being ""restartable"" since they never completed initially. The test behaviors that have been ignored are: ; ""successfully terminate the system on an exception; ""successfully warn about unexpected output"". AC: They both require cleanup so that the workflows end up with a terminal state when the test spec end.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/967
https://github.com/broadinstitute/cromwell/issues/967:217,Testability,test,tests,217,"Two tests in the SingleWorkflowRunnerActorSpec 0.19_hotfix have been ignored because the Workflows don't stop running when the test ends. The reason they are ignored is because they break the WorkflowManagerActorSpec tests when workflow restarts are being tested, the WFMA expects 0 wofklows to be restartable but finds that singleWorkflowRunnerActor workflows show up as being ""restartable"" since they never completed initially. The test behaviors that have been ignored are: ; ""successfully terminate the system on an exception; ""successfully warn about unexpected output"". AC: They both require cleanup so that the workflows end up with a terminal state when the test spec end.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/967
https://github.com/broadinstitute/cromwell/issues/967:256,Testability,test,tested,256,"Two tests in the SingleWorkflowRunnerActorSpec 0.19_hotfix have been ignored because the Workflows don't stop running when the test ends. The reason they are ignored is because they break the WorkflowManagerActorSpec tests when workflow restarts are being tested, the WFMA expects 0 wofklows to be restartable but finds that singleWorkflowRunnerActor workflows show up as being ""restartable"" since they never completed initially. The test behaviors that have been ignored are: ; ""successfully terminate the system on an exception; ""successfully warn about unexpected output"". AC: They both require cleanup so that the workflows end up with a terminal state when the test spec end.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/967
https://github.com/broadinstitute/cromwell/issues/967:434,Testability,test,test,434,"Two tests in the SingleWorkflowRunnerActorSpec 0.19_hotfix have been ignored because the Workflows don't stop running when the test ends. The reason they are ignored is because they break the WorkflowManagerActorSpec tests when workflow restarts are being tested, the WFMA expects 0 wofklows to be restartable but finds that singleWorkflowRunnerActor workflows show up as being ""restartable"" since they never completed initially. The test behaviors that have been ignored are: ; ""successfully terminate the system on an exception; ""successfully warn about unexpected output"". AC: They both require cleanup so that the workflows end up with a terminal state when the test spec end.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/967
https://github.com/broadinstitute/cromwell/issues/967:666,Testability,test,test,666,"Two tests in the SingleWorkflowRunnerActorSpec 0.19_hotfix have been ignored because the Workflows don't stop running when the test ends. The reason they are ignored is because they break the WorkflowManagerActorSpec tests when workflow restarts are being tested, the WFMA expects 0 wofklows to be restartable but finds that singleWorkflowRunnerActor workflows show up as being ""restartable"" since they never completed initially. The test behaviors that have been ignored are: ; ""successfully terminate the system on an exception; ""successfully warn about unexpected output"". AC: They both require cleanup so that the workflows end up with a terminal state when the test spec end.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/967
https://github.com/broadinstitute/cromwell/issues/972:955,Performance,perform,perform,955,"The new `super_massive_array_output` test in centaur has found a problem in metadata reading. It turns out that it generates quite a bit of metadata:. ```; mysql> select count(*) from METADATA_JOURNAL where WORKFLOW_EXECUTION_UUID=""31861832-66ee-45e6-ae10-891f55d176df"";; +----------+; | count(*) |; +----------+; | 2278541 |; +----------+; ```. Luckily, most of it is either inputs or outputs:. ```; mysql> select count(*) from METADATA_JOURNAL where WORKFLOW_EXECUTION_UUID=""31861832-66ee-45e6-ae10-891f55d176df"" and `metadata_key` like ""%output%"" or `metadata_key` like ""%input%"";; +----------+; | count(*) |; +----------+; | 2268240 |; +----------+; ```. The cromwell service is simply unable to muster 2.3 million rows of metadata into JSON in time or in the memory it has. On scaling up the scatter from 500 to 20,000, the metadata rows required will almost certainly scale proportionally. Luckily, this is a read-time problem, Cromwell was able to perform the 500x scatter effortlessly and completed successfully. Only the post-facto attempt to see metadata caused problems.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/972
https://github.com/broadinstitute/cromwell/issues/972:37,Testability,test,test,37,"The new `super_massive_array_output` test in centaur has found a problem in metadata reading. It turns out that it generates quite a bit of metadata:. ```; mysql> select count(*) from METADATA_JOURNAL where WORKFLOW_EXECUTION_UUID=""31861832-66ee-45e6-ae10-891f55d176df"";; +----------+; | count(*) |; +----------+; | 2278541 |; +----------+; ```. Luckily, most of it is either inputs or outputs:. ```; mysql> select count(*) from METADATA_JOURNAL where WORKFLOW_EXECUTION_UUID=""31861832-66ee-45e6-ae10-891f55d176df"" and `metadata_key` like ""%output%"" or `metadata_key` like ""%input%"";; +----------+; | count(*) |; +----------+; | 2268240 |; +----------+; ```. The cromwell service is simply unable to muster 2.3 million rows of metadata into JSON in time or in the memory it has. On scaling up the scatter from 500 to 20,000, the metadata rows required will almost certainly scale proportionally. Luckily, this is a read-time problem, Cromwell was able to perform the 500x scatter effortlessly and completed successfully. Only the post-facto attempt to see metadata caused problems.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/972
https://github.com/broadinstitute/cromwell/issues/972:683,Usability,simpl,simply,683,"The new `super_massive_array_output` test in centaur has found a problem in metadata reading. It turns out that it generates quite a bit of metadata:. ```; mysql> select count(*) from METADATA_JOURNAL where WORKFLOW_EXECUTION_UUID=""31861832-66ee-45e6-ae10-891f55d176df"";; +----------+; | count(*) |; +----------+; | 2278541 |; +----------+; ```. Luckily, most of it is either inputs or outputs:. ```; mysql> select count(*) from METADATA_JOURNAL where WORKFLOW_EXECUTION_UUID=""31861832-66ee-45e6-ae10-891f55d176df"" and `metadata_key` like ""%output%"" or `metadata_key` like ""%input%"";; +----------+; | count(*) |; +----------+; | 2268240 |; +----------+; ```. The cromwell service is simply unable to muster 2.3 million rows of metadata into JSON in time or in the memory it has. On scaling up the scatter from 500 to 20,000, the metadata rows required will almost certainly scale proportionally. Luckily, this is a read-time problem, Cromwell was able to perform the 500x scatter effortlessly and completed successfully. Only the post-facto attempt to see metadata caused problems.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/972
https://github.com/broadinstitute/cromwell/pull/974:83,Performance,Concurren,ConcurrentModificationException,83,"Bumped `liquibase-core` version to latest `3.5.1` that fixes among other things a `ConcurrentModificationException` (see liquibase pull 539).; Moved cromwell specific liquibase diff filtering out of (hopefully someday) common `DiffResultFilter`.; Now filtering new ""order"" differences.; Prettier printing of liquibase/slick differences in `SlickDatabaseSpec`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/974
https://github.com/broadinstitute/cromwell/pull/977:63,Testability,log,logic,63,The metadata endpoint was previously not applying any business logic to workflow states so it simply returned the last state written to the journal. This adds specific resolution logic similar to that used for workflow summary.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/977
https://github.com/broadinstitute/cromwell/pull/977:179,Testability,log,logic,179,The metadata endpoint was previously not applying any business logic to workflow states so it simply returned the last state written to the journal. This adds specific resolution logic similar to that used for workflow summary.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/977
https://github.com/broadinstitute/cromwell/pull/977:94,Usability,simpl,simply,94,The metadata endpoint was previously not applying any business logic to workflow states so it simply returned the last state written to the journal. This adds specific resolution logic similar to that used for workflow summary.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/977
https://github.com/broadinstitute/cromwell/issues/978:262,Usability,clear,clear,262,"As suggested by @cjllanwarne, record the last processed metadata journal ID in the database. This will allow Cromwell to not spin its wheels processing metadata pointlessly on restarts, as well as give more explicit control if a full summary rebuild is desired (clear WORKFLOW_METADATA_SUMMARY, reset last processed METADATA_JOURNAL id to 0).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/978
https://github.com/broadinstitute/cromwell/issues/982:704,Availability,error,error,704,"We typically have workflow inputs that fall into different categories based on how often they vary.; For example there are inputs that vary according to:; Sample (every time); Genome build (almost never); Plexity (rarely, but sometimes). It would be nice if we could pass multiple workflow jsons to the cromwell server. That would allow us to maintain a static, per-genome build inputs file as well as more dynamic per-run inputs files. The former points to public data and could be distributed among our collaborators when we share our method. We get around the absence of this feature by munging multiple jsons together on every submission. But this makes things harder to share with others. It's also error prone. Priority is low. This is a convenience and community-adoption feature- not a blocker.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/982
https://github.com/broadinstitute/cromwell/issues/984:143,Energy Efficiency,efficient,efficient,143,"These endpoints are not being used by our major clients and represent a special case of data you can get from the metadata endpoint. If a more efficient mechanism is needed to get this data in the future, we can add that as reshaping of the metadata output (e.g. .../metadata/{call}). Make it Gone, including from the README and Swagger!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/984
https://github.com/broadinstitute/cromwell/pull/986:41,Safety,abort,aborting,41,"…. Closes #940 . Note that the tests for aborting were already commented out, and as this would be tricky to test anyways I took that as a sign from above. I've manually verified it, however. @abaumann - this will not clean up previously stuck workflows, I'm going to provide a script or something like that to clean up the old crap, fixing those from within Cromwell was building up too many tendrils for a hack fix to something which is going to be replaced in the near future.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/986
