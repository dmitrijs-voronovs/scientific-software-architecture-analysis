id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://github.com/stardist/stardist/tree/0.9.1/setup.py:194,Availability,error,errors,194,"# thanks to @jaimergp (https://github.com/conda-forge/staged-recipes/pull/17766); # issue: qhull has a mix of c and c++ source files; # gcc warns about passing -std=c++11 for c files, but clang errors out",MatchSource.CODE_COMMENT,setup.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/setup.py
https://github.com/stardist/stardist/tree/0.9.1/setup.py:9,Deployability,patch,patch,9,"# monkey patch the _compile method",MatchSource.CODE_COMMENT,setup.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/setup.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:2,Testability,assert,assert,2,"# assert not (bmin == 0 and bmax >= r_start and not self.at_begin), [(r_start,r_end), bbox, self]",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:61,Safety,avoid,avoid,61,"# print(); [print(t) for t in first]; # add extra context to avoid overlapping write regions of non-neighboring blocks",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:40,Safety,sanity check,sanity checks,40,"# print(); [print(t) for t in first]; # sanity checks",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:37,Usability,simpl,simply,37,"""""""N-dimensional block. Each BlockND simply consists of a 1-dimensional Block per axis and also; has an id (which should be unique). The n-dimensional region represented; by each BlockND is the intersection of all 1D Blocks per axis. Also see `Block`. """"""",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:7,Availability,mask,mask,7,"# x[s][mask] = labels[mask] # doesn't work with zarr",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:22,Availability,mask,mask,22,"# x[s][mask] = labels[mask] # doesn't work with zarr",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:18,Deployability,update,update,18,"# TODO: option to update labels in-place",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:771,Availability,reliab,reliable,771,"# if e.args[0]: # object larger than block write region; # assert any(o >= b for o,b in zip(shape_object,shape_block_write)); # # problem, since this object will probably be saved by another block too; # raise RuntimeError(f""Found object of shape {shape_object}, larger than an entire block's write region of shape {shape_block_write}. Increase 'block_size' to avoid this problem.""); # # print(""found object larger than 'block_size'""); # else:; # assert any(o >= b for o,b in zip(shape_object,shape_min_overlap)); # # print(""found object larger than 'min_overlap'""); # # keep object, because will be dealt with later, i.e.; # # render the poly again into the label image, but this is not; # # ideal since the assumption is that the object outside that; # # region is not reliable because it's in the context; # labels_filtered[slices][r.image] = r.label; # problem_ids.append(r.label)",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:361,Safety,avoid,avoid,361,"# if e.args[0]: # object larger than block write region; # assert any(o >= b for o,b in zip(shape_object,shape_block_write)); # # problem, since this object will probably be saved by another block too; # raise RuntimeError(f""Found object of shape {shape_object}, larger than an entire block's write region of shape {shape_block_write}. Increase 'block_size' to avoid this problem.""); # # print(""found object larger than 'block_size'""); # else:; # assert any(o >= b for o,b in zip(shape_object,shape_min_overlap)); # # print(""found object larger than 'min_overlap'""); # # keep object, because will be dealt with later, i.e.; # # render the poly again into the label image, but this is not; # # ideal since the assumption is that the object outside that; # # region is not reliable because it's in the context; # labels_filtered[slices][r.image] = r.label; # problem_ids.append(r.label)",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:59,Testability,assert,assert,59,"# if e.args[0]: # object larger than block write region; # assert any(o >= b for o,b in zip(shape_object,shape_block_write)); # # problem, since this object will probably be saved by another block too; # raise RuntimeError(f""Found object of shape {shape_object}, larger than an entire block's write region of shape {shape_block_write}. Increase 'block_size' to avoid this problem.""); # # print(""found object larger than 'block_size'""); # else:; # assert any(o >= b for o,b in zip(shape_object,shape_min_overlap)); # # print(""found object larger than 'min_overlap'""); # # keep object, because will be dealt with later, i.e.; # # render the poly again into the label image, but this is not; # # ideal since the assumption is that the object outside that; # # region is not reliable because it's in the context; # labels_filtered[slices][r.image] = r.label; # problem_ids.append(r.label)",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:447,Testability,assert,assert,447,"# if e.args[0]: # object larger than block write region; # assert any(o >= b for o,b in zip(shape_object,shape_block_write)); # # problem, since this object will probably be saved by another block too; # raise RuntimeError(f""Found object of shape {shape_object}, larger than an entire block's write region of shape {shape_block_write}. Increase 'block_size' to avoid this problem.""); # # print(""found object larger than 'block_size'""); # else:; # assert any(o >= b for o,b in zip(shape_object,shape_min_overlap)); # # print(""found object larger than 'min_overlap'""); # # keep object, because will be dealt with later, i.e.; # # render the poly again into the label image, but this is not; # # ideal since the assumption is that the object outside that; # # region is not reliable because it's in the context; # labels_filtered[slices][r.image] = r.label; # problem_ids.append(r.label)",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:2,Testability,assert,assert,2,"# assert len(problem_ids) == 0",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:1047,Availability,mask,mask,1047,"n probability scores.; # Does modify 'output' and 'polys' in-place, but will only write sparsely to 'output' where needed.; # output: numpy.ndarray or similar; # Label image (integer-valued); # labels: iterable of int; # List of integer label ids that occur in output; # polys: dict; # Dictionary of polygon/polyhedra properties.; # Assumption is that the label id (-1) corresponds to the index in the polys dict; # """"""; # assert output.ndim in (2,3); # if show_progress:; # labels = tqdm(labels, leave=True); # labels_eliminated = set(); # # TODO: inelegant to have so much duplicated code here; # if output.ndim == 2:; # coord = lambda i: polys['coord'][i-1]; # prob = lambda i: polys['prob'][i-1]; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polygon(coord(i), shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polygon.coords_bbox(*[coord(j) for j in overlapping], shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polygon(coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhe",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:1393,Availability,mask,mask,1393,"of int; # List of integer label ids that occur in output; # polys: dict; # Dictionary of polygon/polyhedra properties.; # Assumption is that the label id (-1) corresponds to the index in the polys dict; # """"""; # assert output.ndim in (2,3); # if show_progress:; # labels = tqdm(labels, leave=True); # labels_eliminated = set(); # # TODO: inelegant to have so much duplicated code here; # if output.ndim == 2:; # coord = lambda i: polys['coord'][i-1]; # prob = lambda i: polys['prob'][i-1]; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polygon(coord(i), shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polygon.coords_bbox(*[coord(j) for j in overlapping], shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polygon(coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; #",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:1407,Availability,mask,mask,1407,"tionary of polygon/polyhedra properties.; # Assumption is that the label id (-1) corresponds to the index in the polys dict; # """"""; # assert output.ndim in (2,3); # if show_progress:; # labels = tqdm(labels, leave=True); # labels_eliminated = set(); # # TODO: inelegant to have so much duplicated code here; # if output.ndim == 2:; # coord = lambda i: polys['coord'][i-1]; # prob = lambda i: polys['prob'][i-1]; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polygon(coord(i), shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polygon.coords_bbox(*[coord(j) for j in overlapping], shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polygon(coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:1443,Availability,mask,mask,1443," the index in the polys dict; # """"""; # assert output.ndim in (2,3); # if show_progress:; # labels = tqdm(labels, leave=True); # labels_eliminated = set(); # # TODO: inelegant to have so much duplicated code here; # if output.ndim == 2:; # coord = lambda i: polys['coord'][i-1]; # prob = lambda i: polys['prob'][i-1]; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polygon(coord(i), shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polygon.coords_bbox(*[coord(j) for j in overlapping], shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polygon(coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays,",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:1556,Availability,mask,mask,1556," the index in the polys dict; # """"""; # assert output.ndim in (2,3); # if show_progress:; # labels = tqdm(labels, leave=True); # labels_eliminated = set(); # # TODO: inelegant to have so much duplicated code here; # if output.ndim == 2:; # coord = lambda i: polys['coord'][i-1]; # prob = lambda i: polys['prob'][i-1]; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polygon(coord(i), shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polygon.coords_bbox(*[coord(j) for j in overlapping], shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polygon(coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays,",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:1597,Availability,mask,mask,1597," leave=True); # labels_eliminated = set(); # # TODO: inelegant to have so much duplicated code here; # if output.ndim == 2:; # coord = lambda i: polys['coord'][i-1]; # prob = lambda i: polys['prob'][i-1]; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polygon(coord(i), shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polygon.coords_bbox(*[coord(j) for j in overlapping], shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polygon(coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:1707,Availability,mask,mask,1707,"de here; # if output.ndim == 2:; # coord = lambda i: polys['coord'][i-1]; # prob = lambda i: polys['prob'][i-1]; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polygon(coord(i), shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polygon.coords_bbox(*[coord(j) for j in overlapping], shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polygon(coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polyhedron(dist(i), origin(i), rays, bbox=bbox_union); # mask = poly_i.mask.copy(); # ",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:1733,Availability,mask,mask,1733,"de here; # if output.ndim == 2:; # coord = lambda i: polys['coord'][i-1]; # prob = lambda i: polys['prob'][i-1]; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polygon(coord(i), shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polygon.coords_bbox(*[coord(j) for j in overlapping], shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polygon(coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polyhedron(dist(i), origin(i), rays, bbox=bbox_union); # mask = poly_i.mask.copy(); # ",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:1815,Availability,mask,mask,1815,"labels:; # if i in labels_eliminated: continue; # poly_i = Polygon(coord(i), shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polygon.coords_bbox(*[coord(j) for j in overlapping], shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polygon(coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polyhedron(dist(i), origin(i), rays, bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:2289,Availability,mask,mask,2289,"coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polyhedron(dist(i), origin(i), rays, bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polyhedron(dist(j), origin(j), rays, bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # if len(labels_eliminated) > 0:; # ind = [i-1 for i in labels_eliminated]; # for k,v in polys.items():; # if k in OBJECT_KEYS:; # polys[k] = np.delete(v, ind, axis=0); ",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:2679,Availability,mask,mask,2679,"=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polyhedron(dist(i), origin(i), rays, bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polyhedron(dist(j), origin(j), rays, bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # if len(labels_eliminated) > 0:; # ind = [i-1 for i in labels_eliminated]; # for k,v in polys.items():; # if k in OBJECT_KEYS:; # polys[k] = np.delete(v, ind, axis=0); ############",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:2693,Availability,mask,mask,2693,"=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polyhedron(dist(i), origin(i), rays, bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polyhedron(dist(j), origin(j), rays, bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # if len(labels_eliminated) > 0:; # ind = [i-1 for i in labels_eliminated]; # for k,v in polys.items():; # if k in OBJECT_KEYS:; # polys[k] = np.delete(v, ind, axis=0); ############",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:2729,Availability,mask,mask,2729,"=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polyhedron(dist(i), origin(i), rays, bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polyhedron(dist(j), origin(j), rays, bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # if len(labels_eliminated) > 0:; # ind = [i-1 for i in labels_eliminated]; # for k,v in polys.items():; # if k in OBJECT_KEYS:; # polys[k] = np.delete(v, ind, axis=0); ############",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:2842,Availability,mask,mask,2842,"=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polyhedron(dist(i), origin(i), rays, bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polyhedron(dist(j), origin(j), rays, bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # if len(labels_eliminated) > 0:; # ind = [i-1 for i in labels_eliminated]; # for k,v in polys.items():; # if k in OBJECT_KEYS:; # polys[k] = np.delete(v, ind, axis=0); ############",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:2902,Availability,mask,mask,2902,"=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polyhedron(dist(i), origin(i), rays, bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polyhedron(dist(j), origin(j), rays, bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # if len(labels_eliminated) > 0:; # ind = [i-1 for i in labels_eliminated]; # for k,v in polys.items():; # if k in OBJECT_KEYS:; # polys[k] = np.delete(v, ind, axis=0); ############",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:3012,Availability,mask,mask,3012,"=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polyhedron(dist(i), origin(i), rays, bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polyhedron(dist(j), origin(j), rays, bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # if len(labels_eliminated) > 0:; # ind = [i-1 for i in labels_eliminated]; # for k,v in polys.items():; # if k in OBJECT_KEYS:; # polys[k] = np.delete(v, ind, axis=0); ############",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:3038,Availability,mask,mask,3038,"=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polyhedron(dist(i), origin(i), rays, bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polyhedron(dist(j), origin(j), rays, bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # if len(labels_eliminated) > 0:; # ind = [i-1 for i in labels_eliminated]; # for k,v in polys.items():; # if k in OBJECT_KEYS:; # polys[k] = np.delete(v, ind, axis=0); ############",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:3120,Availability,mask,mask,3120,"=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polyhedron(dist(i), origin(i), rays, bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polyhedron(dist(j), origin(j), rays, bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # if len(labels_eliminated) > 0:; # ind = [i-1 for i in labels_eliminated]; # for k,v in polys.items():; # if k in OBJECT_KEYS:; # polys[k] = np.delete(v, ind, axis=0); ############",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:1850,Deployability,update,update,1850,"np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polygon.coords_bbox(*[coord(j) for j in overlapping], shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polygon(coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polyhedron(dist(i), origin(i), rays, bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polyhedron(dist(j), origin(j), rays, bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # cr",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:3155,Deployability,update,update,3155,"=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polyhedron(dist(i), origin(i), rays, bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polyhedron(dist(j), origin(j), rays, bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # if len(labels_eliminated) > 0:; # ind = [i-1 for i in labels_eliminated]; # for k,v in polys.items():; # if k in OBJECT_KEYS:; # polys[k] = np.delete(v, ind, axis=0); ############",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:543,Testability,assert,assert,543,"# def repaint_labels(output, labels, polys, show_progress=True):; # """"""Repaint object instances in correct order based on probability scores.; # Does modify 'output' and 'polys' in-place, but will only write sparsely to 'output' where needed.; # output: numpy.ndarray or similar; # Label image (integer-valued); # labels: iterable of int; # List of integer label ids that occur in output; # polys: dict; # Dictionary of polygon/polyhedra properties.; # Assumption is that the label id (-1) corresponds to the index in the polys dict; # """"""; # assert output.ndim in (2,3); # if show_progress:; # labels = tqdm(labels, leave=True); # labels_eliminated = set(); # # TODO: inelegant to have so much duplicated code here; # if output.ndim == 2:; # coord = lambda i: polys['coord'][i-1]; # prob = lambda i: polys['prob'][i-1]; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polygon(coord(i), shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polygon.coords_bbox(*[coord(j) for j in overlapping], shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polygon(coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: p",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:1064,Testability,assert,assert,1064,"n probability scores.; # Does modify 'output' and 'polys' in-place, but will only write sparsely to 'output' where needed.; # output: numpy.ndarray or similar; # Label image (integer-valued); # labels: iterable of int; # List of integer label ids that occur in output; # polys: dict; # Dictionary of polygon/polyhedra properties.; # Assumption is that the label id (-1) corresponds to the index in the polys dict; # """"""; # assert output.ndim in (2,3); # if show_progress:; # labels = tqdm(labels, leave=True); # labels_eliminated = set(); # # TODO: inelegant to have so much duplicated code here; # if output.ndim == 2:; # coord = lambda i: polys['coord'][i-1]; # prob = lambda i: polys['prob'][i-1]; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polygon(coord(i), shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polygon.coords_bbox(*[coord(j) for j in overlapping], shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polygon(coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhe",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py:2306,Testability,assert,assert,2306,"coord(i), bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polygon(coord(j), bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # else:; # dist = lambda i: polys['dist'][i-1]; # origin = lambda i: polys['points'][i-1]; # prob = lambda i: polys['prob'][i-1]; # rays = polys['rays']; # for i in labels:; # if i in labels_eliminated: continue; # poly_i = Polyhedron(dist(i), origin(i), rays, shape_max=output.shape); # # find all labels that overlap with i (including i); # overlapping = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # assert i in overlapping; # # compute bbox union to find area to crop/replace in large output label image; # bbox_union = Polyhedron.coords_bbox(*[(dist(j),origin(j)) for j in overlapping], rays=rays, shape_max=output.shape); # # crop out label i, including the region that include all overlapping labels; # poly_i = Polyhedron(dist(i), origin(i), rays, bbox=bbox_union); # mask = poly_i.mask.copy(); # # remove pixels from mask that belong to labels with higher probability; # for j in [j for j in overlapping if prob(j) > prob(i)]:; # mask[ Polyhedron(dist(j), origin(j), rays, bbox=bbox_union).mask ] = False; # crop = output[poly_i.slice]; # crop[crop==i] = 0 # delete all remnants of i in crop; # crop[mask] = i # paint i where mask still active; # labels_remaining = set(np.unique(output[poly_i.slice][poly_i.mask])) - {0}; # labels_eliminated.update(overlapping - labels_remaining); # if len(labels_eliminated) > 0:; # ind = [i-1 for i in labels_eliminated]; # for k,v in polys.items():; # if k in OBJECT_KEYS:; # polys[k] = np.delete(v, ind, axis=0); ",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:620,Deployability,install,installed,620,"""""""; //*******************************************************************; // Date: July-2021; // Credits: StarDist, DeepImageJ; // URL:; // https://github.com/stardist/stardist; // https://deepimagej.github.io/deepimagej; // This macro was adapted from; // https://github.com/deepimagej/imagej-macros/blob/648caa867f6ccb459649d4d3799efa1e2e0c5204/StarDist2D_Post-processing.ijm; // Please cite the respective contributions when using this code.; //*******************************************************************; // Macro to run StarDist postprocessing on 2D images.; // StarDist and deepImageJ plugins need to be installed.; // The macro assumes that the image to process is a stack in which; // the first channel corresponds to the object probability map; // and the remaining channels are the radial distances from each; // pixel to the object boundary.; //*******************************************************************. // Get the name of the image to call it; getDimensions(width, height, channels, slices, frames);; name=getTitle();. probThresh={probThresh};; nmsThresh={nmsThresh};. // Isolate the detection probability scores; run(""Make Substack..."", ""channels=1"");; rename(""scores"");. // Isolate the oriented distances; run(""Fire"");; selectWindow(name);; run(""Delete Slice"", ""delete=channel"");; selectWindow(name);; run(""Properties..."", ""channels="" + maxOf(channels, slices) - 1 + "" slices=1 frames=1 pixel_width=1.0000 pixel_height=1.0000 voxel_depth=1.0000"");; rename(""distances"");; run(""royal"");. // Run StarDist plugin; run(""Command From Macro"", ""command=[de.csbdresden.stardist.StarDist2DNMS], args=['prob':'scores', 'dist':'distances', 'probThresh':'"" + probThresh + ""', 'nmsThresh':'"" + nmsThresh + ""', 'outputType':'Both', 'excludeBoundary':'2', 'roiPosition':'Stack', 'verbose':'false'], process=[false]"");; """"""",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:242,Energy Efficiency,adapt,adapted,242,"""""""; //*******************************************************************; // Date: July-2021; // Credits: StarDist, DeepImageJ; // URL:; // https://github.com/stardist/stardist; // https://deepimagej.github.io/deepimagej; // This macro was adapted from; // https://github.com/deepimagej/imagej-macros/blob/648caa867f6ccb459649d4d3799efa1e2e0c5204/StarDist2D_Post-processing.ijm; // Please cite the respective contributions when using this code.; //*******************************************************************; // Macro to run StarDist postprocessing on 2D images.; // StarDist and deepImageJ plugins need to be installed.; // The macro assumes that the image to process is a stack in which; // the first channel corresponds to the object probability map; // and the remaining channels are the radial distances from each; // pixel to the object boundary.; //*******************************************************************. // Get the name of the image to call it; getDimensions(width, height, channels, slices, frames);; name=getTitle();. probThresh={probThresh};; nmsThresh={nmsThresh};. // Isolate the detection probability scores; run(""Make Substack..."", ""channels=1"");; rename(""scores"");. // Isolate the oriented distances; run(""Fire"");; selectWindow(name);; run(""Delete Slice"", ""delete=channel"");; selectWindow(name);; run(""Properties..."", ""channels="" + maxOf(channels, slices) - 1 + "" slices=1 frames=1 pixel_width=1.0000 pixel_height=1.0000 voxel_depth=1.0000"");; rename(""distances"");; run(""royal"");. // Run StarDist plugin; run(""Command From Macro"", ""command=[de.csbdresden.stardist.StarDist2DNMS], args=['prob':'scores', 'dist':'distances', 'probThresh':'"" + probThresh + ""', 'nmsThresh':'"" + nmsThresh + ""', 'outputType':'Both', 'excludeBoundary':'2', 'roiPosition':'Stack', 'verbose':'false'], process=[false]"");; """"""",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:242,Modifiability,adapt,adapted,242,"""""""; //*******************************************************************; // Date: July-2021; // Credits: StarDist, DeepImageJ; // URL:; // https://github.com/stardist/stardist; // https://deepimagej.github.io/deepimagej; // This macro was adapted from; // https://github.com/deepimagej/imagej-macros/blob/648caa867f6ccb459649d4d3799efa1e2e0c5204/StarDist2D_Post-processing.ijm; // Please cite the respective contributions when using this code.; //*******************************************************************; // Macro to run StarDist postprocessing on 2D images.; // StarDist and deepImageJ plugins need to be installed.; // The macro assumes that the image to process is a stack in which; // the first channel corresponds to the object probability map; // and the remaining channels are the radial distances from each; // pixel to the object boundary.; //*******************************************************************. // Get the name of the image to call it; getDimensions(width, height, channels, slices, frames);; name=getTitle();. probThresh={probThresh};; nmsThresh={nmsThresh};. // Isolate the detection probability scores; run(""Make Substack..."", ""channels=1"");; rename(""scores"");. // Isolate the oriented distances; run(""Fire"");; selectWindow(name);; run(""Delete Slice"", ""delete=channel"");; selectWindow(name);; run(""Properties..."", ""channels="" + maxOf(channels, slices) - 1 + "" slices=1 frames=1 pixel_width=1.0000 pixel_height=1.0000 voxel_depth=1.0000"");; rename(""distances"");; run(""royal"");. // Run StarDist plugin; run(""Command From Macro"", ""command=[de.csbdresden.stardist.StarDist2DNMS], args=['prob':'scores', 'dist':'distances', 'probThresh':'"" + probThresh + ""', 'nmsThresh':'"" + nmsThresh + ""', 'outputType':'Both', 'excludeBoundary':'2', 'roiPosition':'Stack', 'verbose':'false'], process=[false]"");; """"""",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:601,Modifiability,plugin,plugins,601,"""""""; //*******************************************************************; // Date: July-2021; // Credits: StarDist, DeepImageJ; // URL:; // https://github.com/stardist/stardist; // https://deepimagej.github.io/deepimagej; // This macro was adapted from; // https://github.com/deepimagej/imagej-macros/blob/648caa867f6ccb459649d4d3799efa1e2e0c5204/StarDist2D_Post-processing.ijm; // Please cite the respective contributions when using this code.; //*******************************************************************; // Macro to run StarDist postprocessing on 2D images.; // StarDist and deepImageJ plugins need to be installed.; // The macro assumes that the image to process is a stack in which; // the first channel corresponds to the object probability map; // and the remaining channels are the radial distances from each; // pixel to the object boundary.; //*******************************************************************. // Get the name of the image to call it; getDimensions(width, height, channels, slices, frames);; name=getTitle();. probThresh={probThresh};; nmsThresh={nmsThresh};. // Isolate the detection probability scores; run(""Make Substack..."", ""channels=1"");; rename(""scores"");. // Isolate the oriented distances; run(""Fire"");; selectWindow(name);; run(""Delete Slice"", ""delete=channel"");; selectWindow(name);; run(""Properties..."", ""channels="" + maxOf(channels, slices) - 1 + "" slices=1 frames=1 pixel_width=1.0000 pixel_height=1.0000 voxel_depth=1.0000"");; rename(""distances"");; run(""royal"");. // Run StarDist plugin; run(""Command From Macro"", ""command=[de.csbdresden.stardist.StarDist2DNMS], args=['prob':'scores', 'dist':'distances', 'probThresh':'"" + probThresh + ""', 'nmsThresh':'"" + nmsThresh + ""', 'outputType':'Both', 'excludeBoundary':'2', 'roiPosition':'Stack', 'verbose':'false'], process=[false]"");; """"""",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:1536,Modifiability,plugin,plugin,1536,"""""""; //*******************************************************************; // Date: July-2021; // Credits: StarDist, DeepImageJ; // URL:; // https://github.com/stardist/stardist; // https://deepimagej.github.io/deepimagej; // This macro was adapted from; // https://github.com/deepimagej/imagej-macros/blob/648caa867f6ccb459649d4d3799efa1e2e0c5204/StarDist2D_Post-processing.ijm; // Please cite the respective contributions when using this code.; //*******************************************************************; // Macro to run StarDist postprocessing on 2D images.; // StarDist and deepImageJ plugins need to be installed.; // The macro assumes that the image to process is a stack in which; // the first channel corresponds to the object probability map; // and the remaining channels are the radial distances from each; // pixel to the object boundary.; //*******************************************************************. // Get the name of the image to call it; getDimensions(width, height, channels, slices, frames);; name=getTitle();. probThresh={probThresh};; nmsThresh={nmsThresh};. // Isolate the detection probability scores; run(""Make Substack..."", ""channels=1"");; rename(""scores"");. // Isolate the oriented distances; run(""Fire"");; selectWindow(name);; run(""Delete Slice"", ""delete=channel"");; selectWindow(name);; run(""Properties..."", ""channels="" + maxOf(channels, slices) - 1 + "" slices=1 frames=1 pixel_width=1.0000 pixel_height=1.0000 voxel_depth=1.0000"");; rename(""distances"");; run(""royal"");. // Run StarDist plugin; run(""Command From Macro"", ""command=[de.csbdresden.stardist.StarDist2DNMS], args=['prob':'scores', 'dist':'distances', 'probThresh':'"" + probThresh + ""', 'nmsThresh':'"" + nmsThresh + ""', 'outputType':'Both', 'excludeBoundary':'2', 'roiPosition':'Stack', 'verbose':'false'], process=[false]"");; """"""",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:1116,Safety,detect,detection,1116,"""""""; //*******************************************************************; // Date: July-2021; // Credits: StarDist, DeepImageJ; // URL:; // https://github.com/stardist/stardist; // https://deepimagej.github.io/deepimagej; // This macro was adapted from; // https://github.com/deepimagej/imagej-macros/blob/648caa867f6ccb459649d4d3799efa1e2e0c5204/StarDist2D_Post-processing.ijm; // Please cite the respective contributions when using this code.; //*******************************************************************; // Macro to run StarDist postprocessing on 2D images.; // StarDist and deepImageJ plugins need to be installed.; // The macro assumes that the image to process is a stack in which; // the first channel corresponds to the object probability map; // and the remaining channels are the radial distances from each; // pixel to the object boundary.; //*******************************************************************. // Get the name of the image to call it; getDimensions(width, height, channels, slices, frames);; name=getTitle();. probThresh={probThresh};; nmsThresh={nmsThresh};. // Isolate the detection probability scores; run(""Make Substack..."", ""channels=1"");; rename(""scores"");. // Isolate the oriented distances; run(""Fire"");; selectWindow(name);; run(""Delete Slice"", ""delete=channel"");; selectWindow(name);; run(""Properties..."", ""channels="" + maxOf(channels, slices) - 1 + "" slices=1 frames=1 pixel_width=1.0000 pixel_height=1.0000 voxel_depth=1.0000"");; rename(""distances"");; run(""royal"");. // Run StarDist plugin; run(""Command From Macro"", ""command=[de.csbdresden.stardist.StarDist2DNMS], args=['prob':'scores', 'dist':'distances', 'probThresh':'"" + probThresh + ""', 'nmsThresh':'"" + nmsThresh + ""', 'outputType':'Both', 'excludeBoundary':'2', 'roiPosition':'Stack', 'verbose':'false'], process=[false]"");; """"""",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:2,Integrability,depend,dependencies,2,"# dependencies that start with the name ""bioimageio"" will be added as conda dependencies",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:76,Integrability,depend,dependencies,76,"# dependencies that start with the name ""bioimageio"" will be added as conda dependencies",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:38,Integrability,depend,dependencies,38,"# only stardist and tensorflow as pip dependencies",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:1279,Integrability,depend,dependencies,1279,"""""""Export stardist model into bioimage.io format, https://github.com/bioimage-io/spec-bioimage-io. Parameters; ----------; model: StarDist2D, StarDist3D; the model to convert; outpath: str, Path; where to save the model; test_input: np.ndarray; input image for generating test data; test_input_axes: str or None; the axes of the test input, for example 'YX' for a 2d image or 'ZYX' for a 3d volume; using None assumes that axes of test_input are the same as those of model; test_input_norm_axes: str; the axes of the test input which will be jointly normalized, for example 'ZYX' for all spatial dimensions ('Z' ignored for 2D input); use 'ZYXC' to also jointly normalize channels (e.g. for RGB input images); name: str; the name of this model (default: None); if None, uses the (folder) name of the model (i.e. `model.name`); mode: str; the export type for this model (default: ""tensorflow_saved_model_bundle""); min_percentile: float; min percentile to be used for image normalization (default: 1.0); max_percentile: float; max percentile to be used for image normalization (default: 99.8); overwrite_spec_kwargs: dict or None; spec keywords that should be overloaded (default: None); generate_default_deps: bool; not required for bioimage.io, i.e. StarDist models don't need a dependencies field in rdf.yaml (default: False); if True, generate an environment.yaml file recording the python, bioimageio.core, stardist and tensorflow requirements; from which a conda environment can be recreated to run this export; """"""",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:272,Testability,test,test,272,"""""""Export stardist model into bioimage.io format, https://github.com/bioimage-io/spec-bioimage-io. Parameters; ----------; model: StarDist2D, StarDist3D; the model to convert; outpath: str, Path; where to save the model; test_input: np.ndarray; input image for generating test data; test_input_axes: str or None; the axes of the test input, for example 'YX' for a 2d image or 'ZYX' for a 3d volume; using None assumes that axes of test_input are the same as those of model; test_input_norm_axes: str; the axes of the test input which will be jointly normalized, for example 'ZYX' for all spatial dimensions ('Z' ignored for 2D input); use 'ZYXC' to also jointly normalize channels (e.g. for RGB input images); name: str; the name of this model (default: None); if None, uses the (folder) name of the model (i.e. `model.name`); mode: str; the export type for this model (default: ""tensorflow_saved_model_bundle""); min_percentile: float; min percentile to be used for image normalization (default: 1.0); max_percentile: float; max percentile to be used for image normalization (default: 99.8); overwrite_spec_kwargs: dict or None; spec keywords that should be overloaded (default: None); generate_default_deps: bool; not required for bioimage.io, i.e. StarDist models don't need a dependencies field in rdf.yaml (default: False); if True, generate an environment.yaml file recording the python, bioimageio.core, stardist and tensorflow requirements; from which a conda environment can be recreated to run this export; """"""",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:329,Testability,test,test,329,"""""""Export stardist model into bioimage.io format, https://github.com/bioimage-io/spec-bioimage-io. Parameters; ----------; model: StarDist2D, StarDist3D; the model to convert; outpath: str, Path; where to save the model; test_input: np.ndarray; input image for generating test data; test_input_axes: str or None; the axes of the test input, for example 'YX' for a 2d image or 'ZYX' for a 3d volume; using None assumes that axes of test_input are the same as those of model; test_input_norm_axes: str; the axes of the test input which will be jointly normalized, for example 'ZYX' for all spatial dimensions ('Z' ignored for 2D input); use 'ZYXC' to also jointly normalize channels (e.g. for RGB input images); name: str; the name of this model (default: None); if None, uses the (folder) name of the model (i.e. `model.name`); mode: str; the export type for this model (default: ""tensorflow_saved_model_bundle""); min_percentile: float; min percentile to be used for image normalization (default: 1.0); max_percentile: float; max percentile to be used for image normalization (default: 99.8); overwrite_spec_kwargs: dict or None; spec keywords that should be overloaded (default: None); generate_default_deps: bool; not required for bioimage.io, i.e. StarDist models don't need a dependencies field in rdf.yaml (default: False); if True, generate an environment.yaml file recording the python, bioimageio.core, stardist and tensorflow requirements; from which a conda environment can be recreated to run this export; """"""",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:517,Testability,test,test,517,"""""""Export stardist model into bioimage.io format, https://github.com/bioimage-io/spec-bioimage-io. Parameters; ----------; model: StarDist2D, StarDist3D; the model to convert; outpath: str, Path; where to save the model; test_input: np.ndarray; input image for generating test data; test_input_axes: str or None; the axes of the test input, for example 'YX' for a 2d image or 'ZYX' for a 3d volume; using None assumes that axes of test_input are the same as those of model; test_input_norm_axes: str; the axes of the test input which will be jointly normalized, for example 'ZYX' for all spatial dimensions ('Z' ignored for 2D input); use 'ZYXC' to also jointly normalize channels (e.g. for RGB input images); name: str; the name of this model (default: None); if None, uses the (folder) name of the model (i.e. `model.name`); mode: str; the export type for this model (default: ""tensorflow_saved_model_bundle""); min_percentile: float; min percentile to be used for image normalization (default: 1.0); max_percentile: float; max percentile to be used for image normalization (default: 99.8); overwrite_spec_kwargs: dict or None; spec keywords that should be overloaded (default: None); generate_default_deps: bool; not required for bioimage.io, i.e. StarDist models don't need a dependencies field in rdf.yaml (default: False); if True, generate an environment.yaml file recording the python, bioimageio.core, stardist and tensorflow requirements; from which a conda environment can be recreated to run this export; """"""",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:501,Performance,load,loaded,501,"""""""Import stardist model from bioimage.io format, https://github.com/bioimage-io/spec-bioimage-io. Load a model in bioimage.io format from the given `source` (e.g. path to zip file, URL); and convert it to a regular stardist model, which will be saved in the folder `outpath`. Parameters; ----------; source: str, Path; bioimage.io resource (e.g. path, URL); outpath: str, Path; folder to save the stardist model (must not exist previously). Returns; -------; StarDist2D or StarDist3D; stardist model loaded from `outpath`. """"""",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:2,Availability,down,download,2,"# download the full model content to a temporary folder",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:11,Modifiability,config,config,11,"# save the config and threshold to json, and weights to hdf5 to enable loading as stardist model; # copy bioimageio files to separate sub-folder",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py:71,Performance,load,loading,71,"# save the config and threshold to json, and weights to hdf5 to enable loading as stardist model; # copy bioimageio files to separate sub-folder",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py:14,Safety,safe,safe,14,"""""""computes a safe divide which returns 0 if y is zero""""""",MatchSource.CODE_COMMENT,stardist/matching.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py:13,Safety,detect,detection,13,"""""""Calculate detection/instance segmentation metrics between ground truth and predicted label images. Currently, the following metrics are implemented:. 'fp', 'tp', 'fn', 'precision', 'recall', 'accuracy', 'f1', 'criterion', 'thresh', 'n_true', 'n_pred', 'mean_true_score', 'mean_matched_score', 'panoptic_quality'. Corresponding objects of y_true and y_pred are counted as true positives (tp), false positives (fp), and false negatives (fn); whether their intersection over union (IoU) >= thresh (for criterion='iou', which can be changed). * mean_matched_score is the mean IoUs of matched true positives. * mean_true_score is the mean IoUs of matched true positives but normalized by the total number of GT objects. * panoptic_quality defined as in Eq. 1 of Kirillov et al. ""Panoptic Segmentation"", CVPR 2019. Parameters; ----------; y_true: ndarray; ground truth label image (integer valued); y_pred: ndarray; predicted label image (integer valued); thresh: float; threshold for matching criterion (default 0.5); criterion: string; matching criterion (default IoU); report_matches: bool; if True, additionally calculate matched_pairs and matched_scores (note, that this returns even gt-pred pairs whose scores are below 'thresh'). Returns; -------; Matching object with different metrics as attributes. Examples; --------; >>> y_true = np.zeros((100,100), np.uint16); >>> y_true[10:20,10:20] = 1; >>> y_pred = np.roll(y_true,5,axis = 0). >>> stats = matching(y_true, y_pred); >>> print(stats); Matching(criterion='iou', thresh=0.5, fp=1, tp=0, fn=1, precision=0, recall=0, accuracy=0, f1=0, n_true=1, n_pred=1, mean_true_score=0.0, mean_matched_score=0.0, panoptic_quality=0.0). """"""",MatchSource.CODE_COMMENT,stardist/matching.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py:78,Safety,predict,predicted,78,"""""""Calculate detection/instance segmentation metrics between ground truth and predicted label images. Currently, the following metrics are implemented:. 'fp', 'tp', 'fn', 'precision', 'recall', 'accuracy', 'f1', 'criterion', 'thresh', 'n_true', 'n_pred', 'mean_true_score', 'mean_matched_score', 'panoptic_quality'. Corresponding objects of y_true and y_pred are counted as true positives (tp), false positives (fp), and false negatives (fn); whether their intersection over union (IoU) >= thresh (for criterion='iou', which can be changed). * mean_matched_score is the mean IoUs of matched true positives. * mean_true_score is the mean IoUs of matched true positives but normalized by the total number of GT objects. * panoptic_quality defined as in Eq. 1 of Kirillov et al. ""Panoptic Segmentation"", CVPR 2019. Parameters; ----------; y_true: ndarray; ground truth label image (integer valued); y_pred: ndarray; predicted label image (integer valued); thresh: float; threshold for matching criterion (default 0.5); criterion: string; matching criterion (default IoU); report_matches: bool; if True, additionally calculate matched_pairs and matched_scores (note, that this returns even gt-pred pairs whose scores are below 'thresh'). Returns; -------; Matching object with different metrics as attributes. Examples; --------; >>> y_true = np.zeros((100,100), np.uint16); >>> y_true[10:20,10:20] = 1; >>> y_pred = np.roll(y_true,5,axis = 0). >>> stats = matching(y_true, y_pred); >>> print(stats); Matching(criterion='iou', thresh=0.5, fp=1, tp=0, fn=1, precision=0, recall=0, accuracy=0, f1=0, n_true=1, n_pred=1, mean_true_score=0.0, mean_matched_score=0.0, panoptic_quality=0.0). """"""",MatchSource.CODE_COMMENT,stardist/matching.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py:913,Safety,predict,predicted,913,"""""""Calculate detection/instance segmentation metrics between ground truth and predicted label images. Currently, the following metrics are implemented:. 'fp', 'tp', 'fn', 'precision', 'recall', 'accuracy', 'f1', 'criterion', 'thresh', 'n_true', 'n_pred', 'mean_true_score', 'mean_matched_score', 'panoptic_quality'. Corresponding objects of y_true and y_pred are counted as true positives (tp), false positives (fp), and false negatives (fn); whether their intersection over union (IoU) >= thresh (for criterion='iou', which can be changed). * mean_matched_score is the mean IoUs of matched true positives. * mean_true_score is the mean IoUs of matched true positives but normalized by the total number of GT objects. * panoptic_quality defined as in Eq. 1 of Kirillov et al. ""Panoptic Segmentation"", CVPR 2019. Parameters; ----------; y_true: ndarray; ground truth label image (integer valued); y_pred: ndarray; predicted label image (integer valued); thresh: float; threshold for matching criterion (default 0.5); criterion: string; matching criterion (default IoU); report_matches: bool; if True, additionally calculate matched_pairs and matched_scores (note, that this returns even gt-pred pairs whose scores are below 'thresh'). Returns; -------; Matching object with different metrics as attributes. Examples; --------; >>> y_true = np.zeros((100,100), np.uint16); >>> y_true[10:20,10:20] = 1; >>> y_pred = np.roll(y_true,5,axis = 0). >>> stats = matching(y_true, y_pred); >>> print(stats); Matching(criterion='iou', thresh=0.5, fp=1, tp=0, fn=1, precision=0, recall=0, accuracy=0, f1=0, n_true=1, n_pred=1, mean_true_score=0.0, mean_matched_score=0.0, panoptic_quality=0.0). """"""",MatchSource.CODE_COMMENT,stardist/matching.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py:2,Testability,assert,assert,2,"# assert tp+fp == n_pred; # assert tp+fn == n_true; # the score sum over all matched objects (tp)",MatchSource.CODE_COMMENT,stardist/matching.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py:28,Testability,assert,assert,28,"# assert tp+fp == n_pred; # assert tp+fn == n_true; # the score sum over all matched objects (tp)",MatchSource.CODE_COMMENT,stardist/matching.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py:65,Deployability,release,release,65,"# copied from scikit-image master for now (remove when part of a release)",MatchSource.CODE_COMMENT,stardist/matching.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py:156,Energy Efficiency,reduce,reduced,156,"""""""Relabel arbitrary labels to {`offset`, ... `offset` + number_of_labels}. This function also returns the forward map (mapping the original labels to; the reduced labels) and the inverse map (mapping the reduced labels back; to the original ones). Parameters; ----------; label_field : numpy array of int, arbitrary shape; An array of labels, which must be non-negative integers.; offset : int, optional; The return labels will start at `offset`, which should be; strictly positive. Returns; -------; relabeled : numpy array of int, same shape as `label_field`; The input label field with labels mapped to; {offset, ..., number_of_labels + offset - 1}.; The data type will be the same as `label_field`, except when; offset + number_of_labels causes overflow of the current data type.; forward_map : numpy array of int, shape ``(label_field.max() + 1,)``; The map from the original label space to the returned label; space. Can be used to re-apply the same mapping. See examples; for usage. The data type will be the same as `relabeled`.; inverse_map : 1D numpy array of int, of length offset + number of labels; The map from the new label space to the original space. This; can be used to reconstruct the original label field from the; relabeled one. The data type will be the same as `relabeled`. Notes; -----; The label 0 is assumed to denote the background and is never remapped. The forward map can be extremely big for some inputs, since its; length is given by the maximum of the label field. However, in most; situations, ``label_field.max()`` is much smaller than; ``label_field.size``, and in these cases the forward map is; guaranteed to be smaller than either the input or output images. Examples; --------; >>> from skimage.segmentation import relabel_sequential; >>> label_field = np.array([1, 1, 5, 5, 8, 99, 42]); >>> relab, fw, inv = relabel_sequential(label_field); >>> relab; array([1, 1, 2, 2, 3, 5, 4]); >>> fw; array([0, 1, 0, 0, 0, 2, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0",MatchSource.CODE_COMMENT,stardist/matching.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py:205,Energy Efficiency,reduce,reduced,205,"""""""Relabel arbitrary labels to {`offset`, ... `offset` + number_of_labels}. This function also returns the forward map (mapping the original labels to; the reduced labels) and the inverse map (mapping the reduced labels back; to the original ones). Parameters; ----------; label_field : numpy array of int, arbitrary shape; An array of labels, which must be non-negative integers.; offset : int, optional; The return labels will start at `offset`, which should be; strictly positive. Returns; -------; relabeled : numpy array of int, same shape as `label_field`; The input label field with labels mapped to; {offset, ..., number_of_labels + offset - 1}.; The data type will be the same as `label_field`, except when; offset + number_of_labels causes overflow of the current data type.; forward_map : numpy array of int, shape ``(label_field.max() + 1,)``; The map from the original label space to the returned label; space. Can be used to re-apply the same mapping. See examples; for usage. The data type will be the same as `relabeled`.; inverse_map : 1D numpy array of int, of length offset + number of labels; The map from the new label space to the original space. This; can be used to reconstruct the original label field from the; relabeled one. The data type will be the same as `relabeled`. Notes; -----; The label 0 is assumed to denote the background and is never remapped. The forward map can be extremely big for some inputs, since its; length is given by the maximum of the label field. However, in most; situations, ``label_field.max()`` is much smaller than; ``label_field.size``, and in these cases the forward map is; guaranteed to be smaller than either the input or output images. Examples; --------; >>> from skimage.segmentation import relabel_sequential; >>> label_field = np.array([1, 1, 5, 5, 8, 99, 42]); >>> relab, fw, inv = relabel_sequential(label_field); >>> relab; array([1, 1, 2, 2, 3, 5, 4]); >>> fw; array([0, 1, 0, 0, 0, 2, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0",MatchSource.CODE_COMMENT,stardist/matching.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/nms.py:57,Safety,predict,prediction,57,"""""""2D coordinates of the polys that survive from a given prediction (prob, coord). prob.shape = (Ny,Nx); coord.shape = (Ny,Nx,2,n_rays). b: don't use pixel closer than b pixels to the image boundary. returns retained points; """"""",MatchSource.CODE_COMMENT,stardist/nms.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/nms.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/nms.py:2,Availability,mask,mask,2,"# mask = prob > prob_thresh; # if b is not None and b > 0:; # _mask = np.zeros_like(mask); # _mask[b:-b,b:-b] = True; # mask &= _mask",MatchSource.CODE_COMMENT,stardist/nms.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/nms.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/nms.py:84,Availability,mask,mask,84,"# mask = prob > prob_thresh; # if b is not None and b > 0:; # _mask = np.zeros_like(mask); # _mask[b:-b,b:-b] = True; # mask &= _mask",MatchSource.CODE_COMMENT,stardist/nms.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/nms.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/nms.py:120,Availability,mask,mask,120,"# mask = prob > prob_thresh; # if b is not None and b > 0:; # _mask = np.zeros_like(mask); # _mask[b:-b,b:-b] = True; # mask &= _mask",MatchSource.CODE_COMMENT,stardist/nms.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/nms.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/nms.py:2,Availability,mask,mask,2,"# mask = prob > prob_thresh; # if b is not None and b > 0:; # _mask = np.zeros_like(mask); # _mask[b:-b,b:-b] = True; # mask &= _mask",MatchSource.CODE_COMMENT,stardist/nms.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/nms.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/nms.py:84,Availability,mask,mask,84,"# mask = prob > prob_thresh; # if b is not None and b > 0:; # _mask = np.zeros_like(mask); # _mask[b:-b,b:-b] = True; # mask &= _mask",MatchSource.CODE_COMMENT,stardist/nms.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/nms.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/nms.py:120,Availability,mask,mask,120,"# mask = prob > prob_thresh; # if b is not None and b > 0:; # _mask = np.zeros_like(mask); # _mask[b:-b,b:-b] = True; # mask &= _mask",MatchSource.CODE_COMMENT,stardist/nms.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/nms.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/sample_patches.py:3,Performance,optimiz,optimized,3,"""""""optimized version of csbdeep.data.sample_patches_from_multiple_stacks; """"""",MatchSource.CODE_COMMENT,stardist/sample_patches.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/sample_patches.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/sample_patches.py:150,Availability,mask,mask,150,"""""""; Returns all indices of an image that ; - can be used as center points for sampling patches of a given patch_size, and; - are part of the boolean mask given by the function patch_filter (if provided). img: np.ndarray; patch_size: tuple of ints ; the width of patches per img dimension, ; patch_filter: None or callable; a function with signature patch_filter(img, patch_size) returning a boolean mask ; """"""",MatchSource.CODE_COMMENT,stardist/sample_patches.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/sample_patches.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/sample_patches.py:400,Availability,mask,mask,400,"""""""; Returns all indices of an image that ; - can be used as center points for sampling patches of a given patch_size, and; - are part of the boolean mask given by the function patch_filter (if provided). img: np.ndarray; patch_size: tuple of ints ; the width of patches per img dimension, ; patch_filter: None or callable; a function with signature patch_filter(img, patch_size) returning a boolean mask ; """"""",MatchSource.CODE_COMMENT,stardist/sample_patches.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/sample_patches.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/sample_patches.py:88,Deployability,patch,patches,88,"""""""; Returns all indices of an image that ; - can be used as center points for sampling patches of a given patch_size, and; - are part of the boolean mask given by the function patch_filter (if provided). img: np.ndarray; patch_size: tuple of ints ; the width of patches per img dimension, ; patch_filter: None or callable; a function with signature patch_filter(img, patch_size) returning a boolean mask ; """"""",MatchSource.CODE_COMMENT,stardist/sample_patches.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/sample_patches.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/sample_patches.py:263,Deployability,patch,patches,263,"""""""; Returns all indices of an image that ; - can be used as center points for sampling patches of a given patch_size, and; - are part of the boolean mask given by the function patch_filter (if provided). img: np.ndarray; patch_size: tuple of ints ; the width of patches per img dimension, ; patch_filter: None or callable; a function with signature patch_filter(img, patch_size) returning a boolean mask ; """"""",MatchSource.CODE_COMMENT,stardist/sample_patches.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/sample_patches.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py:58,Deployability,install,installing,58,"# warnings.warn(""Could not find package edt... \nConsider installing it with \n pip install edt\nto improve training data generation performance."")",MatchSource.CODE_COMMENT,stardist/utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py:84,Deployability,install,install,84,"# warnings.warn(""Could not find package edt... \nConsider installing it with \n pip install edt\nto improve training data generation performance."")",MatchSource.CODE_COMMENT,stardist/utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py:133,Performance,perform,performance,133,"# warnings.warn(""Could not find package edt... \nConsider installing it with \n pip install edt\nto improve training data generation performance."")",MatchSource.CODE_COMMENT,stardist/utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py:58,Deployability,install,installing,58,"# warnings.warn(""Could not find package edt... \nConsider installing it with \n pip install edt\nto improve training data generation performance."")",MatchSource.CODE_COMMENT,stardist/utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py:84,Deployability,install,install,84,"# warnings.warn(""Could not find package edt... \nConsider installing it with \n pip install edt\nto improve training data generation performance."")",MatchSource.CODE_COMMENT,stardist/utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py:133,Performance,perform,performance,133,"# warnings.warn(""Could not find package edt... \nConsider installing it with \n pip install edt\nto improve training data generation performance."")",MatchSource.CODE_COMMENT,stardist/utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py:73,Performance,perform,perform,73,"# 1. grow object slice by 1 for all interior object bounding boxes; # 2. perform (correct) EDT for object with label id i; # 3. extract EDT for object of original slice and normalize; # 4. store edt for object only for pixels of given label id i",MatchSource.CODE_COMMENT,stardist/utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py:8,Modifiability,refactor,refactor,8,"# TODO: refactor 'fill_label_holes' and 'edt_prob' to share code",MatchSource.CODE_COMMENT,stardist/utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py:54,Availability,reliab,reliable,54,"# ignore image boundary, since predictions may not be reliable",MatchSource.CODE_COMMENT,stardist/utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py:31,Safety,predict,predictions,31,"# ignore image boundary, since predictions may not be reliable",MatchSource.CODE_COMMENT,stardist/utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/__init__.py:27,Security,expose,expose,27,"# TODO: which functions to expose here? all?",MatchSource.CODE_COMMENT,stardist/__init__.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/__init__.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/data/__init__.py:38,Availability,mask,mask,38,""""""" Fluorescence microscopy image and mask from the 2018 kaggle DSB challenge. Caicedo et al. ""Nucleus segmentation across imaging experiments: the 2018 Data Science Bowl."" Nature methods 16.12; """"""",MatchSource.CODE_COMMENT,stardist/data/__init__.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/data/__init__.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/geometry/geom3d.py:756,Integrability,message,messages,756,"""""""; creates labeled image from stardist representations. :param dist: array of shape (n_points,n_rays); the list of distances for each point and ray; :param points: array of shape (n_points, 3); the list of center points; :param rays: Rays object; Ray object (e.g. `stardist.Rays_GoldenSpiral`) defining; vertices and faces; :param shape: (nz,ny,nx); output shape of the image; :param prob: array of length/shape (n_points,) or None; probability per polyhedron; :param thr: scalar; probability threshold (only polyhedra with prob>thr are labeled); :param labels: array of length/shape (n_points,) or None; labels to use; :param mode: str; labeling mode, can be ""full"", ""kernel"", ""hull"", ""bbox"" or ""debug""; :param verbose: bool; enable to print some debug messages; :param overlap_label: scalar or None; if given, will label each pixel that belongs ot more than one polyhedron with that label; :return: array of given shape; labeled image; """"""",MatchSource.CODE_COMMENT,stardist/geometry/geom3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/geometry/geom3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:2,Safety,sanity check,sanity checks,2,"# sanity checks",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:23,Availability,avail,available,23,"# no foreground pixels available",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:494,Modifiability,config,config,494,"""""""Prepare for neural network training. Compiles the model and creates; `Keras Callbacks <https://keras.io/callbacks/>`_ to be used for training. Note that this method will be implicitly called once by :func:`train`; (with default arguments) if not done so explicitly beforehand. Parameters; ----------; optimizer : obj or None; Instance of a `Keras Optimizer <https://keras.io/optimizers/>`_ to be used for training.; If ``None`` (default), uses ``Adam`` with the learning rate specified in ``config``. """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:304,Performance,optimiz,optimizer,304,"""""""Prepare for neural network training. Compiles the model and creates; `Keras Callbacks <https://keras.io/callbacks/>`_ to be used for training. Note that this method will be implicitly called once by :func:`train`; (with default arguments) if not done so explicitly beforehand. Parameters; ----------; optimizer : obj or None; Instance of a `Keras Optimizer <https://keras.io/optimizers/>`_ to be used for training.; If ``None`` (default), uses ``Adam`` with the learning rate specified in ``config``. """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:378,Performance,optimiz,optimizers,378,"""""""Prepare for neural network training. Compiles the model and creates; `Keras Callbacks <https://keras.io/callbacks/>`_ to be used for training. Note that this method will be implicitly called once by :func:`train`; (with default arguments) if not done so explicitly beforehand. Parameters; ----------; optimizer : obj or None; Instance of a `Keras Optimizer <https://keras.io/optimizers/>`_ to be used for training.; If ``None`` (default), uses ``Adam`` with the learning rate specified in ``config``. """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:465,Usability,learn,learning,465,"""""""Prepare for neural network training. Compiles the model and creates; `Keras Callbacks <https://keras.io/callbacks/>`_ to be used for training. Note that this method will be implicitly called once by :func:`train`; (with default arguments) if not done so explicitly beforehand. Parameters; ----------; optimizer : obj or None; Instance of a `Keras Optimizer <https://keras.io/optimizers/>`_ to be used for training.; If ``None`` (default), uses ``Adam`` with the learning rate specified in ``config``. """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:48,Testability,log,logs,48,"# TF2: add as first callback to put 'lr' in the logs for TensorBoard",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:31,Safety,predict,predict,31,""""""" Shared setup code between `predict` and `predict_sparse` """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:440,Availability,error,errors,440,"""""""Predict. Parameters; ----------; img : :class:`numpy.ndarray`; Input image; axes : str or None; Axes of the input ``img``.; ``None`` denotes that axes of img are the same as denoted in the config.; normalizer : :class:`csbdeep.data.Normalizer` or None; (Optional) normalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool or callable; If boolean, indicates whether to show progress (via tqdm) during tiled prediction.; If callable, must be a drop-in replacement for tqdm.; show_tile_progress: bool; Whether to show progress during tiled prediction.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model. Returns; -------; (:class:`numpy.ndarray`, :class:`numpy.ndarray`, [:class:`numpy.ndarray`]); Returns the tuple (`prob`, `dist`, [`prob_class`]) of per-pixel object probabilities and star-convex polygon/polyhedra distances.; In multiclass prediction mode, `prob_class` is the probability map for each of the 1+'n_classes' classes (first class is background). """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:192,Modifiability,config,config,192,"""""""Predict. Parameters; ----------; img : :class:`numpy.ndarray`; Input image; axes : str or None; Axes of the input ``img``.; ``None`` denotes that axes of img are the same as denoted in the config.; normalizer : :class:`csbdeep.data.Normalizer` or None; (Optional) normalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool or callable; If boolean, indicates whether to show progress (via tqdm) during tiled prediction.; If callable, must be a drop-in replacement for tqdm.; show_tile_progress: bool; Whether to show progress during tiled prediction.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model. Returns; -------; (:class:`numpy.ndarray`, :class:`numpy.ndarray`, [:class:`numpy.ndarray`]); Returns the tuple (`prob`, `dist`, [`prob_class`]) of per-pixel object probabilities and star-convex polygon/polyhedra distances.; In multiclass prediction mode, `prob_class` is the probability map for each of the 1+'n_classes' classes (first class is background). """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:303,Safety,predict,prediction,303,"""""""Predict. Parameters; ----------; img : :class:`numpy.ndarray`; Input image; axes : str or None; Axes of the input ``img``.; ``None`` denotes that axes of img are the same as denoted in the config.; normalizer : :class:`csbdeep.data.Normalizer` or None; (Optional) normalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool or callable; If boolean, indicates whether to show progress (via tqdm) during tiled prediction.; If callable, must be a drop-in replacement for tqdm.; show_tile_progress: bool; Whether to show progress during tiled prediction.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model. Returns; -------; (:class:`numpy.ndarray`, :class:`numpy.ndarray`, [:class:`numpy.ndarray`]); Returns the tuple (`prob`, `dist`, [`prob_class`]) of per-pixel object probabilities and star-convex polygon/polyhedra distances.; In multiclass prediction mode, `prob_class` is the probability map for each of the 1+'n_classes' classes (first class is background). """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:494,Safety,avoid,avoid,494,"""""""Predict. Parameters; ----------; img : :class:`numpy.ndarray`; Input image; axes : str or None; Axes of the input ``img``.; ``None`` denotes that axes of img are the same as denoted in the config.; normalizer : :class:`csbdeep.data.Normalizer` or None; (Optional) normalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool or callable; If boolean, indicates whether to show progress (via tqdm) during tiled prediction.; If callable, must be a drop-in replacement for tqdm.; show_tile_progress: bool; Whether to show progress during tiled prediction.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model. Returns; -------; (:class:`numpy.ndarray`, :class:`numpy.ndarray`, [:class:`numpy.ndarray`]); Returns the tuple (`prob`, `dist`, [`prob_class`]) of per-pixel object probabilities and star-convex polygon/polyhedra distances.; In multiclass prediction mode, `prob_class` is the probability map for each of the 1+'n_classes' classes (first class is background). """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:871,Safety,predict,prediction,871,"""""""Predict. Parameters; ----------; img : :class:`numpy.ndarray`; Input image; axes : str or None; Axes of the input ``img``.; ``None`` denotes that axes of img are the same as denoted in the config.; normalizer : :class:`csbdeep.data.Normalizer` or None; (Optional) normalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool or callable; If boolean, indicates whether to show progress (via tqdm) during tiled prediction.; If callable, must be a drop-in replacement for tqdm.; show_tile_progress: bool; Whether to show progress during tiled prediction.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model. Returns; -------; (:class:`numpy.ndarray`, :class:`numpy.ndarray`, [:class:`numpy.ndarray`]); Returns the tuple (`prob`, `dist`, [`prob_class`]) of per-pixel object probabilities and star-convex polygon/polyhedra distances.; In multiclass prediction mode, `prob_class` is the probability map for each of the 1+'n_classes' classes (first class is background). """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:1002,Safety,predict,prediction,1002,"""""""Predict. Parameters; ----------; img : :class:`numpy.ndarray`; Input image; axes : str or None; Axes of the input ``img``.; ``None`` denotes that axes of img are the same as denoted in the config.; normalizer : :class:`csbdeep.data.Normalizer` or None; (Optional) normalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool or callable; If boolean, indicates whether to show progress (via tqdm) during tiled prediction.; If callable, must be a drop-in replacement for tqdm.; show_tile_progress: bool; Whether to show progress during tiled prediction.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model. Returns; -------; (:class:`numpy.ndarray`, :class:`numpy.ndarray`, [:class:`numpy.ndarray`]); Returns the tuple (`prob`, `dist`, [`prob_class`]) of per-pixel object probabilities and star-convex polygon/polyhedra distances.; In multiclass prediction mode, `prob_class` is the probability map for each of the 1+'n_classes' classes (first class is background). """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:1061,Safety,predict,predict,1061,"""""""Predict. Parameters; ----------; img : :class:`numpy.ndarray`; Input image; axes : str or None; Axes of the input ``img``.; ``None`` denotes that axes of img are the same as denoted in the config.; normalizer : :class:`csbdeep.data.Normalizer` or None; (Optional) normalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool or callable; If boolean, indicates whether to show progress (via tqdm) during tiled prediction.; If callable, must be a drop-in replacement for tqdm.; show_tile_progress: bool; Whether to show progress during tiled prediction.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model. Returns; -------; (:class:`numpy.ndarray`, :class:`numpy.ndarray`, [:class:`numpy.ndarray`]); Returns the tuple (`prob`, `dist`, [`prob_class`]) of per-pixel object probabilities and star-convex polygon/polyhedra distances.; In multiclass prediction mode, `prob_class` is the probability map for each of the 1+'n_classes' classes (first class is background). """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:1335,Safety,predict,prediction,1335,"""""""Predict. Parameters; ----------; img : :class:`numpy.ndarray`; Input image; axes : str or None; Axes of the input ``img``.; ``None`` denotes that axes of img are the same as denoted in the config.; normalizer : :class:`csbdeep.data.Normalizer` or None; (Optional) normalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool or callable; If boolean, indicates whether to show progress (via tqdm) during tiled prediction.; If callable, must be a drop-in replacement for tqdm.; show_tile_progress: bool; Whether to show progress during tiled prediction.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model. Returns; -------; (:class:`numpy.ndarray`, :class:`numpy.ndarray`, [:class:`numpy.ndarray`]); Returns the tuple (`prob`, `dist`, [`prob_class`]) of per-pixel object probabilities and star-convex polygon/polyhedra distances.; In multiclass prediction mode, `prob_class` is the probability map for each of the 1+'n_classes' classes (first class is background). """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:2,Safety,avoid,avoid,2,"# avoid small dist values to prevent problems with Qhull",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:28,Safety,predict,predict,28,""""""" Sparse version of model.predict(); Returns; -------; (prob, dist, [prob_class], points) flat list of probs, dists, (optional prob_class) and points; """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:1308,Availability,error,errors,1308,"ormalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; sparse: bool; If true, aggregate probabilities/distances sparsely during tiled; prediction to save memory (recommended).; prob_thresh : float or None; Consider only object candidates from pixels with predicted object probability; above this threshold (also see `optimize_thresholds`).; nms_thresh : float or None; Perform non-maximum suppression that considers two objects to be the same; when their area/surface overlap exceeds this threshold (also see `optimize_thresholds`).; scale: None or float or iterable; Scale the input image internally by this factor and rescale the output accordingly.; All spatial axes (X,Y,Z) will be scaled if a scalar value is provided.; Alternatively, multiple scale values (compatible with input `axes`) can be used; for more fine-grained control (scale values for non-spatial axes must be 1).; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool; Whether to show progress during tiled prediction.; verbose: bool; Whether to print some info messages.; return_labels: bool; Whether to create a label image, otherwise return None in its place.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model.; nms_kwargs: dict; Keyword arguments for non-maximum suppression.; overlap_label: scalar or None; if not None, label the regions where polygons overlap with that value; return_predict: bool; Also return the outputs of :func:`predict` (in a separate tuple); If True, implies sparse = False. Returns; -------; (:class:`numpy.ndarray`, dict), (optional: return tuple of :func:`pr",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:1749,Integrability,message,messages,1749,"e probabilities/distances sparsely during tiled; prediction to save memory (recommended).; prob_thresh : float or None; Consider only object candidates from pixels with predicted object probability; above this threshold (also see `optimize_thresholds`).; nms_thresh : float or None; Perform non-maximum suppression that considers two objects to be the same; when their area/surface overlap exceeds this threshold (also see `optimize_thresholds`).; scale: None or float or iterable; Scale the input image internally by this factor and rescale the output accordingly.; All spatial axes (X,Y,Z) will be scaled if a scalar value is provided.; Alternatively, multiple scale values (compatible with input `axes`) can be used; for more fine-grained control (scale values for non-spatial axes must be 1).; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool; Whether to show progress during tiled prediction.; verbose: bool; Whether to print some info messages.; return_labels: bool; Whether to create a label image, otherwise return None in its place.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model.; nms_kwargs: dict; Keyword arguments for non-maximum suppression.; overlap_label: scalar or None; if not None, label the regions where polygons overlap with that value; return_predict: bool; Also return the outputs of :func:`predict` (in a separate tuple); If True, implies sparse = False. Returns; -------; (:class:`numpy.ndarray`, dict), (optional: return tuple of :func:`predict`); Returns a tuple of the label instances image and also; a dictionary with the details (coordinates, etc.) of all remaining polygons/polyhedra. """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:231,Modifiability,config,config,231,"""""""Predict instance segmentation from input image. Parameters; ----------; img : :class:`numpy.ndarray`; Input image; axes : str or None; Axes of the input ``img``.; ``None`` denotes that axes of img are the same as denoted in the config.; normalizer : :class:`csbdeep.data.Normalizer` or None; (Optional) normalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; sparse: bool; If true, aggregate probabilities/distances sparsely during tiled; prediction to save memory (recommended).; prob_thresh : float or None; Consider only object candidates from pixels with predicted object probability; above this threshold (also see `optimize_thresholds`).; nms_thresh : float or None; Perform non-maximum suppression that considers two objects to be the same; when their area/surface overlap exceeds this threshold (also see `optimize_thresholds`).; scale: None or float or iterable; Scale the input image internally by this factor and rescale the output accordingly.; All spatial axes (X,Y,Z) will be scaled if a scalar value is provided.; Alternatively, multiple scale values (compatible with input `axes`) can be used; for more fine-grained control (scale values for non-spatial axes must be 1).; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool; Whether to show progress during tiled prediction.; verbose: bool; Whether to print some info messages.; return_labels: bool; Whether to create a label image, otherwise return None in its place.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model.; nms_kwargs: dict; Keyword arguments for non-maximum suppression.; ov",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:342,Safety,predict,prediction,342,"""""""Predict instance segmentation from input image. Parameters; ----------; img : :class:`numpy.ndarray`; Input image; axes : str or None; Axes of the input ``img``.; ``None`` denotes that axes of img are the same as denoted in the config.; normalizer : :class:`csbdeep.data.Normalizer` or None; (Optional) normalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; sparse: bool; If true, aggregate probabilities/distances sparsely during tiled; prediction to save memory (recommended).; prob_thresh : float or None; Consider only object candidates from pixels with predicted object probability; above this threshold (also see `optimize_thresholds`).; nms_thresh : float or None; Perform non-maximum suppression that considers two objects to be the same; when their area/surface overlap exceeds this threshold (also see `optimize_thresholds`).; scale: None or float or iterable; Scale the input image internally by this factor and rescale the output accordingly.; All spatial axes (X,Y,Z) will be scaled if a scalar value is provided.; Alternatively, multiple scale values (compatible with input `axes`) can be used; for more fine-grained control (scale values for non-spatial axes must be 1).; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool; Whether to show progress during tiled prediction.; verbose: bool; Whether to print some info messages.; return_labels: bool; Whether to create a label image, otherwise return None in its place.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model.; nms_kwargs: dict; Keyword arguments for non-maximum suppression.; ov",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:511,Safety,predict,prediction,511,"""""""Predict instance segmentation from input image. Parameters; ----------; img : :class:`numpy.ndarray`; Input image; axes : str or None; Axes of the input ``img``.; ``None`` denotes that axes of img are the same as denoted in the config.; normalizer : :class:`csbdeep.data.Normalizer` or None; (Optional) normalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; sparse: bool; If true, aggregate probabilities/distances sparsely during tiled; prediction to save memory (recommended).; prob_thresh : float or None; Consider only object candidates from pixels with predicted object probability; above this threshold (also see `optimize_thresholds`).; nms_thresh : float or None; Perform non-maximum suppression that considers two objects to be the same; when their area/surface overlap exceeds this threshold (also see `optimize_thresholds`).; scale: None or float or iterable; Scale the input image internally by this factor and rescale the output accordingly.; All spatial axes (X,Y,Z) will be scaled if a scalar value is provided.; Alternatively, multiple scale values (compatible with input `axes`) can be used; for more fine-grained control (scale values for non-spatial axes must be 1).; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool; Whether to show progress during tiled prediction.; verbose: bool; Whether to print some info messages.; return_labels: bool; Whether to create a label image, otherwise return None in its place.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model.; nms_kwargs: dict; Keyword arguments for non-maximum suppression.; ov",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:631,Safety,predict,predicted,631,"""""""Predict instance segmentation from input image. Parameters; ----------; img : :class:`numpy.ndarray`; Input image; axes : str or None; Axes of the input ``img``.; ``None`` denotes that axes of img are the same as denoted in the config.; normalizer : :class:`csbdeep.data.Normalizer` or None; (Optional) normalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; sparse: bool; If true, aggregate probabilities/distances sparsely during tiled; prediction to save memory (recommended).; prob_thresh : float or None; Consider only object candidates from pixels with predicted object probability; above this threshold (also see `optimize_thresholds`).; nms_thresh : float or None; Perform non-maximum suppression that considers two objects to be the same; when their area/surface overlap exceeds this threshold (also see `optimize_thresholds`).; scale: None or float or iterable; Scale the input image internally by this factor and rescale the output accordingly.; All spatial axes (X,Y,Z) will be scaled if a scalar value is provided.; Alternatively, multiple scale values (compatible with input `axes`) can be used; for more fine-grained control (scale values for non-spatial axes must be 1).; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool; Whether to show progress during tiled prediction.; verbose: bool; Whether to print some info messages.; return_labels: bool; Whether to create a label image, otherwise return None in its place.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model.; nms_kwargs: dict; Keyword arguments for non-maximum suppression.; ov",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:1362,Safety,avoid,avoid,1362,"alized.; sparse: bool; If true, aggregate probabilities/distances sparsely during tiled; prediction to save memory (recommended).; prob_thresh : float or None; Consider only object candidates from pixels with predicted object probability; above this threshold (also see `optimize_thresholds`).; nms_thresh : float or None; Perform non-maximum suppression that considers two objects to be the same; when their area/surface overlap exceeds this threshold (also see `optimize_thresholds`).; scale: None or float or iterable; Scale the input image internally by this factor and rescale the output accordingly.; All spatial axes (X,Y,Z) will be scaled if a scalar value is provided.; Alternatively, multiple scale values (compatible with input `axes`) can be used; for more fine-grained control (scale values for non-spatial axes must be 1).; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool; Whether to show progress during tiled prediction.; verbose: bool; Whether to print some info messages.; return_labels: bool; Whether to create a label image, otherwise return None in its place.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model.; nms_kwargs: dict; Keyword arguments for non-maximum suppression.; overlap_label: scalar or None; if not None, label the regions where polygons overlap with that value; return_predict: bool; Also return the outputs of :func:`predict` (in a separate tuple); If True, implies sparse = False. Returns; -------; (:class:`numpy.ndarray`, dict), (optional: return tuple of :func:`predict`); Returns a tuple of the label instances image and also; a dictionary with the details (coordinates, etc.) ",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:1694,Safety,predict,prediction,1694,"e probabilities/distances sparsely during tiled; prediction to save memory (recommended).; prob_thresh : float or None; Consider only object candidates from pixels with predicted object probability; above this threshold (also see `optimize_thresholds`).; nms_thresh : float or None; Perform non-maximum suppression that considers two objects to be the same; when their area/surface overlap exceeds this threshold (also see `optimize_thresholds`).; scale: None or float or iterable; Scale the input image internally by this factor and rescale the output accordingly.; All spatial axes (X,Y,Z) will be scaled if a scalar value is provided.; Alternatively, multiple scale values (compatible with input `axes`) can be used; for more fine-grained control (scale values for non-spatial axes must be 1).; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool; Whether to show progress during tiled prediction.; verbose: bool; Whether to print some info messages.; return_labels: bool; Whether to create a label image, otherwise return None in its place.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model.; nms_kwargs: dict; Keyword arguments for non-maximum suppression.; overlap_label: scalar or None; if not None, label the regions where polygons overlap with that value; return_predict: bool; Also return the outputs of :func:`predict` (in a separate tuple); If True, implies sparse = False. Returns; -------; (:class:`numpy.ndarray`, dict), (optional: return tuple of :func:`predict`); Returns a tuple of the label instances image and also; a dictionary with the details (coordinates, etc.) of all remaining polygons/polyhedra. """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:1897,Safety,predict,predict,1897,"e probabilities/distances sparsely during tiled; prediction to save memory (recommended).; prob_thresh : float or None; Consider only object candidates from pixels with predicted object probability; above this threshold (also see `optimize_thresholds`).; nms_thresh : float or None; Perform non-maximum suppression that considers two objects to be the same; when their area/surface overlap exceeds this threshold (also see `optimize_thresholds`).; scale: None or float or iterable; Scale the input image internally by this factor and rescale the output accordingly.; All spatial axes (X,Y,Z) will be scaled if a scalar value is provided.; Alternatively, multiple scale values (compatible with input `axes`) can be used; for more fine-grained control (scale values for non-spatial axes must be 1).; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool; Whether to show progress during tiled prediction.; verbose: bool; Whether to print some info messages.; return_labels: bool; Whether to create a label image, otherwise return None in its place.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model.; nms_kwargs: dict; Keyword arguments for non-maximum suppression.; overlap_label: scalar or None; if not None, label the regions where polygons overlap with that value; return_predict: bool; Also return the outputs of :func:`predict` (in a separate tuple); If True, implies sparse = False. Returns; -------; (:class:`numpy.ndarray`, dict), (optional: return tuple of :func:`predict`); Returns a tuple of the label instances image and also; a dictionary with the details (coordinates, etc.) of all remaining polygons/polyhedra. """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:2157,Safety,predict,predict,2157,"e probabilities/distances sparsely during tiled; prediction to save memory (recommended).; prob_thresh : float or None; Consider only object candidates from pixels with predicted object probability; above this threshold (also see `optimize_thresholds`).; nms_thresh : float or None; Perform non-maximum suppression that considers two objects to be the same; when their area/surface overlap exceeds this threshold (also see `optimize_thresholds`).; scale: None or float or iterable; Scale the input image internally by this factor and rescale the output accordingly.; All spatial axes (X,Y,Z) will be scaled if a scalar value is provided.; Alternatively, multiple scale values (compatible with input `axes`) can be used; for more fine-grained control (scale values for non-spatial axes must be 1).; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool; Whether to show progress during tiled prediction.; verbose: bool; Whether to print some info messages.; return_labels: bool; Whether to create a label image, otherwise return None in its place.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model.; nms_kwargs: dict; Keyword arguments for non-maximum suppression.; overlap_label: scalar or None; if not None, label the regions where polygons overlap with that value; return_predict: bool; Also return the outputs of :func:`predict` (in a separate tuple); If True, implies sparse = False. Returns; -------; (:class:`numpy.ndarray`, dict), (optional: return tuple of :func:`predict`); Returns a tuple of the label instances image and also; a dictionary with the details (coordinates, etc.) of all remaining polygons/polyhedra. """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:2306,Safety,predict,predict,2306,"e probabilities/distances sparsely during tiled; prediction to save memory (recommended).; prob_thresh : float or None; Consider only object candidates from pixels with predicted object probability; above this threshold (also see `optimize_thresholds`).; nms_thresh : float or None; Perform non-maximum suppression that considers two objects to be the same; when their area/surface overlap exceeds this threshold (also see `optimize_thresholds`).; scale: None or float or iterable; Scale the input image internally by this factor and rescale the output accordingly.; All spatial axes (X,Y,Z) will be scaled if a scalar value is provided.; Alternatively, multiple scale values (compatible with input `axes`) can be used; for more fine-grained control (scale values for non-spatial axes must be 1).; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool; Whether to show progress during tiled prediction.; verbose: bool; Whether to print some info messages.; return_labels: bool; Whether to create a label image, otherwise return None in its place.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model.; nms_kwargs: dict; Keyword arguments for non-maximum suppression.; overlap_label: scalar or None; if not None, label the regions where polygons overlap with that value; return_predict: bool; Also return the outputs of :func:`predict` (in a separate tuple); If True, implies sparse = False. Returns; -------; (:class:`numpy.ndarray`, dict), (optional: return tuple of :func:`predict`); Returns a tuple of the label instances image and also; a dictionary with the details (coordinates, etc.) of all remaining polygons/polyhedra. """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:16,Safety,predict,prediction,16,"# indicate that prediction is starting",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:393,Integrability,wrap,wraps,393,"# the reason why the actual computation happens as a generator function; # (in '_predict_instances_generator') is that the generator is called; # from the stardist napari plugin, which has its benefits regarding; # control flow and progress display. however, typical use cases should; # almost always use this function ('predict_instances'), and shouldn't; # even notice (thanks to @functools.wraps) that it wraps the generator; # function. note that similar reasoning applies to 'predict' and; # 'predict_sparse'.; # return last ""yield""ed value of generator",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:408,Integrability,wrap,wraps,408,"# the reason why the actual computation happens as a generator function; # (in '_predict_instances_generator') is that the generator is called; # from the stardist napari plugin, which has its benefits regarding; # control flow and progress display. however, typical use cases should; # almost always use this function ('predict_instances'), and shouldn't; # even notice (thanks to @functools.wraps) that it wraps the generator; # function. note that similar reasoning applies to 'predict' and; # 'predict_sparse'.; # return last ""yield""ed value of generator",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:171,Modifiability,plugin,plugin,171,"# the reason why the actual computation happens as a generator function; # (in '_predict_instances_generator') is that the generator is called; # from the stardist napari plugin, which has its benefits regarding; # control flow and progress display. however, typical use cases should; # almost always use this function ('predict_instances'), and shouldn't; # even notice (thanks to @functools.wraps) that it wraps the generator; # function. note that similar reasoning applies to 'predict' and; # 'predict_sparse'.; # return last ""yield""ed value of generator",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:481,Safety,predict,predict,481,"# the reason why the actual computation happens as a generator function; # (in '_predict_instances_generator') is that the generator is called; # from the stardist napari plugin, which has its benefits regarding; # control flow and progress display. however, typical use cases should; # almost always use this function ('predict_instances'), and shouldn't; # even notice (thanks to @functools.wraps) that it wraps the generator; # function. note that similar reasoning applies to 'predict' and; # 'predict_sparse'.; # return last ""yield""ed value of generator",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:507,Modifiability,config,config,507,"# def _predict_instances_old(self, img, axes=None, normalizer=None,; # sparse = False,; # prob_thresh=None, nms_thresh=None,; # n_tiles=None, show_tile_progress=True,; # verbose = False,; # predict_kwargs=None, nms_kwargs=None, overlap_label=None):; # """"""; # old version, should be removed....; # """"""; # if predict_kwargs is None:; # predict_kwargs = {}; # if nms_kwargs is None:; # nms_kwargs = {}; # nms_kwargs.setdefault(""verbose"", verbose); # _axes = self._normalize_axes(img, axes); # _axes_net = self.config.axes; # _permute_axes = self._make_permute_axes(_axes, _axes_net); # _shape_inst = tuple(s for s,a in zip(_permute_axes(img).shape, _axes_net) if a != 'C'); # res = self.predict(img, axes=axes, normalizer=normalizer,; # n_tiles=n_tiles,; # show_tile_progress=show_tile_progress,; # **predict_kwargs); # res = tuple(res) + (None,); # if self._is_multiclass():; # prob, dist, prob_class, points = res; # else:; # prob, dist, points = res; # prob_class = None; # return self._instances_from_prediction_old(_shape_inst, prob, dist,; # points = points,; # prob_class = prob_class,; # prob_thresh=prob_thresh,; # nms_thresh=nms_thresh,; # overlap_label=overlap_label,; # **nms_kwargs)",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:684,Safety,predict,predict,684,"# def _predict_instances_old(self, img, axes=None, normalizer=None,; # sparse = False,; # prob_thresh=None, nms_thresh=None,; # n_tiles=None, show_tile_progress=True,; # verbose = False,; # predict_kwargs=None, nms_kwargs=None, overlap_label=None):; # """"""; # old version, should be removed....; # """"""; # if predict_kwargs is None:; # predict_kwargs = {}; # if nms_kwargs is None:; # nms_kwargs = {}; # nms_kwargs.setdefault(""verbose"", verbose); # _axes = self._normalize_axes(img, axes); # _axes_net = self.config.axes; # _permute_axes = self._make_permute_axes(_axes, _axes_net); # _shape_inst = tuple(s for s,a in zip(_permute_axes(img).shape, _axes_net) if a != 'C'); # res = self.predict(img, axes=axes, normalizer=normalizer,; # n_tiles=n_tiles,; # show_tile_progress=show_tile_progress,; # **predict_kwargs); # res = tuple(res) + (None,); # if self._is_multiclass():; # prob, dist, prob_class, points = res; # else:; # prob, dist, points = res; # prob_class = None; # return self._instances_from_prediction_old(_shape_inst, prob, dist,; # points = points,; # prob_class = prob_class,; # prob_thresh=prob_thresh,; # nms_thresh=nms_thresh,; # overlap_label=overlap_label,; # **nms_kwargs)",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:1676,Energy Efficiency,allocate,allocate,1676,"_instances` and assemble all the partial results. If used as intended, the result; should be the same as if `predict_instances` was used directly on the whole image. **Important**: The crucial assumption is that all predicted object instances are smaller than; the provided `min_overlap`. Also, it must hold that: min_overlap + 2*context < block_size. Example; -------; >>> img.shape; (20000, 20000); >>> labels, polys = model.predict_instances_big(img, axes='YX', block_size=4096,; min_overlap=128, context=128, n_tiles=(4,4)). Parameters; ----------; img: :class:`numpy.ndarray` or similar; Input image; axes: str; Axes of the input ``img`` (such as 'YX', 'ZYX', 'YXC', etc.); block_size: int or iterable of int; Process input image in blocks of the provided shape.; (If a scalar value is given, it is used for all spatial image dimensions.); min_overlap: int or iterable of int; Amount of guaranteed overlap between blocks.; (If a scalar value is given, it is used for all spatial image dimensions.); context: int or iterable of int, or None; Amount of image context on all sides of a block, which is discarded.; If None, uses an automatic estimate that should work in many cases.; (If a scalar value is given, it is used for all spatial image dimensions.); labels_out: :class:`numpy.ndarray` or similar, or None, or False; numpy array or similar (must be of correct shape) to which the label image is written.; If None, will allocate a numpy array of the correct shape and data type ``labels_out_dtype``.; If False, will not write the label image (useful if only the dictionary is needed).; labels_out_dtype: str or dtype; Data type of returned label image if ``labels_out=None`` (has no effect otherwise).; show_progress: bool; Show progress bar for block processing.; kwargs: dict; Keyword arguments for ``predict_instances``. Returns; -------; (:class:`numpy.ndarray` or False, dict); Returns the label image and a dictionary with the details (coordinates, etc.) of the polygons/polyhedra. """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:463,Safety,predict,predicted,463,"""""""Predict instance segmentation from very large input images. Intended to be used when `predict_instances` cannot be used due to memory limitations.; This function will break the input image into blocks and process them individually; via `predict_instances` and assemble all the partial results. If used as intended, the result; should be the same as if `predict_instances` was used directly on the whole image. **Important**: The crucial assumption is that all predicted object instances are smaller than; the provided `min_overlap`. Also, it must hold that: min_overlap + 2*context < block_size. Example; -------; >>> img.shape; (20000, 20000); >>> labels, polys = model.predict_instances_big(img, axes='YX', block_size=4096,; min_overlap=128, context=128, n_tiles=(4,4)). Parameters; ----------; img: :class:`numpy.ndarray` or similar; Input image; axes: str; Axes of the input ``img`` (such as 'YX', 'ZYX', 'YXC', etc.); block_size: int or iterable of int; Process input image in blocks of the provided shape.; (If a scalar value is given, it is used for all spatial image dimensions.); min_overlap: int or iterable of int; Amount of guaranteed overlap between blocks.; (If a scalar value is given, it is used for all spatial image dimensions.); context: int or iterable of int, or None; Amount of image context on all sides of a block, which is discarded.; If None, uses an automatic estimate that should work in many cases.; (If a scalar value is given, it is used for all spatial image dimensions.); labels_out: :class:`numpy.ndarray` or similar, or None, or False; numpy array or similar (must be of correct shape) to which the label image is written.; If None, will allocate a numpy array of the correct shape and data type ``labels_out_dtype``.; If False, will not write the label image (useful if only the dictionary is needed).; labels_out_dtype: str or dtype; Data type of returned label image if ``labels_out=None`` (has no effect otherwise).; show_progress: bool; Show progress bar for",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:1985,Usability,progress bar,progress bar,1985,"_instances` and assemble all the partial results. If used as intended, the result; should be the same as if `predict_instances` was used directly on the whole image. **Important**: The crucial assumption is that all predicted object instances are smaller than; the provided `min_overlap`. Also, it must hold that: min_overlap + 2*context < block_size. Example; -------; >>> img.shape; (20000, 20000); >>> labels, polys = model.predict_instances_big(img, axes='YX', block_size=4096,; min_overlap=128, context=128, n_tiles=(4,4)). Parameters; ----------; img: :class:`numpy.ndarray` or similar; Input image; axes: str; Axes of the input ``img`` (such as 'YX', 'ZYX', 'YXC', etc.); block_size: int or iterable of int; Process input image in blocks of the provided shape.; (If a scalar value is given, it is used for all spatial image dimensions.); min_overlap: int or iterable of int; Amount of guaranteed overlap between blocks.; (If a scalar value is given, it is used for all spatial image dimensions.); context: int or iterable of int, or None; Amount of image context on all sides of a block, which is discarded.; If None, uses an automatic estimate that should work in many cases.; (If a scalar value is given, it is used for all spatial image dimensions.); labels_out: :class:`numpy.ndarray` or similar, or None, or False; numpy array or similar (must be of correct shape) to which the label image is written.; If None, will allocate a numpy array of the correct shape and data type ``labels_out_dtype``.; If False, will not write the label image (useful if only the dictionary is needed).; labels_out_dtype: str or dtype; Data type of returned label image if ``labels_out=None`` (has no effect otherwise).; show_progress: bool; Show progress bar for block processing.; kwargs: dict; Keyword arguments for ``predict_instances``. Returns; -------; (:class:`numpy.ndarray` or False, dict); Returns the label image and a dictionary with the details (coordinates, etc.) of the polygons/polyhedra. """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:187,Safety,avoid,avoid,187,"# if (block_size[i], min_overlap[i], context[i]) != (None, None, None):; # print(""Ignoring values of 'block_size', 'min_overlap', and 'context' for channel axis "" +; # ""(set to 'None' to avoid this warning)."", file=sys.stderr, flush=True)",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:46,Energy Efficiency,efficient,efficient,46,"# TODO: relabel_sequential is not very memory-efficient (will allocate memory proportional to label_offset); # this should not change the order of labels",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:62,Energy Efficiency,allocate,allocate,62,"# TODO: relabel_sequential is not very memory-efficient (will allocate memory proportional to label_offset); # this should not change the order of labels",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:106,Modifiability,extend,extend,106,"# labels, fwd_map, _ = relabel_sequential(labels, label_offset); # if len(incomplete) > 0:; # problem_ids.extend([fwd_map[i] for i in incomplete]); # if show_progress:; # blocks.set_postfix_str(f""found {len(problem_ids)} problematic {'object' if len(problem_ids)==1 else 'objects'}"")",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:1163,Availability,error,errors,1163,"""""""Optimize two thresholds (probability, NMS overlap) necessary for predicting object instances. Note that the default thresholds yield good results in many cases, but optimizing; the thresholds for a particular dataset can further improve performance. The optimized thresholds are automatically used for all further predictions; and also written to the model directory. See ``utils.optimize_threshold`` for details and possible choices for ``optimize_kwargs``. Parameters; ----------; X_val : list of ndarray; (Validation) input images (must be normalized) to use for threshold tuning.; Y_val : list of ndarray; (Validation) label images to use for threshold tuning.; nms_threshs : list of float; List of overlap thresholds to be considered for NMS.; For each value in this list, optimization is run to find a corresponding prob_thresh value.; iou_threshs : list of float; List of intersection over union (IOU) thresholds for which; the (average) matching performance is considered to tune the thresholds.; predict_kwargs: dict; Keyword arguments for ``predict`` function of this class.; (If not provided, will guess value for `n_tiles` to prevent out of memory errors.); optimize_kwargs: dict; Keyword arguments for ``utils.optimize_threshold`` function. """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:168,Performance,optimiz,optimizing,168,"""""""Optimize two thresholds (probability, NMS overlap) necessary for predicting object instances. Note that the default thresholds yield good results in many cases, but optimizing; the thresholds for a particular dataset can further improve performance. The optimized thresholds are automatically used for all further predictions; and also written to the model directory. See ``utils.optimize_threshold`` for details and possible choices for ``optimize_kwargs``. Parameters; ----------; X_val : list of ndarray; (Validation) input images (must be normalized) to use for threshold tuning.; Y_val : list of ndarray; (Validation) label images to use for threshold tuning.; nms_threshs : list of float; List of overlap thresholds to be considered for NMS.; For each value in this list, optimization is run to find a corresponding prob_thresh value.; iou_threshs : list of float; List of intersection over union (IOU) thresholds for which; the (average) matching performance is considered to tune the thresholds.; predict_kwargs: dict; Keyword arguments for ``predict`` function of this class.; (If not provided, will guess value for `n_tiles` to prevent out of memory errors.); optimize_kwargs: dict; Keyword arguments for ``utils.optimize_threshold`` function. """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:240,Performance,perform,performance,240,"""""""Optimize two thresholds (probability, NMS overlap) necessary for predicting object instances. Note that the default thresholds yield good results in many cases, but optimizing; the thresholds for a particular dataset can further improve performance. The optimized thresholds are automatically used for all further predictions; and also written to the model directory. See ``utils.optimize_threshold`` for details and possible choices for ``optimize_kwargs``. Parameters; ----------; X_val : list of ndarray; (Validation) input images (must be normalized) to use for threshold tuning.; Y_val : list of ndarray; (Validation) label images to use for threshold tuning.; nms_threshs : list of float; List of overlap thresholds to be considered for NMS.; For each value in this list, optimization is run to find a corresponding prob_thresh value.; iou_threshs : list of float; List of intersection over union (IOU) thresholds for which; the (average) matching performance is considered to tune the thresholds.; predict_kwargs: dict; Keyword arguments for ``predict`` function of this class.; (If not provided, will guess value for `n_tiles` to prevent out of memory errors.); optimize_kwargs: dict; Keyword arguments for ``utils.optimize_threshold`` function. """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:257,Performance,optimiz,optimized,257,"""""""Optimize two thresholds (probability, NMS overlap) necessary for predicting object instances. Note that the default thresholds yield good results in many cases, but optimizing; the thresholds for a particular dataset can further improve performance. The optimized thresholds are automatically used for all further predictions; and also written to the model directory. See ``utils.optimize_threshold`` for details and possible choices for ``optimize_kwargs``. Parameters; ----------; X_val : list of ndarray; (Validation) input images (must be normalized) to use for threshold tuning.; Y_val : list of ndarray; (Validation) label images to use for threshold tuning.; nms_threshs : list of float; List of overlap thresholds to be considered for NMS.; For each value in this list, optimization is run to find a corresponding prob_thresh value.; iou_threshs : list of float; List of intersection over union (IOU) thresholds for which; the (average) matching performance is considered to tune the thresholds.; predict_kwargs: dict; Keyword arguments for ``predict`` function of this class.; (If not provided, will guess value for `n_tiles` to prevent out of memory errors.); optimize_kwargs: dict; Keyword arguments for ``utils.optimize_threshold`` function. """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:781,Performance,optimiz,optimization,781,"""""""Optimize two thresholds (probability, NMS overlap) necessary for predicting object instances. Note that the default thresholds yield good results in many cases, but optimizing; the thresholds for a particular dataset can further improve performance. The optimized thresholds are automatically used for all further predictions; and also written to the model directory. See ``utils.optimize_threshold`` for details and possible choices for ``optimize_kwargs``. Parameters; ----------; X_val : list of ndarray; (Validation) input images (must be normalized) to use for threshold tuning.; Y_val : list of ndarray; (Validation) label images to use for threshold tuning.; nms_threshs : list of float; List of overlap thresholds to be considered for NMS.; For each value in this list, optimization is run to find a corresponding prob_thresh value.; iou_threshs : list of float; List of intersection over union (IOU) thresholds for which; the (average) matching performance is considered to tune the thresholds.; predict_kwargs: dict; Keyword arguments for ``predict`` function of this class.; (If not provided, will guess value for `n_tiles` to prevent out of memory errors.); optimize_kwargs: dict; Keyword arguments for ``utils.optimize_threshold`` function. """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:957,Performance,perform,performance,957,"""""""Optimize two thresholds (probability, NMS overlap) necessary for predicting object instances. Note that the default thresholds yield good results in many cases, but optimizing; the thresholds for a particular dataset can further improve performance. The optimized thresholds are automatically used for all further predictions; and also written to the model directory. See ``utils.optimize_threshold`` for details and possible choices for ``optimize_kwargs``. Parameters; ----------; X_val : list of ndarray; (Validation) input images (must be normalized) to use for threshold tuning.; Y_val : list of ndarray; (Validation) label images to use for threshold tuning.; nms_threshs : list of float; List of overlap thresholds to be considered for NMS.; For each value in this list, optimization is run to find a corresponding prob_thresh value.; iou_threshs : list of float; List of intersection over union (IOU) thresholds for which; the (average) matching performance is considered to tune the thresholds.; predict_kwargs: dict; Keyword arguments for ``predict`` function of this class.; (If not provided, will guess value for `n_tiles` to prevent out of memory errors.); optimize_kwargs: dict; Keyword arguments for ``utils.optimize_threshold`` function. """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:986,Performance,tune,tune,986,"""""""Optimize two thresholds (probability, NMS overlap) necessary for predicting object instances. Note that the default thresholds yield good results in many cases, but optimizing; the thresholds for a particular dataset can further improve performance. The optimized thresholds are automatically used for all further predictions; and also written to the model directory. See ``utils.optimize_threshold`` for details and possible choices for ``optimize_kwargs``. Parameters; ----------; X_val : list of ndarray; (Validation) input images (must be normalized) to use for threshold tuning.; Y_val : list of ndarray; (Validation) label images to use for threshold tuning.; nms_threshs : list of float; List of overlap thresholds to be considered for NMS.; For each value in this list, optimization is run to find a corresponding prob_thresh value.; iou_threshs : list of float; List of intersection over union (IOU) thresholds for which; the (average) matching performance is considered to tune the thresholds.; predict_kwargs: dict; Keyword arguments for ``predict`` function of this class.; (If not provided, will guess value for `n_tiles` to prevent out of memory errors.); optimize_kwargs: dict; Keyword arguments for ``utils.optimize_threshold`` function. """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:68,Safety,predict,predicting,68,"""""""Optimize two thresholds (probability, NMS overlap) necessary for predicting object instances. Note that the default thresholds yield good results in many cases, but optimizing; the thresholds for a particular dataset can further improve performance. The optimized thresholds are automatically used for all further predictions; and also written to the model directory. See ``utils.optimize_threshold`` for details and possible choices for ``optimize_kwargs``. Parameters; ----------; X_val : list of ndarray; (Validation) input images (must be normalized) to use for threshold tuning.; Y_val : list of ndarray; (Validation) label images to use for threshold tuning.; nms_threshs : list of float; List of overlap thresholds to be considered for NMS.; For each value in this list, optimization is run to find a corresponding prob_thresh value.; iou_threshs : list of float; List of intersection over union (IOU) thresholds for which; the (average) matching performance is considered to tune the thresholds.; predict_kwargs: dict; Keyword arguments for ``predict`` function of this class.; (If not provided, will guess value for `n_tiles` to prevent out of memory errors.); optimize_kwargs: dict; Keyword arguments for ``utils.optimize_threshold`` function. """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:317,Safety,predict,predictions,317,"""""""Optimize two thresholds (probability, NMS overlap) necessary for predicting object instances. Note that the default thresholds yield good results in many cases, but optimizing; the thresholds for a particular dataset can further improve performance. The optimized thresholds are automatically used for all further predictions; and also written to the model directory. See ``utils.optimize_threshold`` for details and possible choices for ``optimize_kwargs``. Parameters; ----------; X_val : list of ndarray; (Validation) input images (must be normalized) to use for threshold tuning.; Y_val : list of ndarray; (Validation) label images to use for threshold tuning.; nms_threshs : list of float; List of overlap thresholds to be considered for NMS.; For each value in this list, optimization is run to find a corresponding prob_thresh value.; iou_threshs : list of float; List of intersection over union (IOU) thresholds for which; the (average) matching performance is considered to tune the thresholds.; predict_kwargs: dict; Keyword arguments for ``predict`` function of this class.; (If not provided, will guess value for `n_tiles` to prevent out of memory errors.); optimize_kwargs: dict; Keyword arguments for ``utils.optimize_threshold`` function. """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:1054,Safety,predict,predict,1054,"""""""Optimize two thresholds (probability, NMS overlap) necessary for predicting object instances. Note that the default thresholds yield good results in many cases, but optimizing; the thresholds for a particular dataset can further improve performance. The optimized thresholds are automatically used for all further predictions; and also written to the model directory. See ``utils.optimize_threshold`` for details and possible choices for ``optimize_kwargs``. Parameters; ----------; X_val : list of ndarray; (Validation) input images (must be normalized) to use for threshold tuning.; Y_val : list of ndarray; (Validation) label images to use for threshold tuning.; nms_threshs : list of float; List of overlap thresholds to be considered for NMS.; For each value in this list, optimization is run to find a corresponding prob_thresh value.; iou_threshs : list of float; List of intersection over union (IOU) thresholds for which; the (average) matching performance is considered to tune the thresholds.; predict_kwargs: dict; Keyword arguments for ``predict`` function of this class.; (If not provided, will guess value for `n_tiles` to prevent out of memory errors.); optimize_kwargs: dict; Keyword arguments for ``utils.optimize_threshold`` function. """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:34,Safety,predict,predict,34,"# only take first two elements of predict in case multi class is activated",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:60,Modifiability,config,config,60,"# img has no dedicated channel axis, but 'C' always part of config axes",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:84,Modifiability,plugin,plugin,84,"""""""Export model to TensorFlow's SavedModel format that can be used e.g. in the Fiji plugin. Parameters; ----------; fname : str; Path of the zip file to store the model; If None, the default path ""<modeldir>/TF_SavedModel.zip"" is used; single_output: bool; If set, concatenates the two model outputs into a single output (note: this is currently mandatory for further use in Fiji); upsample_grid: bool; If set, upsamples the output to the input shape (note: this is currently mandatory for further use in Fiji); """"""",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py:15,Modifiability,plugin,plugin,15,"# CSBDeep Fiji plugin needs same size input/output; # -> we need to upsample the outputs if grid > (1,1); # note: upsampling prob with a transposed convolution creates sparse; # prob output with less candidates than with standard upsampling",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:20,Availability,down,downsampling,20,"# TODO: investigate downsampling via simple indexing vs. using 'zoom'; # prob_class = prob_class[self.ss_grid]; # 'zoom' might lead to better registered maps (especially if upscaled later)",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:37,Usability,simpl,simple,37,"# TODO: investigate downsampling via simple indexing vs. using 'zoom'; # prob_class = prob_class[self.ss_grid]; # 'zoom' might lead to better registered maps (especially if upscaled later)",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:830,Availability,down,down,830,"""""""Configuration for a :class:`StarDist2D` model. Parameters; ----------; axes : str or None; Axes of the input images.; n_rays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate ",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:1066,Availability,down,down-sampling,1066,"-------; axes : str or None; Axes of the input images.; n_rays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable t",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:713,Deployability,configurat,configuration,713,"""""""Configuration for a :class:`StarDist2D` model. Parameters; ----------; axes : str or None; Axes of the input images.; n_rays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate ",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:1574,Deployability,patch,patches,1574,"nt; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:1673,Deployability,patch,patches,1673,"kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_tensorboard : bool; Enable TensorBoard f",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:1885,Deployability,patch,patches,1885,"-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:2018,Deployability,patch,patch,2018,"els (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .. _ReduceLROnPlateau: https://keras.io/api/callbacks/reduce_lr_on_plateau/; """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:2381,Deployability,update,update,2381,"els (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .. _ReduceLROnPlateau: https://keras.io/api/callbacks/reduce_lr_on_plateau/; """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:2551,Deployability,patch,patches,2551,"els (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .. _ReduceLROnPlateau: https://keras.io/api/callbacks/reduce_lr_on_plateau/; """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:2614,Deployability,patch,patch,2614,"els (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .. _ReduceLROnPlateau: https://keras.io/api/callbacks/reduce_lr_on_plateau/; """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:214,Energy Efficiency,power,power,214,"""""""Configuration for a :class:`StarDist2D` model. Parameters; ----------; axes : str or None; Axes of the input images.; n_rays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate ",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:363,Energy Efficiency,power,powers,363,"""""""Configuration for a :class:`StarDist2D` model. Parameters; ----------; axes : str or None; Axes of the input images.; n_rays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate ",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:2682,Energy Efficiency,monitor,monitoring,2682,"els (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .. _ReduceLROnPlateau: https://keras.io/api/callbacks/reduce_lr_on_plateau/; """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:713,Modifiability,config,configuration,713,"""""""Configuration for a :class:`StarDist2D` model. Parameters; ----------; axes : str or None; Axes of the input images.; n_rays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate ",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:847,Modifiability,layers,layers,847,"""""""Configuration for a :class:`StarDist2D` model. Parameters; ----------; axes : str or None; Axes of the input images.; n_rays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate ",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:939,Modifiability,layers,layers,939,"""""""Configuration for a :class:`StarDist2D` model. Parameters; ----------; axes : str or None; Axes of the input images.; n_rays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate ",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:1155,Modifiability,layers,layers,1155,"ays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; ",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:410,Safety,predict,predict,410,"""""""Configuration for a :class:`StarDist2D` model. Parameters; ----------; axes : str or None; Axes of the input images.; n_rays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate ",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:564,Safety,predict,prediction,564,"""""""Configuration for a :class:`StarDist2D` model. Parameters; ----------; axes : str or None; Axes of the input images.; n_rays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate ",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:1370,Safety,predict,predict,1370,"ch of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter u",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:1791,Safety,predict,predictions,1791,"_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlate",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:2580,Security,validat,validation,2580,"els (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .. _ReduceLROnPlateau: https://keras.io/api/callbacks/reduce_lr_on_plateau/; """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:10,Modifiability,config,config,10,"# default config (can be overwritten by kwargs below)",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:505,Deployability,configurat,configuration,505,"""""""StarDist2D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:828,Deployability,configurat,configuration,828,"""""""StarDist2D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:45,Modifiability,config,config,45,"""""""StarDist2D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:112,Modifiability,config,config,112,"""""""StarDist2D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:402,Modifiability,config,config,402,"""""""StarDist2D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:420,Modifiability,config,config,420,"""""""StarDist2D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:505,Modifiability,config,configuration,505,"""""""StarDist2D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:544,Modifiability,config,config,544,"""""""StarDist2D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:828,Modifiability,config,configuration,828,"""""""StarDist2D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:157,Performance,load,loaded,157,"""""""StarDist2D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:437,Performance,load,loaded,437,"""""""StarDist2D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:761,Testability,log,logdir,761,"""""""StarDist2D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:696,Usability,guid,guide,696,"""""""StarDist2D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:209,Availability,mask,masks,209,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:517,Availability,mask,mask,517,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:1396,Deployability,patch,patches,1396,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:738,Modifiability,config,config,738,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:1479,Modifiability,config,config,1479,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:1566,Modifiability,config,config,1566,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:541,Safety,predict,prediction,541,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:909,Security,validat,validation,909,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:1190,Security,validat,validation,1190,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:1385,Security,validat,validation,1385,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:11,Security,validat,validation,11,"# generate validation data and store in numpy arrays",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:2,Security,expose,expose,2,"# expose data generator as member for general diagnostics",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:6,Security,validat,validation,6,"# set validation batchsize to training batchsize (only works for tf >= 2.2)",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:1192,Deployability,update,update,1192,"# def _instances_from_prediction_old(self, img_shape, prob, dist,points = None, prob_class = None, prob_thresh=None, nms_thresh=None, overlap_label = None, **nms_kwargs):; # from stardist.geometry.geom2d import _polygons_to_label_old, _dist_to_coord_old; # from stardist.nms import _non_maximum_suppression_old; # if prob_thresh is None: prob_thresh = self.thresholds.prob; # if nms_thresh is None: nms_thresh = self.thresholds.nms; # if overlap_label is not None: raise NotImplementedError(""overlap_label not supported for 2D yet!""); # coord = _dist_to_coord_old(dist, grid=self.config.grid); # inds = _non_maximum_suppression_old(coord, prob, grid=self.config.grid,; # prob_thresh=prob_thresh, nms_thresh=nms_thresh, **nms_kwargs); # labels = _polygons_to_label_old(coord, prob, inds, shape=img_shape); # # sort 'inds' such that ids in 'labels' map to entries in polygon dictionary entries; # inds = inds[np.argsort(prob[inds[:,0],inds[:,1]])]; # # adjust for grid; # points = inds*np.array(self.config.grid); # res_dict = dict(coord=coord[inds[:,0],inds[:,1]], points=points, prob=prob[inds[:,0],inds[:,1]]); # if prob_class is not None:; # prob_class = np.asarray(prob_class); # res_dict.update(dict(class_prob = prob_class)); # return labels, res_dict",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:580,Modifiability,config,config,580,"# def _instances_from_prediction_old(self, img_shape, prob, dist,points = None, prob_class = None, prob_thresh=None, nms_thresh=None, overlap_label = None, **nms_kwargs):; # from stardist.geometry.geom2d import _polygons_to_label_old, _dist_to_coord_old; # from stardist.nms import _non_maximum_suppression_old; # if prob_thresh is None: prob_thresh = self.thresholds.prob; # if nms_thresh is None: nms_thresh = self.thresholds.nms; # if overlap_label is not None: raise NotImplementedError(""overlap_label not supported for 2D yet!""); # coord = _dist_to_coord_old(dist, grid=self.config.grid); # inds = _non_maximum_suppression_old(coord, prob, grid=self.config.grid,; # prob_thresh=prob_thresh, nms_thresh=nms_thresh, **nms_kwargs); # labels = _polygons_to_label_old(coord, prob, inds, shape=img_shape); # # sort 'inds' such that ids in 'labels' map to entries in polygon dictionary entries; # inds = inds[np.argsort(prob[inds[:,0],inds[:,1]])]; # # adjust for grid; # points = inds*np.array(self.config.grid); # res_dict = dict(coord=coord[inds[:,0],inds[:,1]], points=points, prob=prob[inds[:,0],inds[:,1]]); # if prob_class is not None:; # prob_class = np.asarray(prob_class); # res_dict.update(dict(class_prob = prob_class)); # return labels, res_dict",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:655,Modifiability,config,config,655,"# def _instances_from_prediction_old(self, img_shape, prob, dist,points = None, prob_class = None, prob_thresh=None, nms_thresh=None, overlap_label = None, **nms_kwargs):; # from stardist.geometry.geom2d import _polygons_to_label_old, _dist_to_coord_old; # from stardist.nms import _non_maximum_suppression_old; # if prob_thresh is None: prob_thresh = self.thresholds.prob; # if nms_thresh is None: nms_thresh = self.thresholds.nms; # if overlap_label is not None: raise NotImplementedError(""overlap_label not supported for 2D yet!""); # coord = _dist_to_coord_old(dist, grid=self.config.grid); # inds = _non_maximum_suppression_old(coord, prob, grid=self.config.grid,; # prob_thresh=prob_thresh, nms_thresh=nms_thresh, **nms_kwargs); # labels = _polygons_to_label_old(coord, prob, inds, shape=img_shape); # # sort 'inds' such that ids in 'labels' map to entries in polygon dictionary entries; # inds = inds[np.argsort(prob[inds[:,0],inds[:,1]])]; # # adjust for grid; # points = inds*np.array(self.config.grid); # res_dict = dict(coord=coord[inds[:,0],inds[:,1]], points=points, prob=prob[inds[:,0],inds[:,1]]); # if prob_class is not None:; # prob_class = np.asarray(prob_class); # res_dict.update(dict(class_prob = prob_class)); # return labels, res_dict",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:998,Modifiability,config,config,998,"# def _instances_from_prediction_old(self, img_shape, prob, dist,points = None, prob_class = None, prob_thresh=None, nms_thresh=None, overlap_label = None, **nms_kwargs):; # from stardist.geometry.geom2d import _polygons_to_label_old, _dist_to_coord_old; # from stardist.nms import _non_maximum_suppression_old; # if prob_thresh is None: prob_thresh = self.thresholds.prob; # if nms_thresh is None: nms_thresh = self.thresholds.nms; # if overlap_label is not None: raise NotImplementedError(""overlap_label not supported for 2D yet!""); # coord = _dist_to_coord_old(dist, grid=self.config.grid); # inds = _non_maximum_suppression_old(coord, prob, grid=self.config.grid,; # prob_thresh=prob_thresh, nms_thresh=nms_thresh, **nms_kwargs); # labels = _polygons_to_label_old(coord, prob, inds, shape=img_shape); # # sort 'inds' such that ids in 'labels' map to entries in polygon dictionary entries; # inds = inds[np.argsort(prob[inds[:,0],inds[:,1]])]; # # adjust for grid; # points = inds*np.array(self.config.grid); # res_dict = dict(coord=coord[inds[:,0],inds[:,1]], points=points, prob=prob[inds[:,0],inds[:,1]]); # if prob_class is not None:; # prob_class = np.asarray(prob_class); # res_dict.update(dict(class_prob = prob_class)); # return labels, res_dict",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:32,Safety,predict,prediction,32,"""""""; if points is None -> dense prediction; if points is not None -> sparse prediction. if prob_class is None -> single class prediction; if prob_class is not None -> multi class prediction; """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:76,Safety,predict,prediction,76,"""""""; if points is None -> dense prediction; if points is not None -> sparse prediction. if prob_class is None -> single class prediction; if prob_class is not None -> multi class prediction; """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:126,Safety,predict,prediction,126,"""""""; if points is None -> dense prediction; if points is not None -> sparse prediction. if prob_class is None -> single class prediction; if prob_class is not None -> multi class prediction; """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:179,Safety,predict,prediction,179,"""""""; if points is None -> dense prediction; if points is not None -> sparse prediction. if prob_class is None -> single class prediction; if prob_class is not None -> multi class prediction; """"""",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:9,Safety,predict,prediction,9,"# sparse prediction",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:8,Safety,predict,prediction,8,"# dense prediction",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:10,Usability,undo,undo,10,"# need to undo the scaling given by the scale dict, e.g. scale = dict(X=0.5,Y=0.5):; # 1. re-scale points (origins of polygons); # 2. re-scale coordinates (computed from distances) of (zero-origin) polygons",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:14,Safety,predict,prediction,14,"# multi class prediction",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:52,Modifiability,config,config,52,"# def _axes_tile_overlap(self, query_axes):; # self.config.backbone == 'unet' or _raise(NotImplementedError()); # query_axes = axes_check_and_normalize(query_axes); # assert len(self.config.unet_pool) == len(self.config.grid) == len(self.config.unet_kernel_size); # # TODO: compute this properly when any value of grid > 1; # # all(g==1 for g in self.config.grid) or warnings.warn('FIXME'); # overlap = dict(zip(; # self.config.axes.replace('C',''),; # tuple(tile_overlap(self.config.unet_n_depth + int(np.log2(g)), k, p); # for p,k,g in zip(self.config.unet_pool,self.config.unet_kernel_size,self.config.grid)); # )); # return tuple(overlap.get(a,0) for a in query_axes)",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:183,Modifiability,config,config,183,"# def _axes_tile_overlap(self, query_axes):; # self.config.backbone == 'unet' or _raise(NotImplementedError()); # query_axes = axes_check_and_normalize(query_axes); # assert len(self.config.unet_pool) == len(self.config.grid) == len(self.config.unet_kernel_size); # # TODO: compute this properly when any value of grid > 1; # # all(g==1 for g in self.config.grid) or warnings.warn('FIXME'); # overlap = dict(zip(; # self.config.axes.replace('C',''),; # tuple(tile_overlap(self.config.unet_n_depth + int(np.log2(g)), k, p); # for p,k,g in zip(self.config.unet_pool,self.config.unet_kernel_size,self.config.grid)); # )); # return tuple(overlap.get(a,0) for a in query_axes)",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:213,Modifiability,config,config,213,"# def _axes_tile_overlap(self, query_axes):; # self.config.backbone == 'unet' or _raise(NotImplementedError()); # query_axes = axes_check_and_normalize(query_axes); # assert len(self.config.unet_pool) == len(self.config.grid) == len(self.config.unet_kernel_size); # # TODO: compute this properly when any value of grid > 1; # # all(g==1 for g in self.config.grid) or warnings.warn('FIXME'); # overlap = dict(zip(; # self.config.axes.replace('C',''),; # tuple(tile_overlap(self.config.unet_n_depth + int(np.log2(g)), k, p); # for p,k,g in zip(self.config.unet_pool,self.config.unet_kernel_size,self.config.grid)); # )); # return tuple(overlap.get(a,0) for a in query_axes)",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:238,Modifiability,config,config,238,"# def _axes_tile_overlap(self, query_axes):; # self.config.backbone == 'unet' or _raise(NotImplementedError()); # query_axes = axes_check_and_normalize(query_axes); # assert len(self.config.unet_pool) == len(self.config.grid) == len(self.config.unet_kernel_size); # # TODO: compute this properly when any value of grid > 1; # # all(g==1 for g in self.config.grid) or warnings.warn('FIXME'); # overlap = dict(zip(; # self.config.axes.replace('C',''),; # tuple(tile_overlap(self.config.unet_n_depth + int(np.log2(g)), k, p); # for p,k,g in zip(self.config.unet_pool,self.config.unet_kernel_size,self.config.grid)); # )); # return tuple(overlap.get(a,0) for a in query_axes)",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:351,Modifiability,config,config,351,"# def _axes_tile_overlap(self, query_axes):; # self.config.backbone == 'unet' or _raise(NotImplementedError()); # query_axes = axes_check_and_normalize(query_axes); # assert len(self.config.unet_pool) == len(self.config.grid) == len(self.config.unet_kernel_size); # # TODO: compute this properly when any value of grid > 1; # # all(g==1 for g in self.config.grid) or warnings.warn('FIXME'); # overlap = dict(zip(; # self.config.axes.replace('C',''),; # tuple(tile_overlap(self.config.unet_n_depth + int(np.log2(g)), k, p); # for p,k,g in zip(self.config.unet_pool,self.config.unet_kernel_size,self.config.grid)); # )); # return tuple(overlap.get(a,0) for a in query_axes)",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:421,Modifiability,config,config,421,"# def _axes_tile_overlap(self, query_axes):; # self.config.backbone == 'unet' or _raise(NotImplementedError()); # query_axes = axes_check_and_normalize(query_axes); # assert len(self.config.unet_pool) == len(self.config.grid) == len(self.config.unet_kernel_size); # # TODO: compute this properly when any value of grid > 1; # # all(g==1 for g in self.config.grid) or warnings.warn('FIXME'); # overlap = dict(zip(; # self.config.axes.replace('C',''),; # tuple(tile_overlap(self.config.unet_n_depth + int(np.log2(g)), k, p); # for p,k,g in zip(self.config.unet_pool,self.config.unet_kernel_size,self.config.grid)); # )); # return tuple(overlap.get(a,0) for a in query_axes)",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:477,Modifiability,config,config,477,"# def _axes_tile_overlap(self, query_axes):; # self.config.backbone == 'unet' or _raise(NotImplementedError()); # query_axes = axes_check_and_normalize(query_axes); # assert len(self.config.unet_pool) == len(self.config.grid) == len(self.config.unet_kernel_size); # # TODO: compute this properly when any value of grid > 1; # # all(g==1 for g in self.config.grid) or warnings.warn('FIXME'); # overlap = dict(zip(; # self.config.axes.replace('C',''),; # tuple(tile_overlap(self.config.unet_n_depth + int(np.log2(g)), k, p); # for p,k,g in zip(self.config.unet_pool,self.config.unet_kernel_size,self.config.grid)); # )); # return tuple(overlap.get(a,0) for a in query_axes)",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:547,Modifiability,config,config,547,"# def _axes_tile_overlap(self, query_axes):; # self.config.backbone == 'unet' or _raise(NotImplementedError()); # query_axes = axes_check_and_normalize(query_axes); # assert len(self.config.unet_pool) == len(self.config.grid) == len(self.config.unet_kernel_size); # # TODO: compute this properly when any value of grid > 1; # # all(g==1 for g in self.config.grid) or warnings.warn('FIXME'); # overlap = dict(zip(; # self.config.axes.replace('C',''),; # tuple(tile_overlap(self.config.unet_n_depth + int(np.log2(g)), k, p); # for p,k,g in zip(self.config.unet_pool,self.config.unet_kernel_size,self.config.grid)); # )); # return tuple(overlap.get(a,0) for a in query_axes)",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:569,Modifiability,config,config,569,"# def _axes_tile_overlap(self, query_axes):; # self.config.backbone == 'unet' or _raise(NotImplementedError()); # query_axes = axes_check_and_normalize(query_axes); # assert len(self.config.unet_pool) == len(self.config.grid) == len(self.config.unet_kernel_size); # # TODO: compute this properly when any value of grid > 1; # # all(g==1 for g in self.config.grid) or warnings.warn('FIXME'); # overlap = dict(zip(; # self.config.axes.replace('C',''),; # tuple(tile_overlap(self.config.unet_n_depth + int(np.log2(g)), k, p); # for p,k,g in zip(self.config.unet_pool,self.config.unet_kernel_size,self.config.grid)); # )); # return tuple(overlap.get(a,0) for a in query_axes)",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:598,Modifiability,config,config,598,"# def _axes_tile_overlap(self, query_axes):; # self.config.backbone == 'unet' or _raise(NotImplementedError()); # query_axes = axes_check_and_normalize(query_axes); # assert len(self.config.unet_pool) == len(self.config.grid) == len(self.config.unet_kernel_size); # # TODO: compute this properly when any value of grid > 1; # # all(g==1 for g in self.config.grid) or warnings.warn('FIXME'); # overlap = dict(zip(; # self.config.axes.replace('C',''),; # tuple(tile_overlap(self.config.unet_n_depth + int(np.log2(g)), k, p); # for p,k,g in zip(self.config.unet_pool,self.config.unet_kernel_size,self.config.grid)); # )); # return tuple(overlap.get(a,0) for a in query_axes)",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py:167,Testability,assert,assert,167,"# def _axes_tile_overlap(self, query_axes):; # self.config.backbone == 'unet' or _raise(NotImplementedError()); # query_axes = axes_check_and_normalize(query_axes); # assert len(self.config.unet_pool) == len(self.config.grid) == len(self.config.unet_kernel_size); # # TODO: compute this properly when any value of grid > 1; # # all(g==1 for g in self.config.grid) or warnings.warn('FIXME'); # overlap = dict(zip(; # self.config.axes.replace('C',''),; # tuple(tile_overlap(self.config.unet_n_depth + int(np.log2(g)), k, p); # for p,k,g in zip(self.config.unet_pool,self.config.unet_kernel_size,self.config.grid)); # )); # return tuple(overlap.get(a,0) for a in query_axes)",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:8,Availability,down,downsample,8,"# TODO: downsample here before stacking?",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:20,Availability,down,downsampling,20,"# TODO: investigate downsampling via simple indexing vs. using 'zoom'; # prob_class = prob_class[self.ss_grid]; # 'zoom' might lead to better registered maps (especially if upscaled later)",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:37,Usability,simpl,simple,37,"# TODO: investigate downsampling via simple indexing vs. using 'zoom'; # prob_class = prob_class[self.ss_grid]; # 'zoom' might lead to better registered maps (especially if upscaled later)",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:1029,Availability,down,down,1029,"""""Configuration for a :class:`StarDist3D` model. Parameters; ----------; axes : str or None; Axes of the input images.; rays : Rays_Base, int, or None; Ray factory (e.g. Ray_GoldenSpiral).; If an integer then Ray_GoldenSpiral(rays) will be used; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_si",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:1269,Availability,down,down-sampling,1269,"umber of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be s",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:1792,Availability,down,downsampling,1792,"nts``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : floa",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:912,Deployability,configurat,configuration,912,"""""""Configuration for a :class:`StarDist3D` model. Parameters; ----------; axes : str or None; Axes of the input images.; rays : Rays_Base, int, or None; Ray factory (e.g. Ray_GoldenSpiral).; If an integer then Ray_GoldenSpiral(rays) will be used; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_s",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:2030,Deployability,patch,patches,2030,"up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_n_val_patches : int; Number of patches to be extracted from validation images",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:2242,Deployability,patch,patches,2242,"ling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:2375,Deployability,patch,patch,2375,"tion layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .. _ReduceLROnPlateau: https://keras.io/api/callbacks/reduce_lr_on_plateau/; """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:2738,Deployability,update,update,2738,"tion layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .. _ReduceLROnPlateau: https://keras.io/api/callbacks/reduce_lr_on_plateau/; """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:2988,Deployability,patch,patches,2988,"tion layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .. _ReduceLROnPlateau: https://keras.io/api/callbacks/reduce_lr_on_plateau/; """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:3051,Deployability,patch,patch,3051,"tion layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .. _ReduceLROnPlateau: https://keras.io/api/callbacks/reduce_lr_on_plateau/; """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:373,Energy Efficiency,power,powers,373,"""""""Configuration for a :class:`StarDist3D` model. Parameters; ----------; axes : str or None; Axes of the input images.; rays : Rays_Base, int, or None; Ray factory (e.g. Ray_GoldenSpiral).; If an integer then Ray_GoldenSpiral(rays) will be used; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_s",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:2920,Energy Efficiency,monitor,monitoring,2920,"tion layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .. _ReduceLROnPlateau: https://keras.io/api/callbacks/reduce_lr_on_plateau/; """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:912,Modifiability,config,configuration,912,"""""""Configuration for a :class:`StarDist3D` model. Parameters; ----------; axes : str or None; Axes of the input images.; rays : Rays_Base, int, or None; Ray factory (e.g. Ray_GoldenSpiral).; If an integer then Ray_GoldenSpiral(rays) will be used; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_s",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:1046,Modifiability,layers,layers,1046,"""""Configuration for a :class:`StarDist3D` model. Parameters; ----------; axes : str or None; Axes of the input images.; rays : Rays_Base, int, or None; Ray factory (e.g. Ray_GoldenSpiral).; If an integer then Ray_GoldenSpiral(rays) will be used; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_si",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:1142,Modifiability,layers,layers,1142," the input images.; rays : Rays_Base, int, or None; Ray factory (e.g. Ray_GoldenSpiral).; If an integer then Ray_GoldenSpiral(rays) will be used; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_r",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:1362,Modifiability,layers,layers,1362,"(int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_s",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:420,Safety,predict,predict,420,"""""""Configuration for a :class:`StarDist3D` model. Parameters; ----------; axes : str or None; Axes of the input images.; rays : Rays_Base, int, or None; Ray factory (e.g. Ray_GoldenSpiral).; If an integer then Ray_GoldenSpiral(rays) will be used; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_s",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:574,Safety,predict,prediction,574,"""""""Configuration for a :class:`StarDist3D` model. Parameters; ----------; axes : str or None; Axes of the input images.; rays : Rays_Base, int, or None; Ray factory (e.g. Ray_GoldenSpiral).; If an integer then Ray_GoldenSpiral(rays) will be used; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_s",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:2148,Safety,predict,predictions,2148,"ution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlate",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:3017,Security,validat,validation,3017,"tion layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet (0 to disable).; resnet_* : *; Additional parameters for ResNet backbone.; train_patch_size : (int,int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .. _ReduceLROnPlateau: https://keras.io/api/callbacks/reduce_lr_on_plateau/; """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:10,Modifiability,config,config,10,"# default config (can be overwritten by kwargs below)",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:505,Deployability,configurat,configuration,505,"""""""StarDist3D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:828,Deployability,configurat,configuration,828,"""""""StarDist3D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:45,Modifiability,config,config,45,"""""""StarDist3D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:112,Modifiability,config,config,112,"""""""StarDist3D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:402,Modifiability,config,config,402,"""""""StarDist3D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:420,Modifiability,config,config,420,"""""""StarDist3D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:505,Modifiability,config,configuration,505,"""""""StarDist3D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:544,Modifiability,config,config,544,"""""""StarDist3D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:828,Modifiability,config,configuration,828,"""""""StarDist3D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:157,Performance,load,loaded,157,"""""""StarDist3D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:437,Performance,load,loaded,437,"""""""StarDist3D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:761,Testability,log,logdir,761,"""""""StarDist3D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:696,Usability,guid,guide,696,"""""""StarDist3D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:209,Availability,mask,masks,209,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:517,Availability,mask,mask,517,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:1396,Deployability,patch,patches,1396,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:738,Modifiability,config,config,738,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:1479,Modifiability,config,config,1479,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:1566,Modifiability,config,config,1566,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:541,Safety,predict,prediction,541,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:909,Security,validat,validation,909,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:1190,Security,validat,validation,1190,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:1385,Security,validat,validation,1385,"""""""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data : tuple(:class:`numpy.ndarray`, :class:`numpy.ndarray`) or triple (if multiclass); Tuple (triple if multiclass) of X,Y,[classes] validation data.; augmenter : None or callable; Function with expected signature ``xt, yt = augmenter(x, y)``; that takes in a single pair of input/label image (x,y) and returns; the transformed images (xt, yt) for the purpose of data augmentation; during training. Not applied to validation images.; Example:; def simple_augmenter(x,y):; x = x + 0.05*np.random.normal(0,1,x.shape); return x,y; seed : int; Convenience to set ``np.random.seed(seed)``. (To obtain reproducible validation patches, etc.); epochs : int; Optional argument to use instead of the value from ``config``.; steps_per_epoch : int; Optional argument to use instead of the value from ``config``. Returns; -------; ``History`` object; See `Keras training history <https://keras.io/models/model/#fit>`_. """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:11,Security,validat,validation,11,"# generate validation data and store in numpy arrays",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:2,Security,expose,expose,2,"# expose data generator as member for general diagnostics",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:6,Security,validat,validation,6,"# set validation batchsize to training batchsize (only works in tf 2.x)",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:32,Safety,predict,prediction,32,"""""""; if points is None -> dense prediction; if points is not None -> sparse prediction. if prob_class is None -> single class prediction; if prob_class is not None -> multi class prediction; """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:76,Safety,predict,prediction,76,"""""""; if points is None -> dense prediction; if points is not None -> sparse prediction. if prob_class is None -> single class prediction; if prob_class is not None -> multi class prediction; """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:126,Safety,predict,prediction,126,"""""""; if points is None -> dense prediction; if points is not None -> sparse prediction. if prob_class is None -> single class prediction; if prob_class is not None -> multi class prediction; """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:179,Safety,predict,prediction,179,"""""""; if points is None -> dense prediction; if points is not None -> sparse prediction. if prob_class is None -> single class prediction; if prob_class is not None -> multi class prediction; """"""",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:9,Safety,predict,prediction,9,"# sparse prediction",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:8,Safety,predict,prediction,8,"# dense prediction",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:10,Usability,undo,undo,10,"# need to undo the scaling given by the scale dict, e.g. scale = dict(X=0.5,Y=0.5,Z=1.0):; # 1. re-scale points (origins of polyhedra); # 2. re-scale vectors of rays object (computed from distances)",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:579,Deployability,update,update,579,"# build the list of class ids per label via majority vote; # zoom prob_class to img_shape; # prob_class_up = zoom(prob_class,; # tuple(s2/s1 for s1, s2 in zip(prob_class.shape[:3], img_shape))+(1,),; # order=0); # class_id, label_ids = [], []; # for reg in regionprops(labels):; # m = labels[reg.slice]==reg.label; # cls_id = np.argmax(np.mean(prob_class_up[reg.slice][m], axis = 0)); # class_id.append(cls_id); # label_ids.append(reg.label); # # just a sanity check whether labels where in sorted order; # assert all(x <= y for x,y in zip(label_ids, label_ids[1:])); # res_dict.update(dict(classes = class_id)); # res_dict.update(dict(labels = label_ids)); # self.p = prob_class_up",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:624,Deployability,update,update,624,"# build the list of class ids per label via majority vote; # zoom prob_class to img_shape; # prob_class_up = zoom(prob_class,; # tuple(s2/s1 for s1, s2 in zip(prob_class.shape[:3], img_shape))+(1,),; # order=0); # class_id, label_ids = [], []; # for reg in regionprops(labels):; # m = labels[reg.slice]==reg.label; # cls_id = np.argmax(np.mean(prob_class_up[reg.slice][m], axis = 0)); # class_id.append(cls_id); # label_ids.append(reg.label); # # just a sanity check whether labels where in sorted order; # assert all(x <= y for x,y in zip(label_ids, label_ids[1:])); # res_dict.update(dict(classes = class_id)); # res_dict.update(dict(labels = label_ids)); # self.p = prob_class_up",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:454,Safety,sanity check,sanity check,454,"# build the list of class ids per label via majority vote; # zoom prob_class to img_shape; # prob_class_up = zoom(prob_class,; # tuple(s2/s1 for s1, s2 in zip(prob_class.shape[:3], img_shape))+(1,),; # order=0); # class_id, label_ids = [], []; # for reg in regionprops(labels):; # m = labels[reg.slice]==reg.label; # cls_id = np.argmax(np.mean(prob_class_up[reg.slice][m], axis = 0)); # class_id.append(cls_id); # label_ids.append(reg.label); # # just a sanity check whether labels where in sorted order; # assert all(x <= y for x,y in zip(label_ids, label_ids[1:])); # res_dict.update(dict(classes = class_id)); # res_dict.update(dict(labels = label_ids)); # self.p = prob_class_up",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py:507,Testability,assert,assert,507,"# build the list of class ids per label via majority vote; # zoom prob_class to img_shape; # prob_class_up = zoom(prob_class,; # tuple(s2/s1 for s1, s2 in zip(prob_class.shape[:3], img_shape))+(1,),; # order=0); # class_id, label_ids = [], []; # for reg in regionprops(labels):; # m = labels[reg.slice]==reg.label; # cls_id = np.argmax(np.mean(prob_class_up[reg.slice][m], axis = 0)); # class_id.append(cls_id); # label_ids.append(reg.label); # # just a sanity check whether labels where in sorted order; # assert all(x <= y for x,y in zip(label_ids, label_ids[1:])); # res_dict.update(dict(classes = class_id)); # res_dict.update(dict(labels = label_ids)); # self.p = prob_class_up",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py:92,Usability,simpl,simple,92,"""""""Renders a label image and optionally overlays it with another image. Used for generating simple output images to asses the label quality. Parameters; ----------; lbl: np.ndarray of dtype np.uint16; The 2D label image ; img: np.ndarray ; The array to overlay the label image with (optional); cmap: string, tuple, or callable; The label colormap. If given as rgb(a) only a single color is used, if None uses a random colormap ; cmap_img: string or callable; The colormap of img (optional); alpha: float ; The alpha value of the overlay. Set alpha=1 to get fully opaque labels; alpha_boundary: float; The alpha value of the boundary (if None, use the same as for labels, i.e. no boundaries are visible); normalize_img: bool; If True, normalizes the img (if given). Returns; -------; img: np.ndarray; the (m,n,4) RGBA image of the rendered label . Example; -------. from scipy.ndimage import label, zoom ; img = zoom(np.random.uniform(0,1,(16,16)),(8,8),order=3) ; lbl,_ = label(img>.8); u1 = render_label(lbl, img = img, alpha = .7); u2 = render_label(lbl, img = img, alpha = 0, alpha_boundary =.8); plt.subplot(1,2,1);plt.imshow(u1); plt.subplot(1,2,2);plt.imshow(u2). """"""",MatchSource.CODE_COMMENT,stardist/plot/render.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py:33,Energy Efficiency,green,green,33,"""""""; h0 = 0 -> red; h0 = 0.33 -> green; h0 = 0.66 -> blue; h0 = 0.833 -> magenta; """"""",MatchSource.CODE_COMMENT,stardist/plot/render.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py:44,Availability,error,errors,44,"""""""Renders an image that shows segmentation errors between y_true and y_pred . Correctly matched objects (TP) are colored green (with transparency tp_alpha); Erronously detected objects (FP) are colored red (with transparency fp_alpha); MIssing GT objects (FN) are colored blue (with transparency fn_alpha). Parameters; ----------; y_true: np.ndarray of dtype np.uint16; The 2D GT label image ; y_pred: np.ndarray of dtype np.uint16; The 2D prediction label image ; img: np.ndarray ; The array to overlay the label image with (optional); cmap_img: string or callable; The colormap of img (optional); tp_alpha: float ; The alpha value of the TP ; fp_alpha: float ; The alpha value of the FP ; fn_alpha: float ; The alpha value of the FN ; matching_kwargs: dict; The parameters of stardist.matching.matching that are used to compute the TP/FP/FN; normalize_img: bool; If True, normalizes the img (if given). Returns; -------; img: np.ndarray; the (m,n,4) RGBA image of the rendered image. Example; ------- . from scipy.ndimage import label, zoom ; img = zoom(np.random.uniform(0,1,(16,16)),(8,8),order=3); y_true = label(img>.9)[0]; y_pred = label(img>.02)[0]; plt.imshow(render_label_pred(y_true, y_pred, img=img)). """"""",MatchSource.CODE_COMMENT,stardist/plot/render.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py:122,Energy Efficiency,green,green,122,"""""""Renders an image that shows segmentation errors between y_true and y_pred . Correctly matched objects (TP) are colored green (with transparency tp_alpha); Erronously detected objects (FP) are colored red (with transparency fp_alpha); MIssing GT objects (FN) are colored blue (with transparency fn_alpha). Parameters; ----------; y_true: np.ndarray of dtype np.uint16; The 2D GT label image ; y_pred: np.ndarray of dtype np.uint16; The 2D prediction label image ; img: np.ndarray ; The array to overlay the label image with (optional); cmap_img: string or callable; The colormap of img (optional); tp_alpha: float ; The alpha value of the TP ; fp_alpha: float ; The alpha value of the FP ; fn_alpha: float ; The alpha value of the FN ; matching_kwargs: dict; The parameters of stardist.matching.matching that are used to compute the TP/FP/FN; normalize_img: bool; If True, normalizes the img (if given). Returns; -------; img: np.ndarray; the (m,n,4) RGBA image of the rendered image. Example; ------- . from scipy.ndimage import label, zoom ; img = zoom(np.random.uniform(0,1,(16,16)),(8,8),order=3); y_true = label(img>.9)[0]; y_pred = label(img>.02)[0]; plt.imshow(render_label_pred(y_true, y_pred, img=img)). """"""",MatchSource.CODE_COMMENT,stardist/plot/render.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py:169,Safety,detect,detected,169,"""""""Renders an image that shows segmentation errors between y_true and y_pred . Correctly matched objects (TP) are colored green (with transparency tp_alpha); Erronously detected objects (FP) are colored red (with transparency fp_alpha); MIssing GT objects (FN) are colored blue (with transparency fn_alpha). Parameters; ----------; y_true: np.ndarray of dtype np.uint16; The 2D GT label image ; y_pred: np.ndarray of dtype np.uint16; The 2D prediction label image ; img: np.ndarray ; The array to overlay the label image with (optional); cmap_img: string or callable; The colormap of img (optional); tp_alpha: float ; The alpha value of the TP ; fp_alpha: float ; The alpha value of the FP ; fn_alpha: float ; The alpha value of the FN ; matching_kwargs: dict; The parameters of stardist.matching.matching that are used to compute the TP/FP/FN; normalize_img: bool; If True, normalizes the img (if given). Returns; -------; img: np.ndarray; the (m,n,4) RGBA image of the rendered image. Example; ------- . from scipy.ndimage import label, zoom ; img = zoom(np.random.uniform(0,1,(16,16)),(8,8),order=3); y_true = label(img>.9)[0]; y_pred = label(img>.02)[0]; plt.imshow(render_label_pred(y_true, y_pred, img=img)). """"""",MatchSource.CODE_COMMENT,stardist/plot/render.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py:441,Safety,predict,prediction,441,"""""""Renders an image that shows segmentation errors between y_true and y_pred . Correctly matched objects (TP) are colored green (with transparency tp_alpha); Erronously detected objects (FP) are colored red (with transparency fp_alpha); MIssing GT objects (FN) are colored blue (with transparency fn_alpha). Parameters; ----------; y_true: np.ndarray of dtype np.uint16; The 2D GT label image ; y_pred: np.ndarray of dtype np.uint16; The 2D prediction label image ; img: np.ndarray ; The array to overlay the label image with (optional); cmap_img: string or callable; The colormap of img (optional); tp_alpha: float ; The alpha value of the TP ; fp_alpha: float ; The alpha value of the FP ; fn_alpha: float ; The alpha value of the FN ; matching_kwargs: dict; The parameters of stardist.matching.matching that are used to compute the TP/FP/FN; normalize_img: bool; If True, normalizes the img (if given). Returns; -------; img: np.ndarray; the (m,n,4) RGBA image of the rendered image. Example; ------- . from scipy.ndimage import label, zoom ; img = zoom(np.random.uniform(0,1,(16,16)),(8,8),order=3); y_true = label(img>.9)[0]; y_pred = label(img>.02)[0]; plt.imshow(render_label_pred(y_true, y_pred, img=img)). """"""",MatchSource.CODE_COMMENT,stardist/plot/render.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py:2,Energy Efficiency,green,green,2,"# green",MatchSource.CODE_COMMENT,stardist/plot/render.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict2d.py:28,Performance,perform,perform,28,""""""". Command line script to perform prediction in 2D. """"""",MatchSource.CODE_COMMENT,stardist/scripts/predict2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict2d.py:36,Safety,predict,prediction,36,""""""". Command line script to perform prediction in 2D. """"""",MatchSource.CODE_COMMENT,stardist/scripts/predict2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict2d.py:64,Safety,predict,predict,64,"""""""; Prediction script for a 2D stardist model, usage: stardist-predict -i input.tif -m model_folder_or_pretrained_name -o output_folder. """"""",MatchSource.CODE_COMMENT,stardist/scripts/predict2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict2d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict3d.py:28,Performance,perform,perform,28,""""""". Command line script to perform prediction in 3D. """"""",MatchSource.CODE_COMMENT,stardist/scripts/predict3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict3d.py:36,Safety,predict,prediction,36,""""""". Command line script to perform prediction in 3D. """"""",MatchSource.CODE_COMMENT,stardist/scripts/predict3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict3d.py
https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict3d.py:64,Safety,predict,predict,64,"""""""; Prediction script for a 3D stardist model, usage: stardist-predict -i input.tif -m model_folder_or_pretrained_name -o output_folder. """"""",MatchSource.CODE_COMMENT,stardist/scripts/predict3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict3d.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py:160,Safety,predict,predict-instances-big,160,"# in some cases need to add extra context to prevent overlapping write regions of non-neighboring blocks; # cf. https://forum.image.sc/t/trouble-using-stardist-predict-instances-big/88871/6",MatchSource.CODE_COMMENT,tests/test_big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py:173,Testability,assert,assert,173,"# 2024-01-25: failed on github actions: ""windows-latest"" in combination with tensorflow 2.15.0 (python 3.9, 3.10, and 3.11); # (m.mean_true_score was 0.9999979271079009); # assert (1.0, 1.0) == (m.accuracy, m.mean_true_score)",MatchSource.CODE_COMMENT,tests/test_big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py:161,Safety,predict,predictions,161,"# def test_repaint2D(model2d):; # np.random.seed(42); # model = model2d; # img = real_image2d()[0]; # img = normalize(img, 1, 99.8); # # get overlapping polygon predictions, wiggle them a bit, render reference label image; # polys = model.predict_instances(img, nms_thresh=0.97)[1]; # polys['coord'] += np.random.normal(scale=3, size=polys['coord'].shape[:2]+(1,)); # labels = render_polygons(polys, img.shape); # # shuffle polygon probabilities/scores and render label image; # polys2 = {k:v.copy() for k,v in polys.items()}; # np.random.shuffle(polys2['prob']); # labels2 = render_polygons(polys2, img.shape); # assert not np.all(labels == labels2); # # repaint all labels (which are visible in the reference label image); # repaint_ids = set(np.unique(labels)) - {0}; # repaint_labels(labels2, list(repaint_ids), polys); # assert np.all(labels == labels2); # def test_repaint3D(model3d):; # np.random.seed(42); # model = model3d; # img = real_image3d()[0]; # img = normalize(img, 1, 99.8); # # get overlapping polygon predictions, wiggle them a bit, render reference label image; # polys = model.predict_instances(img, nms_thresh=0.95)[1]; # polys['dist'] += np.random.normal(scale=3, size=polys['dist'].shape[:1]+(1,)); # polys['dist'] = np.maximum(1, polys['dist']); # labels = polyhedron_to_label(polys['dist'], polys['points'], polys['rays'], img.shape, prob=polys['prob']); # # shuffle polygon probabilities/scores and render label image; # polys2 = {k:v.copy() if isinstance(v,np.ndarray) else v for k,v in polys.items()}; # np.random.shuffle(polys2['prob']); # labels2 = polyhedron_to_label(polys2['dist'], polys2['points'], polys2['rays'], img.shape, prob=polys2['prob']); # assert np.count_nonzero(labels != labels2) > 10000; # # repaint all labels (which are visible in the reference label image); # repaint_ids = set(np.unique(labels)) - {0}; # repaint_labels(labels2, list(repaint_ids), polys); # assert np.count_nonzero(labels != labels2) < 10 # TODO: why not 0?",MatchSource.CODE_COMMENT,tests/test_big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py:1021,Safety,predict,predictions,1021,"# def test_repaint2D(model2d):; # np.random.seed(42); # model = model2d; # img = real_image2d()[0]; # img = normalize(img, 1, 99.8); # # get overlapping polygon predictions, wiggle them a bit, render reference label image; # polys = model.predict_instances(img, nms_thresh=0.97)[1]; # polys['coord'] += np.random.normal(scale=3, size=polys['coord'].shape[:2]+(1,)); # labels = render_polygons(polys, img.shape); # # shuffle polygon probabilities/scores and render label image; # polys2 = {k:v.copy() for k,v in polys.items()}; # np.random.shuffle(polys2['prob']); # labels2 = render_polygons(polys2, img.shape); # assert not np.all(labels == labels2); # # repaint all labels (which are visible in the reference label image); # repaint_ids = set(np.unique(labels)) - {0}; # repaint_labels(labels2, list(repaint_ids), polys); # assert np.all(labels == labels2); # def test_repaint3D(model3d):; # np.random.seed(42); # model = model3d; # img = real_image3d()[0]; # img = normalize(img, 1, 99.8); # # get overlapping polygon predictions, wiggle them a bit, render reference label image; # polys = model.predict_instances(img, nms_thresh=0.95)[1]; # polys['dist'] += np.random.normal(scale=3, size=polys['dist'].shape[:1]+(1,)); # polys['dist'] = np.maximum(1, polys['dist']); # labels = polyhedron_to_label(polys['dist'], polys['points'], polys['rays'], img.shape, prob=polys['prob']); # # shuffle polygon probabilities/scores and render label image; # polys2 = {k:v.copy() if isinstance(v,np.ndarray) else v for k,v in polys.items()}; # np.random.shuffle(polys2['prob']); # labels2 = polyhedron_to_label(polys2['dist'], polys2['points'], polys2['rays'], img.shape, prob=polys2['prob']); # assert np.count_nonzero(labels != labels2) > 10000; # # repaint all labels (which are visible in the reference label image); # repaint_ids = set(np.unique(labels)) - {0}; # repaint_labels(labels2, list(repaint_ids), polys); # assert np.count_nonzero(labels != labels2) < 10 # TODO: why not 0?",MatchSource.CODE_COMMENT,tests/test_big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py:614,Testability,assert,assert,614,"# def test_repaint2D(model2d):; # np.random.seed(42); # model = model2d; # img = real_image2d()[0]; # img = normalize(img, 1, 99.8); # # get overlapping polygon predictions, wiggle them a bit, render reference label image; # polys = model.predict_instances(img, nms_thresh=0.97)[1]; # polys['coord'] += np.random.normal(scale=3, size=polys['coord'].shape[:2]+(1,)); # labels = render_polygons(polys, img.shape); # # shuffle polygon probabilities/scores and render label image; # polys2 = {k:v.copy() for k,v in polys.items()}; # np.random.shuffle(polys2['prob']); # labels2 = render_polygons(polys2, img.shape); # assert not np.all(labels == labels2); # # repaint all labels (which are visible in the reference label image); # repaint_ids = set(np.unique(labels)) - {0}; # repaint_labels(labels2, list(repaint_ids), polys); # assert np.all(labels == labels2); # def test_repaint3D(model3d):; # np.random.seed(42); # model = model3d; # img = real_image3d()[0]; # img = normalize(img, 1, 99.8); # # get overlapping polygon predictions, wiggle them a bit, render reference label image; # polys = model.predict_instances(img, nms_thresh=0.95)[1]; # polys['dist'] += np.random.normal(scale=3, size=polys['dist'].shape[:1]+(1,)); # polys['dist'] = np.maximum(1, polys['dist']); # labels = polyhedron_to_label(polys['dist'], polys['points'], polys['rays'], img.shape, prob=polys['prob']); # # shuffle polygon probabilities/scores and render label image; # polys2 = {k:v.copy() if isinstance(v,np.ndarray) else v for k,v in polys.items()}; # np.random.shuffle(polys2['prob']); # labels2 = polyhedron_to_label(polys2['dist'], polys2['points'], polys2['rays'], img.shape, prob=polys2['prob']); # assert np.count_nonzero(labels != labels2) > 10000; # # repaint all labels (which are visible in the reference label image); # repaint_ids = set(np.unique(labels)) - {0}; # repaint_labels(labels2, list(repaint_ids), polys); # assert np.count_nonzero(labels != labels2) < 10 # TODO: why not 0?",MatchSource.CODE_COMMENT,tests/test_big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py:826,Testability,assert,assert,826,"# def test_repaint2D(model2d):; # np.random.seed(42); # model = model2d; # img = real_image2d()[0]; # img = normalize(img, 1, 99.8); # # get overlapping polygon predictions, wiggle them a bit, render reference label image; # polys = model.predict_instances(img, nms_thresh=0.97)[1]; # polys['coord'] += np.random.normal(scale=3, size=polys['coord'].shape[:2]+(1,)); # labels = render_polygons(polys, img.shape); # # shuffle polygon probabilities/scores and render label image; # polys2 = {k:v.copy() for k,v in polys.items()}; # np.random.shuffle(polys2['prob']); # labels2 = render_polygons(polys2, img.shape); # assert not np.all(labels == labels2); # # repaint all labels (which are visible in the reference label image); # repaint_ids = set(np.unique(labels)) - {0}; # repaint_labels(labels2, list(repaint_ids), polys); # assert np.all(labels == labels2); # def test_repaint3D(model3d):; # np.random.seed(42); # model = model3d; # img = real_image3d()[0]; # img = normalize(img, 1, 99.8); # # get overlapping polygon predictions, wiggle them a bit, render reference label image; # polys = model.predict_instances(img, nms_thresh=0.95)[1]; # polys['dist'] += np.random.normal(scale=3, size=polys['dist'].shape[:1]+(1,)); # polys['dist'] = np.maximum(1, polys['dist']); # labels = polyhedron_to_label(polys['dist'], polys['points'], polys['rays'], img.shape, prob=polys['prob']); # # shuffle polygon probabilities/scores and render label image; # polys2 = {k:v.copy() if isinstance(v,np.ndarray) else v for k,v in polys.items()}; # np.random.shuffle(polys2['prob']); # labels2 = polyhedron_to_label(polys2['dist'], polys2['points'], polys2['rays'], img.shape, prob=polys2['prob']); # assert np.count_nonzero(labels != labels2) > 10000; # # repaint all labels (which are visible in the reference label image); # repaint_ids = set(np.unique(labels)) - {0}; # repaint_labels(labels2, list(repaint_ids), polys); # assert np.count_nonzero(labels != labels2) < 10 # TODO: why not 0?",MatchSource.CODE_COMMENT,tests/test_big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py:1686,Testability,assert,assert,1686,"# def test_repaint2D(model2d):; # np.random.seed(42); # model = model2d; # img = real_image2d()[0]; # img = normalize(img, 1, 99.8); # # get overlapping polygon predictions, wiggle them a bit, render reference label image; # polys = model.predict_instances(img, nms_thresh=0.97)[1]; # polys['coord'] += np.random.normal(scale=3, size=polys['coord'].shape[:2]+(1,)); # labels = render_polygons(polys, img.shape); # # shuffle polygon probabilities/scores and render label image; # polys2 = {k:v.copy() for k,v in polys.items()}; # np.random.shuffle(polys2['prob']); # labels2 = render_polygons(polys2, img.shape); # assert not np.all(labels == labels2); # # repaint all labels (which are visible in the reference label image); # repaint_ids = set(np.unique(labels)) - {0}; # repaint_labels(labels2, list(repaint_ids), polys); # assert np.all(labels == labels2); # def test_repaint3D(model3d):; # np.random.seed(42); # model = model3d; # img = real_image3d()[0]; # img = normalize(img, 1, 99.8); # # get overlapping polygon predictions, wiggle them a bit, render reference label image; # polys = model.predict_instances(img, nms_thresh=0.95)[1]; # polys['dist'] += np.random.normal(scale=3, size=polys['dist'].shape[:1]+(1,)); # polys['dist'] = np.maximum(1, polys['dist']); # labels = polyhedron_to_label(polys['dist'], polys['points'], polys['rays'], img.shape, prob=polys['prob']); # # shuffle polygon probabilities/scores and render label image; # polys2 = {k:v.copy() if isinstance(v,np.ndarray) else v for k,v in polys.items()}; # np.random.shuffle(polys2['prob']); # labels2 = polyhedron_to_label(polys2['dist'], polys2['points'], polys2['rays'], img.shape, prob=polys2['prob']); # assert np.count_nonzero(labels != labels2) > 10000; # # repaint all labels (which are visible in the reference label image); # repaint_ids = set(np.unique(labels)) - {0}; # repaint_labels(labels2, list(repaint_ids), polys); # assert np.count_nonzero(labels != labels2) < 10 # TODO: why not 0?",MatchSource.CODE_COMMENT,tests/test_big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py:1912,Testability,assert,assert,1912,"# def test_repaint2D(model2d):; # np.random.seed(42); # model = model2d; # img = real_image2d()[0]; # img = normalize(img, 1, 99.8); # # get overlapping polygon predictions, wiggle them a bit, render reference label image; # polys = model.predict_instances(img, nms_thresh=0.97)[1]; # polys['coord'] += np.random.normal(scale=3, size=polys['coord'].shape[:2]+(1,)); # labels = render_polygons(polys, img.shape); # # shuffle polygon probabilities/scores and render label image; # polys2 = {k:v.copy() for k,v in polys.items()}; # np.random.shuffle(polys2['prob']); # labels2 = render_polygons(polys2, img.shape); # assert not np.all(labels == labels2); # # repaint all labels (which are visible in the reference label image); # repaint_ids = set(np.unique(labels)) - {0}; # repaint_labels(labels2, list(repaint_ids), polys); # assert np.all(labels == labels2); # def test_repaint3D(model3d):; # np.random.seed(42); # model = model3d; # img = real_image3d()[0]; # img = normalize(img, 1, 99.8); # # get overlapping polygon predictions, wiggle them a bit, render reference label image; # polys = model.predict_instances(img, nms_thresh=0.95)[1]; # polys['dist'] += np.random.normal(scale=3, size=polys['dist'].shape[:1]+(1,)); # polys['dist'] = np.maximum(1, polys['dist']); # labels = polyhedron_to_label(polys['dist'], polys['points'], polys['rays'], img.shape, prob=polys['prob']); # # shuffle polygon probabilities/scores and render label image; # polys2 = {k:v.copy() if isinstance(v,np.ndarray) else v for k,v in polys.items()}; # np.random.shuffle(polys2['prob']); # labels2 = polyhedron_to_label(polys2['dist'], polys2['points'], polys2['rays'], img.shape, prob=polys2['prob']); # assert np.count_nonzero(labels != labels2) > 10000; # # repaint all labels (which are visible in the reference label image); # repaint_ids = set(np.unique(labels)) - {0}; # repaint_labels(labels2, list(repaint_ids), polys); # assert np.count_nonzero(labels != labels2) < 10 # TODO: why not 0?",MatchSource.CODE_COMMENT,tests/test_big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py:2,Availability,mask,mask,2,"# mask of object with id i in label image (not occluded since nms_thresh=0)",MatchSource.CODE_COMMENT,tests/test_big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py:2,Availability,mask,mask,2,"# mask of object with id i in label image (not occluded since nms_thresh=0)",MatchSource.CODE_COMMENT,tests/test_big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py:18,Availability,mask,mask,18,"# assert np.all(p.mask == mask_i) # few pixels are sometimes different, why?",MatchSource.CODE_COMMENT,tests/test_big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py:2,Testability,assert,assert,2,"# assert np.all(p.mask == mask_i) # few pixels are sometimes different, why?",MatchSource.CODE_COMMENT,tests/test_big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_bioimageio.py:2,Testability,test,test,2,"# test exported model",MatchSource.CODE_COMMENT,tests/test_bioimageio.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_bioimageio.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_bioimageio.py:2,Testability,test,test,2,"# test that model and imported exported model are equal",MatchSource.CODE_COMMENT,tests/test_bioimageio.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_bioimageio.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py:2,Deployability,integrat,integration,2,"# integration test",MatchSource.CODE_COMMENT,tests/test_model2D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py:2,Integrability,integrat,integration,2,"# integration test",MatchSource.CODE_COMMENT,tests/test_model2D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py:14,Testability,test,test,14,"# integration test",MatchSource.CODE_COMMENT,tests/test_model2D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py:57,Testability,assert,assert,57,"# deactivate as order of labels might not be the same; # assert all(np.allclose(u,v) for u,v in zip(ref,res))",MatchSource.CODE_COMMENT,tests/test_model2D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py:36,Deployability,patch,patches,36,"# ask to train only with foreground patches when there are none; # include a constant label image that must trigger a warning",MatchSource.CODE_COMMENT,tests/test_model2D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py:2,Availability,mask,mask,2,"# mask to make labels negative",MatchSource.CODE_COMMENT,tests/test_model2D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py:148,Testability,assert,assert,148,"# labels3, res3 = model.predict_instances_big(img, axes=""YX"" if img.ndim==2 else ""YXC"",; # block_size=640, min_overlap=32, context=96, **kwargs); # assert matching(labels1, labels3, thresh=0.99).f1 == 1",MatchSource.CODE_COMMENT,tests/test_model2D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py:296,Testability,assert,assert,296,"# y2, res2 = model._instances_from_prediction_old(img.shape,prob,dist, nms_thresh=.3); # # reorder as polygons is inverted in newer versions; # res2 = dict((k,v[::-1]) for k,v in res2.items()); # y2[y2>0] = np.max(y2)-y2[y2>0]+1; # for k in res1.keys():; # if isinstance(res1[k], np.ndarray):; # assert np.allclose(res1[k],res2[k]); # assert np.allclose(y1,y2); # return y1, res1, y2, res2",MatchSource.CODE_COMMENT,tests/test_model2D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py:335,Testability,assert,assert,335,"# y2, res2 = model._instances_from_prediction_old(img.shape,prob,dist, nms_thresh=.3); # # reorder as polygons is inverted in newer versions; # res2 = dict((k,v[::-1]) for k,v in res2.items()); # y2[y2>0] = np.max(y2)-y2[y2>0]+1; # for k in res1.keys():; # if isinstance(res1[k], np.ndarray):; # assert np.allclose(res1[k],res2[k]); # assert np.allclose(y1,y2); # return y1, res1, y2, res2",MatchSource.CODE_COMMENT,tests/test_model2D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py:75,Testability,test,test,75,"# x = zoom(x, (0.5,0.5) if x.ndim==2 else (0.5,0.5,1), order=1) # to speed test up",MatchSource.CODE_COMMENT,tests/test_model2D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py:7,Testability,test,test,7,"# this test has to be at the end of the model",MatchSource.CODE_COMMENT,tests/test_model2D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_model3D.py:2,Deployability,integrat,integration,2,"# integration test",MatchSource.CODE_COMMENT,tests/test_model3D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model3D.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_model3D.py:2,Integrability,integrat,integration,2,"# integration test",MatchSource.CODE_COMMENT,tests/test_model3D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model3D.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_model3D.py:14,Testability,test,test,14,"# integration test",MatchSource.CODE_COMMENT,tests/test_model3D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model3D.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_model3D.py:57,Testability,assert,assert,57,"# deactivate as order of labels might not be the same; # assert all(np.allclose(u,v) for u,v in zip(ref,res))",MatchSource.CODE_COMMENT,tests/test_model3D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model3D.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_model3D.py:36,Deployability,patch,patches,36,"# ask to train only with foreground patches when there are none; # include a constant label image that must trigger a warning",MatchSource.CODE_COMMENT,tests/test_model3D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model3D.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_model3D.py:2,Availability,mask,mask,2,"# mask to make labels negative",MatchSource.CODE_COMMENT,tests/test_model3D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model3D.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_model3D.py:7,Testability,test,test,7,"# this test has to be at the end of the model",MatchSource.CODE_COMMENT,tests/test_model3D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model3D.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_stardist2D.py:4,Testability,test,test,4,""""""" test whether an already star-convex label image gets perfectly relabeld""""""",MatchSource.CODE_COMMENT,tests/test_stardist2D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_stardist2D.py
https://github.com/stardist/stardist/tree/0.9.1/tests/test_stardist3D.py:4,Testability,test,test,4,""""""" test whether an already star-convex label image gets perfectly relabeld""""""",MatchSource.CODE_COMMENT,tests/test_stardist3D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_stardist3D.py
