quality_attribute,keyword,matched_word,sentence,source,filename,author,repo,version,wiki,url
Availability,error,errors,"# https://www.openmp.org/resources/openmp-compilers-tools/; # python setup.py build_ext --help-compiler; # ?; # thanks to @jaimergp (https://github.com/conda-forge/staged-recipes/pull/17766); # issue: qhull has a mix of c and c++ source files; # gcc warns about passing -std=c++11 for c files, but clang errors out; # remove c++ specific (extra) options for c files; # monkey patch the _compile method; # store original args; # try compiler-specific flag(s) to enable openmp; #------------------------------------------------------------------------------------; # https://stackoverflow.com/a/22866630; # python setup.py sdist -> __file__ is relative path; # python /absolute/path/to/setup.py sdist -> __file__ is absolute path; # python -m build --sdist -> __file__ is absolute path; # cf. https://github.com/mkleehammer/pyodbc/issues/82#issuecomment-231561240; # _dir = path.dirname(__file__); # assumption: Path(__file__).parent == Path.cwd()",MatchSource.CODE_COMMENT,setup.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/setup.py
Deployability,patch,patch,"# https://www.openmp.org/resources/openmp-compilers-tools/; # python setup.py build_ext --help-compiler; # ?; # thanks to @jaimergp (https://github.com/conda-forge/staged-recipes/pull/17766); # issue: qhull has a mix of c and c++ source files; # gcc warns about passing -std=c++11 for c files, but clang errors out; # remove c++ specific (extra) options for c files; # monkey patch the _compile method; # store original args; # try compiler-specific flag(s) to enable openmp; #------------------------------------------------------------------------------------; # https://stackoverflow.com/a/22866630; # python setup.py sdist -> __file__ is relative path; # python /absolute/path/to/setup.py sdist -> __file__ is absolute path; # python -m build --sdist -> __file__ is absolute path; # cf. https://github.com/mkleehammer/pyodbc/issues/82#issuecomment-231561240; # _dir = path.dirname(__file__); # assumption: Path(__file__).parent == Path.cwd()",MatchSource.CODE_COMMENT,setup.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/setup.py
Availability,mask,mask,"r t in first]; # add extra context to avoid overlapping write regions of non-neighboring blocks; # print(); [print(t) for t in first]; # make a copy of the cover and multiply sizes by grid; #; # change size of last block; # will be padded internally to the same size; # as the others by model.predict_instances; # for efficiency (to not determine starts recursively from now on); # print(); [print(t) for t in first]; # sanity checks; # print(); [print(t) for t in first]; # only neighboring blocks should be overlapping; """"""N-dimensional block. Each BlockND simply consists of a 1-dimensional Block per axis and also; has an id (which should be unique). The n-dimensional region represented; by each BlockND is the intersection of all 1D Blocks per axis. Also see `Block`. """"""; """"""Read block ""read region"" from x (numpy.ndarray or similar)""""""; """"""Write (only entries > 0 of) labels to block ""write region"" of x (numpy.ndarray or similar)""""""; # x[s][mask] = labels[mask] # doesn't work with zarr; # ------------------------; """"""Filter out objects that block is not responsible for. Given label image 'labels' and dictionary 'polys' of polygon/polyhedron objects,; only retain those objects that this block is responsible for. This function will return a pair (labels, polys) of the modified label image and dictionary.; It will raise a RuntimeError if an object is found in the overlap area; of neighboring blocks that violates the assumption to be smaller than 'min_overlap'. If parameter 'polys' is None, only the filtered label image will be returned. Notes; -----; - Important: It is assumed that the object label ids in 'labels' and; the entries in 'polys' are sorted in the same way.; - Does not modify 'labels' and 'polys', but returns modified copies. Example; -------; >>> labels, polys = model.predict_instances(block.read(img)); >>> labels = block.crop_context(labels); >>> labels, polys = block.filter_objects(labels, polys). """"""; # TODO: option to update labels in-place; # problem_ids =",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
Deployability,update,update,"with zarr; # ------------------------; """"""Filter out objects that block is not responsible for. Given label image 'labels' and dictionary 'polys' of polygon/polyhedron objects,; only retain those objects that this block is responsible for. This function will return a pair (labels, polys) of the modified label image and dictionary.; It will raise a RuntimeError if an object is found in the overlap area; of neighboring blocks that violates the assumption to be smaller than 'min_overlap'. If parameter 'polys' is None, only the filtered label image will be returned. Notes; -----; - Important: It is assumed that the object label ids in 'labels' and; the entries in 'polys' are sorted in the same way.; - Does not modify 'labels' and 'polys', but returns modified copies. Example; -------; >>> labels, polys = model.predict_instances(block.read(img)); >>> labels = block.crop_context(labels); >>> labels, polys = block.filter_objects(labels, polys). """"""; # TODO: option to update labels in-place; # problem_ids = []; # shape_block_write = tuple(s.stop-s.start for s in self.slice_write(axes)); # if e.args[0]: # object larger than block write region; # assert any(o >= b for o,b in zip(shape_object,shape_block_write)); # # problem, since this object will probably be saved by another block too; # raise RuntimeError(f""Found object of shape {shape_object}, larger than an entire block's write region of shape {shape_block_write}. Increase 'block_size' to avoid this problem.""); # # print(""found object larger than 'block_size'""); # else:; # assert any(o >= b for o,b in zip(shape_object,shape_min_overlap)); # # print(""found object larger than 'min_overlap'""); # # keep object, because will be dealt with later, i.e.; # # render the poly again into the label image, but this is not; # # ideal since the assumption is that the object outside that; # # region is not reliable because it's in the context; # labels_filtered[slices][r.image] = r.label; # problem_ids.append(r.label); # assert len(probl",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
Safety,avoid,avoid,"verlap region, i.e. is only partially visible here and also by the predecessor block; # object ends before responsible region start; # object touches the end of the responsible region (only take if at end); # ------------------------; # ------------------------; """"""Return chain of grid-aligned blocks to cover the interval [0,size]. Parameters block_size, min_overlap, and context will be used; for all blocks of the chain. Only the size of the last block; may differ. Except for the last block, start and end positions of all blocks will; be multiples of grid. To that end, the provided block parameters may; be increased to achieve that. Note that parameters must be chosen such that the write regions of only; neighboring blocks are overlapping. """"""; # allow size not to be divisible by grid; # divide all sizes by grid; # compute cover in grid-multiples; # print(); [print(t) for t in first]; # move blocks around to make it fit; # print(); [print(t) for t in first]; # add extra context to avoid overlapping write regions of non-neighboring blocks; # print(); [print(t) for t in first]; # make a copy of the cover and multiply sizes by grid; #; # change size of last block; # will be padded internally to the same size; # as the others by model.predict_instances; # for efficiency (to not determine starts recursively from now on); # print(); [print(t) for t in first]; # sanity checks; # print(); [print(t) for t in first]; # only neighboring blocks should be overlapping; """"""N-dimensional block. Each BlockND simply consists of a 1-dimensional Block per axis and also; has an id (which should be unique). The n-dimensional region represented; by each BlockND is the intersection of all 1D Blocks per axis. Also see `Block`. """"""; """"""Read block ""read region"" from x (numpy.ndarray or similar)""""""; """"""Write (only entries > 0 of) labels to block ""write region"" of x (numpy.ndarray or similar)""""""; # x[s][mask] = labels[mask] # doesn't work with zarr; # ------------------------; """"""Filter out obj",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
Testability,assert,assert,"erlap with one another (at least min_overlap + 2*context) and; have a read region (the entire block) and a write region (ignoring context).; Given a query interval, Block.is_responsible will return true for only one; block of a chain (or raise an exception if the interval is larger than; min_overlap or even the entire block without context). """"""; """"""Call on first block to freeze entire chain (after construction is done)""""""; """"""Crop context relative to read region""""""; """"""Responsibility for query interval bbox, which is assumed to be smaller than min_overlap. If the assumption is met, only one block of a chain will return true.; If violated, one or more blocks of a chain may raise a NotFullyVisible exception.; The exception will have an argument that is; False if bbox is larger than min_overlap, and; True if bbox is even larger than the entire block without context. bbox: (int,int); 1D bounding box interval with coordinates relative to size without context. """"""; # assert not (bmin == 0 and bmax >= r_start and not self.at_begin), [(r_start,r_end), bbox, self]; # object spans the entire block, i.e. is probably larger than size (minus the context); # object spans the entire overlap region, i.e. is only partially visible here and also by the predecessor block; # object ends before responsible region start; # object touches the end of the responsible region (only take if at end); # ------------------------; # ------------------------; """"""Return chain of grid-aligned blocks to cover the interval [0,size]. Parameters block_size, min_overlap, and context will be used; for all blocks of the chain. Only the size of the last block; may differ. Except for the last block, start and end positions of all blocks will; be multiples of grid. To that end, the provided block parameters may; be increased to achieve that. Note that parameters must be chosen such that the write regions of only; neighboring blocks are overlapping. """"""; # allow size not to be divisible by grid; # divide all si",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
Usability,simpl,simply,"grid. To that end, the provided block parameters may; be increased to achieve that. Note that parameters must be chosen such that the write regions of only; neighboring blocks are overlapping. """"""; # allow size not to be divisible by grid; # divide all sizes by grid; # compute cover in grid-multiples; # print(); [print(t) for t in first]; # move blocks around to make it fit; # print(); [print(t) for t in first]; # add extra context to avoid overlapping write regions of non-neighboring blocks; # print(); [print(t) for t in first]; # make a copy of the cover and multiply sizes by grid; #; # change size of last block; # will be padded internally to the same size; # as the others by model.predict_instances; # for efficiency (to not determine starts recursively from now on); # print(); [print(t) for t in first]; # sanity checks; # print(); [print(t) for t in first]; # only neighboring blocks should be overlapping; """"""N-dimensional block. Each BlockND simply consists of a 1-dimensional Block per axis and also; has an id (which should be unique). The n-dimensional region represented; by each BlockND is the intersection of all 1D Blocks per axis. Also see `Block`. """"""; """"""Read block ""read region"" from x (numpy.ndarray or similar)""""""; """"""Write (only entries > 0 of) labels to block ""write region"" of x (numpy.ndarray or similar)""""""; # x[s][mask] = labels[mask] # doesn't work with zarr; # ------------------------; """"""Filter out objects that block is not responsible for. Given label image 'labels' and dictionary 'polys' of polygon/polyhedron objects,; only retain those objects that this block is responsible for. This function will return a pair (labels, polys) of the modified label image and dictionary.; It will raise a RuntimeError if an object is found in the overlap area; of neighboring blocks that violates the assumption to be smaller than 'min_overlap'. If parameter 'polys' is None, only the filtered label image will be returned. Notes; -----; - Important: It is assumed that",MatchSource.CODE_COMMENT,stardist/big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/big.py
Availability,down,download,"ple 'YX' for a 2d image or 'ZYX' for a 3d volume; using None assumes that axes of test_input are the same as those of model; test_input_norm_axes: str; the axes of the test input which will be jointly normalized, for example 'ZYX' for all spatial dimensions ('Z' ignored for 2D input); use 'ZYXC' to also jointly normalize channels (e.g. for RGB input images); name: str; the name of this model (default: None); if None, uses the (folder) name of the model (i.e. `model.name`); mode: str; the export type for this model (default: ""tensorflow_saved_model_bundle""); min_percentile: float; min percentile to be used for image normalization (default: 1.0); max_percentile: float; max percentile to be used for image normalization (default: 99.8); overwrite_spec_kwargs: dict or None; spec keywords that should be overloaded (default: None); generate_default_deps: bool; not required for bioimage.io, i.e. StarDist models don't need a dependencies field in rdf.yaml (default: False); if True, generate an environment.yaml file recording the python, bioimageio.core, stardist and tensorflow requirements; from which a conda environment can be recreated to run this export; """"""; """"""Import stardist model from bioimage.io format, https://github.com/bioimage-io/spec-bioimage-io. Load a model in bioimage.io format from the given `source` (e.g. path to zip file, URL); and convert it to a regular stardist model, which will be saved in the folder `outpath`. Parameters; ----------; source: str, Path; bioimage.io resource (e.g. path, URL); outpath: str, Path; folder to save the stardist model (must not exist previously). Returns; -------; StarDist2D or StarDist3D; stardist model loaded from `outpath`. """"""; # download the full model content to a temporary folder; # read the stardist specific content; # make sure that the keras weights are in the attachments; # save the config and threshold to json, and weights to hdf5 to enable loading as stardist model; # copy bioimageio files to separate sub-folder",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
Deployability,install,installed,"""""""; //*******************************************************************; // Date: July-2021; // Credits: StarDist, DeepImageJ; // URL:; // https://github.com/stardist/stardist; // https://deepimagej.github.io/deepimagej; // This macro was adapted from; // https://github.com/deepimagej/imagej-macros/blob/648caa867f6ccb459649d4d3799efa1e2e0c5204/StarDist2D_Post-processing.ijm; // Please cite the respective contributions when using this code.; //*******************************************************************; // Macro to run StarDist postprocessing on 2D images.; // StarDist and deepImageJ plugins need to be installed.; // The macro assumes that the image to process is a stack in which; // the first channel corresponds to the object probability map; // and the remaining channels are the radial distances from each; // pixel to the object boundary.; //*******************************************************************. // Get the name of the image to call it; getDimensions(width, height, channels, slices, frames);; name=getTitle();. probThresh={probThresh};; nmsThresh={nmsThresh};. // Isolate the detection probability scores; run(""Make Substack..."", ""channels=1"");; rename(""scores"");. // Isolate the oriented distances; run(""Fire"");; selectWindow(name);; run(""Delete Slice"", ""delete=channel"");; selectWindow(name);; run(""Properties..."", ""channels="" + maxOf(channels, slices) - 1 + "" slices=1 frames=1 pixel_width=1.0000 pixel_height=1.0000 voxel_depth=1.0000"");; rename(""distances"");; run(""royal"");. // Run StarDist plugin; run(""Command From Macro"", ""command=[de.csbdresden.stardist.StarDist2DNMS], args=['prob':'scores', 'dist':'distances', 'probThresh':'"" + probThresh + ""', 'nmsThresh':'"" + nmsThresh + ""', 'outputType':'Both', 'excludeBoundary':'2', 'roiPosition':'Stack', 'verbose':'false'], process=[false]"");; """"""; # type: ignore; # type: ignore; # dependencies that start with the name ""bioimageio"" will be added as conda dependencies; # only stardist and tensorflow as pip",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
Energy Efficiency,adapt,adapted,"""""""; //*******************************************************************; // Date: July-2021; // Credits: StarDist, DeepImageJ; // URL:; // https://github.com/stardist/stardist; // https://deepimagej.github.io/deepimagej; // This macro was adapted from; // https://github.com/deepimagej/imagej-macros/blob/648caa867f6ccb459649d4d3799efa1e2e0c5204/StarDist2D_Post-processing.ijm; // Please cite the respective contributions when using this code.; //*******************************************************************; // Macro to run StarDist postprocessing on 2D images.; // StarDist and deepImageJ plugins need to be installed.; // The macro assumes that the image to process is a stack in which; // the first channel corresponds to the object probability map; // and the remaining channels are the radial distances from each; // pixel to the object boundary.; //*******************************************************************. // Get the name of the image to call it; getDimensions(width, height, channels, slices, frames);; name=getTitle();. probThresh={probThresh};; nmsThresh={nmsThresh};. // Isolate the detection probability scores; run(""Make Substack..."", ""channels=1"");; rename(""scores"");. // Isolate the oriented distances; run(""Fire"");; selectWindow(name);; run(""Delete Slice"", ""delete=channel"");; selectWindow(name);; run(""Properties..."", ""channels="" + maxOf(channels, slices) - 1 + "" slices=1 frames=1 pixel_width=1.0000 pixel_height=1.0000 voxel_depth=1.0000"");; rename(""distances"");; run(""royal"");. // Run StarDist plugin; run(""Command From Macro"", ""command=[de.csbdresden.stardist.StarDist2DNMS], args=['prob':'scores', 'dist':'distances', 'probThresh':'"" + probThresh + ""', 'nmsThresh':'"" + nmsThresh + ""', 'outputType':'Both', 'excludeBoundary':'2', 'roiPosition':'Stack', 'verbose':'false'], process=[false]"");; """"""; # type: ignore; # type: ignore; # dependencies that start with the name ""bioimageio"" will be added as conda dependencies; # only stardist and tensorflow as pip",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
Integrability,depend,dependencies,"***************************************************. // Get the name of the image to call it; getDimensions(width, height, channels, slices, frames);; name=getTitle();. probThresh={probThresh};; nmsThresh={nmsThresh};. // Isolate the detection probability scores; run(""Make Substack..."", ""channels=1"");; rename(""scores"");. // Isolate the oriented distances; run(""Fire"");; selectWindow(name);; run(""Delete Slice"", ""delete=channel"");; selectWindow(name);; run(""Properties..."", ""channels="" + maxOf(channels, slices) - 1 + "" slices=1 frames=1 pixel_width=1.0000 pixel_height=1.0000 voxel_depth=1.0000"");; rename(""distances"");; run(""royal"");. // Run StarDist plugin; run(""Command From Macro"", ""command=[de.csbdresden.stardist.StarDist2DNMS], args=['prob':'scores', 'dist':'distances', 'probThresh':'"" + probThresh + ""', 'nmsThresh':'"" + nmsThresh + ""', 'outputType':'Both', 'excludeBoundary':'2', 'roiPosition':'Stack', 'verbose':'false'], process=[false]"");; """"""; # type: ignore; # type: ignore; # dependencies that start with the name ""bioimageio"" will be added as conda dependencies; # only stardist and tensorflow as pip dependencies; # conda environment; # modality; # dims; # content; # framework; # software; # network; # task; # only if requested, as not required for bioimage.io; # need to unzip the model assets; # make a new graph, i.e. don't use the global default graph; # get the path to the exported model assets (saved in outdir); # to force ""inputs.data_type: float32"" in the spec (bonus: disables normalization warning in model._predict_setup); # convert test_input to axes_net semantics and shape, also resize if necessary (to adhere to axes_net_div_by); # normalization axes string and numeric indices; # preserve order of axes_net; # normalize input image; # add the batch axis to shape and step; # the axes strings in bioimageio convention; # the output shape is computed from the input shape using; # output_shape[i] = output_scale[i] * input_shape[i] + 2 * output_offset[i]; # regar",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
Modifiability,adapt,adapted,"""""""; //*******************************************************************; // Date: July-2021; // Credits: StarDist, DeepImageJ; // URL:; // https://github.com/stardist/stardist; // https://deepimagej.github.io/deepimagej; // This macro was adapted from; // https://github.com/deepimagej/imagej-macros/blob/648caa867f6ccb459649d4d3799efa1e2e0c5204/StarDist2D_Post-processing.ijm; // Please cite the respective contributions when using this code.; //*******************************************************************; // Macro to run StarDist postprocessing on 2D images.; // StarDist and deepImageJ plugins need to be installed.; // The macro assumes that the image to process is a stack in which; // the first channel corresponds to the object probability map; // and the remaining channels are the radial distances from each; // pixel to the object boundary.; //*******************************************************************. // Get the name of the image to call it; getDimensions(width, height, channels, slices, frames);; name=getTitle();. probThresh={probThresh};; nmsThresh={nmsThresh};. // Isolate the detection probability scores; run(""Make Substack..."", ""channels=1"");; rename(""scores"");. // Isolate the oriented distances; run(""Fire"");; selectWindow(name);; run(""Delete Slice"", ""delete=channel"");; selectWindow(name);; run(""Properties..."", ""channels="" + maxOf(channels, slices) - 1 + "" slices=1 frames=1 pixel_width=1.0000 pixel_height=1.0000 voxel_depth=1.0000"");; rename(""distances"");; run(""royal"");. // Run StarDist plugin; run(""Command From Macro"", ""command=[de.csbdresden.stardist.StarDist2DNMS], args=['prob':'scores', 'dist':'distances', 'probThresh':'"" + probThresh + ""', 'nmsThresh':'"" + nmsThresh + ""', 'outputType':'Both', 'excludeBoundary':'2', 'roiPosition':'Stack', 'verbose':'false'], process=[false]"");; """"""; # type: ignore; # type: ignore; # dependencies that start with the name ""bioimageio"" will be added as conda dependencies; # only stardist and tensorflow as pip",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
Performance,load,loaded,"ple 'YX' for a 2d image or 'ZYX' for a 3d volume; using None assumes that axes of test_input are the same as those of model; test_input_norm_axes: str; the axes of the test input which will be jointly normalized, for example 'ZYX' for all spatial dimensions ('Z' ignored for 2D input); use 'ZYXC' to also jointly normalize channels (e.g. for RGB input images); name: str; the name of this model (default: None); if None, uses the (folder) name of the model (i.e. `model.name`); mode: str; the export type for this model (default: ""tensorflow_saved_model_bundle""); min_percentile: float; min percentile to be used for image normalization (default: 1.0); max_percentile: float; max percentile to be used for image normalization (default: 99.8); overwrite_spec_kwargs: dict or None; spec keywords that should be overloaded (default: None); generate_default_deps: bool; not required for bioimage.io, i.e. StarDist models don't need a dependencies field in rdf.yaml (default: False); if True, generate an environment.yaml file recording the python, bioimageio.core, stardist and tensorflow requirements; from which a conda environment can be recreated to run this export; """"""; """"""Import stardist model from bioimage.io format, https://github.com/bioimage-io/spec-bioimage-io. Load a model in bioimage.io format from the given `source` (e.g. path to zip file, URL); and convert it to a regular stardist model, which will be saved in the folder `outpath`. Parameters; ----------; source: str, Path; bioimage.io resource (e.g. path, URL); outpath: str, Path; folder to save the stardist model (must not exist previously). Returns; -------; StarDist2D or StarDist3D; stardist model loaded from `outpath`. """"""; # download the full model content to a temporary folder; # read the stardist specific content; # make sure that the keras weights are in the attachments; # save the config and threshold to json, and weights to hdf5 to enable loading as stardist model; # copy bioimageio files to separate sub-folder",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
Safety,detect,detection," URL:; // https://github.com/stardist/stardist; // https://deepimagej.github.io/deepimagej; // This macro was adapted from; // https://github.com/deepimagej/imagej-macros/blob/648caa867f6ccb459649d4d3799efa1e2e0c5204/StarDist2D_Post-processing.ijm; // Please cite the respective contributions when using this code.; //*******************************************************************; // Macro to run StarDist postprocessing on 2D images.; // StarDist and deepImageJ plugins need to be installed.; // The macro assumes that the image to process is a stack in which; // the first channel corresponds to the object probability map; // and the remaining channels are the radial distances from each; // pixel to the object boundary.; //*******************************************************************. // Get the name of the image to call it; getDimensions(width, height, channels, slices, frames);; name=getTitle();. probThresh={probThresh};; nmsThresh={nmsThresh};. // Isolate the detection probability scores; run(""Make Substack..."", ""channels=1"");; rename(""scores"");. // Isolate the oriented distances; run(""Fire"");; selectWindow(name);; run(""Delete Slice"", ""delete=channel"");; selectWindow(name);; run(""Properties..."", ""channels="" + maxOf(channels, slices) - 1 + "" slices=1 frames=1 pixel_width=1.0000 pixel_height=1.0000 voxel_depth=1.0000"");; rename(""distances"");; run(""royal"");. // Run StarDist plugin; run(""Command From Macro"", ""command=[de.csbdresden.stardist.StarDist2DNMS], args=['prob':'scores', 'dist':'distances', 'probThresh':'"" + probThresh + ""', 'nmsThresh':'"" + nmsThresh + ""', 'outputType':'Both', 'excludeBoundary':'2', 'roiPosition':'Stack', 'verbose':'false'], process=[false]"");; """"""; # type: ignore; # type: ignore; # dependencies that start with the name ""bioimageio"" will be added as conda dependencies; # only stardist and tensorflow as pip dependencies; # conda environment; # modality; # dims; # content; # framework; # software; # network; # task; # only if requested, ",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
Testability,test,test,"ale[i] * input_shape[i] + 2 * output_offset[i]; # same shape as input except for the channel dimension; # no offset, except for the input axes, where it is output channel / 2; # optional: round up to be divisible by 8; # the output shape needs to be valid after cropping the halo, so we add the halo to the input min shape; # make sure the input min shape is still divisible by the min axis divisor; # out_paths = []; # for i, out in enumerate(test_outputs):; # p = outdir / f""test_output{i}.npy""; # np.save(p, out); # out_paths.append(p); """"""Export stardist model into bioimage.io format, https://github.com/bioimage-io/spec-bioimage-io. Parameters; ----------; model: StarDist2D, StarDist3D; the model to convert; outpath: str, Path; where to save the model; test_input: np.ndarray; input image for generating test data; test_input_axes: str or None; the axes of the test input, for example 'YX' for a 2d image or 'ZYX' for a 3d volume; using None assumes that axes of test_input are the same as those of model; test_input_norm_axes: str; the axes of the test input which will be jointly normalized, for example 'ZYX' for all spatial dimensions ('Z' ignored for 2D input); use 'ZYXC' to also jointly normalize channels (e.g. for RGB input images); name: str; the name of this model (default: None); if None, uses the (folder) name of the model (i.e. `model.name`); mode: str; the export type for this model (default: ""tensorflow_saved_model_bundle""); min_percentile: float; min percentile to be used for image normalization (default: 1.0); max_percentile: float; max percentile to be used for image normalization (default: 99.8); overwrite_spec_kwargs: dict or None; spec keywords that should be overloaded (default: None); generate_default_deps: bool; not required for bioimage.io, i.e. StarDist models don't need a dependencies field in rdf.yaml (default: False); if True, generate an environment.yaml file recording the python, bioimageio.core, stardist and tensorflow requirements; from which a",MatchSource.CODE_COMMENT,stardist/bioimageio_utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/bioimageio_utils.py
Deployability,release,release,"butes. Examples; --------; >>> y_true = np.zeros((100,100), np.uint16); >>> y_true[10:20,10:20] = 1; >>> y_pred = np.roll(y_true,5,axis = 0). >>> stats = matching(y_true, y_pred); >>> print(stats); Matching(criterion='iou', thresh=0.5, fp=1, tp=0, fn=1, precision=0, recall=0, accuracy=0, f1=0, n_true=1, n_pred=1, mean_true_score=0.0, mean_matched_score=0.0, panoptic_quality=0.0). """"""; # ignoring background; # not_trivial = n_matched > 0 and np.any(scores >= thr); # compute optimal matching with scores as tie-breaker; # assert tp+fp == n_pred; # assert tp+fn == n_true; # the score sum over all matched objects (tp); # the score average over all matched objects (tp); # the score average over all gt/true objects; # int() to be json serializable; """"""matching metrics for list of images, see `stardist.matching.matching`; """"""; # compute matching stats for every pair of label images; # accumulate results over all images for each threshold separately; # convert mean_true_score to ""sum_matched_score""; # normalize/compute 'precision', 'recall', 'accuracy', 'f1'; # copied from scikit-image master for now (remove when part of a release); """"""Relabel arbitrary labels to {`offset`, ... `offset` + number_of_labels}. This function also returns the forward map (mapping the original labels to; the reduced labels) and the inverse map (mapping the reduced labels back; to the original ones). Parameters; ----------; label_field : numpy array of int, arbitrary shape; An array of labels, which must be non-negative integers.; offset : int, optional; The return labels will start at `offset`, which should be; strictly positive. Returns; -------; relabeled : numpy array of int, same shape as `label_field`; The input label field with labels mapped to; {offset, ..., number_of_labels + offset - 1}.; The data type will be the same as `label_field`, except when; offset + number_of_labels causes overflow of the current data type.; forward_map : numpy array of int, shape ``(label_field.max() + 1,)``; Th",MatchSource.CODE_COMMENT,stardist/matching.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py
Energy Efficiency,reduce,reduced,", n_pred=1, mean_true_score=0.0, mean_matched_score=0.0, panoptic_quality=0.0). """"""; # ignoring background; # not_trivial = n_matched > 0 and np.any(scores >= thr); # compute optimal matching with scores as tie-breaker; # assert tp+fp == n_pred; # assert tp+fn == n_true; # the score sum over all matched objects (tp); # the score average over all matched objects (tp); # the score average over all gt/true objects; # int() to be json serializable; """"""matching metrics for list of images, see `stardist.matching.matching`; """"""; # compute matching stats for every pair of label images; # accumulate results over all images for each threshold separately; # convert mean_true_score to ""sum_matched_score""; # normalize/compute 'precision', 'recall', 'accuracy', 'f1'; # copied from scikit-image master for now (remove when part of a release); """"""Relabel arbitrary labels to {`offset`, ... `offset` + number_of_labels}. This function also returns the forward map (mapping the original labels to; the reduced labels) and the inverse map (mapping the reduced labels back; to the original ones). Parameters; ----------; label_field : numpy array of int, arbitrary shape; An array of labels, which must be non-negative integers.; offset : int, optional; The return labels will start at `offset`, which should be; strictly positive. Returns; -------; relabeled : numpy array of int, same shape as `label_field`; The input label field with labels mapped to; {offset, ..., number_of_labels + offset - 1}.; The data type will be the same as `label_field`, except when; offset + number_of_labels causes overflow of the current data type.; forward_map : numpy array of int, shape ``(label_field.max() + 1,)``; The map from the original label space to the returned label; space. Can be used to re-apply the same mapping. See examples; for usage. The data type will be the same as `relabeled`.; inverse_map : 1D numpy array of int, of length offset + number of labels; The map from the new label space to the original ",MatchSource.CODE_COMMENT,stardist/matching.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py
Safety,safe,safe,""""""" returns true if y has only sequential labels from 1... """"""; """"""computes a safe divide which returns 0 if y is zero""""""; # also known as ""average precision"" (?); # -> https://www.kaggle.com/c/data-science-bowl-2018#evaluation; # also known as ""dice coefficient""; """"""Calculate detection/instance segmentation metrics between ground truth and predicted label images. Currently, the following metrics are implemented:. 'fp', 'tp', 'fn', 'precision', 'recall', 'accuracy', 'f1', 'criterion', 'thresh', 'n_true', 'n_pred', 'mean_true_score', 'mean_matched_score', 'panoptic_quality'. Corresponding objects of y_true and y_pred are counted as true positives (tp), false positives (fp), and false negatives (fn); whether their intersection over union (IoU) >= thresh (for criterion='iou', which can be changed). * mean_matched_score is the mean IoUs of matched true positives. * mean_true_score is the mean IoUs of matched true positives but normalized by the total number of GT objects. * panoptic_quality defined as in Eq. 1 of Kirillov et al. ""Panoptic Segmentation"", CVPR 2019. Parameters; ----------; y_true: ndarray; ground truth label image (integer valued); y_pred: ndarray; predicted label image (integer valued); thresh: float; threshold for matching criterion (default 0.5); criterion: string; matching criterion (default IoU); report_matches: bool; if True, additionally calculate matched_pairs and matched_scores (note, that this returns even gt-pred pairs whose scores are below 'thresh'). Returns; -------; Matching object with different metrics as attributes. Examples; --------; >>> y_true = np.zeros((100,100), np.uint16); >>> y_true[10:20,10:20] = 1; >>> y_pred = np.roll(y_true,5,axis = 0). >>> stats = matching(y_true, y_pred); >>> print(stats); Matching(criterion='iou', thresh=0.5, fp=1, tp=0, fn=1, precision=0, recall=0, accuracy=0, f1=0, n_true=1, n_pred=1, mean_true_score=0.0, mean_matched_score=0.0, panoptic_quality=0.0). """"""; # ignoring background; # not_trivial = n_matched ",MatchSource.CODE_COMMENT,stardist/matching.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py
Testability,assert,assert,"el image (integer valued); thresh: float; threshold for matching criterion (default 0.5); criterion: string; matching criterion (default IoU); report_matches: bool; if True, additionally calculate matched_pairs and matched_scores (note, that this returns even gt-pred pairs whose scores are below 'thresh'). Returns; -------; Matching object with different metrics as attributes. Examples; --------; >>> y_true = np.zeros((100,100), np.uint16); >>> y_true[10:20,10:20] = 1; >>> y_pred = np.roll(y_true,5,axis = 0). >>> stats = matching(y_true, y_pred); >>> print(stats); Matching(criterion='iou', thresh=0.5, fp=1, tp=0, fn=1, precision=0, recall=0, accuracy=0, f1=0, n_true=1, n_pred=1, mean_true_score=0.0, mean_matched_score=0.0, panoptic_quality=0.0). """"""; # ignoring background; # not_trivial = n_matched > 0 and np.any(scores >= thr); # compute optimal matching with scores as tie-breaker; # assert tp+fp == n_pred; # assert tp+fn == n_true; # the score sum over all matched objects (tp); # the score average over all matched objects (tp); # the score average over all gt/true objects; # int() to be json serializable; """"""matching metrics for list of images, see `stardist.matching.matching`; """"""; # compute matching stats for every pair of label images; # accumulate results over all images for each threshold separately; # convert mean_true_score to ""sum_matched_score""; # normalize/compute 'precision', 'recall', 'accuracy', 'f1'; # copied from scikit-image master for now (remove when part of a release); """"""Relabel arbitrary labels to {`offset`, ... `offset` + number_of_labels}. This function also returns the forward map (mapping the original labels to; the reduced labels) and the inverse map (mapping the reduced labels back; to the original ones). Parameters; ----------; label_field : numpy array of int, arbitrary shape; An array of labels, which must be non-negative integers.; offset : int, optional; The return labels will start at `offset`, which should be; strictly positive. R",MatchSource.CODE_COMMENT,stardist/matching.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/matching.py
Availability,mask,mask,"""""""2D coordinates of the polys that survive from a given prediction (prob, coord). prob.shape = (Ny,Nx); coord.shape = (Ny,Nx,2,n_rays). b: don't use pixel closer than b pixels to the image boundary. returns retained points; """"""; # TODO: using b>0 with grid>1 can suppress small/cropped objects at the image boundary; # mask = prob > prob_thresh; # if b is not None and b > 0:; # _mask = np.zeros_like(mask); # _mask[b:-b,b:-b] = True; # mask &= _mask; # sort scores descendingly; # map pixel indices to ids of sorted polygons (-1 => polygon at that pixel not a candidate); """"""Non-Maximum-Supression of 2D polygons. Retains only polygons whose overlap is smaller than nms_thresh. dist.shape = (Ny,Nx, n_rays); prob.shape = (Ny,Nx). returns the retained points, probabilities, and distances:. points, prob, dist = non_maximum_suppression(dist, prob, .... """"""; # TODO: using b>0 with grid>1 can suppress small/cropped objects at the image boundary; # mask = prob > prob_thresh; # if b is not None and b > 0:; # _mask = np.zeros_like(mask); # _mask[b:-b,b:-b] = True; # mask &= _mask; # sort scores descendingly; """"""Non-Maximum-Supression of 2D polygons from a list of dists, probs (scores), and points. Retains only polyhedra whose overlap is smaller than nms_thresh. dist.shape = (n_polys, n_rays); prob.shape = (n_polys,); points.shape = (n_polys,2). returns the retained instances. (pointsi, probi, disti, indsi). with; pointsi = points[indsi] ... """"""; # TODO: using b>0 with grid>1 can suppress small/cropped objects at the image boundary; """"""; Applies non maximum supression to ray-convex polygons given by dists and points; sorted by scores and IoU threshold. P1 will suppress P2, if IoU(P1,P2) > thresh. with IoU(P1,P2) = Ainter(P1,P2) / min(A(P1),A(P2)). i.e. the smaller thresh, the more polygons will be supressed. dist.shape = (n_poly, n_rays); point.shape = (n_poly, 2); score.shape = (n_poly,). returns indices of selected polygons; """"""; #########; """"""Non-Maximum-Supression of 3D polyhedra",MatchSource.CODE_COMMENT,stardist/nms.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/nms.py
Safety,predict,prediction,"""""""2D coordinates of the polys that survive from a given prediction (prob, coord). prob.shape = (Ny,Nx); coord.shape = (Ny,Nx,2,n_rays). b: don't use pixel closer than b pixels to the image boundary. returns retained points; """"""; # TODO: using b>0 with grid>1 can suppress small/cropped objects at the image boundary; # mask = prob > prob_thresh; # if b is not None and b > 0:; # _mask = np.zeros_like(mask); # _mask[b:-b,b:-b] = True; # mask &= _mask; # sort scores descendingly; # map pixel indices to ids of sorted polygons (-1 => polygon at that pixel not a candidate); """"""Non-Maximum-Supression of 2D polygons. Retains only polygons whose overlap is smaller than nms_thresh. dist.shape = (Ny,Nx, n_rays); prob.shape = (Ny,Nx). returns the retained points, probabilities, and distances:. points, prob, dist = non_maximum_suppression(dist, prob, .... """"""; # TODO: using b>0 with grid>1 can suppress small/cropped objects at the image boundary; # mask = prob > prob_thresh; # if b is not None and b > 0:; # _mask = np.zeros_like(mask); # _mask[b:-b,b:-b] = True; # mask &= _mask; # sort scores descendingly; """"""Non-Maximum-Supression of 2D polygons from a list of dists, probs (scores), and points. Retains only polyhedra whose overlap is smaller than nms_thresh. dist.shape = (n_polys, n_rays); prob.shape = (n_polys,); points.shape = (n_polys,2). returns the retained instances. (pointsi, probi, disti, indsi). with; pointsi = points[indsi] ... """"""; # TODO: using b>0 with grid>1 can suppress small/cropped objects at the image boundary; """"""; Applies non maximum supression to ray-convex polygons given by dists and points; sorted by scores and IoU threshold. P1 will suppress P2, if IoU(P1,P2) > thresh. with IoU(P1,P2) = Ainter(P1,P2) / min(A(P1),A(P2)). i.e. the smaller thresh, the more polygons will be supressed. dist.shape = (n_poly, n_rays); point.shape = (n_poly, 2); score.shape = (n_poly,). returns indices of selected polygons; """"""; #########; """"""Non-Maximum-Supression of 3D polyhedra",MatchSource.CODE_COMMENT,stardist/nms.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/nms.py
Availability,mask,mask,"""""""provides a faster sampling function""""""; """"""optimized version of csbdeep.data.sample_patches_from_multiple_stacks; """"""; """"""; Returns all indices of an image that ; - can be used as center points for sampling patches of a given patch_size, and; - are part of the boolean mask given by the function patch_filter (if provided). img: np.ndarray; patch_size: tuple of ints ; the width of patches per img dimension, ; patch_filter: None or callable; a function with signature patch_filter(img, patch_size) returning a boolean mask ; """"""; # only cut border indices (which is faster); # get the valid indices",MatchSource.CODE_COMMENT,stardist/sample_patches.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/sample_patches.py
Deployability,patch,patches,"""""""provides a faster sampling function""""""; """"""optimized version of csbdeep.data.sample_patches_from_multiple_stacks; """"""; """"""; Returns all indices of an image that ; - can be used as center points for sampling patches of a given patch_size, and; - are part of the boolean mask given by the function patch_filter (if provided). img: np.ndarray; patch_size: tuple of ints ; the width of patches per img dimension, ; patch_filter: None or callable; a function with signature patch_filter(img, patch_size) returning a boolean mask ; """"""; # only cut border indices (which is faster); # get the valid indices",MatchSource.CODE_COMMENT,stardist/sample_patches.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/sample_patches.py
Performance,optimiz,optimized,"""""""provides a faster sampling function""""""; """"""optimized version of csbdeep.data.sample_patches_from_multiple_stacks; """"""; """"""; Returns all indices of an image that ; - can be used as center points for sampling patches of a given patch_size, and; - are part of the boolean mask given by the function patch_filter (if provided). img: np.ndarray; patch_size: tuple of ints ; the width of patches per img dimension, ; patch_filter: None or callable; a function with signature patch_filter(img, patch_size) returning a boolean mask ; """"""; # only cut border indices (which is faster); # get the valid indices",MatchSource.CODE_COMMENT,stardist/sample_patches.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/sample_patches.py
Availability,reliab,reliable,"rn(""Could not find package edt... \nConsider installing it with \n pip install edt\nto improve training data generation performance.""); """"""Perform EDT on each labeled object and normalize.; Internally uses https://github.com/seung-lab/euclidean-distance-transform-3d; that can handle multiple labels at once; """"""; # we just need to compute the edt once but then normalize it for each object; # i: object label id, sl: slices of object in lbl_img; # normalize it; """"""Perform EDT on each labeled object and normalize.""""""; # i: object label id, sl: slices of object in lbl_img; # 1. grow object slice by 1 for all interior object bounding boxes; # 2. perform (correct) EDT for object with label id i; # 3. extract EDT for object of original slice and normalize; # 4. store edt for object only for pixels of given label id i; """"""Fill small holes in label image.""""""; # TODO: refactor 'fill_label_holes' and 'edt_prob' to share code; """"""sample points to draw some of the associated polygons""""""; # ignore image boundary, since predictions may not be reliable; # weighted sampling via prob; """""" Aggregate bounding box sizes of objects in label images. """"""; """""" Byte array of polygon roi with provided x and y coordinates; See https://github.com/imagej/imagej1/blob/master/ij/io/RoiDecoder.java; """"""; # add offset since pixel center is at (0.5,0.5) in ImageJ; # bbox; # magic start; # version; # roi type (0 = polygon); # bbox top; # bbox left; # bbox bottom; # bbox right; # number of coordinates; # subpixel resolution (option flag); # position (C, Z, or T); """""" polygons assumed to be a list of arrays with shape (id,2,c) """"""; """""" Tune prob_thresh for provided (fixed) nms_thresh to maximize matching score (for given measure and averaged over iou_threshs). """"""; # print(""bracket ="", bracket); """""" return v-> [k_1,k_2,k_3....] for k,v in d""""""; """"""generates a multi-channel categorical class map. Parameters; ----------; y : n-dimensional ndarray; integer label array; n_classes : int; Number of different c",MatchSource.CODE_COMMENT,stardist/utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py
Deployability,install,installing,"# warnings.warn(""Could not find package edt... \nConsider installing it with \n pip install edt\nto improve training data generation performance.""); """""" Get absolute path to resource""""""; # warnings.warn(""Could not find package edt... \nConsider installing it with \n pip install edt\nto improve training data generation performance.""); """"""Perform EDT on each labeled object and normalize.; Internally uses https://github.com/seung-lab/euclidean-distance-transform-3d; that can handle multiple labels at once; """"""; # we just need to compute the edt once but then normalize it for each object; # i: object label id, sl: slices of object in lbl_img; # normalize it; """"""Perform EDT on each labeled object and normalize.""""""; # i: object label id, sl: slices of object in lbl_img; # 1. grow object slice by 1 for all interior object bounding boxes; # 2. perform (correct) EDT for object with label id i; # 3. extract EDT for object of original slice and normalize; # 4. store edt for object only for pixels of given label id i; """"""Fill small holes in label image.""""""; # TODO: refactor 'fill_label_holes' and 'edt_prob' to share code; """"""sample points to draw some of the associated polygons""""""; # ignore image boundary, since predictions may not be reliable; # weighted sampling via prob; """""" Aggregate bounding box sizes of objects in label images. """"""; """""" Byte array of polygon roi with provided x and y coordinates; See https://github.com/imagej/imagej1/blob/master/ij/io/RoiDecoder.java; """"""; # add offset since pixel center is at (0.5,0.5) in ImageJ; # bbox; # magic start; # version; # roi type (0 = polygon); # bbox top; # bbox left; # bbox bottom; # bbox right; # number of coordinates; # subpixel resolution (option flag); # position (C, Z, or T); """""" polygons assumed to be a list of arrays with shape (id,2,c) """"""; """""" Tune prob_thresh for provided (fixed) nms_thresh to maximize matching score (for given measure and averaged over iou_threshs). """"""; # print(""bracket ="", bracket); """""" return v-",MatchSource.CODE_COMMENT,stardist/utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py
Modifiability,refactor,refactor,"rn(""Could not find package edt... \nConsider installing it with \n pip install edt\nto improve training data generation performance.""); """"""Perform EDT on each labeled object and normalize.; Internally uses https://github.com/seung-lab/euclidean-distance-transform-3d; that can handle multiple labels at once; """"""; # we just need to compute the edt once but then normalize it for each object; # i: object label id, sl: slices of object in lbl_img; # normalize it; """"""Perform EDT on each labeled object and normalize.""""""; # i: object label id, sl: slices of object in lbl_img; # 1. grow object slice by 1 for all interior object bounding boxes; # 2. perform (correct) EDT for object with label id i; # 3. extract EDT for object of original slice and normalize; # 4. store edt for object only for pixels of given label id i; """"""Fill small holes in label image.""""""; # TODO: refactor 'fill_label_holes' and 'edt_prob' to share code; """"""sample points to draw some of the associated polygons""""""; # ignore image boundary, since predictions may not be reliable; # weighted sampling via prob; """""" Aggregate bounding box sizes of objects in label images. """"""; """""" Byte array of polygon roi with provided x and y coordinates; See https://github.com/imagej/imagej1/blob/master/ij/io/RoiDecoder.java; """"""; # add offset since pixel center is at (0.5,0.5) in ImageJ; # bbox; # magic start; # version; # roi type (0 = polygon); # bbox top; # bbox left; # bbox bottom; # bbox right; # number of coordinates; # subpixel resolution (option flag); # position (C, Z, or T); """""" polygons assumed to be a list of arrays with shape (id,2,c) """"""; """""" Tune prob_thresh for provided (fixed) nms_thresh to maximize matching score (for given measure and averaged over iou_threshs). """"""; # print(""bracket ="", bracket); """""" return v-> [k_1,k_2,k_3....] for k,v in d""""""; """"""generates a multi-channel categorical class map. Parameters; ----------; y : n-dimensional ndarray; integer label array; n_classes : int; Number of different c",MatchSource.CODE_COMMENT,stardist/utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py
Performance,perform,performance,"# warnings.warn(""Could not find package edt... \nConsider installing it with \n pip install edt\nto improve training data generation performance.""); """""" Get absolute path to resource""""""; # warnings.warn(""Could not find package edt... \nConsider installing it with \n pip install edt\nto improve training data generation performance.""); """"""Perform EDT on each labeled object and normalize.; Internally uses https://github.com/seung-lab/euclidean-distance-transform-3d; that can handle multiple labels at once; """"""; # we just need to compute the edt once but then normalize it for each object; # i: object label id, sl: slices of object in lbl_img; # normalize it; """"""Perform EDT on each labeled object and normalize.""""""; # i: object label id, sl: slices of object in lbl_img; # 1. grow object slice by 1 for all interior object bounding boxes; # 2. perform (correct) EDT for object with label id i; # 3. extract EDT for object of original slice and normalize; # 4. store edt for object only for pixels of given label id i; """"""Fill small holes in label image.""""""; # TODO: refactor 'fill_label_holes' and 'edt_prob' to share code; """"""sample points to draw some of the associated polygons""""""; # ignore image boundary, since predictions may not be reliable; # weighted sampling via prob; """""" Aggregate bounding box sizes of objects in label images. """"""; """""" Byte array of polygon roi with provided x and y coordinates; See https://github.com/imagej/imagej1/blob/master/ij/io/RoiDecoder.java; """"""; # add offset since pixel center is at (0.5,0.5) in ImageJ; # bbox; # magic start; # version; # roi type (0 = polygon); # bbox top; # bbox left; # bbox bottom; # bbox right; # number of coordinates; # subpixel resolution (option flag); # position (C, Z, or T); """""" polygons assumed to be a list of arrays with shape (id,2,c) """"""; """""" Tune prob_thresh for provided (fixed) nms_thresh to maximize matching score (for given measure and averaged over iou_threshs). """"""; # print(""bracket ="", bracket); """""" return v-",MatchSource.CODE_COMMENT,stardist/utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py
Safety,predict,predictions,"rn(""Could not find package edt... \nConsider installing it with \n pip install edt\nto improve training data generation performance.""); """"""Perform EDT on each labeled object and normalize.; Internally uses https://github.com/seung-lab/euclidean-distance-transform-3d; that can handle multiple labels at once; """"""; # we just need to compute the edt once but then normalize it for each object; # i: object label id, sl: slices of object in lbl_img; # normalize it; """"""Perform EDT on each labeled object and normalize.""""""; # i: object label id, sl: slices of object in lbl_img; # 1. grow object slice by 1 for all interior object bounding boxes; # 2. perform (correct) EDT for object with label id i; # 3. extract EDT for object of original slice and normalize; # 4. store edt for object only for pixels of given label id i; """"""Fill small holes in label image.""""""; # TODO: refactor 'fill_label_holes' and 'edt_prob' to share code; """"""sample points to draw some of the associated polygons""""""; # ignore image boundary, since predictions may not be reliable; # weighted sampling via prob; """""" Aggregate bounding box sizes of objects in label images. """"""; """""" Byte array of polygon roi with provided x and y coordinates; See https://github.com/imagej/imagej1/blob/master/ij/io/RoiDecoder.java; """"""; # add offset since pixel center is at (0.5,0.5) in ImageJ; # bbox; # magic start; # version; # roi type (0 = polygon); # bbox top; # bbox left; # bbox bottom; # bbox right; # number of coordinates; # subpixel resolution (option flag); # position (C, Z, or T); """""" polygons assumed to be a list of arrays with shape (id,2,c) """"""; """""" Tune prob_thresh for provided (fixed) nms_thresh to maximize matching score (for given measure and averaged over iou_threshs). """"""; # print(""bracket ="", bracket); """""" return v-> [k_1,k_2,k_3....] for k,v in d""""""; """"""generates a multi-channel categorical class map. Parameters; ----------; y : n-dimensional ndarray; integer label array; n_classes : int; Number of different c",MatchSource.CODE_COMMENT,stardist/utils.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/utils.py
Security,expose,expose,"# TODO: which functions to expose here? all?",MatchSource.CODE_COMMENT,stardist/__init__.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/__init__.py
Availability,mask,mask,""""""" Fluorescence microscopy image and mask from the 2018 kaggle DSB challenge. Caicedo et al. ""Nucleus segmentation across imaging experiments: the 2018 Data Science Bowl."" Nature methods 16.12; """"""; """""" H&E stained RGB example image from the Cancer Imaging Archive; https://www.cancerimagingarchive.net; """"""; """""" synthetic nuclei ; """"""",MatchSource.CODE_COMMENT,stardist/data/__init__.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/data/__init__.py
Integrability,message,messages,"# from ..lib.stardist3d import c_star_dist3d, c_polyhedron_to_label, c_dist_to_volume, c_dist_to_centroid; # if not all(g==1 for g in grid):; # raise NotImplementedError(""grid not yet implemented for OpenCL version of star_dist3D()...""); # slicing with grid is done with tuple(slice(0, None, g) for g in grid); """"""lbl assumbed to be a label image with integer values that encode object ids. id 0 denotes background.""""""; """"""; creates labeled image from stardist representations. :param dist: array of shape (n_points,n_rays); the list of distances for each point and ray; :param points: array of shape (n_points, 3); the list of center points; :param rays: Rays object; Ray object (e.g. `stardist.Rays_GoldenSpiral`) defining; vertices and faces; :param shape: (nz,ny,nx); output shape of the image; :param prob: array of length/shape (n_points,) or None; probability per polyhedron; :param thr: scalar; probability threshold (only polyhedra with prob>thr are labeled); :param labels: array of length/shape (n_points,) or None; labels to use; :param mode: str; labeling mode, can be ""full"", ""kernel"", ""hull"", ""bbox"" or ""debug""; :param verbose: bool; enable to print some debug messages; :param overlap_label: scalar or None; if given, will label each pixel that belongs ot more than one polyhedron with that label; :return: array of given shape; labeled image; """"""; # filter points; # sort points with decreasing probability; """"""relabel each label region in `lbl` with its star representation""""""; """""" returns areas of polyhedra; dist.shape = (nz,ny,nx,nrays); """"""; """""" returns centroids of polyhedra. dist.shape = (nz,ny,nx,nrays); mode = 'absolute' or 'relative'. """"""; """""" converts dist/points/rays_vertices to list of coords """"""; # return points[:,np.newaxis]+dist[...,np.newaxis]*rays_vertices; """""" exports 3D mesh result to obj file format """"""; # reorder to xyz; # print(xs); # new object; # vertex coords; # UV coords; # face indices",MatchSource.CODE_COMMENT,stardist/geometry/geom3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/geometry/geom3d.py
Availability,avail,available,"# TODO: helper function to check if receptive field of cnn is sufficient for object sizes in GT; # TODO: should we use norm_by_mask=True in the loss or only in a metric?; # previous 2D behavior was norm_by_mask=False; # same question for reg_weight? use 1e-4 (as in 3D) or 0 (as in 2D)?; # pixels to ignore have y_true == -1; # y_pred can be negative (since not constrained) -> 'inter' can be very large for y_pred << 0; # - clipping y_pred values at 0 can lead to vanishing gradients; # - 'K.sign(y_pred)' term fixes issue by enforcing that y_pred values >= 0 always lead to larger 'inter' (lower loss); # + 0.005*K.abs(y_true-y_pred); """""" ndim = (2,3) """"""; # ignore pixels that have y_true (prob_class) < 0; # sanity checks; # set classes to None for all images (i.e. defaults to every object instance assigned the same class); # self.batch_size = batch_size; # no foreground pixels available; """""" creates a proper classes tuple from different possible ""classes"" arguments in model.train(). classes can be; ""auto"" -> all objects will be assigned to the first foreground class (unless n_classes is None); single integer -> all objects will be assigned that class; tuple, list, ndarray -> do nothing (needs to be of given length). returns a tuple of given length; """"""; """"""Prepare for neural network training. Compiles the model and creates; `Keras Callbacks <https://keras.io/callbacks/>`_ to be used for training. Note that this method will be implicitly called once by :func:`train`; (with default arguments) if not done so explicitly beforehand. Parameters; ----------; optimizer : obj or None; Instance of a `Keras Optimizer <https://keras.io/optimizers/>`_ to be used for training.; If ``None`` (default), uses ``Adam`` with the learning rate specified in ``config``. """"""; # TF2: add as first callback to put 'lr' in the logs for TensorBoard; """""" Shared setup code between `predict` and `predict_sparse` """"""; # x has axes_net semantics; # axes eligible for tiling; # numerical axis ids for x; # h",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
Energy Efficiency,allocate,allocate,"YX', block_size=4096,; min_overlap=128, context=128, n_tiles=(4,4)). Parameters; ----------; img: :class:`numpy.ndarray` or similar; Input image; axes: str; Axes of the input ``img`` (such as 'YX', 'ZYX', 'YXC', etc.); block_size: int or iterable of int; Process input image in blocks of the provided shape.; (If a scalar value is given, it is used for all spatial image dimensions.); min_overlap: int or iterable of int; Amount of guaranteed overlap between blocks.; (If a scalar value is given, it is used for all spatial image dimensions.); context: int or iterable of int, or None; Amount of image context on all sides of a block, which is discarded.; If None, uses an automatic estimate that should work in many cases.; (If a scalar value is given, it is used for all spatial image dimensions.); labels_out: :class:`numpy.ndarray` or similar, or None, or False; numpy array or similar (must be of correct shape) to which the label image is written.; If None, will allocate a numpy array of the correct shape and data type ``labels_out_dtype``.; If False, will not write the label image (useful if only the dictionary is needed).; labels_out_dtype: str or dtype; Data type of returned label image if ``labels_out=None`` (has no effect otherwise).; show_progress: bool; Show progress bar for block processing.; kwargs: dict; Keyword arguments for ``predict_instances``. Returns; -------; (:class:`numpy.ndarray` or False, dict); Returns the label image and a dictionary with the details (coordinates, etc.) of the polygons/polyhedra. """"""; #, repaint_labels; # single block for channel axis; # if (block_size[i], min_overlap[i], context[i]) != (None, None, None):; # print(""Ignoring values of 'block_size', 'min_overlap', and 'context' for channel axis "" +; # ""(set to 'None' to avoid this warning)."", file=sys.stderr, flush=True); # print(f""input: shape {img.shape} with axes {axes}""); # create block cover; # problem_ids = []; # disable progress for predict_instances; # actual computation; # TODO",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
Integrability,message,messages,"loat or None; Perform non-maximum suppression that considers two objects to be the same; when their area/surface overlap exceeds this threshold (also see `optimize_thresholds`).; scale: None or float or iterable; Scale the input image internally by this factor and rescale the output accordingly.; All spatial axes (X,Y,Z) will be scaled if a scalar value is provided.; Alternatively, multiple scale values (compatible with input `axes`) can be used; for more fine-grained control (scale values for non-spatial axes must be 1).; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool; Whether to show progress during tiled prediction.; verbose: bool; Whether to print some info messages.; return_labels: bool; Whether to create a label image, otherwise return None in its place.; predict_kwargs: dict; Keyword arguments for ``predict`` function of Keras model.; nms_kwargs: dict; Keyword arguments for non-maximum suppression.; overlap_label: scalar or None; if not None, label the regions where polygons overlap with that value; return_predict: bool; Also return the outputs of :func:`predict` (in a separate tuple); If True, implies sparse = False. Returns; -------; (:class:`numpy.ndarray`, dict), (optional: return tuple of :func:`predict`); Returns a tuple of the label instances image and also; a dictionary with the details (coordinates, etc.) of all remaining polygons/polyhedra. """"""; # indicate that prediction is starting; # yield 'tile' each time a tile has been processed; # yield 'tile' each time a tile has been processed; # indicate that non-maximum suppression is starting; # last ""yield"" is the actual output that would have been ""return""ed if ",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
Modifiability,config,config,"set classes to None for all images (i.e. defaults to every object instance assigned the same class); # self.batch_size = batch_size; # no foreground pixels available; """""" creates a proper classes tuple from different possible ""classes"" arguments in model.train(). classes can be; ""auto"" -> all objects will be assigned to the first foreground class (unless n_classes is None); single integer -> all objects will be assigned that class; tuple, list, ndarray -> do nothing (needs to be of given length). returns a tuple of given length; """"""; """"""Prepare for neural network training. Compiles the model and creates; `Keras Callbacks <https://keras.io/callbacks/>`_ to be used for training. Note that this method will be implicitly called once by :func:`train`; (with default arguments) if not done so explicitly beforehand. Parameters; ----------; optimizer : obj or None; Instance of a `Keras Optimizer <https://keras.io/optimizers/>`_ to be used for training.; If ``None`` (default), uses ``Adam`` with the learning rate specified in ``config``. """"""; # TF2: add as first callback to put 'lr' in the logs for TensorBoard; """""" Shared setup code between `predict` and `predict_sparse` """"""; # x has axes_net semantics; # axes eligible for tiling; # numerical axis ids for x; # hack: permute tiling axis in the same way as img -> x was permuted; """"""Predict. Parameters; ----------; img : :class:`numpy.ndarray`; Input image; axes : str or None; Axes of the input ``img``.; ``None`` denotes that axes of img are the same as denoted in the config.; normalizer : :class:`csbdeep.data.Normalizer` or None; (Optional) normalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the nu",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
Performance,optimiz,optimizer,"r loss); # + 0.005*K.abs(y_true-y_pred); """""" ndim = (2,3) """"""; # ignore pixels that have y_true (prob_class) < 0; # sanity checks; # set classes to None for all images (i.e. defaults to every object instance assigned the same class); # self.batch_size = batch_size; # no foreground pixels available; """""" creates a proper classes tuple from different possible ""classes"" arguments in model.train(). classes can be; ""auto"" -> all objects will be assigned to the first foreground class (unless n_classes is None); single integer -> all objects will be assigned that class; tuple, list, ndarray -> do nothing (needs to be of given length). returns a tuple of given length; """"""; """"""Prepare for neural network training. Compiles the model and creates; `Keras Callbacks <https://keras.io/callbacks/>`_ to be used for training. Note that this method will be implicitly called once by :func:`train`; (with default arguments) if not done so explicitly beforehand. Parameters; ----------; optimizer : obj or None; Instance of a `Keras Optimizer <https://keras.io/optimizers/>`_ to be used for training.; If ``None`` (default), uses ``Adam`` with the learning rate specified in ``config``. """"""; # TF2: add as first callback to put 'lr' in the logs for TensorBoard; """""" Shared setup code between `predict` and `predict_sparse` """"""; # x has axes_net semantics; # axes eligible for tiling; # numerical axis ids for x; # hack: permute tiling axis in the same way as img -> x was permuted; """"""Predict. Parameters; ----------; img : :class:`numpy.ndarray`; Input image; axes : str or None; Axes of the input ``img``.; ``None`` denotes that axes of img are the same as denoted in the config.; normalizer : :class:`csbdeep.data.Normalizer` or None; (Optional) normalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input imag",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
Safety,sanity check,sanity checks,"# TODO: helper function to check if receptive field of cnn is sufficient for object sizes in GT; # TODO: should we use norm_by_mask=True in the loss or only in a metric?; # previous 2D behavior was norm_by_mask=False; # same question for reg_weight? use 1e-4 (as in 3D) or 0 (as in 2D)?; # pixels to ignore have y_true == -1; # y_pred can be negative (since not constrained) -> 'inter' can be very large for y_pred << 0; # - clipping y_pred values at 0 can lead to vanishing gradients; # - 'K.sign(y_pred)' term fixes issue by enforcing that y_pred values >= 0 always lead to larger 'inter' (lower loss); # + 0.005*K.abs(y_true-y_pred); """""" ndim = (2,3) """"""; # ignore pixels that have y_true (prob_class) < 0; # sanity checks; # set classes to None for all images (i.e. defaults to every object instance assigned the same class); # self.batch_size = batch_size; # no foreground pixels available; """""" creates a proper classes tuple from different possible ""classes"" arguments in model.train(). classes can be; ""auto"" -> all objects will be assigned to the first foreground class (unless n_classes is None); single integer -> all objects will be assigned that class; tuple, list, ndarray -> do nothing (needs to be of given length). returns a tuple of given length; """"""; """"""Prepare for neural network training. Compiles the model and creates; `Keras Callbacks <https://keras.io/callbacks/>`_ to be used for training. Note that this method will be implicitly called once by :func:`train`; (with default arguments) if not done so explicitly beforehand. Parameters; ----------; optimizer : obj or None; Instance of a `Keras Optimizer <https://keras.io/optimizers/>`_ to be used for training.; If ``None`` (default), uses ``Adam`` with the learning rate specified in ``config``. """"""; # TF2: add as first callback to put 'lr' in the logs for TensorBoard; """""" Shared setup code between `predict` and `predict_sparse` """"""; # x has axes_net semantics; # axes eligible for tiling; # numerical axis ids for x; # h",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
Testability,log,logs,"tuple from different possible ""classes"" arguments in model.train(). classes can be; ""auto"" -> all objects will be assigned to the first foreground class (unless n_classes is None); single integer -> all objects will be assigned that class; tuple, list, ndarray -> do nothing (needs to be of given length). returns a tuple of given length; """"""; """"""Prepare for neural network training. Compiles the model and creates; `Keras Callbacks <https://keras.io/callbacks/>`_ to be used for training. Note that this method will be implicitly called once by :func:`train`; (with default arguments) if not done so explicitly beforehand. Parameters; ----------; optimizer : obj or None; Instance of a `Keras Optimizer <https://keras.io/optimizers/>`_ to be used for training.; If ``None`` (default), uses ``Adam`` with the learning rate specified in ``config``. """"""; # TF2: add as first callback to put 'lr' in the logs for TensorBoard; """""" Shared setup code between `predict` and `predict_sparse` """"""; # x has axes_net semantics; # axes eligible for tiling; # numerical axis ids for x; # hack: permute tiling axis in the same way as img -> x was permuted; """"""Predict. Parameters; ----------; img : :class:`numpy.ndarray`; Input image; axes : str or None; Axes of the input ``img``.; ``None`` denotes that axes of img are the same as denoted in the config.; normalizer : :class:`csbdeep.data.Normalizer` or None; (Optional) normalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the number of tiles for every image axis (see ``axes``).; ``None`` denotes that no tiling should be used.; show_tile_progress: bool or callable; If boolean, indicates whether to show progress (via tqdm) ",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
Usability,learn,learning,"set classes to None for all images (i.e. defaults to every object instance assigned the same class); # self.batch_size = batch_size; # no foreground pixels available; """""" creates a proper classes tuple from different possible ""classes"" arguments in model.train(). classes can be; ""auto"" -> all objects will be assigned to the first foreground class (unless n_classes is None); single integer -> all objects will be assigned that class; tuple, list, ndarray -> do nothing (needs to be of given length). returns a tuple of given length; """"""; """"""Prepare for neural network training. Compiles the model and creates; `Keras Callbacks <https://keras.io/callbacks/>`_ to be used for training. Note that this method will be implicitly called once by :func:`train`; (with default arguments) if not done so explicitly beforehand. Parameters; ----------; optimizer : obj or None; Instance of a `Keras Optimizer <https://keras.io/optimizers/>`_ to be used for training.; If ``None`` (default), uses ``Adam`` with the learning rate specified in ``config``. """"""; # TF2: add as first callback to put 'lr' in the logs for TensorBoard; """""" Shared setup code between `predict` and `predict_sparse` """"""; # x has axes_net semantics; # axes eligible for tiling; # numerical axis ids for x; # hack: permute tiling axis in the same way as img -> x was permuted; """"""Predict. Parameters; ----------; img : :class:`numpy.ndarray`; Input image; axes : str or None; Axes of the input ``img``.; ``None`` denotes that axes of img are the same as denoted in the config.; normalizer : :class:`csbdeep.data.Normalizer` or None; (Optional) normalization of input image before prediction.; Note that the default (``None``) assumes ``img`` to be already normalized.; n_tiles : iterable or None; Out of memory (OOM) errors can occur if the input image is too large.; To avoid this problem, the input image is broken up into (overlapping) tiles; that are processed independently and re-assembled.; This parameter denotes a tuple of the nu",MatchSource.CODE_COMMENT,stardist/models/base.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/base.py
Availability,down,downsampling,"# set negative label pixels to 0 (background); # prob = np.stack([edt_prob(lbl[self.b]) for lbl in Y]); # prob = prob[self.ss_grid]; # directly subsample with grid; # input image has no channel axis; # subsample wth given grid; # dist_mask = dist_mask[self.ss_grid]; # prob = prob[self.ss_grid]; # append dist_mask to dist as additional channel; # dist_and_mask = np.concatenate([dist,dist_mask],axis=-1); # faster than concatenate; # set to -1 to disable loss; # note: must return tuples in keras 3 (cf. https://stackoverflow.com/a/78158487); # TODO: investigate downsampling via simple indexing vs. using 'zoom'; # prob_class = prob_class[self.ss_grid]; # 'zoom' might lead to better registered maps (especially if upscaled later); # set to -1 to disable loss; """"""Configuration for a :class:`StarDist2D` model. Parameters; ----------; axes : str or None; Axes of the input images.; n_rays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution laye",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
Deployability,configurat,configuration,"eturn tuples in keras 3 (cf. https://stackoverflow.com/a/78158487); # TODO: investigate downsampling via simple indexing vs. using 'zoom'; # prob_class = prob_class[self.ss_grid]; # 'zoom' might lead to better registered maps (especially if upscaled later); # set to -1 to disable loss; """"""Configuration for a :class:`StarDist2D` model. Parameters; ----------; axes : str or None; Axes of the input images.; n_rays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided train",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
Energy Efficiency,power,power,"# set negative label pixels to 0 (background); # prob = np.stack([edt_prob(lbl[self.b]) for lbl in Y]); # prob = prob[self.ss_grid]; # directly subsample with grid; # input image has no channel axis; # subsample wth given grid; # dist_mask = dist_mask[self.ss_grid]; # prob = prob[self.ss_grid]; # append dist_mask to dist as additional channel; # dist_and_mask = np.concatenate([dist,dist_mask],axis=-1); # faster than concatenate; # set to -1 to disable loss; # note: must return tuples in keras 3 (cf. https://stackoverflow.com/a/78158487); # TODO: investigate downsampling via simple indexing vs. using 'zoom'; # prob_class = prob_class[self.ss_grid]; # 'zoom' might lead to better registered maps (especially if upscaled later); # set to -1 to disable loss; """"""Configuration for a :class:`StarDist2D` model. Parameters; ----------; axes : str or None; Axes of the input images.; n_rays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution laye",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
Modifiability,config,configuration,"eturn tuples in keras 3 (cf. https://stackoverflow.com/a/78158487); # TODO: investigate downsampling via simple indexing vs. using 'zoom'; # prob_class = prob_class[self.ss_grid]; # 'zoom' might lead to better registered maps (especially if upscaled later); # set to -1 to disable loss; """"""Configuration for a :class:`StarDist2D` model. Parameters; ----------; axes : str or None; Axes of the input images.; n_rays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.; train_completion_crop : int; If 'train_shape_completion' is set to True, specify number of pixels to crop at boundary of training patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided train",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
Performance,load,loaded,"m validation images (``None`` = one patch per image).; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .. _ReduceLROnPlateau: https://keras.io/api/callbacks/reduce_lr_on_plateau/; """"""; """"""See class docstring.""""""; # directly set by parameters; # default config (can be overwritten by kwargs below); # TODO: resnet backbone for 2D model?; # net_mask_shape not needed but kept for legacy reasons; # the parameter 'min_delta' was called 'epsilon' for keras<=2.1.5; # keras.__version__ was removed in tensorflow 2.13.0; # remove derived attributes that shouldn't be overwritten; # FIXME: put into is_valid(); """"""StarDist2D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""; """"""See class docstring.""""""; # maxpool input image to grid size; # attach extra classification head when self.n_classes is given; """"""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `n",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
Safety,predict,predict,"ample wth given grid; # dist_mask = dist_mask[self.ss_grid]; # prob = prob[self.ss_grid]; # append dist_mask to dist as additional channel; # dist_and_mask = np.concatenate([dist,dist_mask],axis=-1); # faster than concatenate; # set to -1 to disable loss; # note: must return tuples in keras 3 (cf. https://stackoverflow.com/a/78158487); # TODO: investigate downsampling via simple indexing vs. using 'zoom'; # prob_class = prob_class[self.ss_grid]; # 'zoom' might lead to better registered maps (especially if upscaled later); # set to -1 to disable loss; """"""Configuration for a :class:`StarDist2D` model. Parameters; ----------; axes : str or None; Axes of the input images.; n_rays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; train_shape_completion : bool; Train model to predict complete shapes for partially visible objects at image boundary.;",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
Security,validat,validation,"ng patches.; Should be chosen based on (largest) object sizes.; train_patch_size : (int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .. _ReduceLROnPlateau: https://keras.io/api/callbacks/reduce_lr_on_plateau/; """"""; """"""See class docstring.""""""; # directly set by parameters; # default config (can be overwritten by kwargs below); # TODO: resnet backbone for 2D model?; # net_mask_shape not needed but kept for legacy reasons; # the parameter 'min_delta' was called 'epsilon' for keras<=2.1.5; # keras.__version__ was removed in tensorflow 2.13.0; # remove derived attributes that shouldn't be overwritten; # FIXME: put into is_valid(); """"""StarDist2D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, wi",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
Testability,log,logdir,"r legacy reasons; # the parameter 'min_delta' was called 'epsilon' for keras<=2.1.5; # keras.__version__ was removed in tensorflow 2.13.0; # remove derived attributes that shouldn't be overwritten; # FIXME: put into is_valid(); """"""StarDist2D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""; """"""See class docstring.""""""; # maxpool input image to grid size; # attach extra classification head when self.n_classes is given; """"""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,; or will be ignored if config.n_classes is None; validation_data ",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
Usability,simpl,simple,"# set negative label pixels to 0 (background); # prob = np.stack([edt_prob(lbl[self.b]) for lbl in Y]); # prob = prob[self.ss_grid]; # directly subsample with grid; # input image has no channel axis; # subsample wth given grid; # dist_mask = dist_mask[self.ss_grid]; # prob = prob[self.ss_grid]; # append dist_mask to dist as additional channel; # dist_and_mask = np.concatenate([dist,dist_mask],axis=-1); # faster than concatenate; # set to -1 to disable loss; # note: must return tuples in keras 3 (cf. https://stackoverflow.com/a/78158487); # TODO: investigate downsampling via simple indexing vs. using 'zoom'; # prob_class = prob_class[self.ss_grid]; # 'zoom' might lead to better registered maps (especially if upscaled later); # set to -1 to disable loss; """"""Configuration for a :class:`StarDist2D` model. Parameters; ----------; axes : str or None; Axes of the input images.; n_rays : int; Number of radial directions for the star-convex polygon.; Recommended to use a power of 2 (default: 32).; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution laye",MatchSource.CODE_COMMENT,stardist/models/model2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model2d.py
Availability,down,downsample,"# TODO: support shape completion as in 2D?; # re-use arrays; # set negative label pixels to 0 (background); # input image has no channel axis; # append dist_mask to dist as additional channel; # set to -1 to disable loss; # note: must return tuples in keras 3 (cf. https://stackoverflow.com/a/78158487); # TODO: downsample here before stacking?; # TODO: investigate downsampling via simple indexing vs. using 'zoom'; # prob_class = prob_class[self.ss_grid]; # 'zoom' might lead to better registered maps (especially if upscaled later); # set to -1 to disable loss; """"""Configuration for a :class:`StarDist3D` model. Parameters; ----------; axes : str or None; Axes of the input images.; rays : Rays_Base, int, or None; Ray factory (e.g. Ray_GoldenSpiral).; If an integer then Ray_GoldenSpiral(rays) will be used; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolu",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
Deployability,configurat,configuration," to better registered maps (especially if upscaled later); # set to -1 to disable loss; """"""Configuration for a :class:`StarDist3D` model. Parameters; ----------; axes : str or None; Axes of the input images.; rays : Rays_Base, int, or None; Ray factory (e.g. Ray_GoldenSpiral).; If an integer then Ray_GoldenSpiral(rays) will be used; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet ",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
Energy Efficiency,power,powers,"# TODO: support shape completion as in 2D?; # re-use arrays; # set negative label pixels to 0 (background); # input image has no channel axis; # append dist_mask to dist as additional channel; # set to -1 to disable loss; # note: must return tuples in keras 3 (cf. https://stackoverflow.com/a/78158487); # TODO: downsample here before stacking?; # TODO: investigate downsampling via simple indexing vs. using 'zoom'; # prob_class = prob_class[self.ss_grid]; # 'zoom' might lead to better registered maps (especially if upscaled later); # set to -1 to disable loss; """"""Configuration for a :class:`StarDist3D` model. Parameters; ----------; axes : str or None; Axes of the input images.; rays : Rays_Base, int, or None; Ray factory (e.g. Ray_GoldenSpiral).; If an integer then Ray_GoldenSpiral(rays) will be used; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolu",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
Modifiability,config,configuration," to better registered maps (especially if upscaled later); # set to -1 to disable loss; """"""Configuration for a :class:`StarDist3D` model. Parameters; ----------; axes : str or None; Axes of the input images.; rays : Rays_Base, int, or None; Ray factory (e.g. Ray_GoldenSpiral).; If an integer then Ray_GoldenSpiral(rays) will be used; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after U-Net (0 to disable).; unet_* : *; Additional parameters for U-net backbone.; resnet_n_blocks : int; Number of ResNet blocks.; resnet_kernel_size : (int,int,int); Convolution kernel size for all ResNet blocks.; resnet_n_filter_base : int; Number of convolution kernels (feature channels) for ResNet blocks.; (Number is doubled after every downsampling, see ``grid``.); net_conv_after_resnet : int; Number of filters of the extra convolution layer after ResNet ",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
Performance,load,loaded,"ogress.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .. _ReduceLROnPlateau: https://keras.io/api/callbacks/reduce_lr_on_plateau/; """"""; # directly set by parameters; # default config (can be overwritten by kwargs below); # net_mask_shape not needed but kept for legacy reasons; # self.train_shape_completion = False; # self.train_completion_crop = 32; # the parameter 'min_delta' was called 'epsilon' for keras<=2.1.5; # keras.__version__ was removed in tensorflow 2.13.0; # remove derived attributes that shouldn't be overwritten; # FIXME: put into is_valid(); """"""StarDist3D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""; """"""See class docstring.""""""; # maxpool input image to grid size; # attach extra classification head when self.n_classes is given; # attach extra classification head when self.n_classes is given; """"""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.nd",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
Safety,predict,predict,"ape completion as in 2D?; # re-use arrays; # set negative label pixels to 0 (background); # input image has no channel axis; # append dist_mask to dist as additional channel; # set to -1 to disable loss; # note: must return tuples in keras 3 (cf. https://stackoverflow.com/a/78158487); # TODO: downsample here before stacking?; # TODO: investigate downsampling via simple indexing vs. using 'zoom'; # prob_class = prob_class[self.ss_grid]; # 'zoom' might lead to better registered maps (especially if upscaled later); # set to -1 to disable loss; """"""Configuration for a :class:`StarDist3D` model. Parameters; ----------; axes : str or None; Axes of the input images.; rays : Rays_Base, int, or None; Ray factory (e.g. Ray_GoldenSpiral).; If an integer then Ray_GoldenSpiral(rays) will be used; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolution layer after ",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
Security,validat,validation,"int,int,int); Size of patches to be cropped from provided training images.; train_background_reg : float; Regularizer to encourage distance predictions on background regions to be 0.; train_foreground_only : float; Fraction (0..1) of patches that will only be sampled from regions that contain foreground pixels.; train_sample_cache : bool; Activate caching of valid patch regions for all training images (disable to save memory for large datasets); train_dist_loss : str; Training loss for star-convex polygon distances ('mse' or 'mae').; train_loss_weights : tuple of float; Weights for losses relating to (probability, distance); train_epochs : int; Number of training epochs.; train_steps_per_epoch : int; Number of parameter update steps per epoch.; train_learning_rate : float; Learning rate for training.; train_batch_size : int; Batch size for training.; train_tensorboard : bool; Enable TensorBoard for monitoring training progress.; train_n_val_patches : int; Number of patches to be extracted from validation images (``None`` = one patch per image).; train_reduce_lr : dict; Parameter :class:`dict` of ReduceLROnPlateau_ callback; set to ``None`` to disable.; use_gpu : bool; Indicate that the data generator should use OpenCL to do computations on the GPU. .. _ReduceLROnPlateau: https://keras.io/api/callbacks/reduce_lr_on_plateau/; """"""; # directly set by parameters; # default config (can be overwritten by kwargs below); # net_mask_shape not needed but kept for legacy reasons; # self.train_shape_completion = False; # self.train_completion_crop = 32; # the parameter 'min_delta' was called 'epsilon' for keras<=2.1.5; # keras.__version__ was removed in tensorflow 2.13.0; # remove derived attributes that shouldn't be overwritten; # FIXME: put into is_valid(); """"""StarDist3D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Use",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
Testability,log,logdir,"letion_crop = 32; # the parameter 'min_delta' was called 'epsilon' for keras<=2.1.5; # keras.__version__ was removed in tensorflow 2.13.0; # remove derived attributes that shouldn't be overwritten; # FIXME: put into is_valid(); """"""StarDist3D model. Parameters; ----------; config : :class:`Config` or None; Will be saved to disk as JSON (``config.json``).; If set to ``None``, will be loaded from disk (must exist).; name : str or None; Model name. Uses a timestamp if set to ``None`` (default).; basedir : str; Directory that contains (or will contain) a folder with the given model name. Raises; ------; FileNotFoundError; If ``config=None`` and config cannot be loaded from disk.; ValueError; Illegal arguments, including invalid configuration. Attributes; ----------; config : :class:`Config`; Configuration, as provided during instantiation.; keras_model : `Keras model <https://keras.io/getting-started/functional-api-guide/>`_; Keras neural network model.; name : str; Model name.; logdir : :class:`pathlib.Path`; Path to model folder (which stores configuration, weights, etc.); """"""; """"""See class docstring.""""""; # maxpool input image to grid size; # attach extra classification head when self.n_classes is given; # attach extra classification head when self.n_classes is given; """"""Train the neural network with the given data. Parameters; ----------; X : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Input images; Y : tuple, list, `numpy.ndarray`, `keras.utils.Sequence`; Label masks; Positive pixel values denote object instance ids (0 for background).; Negative values can be used to turn off all losses for the corresponding pixels (e.g. for regions that haven't been labeled).; classes (optional): 'auto' or iterable of same length as X; label id -> class id mapping for each label mask of Y if multiclass prediction is activated (n_classes > 0); list of dicts with label id -> class id (1,...,n_classes); 'auto' -> all objects will be assigned to the first non-background class,;",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
Usability,simpl,simple,"# TODO: support shape completion as in 2D?; # re-use arrays; # set negative label pixels to 0 (background); # input image has no channel axis; # append dist_mask to dist as additional channel; # set to -1 to disable loss; # note: must return tuples in keras 3 (cf. https://stackoverflow.com/a/78158487); # TODO: downsample here before stacking?; # TODO: investigate downsampling via simple indexing vs. using 'zoom'; # prob_class = prob_class[self.ss_grid]; # 'zoom' might lead to better registered maps (especially if upscaled later); # set to -1 to disable loss; """"""Configuration for a :class:`StarDist3D` model. Parameters; ----------; axes : str or None; Axes of the input images.; rays : Rays_Base, int, or None; Ray factory (e.g. Ray_GoldenSpiral).; If an integer then Ray_GoldenSpiral(rays) will be used; n_channel_in : int; Number of channels of given input image (default: 1).; grid : (int,int,int); Subsampling factors (must be powers of 2) for each of the axes.; Model will predict on a subsampled grid for increased efficiency and larger field of view.; n_classes : None or int; Number of object classes to use for multi-class prediction (use None to disable); anisotropy : (float,float,float); Anisotropy of objects along each of the axes.; Use ``None`` to disable only for (nearly) isotropic objects shapes.; Also see ``utils.calculate_extents``.; backbone : str; Name of the neural network architecture to be used as backbone.; kwargs : dict; Overwrite (or add) configuration attributes (see below). Attributes; ----------; unet_n_depth : int; Number of U-Net resolution levels (down/up-sampling layers).; unet_kernel_size : (int,int,int); Convolution kernel size for all (U-Net) convolution layers.; unet_n_filter_base : int; Number of convolution kernels (feature channels) for first U-Net layer.; Doubled after each down-sampling layer.; unet_pool : (int,int,int); Maxpooling size for all (U-Net) convolution layers.; net_conv_after_unet : int; Number of filters of the extra convolu",MatchSource.CODE_COMMENT,stardist/models/model3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/models/model3d.py
Availability,error,errors,"as rgb(a) only a single color is used, if None uses a random colormap ; cmap_img: string or callable; The colormap of img (optional); alpha: float ; The alpha value of the overlay. Set alpha=1 to get fully opaque labels; alpha_boundary: float; The alpha value of the boundary (if None, use the same as for labels, i.e. no boundaries are visible); normalize_img: bool; If True, normalizes the img (if given). Returns; -------; img: np.ndarray; the (m,n,4) RGBA image of the rendered label . Example; -------. from scipy.ndimage import label, zoom ; img = zoom(np.random.uniform(0,1,(16,16)),(8,8),order=3) ; lbl,_ = label(img>.8); u1 = render_label(lbl, img = img, alpha = .7); u2 = render_label(lbl, img = img, alpha = 0, alpha_boundary =.8); plt.subplot(1,2,1);plt.imshow(u1); plt.subplot(1,2,2);plt.imshow(u2). """"""; # render image if given; # render label; # blend; """"""; h0 = 0 -> red; h0 = 0.33 -> green; h0 = 0.66 -> blue; h0 = 0.833 -> magenta; """"""; """"""match labels from y to y0""""""; """"""Renders an image that shows segmentation errors between y_true and y_pred . Correctly matched objects (TP) are colored green (with transparency tp_alpha); Erronously detected objects (FP) are colored red (with transparency fp_alpha); MIssing GT objects (FN) are colored blue (with transparency fn_alpha). Parameters; ----------; y_true: np.ndarray of dtype np.uint16; The 2D GT label image ; y_pred: np.ndarray of dtype np.uint16; The 2D prediction label image ; img: np.ndarray ; The array to overlay the label image with (optional); cmap_img: string or callable; The colormap of img (optional); tp_alpha: float ; The alpha value of the TP ; fp_alpha: float ; The alpha value of the FP ; fn_alpha: float ; The alpha value of the FN ; matching_kwargs: dict; The parameters of stardist.matching.matching that are used to compute the TP/FP/FN; normalize_img: bool; If True, normalizes the img (if given). Returns; -------; img: np.ndarray; the (m,n,4) RGBA image of the rendered image. Example; ------- . from s",MatchSource.CODE_COMMENT,stardist/plot/render.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py
Energy Efficiency,green,green,"he label image with (optional); cmap: string, tuple, or callable; The label colormap. If given as rgb(a) only a single color is used, if None uses a random colormap ; cmap_img: string or callable; The colormap of img (optional); alpha: float ; The alpha value of the overlay. Set alpha=1 to get fully opaque labels; alpha_boundary: float; The alpha value of the boundary (if None, use the same as for labels, i.e. no boundaries are visible); normalize_img: bool; If True, normalizes the img (if given). Returns; -------; img: np.ndarray; the (m,n,4) RGBA image of the rendered label . Example; -------. from scipy.ndimage import label, zoom ; img = zoom(np.random.uniform(0,1,(16,16)),(8,8),order=3) ; lbl,_ = label(img>.8); u1 = render_label(lbl, img = img, alpha = .7); u2 = render_label(lbl, img = img, alpha = 0, alpha_boundary =.8); plt.subplot(1,2,1);plt.imshow(u1); plt.subplot(1,2,2);plt.imshow(u2). """"""; # render image if given; # render label; # blend; """"""; h0 = 0 -> red; h0 = 0.33 -> green; h0 = 0.66 -> blue; h0 = 0.833 -> magenta; """"""; """"""match labels from y to y0""""""; """"""Renders an image that shows segmentation errors between y_true and y_pred . Correctly matched objects (TP) are colored green (with transparency tp_alpha); Erronously detected objects (FP) are colored red (with transparency fp_alpha); MIssing GT objects (FN) are colored blue (with transparency fn_alpha). Parameters; ----------; y_true: np.ndarray of dtype np.uint16; The 2D GT label image ; y_pred: np.ndarray of dtype np.uint16; The 2D prediction label image ; img: np.ndarray ; The array to overlay the label image with (optional); cmap_img: string or callable; The colormap of img (optional); tp_alpha: float ; The alpha value of the TP ; fp_alpha: float ; The alpha value of the FP ; fn_alpha: float ; The alpha value of the FN ; matching_kwargs: dict; The parameters of stardist.matching.matching that are used to compute the TP/FP/FN; normalize_img: bool; If True, normalizes the img (if given). Returns; --",MatchSource.CODE_COMMENT,stardist/plot/render.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py
Safety,detect,detected," Set alpha=1 to get fully opaque labels; alpha_boundary: float; The alpha value of the boundary (if None, use the same as for labels, i.e. no boundaries are visible); normalize_img: bool; If True, normalizes the img (if given). Returns; -------; img: np.ndarray; the (m,n,4) RGBA image of the rendered label . Example; -------. from scipy.ndimage import label, zoom ; img = zoom(np.random.uniform(0,1,(16,16)),(8,8),order=3) ; lbl,_ = label(img>.8); u1 = render_label(lbl, img = img, alpha = .7); u2 = render_label(lbl, img = img, alpha = 0, alpha_boundary =.8); plt.subplot(1,2,1);plt.imshow(u1); plt.subplot(1,2,2);plt.imshow(u2). """"""; # render image if given; # render label; # blend; """"""; h0 = 0 -> red; h0 = 0.33 -> green; h0 = 0.66 -> blue; h0 = 0.833 -> magenta; """"""; """"""match labels from y to y0""""""; """"""Renders an image that shows segmentation errors between y_true and y_pred . Correctly matched objects (TP) are colored green (with transparency tp_alpha); Erronously detected objects (FP) are colored red (with transparency fp_alpha); MIssing GT objects (FN) are colored blue (with transparency fn_alpha). Parameters; ----------; y_true: np.ndarray of dtype np.uint16; The 2D GT label image ; y_pred: np.ndarray of dtype np.uint16; The 2D prediction label image ; img: np.ndarray ; The array to overlay the label image with (optional); cmap_img: string or callable; The colormap of img (optional); tp_alpha: float ; The alpha value of the TP ; fp_alpha: float ; The alpha value of the FP ; fn_alpha: float ; The alpha value of the FN ; matching_kwargs: dict; The parameters of stardist.matching.matching that are used to compute the TP/FP/FN; normalize_img: bool; If True, normalizes the img (if given). Returns; -------; img: np.ndarray; the (m,n,4) RGBA image of the rendered image. Example; ------- . from scipy.ndimage import label, zoom ; img = zoom(np.random.uniform(0,1,(16,16)),(8,8),order=3); y_true = label(img>.9)[0]; y_pred = label(img>.02)[0]; plt.imshow(render_label_pred(y_tru",MatchSource.CODE_COMMENT,stardist/plot/render.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py
Usability,simpl,simple,"""""""Renders a label image and optionally overlays it with another image. Used for generating simple output images to asses the label quality. Parameters; ----------; lbl: np.ndarray of dtype np.uint16; The 2D label image ; img: np.ndarray ; The array to overlay the label image with (optional); cmap: string, tuple, or callable; The label colormap. If given as rgb(a) only a single color is used, if None uses a random colormap ; cmap_img: string or callable; The colormap of img (optional); alpha: float ; The alpha value of the overlay. Set alpha=1 to get fully opaque labels; alpha_boundary: float; The alpha value of the boundary (if None, use the same as for labels, i.e. no boundaries are visible); normalize_img: bool; If True, normalizes the img (if given). Returns; -------; img: np.ndarray; the (m,n,4) RGBA image of the rendered label . Example; -------. from scipy.ndimage import label, zoom ; img = zoom(np.random.uniform(0,1,(16,16)),(8,8),order=3) ; lbl,_ = label(img>.8); u1 = render_label(lbl, img = img, alpha = .7); u2 = render_label(lbl, img = img, alpha = 0, alpha_boundary =.8); plt.subplot(1,2,1);plt.imshow(u1); plt.subplot(1,2,2);plt.imshow(u2). """"""; # render image if given; # render label; # blend; """"""; h0 = 0 -> red; h0 = 0.33 -> green; h0 = 0.66 -> blue; h0 = 0.833 -> magenta; """"""; """"""match labels from y to y0""""""; """"""Renders an image that shows segmentation errors between y_true and y_pred . Correctly matched objects (TP) are colored green (with transparency tp_alpha); Erronously detected objects (FP) are colored red (with transparency fp_alpha); MIssing GT objects (FN) are colored blue (with transparency fn_alpha). Parameters; ----------; y_true: np.ndarray of dtype np.uint16; The 2D GT label image ; y_pred: np.ndarray of dtype np.uint16; The 2D prediction label image ; img: np.ndarray ; The array to overlay the label image with (optional); cmap_img: string or callable; The colormap of img (optional); tp_alpha: float ; The alpha value of the TP ; fp_alpha: ",MatchSource.CODE_COMMENT,stardist/plot/render.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/plot/render.py
Performance,perform,perform,""""""". Command line script to perform prediction in 2D. """"""; """"""; Prediction script for a 2D stardist model, usage: stardist-predict -i input.tif -m model_folder_or_pretrained_name -o output_folder. """"""",MatchSource.CODE_COMMENT,stardist/scripts/predict2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict2d.py
Safety,predict,prediction,""""""". Command line script to perform prediction in 2D. """"""; """"""; Prediction script for a 2D stardist model, usage: stardist-predict -i input.tif -m model_folder_or_pretrained_name -o output_folder. """"""",MatchSource.CODE_COMMENT,stardist/scripts/predict2d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict2d.py
Performance,perform,perform,""""""". Command line script to perform prediction in 3D. """"""; """"""; Prediction script for a 3D stardist model, usage: stardist-predict -i input.tif -m model_folder_or_pretrained_name -o output_folder. """"""",MatchSource.CODE_COMMENT,stardist/scripts/predict3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict3d.py
Safety,predict,prediction,""""""". Command line script to perform prediction in 3D. """"""; """"""; Prediction script for a 3D stardist model, usage: stardist-predict -i input.tif -m model_folder_or_pretrained_name -o output_folder. """"""",MatchSource.CODE_COMMENT,stardist/scripts/predict3d.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/stardist/scripts/predict3d.py
Availability,mask,mask,"ize=polys['coord'].shape[:2]+(1,)); # labels = render_polygons(polys, img.shape); # # shuffle polygon probabilities/scores and render label image; # polys2 = {k:v.copy() for k,v in polys.items()}; # np.random.shuffle(polys2['prob']); # labels2 = render_polygons(polys2, img.shape); # assert not np.all(labels == labels2); # # repaint all labels (which are visible in the reference label image); # repaint_ids = set(np.unique(labels)) - {0}; # repaint_labels(labels2, list(repaint_ids), polys); # assert np.all(labels == labels2); # def test_repaint3D(model3d):; # np.random.seed(42); # model = model3d; # img = real_image3d()[0]; # img = normalize(img, 1, 99.8); # # get overlapping polygon predictions, wiggle them a bit, render reference label image; # polys = model.predict_instances(img, nms_thresh=0.95)[1]; # polys['dist'] += np.random.normal(scale=3, size=polys['dist'].shape[:1]+(1,)); # polys['dist'] = np.maximum(1, polys['dist']); # labels = polyhedron_to_label(polys['dist'], polys['points'], polys['rays'], img.shape, prob=polys['prob']); # # shuffle polygon probabilities/scores and render label image; # polys2 = {k:v.copy() if isinstance(v,np.ndarray) else v for k,v in polys.items()}; # np.random.shuffle(polys2['prob']); # labels2 = polyhedron_to_label(polys2['dist'], polys2['points'], polys2['rays'], img.shape, prob=polys2['prob']); # assert np.count_nonzero(labels != labels2) > 10000; # # repaint all labels (which are visible in the reference label image); # repaint_ids = set(np.unique(labels)) - {0}; # repaint_labels(labels2, list(repaint_ids), polys); # assert np.count_nonzero(labels != labels2) < 10 # TODO: why not 0?; # polygon representing object with id i; # mask of object with id i in label image (not occluded since nms_thresh=0); # polygon representing object with id i; # mask of object with id i in label image (not occluded since nms_thresh=0); # assert np.all(p.mask == mask_i) # few pixels are sometimes different, why?; # test_polygon_order_2D(_model2d())",MatchSource.CODE_COMMENT,tests/test_big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py
Safety,predict,predict-instances-big,"# print(len(blocks)); # in some cases need to add extra context to prevent overlapping write regions of non-neighboring blocks; # cf. https://forum.image.sc/t/trouble-using-stardist-predict-instances-big/88871/6; # sort them first lexicographic; # 2024-01-25: failed on github actions: ""windows-latest"" in combination with tensorflow 2.15.0 (python 3.9, 3.10, and 3.11); # (m.mean_true_score was 0.9999979271079009); # assert (1.0, 1.0) == (m.accuracy, m.mean_true_score); # sort them first lexicographic; # def test_repaint2D(model2d):; # np.random.seed(42); # model = model2d; # img = real_image2d()[0]; # img = normalize(img, 1, 99.8); # # get overlapping polygon predictions, wiggle them a bit, render reference label image; # polys = model.predict_instances(img, nms_thresh=0.97)[1]; # polys['coord'] += np.random.normal(scale=3, size=polys['coord'].shape[:2]+(1,)); # labels = render_polygons(polys, img.shape); # # shuffle polygon probabilities/scores and render label image; # polys2 = {k:v.copy() for k,v in polys.items()}; # np.random.shuffle(polys2['prob']); # labels2 = render_polygons(polys2, img.shape); # assert not np.all(labels == labels2); # # repaint all labels (which are visible in the reference label image); # repaint_ids = set(np.unique(labels)) - {0}; # repaint_labels(labels2, list(repaint_ids), polys); # assert np.all(labels == labels2); # def test_repaint3D(model3d):; # np.random.seed(42); # model = model3d; # img = real_image3d()[0]; # img = normalize(img, 1, 99.8); # # get overlapping polygon predictions, wiggle them a bit, render reference label image; # polys = model.predict_instances(img, nms_thresh=0.95)[1]; # polys['dist'] += np.random.normal(scale=3, size=polys['dist'].shape[:1]+(1,)); # polys['dist'] = np.maximum(1, polys['dist']); # labels = polyhedron_to_label(polys['dist'], polys['points'], polys['rays'], img.shape, prob=polys['prob']); # # shuffle polygon probabilities/scores and render label image; # polys2 = {k:v.copy() if isinstance(v,np.ndarra",MatchSource.CODE_COMMENT,tests/test_big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py
Testability,assert,assert,"# print(len(blocks)); # in some cases need to add extra context to prevent overlapping write regions of non-neighboring blocks; # cf. https://forum.image.sc/t/trouble-using-stardist-predict-instances-big/88871/6; # sort them first lexicographic; # 2024-01-25: failed on github actions: ""windows-latest"" in combination with tensorflow 2.15.0 (python 3.9, 3.10, and 3.11); # (m.mean_true_score was 0.9999979271079009); # assert (1.0, 1.0) == (m.accuracy, m.mean_true_score); # sort them first lexicographic; # def test_repaint2D(model2d):; # np.random.seed(42); # model = model2d; # img = real_image2d()[0]; # img = normalize(img, 1, 99.8); # # get overlapping polygon predictions, wiggle them a bit, render reference label image; # polys = model.predict_instances(img, nms_thresh=0.97)[1]; # polys['coord'] += np.random.normal(scale=3, size=polys['coord'].shape[:2]+(1,)); # labels = render_polygons(polys, img.shape); # # shuffle polygon probabilities/scores and render label image; # polys2 = {k:v.copy() for k,v in polys.items()}; # np.random.shuffle(polys2['prob']); # labels2 = render_polygons(polys2, img.shape); # assert not np.all(labels == labels2); # # repaint all labels (which are visible in the reference label image); # repaint_ids = set(np.unique(labels)) - {0}; # repaint_labels(labels2, list(repaint_ids), polys); # assert np.all(labels == labels2); # def test_repaint3D(model3d):; # np.random.seed(42); # model = model3d; # img = real_image3d()[0]; # img = normalize(img, 1, 99.8); # # get overlapping polygon predictions, wiggle them a bit, render reference label image; # polys = model.predict_instances(img, nms_thresh=0.95)[1]; # polys['dist'] += np.random.normal(scale=3, size=polys['dist'].shape[:1]+(1,)); # polys['dist'] = np.maximum(1, polys['dist']); # labels = polyhedron_to_label(polys['dist'], polys['points'], polys['rays'], img.shape, prob=polys['prob']); # # shuffle polygon probabilities/scores and render label image; # polys2 = {k:v.copy() if isinstance(v,np.ndarra",MatchSource.CODE_COMMENT,tests/test_big.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_big.py
Testability,test,test,"# export model; # test exported model; # import exported model; # test that model and imported exported model are equal; # normalize dict (especially tuples -> lists)",MatchSource.CODE_COMMENT,tests/test_bioimageio.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_bioimageio.py
Availability,mask,mask,"# integration test; # deactivate as order of labels might not be the same; # assert all(np.allclose(u,v) for u,v in zip(ref,res)); # ask to train only with foreground patches when there are none; # include a constant label image that must trigger a warning; ###; # mask to make labels negative; # im = render_label(y,img = x, alpha = 0.3, alpha_boundary=1, cmap = (.3,.4,0)); # return x,y; # sleep(np.abs(deg)/180); # img = np.tile(img,(4,4) if img.ndim==2 else (4,4,1)); # labels3, res3 = model.predict_instances_big(img, axes=""YX"" if img.ndim==2 else ""YXC"",; # block_size=640, min_overlap=32, context=96, **kwargs); # assert matching(labels1, labels3, thresh=0.99).f1 == 1; #, res3; # y2, res2 = model._instances_from_prediction_old(img.shape,prob,dist, nms_thresh=.3); # # reorder as polygons is inverted in newer versions; # res2 = dict((k,v[::-1]) for k,v in res2.items()); # y2[y2>0] = np.max(y2)-y2[y2>0]+1; # for k in res1.keys():; # if isinstance(res1[k], np.ndarray):; # assert np.allclose(res1[k],res2[k]); # assert np.allclose(y1,y2); # return y1, res1, y2, res2; # x = zoom(x, (0.5,0.5) if x.ndim==2 else (0.5,0.5,1), order=1) # to speed test up; # this test has to be at the end of the model; # model.export_TF(single_output=False, upsample_grid=False); # model.export_TF(single_output=False, upsample_grid=True); # test_speed(_model2d()); # _test_model_multiclass(n_classes = 1, classes = ""auto"", n_channel = None, basedir = None); # a,b,s = test_stardistdata_multithreaded(); # test_model(""foo"", 32, (1,1), None, 4); # test_foreground_warning(); # model = test_model(""tmpdir"", 32, (2, 2), 1, False, 1); # test_load_and_export_TF(model); # test_predict_dense_sparse(_model2d())",MatchSource.CODE_COMMENT,tests/test_model2D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py
Deployability,integrat,integration,"# integration test; # deactivate as order of labels might not be the same; # assert all(np.allclose(u,v) for u,v in zip(ref,res)); # ask to train only with foreground patches when there are none; # include a constant label image that must trigger a warning; ###; # mask to make labels negative; # im = render_label(y,img = x, alpha = 0.3, alpha_boundary=1, cmap = (.3,.4,0)); # return x,y; # sleep(np.abs(deg)/180); # img = np.tile(img,(4,4) if img.ndim==2 else (4,4,1)); # labels3, res3 = model.predict_instances_big(img, axes=""YX"" if img.ndim==2 else ""YXC"",; # block_size=640, min_overlap=32, context=96, **kwargs); # assert matching(labels1, labels3, thresh=0.99).f1 == 1; #, res3; # y2, res2 = model._instances_from_prediction_old(img.shape,prob,dist, nms_thresh=.3); # # reorder as polygons is inverted in newer versions; # res2 = dict((k,v[::-1]) for k,v in res2.items()); # y2[y2>0] = np.max(y2)-y2[y2>0]+1; # for k in res1.keys():; # if isinstance(res1[k], np.ndarray):; # assert np.allclose(res1[k],res2[k]); # assert np.allclose(y1,y2); # return y1, res1, y2, res2; # x = zoom(x, (0.5,0.5) if x.ndim==2 else (0.5,0.5,1), order=1) # to speed test up; # this test has to be at the end of the model; # model.export_TF(single_output=False, upsample_grid=False); # model.export_TF(single_output=False, upsample_grid=True); # test_speed(_model2d()); # _test_model_multiclass(n_classes = 1, classes = ""auto"", n_channel = None, basedir = None); # a,b,s = test_stardistdata_multithreaded(); # test_model(""foo"", 32, (1,1), None, 4); # test_foreground_warning(); # model = test_model(""tmpdir"", 32, (2, 2), 1, False, 1); # test_load_and_export_TF(model); # test_predict_dense_sparse(_model2d())",MatchSource.CODE_COMMENT,tests/test_model2D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py
Integrability,integrat,integration,"# integration test; # deactivate as order of labels might not be the same; # assert all(np.allclose(u,v) for u,v in zip(ref,res)); # ask to train only with foreground patches when there are none; # include a constant label image that must trigger a warning; ###; # mask to make labels negative; # im = render_label(y,img = x, alpha = 0.3, alpha_boundary=1, cmap = (.3,.4,0)); # return x,y; # sleep(np.abs(deg)/180); # img = np.tile(img,(4,4) if img.ndim==2 else (4,4,1)); # labels3, res3 = model.predict_instances_big(img, axes=""YX"" if img.ndim==2 else ""YXC"",; # block_size=640, min_overlap=32, context=96, **kwargs); # assert matching(labels1, labels3, thresh=0.99).f1 == 1; #, res3; # y2, res2 = model._instances_from_prediction_old(img.shape,prob,dist, nms_thresh=.3); # # reorder as polygons is inverted in newer versions; # res2 = dict((k,v[::-1]) for k,v in res2.items()); # y2[y2>0] = np.max(y2)-y2[y2>0]+1; # for k in res1.keys():; # if isinstance(res1[k], np.ndarray):; # assert np.allclose(res1[k],res2[k]); # assert np.allclose(y1,y2); # return y1, res1, y2, res2; # x = zoom(x, (0.5,0.5) if x.ndim==2 else (0.5,0.5,1), order=1) # to speed test up; # this test has to be at the end of the model; # model.export_TF(single_output=False, upsample_grid=False); # model.export_TF(single_output=False, upsample_grid=True); # test_speed(_model2d()); # _test_model_multiclass(n_classes = 1, classes = ""auto"", n_channel = None, basedir = None); # a,b,s = test_stardistdata_multithreaded(); # test_model(""foo"", 32, (1,1), None, 4); # test_foreground_warning(); # model = test_model(""tmpdir"", 32, (2, 2), 1, False, 1); # test_load_and_export_TF(model); # test_predict_dense_sparse(_model2d())",MatchSource.CODE_COMMENT,tests/test_model2D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py
Testability,test,test,"# integration test; # deactivate as order of labels might not be the same; # assert all(np.allclose(u,v) for u,v in zip(ref,res)); # ask to train only with foreground patches when there are none; # include a constant label image that must trigger a warning; ###; # mask to make labels negative; # im = render_label(y,img = x, alpha = 0.3, alpha_boundary=1, cmap = (.3,.4,0)); # return x,y; # sleep(np.abs(deg)/180); # img = np.tile(img,(4,4) if img.ndim==2 else (4,4,1)); # labels3, res3 = model.predict_instances_big(img, axes=""YX"" if img.ndim==2 else ""YXC"",; # block_size=640, min_overlap=32, context=96, **kwargs); # assert matching(labels1, labels3, thresh=0.99).f1 == 1; #, res3; # y2, res2 = model._instances_from_prediction_old(img.shape,prob,dist, nms_thresh=.3); # # reorder as polygons is inverted in newer versions; # res2 = dict((k,v[::-1]) for k,v in res2.items()); # y2[y2>0] = np.max(y2)-y2[y2>0]+1; # for k in res1.keys():; # if isinstance(res1[k], np.ndarray):; # assert np.allclose(res1[k],res2[k]); # assert np.allclose(y1,y2); # return y1, res1, y2, res2; # x = zoom(x, (0.5,0.5) if x.ndim==2 else (0.5,0.5,1), order=1) # to speed test up; # this test has to be at the end of the model; # model.export_TF(single_output=False, upsample_grid=False); # model.export_TF(single_output=False, upsample_grid=True); # test_speed(_model2d()); # _test_model_multiclass(n_classes = 1, classes = ""auto"", n_channel = None, basedir = None); # a,b,s = test_stardistdata_multithreaded(); # test_model(""foo"", 32, (1,1), None, 4); # test_foreground_warning(); # model = test_model(""tmpdir"", 32, (2, 2), 1, False, 1); # test_load_and_export_TF(model); # test_predict_dense_sparse(_model2d())",MatchSource.CODE_COMMENT,tests/test_model2D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model2D.py
Availability,mask,mask,"# integration test; # deactivate as order of labels might not be the same; # assert all(np.allclose(u,v) for u,v in zip(ref,res)); # ask to train only with foreground patches when there are none; # include a constant label image that must trigger a warning; # enforce implicit tiling; ###; # mask to make labels negative; # efine some classes according to the areas; # labels, res = model.predict_instances(img); # return model, X,Y, classes, labels, res; # img = np.tile(img,(4,2,2) if img.ndim==3 else (4,2,2,1)); # labels3, res3 = model.predict_instances_big(img, axes=""ZYX"" if img.ndim==3 else ""ZYXC"",; # block_size=96, min_overlap=8, context=8, **kwargs); #, res3; # (3, (1,2,3), 3, 1, 2),; # this test has to be at the end of the model; # model.export_TF(single_output=False, upsample_grid=False); # model.export_TF(single_output=False, upsample_grid=True); # from conftest import _model3d; # model, lbl = test_load_and_predict_with_overlap(_model3d()); # res = _test_model_multiclass(n_classes = 2, classes=""auto"", n_channel=1, epochs=20); # test_stardistdata((2,2,2), True); # x, y = test_predict_with_scale((.4,1,1))",MatchSource.CODE_COMMENT,tests/test_model3D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model3D.py
Deployability,integrat,integration,"# integration test; # deactivate as order of labels might not be the same; # assert all(np.allclose(u,v) for u,v in zip(ref,res)); # ask to train only with foreground patches when there are none; # include a constant label image that must trigger a warning; # enforce implicit tiling; ###; # mask to make labels negative; # efine some classes according to the areas; # labels, res = model.predict_instances(img); # return model, X,Y, classes, labels, res; # img = np.tile(img,(4,2,2) if img.ndim==3 else (4,2,2,1)); # labels3, res3 = model.predict_instances_big(img, axes=""ZYX"" if img.ndim==3 else ""ZYXC"",; # block_size=96, min_overlap=8, context=8, **kwargs); #, res3; # (3, (1,2,3), 3, 1, 2),; # this test has to be at the end of the model; # model.export_TF(single_output=False, upsample_grid=False); # model.export_TF(single_output=False, upsample_grid=True); # from conftest import _model3d; # model, lbl = test_load_and_predict_with_overlap(_model3d()); # res = _test_model_multiclass(n_classes = 2, classes=""auto"", n_channel=1, epochs=20); # test_stardistdata((2,2,2), True); # x, y = test_predict_with_scale((.4,1,1))",MatchSource.CODE_COMMENT,tests/test_model3D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model3D.py
Integrability,integrat,integration,"# integration test; # deactivate as order of labels might not be the same; # assert all(np.allclose(u,v) for u,v in zip(ref,res)); # ask to train only with foreground patches when there are none; # include a constant label image that must trigger a warning; # enforce implicit tiling; ###; # mask to make labels negative; # efine some classes according to the areas; # labels, res = model.predict_instances(img); # return model, X,Y, classes, labels, res; # img = np.tile(img,(4,2,2) if img.ndim==3 else (4,2,2,1)); # labels3, res3 = model.predict_instances_big(img, axes=""ZYX"" if img.ndim==3 else ""ZYXC"",; # block_size=96, min_overlap=8, context=8, **kwargs); #, res3; # (3, (1,2,3), 3, 1, 2),; # this test has to be at the end of the model; # model.export_TF(single_output=False, upsample_grid=False); # model.export_TF(single_output=False, upsample_grid=True); # from conftest import _model3d; # model, lbl = test_load_and_predict_with_overlap(_model3d()); # res = _test_model_multiclass(n_classes = 2, classes=""auto"", n_channel=1, epochs=20); # test_stardistdata((2,2,2), True); # x, y = test_predict_with_scale((.4,1,1))",MatchSource.CODE_COMMENT,tests/test_model3D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model3D.py
Testability,test,test,"# integration test; # deactivate as order of labels might not be the same; # assert all(np.allclose(u,v) for u,v in zip(ref,res)); # ask to train only with foreground patches when there are none; # include a constant label image that must trigger a warning; # enforce implicit tiling; ###; # mask to make labels negative; # efine some classes according to the areas; # labels, res = model.predict_instances(img); # return model, X,Y, classes, labels, res; # img = np.tile(img,(4,2,2) if img.ndim==3 else (4,2,2,1)); # labels3, res3 = model.predict_instances_big(img, axes=""ZYX"" if img.ndim==3 else ""ZYXC"",; # block_size=96, min_overlap=8, context=8, **kwargs); #, res3; # (3, (1,2,3), 3, 1, 2),; # this test has to be at the end of the model; # model.export_TF(single_output=False, upsample_grid=False); # model.export_TF(single_output=False, upsample_grid=True); # from conftest import _model3d; # model, lbl = test_load_and_predict_with_overlap(_model3d()); # res = _test_model_multiclass(n_classes = 2, classes=""auto"", n_channel=1, epochs=20); # test_stardistdata((2,2,2), True); # x, y = test_predict_with_scale((.4,1,1))",MatchSource.CODE_COMMENT,tests/test_model3D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_model3D.py
Testability,test,test,""""""" test whether an already star-convex label image gets perfectly relabeld""""""; # lbl1, lbl2 = test_relabel_consistency(32,eps = (.7,1), plot = True)",MatchSource.CODE_COMMENT,tests/test_stardist2D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_stardist2D.py
Testability,test,test,""""""" test whether an already star-convex label image gets perfectly relabeld""""""; # img = random_image((128, 123)); # lbl1, lbl2 = test_relabel_consistency(128,eps = (.5,1,1.2), plot = True) ; # lbl, d1,d2 = test_grid(grid=(1,2,2),shape=(62,63,66)); # test_grid((2,1,2), (32,67,93))",MatchSource.CODE_COMMENT,tests/test_stardist3D.py,stardist,stardist,0.9.1,,https://github.com/stardist/stardist/tree/0.9.1/tests/test_stardist3D.py
