id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/hail-is/hail/pull/9320:370,Performance,optimiz,optimization,370,"This PR adds `utils/StackSafe.scala`, which contains generic tools for writing stack safe code. To illustrate its use, I've converted `NormalizeNames` and `RewriteBottomUp` to be stack safe. This approach optimizes for the minimal possible change to existing code to make it stack safe. I originally expected this to have mediocre performance, and designed this to have optimization opportunities--requiring more substantial rewrites--where we found it was necessary. In a follow up PR, I converted the IR parser to be stack safe. In benchmarking that, I'm not able to see any performance penalty (if anything, the stack safe version looks slightly faster, which is probably just noise). So it's possible this will perform well enough as is, but we can keep an eye on it as we convert more passes. The basic idea is to rewrite functions that can be called recursively (directly or indirectly through a path of mutually recursive functions) from `f: (...) => A` to `f: (...) => StackFrame[A]`. Where the former evaluates, executing all recursive calls, and then returns the `A` result, the later returns a description of the work to be done before making any recursive calls. The method `StackFrame[A].run(): A` executes that description in a non-recursive loop. `StackFrame` is a monad, implementing `map` and `flatMap`, which allows the `for` syntactic sugar to be used. When a method makes several recursive calls, this can be significantly more readable. The public api is small. There are the free functions; ```scala; def done[A](result: A): StackFrame[A]; def call[A](body: => StackFrame[A]): StackFrame[A]; ```; and the methods; ```scala; abstract class StackFrame[A] {; def flatMap[B](f: A => StackFrame[B]): StackFrame[B]; def map[B](f: A => B): StackFrame[B] = flatMap(a => Done(f(a))); def run(): A; }; ```; `done` is basically the return statement. `call` is very important: it wraps a recursive call in a thunk, so that returning a `StackFrame` doesn't require descending all the way to t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9320
https://github.com/hail-is/hail/pull/9320:577,Performance,perform,performance,577,"This PR adds `utils/StackSafe.scala`, which contains generic tools for writing stack safe code. To illustrate its use, I've converted `NormalizeNames` and `RewriteBottomUp` to be stack safe. This approach optimizes for the minimal possible change to existing code to make it stack safe. I originally expected this to have mediocre performance, and designed this to have optimization opportunities--requiring more substantial rewrites--where we found it was necessary. In a follow up PR, I converted the IR parser to be stack safe. In benchmarking that, I'm not able to see any performance penalty (if anything, the stack safe version looks slightly faster, which is probably just noise). So it's possible this will perform well enough as is, but we can keep an eye on it as we convert more passes. The basic idea is to rewrite functions that can be called recursively (directly or indirectly through a path of mutually recursive functions) from `f: (...) => A` to `f: (...) => StackFrame[A]`. Where the former evaluates, executing all recursive calls, and then returns the `A` result, the later returns a description of the work to be done before making any recursive calls. The method `StackFrame[A].run(): A` executes that description in a non-recursive loop. `StackFrame` is a monad, implementing `map` and `flatMap`, which allows the `for` syntactic sugar to be used. When a method makes several recursive calls, this can be significantly more readable. The public api is small. There are the free functions; ```scala; def done[A](result: A): StackFrame[A]; def call[A](body: => StackFrame[A]): StackFrame[A]; ```; and the methods; ```scala; abstract class StackFrame[A] {; def flatMap[B](f: A => StackFrame[B]): StackFrame[B]; def map[B](f: A => B): StackFrame[B] = flatMap(a => Done(f(a))); def run(): A; }; ```; `done` is basically the return statement. `call` is very important: it wraps a recursive call in a thunk, so that returning a `StackFrame` doesn't require descending all the way to t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9320
https://github.com/hail-is/hail/pull/9320:715,Performance,perform,perform,715,"This PR adds `utils/StackSafe.scala`, which contains generic tools for writing stack safe code. To illustrate its use, I've converted `NormalizeNames` and `RewriteBottomUp` to be stack safe. This approach optimizes for the minimal possible change to existing code to make it stack safe. I originally expected this to have mediocre performance, and designed this to have optimization opportunities--requiring more substantial rewrites--where we found it was necessary. In a follow up PR, I converted the IR parser to be stack safe. In benchmarking that, I'm not able to see any performance penalty (if anything, the stack safe version looks slightly faster, which is probably just noise). So it's possible this will perform well enough as is, but we can keep an eye on it as we convert more passes. The basic idea is to rewrite functions that can be called recursively (directly or indirectly through a path of mutually recursive functions) from `f: (...) => A` to `f: (...) => StackFrame[A]`. Where the former evaluates, executing all recursive calls, and then returns the `A` result, the later returns a description of the work to be done before making any recursive calls. The method `StackFrame[A].run(): A` executes that description in a non-recursive loop. `StackFrame` is a monad, implementing `map` and `flatMap`, which allows the `for` syntactic sugar to be used. When a method makes several recursive calls, this can be significantly more readable. The public api is small. There are the free functions; ```scala; def done[A](result: A): StackFrame[A]; def call[A](body: => StackFrame[A]): StackFrame[A]; ```; and the methods; ```scala; abstract class StackFrame[A] {; def flatMap[B](f: A => StackFrame[B]): StackFrame[B]; def map[B](f: A => B): StackFrame[B] = flatMap(a => Done(f(a))); def run(): A; }; ```; `done` is basically the return statement. `call` is very important: it wraps a recursive call in a thunk, so that returning a `StackFrame` doesn't require descending all the way to t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9320
https://github.com/hail-is/hail/pull/9320:85,Safety,safe,safe,85,"This PR adds `utils/StackSafe.scala`, which contains generic tools for writing stack safe code. To illustrate its use, I've converted `NormalizeNames` and `RewriteBottomUp` to be stack safe. This approach optimizes for the minimal possible change to existing code to make it stack safe. I originally expected this to have mediocre performance, and designed this to have optimization opportunities--requiring more substantial rewrites--where we found it was necessary. In a follow up PR, I converted the IR parser to be stack safe. In benchmarking that, I'm not able to see any performance penalty (if anything, the stack safe version looks slightly faster, which is probably just noise). So it's possible this will perform well enough as is, but we can keep an eye on it as we convert more passes. The basic idea is to rewrite functions that can be called recursively (directly or indirectly through a path of mutually recursive functions) from `f: (...) => A` to `f: (...) => StackFrame[A]`. Where the former evaluates, executing all recursive calls, and then returns the `A` result, the later returns a description of the work to be done before making any recursive calls. The method `StackFrame[A].run(): A` executes that description in a non-recursive loop. `StackFrame` is a monad, implementing `map` and `flatMap`, which allows the `for` syntactic sugar to be used. When a method makes several recursive calls, this can be significantly more readable. The public api is small. There are the free functions; ```scala; def done[A](result: A): StackFrame[A]; def call[A](body: => StackFrame[A]): StackFrame[A]; ```; and the methods; ```scala; abstract class StackFrame[A] {; def flatMap[B](f: A => StackFrame[B]): StackFrame[B]; def map[B](f: A => B): StackFrame[B] = flatMap(a => Done(f(a))); def run(): A; }; ```; `done` is basically the return statement. `call` is very important: it wraps a recursive call in a thunk, so that returning a `StackFrame` doesn't require descending all the way to t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9320
https://github.com/hail-is/hail/pull/9320:185,Safety,safe,safe,185,"This PR adds `utils/StackSafe.scala`, which contains generic tools for writing stack safe code. To illustrate its use, I've converted `NormalizeNames` and `RewriteBottomUp` to be stack safe. This approach optimizes for the minimal possible change to existing code to make it stack safe. I originally expected this to have mediocre performance, and designed this to have optimization opportunities--requiring more substantial rewrites--where we found it was necessary. In a follow up PR, I converted the IR parser to be stack safe. In benchmarking that, I'm not able to see any performance penalty (if anything, the stack safe version looks slightly faster, which is probably just noise). So it's possible this will perform well enough as is, but we can keep an eye on it as we convert more passes. The basic idea is to rewrite functions that can be called recursively (directly or indirectly through a path of mutually recursive functions) from `f: (...) => A` to `f: (...) => StackFrame[A]`. Where the former evaluates, executing all recursive calls, and then returns the `A` result, the later returns a description of the work to be done before making any recursive calls. The method `StackFrame[A].run(): A` executes that description in a non-recursive loop. `StackFrame` is a monad, implementing `map` and `flatMap`, which allows the `for` syntactic sugar to be used. When a method makes several recursive calls, this can be significantly more readable. The public api is small. There are the free functions; ```scala; def done[A](result: A): StackFrame[A]; def call[A](body: => StackFrame[A]): StackFrame[A]; ```; and the methods; ```scala; abstract class StackFrame[A] {; def flatMap[B](f: A => StackFrame[B]): StackFrame[B]; def map[B](f: A => B): StackFrame[B] = flatMap(a => Done(f(a))); def run(): A; }; ```; `done` is basically the return statement. `call` is very important: it wraps a recursive call in a thunk, so that returning a `StackFrame` doesn't require descending all the way to t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9320
https://github.com/hail-is/hail/pull/9320:281,Safety,safe,safe,281,"This PR adds `utils/StackSafe.scala`, which contains generic tools for writing stack safe code. To illustrate its use, I've converted `NormalizeNames` and `RewriteBottomUp` to be stack safe. This approach optimizes for the minimal possible change to existing code to make it stack safe. I originally expected this to have mediocre performance, and designed this to have optimization opportunities--requiring more substantial rewrites--where we found it was necessary. In a follow up PR, I converted the IR parser to be stack safe. In benchmarking that, I'm not able to see any performance penalty (if anything, the stack safe version looks slightly faster, which is probably just noise). So it's possible this will perform well enough as is, but we can keep an eye on it as we convert more passes. The basic idea is to rewrite functions that can be called recursively (directly or indirectly through a path of mutually recursive functions) from `f: (...) => A` to `f: (...) => StackFrame[A]`. Where the former evaluates, executing all recursive calls, and then returns the `A` result, the later returns a description of the work to be done before making any recursive calls. The method `StackFrame[A].run(): A` executes that description in a non-recursive loop. `StackFrame` is a monad, implementing `map` and `flatMap`, which allows the `for` syntactic sugar to be used. When a method makes several recursive calls, this can be significantly more readable. The public api is small. There are the free functions; ```scala; def done[A](result: A): StackFrame[A]; def call[A](body: => StackFrame[A]): StackFrame[A]; ```; and the methods; ```scala; abstract class StackFrame[A] {; def flatMap[B](f: A => StackFrame[B]): StackFrame[B]; def map[B](f: A => B): StackFrame[B] = flatMap(a => Done(f(a))); def run(): A; }; ```; `done` is basically the return statement. `call` is very important: it wraps a recursive call in a thunk, so that returning a `StackFrame` doesn't require descending all the way to t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9320
https://github.com/hail-is/hail/pull/9320:525,Safety,safe,safe,525,"This PR adds `utils/StackSafe.scala`, which contains generic tools for writing stack safe code. To illustrate its use, I've converted `NormalizeNames` and `RewriteBottomUp` to be stack safe. This approach optimizes for the minimal possible change to existing code to make it stack safe. I originally expected this to have mediocre performance, and designed this to have optimization opportunities--requiring more substantial rewrites--where we found it was necessary. In a follow up PR, I converted the IR parser to be stack safe. In benchmarking that, I'm not able to see any performance penalty (if anything, the stack safe version looks slightly faster, which is probably just noise). So it's possible this will perform well enough as is, but we can keep an eye on it as we convert more passes. The basic idea is to rewrite functions that can be called recursively (directly or indirectly through a path of mutually recursive functions) from `f: (...) => A` to `f: (...) => StackFrame[A]`. Where the former evaluates, executing all recursive calls, and then returns the `A` result, the later returns a description of the work to be done before making any recursive calls. The method `StackFrame[A].run(): A` executes that description in a non-recursive loop. `StackFrame` is a monad, implementing `map` and `flatMap`, which allows the `for` syntactic sugar to be used. When a method makes several recursive calls, this can be significantly more readable. The public api is small. There are the free functions; ```scala; def done[A](result: A): StackFrame[A]; def call[A](body: => StackFrame[A]): StackFrame[A]; ```; and the methods; ```scala; abstract class StackFrame[A] {; def flatMap[B](f: A => StackFrame[B]): StackFrame[B]; def map[B](f: A => B): StackFrame[B] = flatMap(a => Done(f(a))); def run(): A; }; ```; `done` is basically the return statement. `call` is very important: it wraps a recursive call in a thunk, so that returning a `StackFrame` doesn't require descending all the way to t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9320
https://github.com/hail-is/hail/pull/9320:621,Safety,safe,safe,621,"This PR adds `utils/StackSafe.scala`, which contains generic tools for writing stack safe code. To illustrate its use, I've converted `NormalizeNames` and `RewriteBottomUp` to be stack safe. This approach optimizes for the minimal possible change to existing code to make it stack safe. I originally expected this to have mediocre performance, and designed this to have optimization opportunities--requiring more substantial rewrites--where we found it was necessary. In a follow up PR, I converted the IR parser to be stack safe. In benchmarking that, I'm not able to see any performance penalty (if anything, the stack safe version looks slightly faster, which is probably just noise). So it's possible this will perform well enough as is, but we can keep an eye on it as we convert more passes. The basic idea is to rewrite functions that can be called recursively (directly or indirectly through a path of mutually recursive functions) from `f: (...) => A` to `f: (...) => StackFrame[A]`. Where the former evaluates, executing all recursive calls, and then returns the `A` result, the later returns a description of the work to be done before making any recursive calls. The method `StackFrame[A].run(): A` executes that description in a non-recursive loop. `StackFrame` is a monad, implementing `map` and `flatMap`, which allows the `for` syntactic sugar to be used. When a method makes several recursive calls, this can be significantly more readable. The public api is small. There are the free functions; ```scala; def done[A](result: A): StackFrame[A]; def call[A](body: => StackFrame[A]): StackFrame[A]; ```; and the methods; ```scala; abstract class StackFrame[A] {; def flatMap[B](f: A => StackFrame[B]): StackFrame[B]; def map[B](f: A => B): StackFrame[B] = flatMap(a => Done(f(a))); def run(): A; }; ```; `done` is basically the return statement. `call` is very important: it wraps a recursive call in a thunk, so that returning a `StackFrame` doesn't require descending all the way to t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9320
https://github.com/hail-is/hail/pull/9320:534,Testability,benchmark,benchmarking,534,"This PR adds `utils/StackSafe.scala`, which contains generic tools for writing stack safe code. To illustrate its use, I've converted `NormalizeNames` and `RewriteBottomUp` to be stack safe. This approach optimizes for the minimal possible change to existing code to make it stack safe. I originally expected this to have mediocre performance, and designed this to have optimization opportunities--requiring more substantial rewrites--where we found it was necessary. In a follow up PR, I converted the IR parser to be stack safe. In benchmarking that, I'm not able to see any performance penalty (if anything, the stack safe version looks slightly faster, which is probably just noise). So it's possible this will perform well enough as is, but we can keep an eye on it as we convert more passes. The basic idea is to rewrite functions that can be called recursively (directly or indirectly through a path of mutually recursive functions) from `f: (...) => A` to `f: (...) => StackFrame[A]`. Where the former evaluates, executing all recursive calls, and then returns the `A` result, the later returns a description of the work to be done before making any recursive calls. The method `StackFrame[A].run(): A` executes that description in a non-recursive loop. `StackFrame` is a monad, implementing `map` and `flatMap`, which allows the `for` syntactic sugar to be used. When a method makes several recursive calls, this can be significantly more readable. The public api is small. There are the free functions; ```scala; def done[A](result: A): StackFrame[A]; def call[A](body: => StackFrame[A]): StackFrame[A]; ```; and the methods; ```scala; abstract class StackFrame[A] {; def flatMap[B](f: A => StackFrame[B]): StackFrame[B]; def map[B](f: A => B): StackFrame[B] = flatMap(a => Done(f(a))); def run(): A; }; ```; `done` is basically the return statement. `call` is very important: it wraps a recursive call in a thunk, so that returning a `StackFrame` doesn't require descending all the way to t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9320
https://github.com/hail-is/hail/pull/9324:317,Availability,avail,available,317,"This groups IBD and pc_relate together. I will follow up with KING. I plan to; lift some of the documentation verbiage from PC-Relate up and to unify the; mathematical presentation for PC-Relate and KING. I did not change the implementations, I just moved them into the relatedness; package. Both functions are still available at `hl.methods.XXX`. The import changes are just me using `(` and `)` instead of line continuation.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9324
https://github.com/hail-is/hail/pull/9328:918,Energy Efficiency,allocate,allocate,918,"CHANGELOG: Eliminate quadratic behavior in `BlockMatrix.to_matrix_table_row_major`. Users should expect significant reduction in run-time. There are two significant changes in this PR:; - Teach `LZ4InputBlockBuffer` how to skip bytes without decompressing every block, and; - Teach BlockMatrix to use a small cache of rows when converting from a BlockMatrix to a row-wise RDD. ### Blocked LZ4 Byte Skipping. We compress in blocks of 16 KiB. The blocks begin with an 32-bit integer indicating the decompressed length. When we're skipping large numbers of bytes we can request an `LZ4InputBlockBuffer` to skip decompression if the entire block will be skipped. ### BlockMatrix Blocks to Rows Caching; Currently, for every row in every block, BM opens a file, skips to the appropriate location, reads that one row, writes it into an RVB, and then closes the file. This has terrible cache and I/O performance. Instead, we allocate 32 MiB to cache the rows of each block. We divide the cache evenly across all rows. The new implementation requires the cache can at least fit one row of the block, with 32 MiB we're good up to ~4 million (total) columns. We'll need to reimplement this to also use a tree-aggregate long before we get to 4 million columns. ### Benchmark Results. This branch vs main (3149211fb79b):; ```; Benchmark Name Ratio Time 1 Time 2; -------------- ----- ------ ------; to_matrix_table_row_major 716.3% 251.300 1800.000; ----------------------; Harmonic mean: 716.3%; Geometric mean: 716.3%; Arithmetic mean: 716.3%; Median: 716.3%; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9328
https://github.com/hail-is/hail/pull/9328:309,Performance,cache,cache,309,"CHANGELOG: Eliminate quadratic behavior in `BlockMatrix.to_matrix_table_row_major`. Users should expect significant reduction in run-time. There are two significant changes in this PR:; - Teach `LZ4InputBlockBuffer` how to skip bytes without decompressing every block, and; - Teach BlockMatrix to use a small cache of rows when converting from a BlockMatrix to a row-wise RDD. ### Blocked LZ4 Byte Skipping. We compress in blocks of 16 KiB. The blocks begin with an 32-bit integer indicating the decompressed length. When we're skipping large numbers of bytes we can request an `LZ4InputBlockBuffer` to skip decompression if the entire block will be skipped. ### BlockMatrix Blocks to Rows Caching; Currently, for every row in every block, BM opens a file, skips to the appropriate location, reads that one row, writes it into an RVB, and then closes the file. This has terrible cache and I/O performance. Instead, we allocate 32 MiB to cache the rows of each block. We divide the cache evenly across all rows. The new implementation requires the cache can at least fit one row of the block, with 32 MiB we're good up to ~4 million (total) columns. We'll need to reimplement this to also use a tree-aggregate long before we get to 4 million columns. ### Benchmark Results. This branch vs main (3149211fb79b):; ```; Benchmark Name Ratio Time 1 Time 2; -------------- ----- ------ ------; to_matrix_table_row_major 716.3% 251.300 1800.000; ----------------------; Harmonic mean: 716.3%; Geometric mean: 716.3%; Arithmetic mean: 716.3%; Median: 716.3%; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9328
https://github.com/hail-is/hail/pull/9328:879,Performance,cache,cache,879,"CHANGELOG: Eliminate quadratic behavior in `BlockMatrix.to_matrix_table_row_major`. Users should expect significant reduction in run-time. There are two significant changes in this PR:; - Teach `LZ4InputBlockBuffer` how to skip bytes without decompressing every block, and; - Teach BlockMatrix to use a small cache of rows when converting from a BlockMatrix to a row-wise RDD. ### Blocked LZ4 Byte Skipping. We compress in blocks of 16 KiB. The blocks begin with an 32-bit integer indicating the decompressed length. When we're skipping large numbers of bytes we can request an `LZ4InputBlockBuffer` to skip decompression if the entire block will be skipped. ### BlockMatrix Blocks to Rows Caching; Currently, for every row in every block, BM opens a file, skips to the appropriate location, reads that one row, writes it into an RVB, and then closes the file. This has terrible cache and I/O performance. Instead, we allocate 32 MiB to cache the rows of each block. We divide the cache evenly across all rows. The new implementation requires the cache can at least fit one row of the block, with 32 MiB we're good up to ~4 million (total) columns. We'll need to reimplement this to also use a tree-aggregate long before we get to 4 million columns. ### Benchmark Results. This branch vs main (3149211fb79b):; ```; Benchmark Name Ratio Time 1 Time 2; -------------- ----- ------ ------; to_matrix_table_row_major 716.3% 251.300 1800.000; ----------------------; Harmonic mean: 716.3%; Geometric mean: 716.3%; Arithmetic mean: 716.3%; Median: 716.3%; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9328
https://github.com/hail-is/hail/pull/9328:893,Performance,perform,performance,893,"CHANGELOG: Eliminate quadratic behavior in `BlockMatrix.to_matrix_table_row_major`. Users should expect significant reduction in run-time. There are two significant changes in this PR:; - Teach `LZ4InputBlockBuffer` how to skip bytes without decompressing every block, and; - Teach BlockMatrix to use a small cache of rows when converting from a BlockMatrix to a row-wise RDD. ### Blocked LZ4 Byte Skipping. We compress in blocks of 16 KiB. The blocks begin with an 32-bit integer indicating the decompressed length. When we're skipping large numbers of bytes we can request an `LZ4InputBlockBuffer` to skip decompression if the entire block will be skipped. ### BlockMatrix Blocks to Rows Caching; Currently, for every row in every block, BM opens a file, skips to the appropriate location, reads that one row, writes it into an RVB, and then closes the file. This has terrible cache and I/O performance. Instead, we allocate 32 MiB to cache the rows of each block. We divide the cache evenly across all rows. The new implementation requires the cache can at least fit one row of the block, with 32 MiB we're good up to ~4 million (total) columns. We'll need to reimplement this to also use a tree-aggregate long before we get to 4 million columns. ### Benchmark Results. This branch vs main (3149211fb79b):; ```; Benchmark Name Ratio Time 1 Time 2; -------------- ----- ------ ------; to_matrix_table_row_major 716.3% 251.300 1800.000; ----------------------; Harmonic mean: 716.3%; Geometric mean: 716.3%; Arithmetic mean: 716.3%; Median: 716.3%; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9328
https://github.com/hail-is/hail/pull/9328:937,Performance,cache,cache,937,"CHANGELOG: Eliminate quadratic behavior in `BlockMatrix.to_matrix_table_row_major`. Users should expect significant reduction in run-time. There are two significant changes in this PR:; - Teach `LZ4InputBlockBuffer` how to skip bytes without decompressing every block, and; - Teach BlockMatrix to use a small cache of rows when converting from a BlockMatrix to a row-wise RDD. ### Blocked LZ4 Byte Skipping. We compress in blocks of 16 KiB. The blocks begin with an 32-bit integer indicating the decompressed length. When we're skipping large numbers of bytes we can request an `LZ4InputBlockBuffer` to skip decompression if the entire block will be skipped. ### BlockMatrix Blocks to Rows Caching; Currently, for every row in every block, BM opens a file, skips to the appropriate location, reads that one row, writes it into an RVB, and then closes the file. This has terrible cache and I/O performance. Instead, we allocate 32 MiB to cache the rows of each block. We divide the cache evenly across all rows. The new implementation requires the cache can at least fit one row of the block, with 32 MiB we're good up to ~4 million (total) columns. We'll need to reimplement this to also use a tree-aggregate long before we get to 4 million columns. ### Benchmark Results. This branch vs main (3149211fb79b):; ```; Benchmark Name Ratio Time 1 Time 2; -------------- ----- ------ ------; to_matrix_table_row_major 716.3% 251.300 1800.000; ----------------------; Harmonic mean: 716.3%; Geometric mean: 716.3%; Arithmetic mean: 716.3%; Median: 716.3%; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9328
https://github.com/hail-is/hail/pull/9328:981,Performance,cache,cache,981,"CHANGELOG: Eliminate quadratic behavior in `BlockMatrix.to_matrix_table_row_major`. Users should expect significant reduction in run-time. There are two significant changes in this PR:; - Teach `LZ4InputBlockBuffer` how to skip bytes without decompressing every block, and; - Teach BlockMatrix to use a small cache of rows when converting from a BlockMatrix to a row-wise RDD. ### Blocked LZ4 Byte Skipping. We compress in blocks of 16 KiB. The blocks begin with an 32-bit integer indicating the decompressed length. When we're skipping large numbers of bytes we can request an `LZ4InputBlockBuffer` to skip decompression if the entire block will be skipped. ### BlockMatrix Blocks to Rows Caching; Currently, for every row in every block, BM opens a file, skips to the appropriate location, reads that one row, writes it into an RVB, and then closes the file. This has terrible cache and I/O performance. Instead, we allocate 32 MiB to cache the rows of each block. We divide the cache evenly across all rows. The new implementation requires the cache can at least fit one row of the block, with 32 MiB we're good up to ~4 million (total) columns. We'll need to reimplement this to also use a tree-aggregate long before we get to 4 million columns. ### Benchmark Results. This branch vs main (3149211fb79b):; ```; Benchmark Name Ratio Time 1 Time 2; -------------- ----- ------ ------; to_matrix_table_row_major 716.3% 251.300 1800.000; ----------------------; Harmonic mean: 716.3%; Geometric mean: 716.3%; Arithmetic mean: 716.3%; Median: 716.3%; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9328
https://github.com/hail-is/hail/pull/9328:1047,Performance,cache,cache,1047,"CHANGELOG: Eliminate quadratic behavior in `BlockMatrix.to_matrix_table_row_major`. Users should expect significant reduction in run-time. There are two significant changes in this PR:; - Teach `LZ4InputBlockBuffer` how to skip bytes without decompressing every block, and; - Teach BlockMatrix to use a small cache of rows when converting from a BlockMatrix to a row-wise RDD. ### Blocked LZ4 Byte Skipping. We compress in blocks of 16 KiB. The blocks begin with an 32-bit integer indicating the decompressed length. When we're skipping large numbers of bytes we can request an `LZ4InputBlockBuffer` to skip decompression if the entire block will be skipped. ### BlockMatrix Blocks to Rows Caching; Currently, for every row in every block, BM opens a file, skips to the appropriate location, reads that one row, writes it into an RVB, and then closes the file. This has terrible cache and I/O performance. Instead, we allocate 32 MiB to cache the rows of each block. We divide the cache evenly across all rows. The new implementation requires the cache can at least fit one row of the block, with 32 MiB we're good up to ~4 million (total) columns. We'll need to reimplement this to also use a tree-aggregate long before we get to 4 million columns. ### Benchmark Results. This branch vs main (3149211fb79b):; ```; Benchmark Name Ratio Time 1 Time 2; -------------- ----- ------ ------; to_matrix_table_row_major 716.3% 251.300 1800.000; ----------------------; Harmonic mean: 716.3%; Geometric mean: 716.3%; Arithmetic mean: 716.3%; Median: 716.3%; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9328
https://github.com/hail-is/hail/pull/9328:1254,Testability,Benchmark,Benchmark,1254,"CHANGELOG: Eliminate quadratic behavior in `BlockMatrix.to_matrix_table_row_major`. Users should expect significant reduction in run-time. There are two significant changes in this PR:; - Teach `LZ4InputBlockBuffer` how to skip bytes without decompressing every block, and; - Teach BlockMatrix to use a small cache of rows when converting from a BlockMatrix to a row-wise RDD. ### Blocked LZ4 Byte Skipping. We compress in blocks of 16 KiB. The blocks begin with an 32-bit integer indicating the decompressed length. When we're skipping large numbers of bytes we can request an `LZ4InputBlockBuffer` to skip decompression if the entire block will be skipped. ### BlockMatrix Blocks to Rows Caching; Currently, for every row in every block, BM opens a file, skips to the appropriate location, reads that one row, writes it into an RVB, and then closes the file. This has terrible cache and I/O performance. Instead, we allocate 32 MiB to cache the rows of each block. We divide the cache evenly across all rows. The new implementation requires the cache can at least fit one row of the block, with 32 MiB we're good up to ~4 million (total) columns. We'll need to reimplement this to also use a tree-aggregate long before we get to 4 million columns. ### Benchmark Results. This branch vs main (3149211fb79b):; ```; Benchmark Name Ratio Time 1 Time 2; -------------- ----- ------ ------; to_matrix_table_row_major 716.3% 251.300 1800.000; ----------------------; Harmonic mean: 716.3%; Geometric mean: 716.3%; Arithmetic mean: 716.3%; Median: 716.3%; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9328
https://github.com/hail-is/hail/pull/9328:1315,Testability,Benchmark,Benchmark,1315,"CHANGELOG: Eliminate quadratic behavior in `BlockMatrix.to_matrix_table_row_major`. Users should expect significant reduction in run-time. There are two significant changes in this PR:; - Teach `LZ4InputBlockBuffer` how to skip bytes without decompressing every block, and; - Teach BlockMatrix to use a small cache of rows when converting from a BlockMatrix to a row-wise RDD. ### Blocked LZ4 Byte Skipping. We compress in blocks of 16 KiB. The blocks begin with an 32-bit integer indicating the decompressed length. When we're skipping large numbers of bytes we can request an `LZ4InputBlockBuffer` to skip decompression if the entire block will be skipped. ### BlockMatrix Blocks to Rows Caching; Currently, for every row in every block, BM opens a file, skips to the appropriate location, reads that one row, writes it into an RVB, and then closes the file. This has terrible cache and I/O performance. Instead, we allocate 32 MiB to cache the rows of each block. We divide the cache evenly across all rows. The new implementation requires the cache can at least fit one row of the block, with 32 MiB we're good up to ~4 million (total) columns. We'll need to reimplement this to also use a tree-aggregate long before we get to 4 million columns. ### Benchmark Results. This branch vs main (3149211fb79b):; ```; Benchmark Name Ratio Time 1 Time 2; -------------- ----- ------ ------; to_matrix_table_row_major 716.3% 251.300 1800.000; ----------------------; Harmonic mean: 716.3%; Geometric mean: 716.3%; Arithmetic mean: 716.3%; Median: 716.3%; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9328
https://github.com/hail-is/hail/pull/9331:76,Availability,avail,available,76,"Updated the datasets/annotation_db.json config file with datasets currently available in bucket at gs://hail-datasets-hail-data, also updated docs to reflect the datasets available via the `load_datasets()` function.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9331
https://github.com/hail-is/hail/pull/9331:171,Availability,avail,available,171,"Updated the datasets/annotation_db.json config file with datasets currently available in bucket at gs://hail-datasets-hail-data, also updated docs to reflect the datasets available via the `load_datasets()` function.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9331
https://github.com/hail-is/hail/pull/9331:0,Deployability,Update,Updated,0,"Updated the datasets/annotation_db.json config file with datasets currently available in bucket at gs://hail-datasets-hail-data, also updated docs to reflect the datasets available via the `load_datasets()` function.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9331
https://github.com/hail-is/hail/pull/9331:134,Deployability,update,updated,134,"Updated the datasets/annotation_db.json config file with datasets currently available in bucket at gs://hail-datasets-hail-data, also updated docs to reflect the datasets available via the `load_datasets()` function.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9331
https://github.com/hail-is/hail/pull/9331:40,Modifiability,config,config,40,"Updated the datasets/annotation_db.json config file with datasets currently available in bucket at gs://hail-datasets-hail-data, also updated docs to reflect the datasets available via the `load_datasets()` function.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9331
https://github.com/hail-is/hail/pull/9332:157,Modifiability,refactor,refactoring,157,"~~Stacked on #9320~~. Use the framework introduced in #9320 to make the IR parser stack safe. This touches a lot of lines, but it is a completely mechanical refactoring. I did some preliminary benchmarking by timing the parse of the IR in `test_ld_prune`. (I chose that test fairly arbitrarily, and we can probably find better test cases, or generate synthetic large IRs.) Running a loop parsing the same IR repeatedly, with 10 burn-in rounds, and 60 timed rounds, I got the following results:; * On main; ```; quartiles = [4.55816, 5.209579, 5.647135]; avg = 5.332496950000001, std = 1.13761574944604; ```; * Using `StackSafe`, without the optimization in `repUntil`; ```; quantiles = [4.610798, 5.09793, 7.159075]; avg = 5.7519015000000016, std = 1.612397075594852; ```; * Using `StackSafe, with the optimization which reuses the `cont` closure, instead of allocating a new one for each token.; ```; quantiles = [4.466849, 4.826873, 5.719238]; avg = 5.2787357833333335, std = 1.272006325411254; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9332
https://github.com/hail-is/hail/pull/9332:641,Performance,optimiz,optimization,641,"~~Stacked on #9320~~. Use the framework introduced in #9320 to make the IR parser stack safe. This touches a lot of lines, but it is a completely mechanical refactoring. I did some preliminary benchmarking by timing the parse of the IR in `test_ld_prune`. (I chose that test fairly arbitrarily, and we can probably find better test cases, or generate synthetic large IRs.) Running a loop parsing the same IR repeatedly, with 10 burn-in rounds, and 60 timed rounds, I got the following results:; * On main; ```; quartiles = [4.55816, 5.209579, 5.647135]; avg = 5.332496950000001, std = 1.13761574944604; ```; * Using `StackSafe`, without the optimization in `repUntil`; ```; quantiles = [4.610798, 5.09793, 7.159075]; avg = 5.7519015000000016, std = 1.612397075594852; ```; * Using `StackSafe, with the optimization which reuses the `cont` closure, instead of allocating a new one for each token.; ```; quantiles = [4.466849, 4.826873, 5.719238]; avg = 5.2787357833333335, std = 1.272006325411254; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9332
https://github.com/hail-is/hail/pull/9332:802,Performance,optimiz,optimization,802,"~~Stacked on #9320~~. Use the framework introduced in #9320 to make the IR parser stack safe. This touches a lot of lines, but it is a completely mechanical refactoring. I did some preliminary benchmarking by timing the parse of the IR in `test_ld_prune`. (I chose that test fairly arbitrarily, and we can probably find better test cases, or generate synthetic large IRs.) Running a loop parsing the same IR repeatedly, with 10 burn-in rounds, and 60 timed rounds, I got the following results:; * On main; ```; quartiles = [4.55816, 5.209579, 5.647135]; avg = 5.332496950000001, std = 1.13761574944604; ```; * Using `StackSafe`, without the optimization in `repUntil`; ```; quantiles = [4.610798, 5.09793, 7.159075]; avg = 5.7519015000000016, std = 1.612397075594852; ```; * Using `StackSafe, with the optimization which reuses the `cont` closure, instead of allocating a new one for each token.; ```; quantiles = [4.466849, 4.826873, 5.719238]; avg = 5.2787357833333335, std = 1.272006325411254; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9332
https://github.com/hail-is/hail/pull/9332:88,Safety,safe,safe,88,"~~Stacked on #9320~~. Use the framework introduced in #9320 to make the IR parser stack safe. This touches a lot of lines, but it is a completely mechanical refactoring. I did some preliminary benchmarking by timing the parse of the IR in `test_ld_prune`. (I chose that test fairly arbitrarily, and we can probably find better test cases, or generate synthetic large IRs.) Running a loop parsing the same IR repeatedly, with 10 burn-in rounds, and 60 timed rounds, I got the following results:; * On main; ```; quartiles = [4.55816, 5.209579, 5.647135]; avg = 5.332496950000001, std = 1.13761574944604; ```; * Using `StackSafe`, without the optimization in `repUntil`; ```; quantiles = [4.610798, 5.09793, 7.159075]; avg = 5.7519015000000016, std = 1.612397075594852; ```; * Using `StackSafe, with the optimization which reuses the `cont` closure, instead of allocating a new one for each token.; ```; quantiles = [4.466849, 4.826873, 5.719238]; avg = 5.2787357833333335, std = 1.272006325411254; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9332
https://github.com/hail-is/hail/pull/9332:193,Testability,benchmark,benchmarking,193,"~~Stacked on #9320~~. Use the framework introduced in #9320 to make the IR parser stack safe. This touches a lot of lines, but it is a completely mechanical refactoring. I did some preliminary benchmarking by timing the parse of the IR in `test_ld_prune`. (I chose that test fairly arbitrarily, and we can probably find better test cases, or generate synthetic large IRs.) Running a loop parsing the same IR repeatedly, with 10 burn-in rounds, and 60 timed rounds, I got the following results:; * On main; ```; quartiles = [4.55816, 5.209579, 5.647135]; avg = 5.332496950000001, std = 1.13761574944604; ```; * Using `StackSafe`, without the optimization in `repUntil`; ```; quantiles = [4.610798, 5.09793, 7.159075]; avg = 5.7519015000000016, std = 1.612397075594852; ```; * Using `StackSafe, with the optimization which reuses the `cont` closure, instead of allocating a new one for each token.; ```; quantiles = [4.466849, 4.826873, 5.719238]; avg = 5.2787357833333335, std = 1.272006325411254; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9332
https://github.com/hail-is/hail/pull/9332:270,Testability,test,test,270,"~~Stacked on #9320~~. Use the framework introduced in #9320 to make the IR parser stack safe. This touches a lot of lines, but it is a completely mechanical refactoring. I did some preliminary benchmarking by timing the parse of the IR in `test_ld_prune`. (I chose that test fairly arbitrarily, and we can probably find better test cases, or generate synthetic large IRs.) Running a loop parsing the same IR repeatedly, with 10 burn-in rounds, and 60 timed rounds, I got the following results:; * On main; ```; quartiles = [4.55816, 5.209579, 5.647135]; avg = 5.332496950000001, std = 1.13761574944604; ```; * Using `StackSafe`, without the optimization in `repUntil`; ```; quantiles = [4.610798, 5.09793, 7.159075]; avg = 5.7519015000000016, std = 1.612397075594852; ```; * Using `StackSafe, with the optimization which reuses the `cont` closure, instead of allocating a new one for each token.; ```; quantiles = [4.466849, 4.826873, 5.719238]; avg = 5.2787357833333335, std = 1.272006325411254; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9332
https://github.com/hail-is/hail/pull/9332:327,Testability,test,test,327,"~~Stacked on #9320~~. Use the framework introduced in #9320 to make the IR parser stack safe. This touches a lot of lines, but it is a completely mechanical refactoring. I did some preliminary benchmarking by timing the parse of the IR in `test_ld_prune`. (I chose that test fairly arbitrarily, and we can probably find better test cases, or generate synthetic large IRs.) Running a loop parsing the same IR repeatedly, with 10 burn-in rounds, and 60 timed rounds, I got the following results:; * On main; ```; quartiles = [4.55816, 5.209579, 5.647135]; avg = 5.332496950000001, std = 1.13761574944604; ```; * Using `StackSafe`, without the optimization in `repUntil`; ```; quantiles = [4.610798, 5.09793, 7.159075]; avg = 5.7519015000000016, std = 1.612397075594852; ```; * Using `StackSafe, with the optimization which reuses the `cont` closure, instead of allocating a new one for each token.; ```; quantiles = [4.466849, 4.826873, 5.719238]; avg = 5.2787357833333335, std = 1.272006325411254; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9332
https://github.com/hail-is/hail/pull/9335:137,Availability,failure,failures,137,"I am not really sure why $? is not set to 1 if these parentheses are absent. Nonetheless,; this fixes CI to actually complain about mypy failures.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9335
https://github.com/hail-is/hail/pull/9337:292,Safety,safe,safe,292,"It seems that 83 is potentially too high now. I saw batch-driver get overwhelmed with the current setting. However, there was also a bug related leaking database connections which also contributed to the observed behavior. Batch was able to make forward progress with 45, so at least this is safe and can be adjusted again next time we're running at scale.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9337
https://github.com/hail-is/hail/pull/9338:128,Availability,echo,echo,128,Make evaluates the entire recipe before executing it. Consider this:; ```; (base) # cat Makefile; rm -rf file; make foo; foo:; 	echo hello > file; 	echo $(shell cat file); cat: file: No such file or directory; echo hello > file; echo . ```; The file does not exist because Make runs cat before the recipe is executed.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9338
https://github.com/hail-is/hail/pull/9338:148,Availability,echo,echo,148,Make evaluates the entire recipe before executing it. Consider this:; ```; (base) # cat Makefile; rm -rf file; make foo; foo:; 	echo hello > file; 	echo $(shell cat file); cat: file: No such file or directory; echo hello > file; echo . ```; The file does not exist because Make runs cat before the recipe is executed.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9338
https://github.com/hail-is/hail/pull/9338:210,Availability,echo,echo,210,Make evaluates the entire recipe before executing it. Consider this:; ```; (base) # cat Makefile; rm -rf file; make foo; foo:; 	echo hello > file; 	echo $(shell cat file); cat: file: No such file or directory; echo hello > file; echo . ```; The file does not exist because Make runs cat before the recipe is executed.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9338
https://github.com/hail-is/hail/pull/9338:229,Availability,echo,echo,229,Make evaluates the entire recipe before executing it. Consider this:; ```; (base) # cat Makefile; rm -rf file; make foo; foo:; 	echo hello > file; 	echo $(shell cat file); cat: file: No such file or directory; echo hello > file; echo . ```; The file does not exist because Make runs cat before the recipe is executed.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9338
https://github.com/hail-is/hail/pull/9341:28,Testability,benchmark,benchmark,28,This ensures that we fail a benchmark early if we cannot copy into the output directory.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9341
https://github.com/hail-is/hail/pull/9343:639,Integrability,interface,interface,639,"CHANGELOG: Implement the KING method for relationship inference as hl.methods.king. Just look at the last commit. The other commits are PRs that I hope will merge; on Tuesday. This PR implements `hl.methods.king` a new, relatively fast, method for; relationship inference on genotype data. I am eager for criticism of the ""Notes""; section in which I attempt to describe the KING method to a Hail user with only; a basic understanding of genotype matrices and Hail. I also include a benchmark which exercises MT->BM, matrix multiply, and; BM->MT. We have an opportunity for a substantial improvement in performance by; BM->replacing the BM interface by one which permits multiple entry fields. In; BM->particular, note that I have to convert from row-partitioning to; BM->block-partitioning four times!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9343
https://github.com/hail-is/hail/pull/9343:602,Performance,perform,performance,602,"CHANGELOG: Implement the KING method for relationship inference as hl.methods.king. Just look at the last commit. The other commits are PRs that I hope will merge; on Tuesday. This PR implements `hl.methods.king` a new, relatively fast, method for; relationship inference on genotype data. I am eager for criticism of the ""Notes""; section in which I attempt to describe the KING method to a Hail user with only; a basic understanding of genotype matrices and Hail. I also include a benchmark which exercises MT->BM, matrix multiply, and; BM->MT. We have an opportunity for a substantial improvement in performance by; BM->replacing the BM interface by one which permits multiple entry fields. In; BM->particular, note that I have to convert from row-partitioning to; BM->block-partitioning four times!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9343
https://github.com/hail-is/hail/pull/9343:482,Testability,benchmark,benchmark,482,"CHANGELOG: Implement the KING method for relationship inference as hl.methods.king. Just look at the last commit. The other commits are PRs that I hope will merge; on Tuesday. This PR implements `hl.methods.king` a new, relatively fast, method for; relationship inference on genotype data. I am eager for criticism of the ""Notes""; section in which I attempt to describe the KING method to a Hail user with only; a basic understanding of genotype matrices and Hail. I also include a benchmark which exercises MT->BM, matrix multiply, and; BM->MT. We have an opportunity for a substantial improvement in performance by; BM->replacing the BM interface by one which permits multiple entry fields. In; BM->particular, note that I have to convert from row-partitioning to; BM->block-partitioning four times!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9343
https://github.com/hail-is/hail/pull/9346:83,Availability,error,errors,83,I tested this by adding the check_aggregated_resources loop which didn't throw any errors. I tested the cost by looking at the UI and submitting one job that cost $0.0004 and then two of that same job in a batch and it cost $0.0008. The database looked like this:. mysql> select * FROM aggregated_batch_resources where batch_id > 46;; +----------+--------------------------+-------------+-------+; | batch_id | resource | usage | token |; +----------+--------------------------+-------------+-------+; | 47 | compute/n1-preemptible/1 | 25867000 | 11 |; | 47 | compute/n1-preemptible/1 | 0 | 115 |; | 47 | compute/n1-preemptible/1 | 0 | 132 |; | 47 | disk/local-ssd/1 | 9932928000 | 11 |; | 47 | disk/local-ssd/1 | 0 | 54 |; | 47 | disk/local-ssd/1 | 0 | 132 |; | 47 | disk/pd-ssd/1 | 529756160 | 11 |; | 47 | disk/pd-ssd/1 | 0 | 132 |; | 47 | disk/pd-ssd/1 | 0 | 186 |; | 47 | ip-fee/1024/1 | 26487808 | 11 |; | 47 | ip-fee/1024/1 | 0 | 132 |; | 47 | ip-fee/1024/1 | 0 | 188 |; | 47 | memory/n1-preemptible/1 | 99329280 | 11 |; | 47 | memory/n1-preemptible/1 | 0 | 26 |; | 47 | memory/n1-preemptible/1 | 0 | 132 |; | 47 | service-fee/1 | 25867000 | 11 |; | 47 | service-fee/1 | 0 | 110 |; | 47 | service-fee/1 | 0 | 132 |; | 48 | compute/n1-preemptible/1 | 0 | 31 |; | 48 | compute/n1-preemptible/1 | 0 | 76 |; | 48 | compute/n1-preemptible/1 | 27659000 | 94 |; | 48 | compute/n1-preemptible/1 | 26520000 | 122 |; | 48 | compute/n1-preemptible/1 | 0 | 156 |; | 48 | compute/n1-preemptible/1 | 0 | 168 |; | 48 | disk/local-ssd/1 | 10621056000 | 94 |; | 48 | disk/local-ssd/1 | 10183680000 | 122 |; | 48 | disk/local-ssd/1 | 0 | 125 |; | 48 | disk/local-ssd/1 | 0 | 154 |; | 48 | disk/local-ssd/1 | 0 | 156 |; | 48 | disk/local-ssd/1 | 0 | 168 |; | 48 | disk/pd-ssd/1 | 0 | 69 |; | 48 | disk/pd-ssd/1 | 566456320 | 94 |; | 48 | disk/pd-ssd/1 | 0 | 102 |; | 48 | disk/pd-ssd/1 | 543129600 | 122 |; | 48 | disk/pd-ssd/1 | 0 | 156 |; | 48 | disk/pd-ssd/1 | 0 | 168 |; | 48 | ip-fee/1024/1 | 0 | 57 |; | 48 ,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9346
https://github.com/hail-is/hail/pull/9346:2,Testability,test,tested,2,I tested this by adding the check_aggregated_resources loop which didn't throw any errors. I tested the cost by looking at the UI and submitting one job that cost $0.0004 and then two of that same job in a batch and it cost $0.0008. The database looked like this:. mysql> select * FROM aggregated_batch_resources where batch_id > 46;; +----------+--------------------------+-------------+-------+; | batch_id | resource | usage | token |; +----------+--------------------------+-------------+-------+; | 47 | compute/n1-preemptible/1 | 25867000 | 11 |; | 47 | compute/n1-preemptible/1 | 0 | 115 |; | 47 | compute/n1-preemptible/1 | 0 | 132 |; | 47 | disk/local-ssd/1 | 9932928000 | 11 |; | 47 | disk/local-ssd/1 | 0 | 54 |; | 47 | disk/local-ssd/1 | 0 | 132 |; | 47 | disk/pd-ssd/1 | 529756160 | 11 |; | 47 | disk/pd-ssd/1 | 0 | 132 |; | 47 | disk/pd-ssd/1 | 0 | 186 |; | 47 | ip-fee/1024/1 | 26487808 | 11 |; | 47 | ip-fee/1024/1 | 0 | 132 |; | 47 | ip-fee/1024/1 | 0 | 188 |; | 47 | memory/n1-preemptible/1 | 99329280 | 11 |; | 47 | memory/n1-preemptible/1 | 0 | 26 |; | 47 | memory/n1-preemptible/1 | 0 | 132 |; | 47 | service-fee/1 | 25867000 | 11 |; | 47 | service-fee/1 | 0 | 110 |; | 47 | service-fee/1 | 0 | 132 |; | 48 | compute/n1-preemptible/1 | 0 | 31 |; | 48 | compute/n1-preemptible/1 | 0 | 76 |; | 48 | compute/n1-preemptible/1 | 27659000 | 94 |; | 48 | compute/n1-preemptible/1 | 26520000 | 122 |; | 48 | compute/n1-preemptible/1 | 0 | 156 |; | 48 | compute/n1-preemptible/1 | 0 | 168 |; | 48 | disk/local-ssd/1 | 10621056000 | 94 |; | 48 | disk/local-ssd/1 | 10183680000 | 122 |; | 48 | disk/local-ssd/1 | 0 | 125 |; | 48 | disk/local-ssd/1 | 0 | 154 |; | 48 | disk/local-ssd/1 | 0 | 156 |; | 48 | disk/local-ssd/1 | 0 | 168 |; | 48 | disk/pd-ssd/1 | 0 | 69 |; | 48 | disk/pd-ssd/1 | 566456320 | 94 |; | 48 | disk/pd-ssd/1 | 0 | 102 |; | 48 | disk/pd-ssd/1 | 543129600 | 122 |; | 48 | disk/pd-ssd/1 | 0 | 156 |; | 48 | disk/pd-ssd/1 | 0 | 168 |; | 48 | ip-fee/1024/1 | 0 | 57 |; | 48 ,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9346
https://github.com/hail-is/hail/pull/9346:93,Testability,test,tested,93,I tested this by adding the check_aggregated_resources loop which didn't throw any errors. I tested the cost by looking at the UI and submitting one job that cost $0.0004 and then two of that same job in a batch and it cost $0.0008. The database looked like this:. mysql> select * FROM aggregated_batch_resources where batch_id > 46;; +----------+--------------------------+-------------+-------+; | batch_id | resource | usage | token |; +----------+--------------------------+-------------+-------+; | 47 | compute/n1-preemptible/1 | 25867000 | 11 |; | 47 | compute/n1-preemptible/1 | 0 | 115 |; | 47 | compute/n1-preemptible/1 | 0 | 132 |; | 47 | disk/local-ssd/1 | 9932928000 | 11 |; | 47 | disk/local-ssd/1 | 0 | 54 |; | 47 | disk/local-ssd/1 | 0 | 132 |; | 47 | disk/pd-ssd/1 | 529756160 | 11 |; | 47 | disk/pd-ssd/1 | 0 | 132 |; | 47 | disk/pd-ssd/1 | 0 | 186 |; | 47 | ip-fee/1024/1 | 26487808 | 11 |; | 47 | ip-fee/1024/1 | 0 | 132 |; | 47 | ip-fee/1024/1 | 0 | 188 |; | 47 | memory/n1-preemptible/1 | 99329280 | 11 |; | 47 | memory/n1-preemptible/1 | 0 | 26 |; | 47 | memory/n1-preemptible/1 | 0 | 132 |; | 47 | service-fee/1 | 25867000 | 11 |; | 47 | service-fee/1 | 0 | 110 |; | 47 | service-fee/1 | 0 | 132 |; | 48 | compute/n1-preemptible/1 | 0 | 31 |; | 48 | compute/n1-preemptible/1 | 0 | 76 |; | 48 | compute/n1-preemptible/1 | 27659000 | 94 |; | 48 | compute/n1-preemptible/1 | 26520000 | 122 |; | 48 | compute/n1-preemptible/1 | 0 | 156 |; | 48 | compute/n1-preemptible/1 | 0 | 168 |; | 48 | disk/local-ssd/1 | 10621056000 | 94 |; | 48 | disk/local-ssd/1 | 10183680000 | 122 |; | 48 | disk/local-ssd/1 | 0 | 125 |; | 48 | disk/local-ssd/1 | 0 | 154 |; | 48 | disk/local-ssd/1 | 0 | 156 |; | 48 | disk/local-ssd/1 | 0 | 168 |; | 48 | disk/pd-ssd/1 | 0 | 69 |; | 48 | disk/pd-ssd/1 | 566456320 | 94 |; | 48 | disk/pd-ssd/1 | 0 | 102 |; | 48 | disk/pd-ssd/1 | 543129600 | 122 |; | 48 | disk/pd-ssd/1 | 0 | 156 |; | 48 | disk/pd-ssd/1 | 0 | 168 |; | 48 | ip-fee/1024/1 | 0 | 57 |; | 48 ,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9346
https://github.com/hail-is/hail/pull/9348:338,Deployability,install,installed,338,"It takes one minute to build the docs *even if nothing has changed since the; last build*. There are a few things that lengthen the feedback cycle:. - We defeat Sphinx's input cache by deleting and re-copying over all the source; files.; - We defeat Sphinx's output cache by `mv`ing the output to a new location.; - We check that Hail is installed (at a cost of two seconds) *every* time we; build the docs. This isn't necessary, Sphinx prints a reasonable message; (""cannot import ..."") if Hail is not installed.; - We create a wheel file every time we build the docs at a cost of several; seconds.; - We recreate the tutorials tar even if it has not changed. Instead, I propose this PR:. - Do not copy the source files.; - Copy the output to the new location.; - Do not check hail is installed.; - Do not even install Hail.; - Use Make to check if the tutorial tar need be recreated. Regarding not installing Hail: even install-editable takes two seconds. It is; the developer's responsibility to ensure the right version of Hail is; installed. When you check out a branch just run `make install-editable`; once. Then edit the docs to your heart's desire, never re-install Hail. With this PR it takes ~3.5 seconds to rebuild the docs if nothing has; changed. We do work proportional to the number of changed files, not; proportional to all files. Sphinx itself takes 2-3 seconds, so we can't do much; better than this. Dice came up Patrick, but I imagine @tpoterba has thoughts.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9348
https://github.com/hail-is/hail/pull/9348:503,Deployability,install,installed,503,"It takes one minute to build the docs *even if nothing has changed since the; last build*. There are a few things that lengthen the feedback cycle:. - We defeat Sphinx's input cache by deleting and re-copying over all the source; files.; - We defeat Sphinx's output cache by `mv`ing the output to a new location.; - We check that Hail is installed (at a cost of two seconds) *every* time we; build the docs. This isn't necessary, Sphinx prints a reasonable message; (""cannot import ..."") if Hail is not installed.; - We create a wheel file every time we build the docs at a cost of several; seconds.; - We recreate the tutorials tar even if it has not changed. Instead, I propose this PR:. - Do not copy the source files.; - Copy the output to the new location.; - Do not check hail is installed.; - Do not even install Hail.; - Use Make to check if the tutorial tar need be recreated. Regarding not installing Hail: even install-editable takes two seconds. It is; the developer's responsibility to ensure the right version of Hail is; installed. When you check out a branch just run `make install-editable`; once. Then edit the docs to your heart's desire, never re-install Hail. With this PR it takes ~3.5 seconds to rebuild the docs if nothing has; changed. We do work proportional to the number of changed files, not; proportional to all files. Sphinx itself takes 2-3 seconds, so we can't do much; better than this. Dice came up Patrick, but I imagine @tpoterba has thoughts.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9348
https://github.com/hail-is/hail/pull/9348:786,Deployability,install,installed,786,"It takes one minute to build the docs *even if nothing has changed since the; last build*. There are a few things that lengthen the feedback cycle:. - We defeat Sphinx's input cache by deleting and re-copying over all the source; files.; - We defeat Sphinx's output cache by `mv`ing the output to a new location.; - We check that Hail is installed (at a cost of two seconds) *every* time we; build the docs. This isn't necessary, Sphinx prints a reasonable message; (""cannot import ..."") if Hail is not installed.; - We create a wheel file every time we build the docs at a cost of several; seconds.; - We recreate the tutorials tar even if it has not changed. Instead, I propose this PR:. - Do not copy the source files.; - Copy the output to the new location.; - Do not check hail is installed.; - Do not even install Hail.; - Use Make to check if the tutorial tar need be recreated. Regarding not installing Hail: even install-editable takes two seconds. It is; the developer's responsibility to ensure the right version of Hail is; installed. When you check out a branch just run `make install-editable`; once. Then edit the docs to your heart's desire, never re-install Hail. With this PR it takes ~3.5 seconds to rebuild the docs if nothing has; changed. We do work proportional to the number of changed files, not; proportional to all files. Sphinx itself takes 2-3 seconds, so we can't do much; better than this. Dice came up Patrick, but I imagine @tpoterba has thoughts.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9348
https://github.com/hail-is/hail/pull/9348:812,Deployability,install,install,812,"It takes one minute to build the docs *even if nothing has changed since the; last build*. There are a few things that lengthen the feedback cycle:. - We defeat Sphinx's input cache by deleting and re-copying over all the source; files.; - We defeat Sphinx's output cache by `mv`ing the output to a new location.; - We check that Hail is installed (at a cost of two seconds) *every* time we; build the docs. This isn't necessary, Sphinx prints a reasonable message; (""cannot import ..."") if Hail is not installed.; - We create a wheel file every time we build the docs at a cost of several; seconds.; - We recreate the tutorials tar even if it has not changed. Instead, I propose this PR:. - Do not copy the source files.; - Copy the output to the new location.; - Do not check hail is installed.; - Do not even install Hail.; - Use Make to check if the tutorial tar need be recreated. Regarding not installing Hail: even install-editable takes two seconds. It is; the developer's responsibility to ensure the right version of Hail is; installed. When you check out a branch just run `make install-editable`; once. Then edit the docs to your heart's desire, never re-install Hail. With this PR it takes ~3.5 seconds to rebuild the docs if nothing has; changed. We do work proportional to the number of changed files, not; proportional to all files. Sphinx itself takes 2-3 seconds, so we can't do much; better than this. Dice came up Patrick, but I imagine @tpoterba has thoughts.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9348
https://github.com/hail-is/hail/pull/9348:900,Deployability,install,installing,900,"It takes one minute to build the docs *even if nothing has changed since the; last build*. There are a few things that lengthen the feedback cycle:. - We defeat Sphinx's input cache by deleting and re-copying over all the source; files.; - We defeat Sphinx's output cache by `mv`ing the output to a new location.; - We check that Hail is installed (at a cost of two seconds) *every* time we; build the docs. This isn't necessary, Sphinx prints a reasonable message; (""cannot import ..."") if Hail is not installed.; - We create a wheel file every time we build the docs at a cost of several; seconds.; - We recreate the tutorials tar even if it has not changed. Instead, I propose this PR:. - Do not copy the source files.; - Copy the output to the new location.; - Do not check hail is installed.; - Do not even install Hail.; - Use Make to check if the tutorial tar need be recreated. Regarding not installing Hail: even install-editable takes two seconds. It is; the developer's responsibility to ensure the right version of Hail is; installed. When you check out a branch just run `make install-editable`; once. Then edit the docs to your heart's desire, never re-install Hail. With this PR it takes ~3.5 seconds to rebuild the docs if nothing has; changed. We do work proportional to the number of changed files, not; proportional to all files. Sphinx itself takes 2-3 seconds, so we can't do much; better than this. Dice came up Patrick, but I imagine @tpoterba has thoughts.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9348
https://github.com/hail-is/hail/pull/9348:922,Deployability,install,install-editable,922,"It takes one minute to build the docs *even if nothing has changed since the; last build*. There are a few things that lengthen the feedback cycle:. - We defeat Sphinx's input cache by deleting and re-copying over all the source; files.; - We defeat Sphinx's output cache by `mv`ing the output to a new location.; - We check that Hail is installed (at a cost of two seconds) *every* time we; build the docs. This isn't necessary, Sphinx prints a reasonable message; (""cannot import ..."") if Hail is not installed.; - We create a wheel file every time we build the docs at a cost of several; seconds.; - We recreate the tutorials tar even if it has not changed. Instead, I propose this PR:. - Do not copy the source files.; - Copy the output to the new location.; - Do not check hail is installed.; - Do not even install Hail.; - Use Make to check if the tutorial tar need be recreated. Regarding not installing Hail: even install-editable takes two seconds. It is; the developer's responsibility to ensure the right version of Hail is; installed. When you check out a branch just run `make install-editable`; once. Then edit the docs to your heart's desire, never re-install Hail. With this PR it takes ~3.5 seconds to rebuild the docs if nothing has; changed. We do work proportional to the number of changed files, not; proportional to all files. Sphinx itself takes 2-3 seconds, so we can't do much; better than this. Dice came up Patrick, but I imagine @tpoterba has thoughts.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9348
https://github.com/hail-is/hail/pull/9348:1036,Deployability,install,installed,1036,"It takes one minute to build the docs *even if nothing has changed since the; last build*. There are a few things that lengthen the feedback cycle:. - We defeat Sphinx's input cache by deleting and re-copying over all the source; files.; - We defeat Sphinx's output cache by `mv`ing the output to a new location.; - We check that Hail is installed (at a cost of two seconds) *every* time we; build the docs. This isn't necessary, Sphinx prints a reasonable message; (""cannot import ..."") if Hail is not installed.; - We create a wheel file every time we build the docs at a cost of several; seconds.; - We recreate the tutorials tar even if it has not changed. Instead, I propose this PR:. - Do not copy the source files.; - Copy the output to the new location.; - Do not check hail is installed.; - Do not even install Hail.; - Use Make to check if the tutorial tar need be recreated. Regarding not installing Hail: even install-editable takes two seconds. It is; the developer's responsibility to ensure the right version of Hail is; installed. When you check out a branch just run `make install-editable`; once. Then edit the docs to your heart's desire, never re-install Hail. With this PR it takes ~3.5 seconds to rebuild the docs if nothing has; changed. We do work proportional to the number of changed files, not; proportional to all files. Sphinx itself takes 2-3 seconds, so we can't do much; better than this. Dice came up Patrick, but I imagine @tpoterba has thoughts.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9348
https://github.com/hail-is/hail/pull/9348:1090,Deployability,install,install-editable,1090,"It takes one minute to build the docs *even if nothing has changed since the; last build*. There are a few things that lengthen the feedback cycle:. - We defeat Sphinx's input cache by deleting and re-copying over all the source; files.; - We defeat Sphinx's output cache by `mv`ing the output to a new location.; - We check that Hail is installed (at a cost of two seconds) *every* time we; build the docs. This isn't necessary, Sphinx prints a reasonable message; (""cannot import ..."") if Hail is not installed.; - We create a wheel file every time we build the docs at a cost of several; seconds.; - We recreate the tutorials tar even if it has not changed. Instead, I propose this PR:. - Do not copy the source files.; - Copy the output to the new location.; - Do not check hail is installed.; - Do not even install Hail.; - Use Make to check if the tutorial tar need be recreated. Regarding not installing Hail: even install-editable takes two seconds. It is; the developer's responsibility to ensure the right version of Hail is; installed. When you check out a branch just run `make install-editable`; once. Then edit the docs to your heart's desire, never re-install Hail. With this PR it takes ~3.5 seconds to rebuild the docs if nothing has; changed. We do work proportional to the number of changed files, not; proportional to all files. Sphinx itself takes 2-3 seconds, so we can't do much; better than this. Dice came up Patrick, but I imagine @tpoterba has thoughts.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9348
https://github.com/hail-is/hail/pull/9348:1167,Deployability,install,install,1167,"It takes one minute to build the docs *even if nothing has changed since the; last build*. There are a few things that lengthen the feedback cycle:. - We defeat Sphinx's input cache by deleting and re-copying over all the source; files.; - We defeat Sphinx's output cache by `mv`ing the output to a new location.; - We check that Hail is installed (at a cost of two seconds) *every* time we; build the docs. This isn't necessary, Sphinx prints a reasonable message; (""cannot import ..."") if Hail is not installed.; - We create a wheel file every time we build the docs at a cost of several; seconds.; - We recreate the tutorials tar even if it has not changed. Instead, I propose this PR:. - Do not copy the source files.; - Copy the output to the new location.; - Do not check hail is installed.; - Do not even install Hail.; - Use Make to check if the tutorial tar need be recreated. Regarding not installing Hail: even install-editable takes two seconds. It is; the developer's responsibility to ensure the right version of Hail is; installed. When you check out a branch just run `make install-editable`; once. Then edit the docs to your heart's desire, never re-install Hail. With this PR it takes ~3.5 seconds to rebuild the docs if nothing has; changed. We do work proportional to the number of changed files, not; proportional to all files. Sphinx itself takes 2-3 seconds, so we can't do much; better than this. Dice came up Patrick, but I imagine @tpoterba has thoughts.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9348
https://github.com/hail-is/hail/pull/9348:457,Integrability,message,message,457,"It takes one minute to build the docs *even if nothing has changed since the; last build*. There are a few things that lengthen the feedback cycle:. - We defeat Sphinx's input cache by deleting and re-copying over all the source; files.; - We defeat Sphinx's output cache by `mv`ing the output to a new location.; - We check that Hail is installed (at a cost of two seconds) *every* time we; build the docs. This isn't necessary, Sphinx prints a reasonable message; (""cannot import ..."") if Hail is not installed.; - We create a wheel file every time we build the docs at a cost of several; seconds.; - We recreate the tutorials tar even if it has not changed. Instead, I propose this PR:. - Do not copy the source files.; - Copy the output to the new location.; - Do not check hail is installed.; - Do not even install Hail.; - Use Make to check if the tutorial tar need be recreated. Regarding not installing Hail: even install-editable takes two seconds. It is; the developer's responsibility to ensure the right version of Hail is; installed. When you check out a branch just run `make install-editable`; once. Then edit the docs to your heart's desire, never re-install Hail. With this PR it takes ~3.5 seconds to rebuild the docs if nothing has; changed. We do work proportional to the number of changed files, not; proportional to all files. Sphinx itself takes 2-3 seconds, so we can't do much; better than this. Dice came up Patrick, but I imagine @tpoterba has thoughts.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9348
https://github.com/hail-is/hail/pull/9348:176,Performance,cache,cache,176,"It takes one minute to build the docs *even if nothing has changed since the; last build*. There are a few things that lengthen the feedback cycle:. - We defeat Sphinx's input cache by deleting and re-copying over all the source; files.; - We defeat Sphinx's output cache by `mv`ing the output to a new location.; - We check that Hail is installed (at a cost of two seconds) *every* time we; build the docs. This isn't necessary, Sphinx prints a reasonable message; (""cannot import ..."") if Hail is not installed.; - We create a wheel file every time we build the docs at a cost of several; seconds.; - We recreate the tutorials tar even if it has not changed. Instead, I propose this PR:. - Do not copy the source files.; - Copy the output to the new location.; - Do not check hail is installed.; - Do not even install Hail.; - Use Make to check if the tutorial tar need be recreated. Regarding not installing Hail: even install-editable takes two seconds. It is; the developer's responsibility to ensure the right version of Hail is; installed. When you check out a branch just run `make install-editable`; once. Then edit the docs to your heart's desire, never re-install Hail. With this PR it takes ~3.5 seconds to rebuild the docs if nothing has; changed. We do work proportional to the number of changed files, not; proportional to all files. Sphinx itself takes 2-3 seconds, so we can't do much; better than this. Dice came up Patrick, but I imagine @tpoterba has thoughts.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9348
https://github.com/hail-is/hail/pull/9348:266,Performance,cache,cache,266,"It takes one minute to build the docs *even if nothing has changed since the; last build*. There are a few things that lengthen the feedback cycle:. - We defeat Sphinx's input cache by deleting and re-copying over all the source; files.; - We defeat Sphinx's output cache by `mv`ing the output to a new location.; - We check that Hail is installed (at a cost of two seconds) *every* time we; build the docs. This isn't necessary, Sphinx prints a reasonable message; (""cannot import ..."") if Hail is not installed.; - We create a wheel file every time we build the docs at a cost of several; seconds.; - We recreate the tutorials tar even if it has not changed. Instead, I propose this PR:. - Do not copy the source files.; - Copy the output to the new location.; - Do not check hail is installed.; - Do not even install Hail.; - Use Make to check if the tutorial tar need be recreated. Regarding not installing Hail: even install-editable takes two seconds. It is; the developer's responsibility to ensure the right version of Hail is; installed. When you check out a branch just run `make install-editable`; once. Then edit the docs to your heart's desire, never re-install Hail. With this PR it takes ~3.5 seconds to rebuild the docs if nothing has; changed. We do work proportional to the number of changed files, not; proportional to all files. Sphinx itself takes 2-3 seconds, so we can't do much; better than this. Dice came up Patrick, but I imagine @tpoterba has thoughts.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9348
https://github.com/hail-is/hail/pull/9348:132,Usability,feedback,feedback,132,"It takes one minute to build the docs *even if nothing has changed since the; last build*. There are a few things that lengthen the feedback cycle:. - We defeat Sphinx's input cache by deleting and re-copying over all the source; files.; - We defeat Sphinx's output cache by `mv`ing the output to a new location.; - We check that Hail is installed (at a cost of two seconds) *every* time we; build the docs. This isn't necessary, Sphinx prints a reasonable message; (""cannot import ..."") if Hail is not installed.; - We create a wheel file every time we build the docs at a cost of several; seconds.; - We recreate the tutorials tar even if it has not changed. Instead, I propose this PR:. - Do not copy the source files.; - Copy the output to the new location.; - Do not check hail is installed.; - Do not even install Hail.; - Use Make to check if the tutorial tar need be recreated. Regarding not installing Hail: even install-editable takes two seconds. It is; the developer's responsibility to ensure the right version of Hail is; installed. When you check out a branch just run `make install-editable`; once. Then edit the docs to your heart's desire, never re-install Hail. With this PR it takes ~3.5 seconds to rebuild the docs if nothing has; changed. We do work proportional to the number of changed files, not; proportional to all files. Sphinx itself takes 2-3 seconds, so we can't do much; better than this. Dice came up Patrick, but I imagine @tpoterba has thoughts.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9348
https://github.com/hail-is/hail/pull/9353:92,Testability,test,test,92,We're supposed to use DOCKER-USER https://docs.docker.com/network/iptables/. I also added a test.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9353
https://github.com/hail-is/hail/pull/9354:473,Availability,error,errors,473,"Stacked on #9346 . Changes:; - infrastructure needed for kill switch; - UI page; - Default value for the limit is None. Testing:; - In the database migration, there's two updates that populate the initial state of the aggregated_billing_resources_table. I tested this by hand using a database that hadn't been migrated previously, but this might be good to double check.; - I ran the `check_resource_aggregation` loop while running `test_batch` and made sure there were no errors.; - I tested the UI page editing the limits with negative values and gibberish by hand to make sure those failed. I also refreshed the page to make sure the values were in the database and the update worked. So here's a PR where I convinced myself it was correct a couple of days ago, but the longer this sits, the less confident I'm going to be that there's not a mistake somewhere, especially if there are a lot of changes that need to be made to the code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9354
https://github.com/hail-is/hail/pull/9354:57,Deployability,kill switch,kill switch,57,"Stacked on #9346 . Changes:; - infrastructure needed for kill switch; - UI page; - Default value for the limit is None. Testing:; - In the database migration, there's two updates that populate the initial state of the aggregated_billing_resources_table. I tested this by hand using a database that hadn't been migrated previously, but this might be good to double check.; - I ran the `check_resource_aggregation` loop while running `test_batch` and made sure there were no errors.; - I tested the UI page editing the limits with negative values and gibberish by hand to make sure those failed. I also refreshed the page to make sure the values were in the database and the update worked. So here's a PR where I convinced myself it was correct a couple of days ago, but the longer this sits, the less confident I'm going to be that there's not a mistake somewhere, especially if there are a lot of changes that need to be made to the code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9354
https://github.com/hail-is/hail/pull/9354:171,Deployability,update,updates,171,"Stacked on #9346 . Changes:; - infrastructure needed for kill switch; - UI page; - Default value for the limit is None. Testing:; - In the database migration, there's two updates that populate the initial state of the aggregated_billing_resources_table. I tested this by hand using a database that hadn't been migrated previously, but this might be good to double check.; - I ran the `check_resource_aggregation` loop while running `test_batch` and made sure there were no errors.; - I tested the UI page editing the limits with negative values and gibberish by hand to make sure those failed. I also refreshed the page to make sure the values were in the database and the update worked. So here's a PR where I convinced myself it was correct a couple of days ago, but the longer this sits, the less confident I'm going to be that there's not a mistake somewhere, especially if there are a lot of changes that need to be made to the code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9354
https://github.com/hail-is/hail/pull/9354:673,Deployability,update,update,673,"Stacked on #9346 . Changes:; - infrastructure needed for kill switch; - UI page; - Default value for the limit is None. Testing:; - In the database migration, there's two updates that populate the initial state of the aggregated_billing_resources_table. I tested this by hand using a database that hadn't been migrated previously, but this might be good to double check.; - I ran the `check_resource_aggregation` loop while running `test_batch` and made sure there were no errors.; - I tested the UI page editing the limits with negative values and gibberish by hand to make sure those failed. I also refreshed the page to make sure the values were in the database and the update worked. So here's a PR where I convinced myself it was correct a couple of days ago, but the longer this sits, the less confident I'm going to be that there's not a mistake somewhere, especially if there are a lot of changes that need to be made to the code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9354
https://github.com/hail-is/hail/pull/9354:120,Testability,Test,Testing,120,"Stacked on #9346 . Changes:; - infrastructure needed for kill switch; - UI page; - Default value for the limit is None. Testing:; - In the database migration, there's two updates that populate the initial state of the aggregated_billing_resources_table. I tested this by hand using a database that hadn't been migrated previously, but this might be good to double check.; - I ran the `check_resource_aggregation` loop while running `test_batch` and made sure there were no errors.; - I tested the UI page editing the limits with negative values and gibberish by hand to make sure those failed. I also refreshed the page to make sure the values were in the database and the update worked. So here's a PR where I convinced myself it was correct a couple of days ago, but the longer this sits, the less confident I'm going to be that there's not a mistake somewhere, especially if there are a lot of changes that need to be made to the code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9354
https://github.com/hail-is/hail/pull/9354:256,Testability,test,tested,256,"Stacked on #9346 . Changes:; - infrastructure needed for kill switch; - UI page; - Default value for the limit is None. Testing:; - In the database migration, there's two updates that populate the initial state of the aggregated_billing_resources_table. I tested this by hand using a database that hadn't been migrated previously, but this might be good to double check.; - I ran the `check_resource_aggregation` loop while running `test_batch` and made sure there were no errors.; - I tested the UI page editing the limits with negative values and gibberish by hand to make sure those failed. I also refreshed the page to make sure the values were in the database and the update worked. So here's a PR where I convinced myself it was correct a couple of days ago, but the longer this sits, the less confident I'm going to be that there's not a mistake somewhere, especially if there are a lot of changes that need to be made to the code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9354
https://github.com/hail-is/hail/pull/9354:486,Testability,test,tested,486,"Stacked on #9346 . Changes:; - infrastructure needed for kill switch; - UI page; - Default value for the limit is None. Testing:; - In the database migration, there's two updates that populate the initial state of the aggregated_billing_resources_table. I tested this by hand using a database that hadn't been migrated previously, but this might be good to double check.; - I ran the `check_resource_aggregation` loop while running `test_batch` and made sure there were no errors.; - I tested the UI page editing the limits with negative values and gibberish by hand to make sure those failed. I also refreshed the page to make sure the values were in the database and the update worked. So here's a PR where I convinced myself it was correct a couple of days ago, but the longer this sits, the less confident I'm going to be that there's not a mistake somewhere, especially if there are a lot of changes that need to be made to the code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9354
https://github.com/hail-is/hail/pull/9355:37,Testability,test,tests,37,Stacked on #9354. I'm happy with the tests here.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9355
https://github.com/hail-is/hail/pull/9360:70,Deployability,deploy,deploy,70,"Sorry, this is the same PR as #9241. I had to rebase on master to dev deploy efficiently. I added a test to the existing PR and fixed why my tables weren't being created with dev deploy. I also reduced the query size in the test scope by only querying 2 days. It only changed it from 10 MB scanned instead of 20+ MB scanned, but I figured that was better than nothing. The last commit from 35cf654 are the new changes. FYI: @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9360
https://github.com/hail-is/hail/pull/9360:179,Deployability,deploy,deploy,179,"Sorry, this is the same PR as #9241. I had to rebase on master to dev deploy efficiently. I added a test to the existing PR and fixed why my tables weren't being created with dev deploy. I also reduced the query size in the test scope by only querying 2 days. It only changed it from 10 MB scanned instead of 20+ MB scanned, but I figured that was better than nothing. The last commit from 35cf654 are the new changes. FYI: @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9360
https://github.com/hail-is/hail/pull/9360:77,Energy Efficiency,efficient,efficiently,77,"Sorry, this is the same PR as #9241. I had to rebase on master to dev deploy efficiently. I added a test to the existing PR and fixed why my tables weren't being created with dev deploy. I also reduced the query size in the test scope by only querying 2 days. It only changed it from 10 MB scanned instead of 20+ MB scanned, but I figured that was better than nothing. The last commit from 35cf654 are the new changes. FYI: @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9360
https://github.com/hail-is/hail/pull/9360:194,Energy Efficiency,reduce,reduced,194,"Sorry, this is the same PR as #9241. I had to rebase on master to dev deploy efficiently. I added a test to the existing PR and fixed why my tables weren't being created with dev deploy. I also reduced the query size in the test scope by only querying 2 days. It only changed it from 10 MB scanned instead of 20+ MB scanned, but I figured that was better than nothing. The last commit from 35cf654 are the new changes. FYI: @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9360
https://github.com/hail-is/hail/pull/9360:100,Testability,test,test,100,"Sorry, this is the same PR as #9241. I had to rebase on master to dev deploy efficiently. I added a test to the existing PR and fixed why my tables weren't being created with dev deploy. I also reduced the query size in the test scope by only querying 2 days. It only changed it from 10 MB scanned instead of 20+ MB scanned, but I figured that was better than nothing. The last commit from 35cf654 are the new changes. FYI: @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9360
https://github.com/hail-is/hail/pull/9360:224,Testability,test,test,224,"Sorry, this is the same PR as #9241. I had to rebase on master to dev deploy efficiently. I added a test to the existing PR and fixed why my tables weren't being created with dev deploy. I also reduced the query size in the test scope by only querying 2 days. It only changed it from 10 MB scanned instead of 20+ MB scanned, but I figured that was better than nothing. The last commit from 35cf654 are the new changes. FYI: @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9360
https://github.com/hail-is/hail/pull/9362:8,Deployability,deploy,deployed,8,Already deployed,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9362
https://github.com/hail-is/hail/pull/9371:21,Testability,log,logic,21,"This streamlines the logic significantly. No attempt has been made to have the encoder methods take; PCode/EmitCode directly, but that is the future direction here.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9371
https://github.com/hail-is/hail/pull/9373:267,Safety,avoid,avoid,267,"The current `filter_rows` is implemented as a transpose. Nik and Konrad are running into driver memory issues when doing `tree_matmul`, and one theory of mine is that making lots of `BlockMatrixTransposeRDD`'s is contributing to this. I'd like to make this change to avoid that in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9373
https://github.com/hail-is/hail/pull/9375:107,Deployability,deploy,deploy,107,- New job only runs after test_batch because I don't want to spin up everything when running this with dev deploy; - Only run in test and dev (not deploy),MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9375
https://github.com/hail-is/hail/pull/9375:147,Deployability,deploy,deploy,147,- New job only runs after test_batch because I don't want to spin up everything when running this with dev deploy; - Only run in test and dev (not deploy),MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9375
https://github.com/hail-is/hail/pull/9375:129,Testability,test,test,129,- New job only runs after test_batch because I don't want to spin up everything when running this with dev deploy; - Only run in test and dev (not deploy),MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9375
https://github.com/hail-is/hail/pull/9376:37,Testability,test,tests,37,"We want to eventually run all of our tests with the checked memory allocator, plus a few representative tests with the regular allocator. This PR switches the Java tests to the checked memory allocator, while the python tests remain on the normal allocator. I'll follow up to deal with the Python tests, but wanted to get a start in here to at least make sure some CI tests are exercising each allocator.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9376
https://github.com/hail-is/hail/pull/9376:104,Testability,test,tests,104,"We want to eventually run all of our tests with the checked memory allocator, plus a few representative tests with the regular allocator. This PR switches the Java tests to the checked memory allocator, while the python tests remain on the normal allocator. I'll follow up to deal with the Python tests, but wanted to get a start in here to at least make sure some CI tests are exercising each allocator.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9376
https://github.com/hail-is/hail/pull/9376:164,Testability,test,tests,164,"We want to eventually run all of our tests with the checked memory allocator, plus a few representative tests with the regular allocator. This PR switches the Java tests to the checked memory allocator, while the python tests remain on the normal allocator. I'll follow up to deal with the Python tests, but wanted to get a start in here to at least make sure some CI tests are exercising each allocator.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9376
https://github.com/hail-is/hail/pull/9376:220,Testability,test,tests,220,"We want to eventually run all of our tests with the checked memory allocator, plus a few representative tests with the regular allocator. This PR switches the Java tests to the checked memory allocator, while the python tests remain on the normal allocator. I'll follow up to deal with the Python tests, but wanted to get a start in here to at least make sure some CI tests are exercising each allocator.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9376
https://github.com/hail-is/hail/pull/9376:297,Testability,test,tests,297,"We want to eventually run all of our tests with the checked memory allocator, plus a few representative tests with the regular allocator. This PR switches the Java tests to the checked memory allocator, while the python tests remain on the normal allocator. I'll follow up to deal with the Python tests, but wanted to get a start in here to at least make sure some CI tests are exercising each allocator.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9376
https://github.com/hail-is/hail/pull/9376:368,Testability,test,tests,368,"We want to eventually run all of our tests with the checked memory allocator, plus a few representative tests with the regular allocator. This PR switches the Java tests to the checked memory allocator, while the python tests remain on the normal allocator. I'll follow up to deal with the Python tests, but wanted to get a start in here to at least make sure some CI tests are exercising each allocator.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9376
https://github.com/hail-is/hail/pull/9377:183,Deployability,update,update,183,"I misunderstood the issue originally. The exit status was set *in the sub-shell*, so; it did not affect the parent shell's environment. Instead, I run the command in; a sub-shell and update the variable in the parent shell. I also had to fix the issues that arose while the check wasn't honored.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9377
https://github.com/hail-is/hail/pull/9377:194,Modifiability,variab,variable,194,"I misunderstood the issue originally. The exit status was set *in the sub-shell*, so; it did not affect the parent shell's environment. Instead, I run the command in; a sub-shell and update the variable in the parent shell. I also had to fix the issues that arose while the check wasn't honored.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9377
https://github.com/hail-is/hail/pull/9378:68,Availability,down,down,68,"It is possible for socket connect to fail if the shuffle service is down (e.g. https://ci.hail.is/batches/91027/jobs/105).; This change ensure we retry forever, periodically logging that we are retrying",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9378
https://github.com/hail-is/hail/pull/9378:174,Testability,log,logging,174,"It is possible for socket connect to fail if the shuffle service is down (e.g. https://ci.hail.is/batches/91027/jobs/105).; This change ensure we retry forever, periodically logging that we are retrying",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9378
https://github.com/hail-is/hail/pull/9380:523,Integrability,bridg,bridges,523,"User jobs should not have access to our internal network. This enforces that; requirement. Every job spec now has a `network` argument which can be unset,; null, `public`, or `private`. If `private`, the job has access to our internal; network. Both unset and null default to the `public` network. Only the ci user is permitted to create non-`public` network jobs. I define the; networks using Docker and `iptables`. First I create two distinct docker; networks `public` and `private`. These correspond to virtual Ethernet bridges. A; virtual bridge may be connected to many virtual interfaces. Each docker; container is given a virtual interface. The `public` virtual bridge is severely limited. All traffic originating from; the public bridge destined for any of the [three private; subnets](https://en.wikipedia.org/wiki/Private_network#Private_IPv4_addresses); is dropped. Perhaps most importantly, packets destined for other containers on the same host; are dropped. I tested this manually using a Linux VM with Docker. testing it in; the wild is a little tricky! I have no way to ensure a pair of containers end up; on the same VM in a test environment. I did add tests for connecting to `localhost`, `127.0.0.1`, and one's own; IP. Note that one's own IP is the IP of a container, so you might naively think; it should be dropped by the aforementioned rules. However, packets destined for; the container's own IP are never sent to the virtual bridge, the container knows; its own IP and simply routes the packets to itself. I found [this website](https://rancher.com/learning-paths/introduction-to-container-networking/) helpful for understanding Docker networking.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9380
https://github.com/hail-is/hail/pull/9380:543,Integrability,bridg,bridge,543,"User jobs should not have access to our internal network. This enforces that; requirement. Every job spec now has a `network` argument which can be unset,; null, `public`, or `private`. If `private`, the job has access to our internal; network. Both unset and null default to the `public` network. Only the ci user is permitted to create non-`public` network jobs. I define the; networks using Docker and `iptables`. First I create two distinct docker; networks `public` and `private`. These correspond to virtual Ethernet bridges. A; virtual bridge may be connected to many virtual interfaces. Each docker; container is given a virtual interface. The `public` virtual bridge is severely limited. All traffic originating from; the public bridge destined for any of the [three private; subnets](https://en.wikipedia.org/wiki/Private_network#Private_IPv4_addresses); is dropped. Perhaps most importantly, packets destined for other containers on the same host; are dropped. I tested this manually using a Linux VM with Docker. testing it in; the wild is a little tricky! I have no way to ensure a pair of containers end up; on the same VM in a test environment. I did add tests for connecting to `localhost`, `127.0.0.1`, and one's own; IP. Note that one's own IP is the IP of a container, so you might naively think; it should be dropped by the aforementioned rules. However, packets destined for; the container's own IP are never sent to the virtual bridge, the container knows; its own IP and simply routes the packets to itself. I found [this website](https://rancher.com/learning-paths/introduction-to-container-networking/) helpful for understanding Docker networking.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9380
https://github.com/hail-is/hail/pull/9380:583,Integrability,interface,interfaces,583,"User jobs should not have access to our internal network. This enforces that; requirement. Every job spec now has a `network` argument which can be unset,; null, `public`, or `private`. If `private`, the job has access to our internal; network. Both unset and null default to the `public` network. Only the ci user is permitted to create non-`public` network jobs. I define the; networks using Docker and `iptables`. First I create two distinct docker; networks `public` and `private`. These correspond to virtual Ethernet bridges. A; virtual bridge may be connected to many virtual interfaces. Each docker; container is given a virtual interface. The `public` virtual bridge is severely limited. All traffic originating from; the public bridge destined for any of the [three private; subnets](https://en.wikipedia.org/wiki/Private_network#Private_IPv4_addresses); is dropped. Perhaps most importantly, packets destined for other containers on the same host; are dropped. I tested this manually using a Linux VM with Docker. testing it in; the wild is a little tricky! I have no way to ensure a pair of containers end up; on the same VM in a test environment. I did add tests for connecting to `localhost`, `127.0.0.1`, and one's own; IP. Note that one's own IP is the IP of a container, so you might naively think; it should be dropped by the aforementioned rules. However, packets destined for; the container's own IP are never sent to the virtual bridge, the container knows; its own IP and simply routes the packets to itself. I found [this website](https://rancher.com/learning-paths/introduction-to-container-networking/) helpful for understanding Docker networking.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9380
https://github.com/hail-is/hail/pull/9380:637,Integrability,interface,interface,637,"User jobs should not have access to our internal network. This enforces that; requirement. Every job spec now has a `network` argument which can be unset,; null, `public`, or `private`. If `private`, the job has access to our internal; network. Both unset and null default to the `public` network. Only the ci user is permitted to create non-`public` network jobs. I define the; networks using Docker and `iptables`. First I create two distinct docker; networks `public` and `private`. These correspond to virtual Ethernet bridges. A; virtual bridge may be connected to many virtual interfaces. Each docker; container is given a virtual interface. The `public` virtual bridge is severely limited. All traffic originating from; the public bridge destined for any of the [three private; subnets](https://en.wikipedia.org/wiki/Private_network#Private_IPv4_addresses); is dropped. Perhaps most importantly, packets destined for other containers on the same host; are dropped. I tested this manually using a Linux VM with Docker. testing it in; the wild is a little tricky! I have no way to ensure a pair of containers end up; on the same VM in a test environment. I did add tests for connecting to `localhost`, `127.0.0.1`, and one's own; IP. Note that one's own IP is the IP of a container, so you might naively think; it should be dropped by the aforementioned rules. However, packets destined for; the container's own IP are never sent to the virtual bridge, the container knows; its own IP and simply routes the packets to itself. I found [this website](https://rancher.com/learning-paths/introduction-to-container-networking/) helpful for understanding Docker networking.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9380
https://github.com/hail-is/hail/pull/9380:669,Integrability,bridg,bridge,669,"User jobs should not have access to our internal network. This enforces that; requirement. Every job spec now has a `network` argument which can be unset,; null, `public`, or `private`. If `private`, the job has access to our internal; network. Both unset and null default to the `public` network. Only the ci user is permitted to create non-`public` network jobs. I define the; networks using Docker and `iptables`. First I create two distinct docker; networks `public` and `private`. These correspond to virtual Ethernet bridges. A; virtual bridge may be connected to many virtual interfaces. Each docker; container is given a virtual interface. The `public` virtual bridge is severely limited. All traffic originating from; the public bridge destined for any of the [three private; subnets](https://en.wikipedia.org/wiki/Private_network#Private_IPv4_addresses); is dropped. Perhaps most importantly, packets destined for other containers on the same host; are dropped. I tested this manually using a Linux VM with Docker. testing it in; the wild is a little tricky! I have no way to ensure a pair of containers end up; on the same VM in a test environment. I did add tests for connecting to `localhost`, `127.0.0.1`, and one's own; IP. Note that one's own IP is the IP of a container, so you might naively think; it should be dropped by the aforementioned rules. However, packets destined for; the container's own IP are never sent to the virtual bridge, the container knows; its own IP and simply routes the packets to itself. I found [this website](https://rancher.com/learning-paths/introduction-to-container-networking/) helpful for understanding Docker networking.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9380
https://github.com/hail-is/hail/pull/9380:738,Integrability,bridg,bridge,738,"User jobs should not have access to our internal network. This enforces that; requirement. Every job spec now has a `network` argument which can be unset,; null, `public`, or `private`. If `private`, the job has access to our internal; network. Both unset and null default to the `public` network. Only the ci user is permitted to create non-`public` network jobs. I define the; networks using Docker and `iptables`. First I create two distinct docker; networks `public` and `private`. These correspond to virtual Ethernet bridges. A; virtual bridge may be connected to many virtual interfaces. Each docker; container is given a virtual interface. The `public` virtual bridge is severely limited. All traffic originating from; the public bridge destined for any of the [three private; subnets](https://en.wikipedia.org/wiki/Private_network#Private_IPv4_addresses); is dropped. Perhaps most importantly, packets destined for other containers on the same host; are dropped. I tested this manually using a Linux VM with Docker. testing it in; the wild is a little tricky! I have no way to ensure a pair of containers end up; on the same VM in a test environment. I did add tests for connecting to `localhost`, `127.0.0.1`, and one's own; IP. Note that one's own IP is the IP of a container, so you might naively think; it should be dropped by the aforementioned rules. However, packets destined for; the container's own IP are never sent to the virtual bridge, the container knows; its own IP and simply routes the packets to itself. I found [this website](https://rancher.com/learning-paths/introduction-to-container-networking/) helpful for understanding Docker networking.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9380
https://github.com/hail-is/hail/pull/9380:1450,Integrability,bridg,bridge,1450,"User jobs should not have access to our internal network. This enforces that; requirement. Every job spec now has a `network` argument which can be unset,; null, `public`, or `private`. If `private`, the job has access to our internal; network. Both unset and null default to the `public` network. Only the ci user is permitted to create non-`public` network jobs. I define the; networks using Docker and `iptables`. First I create two distinct docker; networks `public` and `private`. These correspond to virtual Ethernet bridges. A; virtual bridge may be connected to many virtual interfaces. Each docker; container is given a virtual interface. The `public` virtual bridge is severely limited. All traffic originating from; the public bridge destined for any of the [three private; subnets](https://en.wikipedia.org/wiki/Private_network#Private_IPv4_addresses); is dropped. Perhaps most importantly, packets destined for other containers on the same host; are dropped. I tested this manually using a Linux VM with Docker. testing it in; the wild is a little tricky! I have no way to ensure a pair of containers end up; on the same VM in a test environment. I did add tests for connecting to `localhost`, `127.0.0.1`, and one's own; IP. Note that one's own IP is the IP of a container, so you might naively think; it should be dropped by the aforementioned rules. However, packets destined for; the container's own IP are never sent to the virtual bridge, the container knows; its own IP and simply routes the packets to itself. I found [this website](https://rancher.com/learning-paths/introduction-to-container-networking/) helpful for understanding Docker networking.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9380
https://github.com/hail-is/hail/pull/9380:1501,Integrability,rout,routes,1501,"User jobs should not have access to our internal network. This enforces that; requirement. Every job spec now has a `network` argument which can be unset,; null, `public`, or `private`. If `private`, the job has access to our internal; network. Both unset and null default to the `public` network. Only the ci user is permitted to create non-`public` network jobs. I define the; networks using Docker and `iptables`. First I create two distinct docker; networks `public` and `private`. These correspond to virtual Ethernet bridges. A; virtual bridge may be connected to many virtual interfaces. Each docker; container is given a virtual interface. The `public` virtual bridge is severely limited. All traffic originating from; the public bridge destined for any of the [three private; subnets](https://en.wikipedia.org/wiki/Private_network#Private_IPv4_addresses); is dropped. Perhaps most importantly, packets destined for other containers on the same host; are dropped. I tested this manually using a Linux VM with Docker. testing it in; the wild is a little tricky! I have no way to ensure a pair of containers end up; on the same VM in a test environment. I did add tests for connecting to `localhost`, `127.0.0.1`, and one's own; IP. Note that one's own IP is the IP of a container, so you might naively think; it should be dropped by the aforementioned rules. However, packets destined for; the container's own IP are never sent to the virtual bridge, the container knows; its own IP and simply routes the packets to itself. I found [this website](https://rancher.com/learning-paths/introduction-to-container-networking/) helpful for understanding Docker networking.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9380
https://github.com/hail-is/hail/pull/9380:26,Security,access,access,26,"User jobs should not have access to our internal network. This enforces that; requirement. Every job spec now has a `network` argument which can be unset,; null, `public`, or `private`. If `private`, the job has access to our internal; network. Both unset and null default to the `public` network. Only the ci user is permitted to create non-`public` network jobs. I define the; networks using Docker and `iptables`. First I create two distinct docker; networks `public` and `private`. These correspond to virtual Ethernet bridges. A; virtual bridge may be connected to many virtual interfaces. Each docker; container is given a virtual interface. The `public` virtual bridge is severely limited. All traffic originating from; the public bridge destined for any of the [three private; subnets](https://en.wikipedia.org/wiki/Private_network#Private_IPv4_addresses); is dropped. Perhaps most importantly, packets destined for other containers on the same host; are dropped. I tested this manually using a Linux VM with Docker. testing it in; the wild is a little tricky! I have no way to ensure a pair of containers end up; on the same VM in a test environment. I did add tests for connecting to `localhost`, `127.0.0.1`, and one's own; IP. Note that one's own IP is the IP of a container, so you might naively think; it should be dropped by the aforementioned rules. However, packets destined for; the container's own IP are never sent to the virtual bridge, the container knows; its own IP and simply routes the packets to itself. I found [this website](https://rancher.com/learning-paths/introduction-to-container-networking/) helpful for understanding Docker networking.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9380
https://github.com/hail-is/hail/pull/9380:212,Security,access,access,212,"User jobs should not have access to our internal network. This enforces that; requirement. Every job spec now has a `network` argument which can be unset,; null, `public`, or `private`. If `private`, the job has access to our internal; network. Both unset and null default to the `public` network. Only the ci user is permitted to create non-`public` network jobs. I define the; networks using Docker and `iptables`. First I create two distinct docker; networks `public` and `private`. These correspond to virtual Ethernet bridges. A; virtual bridge may be connected to many virtual interfaces. Each docker; container is given a virtual interface. The `public` virtual bridge is severely limited. All traffic originating from; the public bridge destined for any of the [three private; subnets](https://en.wikipedia.org/wiki/Private_network#Private_IPv4_addresses); is dropped. Perhaps most importantly, packets destined for other containers on the same host; are dropped. I tested this manually using a Linux VM with Docker. testing it in; the wild is a little tricky! I have no way to ensure a pair of containers end up; on the same VM in a test environment. I did add tests for connecting to `localhost`, `127.0.0.1`, and one's own; IP. Note that one's own IP is the IP of a container, so you might naively think; it should be dropped by the aforementioned rules. However, packets destined for; the container's own IP are never sent to the virtual bridge, the container knows; its own IP and simply routes the packets to itself. I found [this website](https://rancher.com/learning-paths/introduction-to-container-networking/) helpful for understanding Docker networking.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9380
https://github.com/hail-is/hail/pull/9380:974,Testability,test,tested,974,"User jobs should not have access to our internal network. This enforces that; requirement. Every job spec now has a `network` argument which can be unset,; null, `public`, or `private`. If `private`, the job has access to our internal; network. Both unset and null default to the `public` network. Only the ci user is permitted to create non-`public` network jobs. I define the; networks using Docker and `iptables`. First I create two distinct docker; networks `public` and `private`. These correspond to virtual Ethernet bridges. A; virtual bridge may be connected to many virtual interfaces. Each docker; container is given a virtual interface. The `public` virtual bridge is severely limited. All traffic originating from; the public bridge destined for any of the [three private; subnets](https://en.wikipedia.org/wiki/Private_network#Private_IPv4_addresses); is dropped. Perhaps most importantly, packets destined for other containers on the same host; are dropped. I tested this manually using a Linux VM with Docker. testing it in; the wild is a little tricky! I have no way to ensure a pair of containers end up; on the same VM in a test environment. I did add tests for connecting to `localhost`, `127.0.0.1`, and one's own; IP. Note that one's own IP is the IP of a container, so you might naively think; it should be dropped by the aforementioned rules. However, packets destined for; the container's own IP are never sent to the virtual bridge, the container knows; its own IP and simply routes the packets to itself. I found [this website](https://rancher.com/learning-paths/introduction-to-container-networking/) helpful for understanding Docker networking.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9380
https://github.com/hail-is/hail/pull/9380:1025,Testability,test,testing,1025,"User jobs should not have access to our internal network. This enforces that; requirement. Every job spec now has a `network` argument which can be unset,; null, `public`, or `private`. If `private`, the job has access to our internal; network. Both unset and null default to the `public` network. Only the ci user is permitted to create non-`public` network jobs. I define the; networks using Docker and `iptables`. First I create two distinct docker; networks `public` and `private`. These correspond to virtual Ethernet bridges. A; virtual bridge may be connected to many virtual interfaces. Each docker; container is given a virtual interface. The `public` virtual bridge is severely limited. All traffic originating from; the public bridge destined for any of the [three private; subnets](https://en.wikipedia.org/wiki/Private_network#Private_IPv4_addresses); is dropped. Perhaps most importantly, packets destined for other containers on the same host; are dropped. I tested this manually using a Linux VM with Docker. testing it in; the wild is a little tricky! I have no way to ensure a pair of containers end up; on the same VM in a test environment. I did add tests for connecting to `localhost`, `127.0.0.1`, and one's own; IP. Note that one's own IP is the IP of a container, so you might naively think; it should be dropped by the aforementioned rules. However, packets destined for; the container's own IP are never sent to the virtual bridge, the container knows; its own IP and simply routes the packets to itself. I found [this website](https://rancher.com/learning-paths/introduction-to-container-networking/) helpful for understanding Docker networking.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9380
https://github.com/hail-is/hail/pull/9380:1142,Testability,test,test,1142,"User jobs should not have access to our internal network. This enforces that; requirement. Every job spec now has a `network` argument which can be unset,; null, `public`, or `private`. If `private`, the job has access to our internal; network. Both unset and null default to the `public` network. Only the ci user is permitted to create non-`public` network jobs. I define the; networks using Docker and `iptables`. First I create two distinct docker; networks `public` and `private`. These correspond to virtual Ethernet bridges. A; virtual bridge may be connected to many virtual interfaces. Each docker; container is given a virtual interface. The `public` virtual bridge is severely limited. All traffic originating from; the public bridge destined for any of the [three private; subnets](https://en.wikipedia.org/wiki/Private_network#Private_IPv4_addresses); is dropped. Perhaps most importantly, packets destined for other containers on the same host; are dropped. I tested this manually using a Linux VM with Docker. testing it in; the wild is a little tricky! I have no way to ensure a pair of containers end up; on the same VM in a test environment. I did add tests for connecting to `localhost`, `127.0.0.1`, and one's own; IP. Note that one's own IP is the IP of a container, so you might naively think; it should be dropped by the aforementioned rules. However, packets destined for; the container's own IP are never sent to the virtual bridge, the container knows; its own IP and simply routes the packets to itself. I found [this website](https://rancher.com/learning-paths/introduction-to-container-networking/) helpful for understanding Docker networking.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9380
https://github.com/hail-is/hail/pull/9380:1170,Testability,test,tests,1170,"User jobs should not have access to our internal network. This enforces that; requirement. Every job spec now has a `network` argument which can be unset,; null, `public`, or `private`. If `private`, the job has access to our internal; network. Both unset and null default to the `public` network. Only the ci user is permitted to create non-`public` network jobs. I define the; networks using Docker and `iptables`. First I create two distinct docker; networks `public` and `private`. These correspond to virtual Ethernet bridges. A; virtual bridge may be connected to many virtual interfaces. Each docker; container is given a virtual interface. The `public` virtual bridge is severely limited. All traffic originating from; the public bridge destined for any of the [three private; subnets](https://en.wikipedia.org/wiki/Private_network#Private_IPv4_addresses); is dropped. Perhaps most importantly, packets destined for other containers on the same host; are dropped. I tested this manually using a Linux VM with Docker. testing it in; the wild is a little tricky! I have no way to ensure a pair of containers end up; on the same VM in a test environment. I did add tests for connecting to `localhost`, `127.0.0.1`, and one's own; IP. Note that one's own IP is the IP of a container, so you might naively think; it should be dropped by the aforementioned rules. However, packets destined for; the container's own IP are never sent to the virtual bridge, the container knows; its own IP and simply routes the packets to itself. I found [this website](https://rancher.com/learning-paths/introduction-to-container-networking/) helpful for understanding Docker networking.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9380
https://github.com/hail-is/hail/pull/9380:1494,Usability,simpl,simply,1494,"User jobs should not have access to our internal network. This enforces that; requirement. Every job spec now has a `network` argument which can be unset,; null, `public`, or `private`. If `private`, the job has access to our internal; network. Both unset and null default to the `public` network. Only the ci user is permitted to create non-`public` network jobs. I define the; networks using Docker and `iptables`. First I create two distinct docker; networks `public` and `private`. These correspond to virtual Ethernet bridges. A; virtual bridge may be connected to many virtual interfaces. Each docker; container is given a virtual interface. The `public` virtual bridge is severely limited. All traffic originating from; the public bridge destined for any of the [three private; subnets](https://en.wikipedia.org/wiki/Private_network#Private_IPv4_addresses); is dropped. Perhaps most importantly, packets destined for other containers on the same host; are dropped. I tested this manually using a Linux VM with Docker. testing it in; the wild is a little tricky! I have no way to ensure a pair of containers end up; on the same VM in a test environment. I did add tests for connecting to `localhost`, `127.0.0.1`, and one's own; IP. Note that one's own IP is the IP of a container, so you might naively think; it should be dropped by the aforementioned rules. However, packets destined for; the container's own IP are never sent to the virtual bridge, the container knows; its own IP and simply routes the packets to itself. I found [this website](https://rancher.com/learning-paths/introduction-to-container-networking/) helpful for understanding Docker networking.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9380
https://github.com/hail-is/hail/pull/9380:1574,Usability,learn,learning-paths,1574,"User jobs should not have access to our internal network. This enforces that; requirement. Every job spec now has a `network` argument which can be unset,; null, `public`, or `private`. If `private`, the job has access to our internal; network. Both unset and null default to the `public` network. Only the ci user is permitted to create non-`public` network jobs. I define the; networks using Docker and `iptables`. First I create two distinct docker; networks `public` and `private`. These correspond to virtual Ethernet bridges. A; virtual bridge may be connected to many virtual interfaces. Each docker; container is given a virtual interface. The `public` virtual bridge is severely limited. All traffic originating from; the public bridge destined for any of the [three private; subnets](https://en.wikipedia.org/wiki/Private_network#Private_IPv4_addresses); is dropped. Perhaps most importantly, packets destined for other containers on the same host; are dropped. I tested this manually using a Linux VM with Docker. testing it in; the wild is a little tricky! I have no way to ensure a pair of containers end up; on the same VM in a test environment. I did add tests for connecting to `localhost`, `127.0.0.1`, and one's own; IP. Note that one's own IP is the IP of a container, so you might naively think; it should be dropped by the aforementioned rules. However, packets destined for; the container's own IP are never sent to the virtual bridge, the container knows; its own IP and simply routes the packets to itself. I found [this website](https://rancher.com/learning-paths/introduction-to-container-networking/) helpful for understanding Docker networking.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9380
https://github.com/hail-is/hail/pull/9382:337,Deployability,integrat,integrating,337,"I'm not sure where these should live, but I wanted to move them off my laptop and into a place where people can access them, and the repo seems as good of a place as any. There are svgs for a bunch of icons in both blue and white, as well as high-ish resolution images of both versions of the logo and 32x32 icon pngs. I haven't started integrating them into website stuff yet, but I figured that raw images should have a central-ish place to live anyways. All of the images in the PR are as below:; ![all](https://user-images.githubusercontent.com/19789871/91755326-ece1d180-eb98-11ea-83ce-eec6b13ab18f.png)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9382
https://github.com/hail-is/hail/pull/9382:337,Integrability,integrat,integrating,337,"I'm not sure where these should live, but I wanted to move them off my laptop and into a place where people can access them, and the repo seems as good of a place as any. There are svgs for a bunch of icons in both blue and white, as well as high-ish resolution images of both versions of the logo and 32x32 icon pngs. I haven't started integrating them into website stuff yet, but I figured that raw images should have a central-ish place to live anyways. All of the images in the PR are as below:; ![all](https://user-images.githubusercontent.com/19789871/91755326-ece1d180-eb98-11ea-83ce-eec6b13ab18f.png)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9382
https://github.com/hail-is/hail/pull/9382:112,Security,access,access,112,"I'm not sure where these should live, but I wanted to move them off my laptop and into a place where people can access them, and the repo seems as good of a place as any. There are svgs for a bunch of icons in both blue and white, as well as high-ish resolution images of both versions of the logo and 32x32 icon pngs. I haven't started integrating them into website stuff yet, but I figured that raw images should have a central-ish place to live anyways. All of the images in the PR are as below:; ![all](https://user-images.githubusercontent.com/19789871/91755326-ece1d180-eb98-11ea-83ce-eec6b13ab18f.png)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9382
https://github.com/hail-is/hail/pull/9382:293,Testability,log,logo,293,"I'm not sure where these should live, but I wanted to move them off my laptop and into a place where people can access them, and the repo seems as good of a place as any. There are svgs for a bunch of icons in both blue and white, as well as high-ish resolution images of both versions of the logo and 32x32 icon pngs. I haven't started integrating them into website stuff yet, but I figured that raw images should have a central-ish place to live anyways. All of the images in the PR are as below:; ![all](https://user-images.githubusercontent.com/19789871/91755326-ece1d180-eb98-11ea-83ce-eec6b13ab18f.png)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9382
https://github.com/hail-is/hail/pull/9385:403,Testability,test,tests,403,"- I use a right join in the query so that if there are no users, the record['users'] ends up being None rather than [None].; - I decided that an arbitrary user should be able to see all the other users for billing projects they are on.; - I decided that a developer can see all billing projects. This is infrastructure that I figured was nice to have but also will make #9354 better so I can add proper tests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9385
https://github.com/hail-is/hail/pull/9386:0,Deployability,Release,Releases,0,"Releases version 0.2.56. Stacked on #9373, since I'm mainly releasing for performance improvements in #9363, #9373, and #9374.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9386
https://github.com/hail-is/hail/pull/9386:74,Performance,perform,performance,74,"Releases version 0.2.56. Stacked on #9373, since I'm mainly releasing for performance improvements in #9363, #9373, and #9374.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9386
https://github.com/hail-is/hail/pull/9388:466,Integrability,depend,depending,466,"This PR makes the following changes:; * Add a `separateRegions` flag to `PStream`.; * Add a `separateRegions` flag to the stream producer nodes `MakeStream`, `StreamRange`, and `ToStream`.; * Propogate `separateRegions` through all stream nodes in `InferPType`. The intended semantics is that if a stream's type has the `separateRegions` flag set, its consumer must pass it a region which gets cleared every element. If the flag is not set, there is no requirement; depending on context, the consumer may put every element in the same region, but is also allowed to use separate regions for each element. For example, in a zip, the elements of the zipped stream are put in separate regions iff at least one child stream requires separate regions; in that case, all children will get emitted with separate regions, whether they requested it or not. In this PR, the `separateRegions` flags are left unused. Eventually, stream consumers will inspect the flag on their child streams' types, and use that information to construct the appropriate `StagedRegion` to pass to `emitStream`. In implementing that, I did some refactoring of the `StagedRegion` design, which I separated out into a follow-up PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9388
https://github.com/hail-is/hail/pull/9388:1114,Modifiability,refactor,refactoring,1114,"This PR makes the following changes:; * Add a `separateRegions` flag to `PStream`.; * Add a `separateRegions` flag to the stream producer nodes `MakeStream`, `StreamRange`, and `ToStream`.; * Propogate `separateRegions` through all stream nodes in `InferPType`. The intended semantics is that if a stream's type has the `separateRegions` flag set, its consumer must pass it a region which gets cleared every element. If the flag is not set, there is no requirement; depending on context, the consumer may put every element in the same region, but is also allowed to use separate regions for each element. For example, in a zip, the elements of the zipped stream are put in separate regions iff at least one child stream requires separate regions; in that case, all children will get emitted with separate regions, whether they requested it or not. In this PR, the `separateRegions` flags are left unused. Eventually, stream consumers will inspect the flag on their child streams' types, and use that information to construct the appropriate `StagedRegion` to pass to `emitStream`. In implementing that, I did some refactoring of the `StagedRegion` design, which I separated out into a follow-up PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9388
https://github.com/hail-is/hail/pull/9388:394,Usability,clear,cleared,394,"This PR makes the following changes:; * Add a `separateRegions` flag to `PStream`.; * Add a `separateRegions` flag to the stream producer nodes `MakeStream`, `StreamRange`, and `ToStream`.; * Propogate `separateRegions` through all stream nodes in `InferPType`. The intended semantics is that if a stream's type has the `separateRegions` flag set, its consumer must pass it a region which gets cleared every element. If the flag is not set, there is no requirement; depending on context, the consumer may put every element in the same region, but is also allowed to use separate regions for each element. For example, in a zip, the elements of the zipped stream are put in separate regions iff at least one child stream requires separate regions; in that case, all children will get emitted with separate regions, whether they requested it or not. In this PR, the `separateRegions` flags are left unused. Eventually, stream consumers will inspect the flag on their child streams' types, and use that information to construct the appropriate `StagedRegion` to pass to `emitStream`. In implementing that, I did some refactoring of the `StagedRegion` design, which I separated out into a follow-up PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9388
https://github.com/hail-is/hail/pull/9389:138,Energy Efficiency,monitor,monitoring,138,"Fixes:. ```. async def test_billing_monitoring():; deploy_config = get_deploy_config(); monitoring_deploy_config_url = deploy_config.url('monitoring', '/api/v1alpha/billing'); headers = service_auth_headers(deploy_config, 'monitoring'); async with in_cluster_ssl_client_session(; raise_for_status=True,; timeout=aiohttp.ClientTimeout(total=60)) as session:; ; async def wait_forever():; data = None; while data is None:; resp = await utils.request_retry_transient_errors(; session, 'GET', f'{monitoring_deploy_config_url}', headers=headers); data = await resp.json(); await asyncio.sleep(5); return data; ; data = await asyncio.wait_for(wait_forever(), timeout=30 * 60); > assert data['cost_by_service'], str(data); E AssertionError: {'cost_by_service': [], 'compute_cost_breakdown': [], 'cost_by_sku_label': [], 'time_period_query': '09/2020'}; E assert []; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9389
https://github.com/hail-is/hail/pull/9389:223,Energy Efficiency,monitor,monitoring,223,"Fixes:. ```. async def test_billing_monitoring():; deploy_config = get_deploy_config(); monitoring_deploy_config_url = deploy_config.url('monitoring', '/api/v1alpha/billing'); headers = service_auth_headers(deploy_config, 'monitoring'); async with in_cluster_ssl_client_session(; raise_for_status=True,; timeout=aiohttp.ClientTimeout(total=60)) as session:; ; async def wait_forever():; data = None; while data is None:; resp = await utils.request_retry_transient_errors(; session, 'GET', f'{monitoring_deploy_config_url}', headers=headers); data = await resp.json(); await asyncio.sleep(5); return data; ; data = await asyncio.wait_for(wait_forever(), timeout=30 * 60); > assert data['cost_by_service'], str(data); E AssertionError: {'cost_by_service': [], 'compute_cost_breakdown': [], 'cost_by_sku_label': [], 'time_period_query': '09/2020'}; E assert []; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9389
https://github.com/hail-is/hail/pull/9389:304,Safety,timeout,timeout,304,"Fixes:. ```. async def test_billing_monitoring():; deploy_config = get_deploy_config(); monitoring_deploy_config_url = deploy_config.url('monitoring', '/api/v1alpha/billing'); headers = service_auth_headers(deploy_config, 'monitoring'); async with in_cluster_ssl_client_session(; raise_for_status=True,; timeout=aiohttp.ClientTimeout(total=60)) as session:; ; async def wait_forever():; data = None; while data is None:; resp = await utils.request_retry_transient_errors(; session, 'GET', f'{monitoring_deploy_config_url}', headers=headers); data = await resp.json(); await asyncio.sleep(5); return data; ; data = await asyncio.wait_for(wait_forever(), timeout=30 * 60); > assert data['cost_by_service'], str(data); E AssertionError: {'cost_by_service': [], 'compute_cost_breakdown': [], 'cost_by_sku_label': [], 'time_period_query': '09/2020'}; E assert []; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9389
https://github.com/hail-is/hail/pull/9389:653,Safety,timeout,timeout,653,"Fixes:. ```. async def test_billing_monitoring():; deploy_config = get_deploy_config(); monitoring_deploy_config_url = deploy_config.url('monitoring', '/api/v1alpha/billing'); headers = service_auth_headers(deploy_config, 'monitoring'); async with in_cluster_ssl_client_session(; raise_for_status=True,; timeout=aiohttp.ClientTimeout(total=60)) as session:; ; async def wait_forever():; data = None; while data is None:; resp = await utils.request_retry_transient_errors(; session, 'GET', f'{monitoring_deploy_config_url}', headers=headers); data = await resp.json(); await asyncio.sleep(5); return data; ; data = await asyncio.wait_for(wait_forever(), timeout=30 * 60); > assert data['cost_by_service'], str(data); E AssertionError: {'cost_by_service': [], 'compute_cost_breakdown': [], 'cost_by_sku_label': [], 'time_period_query': '09/2020'}; E assert []; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9389
https://github.com/hail-is/hail/pull/9389:673,Testability,assert,assert,673,"Fixes:. ```. async def test_billing_monitoring():; deploy_config = get_deploy_config(); monitoring_deploy_config_url = deploy_config.url('monitoring', '/api/v1alpha/billing'); headers = service_auth_headers(deploy_config, 'monitoring'); async with in_cluster_ssl_client_session(; raise_for_status=True,; timeout=aiohttp.ClientTimeout(total=60)) as session:; ; async def wait_forever():; data = None; while data is None:; resp = await utils.request_retry_transient_errors(; session, 'GET', f'{monitoring_deploy_config_url}', headers=headers); data = await resp.json(); await asyncio.sleep(5); return data; ; data = await asyncio.wait_for(wait_forever(), timeout=30 * 60); > assert data['cost_by_service'], str(data); E AssertionError: {'cost_by_service': [], 'compute_cost_breakdown': [], 'cost_by_sku_label': [], 'time_period_query': '09/2020'}; E assert []; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9389
https://github.com/hail-is/hail/pull/9389:718,Testability,Assert,AssertionError,718,"Fixes:. ```. async def test_billing_monitoring():; deploy_config = get_deploy_config(); monitoring_deploy_config_url = deploy_config.url('monitoring', '/api/v1alpha/billing'); headers = service_auth_headers(deploy_config, 'monitoring'); async with in_cluster_ssl_client_session(; raise_for_status=True,; timeout=aiohttp.ClientTimeout(total=60)) as session:; ; async def wait_forever():; data = None; while data is None:; resp = await utils.request_retry_transient_errors(; session, 'GET', f'{monitoring_deploy_config_url}', headers=headers); data = await resp.json(); await asyncio.sleep(5); return data; ; data = await asyncio.wait_for(wait_forever(), timeout=30 * 60); > assert data['cost_by_service'], str(data); E AssertionError: {'cost_by_service': [], 'compute_cost_breakdown': [], 'cost_by_sku_label': [], 'time_period_query': '09/2020'}; E assert []; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9389
https://github.com/hail-is/hail/pull/9389:848,Testability,assert,assert,848,"Fixes:. ```. async def test_billing_monitoring():; deploy_config = get_deploy_config(); monitoring_deploy_config_url = deploy_config.url('monitoring', '/api/v1alpha/billing'); headers = service_auth_headers(deploy_config, 'monitoring'); async with in_cluster_ssl_client_session(; raise_for_status=True,; timeout=aiohttp.ClientTimeout(total=60)) as session:; ; async def wait_forever():; data = None; while data is None:; resp = await utils.request_retry_transient_errors(; session, 'GET', f'{monitoring_deploy_config_url}', headers=headers); data = await resp.json(); await asyncio.sleep(5); return data; ; data = await asyncio.wait_for(wait_forever(), timeout=30 * 60); > assert data['cost_by_service'], str(data); E AssertionError: {'cost_by_service': [], 'compute_cost_breakdown': [], 'cost_by_sku_label': [], 'time_period_query': '09/2020'}; E assert []; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9389
https://github.com/hail-is/hail/pull/9390:109,Security,authenticat,authenticate,109,"I do not understand how this passed the PR tests, but this fix makes regenie not; use the metadata server to authenticate itself.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9390
https://github.com/hail-is/hail/pull/9390:43,Testability,test,tests,43,"I do not understand how this passed the PR tests, but this fix makes regenie not; use the metadata server to authenticate itself.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9390
https://github.com/hail-is/hail/pull/9396:88,Modifiability,config,config,88,"If these tests are being run, I can't find them. Also, rename incorrectly named gear => config in hailtop tests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9396
https://github.com/hail-is/hail/pull/9396:9,Testability,test,tests,9,"If these tests are being run, I can't find them. Also, rename incorrectly named gear => config in hailtop tests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9396
https://github.com/hail-is/hail/pull/9396:106,Testability,test,tests,106,"If these tests are being run, I can't find them. Also, rename incorrectly named gear => config in hailtop tests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9396
https://github.com/hail-is/hail/pull/9398:73,Availability,error,error-messages-idea,73,"This PR is based on discussion here: https://dev.hail.is/t/better-python-error-messages-idea/201/9 The intention is to create a system to give better error messages from python in a generic way. Tim's work in #7792 does a good job introducing behavior like this this specifically for `ArrayRef` nodes, but I want to add three things on top of that:. 1. I don't want to have to do as much custom per IR node work; 2. I don't want to send the entire python stack trace over py4j to scala for every node; 3. I don't want the user to see a Java stack trace in this scenarios. This first PR is a proof of concept that adds this behavior for the `Die` node, which will catch any errors generated by uses of `CaseBuilder.or_error`. Follow up PRs should change `ArrayRef` to work this way, as well as catch things like looking up a key in a dictionary but not finding it. In an ideal future, we'd bolt on some extra mechanism to give types to these errors, and we could throw a proper `IndexError` in the `ArrayRef` case or `KeyError` in the dictionary case. . It feels a little bit messy right now, open to suggestions. I don't love using `-1` as the ""no error"" situation, but I thought it was probably easier than dealing with optionals between python and scala. . To give an example of what it looks like, the error message for this script:. ```; import hail as hl. ht = hl.utils.range_table(10); ht = ht.annotate(foo = hl.nd.array([[1], [2], [3]])); ht = ht.annotate(bar = ht.foo[0:4, 12]); ht.collect(); ```. is. ```; Traceback (most recent call last):; File ""better_error_test.py"", line 6, in <module>; ht.collect(); File ""<decorator-gen-1103>"", line 2, in collect; File ""/Users/johnc/Code/hail/hail/python/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/johnc/Code/hail/hail/python/hail/table.py"", line 1903, in collect; return Env.backend().execute(e._ir); File ""/Users/johnc/Code/hail/hail/python/hail/backend/spark_backend.py"", line 325, in ex",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9398
https://github.com/hail-is/hail/pull/9398:150,Availability,error,error,150,"This PR is based on discussion here: https://dev.hail.is/t/better-python-error-messages-idea/201/9 The intention is to create a system to give better error messages from python in a generic way. Tim's work in #7792 does a good job introducing behavior like this this specifically for `ArrayRef` nodes, but I want to add three things on top of that:. 1. I don't want to have to do as much custom per IR node work; 2. I don't want to send the entire python stack trace over py4j to scala for every node; 3. I don't want the user to see a Java stack trace in this scenarios. This first PR is a proof of concept that adds this behavior for the `Die` node, which will catch any errors generated by uses of `CaseBuilder.or_error`. Follow up PRs should change `ArrayRef` to work this way, as well as catch things like looking up a key in a dictionary but not finding it. In an ideal future, we'd bolt on some extra mechanism to give types to these errors, and we could throw a proper `IndexError` in the `ArrayRef` case or `KeyError` in the dictionary case. . It feels a little bit messy right now, open to suggestions. I don't love using `-1` as the ""no error"" situation, but I thought it was probably easier than dealing with optionals between python and scala. . To give an example of what it looks like, the error message for this script:. ```; import hail as hl. ht = hl.utils.range_table(10); ht = ht.annotate(foo = hl.nd.array([[1], [2], [3]])); ht = ht.annotate(bar = ht.foo[0:4, 12]); ht.collect(); ```. is. ```; Traceback (most recent call last):; File ""better_error_test.py"", line 6, in <module>; ht.collect(); File ""<decorator-gen-1103>"", line 2, in collect; File ""/Users/johnc/Code/hail/hail/python/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/johnc/Code/hail/hail/python/hail/table.py"", line 1903, in collect; return Env.backend().execute(e._ir); File ""/Users/johnc/Code/hail/hail/python/hail/backend/spark_backend.py"", line 325, in ex",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9398
https://github.com/hail-is/hail/pull/9398:673,Availability,error,errors,673,"This PR is based on discussion here: https://dev.hail.is/t/better-python-error-messages-idea/201/9 The intention is to create a system to give better error messages from python in a generic way. Tim's work in #7792 does a good job introducing behavior like this this specifically for `ArrayRef` nodes, but I want to add three things on top of that:. 1. I don't want to have to do as much custom per IR node work; 2. I don't want to send the entire python stack trace over py4j to scala for every node; 3. I don't want the user to see a Java stack trace in this scenarios. This first PR is a proof of concept that adds this behavior for the `Die` node, which will catch any errors generated by uses of `CaseBuilder.or_error`. Follow up PRs should change `ArrayRef` to work this way, as well as catch things like looking up a key in a dictionary but not finding it. In an ideal future, we'd bolt on some extra mechanism to give types to these errors, and we could throw a proper `IndexError` in the `ArrayRef` case or `KeyError` in the dictionary case. . It feels a little bit messy right now, open to suggestions. I don't love using `-1` as the ""no error"" situation, but I thought it was probably easier than dealing with optionals between python and scala. . To give an example of what it looks like, the error message for this script:. ```; import hail as hl. ht = hl.utils.range_table(10); ht = ht.annotate(foo = hl.nd.array([[1], [2], [3]])); ht = ht.annotate(bar = ht.foo[0:4, 12]); ht.collect(); ```. is. ```; Traceback (most recent call last):; File ""better_error_test.py"", line 6, in <module>; ht.collect(); File ""<decorator-gen-1103>"", line 2, in collect; File ""/Users/johnc/Code/hail/hail/python/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/johnc/Code/hail/hail/python/hail/table.py"", line 1903, in collect; return Env.backend().execute(e._ir); File ""/Users/johnc/Code/hail/hail/python/hail/backend/spark_backend.py"", line 325, in ex",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9398
https://github.com/hail-is/hail/pull/9398:941,Availability,error,errors,941,"This PR is based on discussion here: https://dev.hail.is/t/better-python-error-messages-idea/201/9 The intention is to create a system to give better error messages from python in a generic way. Tim's work in #7792 does a good job introducing behavior like this this specifically for `ArrayRef` nodes, but I want to add three things on top of that:. 1. I don't want to have to do as much custom per IR node work; 2. I don't want to send the entire python stack trace over py4j to scala for every node; 3. I don't want the user to see a Java stack trace in this scenarios. This first PR is a proof of concept that adds this behavior for the `Die` node, which will catch any errors generated by uses of `CaseBuilder.or_error`. Follow up PRs should change `ArrayRef` to work this way, as well as catch things like looking up a key in a dictionary but not finding it. In an ideal future, we'd bolt on some extra mechanism to give types to these errors, and we could throw a proper `IndexError` in the `ArrayRef` case or `KeyError` in the dictionary case. . It feels a little bit messy right now, open to suggestions. I don't love using `-1` as the ""no error"" situation, but I thought it was probably easier than dealing with optionals between python and scala. . To give an example of what it looks like, the error message for this script:. ```; import hail as hl. ht = hl.utils.range_table(10); ht = ht.annotate(foo = hl.nd.array([[1], [2], [3]])); ht = ht.annotate(bar = ht.foo[0:4, 12]); ht.collect(); ```. is. ```; Traceback (most recent call last):; File ""better_error_test.py"", line 6, in <module>; ht.collect(); File ""<decorator-gen-1103>"", line 2, in collect; File ""/Users/johnc/Code/hail/hail/python/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/johnc/Code/hail/hail/python/hail/table.py"", line 1903, in collect; return Env.backend().execute(e._ir); File ""/Users/johnc/Code/hail/hail/python/hail/backend/spark_backend.py"", line 325, in ex",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9398
https://github.com/hail-is/hail/pull/9398:1148,Availability,error,error,1148,"neric way. Tim's work in #7792 does a good job introducing behavior like this this specifically for `ArrayRef` nodes, but I want to add three things on top of that:. 1. I don't want to have to do as much custom per IR node work; 2. I don't want to send the entire python stack trace over py4j to scala for every node; 3. I don't want the user to see a Java stack trace in this scenarios. This first PR is a proof of concept that adds this behavior for the `Die` node, which will catch any errors generated by uses of `CaseBuilder.or_error`. Follow up PRs should change `ArrayRef` to work this way, as well as catch things like looking up a key in a dictionary but not finding it. In an ideal future, we'd bolt on some extra mechanism to give types to these errors, and we could throw a proper `IndexError` in the `ArrayRef` case or `KeyError` in the dictionary case. . It feels a little bit messy right now, open to suggestions. I don't love using `-1` as the ""no error"" situation, but I thought it was probably easier than dealing with optionals between python and scala. . To give an example of what it looks like, the error message for this script:. ```; import hail as hl. ht = hl.utils.range_table(10); ht = ht.annotate(foo = hl.nd.array([[1], [2], [3]])); ht = ht.annotate(bar = ht.foo[0:4, 12]); ht.collect(); ```. is. ```; Traceback (most recent call last):; File ""better_error_test.py"", line 6, in <module>; ht.collect(); File ""<decorator-gen-1103>"", line 2, in collect; File ""/Users/johnc/Code/hail/hail/python/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/johnc/Code/hail/hail/python/hail/table.py"", line 1903, in collect; return Env.backend().execute(e._ir); File ""/Users/johnc/Code/hail/hail/python/hail/backend/spark_backend.py"", line 325, in execute; raise HailUserError(message_and_trace) from None; hail.utils.java.HailUserError: Error summary: HailException: Index 12 is out of bounds for axis 1 with size 1; ------------; H",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9398
https://github.com/hail-is/hail/pull/9398:1305,Availability,error,error,1305,"des, but I want to add three things on top of that:. 1. I don't want to have to do as much custom per IR node work; 2. I don't want to send the entire python stack trace over py4j to scala for every node; 3. I don't want the user to see a Java stack trace in this scenarios. This first PR is a proof of concept that adds this behavior for the `Die` node, which will catch any errors generated by uses of `CaseBuilder.or_error`. Follow up PRs should change `ArrayRef` to work this way, as well as catch things like looking up a key in a dictionary but not finding it. In an ideal future, we'd bolt on some extra mechanism to give types to these errors, and we could throw a proper `IndexError` in the `ArrayRef` case or `KeyError` in the dictionary case. . It feels a little bit messy right now, open to suggestions. I don't love using `-1` as the ""no error"" situation, but I thought it was probably easier than dealing with optionals between python and scala. . To give an example of what it looks like, the error message for this script:. ```; import hail as hl. ht = hl.utils.range_table(10); ht = ht.annotate(foo = hl.nd.array([[1], [2], [3]])); ht = ht.annotate(bar = ht.foo[0:4, 12]); ht.collect(); ```. is. ```; Traceback (most recent call last):; File ""better_error_test.py"", line 6, in <module>; ht.collect(); File ""<decorator-gen-1103>"", line 2, in collect; File ""/Users/johnc/Code/hail/hail/python/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/johnc/Code/hail/hail/python/hail/table.py"", line 1903, in collect; return Env.backend().execute(e._ir); File ""/Users/johnc/Code/hail/hail/python/hail/backend/spark_backend.py"", line 325, in execute; raise HailUserError(message_and_trace) from None; hail.utils.java.HailUserError: Error summary: HailException: Index 12 is out of bounds for axis 1 with size 1; ------------; Hail stack trace:; File ""better_error_test.py"", line 5, in <module>; ht = ht.annotate(bar = ht.foo[0:4, 12]). File",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9398
https://github.com/hail-is/hail/pull/9398:2089,Availability,Error,Error,2089," in a dictionary but not finding it. In an ideal future, we'd bolt on some extra mechanism to give types to these errors, and we could throw a proper `IndexError` in the `ArrayRef` case or `KeyError` in the dictionary case. . It feels a little bit messy right now, open to suggestions. I don't love using `-1` as the ""no error"" situation, but I thought it was probably easier than dealing with optionals between python and scala. . To give an example of what it looks like, the error message for this script:. ```; import hail as hl. ht = hl.utils.range_table(10); ht = ht.annotate(foo = hl.nd.array([[1], [2], [3]])); ht = ht.annotate(bar = ht.foo[0:4, 12]); ht.collect(); ```. is. ```; Traceback (most recent call last):; File ""better_error_test.py"", line 6, in <module>; ht.collect(); File ""<decorator-gen-1103>"", line 2, in collect; File ""/Users/johnc/Code/hail/hail/python/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/johnc/Code/hail/hail/python/hail/table.py"", line 1903, in collect; return Env.backend().execute(e._ir); File ""/Users/johnc/Code/hail/hail/python/hail/backend/spark_backend.py"", line 325, in execute; raise HailUserError(message_and_trace) from None; hail.utils.java.HailUserError: Error summary: HailException: Index 12 is out of bounds for axis 1 with size 1; ------------; Hail stack trace:; File ""better_error_test.py"", line 5, in <module>; ht = ht.annotate(bar = ht.foo[0:4, 12]). File ""<decorator-gen-707>"", line 2, in __getitem__. File ""/Users/johnc/Code/hail/hail/python/hail/expr/expressions/typed_expressions.py"", line 3709, in __getitem__; hl.str(""Index "") + hl.str(s) + hl.str(f"" is out of bounds for axis {i} with size "") + hl.str(dlen). File ""<decorator-gen-1299>"", line 2, in or_error. File ""/Users/johnc/Code/hail/hail/python/hail/expr/builders.py"", line 311, in or_error; die_ir.save_error_info(); ```. (Note that ndarray bounds checking internally uses a case builder, which is why this example works).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9398
https://github.com/hail-is/hail/pull/9398:79,Integrability,message,messages-idea,79,"This PR is based on discussion here: https://dev.hail.is/t/better-python-error-messages-idea/201/9 The intention is to create a system to give better error messages from python in a generic way. Tim's work in #7792 does a good job introducing behavior like this this specifically for `ArrayRef` nodes, but I want to add three things on top of that:. 1. I don't want to have to do as much custom per IR node work; 2. I don't want to send the entire python stack trace over py4j to scala for every node; 3. I don't want the user to see a Java stack trace in this scenarios. This first PR is a proof of concept that adds this behavior for the `Die` node, which will catch any errors generated by uses of `CaseBuilder.or_error`. Follow up PRs should change `ArrayRef` to work this way, as well as catch things like looking up a key in a dictionary but not finding it. In an ideal future, we'd bolt on some extra mechanism to give types to these errors, and we could throw a proper `IndexError` in the `ArrayRef` case or `KeyError` in the dictionary case. . It feels a little bit messy right now, open to suggestions. I don't love using `-1` as the ""no error"" situation, but I thought it was probably easier than dealing with optionals between python and scala. . To give an example of what it looks like, the error message for this script:. ```; import hail as hl. ht = hl.utils.range_table(10); ht = ht.annotate(foo = hl.nd.array([[1], [2], [3]])); ht = ht.annotate(bar = ht.foo[0:4, 12]); ht.collect(); ```. is. ```; Traceback (most recent call last):; File ""better_error_test.py"", line 6, in <module>; ht.collect(); File ""<decorator-gen-1103>"", line 2, in collect; File ""/Users/johnc/Code/hail/hail/python/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/johnc/Code/hail/hail/python/hail/table.py"", line 1903, in collect; return Env.backend().execute(e._ir); File ""/Users/johnc/Code/hail/hail/python/hail/backend/spark_backend.py"", line 325, in ex",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9398
https://github.com/hail-is/hail/pull/9398:156,Integrability,message,messages,156,"This PR is based on discussion here: https://dev.hail.is/t/better-python-error-messages-idea/201/9 The intention is to create a system to give better error messages from python in a generic way. Tim's work in #7792 does a good job introducing behavior like this this specifically for `ArrayRef` nodes, but I want to add three things on top of that:. 1. I don't want to have to do as much custom per IR node work; 2. I don't want to send the entire python stack trace over py4j to scala for every node; 3. I don't want the user to see a Java stack trace in this scenarios. This first PR is a proof of concept that adds this behavior for the `Die` node, which will catch any errors generated by uses of `CaseBuilder.or_error`. Follow up PRs should change `ArrayRef` to work this way, as well as catch things like looking up a key in a dictionary but not finding it. In an ideal future, we'd bolt on some extra mechanism to give types to these errors, and we could throw a proper `IndexError` in the `ArrayRef` case or `KeyError` in the dictionary case. . It feels a little bit messy right now, open to suggestions. I don't love using `-1` as the ""no error"" situation, but I thought it was probably easier than dealing with optionals between python and scala. . To give an example of what it looks like, the error message for this script:. ```; import hail as hl. ht = hl.utils.range_table(10); ht = ht.annotate(foo = hl.nd.array([[1], [2], [3]])); ht = ht.annotate(bar = ht.foo[0:4, 12]); ht.collect(); ```. is. ```; Traceback (most recent call last):; File ""better_error_test.py"", line 6, in <module>; ht.collect(); File ""<decorator-gen-1103>"", line 2, in collect; File ""/Users/johnc/Code/hail/hail/python/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/johnc/Code/hail/hail/python/hail/table.py"", line 1903, in collect; return Env.backend().execute(e._ir); File ""/Users/johnc/Code/hail/hail/python/hail/backend/spark_backend.py"", line 325, in ex",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9398
https://github.com/hail-is/hail/pull/9398:1311,Integrability,message,message,1311,"des, but I want to add three things on top of that:. 1. I don't want to have to do as much custom per IR node work; 2. I don't want to send the entire python stack trace over py4j to scala for every node; 3. I don't want the user to see a Java stack trace in this scenarios. This first PR is a proof of concept that adds this behavior for the `Die` node, which will catch any errors generated by uses of `CaseBuilder.or_error`. Follow up PRs should change `ArrayRef` to work this way, as well as catch things like looking up a key in a dictionary but not finding it. In an ideal future, we'd bolt on some extra mechanism to give types to these errors, and we could throw a proper `IndexError` in the `ArrayRef` case or `KeyError` in the dictionary case. . It feels a little bit messy right now, open to suggestions. I don't love using `-1` as the ""no error"" situation, but I thought it was probably easier than dealing with optionals between python and scala. . To give an example of what it looks like, the error message for this script:. ```; import hail as hl. ht = hl.utils.range_table(10); ht = ht.annotate(foo = hl.nd.array([[1], [2], [3]])); ht = ht.annotate(bar = ht.foo[0:4, 12]); ht.collect(); ```. is. ```; Traceback (most recent call last):; File ""better_error_test.py"", line 6, in <module>; ht.collect(); File ""<decorator-gen-1103>"", line 2, in collect; File ""/Users/johnc/Code/hail/hail/python/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/johnc/Code/hail/hail/python/hail/table.py"", line 1903, in collect; return Env.backend().execute(e._ir); File ""/Users/johnc/Code/hail/hail/python/hail/backend/spark_backend.py"", line 325, in execute; raise HailUserError(message_and_trace) from None; hail.utils.java.HailUserError: Error summary: HailException: Index 12 is out of bounds for axis 1 with size 1; ------------; Hail stack trace:; File ""better_error_test.py"", line 5, in <module>; ht = ht.annotate(bar = ht.foo[0:4, 12]). File",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9398
https://github.com/hail-is/hail/pull/9398:1744,Integrability,wrap,wrapper,1744,"ll as catch things like looking up a key in a dictionary but not finding it. In an ideal future, we'd bolt on some extra mechanism to give types to these errors, and we could throw a proper `IndexError` in the `ArrayRef` case or `KeyError` in the dictionary case. . It feels a little bit messy right now, open to suggestions. I don't love using `-1` as the ""no error"" situation, but I thought it was probably easier than dealing with optionals between python and scala. . To give an example of what it looks like, the error message for this script:. ```; import hail as hl. ht = hl.utils.range_table(10); ht = ht.annotate(foo = hl.nd.array([[1], [2], [3]])); ht = ht.annotate(bar = ht.foo[0:4, 12]); ht.collect(); ```. is. ```; Traceback (most recent call last):; File ""better_error_test.py"", line 6, in <module>; ht.collect(); File ""<decorator-gen-1103>"", line 2, in collect; File ""/Users/johnc/Code/hail/hail/python/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/johnc/Code/hail/hail/python/hail/table.py"", line 1903, in collect; return Env.backend().execute(e._ir); File ""/Users/johnc/Code/hail/hail/python/hail/backend/spark_backend.py"", line 325, in execute; raise HailUserError(message_and_trace) from None; hail.utils.java.HailUserError: Error summary: HailException: Index 12 is out of bounds for axis 1 with size 1; ------------; Hail stack trace:; File ""better_error_test.py"", line 5, in <module>; ht = ht.annotate(bar = ht.foo[0:4, 12]). File ""<decorator-gen-707>"", line 2, in __getitem__. File ""/Users/johnc/Code/hail/hail/python/hail/expr/expressions/typed_expressions.py"", line 3709, in __getitem__; hl.str(""Index "") + hl.str(s) + hl.str(f"" is out of bounds for axis {i} with size "") + hl.str(dlen). File ""<decorator-gen-1299>"", line 2, in or_error. File ""/Users/johnc/Code/hail/hail/python/hail/expr/builders.py"", line 311, in or_error; die_ir.save_error_info(); ```. (Note that ndarray bounds checking internally uses a case bu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9398
https://github.com/hail-is/hail/pull/9399:21,Testability,benchmark,benchmarks,21,I wanted to add some benchmarks to start tracking this. They take roughly 25 and 45 seconds respectively on my laptop currently,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9399
https://github.com/hail-is/hail/pull/9401:2642,Deployability,Update,Update,2642,"t, this happens at stream consumers, where the allocation strategy will be read off the PType of the stream. The full hierarchy is now:; * `StagedRegion` - The root class is the type for passing around unowned regions. Besides writing into the region, the method `asRoot` allows converting to a `RootStagedRegion` by specifying `allowAllocations`; * `ParentStagedRegion` - for passing around un-owned regions which allow creating child regions. Has a `allowSubregions` flag which encodes whether child regions are actually separate run-time regions.; * `ChildStagedRegion` - un-owned regions which know their parent, allowing methods like `copyToParent` and `createSiblingRegion`; * `OwnedStagedRegion` - owned regions are always children; adds methods like `free`, `clear`, `giveToParent`; * The concrete classes `RealOwnedStagedRegion` and `DummyOwnedStagedRegion`. These encode whether the parent region is real or dummy. They are intended to be private to the `StagedRegion` implementation. ### Update. At first, I restricted methods like `copyTo` and `giveTo` to copy/move to either a parent or sibling region. That is easy to verify correctness, but turned out to be too restrictive. I had been assuming an invariant that the `elementRegion` of a stream is always a direct child of the `outerRegion`. But this invariant is violated by some nested stream nodes like `StreamFlatMap` and `StreamGroupBy`. Take `StreamFlatMap`: the `outerRegion` of the inner stream should be the `eltRegion` of the outer stream, which is created and owned by the FlatMap code. But the `eltRegion` of the final flatMapped stream is passed in from the consumer, so is not a child of the inner stream's `outerRegion`. It is also possible for the `eltRegion` to be a descendant, but not child, of the `outerRegion`. To fix this, I had to relax the assertion on `copyTo`, `giveTo`, etc. Now the precondition is that the destination region is a subregion of the parent of the source, captured by the `<=` method: `dest <",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9401
https://github.com/hail-is/hail/pull/9401:3473,Testability,assert,assertion,3473,"gion` and `DummyOwnedStagedRegion`. These encode whether the parent region is real or dummy. They are intended to be private to the `StagedRegion` implementation. ### Update. At first, I restricted methods like `copyTo` and `giveTo` to copy/move to either a parent or sibling region. That is easy to verify correctness, but turned out to be too restrictive. I had been assuming an invariant that the `elementRegion` of a stream is always a direct child of the `outerRegion`. But this invariant is violated by some nested stream nodes like `StreamFlatMap` and `StreamGroupBy`. Take `StreamFlatMap`: the `outerRegion` of the inner stream should be the `eltRegion` of the outer stream, which is created and owned by the FlatMap code. But the `eltRegion` of the final flatMapped stream is passed in from the consumer, so is not a child of the inner stream's `outerRegion`. It is also possible for the `eltRegion` to be a descendant, but not child, of the `outerRegion`. To fix this, I had to relax the assertion on `copyTo`, `giveTo`, etc. Now the precondition is that the destination region is a subregion of the parent of the source, captured by the `<=` method: `dest <= this.parent`. Dynamically, `r1 <= r2` should mean that the lifetime of `r1` is nested inside that of `r2`. If `copyTo` actually copies, it is always correct, so consider the case where the source is a `DummyOwnedStagedRegion`, i.e. an alias of its parent. Then `copyTo` generates no code, and the ""copied"" data actually just points to the original data. For this to be valid for the lifetime of the destination region, we need exactly `dest <= this.parent`. Finally, to handle the `StreamFlatMap` case, we need a way to register a subregion relationship between two regions after both have been constructed. This is implemented by the `asSubregionOf` method, which adds to a list of `otherAncestors`, which are regions other than the parent which we assume have lifetimes containing that of `this` region. I also added an assertio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9401
https://github.com/hail-is/hail/pull/9401:4467,Testability,assert,assertion,4467,"gion is real or dummy. They are intended to be private to the `StagedRegion` implementation. ### Update. At first, I restricted methods like `copyTo` and `giveTo` to copy/move to either a parent or sibling region. That is easy to verify correctness, but turned out to be too restrictive. I had been assuming an invariant that the `elementRegion` of a stream is always a direct child of the `outerRegion`. But this invariant is violated by some nested stream nodes like `StreamFlatMap` and `StreamGroupBy`. Take `StreamFlatMap`: the `outerRegion` of the inner stream should be the `eltRegion` of the outer stream, which is created and owned by the FlatMap code. But the `eltRegion` of the final flatMapped stream is passed in from the consumer, so is not a child of the inner stream's `outerRegion`. It is also possible for the `eltRegion` to be a descendant, but not child, of the `outerRegion`. To fix this, I had to relax the assertion on `copyTo`, `giveTo`, etc. Now the precondition is that the destination region is a subregion of the parent of the source, captured by the `<=` method: `dest <= this.parent`. Dynamically, `r1 <= r2` should mean that the lifetime of `r1` is nested inside that of `r2`. If `copyTo` actually copies, it is always correct, so consider the case where the source is a `DummyOwnedStagedRegion`, i.e. an alias of its parent. Then `copyTo` generates no code, and the ""copied"" data actually just points to the original data. For this to be valid for the lifetime of the destination region, we need exactly `dest <= this.parent`. Finally, to handle the `StreamFlatMap` case, we need a way to register a subregion relationship between two regions after both have been constructed. This is implemented by the `asSubregionOf` method, which adds to a list of `otherAncestors`, which are regions other than the parent which we assume have lifetimes containing that of `this` region. I also added an assertion to verify that for every stream emitted, `eltRegion <= outerRegion`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9401
https://github.com/hail-is/hail/pull/9401:709,Usability,simpl,simplifies,709,"Stacked on #9400 . This PR modifies stream consumers' emit cases to look up `separateRegions` on the child stream's type, using that to construct the appropriate `StagedRegion`, then passing that region into `emitStream`. It also removes `EmitAllocationStrategy`, as this is now encoded in the IR. We may at some point want something similar to choose what allocation behavior to generate during lowering, but that is left for future work. Getting this to work well required some changes to the `StagedRegion` design. First, when a stream node needs to create a fresh region which it owns, the new region is now created as a child of the `outerRegion`, not the consumer's `eltRegion` as was done before. This simplifies the semantics of the parent/child relationship: now the lifetime of a child region is always nested inside that of its parent. The second change also has to do with the tree structure of `StagedRegion`s. Before, any `StagedRegion` could have children, which meant we could have arbitrarily deep trees of `StagedRegion`s, and also that every `StagedRegion` had to know whether children would be genuine sub-regions or just aliases of the parent. Now, the `StagedRegion` hierarchy is split into `ParentStagedRegion` and `ChildStagedRegion`. A `ParentStagedRegion` can have children, while a `ChildStagedRegion` cannot. The main effect of this is that the `allowAllocations` bit is no longer hereditary. A `ChildStagedRegion` can be converted into a `ParentStagedRegion`, and hence another generation of children can be created, but now doing so requires explicitly specifying `allowAllocations` for the new generation. In emit, this happens at stream consumers, where the allocation strategy will be read off the PType of the stream. The full hierarchy is now:; * `StagedRegion` - The root class is the type for passing around unowned regions. Besides writing into the region, the method `asRoot` allows converting to a `RootStagedRegion` by specifying `allowAllocations`; * `ParentS",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9401
https://github.com/hail-is/hail/pull/9401:2410,Usability,clear,clear,2410,"t of this is that the `allowAllocations` bit is no longer hereditary. A `ChildStagedRegion` can be converted into a `ParentStagedRegion`, and hence another generation of children can be created, but now doing so requires explicitly specifying `allowAllocations` for the new generation. In emit, this happens at stream consumers, where the allocation strategy will be read off the PType of the stream. The full hierarchy is now:; * `StagedRegion` - The root class is the type for passing around unowned regions. Besides writing into the region, the method `asRoot` allows converting to a `RootStagedRegion` by specifying `allowAllocations`; * `ParentStagedRegion` - for passing around un-owned regions which allow creating child regions. Has a `allowSubregions` flag which encodes whether child regions are actually separate run-time regions.; * `ChildStagedRegion` - un-owned regions which know their parent, allowing methods like `copyToParent` and `createSiblingRegion`; * `OwnedStagedRegion` - owned regions are always children; adds methods like `free`, `clear`, `giveToParent`; * The concrete classes `RealOwnedStagedRegion` and `DummyOwnedStagedRegion`. These encode whether the parent region is real or dummy. They are intended to be private to the `StagedRegion` implementation. ### Update. At first, I restricted methods like `copyTo` and `giveTo` to copy/move to either a parent or sibling region. That is easy to verify correctness, but turned out to be too restrictive. I had been assuming an invariant that the `elementRegion` of a stream is always a direct child of the `outerRegion`. But this invariant is violated by some nested stream nodes like `StreamFlatMap` and `StreamGroupBy`. Take `StreamFlatMap`: the `outerRegion` of the inner stream should be the `eltRegion` of the outer stream, which is created and owned by the FlatMap code. But the `eltRegion` of the final flatMapped stream is passed in from the consumer, so is not a child of the inner stream's `outerRegion`. It is a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9401
https://github.com/hail-is/hail/pull/9402:95,Modifiability,inherit,inherited,95,"We need to include the :members: directive in newer Sphinx versions. I also elided; hidden and inherited members for now, though we can add those back if we like.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9402
https://github.com/hail-is/hail/pull/9403:7,Availability,down,down,7,We are down to 164 docs failures and I am tired. I will work on it more another time. Then we will be able to enable nitpicky and our docs will never have broken links.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9403
https://github.com/hail-is/hail/pull/9403:24,Availability,failure,failures,24,We are down to 164 docs failures and I am tired. I will work on it more another time. Then we will be able to enable nitpicky and our docs will never have broken links.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9403
https://github.com/hail-is/hail/pull/9404:59,Availability,error,errors,59,I also added SocketException and SSLException as transient errors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9404
https://github.com/hail-is/hail/pull/9406:97,Deployability,deploy,deployed,97,"SQLConfig requires an `ssl_mode`, this prevents auth from creating Developer accounts. I already deployed this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9406
https://github.com/hail-is/hail/pull/9410:246,Availability,avail,available,246,"Updated db.py to allow user to specify region as shown below. `db = hl.experimental.DB(region='us')`; `mt = db.annotate_rows_db(mt, 'gnomad_lof_metrics')`. Data will be accessed from the requester pays bucket in the region specified by the user, available regions are `'us'` and `'eu'`. Modified the following to include region parameter:; - `DB` class ; - `Dataset.from_name_and_json()`. Added method `DatasetVersion.insert_region()` to replace `'{region}'` in `DatasetVersion.url` instance variable with the specified region.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9410
https://github.com/hail-is/hail/pull/9410:0,Deployability,Update,Updated,0,"Updated db.py to allow user to specify region as shown below. `db = hl.experimental.DB(region='us')`; `mt = db.annotate_rows_db(mt, 'gnomad_lof_metrics')`. Data will be accessed from the requester pays bucket in the region specified by the user, available regions are `'us'` and `'eu'`. Modified the following to include region parameter:; - `DB` class ; - `Dataset.from_name_and_json()`. Added method `DatasetVersion.insert_region()` to replace `'{region}'` in `DatasetVersion.url` instance variable with the specified region.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9410
https://github.com/hail-is/hail/pull/9410:492,Modifiability,variab,variable,492,"Updated db.py to allow user to specify region as shown below. `db = hl.experimental.DB(region='us')`; `mt = db.annotate_rows_db(mt, 'gnomad_lof_metrics')`. Data will be accessed from the requester pays bucket in the region specified by the user, available regions are `'us'` and `'eu'`. Modified the following to include region parameter:; - `DB` class ; - `Dataset.from_name_and_json()`. Added method `DatasetVersion.insert_region()` to replace `'{region}'` in `DatasetVersion.url` instance variable with the specified region.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9410
https://github.com/hail-is/hail/pull/9410:169,Security,access,accessed,169,"Updated db.py to allow user to specify region as shown below. `db = hl.experimental.DB(region='us')`; `mt = db.annotate_rows_db(mt, 'gnomad_lof_metrics')`. Data will be accessed from the requester pays bucket in the region specified by the user, available regions are `'us'` and `'eu'`. Modified the following to include region parameter:; - `DB` class ; - `Dataset.from_name_and_json()`. Added method `DatasetVersion.insert_region()` to replace `'{region}'` in `DatasetVersion.url` instance variable with the specified region.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9410
https://github.com/hail-is/hail/pull/9411:48,Modifiability,config,config,48,"Renamed and moved `datasets/annotation_db.json` config file to `hail/experimental/datasets.json` and modified urls in `dataset[path]` to use a region parameter to load datasets from bucket in the appropriate region. Modified `load_datasets()` function to no longer use the `config_file` parameter, and to require user to specify `region` parameter. The checked-in `hail/experimental/datasets.json` file will now be used as the config file.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9411
https://github.com/hail-is/hail/pull/9411:427,Modifiability,config,config,427,"Renamed and moved `datasets/annotation_db.json` config file to `hail/experimental/datasets.json` and modified urls in `dataset[path]` to use a region parameter to load datasets from bucket in the appropriate region. Modified `load_datasets()` function to no longer use the `config_file` parameter, and to require user to specify `region` parameter. The checked-in `hail/experimental/datasets.json` file will now be used as the config file.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9411
https://github.com/hail-is/hail/pull/9411:163,Performance,load,load,163,"Renamed and moved `datasets/annotation_db.json` config file to `hail/experimental/datasets.json` and modified urls in `dataset[path]` to use a region parameter to load datasets from bucket in the appropriate region. Modified `load_datasets()` function to no longer use the `config_file` parameter, and to require user to specify `region` parameter. The checked-in `hail/experimental/datasets.json` file will now be used as the config file.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9411
https://github.com/hail-is/hail/pull/9418:548,Availability,Error,Error,548,I don't think it is used anymore. Builds are failing because it is returning 500. > Unable to load Maven meta-data from https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml.; > Could not get resource 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'.; > Could not GET 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'. Received status code 500 from server: Server Error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9418
https://github.com/hail-is/hail/pull/9418:170,Deployability,release,releases,170,I don't think it is used anymore. Builds are failing because it is returning 500. > Unable to load Maven meta-data from https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml.; > Could not get resource 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'.; > Could not GET 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'. Received status code 500 from server: Server Error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9418
https://github.com/hail-is/hail/pull/9418:309,Deployability,release,releases,309,I don't think it is used anymore. Builds are failing because it is returning 500. > Unable to load Maven meta-data from https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml.; > Could not get resource 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'.; > Could not GET 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'. Received status code 500 from server: Server Error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9418
https://github.com/hail-is/hail/pull/9418:440,Deployability,release,releases,440,I don't think it is used anymore. Builds are failing because it is returning 500. > Unable to load Maven meta-data from https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml.; > Could not get resource 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'.; > Could not GET 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'. Received status code 500 from server: Server Error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9418
https://github.com/hail-is/hail/pull/9418:94,Performance,load,load,94,I don't think it is used anymore. Builds are failing because it is returning 500. > Unable to load Maven meta-data from https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml.; > Could not get resource 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'.; > Could not GET 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'. Received status code 500 from server: Server Error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9418
https://github.com/hail-is/hail/issues/9419:226,Availability,error,error,226,"I am using Hail 0.2.54. However, I also tested with the latest build.gradle file. I run the following make install command:; `make install HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.2`. However, I got this error message which did not appear before. ` > Could not resolve org.scalanlp:breeze-natives_2.11:+.; Required by:; project :; > Failed to list versions for org.scalanlp:breeze-natives_2.11.; > Unable to load Maven meta-data from https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml.; > Could not get resource 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'.; > Could not GET 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'. Received status code 500 from server: Server Error; * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.; * Get more help at https://help.gradle.org. BUILD FAILED in 29s; make: *** [build/libs/hail-all-spark.jar] Error 1`. It seems that is caused by https://repo.hortonworks.com/content/repositories/releases/ server is done.; I am wondering whether there is any maven substitute can be used temporarily to compile hail.jar?. Thanks in advance for your help.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9419
https://github.com/hail-is/hail/issues/9419:884,Availability,Error,Error,884,"I am using Hail 0.2.54. However, I also tested with the latest build.gradle file. I run the following make install command:; `make install HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.2`. However, I got this error message which did not appear before. ` > Could not resolve org.scalanlp:breeze-natives_2.11:+.; Required by:; project :; > Failed to list versions for org.scalanlp:breeze-natives_2.11.; > Unable to load Maven meta-data from https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml.; > Could not get resource 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'.; > Could not GET 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'. Received status code 500 from server: Server Error; * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.; * Get more help at https://help.gradle.org. BUILD FAILED in 29s; make: *** [build/libs/hail-all-spark.jar] Error 1`. It seems that is caused by https://repo.hortonworks.com/content/repositories/releases/ server is done.; I am wondering whether there is any maven substitute can be used temporarily to compile hail.jar?. Thanks in advance for your help.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9419
https://github.com/hail-is/hail/issues/9419:1156,Availability,Error,Error,1156,"I am using Hail 0.2.54. However, I also tested with the latest build.gradle file. I run the following make install command:; `make install HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.2`. However, I got this error message which did not appear before. ` > Could not resolve org.scalanlp:breeze-natives_2.11:+.; Required by:; project :; > Failed to list versions for org.scalanlp:breeze-natives_2.11.; > Unable to load Maven meta-data from https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml.; > Could not get resource 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'.; > Could not GET 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'. Received status code 500 from server: Server Error; * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.; * Get more help at https://help.gradle.org. BUILD FAILED in 29s; make: *** [build/libs/hail-all-spark.jar] Error 1`. It seems that is caused by https://repo.hortonworks.com/content/repositories/releases/ server is done.; I am wondering whether there is any maven substitute can be used temporarily to compile hail.jar?. Thanks in advance for your help.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9419
https://github.com/hail-is/hail/issues/9419:107,Deployability,install,install,107,"I am using Hail 0.2.54. However, I also tested with the latest build.gradle file. I run the following make install command:; `make install HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.2`. However, I got this error message which did not appear before. ` > Could not resolve org.scalanlp:breeze-natives_2.11:+.; Required by:; project :; > Failed to list versions for org.scalanlp:breeze-natives_2.11.; > Unable to load Maven meta-data from https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml.; > Could not get resource 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'.; > Could not GET 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'. Received status code 500 from server: Server Error; * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.; * Get more help at https://help.gradle.org. BUILD FAILED in 29s; make: *** [build/libs/hail-all-spark.jar] Error 1`. It seems that is caused by https://repo.hortonworks.com/content/repositories/releases/ server is done.; I am wondering whether there is any maven substitute can be used temporarily to compile hail.jar?. Thanks in advance for your help.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9419
https://github.com/hail-is/hail/issues/9419:131,Deployability,install,install,131,"I am using Hail 0.2.54. However, I also tested with the latest build.gradle file. I run the following make install command:; `make install HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.2`. However, I got this error message which did not appear before. ` > Could not resolve org.scalanlp:breeze-natives_2.11:+.; Required by:; project :; > Failed to list versions for org.scalanlp:breeze-natives_2.11.; > Unable to load Maven meta-data from https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml.; > Could not get resource 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'.; > Could not GET 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'. Received status code 500 from server: Server Error; * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.; * Get more help at https://help.gradle.org. BUILD FAILED in 29s; make: *** [build/libs/hail-all-spark.jar] Error 1`. It seems that is caused by https://repo.hortonworks.com/content/repositories/releases/ server is done.; I am wondering whether there is any maven substitute can be used temporarily to compile hail.jar?. Thanks in advance for your help.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9419
https://github.com/hail-is/hail/issues/9419:506,Deployability,release,releases,506,"I am using Hail 0.2.54. However, I also tested with the latest build.gradle file. I run the following make install command:; `make install HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.2`. However, I got this error message which did not appear before. ` > Could not resolve org.scalanlp:breeze-natives_2.11:+.; Required by:; project :; > Failed to list versions for org.scalanlp:breeze-natives_2.11.; > Unable to load Maven meta-data from https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml.; > Could not get resource 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'.; > Could not GET 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'. Received status code 500 from server: Server Error; * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.; * Get more help at https://help.gradle.org. BUILD FAILED in 29s; make: *** [build/libs/hail-all-spark.jar] Error 1`. It seems that is caused by https://repo.hortonworks.com/content/repositories/releases/ server is done.; I am wondering whether there is any maven substitute can be used temporarily to compile hail.jar?. Thanks in advance for your help.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9419
https://github.com/hail-is/hail/issues/9419:645,Deployability,release,releases,645,"I am using Hail 0.2.54. However, I also tested with the latest build.gradle file. I run the following make install command:; `make install HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.2`. However, I got this error message which did not appear before. ` > Could not resolve org.scalanlp:breeze-natives_2.11:+.; Required by:; project :; > Failed to list versions for org.scalanlp:breeze-natives_2.11.; > Unable to load Maven meta-data from https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml.; > Could not get resource 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'.; > Could not GET 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'. Received status code 500 from server: Server Error; * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.; * Get more help at https://help.gradle.org. BUILD FAILED in 29s; make: *** [build/libs/hail-all-spark.jar] Error 1`. It seems that is caused by https://repo.hortonworks.com/content/repositories/releases/ server is done.; I am wondering whether there is any maven substitute can be used temporarily to compile hail.jar?. Thanks in advance for your help.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9419
https://github.com/hail-is/hail/issues/9419:776,Deployability,release,releases,776,"I am using Hail 0.2.54. However, I also tested with the latest build.gradle file. I run the following make install command:; `make install HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.2`. However, I got this error message which did not appear before. ` > Could not resolve org.scalanlp:breeze-natives_2.11:+.; Required by:; project :; > Failed to list versions for org.scalanlp:breeze-natives_2.11.; > Unable to load Maven meta-data from https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml.; > Could not get resource 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'.; > Could not GET 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'. Received status code 500 from server: Server Error; * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.; * Get more help at https://help.gradle.org. BUILD FAILED in 29s; make: *** [build/libs/hail-all-spark.jar] Error 1`. It seems that is caused by https://repo.hortonworks.com/content/repositories/releases/ server is done.; I am wondering whether there is any maven substitute can be used temporarily to compile hail.jar?. Thanks in advance for your help.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9419
https://github.com/hail-is/hail/issues/9419:1243,Deployability,release,releases,1243,"I am using Hail 0.2.54. However, I also tested with the latest build.gradle file. I run the following make install command:; `make install HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.2`. However, I got this error message which did not appear before. ` > Could not resolve org.scalanlp:breeze-natives_2.11:+.; Required by:; project :; > Failed to list versions for org.scalanlp:breeze-natives_2.11.; > Unable to load Maven meta-data from https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml.; > Could not get resource 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'.; > Could not GET 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'. Received status code 500 from server: Server Error; * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.; * Get more help at https://help.gradle.org. BUILD FAILED in 29s; make: *** [build/libs/hail-all-spark.jar] Error 1`. It seems that is caused by https://repo.hortonworks.com/content/repositories/releases/ server is done.; I am wondering whether there is any maven substitute can be used temporarily to compile hail.jar?. Thanks in advance for your help.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9419
https://github.com/hail-is/hail/issues/9419:232,Integrability,message,message,232,"I am using Hail 0.2.54. However, I also tested with the latest build.gradle file. I run the following make install command:; `make install HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.2`. However, I got this error message which did not appear before. ` > Could not resolve org.scalanlp:breeze-natives_2.11:+.; Required by:; project :; > Failed to list versions for org.scalanlp:breeze-natives_2.11.; > Unable to load Maven meta-data from https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml.; > Could not get resource 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'.; > Could not GET 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'. Received status code 500 from server: Server Error; * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.; * Get more help at https://help.gradle.org. BUILD FAILED in 29s; make: *** [build/libs/hail-all-spark.jar] Error 1`. It seems that is caused by https://repo.hortonworks.com/content/repositories/releases/ server is done.; I am wondering whether there is any maven substitute can be used temporarily to compile hail.jar?. Thanks in advance for your help.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9419
https://github.com/hail-is/hail/issues/9419:430,Performance,load,load,430,"I am using Hail 0.2.54. However, I also tested with the latest build.gradle file. I run the following make install command:; `make install HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.2`. However, I got this error message which did not appear before. ` > Could not resolve org.scalanlp:breeze-natives_2.11:+.; Required by:; project :; > Failed to list versions for org.scalanlp:breeze-natives_2.11.; > Unable to load Maven meta-data from https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml.; > Could not get resource 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'.; > Could not GET 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'. Received status code 500 from server: Server Error; * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.; * Get more help at https://help.gradle.org. BUILD FAILED in 29s; make: *** [build/libs/hail-all-spark.jar] Error 1`. It seems that is caused by https://repo.hortonworks.com/content/repositories/releases/ server is done.; I am wondering whether there is any maven substitute can be used temporarily to compile hail.jar?. Thanks in advance for your help.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9419
https://github.com/hail-is/hail/issues/9419:40,Testability,test,tested,40,"I am using Hail 0.2.54. However, I also tested with the latest build.gradle file. I run the following make install command:; `make install HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.2`. However, I got this error message which did not appear before. ` > Could not resolve org.scalanlp:breeze-natives_2.11:+.; Required by:; project :; > Failed to list versions for org.scalanlp:breeze-natives_2.11.; > Unable to load Maven meta-data from https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml.; > Could not get resource 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'.; > Could not GET 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'. Received status code 500 from server: Server Error; * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.; * Get more help at https://help.gradle.org. BUILD FAILED in 29s; make: *** [build/libs/hail-all-spark.jar] Error 1`. It seems that is caused by https://repo.hortonworks.com/content/repositories/releases/ server is done.; I am wondering whether there is any maven substitute can be used temporarily to compile hail.jar?. Thanks in advance for your help.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9419
https://github.com/hail-is/hail/issues/9419:998,Testability,log,log,998,"I am using Hail 0.2.54. However, I also tested with the latest build.gradle file. I run the following make install command:; `make install HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.2`. However, I got this error message which did not appear before. ` > Could not resolve org.scalanlp:breeze-natives_2.11:+.; Required by:; project :; > Failed to list versions for org.scalanlp:breeze-natives_2.11.; > Unable to load Maven meta-data from https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml.; > Could not get resource 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'.; > Could not GET 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'. Received status code 500 from server: Server Error; * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.; * Get more help at https://help.gradle.org. BUILD FAILED in 29s; make: *** [build/libs/hail-all-spark.jar] Error 1`. It seems that is caused by https://repo.hortonworks.com/content/repositories/releases/ server is done.; I am wondering whether there is any maven substitute can be used temporarily to compile hail.jar?. Thanks in advance for your help.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9419
https://github.com/hail-is/hail/pull/9422:23,Energy Efficiency,reduce,reduce,23,"CHANGELOG: Drastically reduce memory usage by `tree_matmul`. `tree_matmul` reads from the same RDD many times. The RDDs created by `BlockMatrixRead` can actually be big when reading in a very large matrix, since they contain all the BlockMatrix metadata, which means a very long list of string file names. I don't want to create many different copies of this RDD when it would be better to share one copy.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9422
https://github.com/hail-is/hail/pull/9423:266,Availability,error,error,266,"Increase memory and cpu for test_hail_services_java to match java query tests. This contains tests of the shuffler IR, which runs the hail compiler, so it seems it should have the same resource limits as the other java query tests. #9401 is getting an out of memory error in `testShuffleIR`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9423
https://github.com/hail-is/hail/pull/9423:72,Testability,test,tests,72,"Increase memory and cpu for test_hail_services_java to match java query tests. This contains tests of the shuffler IR, which runs the hail compiler, so it seems it should have the same resource limits as the other java query tests. #9401 is getting an out of memory error in `testShuffleIR`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9423
https://github.com/hail-is/hail/pull/9423:93,Testability,test,tests,93,"Increase memory and cpu for test_hail_services_java to match java query tests. This contains tests of the shuffler IR, which runs the hail compiler, so it seems it should have the same resource limits as the other java query tests. #9401 is getting an out of memory error in `testShuffleIR`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9423
https://github.com/hail-is/hail/pull/9423:225,Testability,test,tests,225,"Increase memory and cpu for test_hail_services_java to match java query tests. This contains tests of the shuffler IR, which runs the hail compiler, so it seems it should have the same resource limits as the other java query tests. #9401 is getting an out of memory error in `testShuffleIR`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9423
https://github.com/hail-is/hail/pull/9423:276,Testability,test,testShuffleIR,276,"Increase memory and cpu for test_hail_services_java to match java query tests. This contains tests of the shuffler IR, which runs the hail compiler, so it seems it should have the same resource limits as the other java query tests. #9401 is getting an out of memory error in `testShuffleIR`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9423
https://github.com/hail-is/hail/pull/9426:116,Integrability,interface,interface,116,"Summary of changes:; - Added a (low level) aiogoogle.StorageClient for Google Storage.; - Added an abstract AsyncFS interface. There are currently 3 implementations: GoogleStorageAsyncFS, LocalAsyncFS, and RouterAsyncFS, which can route (based on the scheme) to other file systems. I tried to copy the standard Python os file system interface (open, remove, mkdir, isfile, etc.) I'm skeptical about pushing hard on this perspective, and I think we're better off finding a natural interface that that unifies local, gs, (hadoop) and s3. Maybe a read-only HttpFS. I think I want to split open() into open (for reading) and create (for writing). LocalFS operations are run in a thread pool which controls the level of IO parallelism.; - AsyncFS.open returns an AsyncStream. This is an async abstraction for Python File-like objects. It still amazes me Python doesn't have something built in for this. Next step is a high-level interface for listing objects. Eventually this and JVM FS should mirror each other.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9426
https://github.com/hail-is/hail/pull/9426:206,Integrability,Rout,RouterAsyncFS,206,"Summary of changes:; - Added a (low level) aiogoogle.StorageClient for Google Storage.; - Added an abstract AsyncFS interface. There are currently 3 implementations: GoogleStorageAsyncFS, LocalAsyncFS, and RouterAsyncFS, which can route (based on the scheme) to other file systems. I tried to copy the standard Python os file system interface (open, remove, mkdir, isfile, etc.) I'm skeptical about pushing hard on this perspective, and I think we're better off finding a natural interface that that unifies local, gs, (hadoop) and s3. Maybe a read-only HttpFS. I think I want to split open() into open (for reading) and create (for writing). LocalFS operations are run in a thread pool which controls the level of IO parallelism.; - AsyncFS.open returns an AsyncStream. This is an async abstraction for Python File-like objects. It still amazes me Python doesn't have something built in for this. Next step is a high-level interface for listing objects. Eventually this and JVM FS should mirror each other.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9426
https://github.com/hail-is/hail/pull/9426:231,Integrability,rout,route,231,"Summary of changes:; - Added a (low level) aiogoogle.StorageClient for Google Storage.; - Added an abstract AsyncFS interface. There are currently 3 implementations: GoogleStorageAsyncFS, LocalAsyncFS, and RouterAsyncFS, which can route (based on the scheme) to other file systems. I tried to copy the standard Python os file system interface (open, remove, mkdir, isfile, etc.) I'm skeptical about pushing hard on this perspective, and I think we're better off finding a natural interface that that unifies local, gs, (hadoop) and s3. Maybe a read-only HttpFS. I think I want to split open() into open (for reading) and create (for writing). LocalFS operations are run in a thread pool which controls the level of IO parallelism.; - AsyncFS.open returns an AsyncStream. This is an async abstraction for Python File-like objects. It still amazes me Python doesn't have something built in for this. Next step is a high-level interface for listing objects. Eventually this and JVM FS should mirror each other.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9426
https://github.com/hail-is/hail/pull/9426:333,Integrability,interface,interface,333,"Summary of changes:; - Added a (low level) aiogoogle.StorageClient for Google Storage.; - Added an abstract AsyncFS interface. There are currently 3 implementations: GoogleStorageAsyncFS, LocalAsyncFS, and RouterAsyncFS, which can route (based on the scheme) to other file systems. I tried to copy the standard Python os file system interface (open, remove, mkdir, isfile, etc.) I'm skeptical about pushing hard on this perspective, and I think we're better off finding a natural interface that that unifies local, gs, (hadoop) and s3. Maybe a read-only HttpFS. I think I want to split open() into open (for reading) and create (for writing). LocalFS operations are run in a thread pool which controls the level of IO parallelism.; - AsyncFS.open returns an AsyncStream. This is an async abstraction for Python File-like objects. It still amazes me Python doesn't have something built in for this. Next step is a high-level interface for listing objects. Eventually this and JVM FS should mirror each other.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9426
https://github.com/hail-is/hail/pull/9426:480,Integrability,interface,interface,480,"Summary of changes:; - Added a (low level) aiogoogle.StorageClient for Google Storage.; - Added an abstract AsyncFS interface. There are currently 3 implementations: GoogleStorageAsyncFS, LocalAsyncFS, and RouterAsyncFS, which can route (based on the scheme) to other file systems. I tried to copy the standard Python os file system interface (open, remove, mkdir, isfile, etc.) I'm skeptical about pushing hard on this perspective, and I think we're better off finding a natural interface that that unifies local, gs, (hadoop) and s3. Maybe a read-only HttpFS. I think I want to split open() into open (for reading) and create (for writing). LocalFS operations are run in a thread pool which controls the level of IO parallelism.; - AsyncFS.open returns an AsyncStream. This is an async abstraction for Python File-like objects. It still amazes me Python doesn't have something built in for this. Next step is a high-level interface for listing objects. Eventually this and JVM FS should mirror each other.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9426
https://github.com/hail-is/hail/pull/9426:924,Integrability,interface,interface,924,"Summary of changes:; - Added a (low level) aiogoogle.StorageClient for Google Storage.; - Added an abstract AsyncFS interface. There are currently 3 implementations: GoogleStorageAsyncFS, LocalAsyncFS, and RouterAsyncFS, which can route (based on the scheme) to other file systems. I tried to copy the standard Python os file system interface (open, remove, mkdir, isfile, etc.) I'm skeptical about pushing hard on this perspective, and I think we're better off finding a natural interface that that unifies local, gs, (hadoop) and s3. Maybe a read-only HttpFS. I think I want to split open() into open (for reading) and create (for writing). LocalFS operations are run in a thread pool which controls the level of IO parallelism.; - AsyncFS.open returns an AsyncStream. This is an async abstraction for Python File-like objects. It still amazes me Python doesn't have something built in for this. Next step is a high-level interface for listing objects. Eventually this and JVM FS should mirror each other.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9426
https://github.com/hail-is/hail/pull/9427:113,Performance,cache,cache,113,"In readBlock, membership was checked in a LinkedHashMap, then if it was; found, the value was retrieved from the cache. This lead to a data race; where a value could be evicted between the check and retrival. The; solution is to grab the block value out of the map, and if it is not; null, return it, otherwise, grab the block string, put it in the map,; and return it. Co-authored-by: Tim Poterba <tpoterba@broadinstitute.org>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9427
https://github.com/hail-is/hail/pull/9428:222,Availability,down,downside,222,"# Current situation. In several places, we call a method `emitNDArrayStandardStrides`, which has the effect of calling `emitDeforestedNDArray`, since that is known to always emit things in column major order. However, the downside of this is that we were doing unnecessary copies of the data, even when it was already in column major order, by constructing an `NDArrayEmitter` that just emitted an NDArray and then looked up values from it:. ```; case _ =>; val ndt = emit(x); val ndAddress = mb.genFieldThisRef[Long](); val setup = (ndAddress := ndt.value[Long]); val xP = x.pType.asInstanceOf[PNDArray]. val shapeAddress = new Value[Long] {; def get: Code[Long] = xP.shape.load(ndAddress); }; val shapeTuple = new CodePTuple(xP.shape.pType, shapeAddress). val shapeArray = (0 until xP.shape.pType.nFields).map(i => shapeTuple.apply[Long](i)). new NDArrayEmitter[C](nDims, shapeArray,; xP.shape.pType, xP.elementType, setup, ndt.setup, ndt.m) {; override def outputElement(elemMB: EmitMethodBuilder[C], idxVars: IndexedSeq[Value[Long]]): Code[_] =; xP.loadElementToIRIntermediate(idxVars, ndAddress, elemMB); }; ```. # New Situation. We now have `emitNDArrayColumnMajorStrides`, which calls `emit` on an ndarray, checks if the emitted thing is column major, and only does a copy if it needs to. This uses new `LinalgCodeUtils` methods `checkColumnMajor` and `createColumnMajorCode`. Everything else in `LinalgCodeUtils` was unused / old style and I removed them.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9428
https://github.com/hail-is/hail/pull/9428:675,Performance,load,load,675,"# Current situation. In several places, we call a method `emitNDArrayStandardStrides`, which has the effect of calling `emitDeforestedNDArray`, since that is known to always emit things in column major order. However, the downside of this is that we were doing unnecessary copies of the data, even when it was already in column major order, by constructing an `NDArrayEmitter` that just emitted an NDArray and then looked up values from it:. ```; case _ =>; val ndt = emit(x); val ndAddress = mb.genFieldThisRef[Long](); val setup = (ndAddress := ndt.value[Long]); val xP = x.pType.asInstanceOf[PNDArray]. val shapeAddress = new Value[Long] {; def get: Code[Long] = xP.shape.load(ndAddress); }; val shapeTuple = new CodePTuple(xP.shape.pType, shapeAddress). val shapeArray = (0 until xP.shape.pType.nFields).map(i => shapeTuple.apply[Long](i)). new NDArrayEmitter[C](nDims, shapeArray,; xP.shape.pType, xP.elementType, setup, ndt.setup, ndt.m) {; override def outputElement(elemMB: EmitMethodBuilder[C], idxVars: IndexedSeq[Value[Long]]): Code[_] =; xP.loadElementToIRIntermediate(idxVars, ndAddress, elemMB); }; ```. # New Situation. We now have `emitNDArrayColumnMajorStrides`, which calls `emit` on an ndarray, checks if the emitted thing is column major, and only does a copy if it needs to. This uses new `LinalgCodeUtils` methods `checkColumnMajor` and `createColumnMajorCode`. Everything else in `LinalgCodeUtils` was unused / old style and I removed them.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9428
https://github.com/hail-is/hail/pull/9428:1053,Performance,load,loadElementToIRIntermediate,1053,"# Current situation. In several places, we call a method `emitNDArrayStandardStrides`, which has the effect of calling `emitDeforestedNDArray`, since that is known to always emit things in column major order. However, the downside of this is that we were doing unnecessary copies of the data, even when it was already in column major order, by constructing an `NDArrayEmitter` that just emitted an NDArray and then looked up values from it:. ```; case _ =>; val ndt = emit(x); val ndAddress = mb.genFieldThisRef[Long](); val setup = (ndAddress := ndt.value[Long]); val xP = x.pType.asInstanceOf[PNDArray]. val shapeAddress = new Value[Long] {; def get: Code[Long] = xP.shape.load(ndAddress); }; val shapeTuple = new CodePTuple(xP.shape.pType, shapeAddress). val shapeArray = (0 until xP.shape.pType.nFields).map(i => shapeTuple.apply[Long](i)). new NDArrayEmitter[C](nDims, shapeArray,; xP.shape.pType, xP.elementType, setup, ndt.setup, ndt.m) {; override def outputElement(elemMB: EmitMethodBuilder[C], idxVars: IndexedSeq[Value[Long]]): Code[_] =; xP.loadElementToIRIntermediate(idxVars, ndAddress, elemMB); }; ```. # New Situation. We now have `emitNDArrayColumnMajorStrides`, which calls `emit` on an ndarray, checks if the emitted thing is column major, and only does a copy if it needs to. This uses new `LinalgCodeUtils` methods `checkColumnMajor` and `createColumnMajorCode`. Everything else in `LinalgCodeUtils` was unused / old style and I removed them.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9428
https://github.com/hail-is/hail/pull/9429:153,Testability,benchmark,benchmark,153,"Going off a suspicion that the JVM jit won't compile methods containing irreducible control flow, I tried to fix StreamFlatMap to be reducible. A simple benchmark based on `testES2FlatMap` showed a 2x speedup, which seems to confirm the suspicion. What caused the irreducibility was the following set of control flow paths (pretend the `Lpull` label was defined in the old version too):; * `Lpull -> LinnerPull`; * `Lpull -> LouterPull`; * `LinnerPull -> innerSource.eos -> LinnerEos -> LouterPull`; * `LouterPull -> outerSource.push -> LinnerPull`. The later two paths form a loop, and the first two make two entries into the loop - the basic irreducible control flow pattern. The fix redirects the last path to go to `Lpull` instead, which will happen to branch to `LinnerPull`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9429
https://github.com/hail-is/hail/pull/9429:146,Usability,simpl,simple,146,"Going off a suspicion that the JVM jit won't compile methods containing irreducible control flow, I tried to fix StreamFlatMap to be reducible. A simple benchmark based on `testES2FlatMap` showed a 2x speedup, which seems to confirm the suspicion. What caused the irreducibility was the following set of control flow paths (pretend the `Lpull` label was defined in the old version too):; * `Lpull -> LinnerPull`; * `Lpull -> LouterPull`; * `LinnerPull -> innerSource.eos -> LinnerEos -> LouterPull`; * `LouterPull -> outerSource.push -> LinnerPull`. The later two paths form a loop, and the first two make two entries into the loop - the basic irreducible control flow pattern. The fix redirects the last path to go to `Lpull` instead, which will happen to branch to `LinnerPull`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9429
https://github.com/hail-is/hail/pull/9434:46,Availability,checkpoint,checkpoint,46,"#9425 fixes the bug that caused us to need to checkpoint twice. This PR removes the second checkpoint. For the `hl.balding_nichols_model(20, 6000, 50000)`, 2 iterations test I've been doing, this gets us down to more like 35 seconds, as opposed to ~40. Current hail PCA takes more like 16 seconds, so we are getting closer (though again, it's not clear that 2 is going to be the right number of iterations in the end).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9434
https://github.com/hail-is/hail/pull/9434:91,Availability,checkpoint,checkpoint,91,"#9425 fixes the bug that caused us to need to checkpoint twice. This PR removes the second checkpoint. For the `hl.balding_nichols_model(20, 6000, 50000)`, 2 iterations test I've been doing, this gets us down to more like 35 seconds, as opposed to ~40. Current hail PCA takes more like 16 seconds, so we are getting closer (though again, it's not clear that 2 is going to be the right number of iterations in the end).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9434
https://github.com/hail-is/hail/pull/9434:204,Availability,down,down,204,"#9425 fixes the bug that caused us to need to checkpoint twice. This PR removes the second checkpoint. For the `hl.balding_nichols_model(20, 6000, 50000)`, 2 iterations test I've been doing, this gets us down to more like 35 seconds, as opposed to ~40. Current hail PCA takes more like 16 seconds, so we are getting closer (though again, it's not clear that 2 is going to be the right number of iterations in the end).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9434
https://github.com/hail-is/hail/pull/9434:169,Testability,test,test,169,"#9425 fixes the bug that caused us to need to checkpoint twice. This PR removes the second checkpoint. For the `hl.balding_nichols_model(20, 6000, 50000)`, 2 iterations test I've been doing, this gets us down to more like 35 seconds, as opposed to ~40. Current hail PCA takes more like 16 seconds, so we are getting closer (though again, it's not clear that 2 is going to be the right number of iterations in the end).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9434
https://github.com/hail-is/hail/pull/9434:347,Usability,clear,clear,347,"#9425 fixes the bug that caused us to need to checkpoint twice. This PR removes the second checkpoint. For the `hl.balding_nichols_model(20, 6000, 50000)`, 2 iterations test I've been doing, this gets us down to more like 35 seconds, as opposed to ~40. Current hail PCA takes more like 16 seconds, so we are getting closer (though again, it's not clear that 2 is going to be the right number of iterations in the end).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9434
https://github.com/hail-is/hail/pull/9435:401,Availability,down,downloading,401,"Introduce FASTAReaderConfig to act as a kind of factory for FASTAReader,; while all FASTAReaders themselves are confined to ThreadLocals (except; in tests). Furthermore, add a lock around the fasta file map to prevent more than; one fasta from being copied per jvm. The can be lock contention on the; map, but if there is large amounts of waiting for said lock, then it; usually means that a fasta is downloading and we definitely should be; waiting.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9435
https://github.com/hail-is/hail/pull/9435:149,Testability,test,tests,149,"Introduce FASTAReaderConfig to act as a kind of factory for FASTAReader,; while all FASTAReaders themselves are confined to ThreadLocals (except; in tests). Furthermore, add a lock around the fasta file map to prevent more than; one fasta from being copied per jvm. The can be lock contention on the; map, but if there is large amounts of waiting for said lock, then it; usually means that a fasta is downloading and we definitely should be; waiting.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9435
https://github.com/hail-is/hail/pull/9436:101,Testability,Test,Tests,101,"On certain occasions, the file inside the FASTA reader can be closed. It; is not yet understood why. Tests indicate that simply reopening the file; seems to resolve the issue when we run the appropriate exception. This also removes the need for SerializableReferenceSequenceFile, and so; deletes it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9436
https://github.com/hail-is/hail/pull/9436:121,Usability,simpl,simply,121,"On certain occasions, the file inside the FASTA reader can be closed. It; is not yet understood why. Tests indicate that simply reopening the file; seems to resolve the issue when we run the appropriate exception. This also removes the need for SerializableReferenceSequenceFile, and so; deletes it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9436
https://github.com/hail-is/hail/pull/9437:365,Integrability,interface,interface,365,"I'd like to give the user the ability to authenticate to our services from within a batch job. The specific use case I need it for is for the query service to be able to cache things with the memory service, but it seems like it could be more broadly applicable. I'm unsure whether this is the correct way to do it. This is currently not exposed in the python user interface (only in BatchClient), but I can pipe the option through in this PR if we want to.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9437
https://github.com/hail-is/hail/pull/9437:170,Performance,cache,cache,170,"I'd like to give the user the ability to authenticate to our services from within a batch job. The specific use case I need it for is for the query service to be able to cache things with the memory service, but it seems like it could be more broadly applicable. I'm unsure whether this is the correct way to do it. This is currently not exposed in the python user interface (only in BatchClient), but I can pipe the option through in this PR if we want to.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9437
https://github.com/hail-is/hail/pull/9437:41,Security,authenticat,authenticate,41,"I'd like to give the user the ability to authenticate to our services from within a batch job. The specific use case I need it for is for the query service to be able to cache things with the memory service, but it seems like it could be more broadly applicable. I'm unsure whether this is the correct way to do it. This is currently not exposed in the python user interface (only in BatchClient), but I can pipe the option through in this PR if we want to.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9437
https://github.com/hail-is/hail/pull/9437:338,Security,expose,exposed,338,"I'd like to give the user the ability to authenticate to our services from within a batch job. The specific use case I need it for is for the query service to be able to cache things with the memory service, but it seems like it could be more broadly applicable. I'm unsure whether this is the correct way to do it. This is currently not exposed in the python user interface (only in BatchClient), but I can pipe the option through in this PR if we want to.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9437
https://github.com/hail-is/hail/pull/9438:53,Deployability,update,update,53,"I'm trying to move all NDArray emission to emitI and update the style a bit, with the plan to eventually overhaul `NDArrayEmitter` to be more in line with the `PCode` interface. This PR updates `NDArrayMatmul` and `NDArrayInv` emit rules to be `emitI` rules, and cleans it up a bit. The diff isn't great, main changes were doing those `emit / flatmap` calls at the top to create `PCode`s, then using the corresponding `PValue`s everywhere I could instead of relying on `PType` methods. All the ""setup"" and missingness check code also went away since the `flatmap`s handle that stuff.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9438
https://github.com/hail-is/hail/pull/9438:186,Deployability,update,updates,186,"I'm trying to move all NDArray emission to emitI and update the style a bit, with the plan to eventually overhaul `NDArrayEmitter` to be more in line with the `PCode` interface. This PR updates `NDArrayMatmul` and `NDArrayInv` emit rules to be `emitI` rules, and cleans it up a bit. The diff isn't great, main changes were doing those `emit / flatmap` calls at the top to create `PCode`s, then using the corresponding `PValue`s everywhere I could instead of relying on `PType` methods. All the ""setup"" and missingness check code also went away since the `flatmap`s handle that stuff.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9438
https://github.com/hail-is/hail/pull/9438:167,Integrability,interface,interface,167,"I'm trying to move all NDArray emission to emitI and update the style a bit, with the plan to eventually overhaul `NDArrayEmitter` to be more in line with the `PCode` interface. This PR updates `NDArrayMatmul` and `NDArrayInv` emit rules to be `emitI` rules, and cleans it up a bit. The diff isn't great, main changes were doing those `emit / flatmap` calls at the top to create `PCode`s, then using the corresponding `PValue`s everywhere I could instead of relying on `PType` methods. All the ""setup"" and missingness check code also went away since the `flatmap`s handle that stuff.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9438
https://github.com/hail-is/hail/pull/9439:294,Availability,error,error,294,"I got an email saying the activity logs are no longer supported after September 30th. Here's the [migration instructions](https://cloud.google.com/compute/docs/logging/migrating-from-activity-logs-to-audit-logs#log_entry_field_mappings). I figured out how to map the fields mostly by trial and error looking at the JSON for an event. The only thing that didn't map at all was the operationType. I hardcoded that as 'insert'. There are different event_subtype names such as 'v1.compute.instances.insert' or 'beta.compute.instances.insert'. So I did what they suggested and looked for a partial match such as 'compute.instances.insert'. I can send you the full JSON for the events if you want to double check anything. I also double checked that the activity logs aren't used anywhere else in the repo, but it might be good for you to confirm that since you wrote a lot of this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9439
https://github.com/hail-is/hail/pull/9439:200,Security,audit,audit-logs,200,"I got an email saying the activity logs are no longer supported after September 30th. Here's the [migration instructions](https://cloud.google.com/compute/docs/logging/migrating-from-activity-logs-to-audit-logs#log_entry_field_mappings). I figured out how to map the fields mostly by trial and error looking at the JSON for an event. The only thing that didn't map at all was the operationType. I hardcoded that as 'insert'. There are different event_subtype names such as 'v1.compute.instances.insert' or 'beta.compute.instances.insert'. So I did what they suggested and looked for a partial match such as 'compute.instances.insert'. I can send you the full JSON for the events if you want to double check anything. I also double checked that the activity logs aren't used anywhere else in the repo, but it might be good for you to confirm that since you wrote a lot of this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9439
https://github.com/hail-is/hail/pull/9439:35,Testability,log,logs,35,"I got an email saying the activity logs are no longer supported after September 30th. Here's the [migration instructions](https://cloud.google.com/compute/docs/logging/migrating-from-activity-logs-to-audit-logs#log_entry_field_mappings). I figured out how to map the fields mostly by trial and error looking at the JSON for an event. The only thing that didn't map at all was the operationType. I hardcoded that as 'insert'. There are different event_subtype names such as 'v1.compute.instances.insert' or 'beta.compute.instances.insert'. So I did what they suggested and looked for a partial match such as 'compute.instances.insert'. I can send you the full JSON for the events if you want to double check anything. I also double checked that the activity logs aren't used anywhere else in the repo, but it might be good for you to confirm that since you wrote a lot of this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9439
https://github.com/hail-is/hail/pull/9439:160,Testability,log,logging,160,"I got an email saying the activity logs are no longer supported after September 30th. Here's the [migration instructions](https://cloud.google.com/compute/docs/logging/migrating-from-activity-logs-to-audit-logs#log_entry_field_mappings). I figured out how to map the fields mostly by trial and error looking at the JSON for an event. The only thing that didn't map at all was the operationType. I hardcoded that as 'insert'. There are different event_subtype names such as 'v1.compute.instances.insert' or 'beta.compute.instances.insert'. So I did what they suggested and looked for a partial match such as 'compute.instances.insert'. I can send you the full JSON for the events if you want to double check anything. I also double checked that the activity logs aren't used anywhere else in the repo, but it might be good for you to confirm that since you wrote a lot of this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9439
https://github.com/hail-is/hail/pull/9439:192,Testability,log,logs-to-audit-logs,192,"I got an email saying the activity logs are no longer supported after September 30th. Here's the [migration instructions](https://cloud.google.com/compute/docs/logging/migrating-from-activity-logs-to-audit-logs#log_entry_field_mappings). I figured out how to map the fields mostly by trial and error looking at the JSON for an event. The only thing that didn't map at all was the operationType. I hardcoded that as 'insert'. There are different event_subtype names such as 'v1.compute.instances.insert' or 'beta.compute.instances.insert'. So I did what they suggested and looked for a partial match such as 'compute.instances.insert'. I can send you the full JSON for the events if you want to double check anything. I also double checked that the activity logs aren't used anywhere else in the repo, but it might be good for you to confirm that since you wrote a lot of this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9439
https://github.com/hail-is/hail/pull/9439:757,Testability,log,logs,757,"I got an email saying the activity logs are no longer supported after September 30th. Here's the [migration instructions](https://cloud.google.com/compute/docs/logging/migrating-from-activity-logs-to-audit-logs#log_entry_field_mappings). I figured out how to map the fields mostly by trial and error looking at the JSON for an event. The only thing that didn't map at all was the operationType. I hardcoded that as 'insert'. There are different event_subtype names such as 'v1.compute.instances.insert' or 'beta.compute.instances.insert'. So I did what they suggested and looked for a partial match such as 'compute.instances.insert'. I can send you the full JSON for the events if you want to double check anything. I also double checked that the activity logs aren't used anywhere else in the repo, but it might be good for you to confirm that since you wrote a lot of this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9439
https://github.com/hail-is/hail/pull/9440:102,Deployability,update,update,102,"After this and #9450 go in, all NDArray IR nodes will be moved to `emitI`, making it easier for me to update `NDArrayEmitter` to use `EmitCodeBuilder` and `PCode`. I cleaned up `NDArrayQR` a little bit in this PR, but all the low level LAPACK stuff means it's still kind of a mess.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9440
https://github.com/hail-is/hail/pull/9441:78,Availability,down,download,78,The tests relying on Batch are getting slower because it takes a long time to download and build Docker images and we're putting more load on Batch. This will increase parallelism and reduce test failures due to timeouts.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9441
https://github.com/hail-is/hail/pull/9441:196,Availability,failure,failures,196,The tests relying on Batch are getting slower because it takes a long time to download and build Docker images and we're putting more load on Batch. This will increase parallelism and reduce test failures due to timeouts.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9441
https://github.com/hail-is/hail/pull/9441:184,Energy Efficiency,reduce,reduce,184,The tests relying on Batch are getting slower because it takes a long time to download and build Docker images and we're putting more load on Batch. This will increase parallelism and reduce test failures due to timeouts.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9441
https://github.com/hail-is/hail/pull/9441:134,Performance,load,load,134,The tests relying on Batch are getting slower because it takes a long time to download and build Docker images and we're putting more load on Batch. This will increase parallelism and reduce test failures due to timeouts.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9441
https://github.com/hail-is/hail/pull/9441:212,Safety,timeout,timeouts,212,The tests relying on Batch are getting slower because it takes a long time to download and build Docker images and we're putting more load on Batch. This will increase parallelism and reduce test failures due to timeouts.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9441
https://github.com/hail-is/hail/pull/9441:4,Testability,test,tests,4,The tests relying on Batch are getting slower because it takes a long time to download and build Docker images and we're putting more load on Batch. This will increase parallelism and reduce test failures due to timeouts.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9441
https://github.com/hail-is/hail/pull/9441:191,Testability,test,test,191,The tests relying on Batch are getting slower because it takes a long time to download and build Docker images and we're putting more load on Batch. This will increase parallelism and reduce test failures due to timeouts.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9441
https://github.com/hail-is/hail/pull/9443:23,Integrability,depend,depends,23,"Nothing in `IEmitCode` depends on the value being a `PCode`. This PR makes `IEmitCode` a type alias, `IEmitCode = IEmitCodeGen[PCode]`, where `IEmitCodeGen` is a generic version. This supports any pattern where we generate missing and present branches, and the value can be anything to be used while generating the present branch, e.g. `Code`, `PCode`, `Array[PCode]`, `Stream`, or even another optional value (an `EmitCode` or `CodeBuilder => IEmitCode`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9443
https://github.com/hail-is/hail/pull/9444:29,Availability,error,error,29,Extending the idea of better error messages from #9398 to include `NDArrayRef`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9444
https://github.com/hail-is/hail/pull/9444:35,Integrability,message,messages,35,Extending the idea of better error messages from #9398 to include `NDArrayRef`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9444
https://github.com/hail-is/hail/pull/9444:0,Modifiability,Extend,Extending,0,Extending the idea of better error messages from #9398 to include `NDArrayRef`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9444
https://github.com/hail-is/hail/pull/9447:461,Usability,simpl,simply,461,"`IEmitCode.consume`, with signature `consume[T](cb: EmitCodeBuilder, ifMissing: => Unit, ifPresent: (A) => T): T`, is wrong: it exports a value that is only defined in the present branch to be used after the two branches have joined. The only use of this manually guarded the exported value by a bit remembering which branch was taken, but this is better handled by memoizing the `IEmitCode` in an `EmitValue`. Almost every other use of `consume` could be more simply expressed using `handle`, and moreover almost every use of `handle` could be more simply expressed using a method `get` which simply throws an exception if the missing branch is taken. For those few cases where one really does want to consume an `IEmitCode` to a `Code` or `PCode`, with definitions given for each branch, I added `consumeCode` and `consumePCode`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9447
https://github.com/hail-is/hail/pull/9447:550,Usability,simpl,simply,550,"`IEmitCode.consume`, with signature `consume[T](cb: EmitCodeBuilder, ifMissing: => Unit, ifPresent: (A) => T): T`, is wrong: it exports a value that is only defined in the present branch to be used after the two branches have joined. The only use of this manually guarded the exported value by a bit remembering which branch was taken, but this is better handled by memoizing the `IEmitCode` in an `EmitValue`. Almost every other use of `consume` could be more simply expressed using `handle`, and moreover almost every use of `handle` could be more simply expressed using a method `get` which simply throws an exception if the missing branch is taken. For those few cases where one really does want to consume an `IEmitCode` to a `Code` or `PCode`, with definitions given for each branch, I added `consumeCode` and `consumePCode`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9447
https://github.com/hail-is/hail/pull/9447:594,Usability,simpl,simply,594,"`IEmitCode.consume`, with signature `consume[T](cb: EmitCodeBuilder, ifMissing: => Unit, ifPresent: (A) => T): T`, is wrong: it exports a value that is only defined in the present branch to be used after the two branches have joined. The only use of this manually guarded the exported value by a bit remembering which branch was taken, but this is better handled by memoizing the `IEmitCode` in an `EmitValue`. Almost every other use of `consume` could be more simply expressed using `handle`, and moreover almost every use of `handle` could be more simply expressed using a method `get` which simply throws an exception if the missing branch is taken. For those few cases where one really does want to consume an `IEmitCode` to a `Code` or `PCode`, with definitions given for each branch, I added `consumeCode` and `consumePCode`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9447
https://github.com/hail-is/hail/pull/9450:124,Integrability,interface,interface,124,"This PR is a redo of #9438 that attempts to address Arcturus's comment about `NDArrayMatMul` using the old `NDArrayEmitter` interface. I created `NDArrayEmiter2` and moved `NDArrayMatMul` over to using that. I don't want this PR to get too much bigger, so after this one goes in I can make a second one that kills the original `NDArrayEmitter` and gets everything over to this new version.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9450
https://github.com/hail-is/hail/pull/9451:74,Integrability,interface,interface,74,Current plan going forward for this:; - I'm getting pretty happy with the interface (but maybe want to rename some things). I think I will document what I have next.; - Get rid of legacy hailtop.GCS. This means we can get rid of all the client libraries except the oauth2 flows in auth.; - The add a glob operation.; - Add a copy/sync operation. I might also add an S3AsyncFS. I could have used that recently.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9451
https://github.com/hail-is/hail/pull/9458:70,Deployability,install,install-dev-deps,70,"Make targets for building docs were renamed in #8086 and #9348. `make install-dev-deps` does not cover all build dependencies for docs (it does not install pandoc), so added a note about what is required.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9458
https://github.com/hail-is/hail/pull/9458:148,Deployability,install,install,148,"Make targets for building docs were renamed in #8086 and #9348. `make install-dev-deps` does not cover all build dependencies for docs (it does not install pandoc), so added a note about what is required.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9458
https://github.com/hail-is/hail/pull/9458:113,Integrability,depend,dependencies,113,"Make targets for building docs were renamed in #8086 and #9348. `make install-dev-deps` does not cover all build dependencies for docs (it does not install pandoc), so added a note about what is required.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9458
https://github.com/hail-is/hail/pull/9460:106,Energy Efficiency,reduce,reduces,106,Add a few helpful log statements and use default CPU/mem rather than explicitly specifying it in CI. This reduces cpu from 1 to 0.1. I have to parse the cgroup requirements to ensure that the host docker daemon does not exceed the limits of the build job.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9460
https://github.com/hail-is/hail/pull/9460:18,Testability,log,log,18,Add a few helpful log statements and use default CPU/mem rather than explicitly specifying it in CI. This reduces cpu from 1 to 0.1. I have to parse the cgroup requirements to ensure that the host docker daemon does not exceed the limits of the build job.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9460
https://github.com/hail-is/hail/pull/9462:157,Safety,avoid,avoid,157,"The `BatchPoolExecutor` assumes, incorrectly, that the default number of CPUs for; a batch job is 1. This is not true in test and development environment. I avoid explicitly setting the value if it is `None`. This choice preserves the; default value in this environment. I set the thread limit to 1 if the CPU is `None`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9462
https://github.com/hail-is/hail/pull/9462:121,Testability,test,test,121,"The `BatchPoolExecutor` assumes, incorrectly, that the default number of CPUs for; a batch job is 1. This is not true in test and development environment. I avoid explicitly setting the value if it is `None`. This choice preserves the; default value in this environment. I set the thread limit to 1 if the CPU is `None`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9462
https://github.com/hail-is/hail/pull/9464:347,Availability,error,error,347,"I noticed that jobs in test deployments were deadlocking because we weren't spinning up extra instances (compared to the production version of Batch). Although each job could fit on an open instance, its allocated share is still less than the core request for that job. This PR aims to increase the probability in which we ignore an exceed shares error the more we have these errors such that at a certain point the rate will be 100% and we'll be able to continue scheduling.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9464
https://github.com/hail-is/hail/pull/9464:376,Availability,error,errors,376,"I noticed that jobs in test deployments were deadlocking because we weren't spinning up extra instances (compared to the production version of Batch). Although each job could fit on an open instance, its allocated share is still less than the core request for that job. This PR aims to increase the probability in which we ignore an exceed shares error the more we have these errors such that at a certain point the rate will be 100% and we'll be able to continue scheduling.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9464
https://github.com/hail-is/hail/pull/9464:28,Deployability,deploy,deployments,28,"I noticed that jobs in test deployments were deadlocking because we weren't spinning up extra instances (compared to the production version of Batch). Although each job could fit on an open instance, its allocated share is still less than the core request for that job. This PR aims to increase the probability in which we ignore an exceed shares error the more we have these errors such that at a certain point the rate will be 100% and we'll be able to continue scheduling.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9464
https://github.com/hail-is/hail/pull/9464:204,Energy Efficiency,allocate,allocated,204,"I noticed that jobs in test deployments were deadlocking because we weren't spinning up extra instances (compared to the production version of Batch). Although each job could fit on an open instance, its allocated share is still less than the core request for that job. This PR aims to increase the probability in which we ignore an exceed shares error the more we have these errors such that at a certain point the rate will be 100% and we'll be able to continue scheduling.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9464
https://github.com/hail-is/hail/pull/9464:464,Energy Efficiency,schedul,scheduling,464,"I noticed that jobs in test deployments were deadlocking because we weren't spinning up extra instances (compared to the production version of Batch). Although each job could fit on an open instance, its allocated share is still less than the core request for that job. This PR aims to increase the probability in which we ignore an exceed shares error the more we have these errors such that at a certain point the rate will be 100% and we'll be able to continue scheduling.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9464
https://github.com/hail-is/hail/pull/9464:23,Testability,test,test,23,"I noticed that jobs in test deployments were deadlocking because we weren't spinning up extra instances (compared to the production version of Batch). Although each job could fit on an open instance, its allocated share is still less than the core request for that job. This PR aims to increase the probability in which we ignore an exceed shares error the more we have these errors such that at a certain point the rate will be 100% and we'll be able to continue scheduling.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9464
https://github.com/hail-is/hail/pull/9465:70,Deployability,configurat,configuration,70,"AFAIK, we do not use this file and it confuses Emacs. Emacs uses this configuration; instead of the one at the root of the repository.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9465
https://github.com/hail-is/hail/pull/9465:70,Modifiability,config,configuration,70,"AFAIK, we do not use this file and it confuses Emacs. Emacs uses this configuration; instead of the one at the root of the repository.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9465
https://github.com/hail-is/hail/pull/9467:54,Availability,error,errors,54,- BPE fix plus ignoring exceeded allocation scheduler errors.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9467
https://github.com/hail-is/hail/pull/9467:44,Energy Efficiency,schedul,scheduler,44,- BPE fix plus ignoring exceeded allocation scheduler errors.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9467
https://github.com/hail-is/hail/pull/9469:629,Availability,avail,available,629,"In this PR, I rewrite `linear_regression_rows_nd` to use `_map_partitions` instead of `_group_within_partitions`. By doing this, I've eliminated the need to do a `key_by` at the end of `linear_regression_rows_nd`. I also think this makes the code clearer. . This PR also makes a few seemingly random changes that are actually bug fixes:. 1. When emitting `Apply` nodes, we were grabbing the `Code[Region]` from the first argument to the `MethodBuilder`. However, the assumption that the first argument will always be a `Region` seems to no longer be true. As such, we just construct a `CodeParam` from the `StagedRegion` we have available. . 2. In the NDArrayEmitter, I want to make sure I call the local `emit` method that passes off to `emitWithRegion`, for the same reason as 1: (Can't trust first argument to be a `Region`). 3. In `EmitStream`, I need to use `memoizeField` instead of `memoize`, because regular `memoize` saves to a `LocalRef`, and that will get reset to 0 when `next` is called on a stream. Lesson: don't trust locals for things that must live between elements of a stream. I feel like you have a better idea of how the Stream stuff gets emitted than I do Patrick. I'm curious if what I wrote in `process_block` could be written in a way that would lead to better code getting emitted, as I still need to figure out how to squeeze more performance out of this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9469
https://github.com/hail-is/hail/pull/9469:14,Modifiability,rewrite,rewrite,14,"In this PR, I rewrite `linear_regression_rows_nd` to use `_map_partitions` instead of `_group_within_partitions`. By doing this, I've eliminated the need to do a `key_by` at the end of `linear_regression_rows_nd`. I also think this makes the code clearer. . This PR also makes a few seemingly random changes that are actually bug fixes:. 1. When emitting `Apply` nodes, we were grabbing the `Code[Region]` from the first argument to the `MethodBuilder`. However, the assumption that the first argument will always be a `Region` seems to no longer be true. As such, we just construct a `CodeParam` from the `StagedRegion` we have available. . 2. In the NDArrayEmitter, I want to make sure I call the local `emit` method that passes off to `emitWithRegion`, for the same reason as 1: (Can't trust first argument to be a `Region`). 3. In `EmitStream`, I need to use `memoizeField` instead of `memoize`, because regular `memoize` saves to a `LocalRef`, and that will get reset to 0 when `next` is called on a stream. Lesson: don't trust locals for things that must live between elements of a stream. I feel like you have a better idea of how the Stream stuff gets emitted than I do Patrick. I'm curious if what I wrote in `process_block` could be written in a way that would lead to better code getting emitted, as I still need to figure out how to squeeze more performance out of this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9469
https://github.com/hail-is/hail/pull/9469:1358,Performance,perform,performance,1358,"In this PR, I rewrite `linear_regression_rows_nd` to use `_map_partitions` instead of `_group_within_partitions`. By doing this, I've eliminated the need to do a `key_by` at the end of `linear_regression_rows_nd`. I also think this makes the code clearer. . This PR also makes a few seemingly random changes that are actually bug fixes:. 1. When emitting `Apply` nodes, we were grabbing the `Code[Region]` from the first argument to the `MethodBuilder`. However, the assumption that the first argument will always be a `Region` seems to no longer be true. As such, we just construct a `CodeParam` from the `StagedRegion` we have available. . 2. In the NDArrayEmitter, I want to make sure I call the local `emit` method that passes off to `emitWithRegion`, for the same reason as 1: (Can't trust first argument to be a `Region`). 3. In `EmitStream`, I need to use `memoizeField` instead of `memoize`, because regular `memoize` saves to a `LocalRef`, and that will get reset to 0 when `next` is called on a stream. Lesson: don't trust locals for things that must live between elements of a stream. I feel like you have a better idea of how the Stream stuff gets emitted than I do Patrick. I'm curious if what I wrote in `process_block` could be written in a way that would lead to better code getting emitted, as I still need to figure out how to squeeze more performance out of this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9469
https://github.com/hail-is/hail/pull/9469:247,Usability,clear,clearer,247,"In this PR, I rewrite `linear_regression_rows_nd` to use `_map_partitions` instead of `_group_within_partitions`. By doing this, I've eliminated the need to do a `key_by` at the end of `linear_regression_rows_nd`. I also think this makes the code clearer. . This PR also makes a few seemingly random changes that are actually bug fixes:. 1. When emitting `Apply` nodes, we were grabbing the `Code[Region]` from the first argument to the `MethodBuilder`. However, the assumption that the first argument will always be a `Region` seems to no longer be true. As such, we just construct a `CodeParam` from the `StagedRegion` we have available. . 2. In the NDArrayEmitter, I want to make sure I call the local `emit` method that passes off to `emitWithRegion`, for the same reason as 1: (Can't trust first argument to be a `Region`). 3. In `EmitStream`, I need to use `memoizeField` instead of `memoize`, because regular `memoize` saves to a `LocalRef`, and that will get reset to 0 when `next` is called on a stream. Lesson: don't trust locals for things that must live between elements of a stream. I feel like you have a better idea of how the Stream stuff gets emitted than I do Patrick. I'm curious if what I wrote in `process_block` could be written in a way that would lead to better code getting emitted, as I still need to figure out how to squeeze more performance out of this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9469
https://github.com/hail-is/hail/pull/9470:64,Availability,error,errors,64,Regenie defaults to requesting 1 core. I also fixed some syntax errors in test_batch.py,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9470
https://github.com/hail-is/hail/pull/9472:91,Energy Efficiency,reduce,reduces,91,The old BPE images (which still exist) are based on the full python image. The; slim image reduces the size by about 750MB. This should substantially improve; image pull on the n1-standards. I have seen image pull for this image take 136; seconds before in a test job.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9472
https://github.com/hail-is/hail/pull/9472:259,Testability,test,test,259,The old BPE images (which still exist) are based on the full python image. The; slim image reduces the size by about 750MB. This should substantially improve; image pull on the n1-standards. I have seen image pull for this image take 136; seconds before in a test job.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9472
https://github.com/hail-is/hail/pull/9473:5,Deployability,update,update,5,Also update all uses of cloud sdk to same version. Seems good to do anyway. I hope the newer version of gcloud includes a faster gsutil. I also hope that using gcr will improve the pull time a bit.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9473
https://github.com/hail-is/hail/pull/9475:182,Energy Efficiency,reduce,reduce,182,"This was a good one :). I havent measured the performance difference, but clearly the bug defeated the purpose of using a union-find data structure in the first place, which was to reduce the complexity of `unify` from quadratic to linear. While I was here, I made a separate simplification. Now that the sets are being unioned as intended, each set contains exactly one block that doesnt start with a `GotoX`, and that block is the final target of all blocks in the set. That observation allows a simplification when computing the `rootFinalTarget` map.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9475
https://github.com/hail-is/hail/pull/9475:47,Performance,perform,performance,47,"This was a good one :). I havent measured the performance difference, but clearly the bug defeated the purpose of using a union-find data structure in the first place, which was to reduce the complexity of `unify` from quadratic to linear. While I was here, I made a separate simplification. Now that the sets are being unioned as intended, each set contains exactly one block that doesnt start with a `GotoX`, and that block is the final target of all blocks in the set. That observation allows a simplification when computing the `rootFinalTarget` map.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9475
https://github.com/hail-is/hail/pull/9475:75,Usability,clear,clearly,75,"This was a good one :). I havent measured the performance difference, but clearly the bug defeated the purpose of using a union-find data structure in the first place, which was to reduce the complexity of `unify` from quadratic to linear. While I was here, I made a separate simplification. Now that the sets are being unioned as intended, each set contains exactly one block that doesnt start with a `GotoX`, and that block is the final target of all blocks in the set. That observation allows a simplification when computing the `rootFinalTarget` map.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9475
https://github.com/hail-is/hail/pull/9475:277,Usability,simpl,simplification,277,"This was a good one :). I havent measured the performance difference, but clearly the bug defeated the purpose of using a union-find data structure in the first place, which was to reduce the complexity of `unify` from quadratic to linear. While I was here, I made a separate simplification. Now that the sets are being unioned as intended, each set contains exactly one block that doesnt start with a `GotoX`, and that block is the final target of all blocks in the set. That observation allows a simplification when computing the `rootFinalTarget` map.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9475
https://github.com/hail-is/hail/pull/9475:500,Usability,simpl,simplification,500,"This was a good one :). I havent measured the performance difference, but clearly the bug defeated the purpose of using a union-find data structure in the first place, which was to reduce the complexity of `unify` from quadratic to linear. While I was here, I made a separate simplification. Now that the sets are being unioned as intended, each set contains exactly one block that doesnt start with a `GotoX`, and that block is the final target of all blocks in the set. That observation allows a simplification when computing the `rootFinalTarget` map.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9475
https://github.com/hail-is/hail/pull/9478:511,Safety,timeout,timeout,511,"- Add a flush after writing the first log statement. This log statement is; displayed before any network requests, the flush ensures we always see it.; - Set the retries for in-cluster synchronous requests to 1.; - Change all external (ones that go through the gateway) HTTP(S) requests to use; a centrally defined session. This session improves the situation in two ways:; 1. It prevents urllib from retrying requests, which ensures Hail's retry; infrastructure is the only retry infrastructure.; 2. It sets a timeout, ensuring that all requests will timeout. Previously,; requests could hang forever.; 3. It permits setting headers that are used for all requests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9478
https://github.com/hail-is/hail/pull/9478:552,Safety,timeout,timeout,552,"- Add a flush after writing the first log statement. This log statement is; displayed before any network requests, the flush ensures we always see it.; - Set the retries for in-cluster synchronous requests to 1.; - Change all external (ones that go through the gateway) HTTP(S) requests to use; a centrally defined session. This session improves the situation in two ways:; 1. It prevents urllib from retrying requests, which ensures Hail's retry; infrastructure is the only retry infrastructure.; 2. It sets a timeout, ensuring that all requests will timeout. Previously,; requests could hang forever.; 3. It permits setting headers that are used for all requests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9478
https://github.com/hail-is/hail/pull/9478:38,Testability,log,log,38,"- Add a flush after writing the first log statement. This log statement is; displayed before any network requests, the flush ensures we always see it.; - Set the retries for in-cluster synchronous requests to 1.; - Change all external (ones that go through the gateway) HTTP(S) requests to use; a centrally defined session. This session improves the situation in two ways:; 1. It prevents urllib from retrying requests, which ensures Hail's retry; infrastructure is the only retry infrastructure.; 2. It sets a timeout, ensuring that all requests will timeout. Previously,; requests could hang forever.; 3. It permits setting headers that are used for all requests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9478
https://github.com/hail-is/hail/pull/9478:58,Testability,log,log,58,"- Add a flush after writing the first log statement. This log statement is; displayed before any network requests, the flush ensures we always see it.; - Set the retries for in-cluster synchronous requests to 1.; - Change all external (ones that go through the gateway) HTTP(S) requests to use; a centrally defined session. This session improves the situation in two ways:; 1. It prevents urllib from retrying requests, which ensures Hail's retry; infrastructure is the only retry infrastructure.; 2. It sets a timeout, ensuring that all requests will timeout. Previously,; requests could hang forever.; 3. It permits setting headers that are used for all requests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9478
https://github.com/hail-is/hail/pull/9479:98,Integrability,message,message,98,"Now we can add a decorator to give a warning when a user uses a deprecated thing. It will print a message out when it is used. . There's a way to get this to automatically print in Sphinx as well, but I'll set that up later. For now, I have manually mentioned in the docstring when a method is deprecated, and now this decorator will give a warning when it's used.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9479
https://github.com/hail-is/hail/pull/9480:99,Usability,simpl,simpler,99,"I broke up #9450. This PR moves just `NDArrayMatMul` to `emitI`, and does so by introducing a new, simpler `NDArrayEmitter` called `NDArrayEmitter2`. In a subsequent PR, I'll delete the old `NDArrayEmitter` entirely and move everything over to new version.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9480
https://github.com/hail-is/hail/pull/9488:154,Security,access,access,154,"- Use the scorecard tag or design-docs tag to have Asana tasks show up in scorecard; - Easy to add different tags to track; - Currently using my personal access token. Not sure if that's ideal, but seemed fine for now.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9488
https://github.com/hail-is/hail/pull/9489:8,Testability,assert,asserts,8,"This PR asserts a stronger precondition for `Method.findBlocks`: all reachable blocks must be non-empty, must be terminated by a control expression, and all targets of the control expression must be non-null.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9489
https://github.com/hail-is/hail/pull/9490:427,Usability,simpl,simplifications,427,"Stacked on #9489 . This PR enforces a stronger invariant on `lir.Block`: a block can never contain dead code, i.e. code that follows a control statement. Prior to this, dead code could be added to a block, only to be removed later. But it's just as easy to have `Block.append` check if a statement to be added would be dead, and just not add it in the first place. And having the stronger invariant always hold allows for some simplifications in the code, in addition to a simpler mental model.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9490
https://github.com/hail-is/hail/pull/9490:473,Usability,simpl,simpler,473,"Stacked on #9489 . This PR enforces a stronger invariant on `lir.Block`: a block can never contain dead code, i.e. code that follows a control statement. Prior to this, dead code could be added to a block, only to be removed later. But it's just as easy to have `Block.append` check if a statement to be added would be dead, and just not add it in the first place. And having the stronger invariant always hold allows for some simplifications in the code, in addition to a simpler mental model.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9490
https://github.com/hail-is/hail/pull/9491:119,Availability,redundant,redundant,119,"~~Stacked on #9490~~. With the stronger invariants enforced by the previous PRs, some of the work done in `asBytes` is redundant.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9491
https://github.com/hail-is/hail/pull/9491:119,Safety,redund,redundant,119,"~~Stacked on #9490~~. With the stronger invariants enforced by the previous PRs, some of the work done in `asBytes` is redundant.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9491
https://github.com/hail-is/hail/pull/9493:25,Modifiability,config,config,25,"It was previously called config.yaml, when it was actually a python; configparser config file, which is a subset of [ini syntax]. [ini syntax]: https://docs.python.org/3/library/configparser.html. Check to see if the .yaml file exists and the .ini file does not exist.; If so, silently rename the config file to the new name.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9493
https://github.com/hail-is/hail/pull/9493:69,Modifiability,config,configparser,69,"It was previously called config.yaml, when it was actually a python; configparser config file, which is a subset of [ini syntax]. [ini syntax]: https://docs.python.org/3/library/configparser.html. Check to see if the .yaml file exists and the .ini file does not exist.; If so, silently rename the config file to the new name.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9493
https://github.com/hail-is/hail/pull/9493:82,Modifiability,config,config,82,"It was previously called config.yaml, when it was actually a python; configparser config file, which is a subset of [ini syntax]. [ini syntax]: https://docs.python.org/3/library/configparser.html. Check to see if the .yaml file exists and the .ini file does not exist.; If so, silently rename the config file to the new name.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9493
https://github.com/hail-is/hail/pull/9493:178,Modifiability,config,configparser,178,"It was previously called config.yaml, when it was actually a python; configparser config file, which is a subset of [ini syntax]. [ini syntax]: https://docs.python.org/3/library/configparser.html. Check to see if the .yaml file exists and the .ini file does not exist.; If so, silently rename the config file to the new name.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9493
https://github.com/hail-is/hail/pull/9493:297,Modifiability,config,config,297,"It was previously called config.yaml, when it was actually a python; configparser config file, which is a subset of [ini syntax]. [ini syntax]: https://docs.python.org/3/library/configparser.html. Check to see if the .yaml file exists and the .ini file does not exist.; If so, silently rename the config file to the new name.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9493
https://github.com/hail-is/hail/pull/9494:65,Availability,error,error,65,I have yet to successfully create a VCF that doesn't hit another error before hitting this one. But user hit this here: https://discuss.hail.is/t/assertionerror-exception/1700,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9494
https://github.com/hail-is/hail/pull/9494:146,Testability,assert,assertionerror-exception,146,I have yet to successfully create a VCF that doesn't hit another error before hitting this one. But user hit this here: https://discuss.hail.is/t/assertionerror-exception/1700,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9494
https://github.com/hail-is/hail/pull/9495:138,Performance,Load,LoadPlink,138,CHANGELOG: Fix hl.import_plink docs to properly report the type of `is_case` and `quant_pheno`. I verified the correct types by checking `LoadPlink.scala`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9495
https://github.com/hail-is/hail/pull/9496:162,Availability,avail,available,162,"Updated db.py to require user to specify region as shown below, so that data will be accessed from the requester pays bucket in the region specified by the user, available regions are `'us'` and `'eu'`. . `db = hl.experimental.DB(region='us')`; `mt = db.annotate_rows_db(mt, 'gnomad_lof_metrics')`. Entries in the `annotation_db.json` file were modified to the following format:. ```; ""dataset_name"": { ""description"": ""some description here"",; ""key_properties"": [],; ""url"": ""https://www.someurlhere.com"",; ""versions"": [{""url"": {""eu"": ""gs://hail-datasets-eu/dataset"",; ""us"": ""gs://hail-datasets-us/dataset""},; ""version"": ""one_version""},; {""url"": {""eu"": ""gs://hail-datasets-eu/dataset"",; ""us"": ""gs://hail-datasets-us/dataset""},; ""version"": ""another_version""}]}; ```. The `annotation_db.json` file is now used by the `load_dataset()` function in `datasets.py` as well, any dataset in the JSON file should now be able to be loaded this way. Made changes to the following:; - `DB` class now requires a `region` parameter.; - `Dataset.from_name_and_json()` has had a `custom_config` parameter added that indicates whether or not the user has supplied their own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and rai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9496
https://github.com/hail-is/hail/pull/9496:1513,Availability,avail,available,1513,"rties"": [],; ""url"": ""https://www.someurlhere.com"",; ""versions"": [{""url"": {""eu"": ""gs://hail-datasets-eu/dataset"",; ""us"": ""gs://hail-datasets-us/dataset""},; ""version"": ""one_version""},; {""url"": {""eu"": ""gs://hail-datasets-eu/dataset"",; ""us"": ""gs://hail-datasets-us/dataset""},; ""version"": ""another_version""}]}; ```. The `annotation_db.json` file is now used by the `load_dataset()` function in `datasets.py` as well, any dataset in the JSON file should now be able to be loaded this way. Made changes to the following:; - `DB` class now requires a `region` parameter.; - `Dataset.from_name_and_json()` has had a `custom_config` parameter added that indicates whether or not the user has supplied their own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and raise a `ValueError`.; - Started to add documentation to the classes and methods, still a work in progress. Changes to datasets and datasets API site:; - Added the `ldsc_baselineLD_annotations`, `ldsc_baselineLD_ldscores`, and `ldsc_baseline_ldscores` datasets to the `annotation_db.json` configuration file. Now accessible via `load_dataset()` and `db.annotate_rows_db()` (for the annotations at least).; - New `.rst` files in `hail/python/hail/docs/datase",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9496
https://github.com/hail-is/hail/pull/9496:1619,Availability,avail,available,1619,"/dataset""},; ""version"": ""one_version""},; {""url"": {""eu"": ""gs://hail-datasets-eu/dataset"",; ""us"": ""gs://hail-datasets-us/dataset""},; ""version"": ""another_version""}]}; ```. The `annotation_db.json` file is now used by the `load_dataset()` function in `datasets.py` as well, any dataset in the JSON file should now be able to be loaded this way. Made changes to the following:; - `DB` class now requires a `region` parameter.; - `Dataset.from_name_and_json()` has had a `custom_config` parameter added that indicates whether or not the user has supplied their own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and raise a `ValueError`.; - Started to add documentation to the classes and methods, still a work in progress. Changes to datasets and datasets API site:; - Added the `ldsc_baselineLD_annotations`, `ldsc_baselineLD_ldscores`, and `ldsc_baseline_ldscores` datasets to the `annotation_db.json` configuration file. Now accessible via `load_dataset()` and `db.annotate_rows_db()` (for the annotations at least).; - New `.rst` files in `hail/python/hail/docs/datasets` have been generated to reflect the available datasets in the config file, and `hail/python/hail/docs/datasets.rst` has been updated with ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9496
https://github.com/hail-is/hail/pull/9496:1711,Availability,avail,available,1711,"sion"": ""another_version""}]}; ```. The `annotation_db.json` file is now used by the `load_dataset()` function in `datasets.py` as well, any dataset in the JSON file should now be able to be loaded this way. Made changes to the following:; - `DB` class now requires a `region` parameter.; - `Dataset.from_name_and_json()` has had a `custom_config` parameter added that indicates whether or not the user has supplied their own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and raise a `ValueError`.; - Started to add documentation to the classes and methods, still a work in progress. Changes to datasets and datasets API site:; - Added the `ldsc_baselineLD_annotations`, `ldsc_baselineLD_ldscores`, and `ldsc_baseline_ldscores` datasets to the `annotation_db.json` configuration file. Now accessible via `load_dataset()` and `db.annotate_rows_db()` (for the annotations at least).; - New `.rst` files in `hail/python/hail/docs/datasets` have been generated to reflect the available datasets in the config file, and `hail/python/hail/docs/datasets.rst` has been updated with the new files as well. Future updates:; - In next PR can add the functionality to automatically determine the users region.; - Also con",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9496
https://github.com/hail-is/hail/pull/9496:1756,Availability,avail,available,1756,"sion"": ""another_version""}]}; ```. The `annotation_db.json` file is now used by the `load_dataset()` function in `datasets.py` as well, any dataset in the JSON file should now be able to be loaded this way. Made changes to the following:; - `DB` class now requires a `region` parameter.; - `Dataset.from_name_and_json()` has had a `custom_config` parameter added that indicates whether or not the user has supplied their own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and raise a `ValueError`.; - Started to add documentation to the classes and methods, still a work in progress. Changes to datasets and datasets API site:; - Added the `ldsc_baselineLD_annotations`, `ldsc_baselineLD_ldscores`, and `ldsc_baseline_ldscores` datasets to the `annotation_db.json` configuration file. Now accessible via `load_dataset()` and `db.annotate_rows_db()` (for the annotations at least).; - New `.rst` files in `hail/python/hail/docs/datasets` have been generated to reflect the available datasets in the config file, and `hail/python/hail/docs/datasets.rst` has been updated with the new files as well. Future updates:; - In next PR can add the functionality to automatically determine the users region.; - Also con",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9496
https://github.com/hail-is/hail/pull/9496:2494,Availability,avail,available,2494," own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and raise a `ValueError`.; - Started to add documentation to the classes and methods, still a work in progress. Changes to datasets and datasets API site:; - Added the `ldsc_baselineLD_annotations`, `ldsc_baselineLD_ldscores`, and `ldsc_baseline_ldscores` datasets to the `annotation_db.json` configuration file. Now accessible via `load_dataset()` and `db.annotate_rows_db()` (for the annotations at least).; - New `.rst` files in `hail/python/hail/docs/datasets` have been generated to reflect the available datasets in the config file, and `hail/python/hail/docs/datasets.rst` has been updated with the new files as well. Future updates:; - In next PR can add the functionality to automatically determine the users region.; - Also considering modifying the `load_datasets()` function a bit to only require one `version` parameter, to be consistent with the way the version strings are formatted in `annotation_db.json`, and to avoid having to check if the version and reference genome are available separately. Something like this:. ```; mt_1kg = hl.experimental.load_dataset(name='1000_Genomes_autosomes',; version='phase_3-GRCh37', ; region='us'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9496
https://github.com/hail-is/hail/pull/9496:2986,Availability,avail,available,2986," own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and raise a `ValueError`.; - Started to add documentation to the classes and methods, still a work in progress. Changes to datasets and datasets API site:; - Added the `ldsc_baselineLD_annotations`, `ldsc_baselineLD_ldscores`, and `ldsc_baseline_ldscores` datasets to the `annotation_db.json` configuration file. Now accessible via `load_dataset()` and `db.annotate_rows_db()` (for the annotations at least).; - New `.rst` files in `hail/python/hail/docs/datasets` have been generated to reflect the available datasets in the config file, and `hail/python/hail/docs/datasets.rst` has been updated with the new files as well. Future updates:; - In next PR can add the functionality to automatically determine the users region.; - Also considering modifying the `load_datasets()` function a bit to only require one `version` parameter, to be consistent with the way the version strings are formatted in `annotation_db.json`, and to avoid having to check if the version and reference genome are available separately. Something like this:. ```; mt_1kg = hl.experimental.load_dataset(name='1000_Genomes_autosomes',; version='phase_3-GRCh37', ; region='us'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9496
https://github.com/hail-is/hail/pull/9496:0,Deployability,Update,Updated,0,"Updated db.py to require user to specify region as shown below, so that data will be accessed from the requester pays bucket in the region specified by the user, available regions are `'us'` and `'eu'`. . `db = hl.experimental.DB(region='us')`; `mt = db.annotate_rows_db(mt, 'gnomad_lof_metrics')`. Entries in the `annotation_db.json` file were modified to the following format:. ```; ""dataset_name"": { ""description"": ""some description here"",; ""key_properties"": [],; ""url"": ""https://www.someurlhere.com"",; ""versions"": [{""url"": {""eu"": ""gs://hail-datasets-eu/dataset"",; ""us"": ""gs://hail-datasets-us/dataset""},; ""version"": ""one_version""},; {""url"": {""eu"": ""gs://hail-datasets-eu/dataset"",; ""us"": ""gs://hail-datasets-us/dataset""},; ""version"": ""another_version""}]}; ```. The `annotation_db.json` file is now used by the `load_dataset()` function in `datasets.py` as well, any dataset in the JSON file should now be able to be loaded this way. Made changes to the following:; - `DB` class now requires a `region` parameter.; - `Dataset.from_name_and_json()` has had a `custom_config` parameter added that indicates whether or not the user has supplied their own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and rai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9496
https://github.com/hail-is/hail/pull/9496:2287,Deployability,configurat,configuration,2287," own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and raise a `ValueError`.; - Started to add documentation to the classes and methods, still a work in progress. Changes to datasets and datasets API site:; - Added the `ldsc_baselineLD_annotations`, `ldsc_baselineLD_ldscores`, and `ldsc_baseline_ldscores` datasets to the `annotation_db.json` configuration file. Now accessible via `load_dataset()` and `db.annotate_rows_db()` (for the annotations at least).; - New `.rst` files in `hail/python/hail/docs/datasets` have been generated to reflect the available datasets in the config file, and `hail/python/hail/docs/datasets.rst` has been updated with the new files as well. Future updates:; - In next PR can add the functionality to automatically determine the users region.; - Also considering modifying the `load_datasets()` function a bit to only require one `version` parameter, to be consistent with the way the version strings are formatted in `annotation_db.json`, and to avoid having to check if the version and reference genome are available separately. Something like this:. ```; mt_1kg = hl.experimental.load_dataset(name='1000_Genomes_autosomes',; version='phase_3-GRCh37', ; region='us'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9496
https://github.com/hail-is/hail/pull/9496:2583,Deployability,update,updated,2583," own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and raise a `ValueError`.; - Started to add documentation to the classes and methods, still a work in progress. Changes to datasets and datasets API site:; - Added the `ldsc_baselineLD_annotations`, `ldsc_baselineLD_ldscores`, and `ldsc_baseline_ldscores` datasets to the `annotation_db.json` configuration file. Now accessible via `load_dataset()` and `db.annotate_rows_db()` (for the annotations at least).; - New `.rst` files in `hail/python/hail/docs/datasets` have been generated to reflect the available datasets in the config file, and `hail/python/hail/docs/datasets.rst` has been updated with the new files as well. Future updates:; - In next PR can add the functionality to automatically determine the users region.; - Also considering modifying the `load_datasets()` function a bit to only require one `version` parameter, to be consistent with the way the version strings are formatted in `annotation_db.json`, and to avoid having to check if the version and reference genome are available separately. Something like this:. ```; mt_1kg = hl.experimental.load_dataset(name='1000_Genomes_autosomes',; version='phase_3-GRCh37', ; region='us'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9496
https://github.com/hail-is/hail/pull/9496:2626,Deployability,update,updates,2626," own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and raise a `ValueError`.; - Started to add documentation to the classes and methods, still a work in progress. Changes to datasets and datasets API site:; - Added the `ldsc_baselineLD_annotations`, `ldsc_baselineLD_ldscores`, and `ldsc_baseline_ldscores` datasets to the `annotation_db.json` configuration file. Now accessible via `load_dataset()` and `db.annotate_rows_db()` (for the annotations at least).; - New `.rst` files in `hail/python/hail/docs/datasets` have been generated to reflect the available datasets in the config file, and `hail/python/hail/docs/datasets.rst` has been updated with the new files as well. Future updates:; - In next PR can add the functionality to automatically determine the users region.; - Also considering modifying the `load_datasets()` function a bit to only require one `version` parameter, to be consistent with the way the version strings are formatted in `annotation_db.json`, and to avoid having to check if the version and reference genome are available separately. Something like this:. ```; mt_1kg = hl.experimental.load_dataset(name='1000_Genomes_autosomes',; version='phase_3-GRCh37', ; region='us'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9496
https://github.com/hail-is/hail/pull/9496:1156,Modifiability,config,config,1156,"e requester pays bucket in the region specified by the user, available regions are `'us'` and `'eu'`. . `db = hl.experimental.DB(region='us')`; `mt = db.annotate_rows_db(mt, 'gnomad_lof_metrics')`. Entries in the `annotation_db.json` file were modified to the following format:. ```; ""dataset_name"": { ""description"": ""some description here"",; ""key_properties"": [],; ""url"": ""https://www.someurlhere.com"",; ""versions"": [{""url"": {""eu"": ""gs://hail-datasets-eu/dataset"",; ""us"": ""gs://hail-datasets-us/dataset""},; ""version"": ""one_version""},; {""url"": {""eu"": ""gs://hail-datasets-eu/dataset"",; ""us"": ""gs://hail-datasets-us/dataset""},; ""version"": ""another_version""}]}; ```. The `annotation_db.json` file is now used by the `load_dataset()` function in `datasets.py` as well, any dataset in the JSON file should now be able to be loaded this way. Made changes to the following:; - `DB` class now requires a `region` parameter.; - `Dataset.from_name_and_json()` has had a `custom_config` parameter added that indicates whether or not the user has supplied their own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and raise a `ValueError`.; - Started to add documentation to the classes and methods, still a work in progr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9496
https://github.com/hail-is/hail/pull/9496:2287,Modifiability,config,configuration,2287," own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and raise a `ValueError`.; - Started to add documentation to the classes and methods, still a work in progress. Changes to datasets and datasets API site:; - Added the `ldsc_baselineLD_annotations`, `ldsc_baselineLD_ldscores`, and `ldsc_baseline_ldscores` datasets to the `annotation_db.json` configuration file. Now accessible via `load_dataset()` and `db.annotate_rows_db()` (for the annotations at least).; - New `.rst` files in `hail/python/hail/docs/datasets` have been generated to reflect the available datasets in the config file, and `hail/python/hail/docs/datasets.rst` has been updated with the new files as well. Future updates:; - In next PR can add the functionality to automatically determine the users region.; - Also considering modifying the `load_datasets()` function a bit to only require one `version` parameter, to be consistent with the way the version strings are formatted in `annotation_db.json`, and to avoid having to check if the version and reference genome are available separately. Something like this:. ```; mt_1kg = hl.experimental.load_dataset(name='1000_Genomes_autosomes',; version='phase_3-GRCh37', ; region='us'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9496
https://github.com/hail-is/hail/pull/9496:2520,Modifiability,config,config,2520," own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and raise a `ValueError`.; - Started to add documentation to the classes and methods, still a work in progress. Changes to datasets and datasets API site:; - Added the `ldsc_baselineLD_annotations`, `ldsc_baselineLD_ldscores`, and `ldsc_baseline_ldscores` datasets to the `annotation_db.json` configuration file. Now accessible via `load_dataset()` and `db.annotate_rows_db()` (for the annotations at least).; - New `.rst` files in `hail/python/hail/docs/datasets` have been generated to reflect the available datasets in the config file, and `hail/python/hail/docs/datasets.rst` has been updated with the new files as well. Future updates:; - In next PR can add the functionality to automatically determine the users region.; - Also considering modifying the `load_datasets()` function a bit to only require one `version` parameter, to be consistent with the way the version strings are formatted in `annotation_db.json`, and to avoid having to check if the version and reference genome are available separately. Something like this:. ```; mt_1kg = hl.experimental.load_dataset(name='1000_Genomes_autosomes',; version='phase_3-GRCh37', ; region='us'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9496
https://github.com/hail-is/hail/pull/9496:920,Performance,load,loaded,920,"Updated db.py to require user to specify region as shown below, so that data will be accessed from the requester pays bucket in the region specified by the user, available regions are `'us'` and `'eu'`. . `db = hl.experimental.DB(region='us')`; `mt = db.annotate_rows_db(mt, 'gnomad_lof_metrics')`. Entries in the `annotation_db.json` file were modified to the following format:. ```; ""dataset_name"": { ""description"": ""some description here"",; ""key_properties"": [],; ""url"": ""https://www.someurlhere.com"",; ""versions"": [{""url"": {""eu"": ""gs://hail-datasets-eu/dataset"",; ""us"": ""gs://hail-datasets-us/dataset""},; ""version"": ""one_version""},; {""url"": {""eu"": ""gs://hail-datasets-eu/dataset"",; ""us"": ""gs://hail-datasets-us/dataset""},; ""version"": ""another_version""}]}; ```. The `annotation_db.json` file is now used by the `load_dataset()` function in `datasets.py` as well, any dataset in the JSON file should now be able to be loaded this way. Made changes to the following:; - `DB` class now requires a `region` parameter.; - `Dataset.from_name_and_json()` has had a `custom_config` parameter added that indicates whether or not the user has supplied their own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and rai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9496
https://github.com/hail-is/hail/pull/9496:2924,Safety,avoid,avoid,2924," own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and raise a `ValueError`.; - Started to add documentation to the classes and methods, still a work in progress. Changes to datasets and datasets API site:; - Added the `ldsc_baselineLD_annotations`, `ldsc_baselineLD_ldscores`, and `ldsc_baseline_ldscores` datasets to the `annotation_db.json` configuration file. Now accessible via `load_dataset()` and `db.annotate_rows_db()` (for the annotations at least).; - New `.rst` files in `hail/python/hail/docs/datasets` have been generated to reflect the available datasets in the config file, and `hail/python/hail/docs/datasets.rst` has been updated with the new files as well. Future updates:; - In next PR can add the functionality to automatically determine the users region.; - Also considering modifying the `load_datasets()` function a bit to only require one `version` parameter, to be consistent with the way the version strings are formatted in `annotation_db.json`, and to avoid having to check if the version and reference genome are available separately. Something like this:. ```; mt_1kg = hl.experimental.load_dataset(name='1000_Genomes_autosomes',; version='phase_3-GRCh37', ; region='us'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9496
https://github.com/hail-is/hail/pull/9496:85,Security,access,accessed,85,"Updated db.py to require user to specify region as shown below, so that data will be accessed from the requester pays bucket in the region specified by the user, available regions are `'us'` and `'eu'`. . `db = hl.experimental.DB(region='us')`; `mt = db.annotate_rows_db(mt, 'gnomad_lof_metrics')`. Entries in the `annotation_db.json` file were modified to the following format:. ```; ""dataset_name"": { ""description"": ""some description here"",; ""key_properties"": [],; ""url"": ""https://www.someurlhere.com"",; ""versions"": [{""url"": {""eu"": ""gs://hail-datasets-eu/dataset"",; ""us"": ""gs://hail-datasets-us/dataset""},; ""version"": ""one_version""},; {""url"": {""eu"": ""gs://hail-datasets-eu/dataset"",; ""us"": ""gs://hail-datasets-us/dataset""},; ""version"": ""another_version""}]}; ```. The `annotation_db.json` file is now used by the `load_dataset()` function in `datasets.py` as well, any dataset in the JSON file should now be able to be loaded this way. Made changes to the following:; - `DB` class now requires a `region` parameter.; - `Dataset.from_name_and_json()` has had a `custom_config` parameter added that indicates whether or not the user has supplied their own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and rai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9496
https://github.com/hail-is/hail/pull/9496:2311,Security,access,accessible,2311," own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and raise a `ValueError`.; - Started to add documentation to the classes and methods, still a work in progress. Changes to datasets and datasets API site:; - Added the `ldsc_baselineLD_annotations`, `ldsc_baselineLD_ldscores`, and `ldsc_baseline_ldscores` datasets to the `annotation_db.json` configuration file. Now accessible via `load_dataset()` and `db.annotate_rows_db()` (for the annotations at least).; - New `.rst` files in `hail/python/hail/docs/datasets` have been generated to reflect the available datasets in the config file, and `hail/python/hail/docs/datasets.rst` has been updated with the new files as well. Future updates:; - In next PR can add the functionality to automatically determine the users region.; - Also considering modifying the `load_datasets()` function a bit to only require one `version` parameter, to be consistent with the way the version strings are formatted in `annotation_db.json`, and to avoid having to check if the version and reference genome are available separately. Something like this:. ```; mt_1kg = hl.experimental.load_dataset(name='1000_Genomes_autosomes',; version='phase_3-GRCh37', ; region='us'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9496
https://github.com/hail-is/hail/pull/9497:82,Integrability,message,message,82,1. Correctly serialize Exceptions.; 2. Include a dictionary diff in the assertion message.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9497
https://github.com/hail-is/hail/pull/9497:72,Testability,assert,assertion,72,1. Correctly serialize Exceptions.; 2. Include a dictionary diff in the assertion message.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9497
https://github.com/hail-is/hail/pull/9499:487,Usability,simpl,simple,487,"This PR is a first step towards full debug information in generated bytecode. It lays the foundation in lir, and uses it to add line numbers to generated exceptions, which then show up in the stack trace. The line numbers are computed by taking the stack trace in `Code._fatal`, and finding the most recent line in `Emit.scala`, if any. Sometimes this will be less useful, e.g. exceptions thrown in aggregators, but it's a step. The design of the source location tracking in lir is very simple: every instruction has an associated line number, and `lir.Emit` watches for when the line numbers of the current and previous instruction are different, and emits the start of a new line number interval. This design might be slightly wasteful of memory, if we expect groups of several consecutive instructions to come from the same source line, but it's probably fine, and makes preserving the source location information through lir transformations trivial. In any case, I expect it to be easy to change in the future if necessary.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9499
https://github.com/hail-is/hail/pull/9501:158,Modifiability,config,configurable,158,"CHANGELOG: Remove memory leak in `BlockMatrix.to_matrix_table_row_major` and `BlockMatrix.to_table_row_major`. Also, make the cache size used in both methods configurable. The `ref` variable was holding entire blocks in memory for no reason. It was a; vestiage of debugging. Moreover, the configurable cache permits users to fine tune; memory usage.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9501
https://github.com/hail-is/hail/pull/9501:182,Modifiability,variab,variable,182,"CHANGELOG: Remove memory leak in `BlockMatrix.to_matrix_table_row_major` and `BlockMatrix.to_table_row_major`. Also, make the cache size used in both methods configurable. The `ref` variable was holding entire blocks in memory for no reason. It was a; vestiage of debugging. Moreover, the configurable cache permits users to fine tune; memory usage.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9501
https://github.com/hail-is/hail/pull/9501:289,Modifiability,config,configurable,289,"CHANGELOG: Remove memory leak in `BlockMatrix.to_matrix_table_row_major` and `BlockMatrix.to_table_row_major`. Also, make the cache size used in both methods configurable. The `ref` variable was holding entire blocks in memory for no reason. It was a; vestiage of debugging. Moreover, the configurable cache permits users to fine tune; memory usage.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9501
https://github.com/hail-is/hail/pull/9501:126,Performance,cache,cache,126,"CHANGELOG: Remove memory leak in `BlockMatrix.to_matrix_table_row_major` and `BlockMatrix.to_table_row_major`. Also, make the cache size used in both methods configurable. The `ref` variable was holding entire blocks in memory for no reason. It was a; vestiage of debugging. Moreover, the configurable cache permits users to fine tune; memory usage.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9501
https://github.com/hail-is/hail/pull/9501:302,Performance,cache,cache,302,"CHANGELOG: Remove memory leak in `BlockMatrix.to_matrix_table_row_major` and `BlockMatrix.to_table_row_major`. Also, make the cache size used in both methods configurable. The `ref` variable was holding entire blocks in memory for no reason. It was a; vestiage of debugging. Moreover, the configurable cache permits users to fine tune; memory usage.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9501
https://github.com/hail-is/hail/pull/9501:330,Performance,tune,tune,330,"CHANGELOG: Remove memory leak in `BlockMatrix.to_matrix_table_row_major` and `BlockMatrix.to_table_row_major`. Also, make the cache size used in both methods configurable. The `ref` variable was holding entire blocks in memory for no reason. It was a; vestiage of debugging. Moreover, the configurable cache permits users to fine tune; memory usage.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9501
https://github.com/hail-is/hail/pull/9502:42,Deployability,install,install,42,CHANGELOG: Fix hailctl dataproc modify to install dependencies of the wheel file.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9502
https://github.com/hail-is/hail/pull/9502:50,Integrability,depend,dependencies,50,CHANGELOG: Fix hailctl dataproc modify to install dependencies of the wheel file.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9502
https://github.com/hail-is/hail/pull/9503:529,Modifiability,flexible,flexible,529,"CHANGELOG: Fixed bug where making NDArrays of non-numeric types would fail. Non-numeric ndarrays still cannot be collected to python though. . NDArrays of non numeric types are broken, have been for a while. No one seems to use them for that currently, so it hasn't been an issue, but I suspect with `dndarray` or BlockedMatrixTable experiments it's going to be desirable. . This PR starts to address that problem by doing the following:. 1. `checkedConvertFrom`, which only supported primitive arrays, is replaced with the more flexible `copyFromType`. As this was the only use of `checkedConvertFrom`, I removed it altogether. . 2. Add tests that show that it's now possible to make an ndarray of non-numeric types, so long as the only things that get returned in python are numbers. The remaining problems all involve conversions to numpy. If you never convert to numpy, things should be fine:. 1. I need to get strides out of the Java ndarray representation. Strides make no sense for non-numeric objects after converting from Java to Python. We say the size of a required tuple of 3 int32's is 12 bytes, but that's not going to be the size of the python object. 2. Strings are tricky too, since the numpy string dtype comes with a max length, so we'll have to do a pass over the strings to figure out how large the largest one is before converting.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9503
https://github.com/hail-is/hail/pull/9503:638,Testability,test,tests,638,"CHANGELOG: Fixed bug where making NDArrays of non-numeric types would fail. Non-numeric ndarrays still cannot be collected to python though. . NDArrays of non numeric types are broken, have been for a while. No one seems to use them for that currently, so it hasn't been an issue, but I suspect with `dndarray` or BlockedMatrixTable experiments it's going to be desirable. . This PR starts to address that problem by doing the following:. 1. `checkedConvertFrom`, which only supported primitive arrays, is replaced with the more flexible `copyFromType`. As this was the only use of `checkedConvertFrom`, I removed it altogether. . 2. Add tests that show that it's now possible to make an ndarray of non-numeric types, so long as the only things that get returned in python are numbers. The remaining problems all involve conversions to numpy. If you never convert to numpy, things should be fine:. 1. I need to get strides out of the Java ndarray representation. Strides make no sense for non-numeric objects after converting from Java to Python. We say the size of a required tuple of 3 int32's is 12 bytes, but that's not going to be the size of the python object. 2. Strings are tricky too, since the numpy string dtype comes with a max length, so we'll have to do a pass over the strings to figure out how large the largest one is before converting.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9503
https://github.com/hail-is/hail/pull/9504:13,Integrability,message,messages,13,More logging messages.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9504
https://github.com/hail-is/hail/pull/9504:5,Testability,log,logging,5,More logging messages.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9504
https://github.com/hail-is/hail/pull/9506:113,Testability,test,tests,113,I wanted a quick way to set global feature flags on the service backend. Also took the opportunity to move query tests into their own file.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9506
https://github.com/hail-is/hail/pull/9510:10,Safety,avoid,avoid,10,This will avoid extra requests especially since most batches statuses; will not change (most batches are finished). The new function last_known_status() will make an HTTP request if and; only if the saved status is None.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9510
https://github.com/hail-is/hail/pull/9511:82,Integrability,interface,interface,82,"This is a simple refactoring of `lir.Emit` to directly use the core visitor based interface of ASM, rather than the higher level `tree` interface. This should have a small performance benefit, as we aren't building the in-memory tree representation only to immediately walk it with a visitor. But I also find this version of `Emit` slightly cleaner. For reference, you can find the documentation for ASM 5.1 [here](https://javadoc.io/doc/org.ow2.asm/asm/5.1/index.html).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9511
https://github.com/hail-is/hail/pull/9511:136,Integrability,interface,interface,136,"This is a simple refactoring of `lir.Emit` to directly use the core visitor based interface of ASM, rather than the higher level `tree` interface. This should have a small performance benefit, as we aren't building the in-memory tree representation only to immediately walk it with a visitor. But I also find this version of `Emit` slightly cleaner. For reference, you can find the documentation for ASM 5.1 [here](https://javadoc.io/doc/org.ow2.asm/asm/5.1/index.html).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9511
https://github.com/hail-is/hail/pull/9511:17,Modifiability,refactor,refactoring,17,"This is a simple refactoring of `lir.Emit` to directly use the core visitor based interface of ASM, rather than the higher level `tree` interface. This should have a small performance benefit, as we aren't building the in-memory tree representation only to immediately walk it with a visitor. But I also find this version of `Emit` slightly cleaner. For reference, you can find the documentation for ASM 5.1 [here](https://javadoc.io/doc/org.ow2.asm/asm/5.1/index.html).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9511
https://github.com/hail-is/hail/pull/9511:172,Performance,perform,performance,172,"This is a simple refactoring of `lir.Emit` to directly use the core visitor based interface of ASM, rather than the higher level `tree` interface. This should have a small performance benefit, as we aren't building the in-memory tree representation only to immediately walk it with a visitor. But I also find this version of `Emit` slightly cleaner. For reference, you can find the documentation for ASM 5.1 [here](https://javadoc.io/doc/org.ow2.asm/asm/5.1/index.html).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9511
https://github.com/hail-is/hail/pull/9511:10,Usability,simpl,simple,10,"This is a simple refactoring of `lir.Emit` to directly use the core visitor based interface of ASM, rather than the higher level `tree` interface. This should have a small performance benefit, as we aren't building the in-memory tree representation only to immediately walk it with a visitor. But I also find this version of `Emit` slightly cleaner. For reference, you can find the documentation for ASM 5.1 [here](https://javadoc.io/doc/org.ow2.asm/asm/5.1/index.html).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9511
https://github.com/hail-is/hail/pull/9513:52,Testability,test,tests,52,"This PR:. 1. Creates test_pca.py, moves current PCA tests there.; 2. Adds several new tests based on Section 7 of https://arxiv.org/pdf/1412.3510.pdf. The idea is to test different singular value spectra (i.e. gradual decay, rapid decay, big cliff in the middle, etc.). The new test is a little slow. It takes ~2 minutes to run altogether.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9513
https://github.com/hail-is/hail/pull/9513:86,Testability,test,tests,86,"This PR:. 1. Creates test_pca.py, moves current PCA tests there.; 2. Adds several new tests based on Section 7 of https://arxiv.org/pdf/1412.3510.pdf. The idea is to test different singular value spectra (i.e. gradual decay, rapid decay, big cliff in the middle, etc.). The new test is a little slow. It takes ~2 minutes to run altogether.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9513
https://github.com/hail-is/hail/pull/9513:166,Testability,test,test,166,"This PR:. 1. Creates test_pca.py, moves current PCA tests there.; 2. Adds several new tests based on Section 7 of https://arxiv.org/pdf/1412.3510.pdf. The idea is to test different singular value spectra (i.e. gradual decay, rapid decay, big cliff in the middle, etc.). The new test is a little slow. It takes ~2 minutes to run altogether.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9513
https://github.com/hail-is/hail/pull/9513:278,Testability,test,test,278,"This PR:. 1. Creates test_pca.py, moves current PCA tests there.; 2. Adds several new tests based on Section 7 of https://arxiv.org/pdf/1412.3510.pdf. The idea is to test different singular value spectra (i.e. gradual decay, rapid decay, big cliff in the middle, etc.). The new test is a little slow. It takes ~2 minutes to run altogether.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9513
https://github.com/hail-is/hail/pull/9514:14,Integrability,message,message,14,The exception message will now have the metadata path to more easily; assist in diagnosing issues.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9514
https://github.com/hail-is/hail/pull/9515:44,Availability,avail,available,44,CHANGELOG: The `Resource` class is now also available at hailtop.batch.Resource.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9515
https://github.com/hail-is/hail/pull/9520:307,Energy Efficiency,charge,charges,307,"Currently, there is no way to use `hailctl dataproc describe` on a table in a [requester pays](https://cloud.google.com/storage/docs/requester-pays) bucket. Accessing files in requester pays buckets requires adding a `-u` flag to `gsutil` with the project to bill for operation, network, and data retrieval charges. https://cloud.google.com/storage/docs/using-requester-pays#using",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9520
https://github.com/hail-is/hail/pull/9520:157,Security,Access,Accessing,157,"Currently, there is no way to use `hailctl dataproc describe` on a table in a [requester pays](https://cloud.google.com/storage/docs/requester-pays) bucket. Accessing files in requester pays buckets requires adding a `-u` flag to `gsutil` with the project to bill for operation, network, and data retrieval charges. https://cloud.google.com/storage/docs/using-requester-pays#using",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9520
https://github.com/hail-is/hail/pull/9521:839,Availability,checkpoint,checkpoint,839,"This PR is a step towards a general picture for generating debugging information in bytecode. The general picture is to write a sequence of files, each corresponding to a certain point in the compile pipeline, where each line in each file includes a line number pointing to the line in the previous file from which this line was derived. (We may eventually want richer source information than just a single line number, like a range or list of ranges.) The top of each file has the file name of the previous printout, which is the target of all line numbers in the file. We could in the future also print a list of transformations that were applied to get from the previous printed state to this one. The idea to implement this picture is simple. Each IR node stores a line number in a mutable variable. When we want to generate a printed checkpoint, we walk the IR, printing a representation of each node, including the stored line number, and then overwriting the node's line number with the current line count of the file being written to. Some work will be required to preserve this source information in all IR transformations. This PR implements this idea in lir only. If the `HAIL_WRITE_IR_FILES` environment variable is set, it is hardcoded to print the lir after the first `SimplifyControl` (because before that is very hard to read), and after method splitting right before emitting bytecode. It also prints out the class files themselves. Longer term we'll want to be able to control which points in the compilation get printed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9521
https://github.com/hail-is/hail/pull/9521:200,Deployability,pipeline,pipeline,200,"This PR is a step towards a general picture for generating debugging information in bytecode. The general picture is to write a sequence of files, each corresponding to a certain point in the compile pipeline, where each line in each file includes a line number pointing to the line in the previous file from which this line was derived. (We may eventually want richer source information than just a single line number, like a range or list of ranges.) The top of each file has the file name of the previous printout, which is the target of all line numbers in the file. We could in the future also print a list of transformations that were applied to get from the previous printed state to this one. The idea to implement this picture is simple. Each IR node stores a line number in a mutable variable. When we want to generate a printed checkpoint, we walk the IR, printing a representation of each node, including the stored line number, and then overwriting the node's line number with the current line count of the file being written to. Some work will be required to preserve this source information in all IR transformations. This PR implements this idea in lir only. If the `HAIL_WRITE_IR_FILES` environment variable is set, it is hardcoded to print the lir after the first `SimplifyControl` (because before that is very hard to read), and after method splitting right before emitting bytecode. It also prints out the class files themselves. Longer term we'll want to be able to control which points in the compilation get printed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9521
https://github.com/hail-is/hail/pull/9521:794,Modifiability,variab,variable,794,"This PR is a step towards a general picture for generating debugging information in bytecode. The general picture is to write a sequence of files, each corresponding to a certain point in the compile pipeline, where each line in each file includes a line number pointing to the line in the previous file from which this line was derived. (We may eventually want richer source information than just a single line number, like a range or list of ranges.) The top of each file has the file name of the previous printout, which is the target of all line numbers in the file. We could in the future also print a list of transformations that were applied to get from the previous printed state to this one. The idea to implement this picture is simple. Each IR node stores a line number in a mutable variable. When we want to generate a printed checkpoint, we walk the IR, printing a representation of each node, including the stored line number, and then overwriting the node's line number with the current line count of the file being written to. Some work will be required to preserve this source information in all IR transformations. This PR implements this idea in lir only. If the `HAIL_WRITE_IR_FILES` environment variable is set, it is hardcoded to print the lir after the first `SimplifyControl` (because before that is very hard to read), and after method splitting right before emitting bytecode. It also prints out the class files themselves. Longer term we'll want to be able to control which points in the compilation get printed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9521
https://github.com/hail-is/hail/pull/9521:1216,Modifiability,variab,variable,1216,"This PR is a step towards a general picture for generating debugging information in bytecode. The general picture is to write a sequence of files, each corresponding to a certain point in the compile pipeline, where each line in each file includes a line number pointing to the line in the previous file from which this line was derived. (We may eventually want richer source information than just a single line number, like a range or list of ranges.) The top of each file has the file name of the previous printout, which is the target of all line numbers in the file. We could in the future also print a list of transformations that were applied to get from the previous printed state to this one. The idea to implement this picture is simple. Each IR node stores a line number in a mutable variable. When we want to generate a printed checkpoint, we walk the IR, printing a representation of each node, including the stored line number, and then overwriting the node's line number with the current line count of the file being written to. Some work will be required to preserve this source information in all IR transformations. This PR implements this idea in lir only. If the `HAIL_WRITE_IR_FILES` environment variable is set, it is hardcoded to print the lir after the first `SimplifyControl` (because before that is very hard to read), and after method splitting right before emitting bytecode. It also prints out the class files themselves. Longer term we'll want to be able to control which points in the compilation get printed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9521
https://github.com/hail-is/hail/pull/9521:739,Usability,simpl,simple,739,"This PR is a step towards a general picture for generating debugging information in bytecode. The general picture is to write a sequence of files, each corresponding to a certain point in the compile pipeline, where each line in each file includes a line number pointing to the line in the previous file from which this line was derived. (We may eventually want richer source information than just a single line number, like a range or list of ranges.) The top of each file has the file name of the previous printout, which is the target of all line numbers in the file. We could in the future also print a list of transformations that were applied to get from the previous printed state to this one. The idea to implement this picture is simple. Each IR node stores a line number in a mutable variable. When we want to generate a printed checkpoint, we walk the IR, printing a representation of each node, including the stored line number, and then overwriting the node's line number with the current line count of the file being written to. Some work will be required to preserve this source information in all IR transformations. This PR implements this idea in lir only. If the `HAIL_WRITE_IR_FILES` environment variable is set, it is hardcoded to print the lir after the first `SimplifyControl` (because before that is very hard to read), and after method splitting right before emitting bytecode. It also prints out the class files themselves. Longer term we'll want to be able to control which points in the compilation get printed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9521
https://github.com/hail-is/hail/pull/9521:1283,Usability,Simpl,SimplifyControl,1283,"This PR is a step towards a general picture for generating debugging information in bytecode. The general picture is to write a sequence of files, each corresponding to a certain point in the compile pipeline, where each line in each file includes a line number pointing to the line in the previous file from which this line was derived. (We may eventually want richer source information than just a single line number, like a range or list of ranges.) The top of each file has the file name of the previous printout, which is the target of all line numbers in the file. We could in the future also print a list of transformations that were applied to get from the previous printed state to this one. The idea to implement this picture is simple. Each IR node stores a line number in a mutable variable. When we want to generate a printed checkpoint, we walk the IR, printing a representation of each node, including the stored line number, and then overwriting the node's line number with the current line count of the file being written to. Some work will be required to preserve this source information in all IR transformations. This PR implements this idea in lir only. If the `HAIL_WRITE_IR_FILES` environment variable is set, it is hardcoded to print the lir after the first `SimplifyControl` (because before that is very hard to read), and after method splitting right before emitting bytecode. It also prints out the class files themselves. Longer term we'll want to be able to control which points in the compilation get printed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9521
https://github.com/hail-is/hail/pull/9523:129,Deployability,Update,Update,129,"flock(2) does not prevent other processes from doing anything to the; locked file unless they also gate usages on an flock call. Update Flock; to open only one descriptor, the directory that is the parent of `path`,; creating said directory if it doesn't exist. The semantics have changed slightly. Previously if path was an already; extant directory, it would be opened and that descriptor would be; flocked. Now, the parent is always locked.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9523
https://github.com/hail-is/hail/pull/9524:869,Availability,Down,Downgraded,869,"Although Dataproc does not have a public Spark 3-based GA release schedule yet, it'd probably be helpful to start supporting a Spark 3 build; tagging @tpoterba for context. I'm not familiar with the release process internally, so let me know what other changes need to be made to accommodate this. In particular, this PR likely needs to change the PySpark requirements specified in https://github.com/hail-is/hail/blob/main/hail/python/requirements.txt. This PR builds on changes from #9199. The code changes are due to Scala 2.12 and Spark 3 changes:. - `y` in `x << y` must be an int; - `mutable.Stack` is deprecated; - `JavaConversions` is deprecated; - `addTaskCompletionListener` is overloaded; - `Row.merge()` is deprecated. The build changes are as follows:. - Upgraded Breeze from 1.0 to 1.1 due to a known bug: https://github.com/scalanlp/breeze/issues/772; - Downgraded from Json4s 3.7.0-M5 to 3.5.3 due to a known bug: https://github.com/json4s/json4s/issues/507; - Upgraded to `scalatest 3.0.5` for Scala 2.12 compatibility; - Update the `pyspark` version in `python/requirements.txt` to match `SCALA_VERSION` during `make install-deps`. The following testing commands pass (at least to the degree that `main` does):. - `make -j8 test SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.5`; - `make -j8 test SCALA_VERSION=2.12.8 SPARK_VERSION=3.0.0`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9524
https://github.com/hail-is/hail/pull/9524:58,Deployability,release,release,58,"Although Dataproc does not have a public Spark 3-based GA release schedule yet, it'd probably be helpful to start supporting a Spark 3 build; tagging @tpoterba for context. I'm not familiar with the release process internally, so let me know what other changes need to be made to accommodate this. In particular, this PR likely needs to change the PySpark requirements specified in https://github.com/hail-is/hail/blob/main/hail/python/requirements.txt. This PR builds on changes from #9199. The code changes are due to Scala 2.12 and Spark 3 changes:. - `y` in `x << y` must be an int; - `mutable.Stack` is deprecated; - `JavaConversions` is deprecated; - `addTaskCompletionListener` is overloaded; - `Row.merge()` is deprecated. The build changes are as follows:. - Upgraded Breeze from 1.0 to 1.1 due to a known bug: https://github.com/scalanlp/breeze/issues/772; - Downgraded from Json4s 3.7.0-M5 to 3.5.3 due to a known bug: https://github.com/json4s/json4s/issues/507; - Upgraded to `scalatest 3.0.5` for Scala 2.12 compatibility; - Update the `pyspark` version in `python/requirements.txt` to match `SCALA_VERSION` during `make install-deps`. The following testing commands pass (at least to the degree that `main` does):. - `make -j8 test SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.5`; - `make -j8 test SCALA_VERSION=2.12.8 SPARK_VERSION=3.0.0`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9524
https://github.com/hail-is/hail/pull/9524:199,Deployability,release,release,199,"Although Dataproc does not have a public Spark 3-based GA release schedule yet, it'd probably be helpful to start supporting a Spark 3 build; tagging @tpoterba for context. I'm not familiar with the release process internally, so let me know what other changes need to be made to accommodate this. In particular, this PR likely needs to change the PySpark requirements specified in https://github.com/hail-is/hail/blob/main/hail/python/requirements.txt. This PR builds on changes from #9199. The code changes are due to Scala 2.12 and Spark 3 changes:. - `y` in `x << y` must be an int; - `mutable.Stack` is deprecated; - `JavaConversions` is deprecated; - `addTaskCompletionListener` is overloaded; - `Row.merge()` is deprecated. The build changes are as follows:. - Upgraded Breeze from 1.0 to 1.1 due to a known bug: https://github.com/scalanlp/breeze/issues/772; - Downgraded from Json4s 3.7.0-M5 to 3.5.3 due to a known bug: https://github.com/json4s/json4s/issues/507; - Upgraded to `scalatest 3.0.5` for Scala 2.12 compatibility; - Update the `pyspark` version in `python/requirements.txt` to match `SCALA_VERSION` during `make install-deps`. The following testing commands pass (at least to the degree that `main` does):. - `make -j8 test SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.5`; - `make -j8 test SCALA_VERSION=2.12.8 SPARK_VERSION=3.0.0`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9524
https://github.com/hail-is/hail/pull/9524:768,Deployability,Upgrade,Upgraded,768,"Although Dataproc does not have a public Spark 3-based GA release schedule yet, it'd probably be helpful to start supporting a Spark 3 build; tagging @tpoterba for context. I'm not familiar with the release process internally, so let me know what other changes need to be made to accommodate this. In particular, this PR likely needs to change the PySpark requirements specified in https://github.com/hail-is/hail/blob/main/hail/python/requirements.txt. This PR builds on changes from #9199. The code changes are due to Scala 2.12 and Spark 3 changes:. - `y` in `x << y` must be an int; - `mutable.Stack` is deprecated; - `JavaConversions` is deprecated; - `addTaskCompletionListener` is overloaded; - `Row.merge()` is deprecated. The build changes are as follows:. - Upgraded Breeze from 1.0 to 1.1 due to a known bug: https://github.com/scalanlp/breeze/issues/772; - Downgraded from Json4s 3.7.0-M5 to 3.5.3 due to a known bug: https://github.com/json4s/json4s/issues/507; - Upgraded to `scalatest 3.0.5` for Scala 2.12 compatibility; - Update the `pyspark` version in `python/requirements.txt` to match `SCALA_VERSION` during `make install-deps`. The following testing commands pass (at least to the degree that `main` does):. - `make -j8 test SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.5`; - `make -j8 test SCALA_VERSION=2.12.8 SPARK_VERSION=3.0.0`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9524
https://github.com/hail-is/hail/pull/9524:977,Deployability,Upgrade,Upgraded,977,"Although Dataproc does not have a public Spark 3-based GA release schedule yet, it'd probably be helpful to start supporting a Spark 3 build; tagging @tpoterba for context. I'm not familiar with the release process internally, so let me know what other changes need to be made to accommodate this. In particular, this PR likely needs to change the PySpark requirements specified in https://github.com/hail-is/hail/blob/main/hail/python/requirements.txt. This PR builds on changes from #9199. The code changes are due to Scala 2.12 and Spark 3 changes:. - `y` in `x << y` must be an int; - `mutable.Stack` is deprecated; - `JavaConversions` is deprecated; - `addTaskCompletionListener` is overloaded; - `Row.merge()` is deprecated. The build changes are as follows:. - Upgraded Breeze from 1.0 to 1.1 due to a known bug: https://github.com/scalanlp/breeze/issues/772; - Downgraded from Json4s 3.7.0-M5 to 3.5.3 due to a known bug: https://github.com/json4s/json4s/issues/507; - Upgraded to `scalatest 3.0.5` for Scala 2.12 compatibility; - Update the `pyspark` version in `python/requirements.txt` to match `SCALA_VERSION` during `make install-deps`. The following testing commands pass (at least to the degree that `main` does):. - `make -j8 test SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.5`; - `make -j8 test SCALA_VERSION=2.12.8 SPARK_VERSION=3.0.0`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9524
https://github.com/hail-is/hail/pull/9524:1039,Deployability,Update,Update,1039,"Although Dataproc does not have a public Spark 3-based GA release schedule yet, it'd probably be helpful to start supporting a Spark 3 build; tagging @tpoterba for context. I'm not familiar with the release process internally, so let me know what other changes need to be made to accommodate this. In particular, this PR likely needs to change the PySpark requirements specified in https://github.com/hail-is/hail/blob/main/hail/python/requirements.txt. This PR builds on changes from #9199. The code changes are due to Scala 2.12 and Spark 3 changes:. - `y` in `x << y` must be an int; - `mutable.Stack` is deprecated; - `JavaConversions` is deprecated; - `addTaskCompletionListener` is overloaded; - `Row.merge()` is deprecated. The build changes are as follows:. - Upgraded Breeze from 1.0 to 1.1 due to a known bug: https://github.com/scalanlp/breeze/issues/772; - Downgraded from Json4s 3.7.0-M5 to 3.5.3 due to a known bug: https://github.com/json4s/json4s/issues/507; - Upgraded to `scalatest 3.0.5` for Scala 2.12 compatibility; - Update the `pyspark` version in `python/requirements.txt` to match `SCALA_VERSION` during `make install-deps`. The following testing commands pass (at least to the degree that `main` does):. - `make -j8 test SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.5`; - `make -j8 test SCALA_VERSION=2.12.8 SPARK_VERSION=3.0.0`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9524
https://github.com/hail-is/hail/pull/9524:1135,Deployability,install,install-deps,1135,"Although Dataproc does not have a public Spark 3-based GA release schedule yet, it'd probably be helpful to start supporting a Spark 3 build; tagging @tpoterba for context. I'm not familiar with the release process internally, so let me know what other changes need to be made to accommodate this. In particular, this PR likely needs to change the PySpark requirements specified in https://github.com/hail-is/hail/blob/main/hail/python/requirements.txt. This PR builds on changes from #9199. The code changes are due to Scala 2.12 and Spark 3 changes:. - `y` in `x << y` must be an int; - `mutable.Stack` is deprecated; - `JavaConversions` is deprecated; - `addTaskCompletionListener` is overloaded; - `Row.merge()` is deprecated. The build changes are as follows:. - Upgraded Breeze from 1.0 to 1.1 due to a known bug: https://github.com/scalanlp/breeze/issues/772; - Downgraded from Json4s 3.7.0-M5 to 3.5.3 due to a known bug: https://github.com/json4s/json4s/issues/507; - Upgraded to `scalatest 3.0.5` for Scala 2.12 compatibility; - Update the `pyspark` version in `python/requirements.txt` to match `SCALA_VERSION` during `make install-deps`. The following testing commands pass (at least to the degree that `main` does):. - `make -j8 test SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.5`; - `make -j8 test SCALA_VERSION=2.12.8 SPARK_VERSION=3.0.0`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9524
https://github.com/hail-is/hail/pull/9524:66,Energy Efficiency,schedul,schedule,66,"Although Dataproc does not have a public Spark 3-based GA release schedule yet, it'd probably be helpful to start supporting a Spark 3 build; tagging @tpoterba for context. I'm not familiar with the release process internally, so let me know what other changes need to be made to accommodate this. In particular, this PR likely needs to change the PySpark requirements specified in https://github.com/hail-is/hail/blob/main/hail/python/requirements.txt. This PR builds on changes from #9199. The code changes are due to Scala 2.12 and Spark 3 changes:. - `y` in `x << y` must be an int; - `mutable.Stack` is deprecated; - `JavaConversions` is deprecated; - `addTaskCompletionListener` is overloaded; - `Row.merge()` is deprecated. The build changes are as follows:. - Upgraded Breeze from 1.0 to 1.1 due to a known bug: https://github.com/scalanlp/breeze/issues/772; - Downgraded from Json4s 3.7.0-M5 to 3.5.3 due to a known bug: https://github.com/json4s/json4s/issues/507; - Upgraded to `scalatest 3.0.5` for Scala 2.12 compatibility; - Update the `pyspark` version in `python/requirements.txt` to match `SCALA_VERSION` during `make install-deps`. The following testing commands pass (at least to the degree that `main` does):. - `make -j8 test SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.5`; - `make -j8 test SCALA_VERSION=2.12.8 SPARK_VERSION=3.0.0`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9524
https://github.com/hail-is/hail/pull/9524:1164,Testability,test,testing,1164,"Although Dataproc does not have a public Spark 3-based GA release schedule yet, it'd probably be helpful to start supporting a Spark 3 build; tagging @tpoterba for context. I'm not familiar with the release process internally, so let me know what other changes need to be made to accommodate this. In particular, this PR likely needs to change the PySpark requirements specified in https://github.com/hail-is/hail/blob/main/hail/python/requirements.txt. This PR builds on changes from #9199. The code changes are due to Scala 2.12 and Spark 3 changes:. - `y` in `x << y` must be an int; - `mutable.Stack` is deprecated; - `JavaConversions` is deprecated; - `addTaskCompletionListener` is overloaded; - `Row.merge()` is deprecated. The build changes are as follows:. - Upgraded Breeze from 1.0 to 1.1 due to a known bug: https://github.com/scalanlp/breeze/issues/772; - Downgraded from Json4s 3.7.0-M5 to 3.5.3 due to a known bug: https://github.com/json4s/json4s/issues/507; - Upgraded to `scalatest 3.0.5` for Scala 2.12 compatibility; - Update the `pyspark` version in `python/requirements.txt` to match `SCALA_VERSION` during `make install-deps`. The following testing commands pass (at least to the degree that `main` does):. - `make -j8 test SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.5`; - `make -j8 test SCALA_VERSION=2.12.8 SPARK_VERSION=3.0.0`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9524
https://github.com/hail-is/hail/pull/9524:1242,Testability,test,test,1242,"Although Dataproc does not have a public Spark 3-based GA release schedule yet, it'd probably be helpful to start supporting a Spark 3 build; tagging @tpoterba for context. I'm not familiar with the release process internally, so let me know what other changes need to be made to accommodate this. In particular, this PR likely needs to change the PySpark requirements specified in https://github.com/hail-is/hail/blob/main/hail/python/requirements.txt. This PR builds on changes from #9199. The code changes are due to Scala 2.12 and Spark 3 changes:. - `y` in `x << y` must be an int; - `mutable.Stack` is deprecated; - `JavaConversions` is deprecated; - `addTaskCompletionListener` is overloaded; - `Row.merge()` is deprecated. The build changes are as follows:. - Upgraded Breeze from 1.0 to 1.1 due to a known bug: https://github.com/scalanlp/breeze/issues/772; - Downgraded from Json4s 3.7.0-M5 to 3.5.3 due to a known bug: https://github.com/json4s/json4s/issues/507; - Upgraded to `scalatest 3.0.5` for Scala 2.12 compatibility; - Update the `pyspark` version in `python/requirements.txt` to match `SCALA_VERSION` during `make install-deps`. The following testing commands pass (at least to the degree that `main` does):. - `make -j8 test SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.5`; - `make -j8 test SCALA_VERSION=2.12.8 SPARK_VERSION=3.0.0`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9524
https://github.com/hail-is/hail/pull/9524:1303,Testability,test,test,1303,"Although Dataproc does not have a public Spark 3-based GA release schedule yet, it'd probably be helpful to start supporting a Spark 3 build; tagging @tpoterba for context. I'm not familiar with the release process internally, so let me know what other changes need to be made to accommodate this. In particular, this PR likely needs to change the PySpark requirements specified in https://github.com/hail-is/hail/blob/main/hail/python/requirements.txt. This PR builds on changes from #9199. The code changes are due to Scala 2.12 and Spark 3 changes:. - `y` in `x << y` must be an int; - `mutable.Stack` is deprecated; - `JavaConversions` is deprecated; - `addTaskCompletionListener` is overloaded; - `Row.merge()` is deprecated. The build changes are as follows:. - Upgraded Breeze from 1.0 to 1.1 due to a known bug: https://github.com/scalanlp/breeze/issues/772; - Downgraded from Json4s 3.7.0-M5 to 3.5.3 due to a known bug: https://github.com/json4s/json4s/issues/507; - Upgraded to `scalatest 3.0.5` for Scala 2.12 compatibility; - Update the `pyspark` version in `python/requirements.txt` to match `SCALA_VERSION` during `make install-deps`. The following testing commands pass (at least to the degree that `main` does):. - `make -j8 test SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.5`; - `make -j8 test SCALA_VERSION=2.12.8 SPARK_VERSION=3.0.0`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9524
https://github.com/hail-is/hail/pull/9525:82,Modifiability,variab,variable,82,"As stated in the GNU make manual, ""Recursive make commands should always; use the variable MAKE, not the explicit command name make"". https://www.gnu.org/software/make/manual/make.html#MAKE-Variable",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9525
https://github.com/hail-is/hail/pull/9525:192,Modifiability,Variab,Variable,192,"As stated in the GNU make manual, ""Recursive make commands should always; use the variable MAKE, not the explicit command name make"". https://www.gnu.org/software/make/manual/make.html#MAKE-Variable",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9525
https://github.com/hail-is/hail/pull/9526:108,Safety,safe,safe,108,"We generate these a lot as intermediates when we manually build service images. I think it should be pretty safe to ignore all of these, since I don't know of anything we need to check in with that extension.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9526
https://github.com/hail-is/hail/pull/9527:97,Testability,test,tested,97,CHANGELOG: Added concatenate and plink_merge functions that use tree aggregation when merging. I tested the PLINK function locally since we don't have tests that use PLINK (can't remember exactly why).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9527
https://github.com/hail-is/hail/pull/9527:151,Testability,test,tests,151,CHANGELOG: Added concatenate and plink_merge functions that use tree aggregation when merging. I tested the PLINK function locally since we don't have tests that use PLINK (can't remember exactly why).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9527
https://github.com/hail-is/hail/pull/9529:16,Modifiability,config,config,16,Syntax: hailctl config list [section]. Output (for each value):; ```; with no section specified:; {section}/{key}={value}; with a section specified:; {key}={value}; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9529
https://github.com/hail-is/hail/pull/9530:134,Testability,test,tests,134,This reverts commit 06b5a9ad7e10a564fc8fc848826beb3c445425db. 9506 modified a migration file which is not permitted. It passes the PR tests because the PR test environment doesn't use an extant database schema. We should really test that the migration works for an extant database ... . We could at least check that none of the SQL files are modified in the current commit.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9530
https://github.com/hail-is/hail/pull/9530:155,Testability,test,test,155,This reverts commit 06b5a9ad7e10a564fc8fc848826beb3c445425db. 9506 modified a migration file which is not permitted. It passes the PR tests because the PR test environment doesn't use an extant database schema. We should really test that the migration works for an extant database ... . We could at least check that none of the SQL files are modified in the current commit.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9530
https://github.com/hail-is/hail/pull/9530:228,Testability,test,test,228,This reverts commit 06b5a9ad7e10a564fc8fc848826beb3c445425db. 9506 modified a migration file which is not permitted. It passes the PR tests because the PR test environment doesn't use an extant database schema. We should really test that the migration works for an extant database ... . We could at least check that none of the SQL files are modified in the current commit.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9530
https://github.com/hail-is/hail/pull/9533:13,Modifiability,variab,variable,13,Save it to a variable and pass it to standard input using a heredoc; instead of a gnarly command line argument. This still outputs the; config to the logs/job output since the variable assignment expression; will be printed with `set -x`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9533
https://github.com/hail-is/hail/pull/9533:136,Modifiability,config,config,136,Save it to a variable and pass it to standard input using a heredoc; instead of a gnarly command line argument. This still outputs the; config to the logs/job output since the variable assignment expression; will be printed with `set -x`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9533
https://github.com/hail-is/hail/pull/9533:176,Modifiability,variab,variable,176,Save it to a variable and pass it to standard input using a heredoc; instead of a gnarly command line argument. This still outputs the; config to the logs/job output since the variable assignment expression; will be printed with `set -x`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9533
https://github.com/hail-is/hail/pull/9533:150,Testability,log,logs,150,Save it to a variable and pass it to standard input using a heredoc; instead of a gnarly command line argument. This still outputs the; config to the logs/job output since the variable assignment expression; will be printed with `set -x`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9533
https://github.com/hail-is/hail/pull/9537:200,Integrability,message,message,200,"Spark 3 resolved the issues with library changes python 3.8, so we can; now use python 3.8 as long as pyspark is version 3 or greater. I also took this opertunity to make every link in or welcome doc message; a canonical https link that will be recognized as such by many parsers; such as sufficiently advanced terminal emulators.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9537
https://github.com/hail-is/hail/pull/9542:34,Deployability,deploy,deployment,34,We started using the scope in the deployment.yaml. This addes it to the JINJA_ENVIRONMENT; in the Makefile.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9542
https://github.com/hail-is/hail/pull/9543:55,Availability,error,error,55,"CHANGELOG: BatchPoolExecutor now raises an informative error message for a variety of ""system"" errors, such as missing container images. If the main container fails for reasons beyond BatchPoolExecutor's control, such; as a missing container image, we previously did not report these errors. In; fact, we encountered errors when trying to load the output file that cannot; exist if the main container errors. Smaller included changes:; - directly use the asynchronous, low-level client instead of the synchronous,; low-level client; - introduce an `async_cancel` now that we have access to the async client.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9543
https://github.com/hail-is/hail/pull/9543:95,Availability,error,errors,95,"CHANGELOG: BatchPoolExecutor now raises an informative error message for a variety of ""system"" errors, such as missing container images. If the main container fails for reasons beyond BatchPoolExecutor's control, such; as a missing container image, we previously did not report these errors. In; fact, we encountered errors when trying to load the output file that cannot; exist if the main container errors. Smaller included changes:; - directly use the asynchronous, low-level client instead of the synchronous,; low-level client; - introduce an `async_cancel` now that we have access to the async client.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9543
https://github.com/hail-is/hail/pull/9543:284,Availability,error,errors,284,"CHANGELOG: BatchPoolExecutor now raises an informative error message for a variety of ""system"" errors, such as missing container images. If the main container fails for reasons beyond BatchPoolExecutor's control, such; as a missing container image, we previously did not report these errors. In; fact, we encountered errors when trying to load the output file that cannot; exist if the main container errors. Smaller included changes:; - directly use the asynchronous, low-level client instead of the synchronous,; low-level client; - introduce an `async_cancel` now that we have access to the async client.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9543
https://github.com/hail-is/hail/pull/9543:317,Availability,error,errors,317,"CHANGELOG: BatchPoolExecutor now raises an informative error message for a variety of ""system"" errors, such as missing container images. If the main container fails for reasons beyond BatchPoolExecutor's control, such; as a missing container image, we previously did not report these errors. In; fact, we encountered errors when trying to load the output file that cannot; exist if the main container errors. Smaller included changes:; - directly use the asynchronous, low-level client instead of the synchronous,; low-level client; - introduce an `async_cancel` now that we have access to the async client.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9543
https://github.com/hail-is/hail/pull/9543:401,Availability,error,errors,401,"CHANGELOG: BatchPoolExecutor now raises an informative error message for a variety of ""system"" errors, such as missing container images. If the main container fails for reasons beyond BatchPoolExecutor's control, such; as a missing container image, we previously did not report these errors. In; fact, we encountered errors when trying to load the output file that cannot; exist if the main container errors. Smaller included changes:; - directly use the asynchronous, low-level client instead of the synchronous,; low-level client; - introduce an `async_cancel` now that we have access to the async client.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9543
https://github.com/hail-is/hail/pull/9543:61,Integrability,message,message,61,"CHANGELOG: BatchPoolExecutor now raises an informative error message for a variety of ""system"" errors, such as missing container images. If the main container fails for reasons beyond BatchPoolExecutor's control, such; as a missing container image, we previously did not report these errors. In; fact, we encountered errors when trying to load the output file that cannot; exist if the main container errors. Smaller included changes:; - directly use the asynchronous, low-level client instead of the synchronous,; low-level client; - introduce an `async_cancel` now that we have access to the async client.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9543
https://github.com/hail-is/hail/pull/9543:339,Performance,load,load,339,"CHANGELOG: BatchPoolExecutor now raises an informative error message for a variety of ""system"" errors, such as missing container images. If the main container fails for reasons beyond BatchPoolExecutor's control, such; as a missing container image, we previously did not report these errors. In; fact, we encountered errors when trying to load the output file that cannot; exist if the main container errors. Smaller included changes:; - directly use the asynchronous, low-level client instead of the synchronous,; low-level client; - introduce an `async_cancel` now that we have access to the async client.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9543
https://github.com/hail-is/hail/pull/9543:580,Security,access,access,580,"CHANGELOG: BatchPoolExecutor now raises an informative error message for a variety of ""system"" errors, such as missing container images. If the main container fails for reasons beyond BatchPoolExecutor's control, such; as a missing container image, we previously did not report these errors. In; fact, we encountered errors when trying to load the output file that cannot; exist if the main container errors. Smaller included changes:; - directly use the asynchronous, low-level client instead of the synchronous,; low-level client; - introduce an `async_cancel` now that we have access to the async client.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9543
https://github.com/hail-is/hail/pull/9544:571,Availability,failure,failures,571,"SQL migrations are not permitted to be modified. Unfortunately, our tests; previously did not verify this at all. Indeed, a PR merged which modified a SQL; file. This PR caused main to fail a deploy. This change verifies that no SQL migration is mutated in the source SHA relative; to the target SHA. One can also use it locally by running `make; check-services` from the root. Unfortunately, it does not work properly when run; on the main branch because there is no obvious point of comparison. I considered comparing against the previous commit, but that might cause; failures if we have to manually fix something in batch. As such, I prefer a; non-deploy only test.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9544
https://github.com/hail-is/hail/pull/9544:192,Deployability,deploy,deploy,192,"SQL migrations are not permitted to be modified. Unfortunately, our tests; previously did not verify this at all. Indeed, a PR merged which modified a SQL; file. This PR caused main to fail a deploy. This change verifies that no SQL migration is mutated in the source SHA relative; to the target SHA. One can also use it locally by running `make; check-services` from the root. Unfortunately, it does not work properly when run; on the main branch because there is no obvious point of comparison. I considered comparing against the previous commit, but that might cause; failures if we have to manually fix something in batch. As such, I prefer a; non-deploy only test.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9544
https://github.com/hail-is/hail/pull/9544:652,Deployability,deploy,deploy,652,"SQL migrations are not permitted to be modified. Unfortunately, our tests; previously did not verify this at all. Indeed, a PR merged which modified a SQL; file. This PR caused main to fail a deploy. This change verifies that no SQL migration is mutated in the source SHA relative; to the target SHA. One can also use it locally by running `make; check-services` from the root. Unfortunately, it does not work properly when run; on the main branch because there is no obvious point of comparison. I considered comparing against the previous commit, but that might cause; failures if we have to manually fix something in batch. As such, I prefer a; non-deploy only test.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9544
https://github.com/hail-is/hail/pull/9544:68,Testability,test,tests,68,"SQL migrations are not permitted to be modified. Unfortunately, our tests; previously did not verify this at all. Indeed, a PR merged which modified a SQL; file. This PR caused main to fail a deploy. This change verifies that no SQL migration is mutated in the source SHA relative; to the target SHA. One can also use it locally by running `make; check-services` from the root. Unfortunately, it does not work properly when run; on the main branch because there is no obvious point of comparison. I considered comparing against the previous commit, but that might cause; failures if we have to manually fix something in batch. As such, I prefer a; non-deploy only test.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9544
https://github.com/hail-is/hail/pull/9544:664,Testability,test,test,664,"SQL migrations are not permitted to be modified. Unfortunately, our tests; previously did not verify this at all. Indeed, a PR merged which modified a SQL; file. This PR caused main to fail a deploy. This change verifies that no SQL migration is mutated in the source SHA relative; to the target SHA. One can also use it locally by running `make; check-services` from the root. Unfortunately, it does not work properly when run; on the main branch because there is no obvious point of comparison. I considered comparing against the previous commit, but that might cause; failures if we have to manually fix something in batch. As such, I prefer a; non-deploy only test.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9544
https://github.com/hail-is/hail/pull/9546:139,Availability,avail,available,139,"Changes to make sure that only the annotation datasets are visible on the docs page, now that the `datasets.json` config file contains all available datasets. Overview:. - In `datasets.json`, moved ""key_properties"" inside an ""annotation_db"" field, like `""annotation_db"": {""key_properties"": []}`, so that only the datasets with the ""annotation_db"" key are shown in the annotation DB docs page. Removed ""key_properties"" from non-annotation datasets. - Minor reformatting changes to docs page, added a reference genome column to the HTML table. - Updated deploy script to reflect the filename change from `annotation_db.json` to `datasets.json`. - Modified checks for keys in dicts from `assert key in doc, doc` to `assert key in doc` in `DatasetVersion.from_json()` and `Dataset.from_name_and_json()`. Since the `doc` that is passed to these methods from the checked in JSON file is just a dict like `doc = {""annotation_db"": {""key_properties"": [...]}, ""description"": ..., ""url"": ..., ""versions"": [...]}` this seems to work fine. Let me know if `key in doc, doc` form was used for other reasons I've overlooked.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9546
https://github.com/hail-is/hail/pull/9546:544,Deployability,Update,Updated,544,"Changes to make sure that only the annotation datasets are visible on the docs page, now that the `datasets.json` config file contains all available datasets. Overview:. - In `datasets.json`, moved ""key_properties"" inside an ""annotation_db"" field, like `""annotation_db"": {""key_properties"": []}`, so that only the datasets with the ""annotation_db"" key are shown in the annotation DB docs page. Removed ""key_properties"" from non-annotation datasets. - Minor reformatting changes to docs page, added a reference genome column to the HTML table. - Updated deploy script to reflect the filename change from `annotation_db.json` to `datasets.json`. - Modified checks for keys in dicts from `assert key in doc, doc` to `assert key in doc` in `DatasetVersion.from_json()` and `Dataset.from_name_and_json()`. Since the `doc` that is passed to these methods from the checked in JSON file is just a dict like `doc = {""annotation_db"": {""key_properties"": [...]}, ""description"": ..., ""url"": ..., ""versions"": [...]}` this seems to work fine. Let me know if `key in doc, doc` form was used for other reasons I've overlooked.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9546
https://github.com/hail-is/hail/pull/9546:552,Deployability,deploy,deploy,552,"Changes to make sure that only the annotation datasets are visible on the docs page, now that the `datasets.json` config file contains all available datasets. Overview:. - In `datasets.json`, moved ""key_properties"" inside an ""annotation_db"" field, like `""annotation_db"": {""key_properties"": []}`, so that only the datasets with the ""annotation_db"" key are shown in the annotation DB docs page. Removed ""key_properties"" from non-annotation datasets. - Minor reformatting changes to docs page, added a reference genome column to the HTML table. - Updated deploy script to reflect the filename change from `annotation_db.json` to `datasets.json`. - Modified checks for keys in dicts from `assert key in doc, doc` to `assert key in doc` in `DatasetVersion.from_json()` and `Dataset.from_name_and_json()`. Since the `doc` that is passed to these methods from the checked in JSON file is just a dict like `doc = {""annotation_db"": {""key_properties"": [...]}, ""description"": ..., ""url"": ..., ""versions"": [...]}` this seems to work fine. Let me know if `key in doc, doc` form was used for other reasons I've overlooked.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9546
https://github.com/hail-is/hail/pull/9546:114,Modifiability,config,config,114,"Changes to make sure that only the annotation datasets are visible on the docs page, now that the `datasets.json` config file contains all available datasets. Overview:. - In `datasets.json`, moved ""key_properties"" inside an ""annotation_db"" field, like `""annotation_db"": {""key_properties"": []}`, so that only the datasets with the ""annotation_db"" key are shown in the annotation DB docs page. Removed ""key_properties"" from non-annotation datasets. - Minor reformatting changes to docs page, added a reference genome column to the HTML table. - Updated deploy script to reflect the filename change from `annotation_db.json` to `datasets.json`. - Modified checks for keys in dicts from `assert key in doc, doc` to `assert key in doc` in `DatasetVersion.from_json()` and `Dataset.from_name_and_json()`. Since the `doc` that is passed to these methods from the checked in JSON file is just a dict like `doc = {""annotation_db"": {""key_properties"": [...]}, ""description"": ..., ""url"": ..., ""versions"": [...]}` this seems to work fine. Let me know if `key in doc, doc` form was used for other reasons I've overlooked.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9546
https://github.com/hail-is/hail/pull/9546:685,Testability,assert,assert,685,"Changes to make sure that only the annotation datasets are visible on the docs page, now that the `datasets.json` config file contains all available datasets. Overview:. - In `datasets.json`, moved ""key_properties"" inside an ""annotation_db"" field, like `""annotation_db"": {""key_properties"": []}`, so that only the datasets with the ""annotation_db"" key are shown in the annotation DB docs page. Removed ""key_properties"" from non-annotation datasets. - Minor reformatting changes to docs page, added a reference genome column to the HTML table. - Updated deploy script to reflect the filename change from `annotation_db.json` to `datasets.json`. - Modified checks for keys in dicts from `assert key in doc, doc` to `assert key in doc` in `DatasetVersion.from_json()` and `Dataset.from_name_and_json()`. Since the `doc` that is passed to these methods from the checked in JSON file is just a dict like `doc = {""annotation_db"": {""key_properties"": [...]}, ""description"": ..., ""url"": ..., ""versions"": [...]}` this seems to work fine. Let me know if `key in doc, doc` form was used for other reasons I've overlooked.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9546
https://github.com/hail-is/hail/pull/9546:713,Testability,assert,assert,713,"Changes to make sure that only the annotation datasets are visible on the docs page, now that the `datasets.json` config file contains all available datasets. Overview:. - In `datasets.json`, moved ""key_properties"" inside an ""annotation_db"" field, like `""annotation_db"": {""key_properties"": []}`, so that only the datasets with the ""annotation_db"" key are shown in the annotation DB docs page. Removed ""key_properties"" from non-annotation datasets. - Minor reformatting changes to docs page, added a reference genome column to the HTML table. - Updated deploy script to reflect the filename change from `annotation_db.json` to `datasets.json`. - Modified checks for keys in dicts from `assert key in doc, doc` to `assert key in doc` in `DatasetVersion.from_json()` and `Dataset.from_name_and_json()`. Since the `doc` that is passed to these methods from the checked in JSON file is just a dict like `doc = {""annotation_db"": {""key_properties"": [...]}, ""description"": ..., ""url"": ..., ""versions"": [...]}` this seems to work fine. Let me know if `key in doc, doc` form was used for other reasons I've overlooked.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9546
https://github.com/hail-is/hail/pull/9553:153,Testability,test,tests,153,"add endpoints for creating/deleting billing projects and adding/removing users from billing projects to let us add batch users with billing projects for tests without having to trigger a migration. This will make testing user isolation easier. I create a new file to test account-related things; all the deletions from test_batch were moved over to that test file. Stacked on #9579, #9585.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9553
https://github.com/hail-is/hail/pull/9553:213,Testability,test,testing,213,"add endpoints for creating/deleting billing projects and adding/removing users from billing projects to let us add batch users with billing projects for tests without having to trigger a migration. This will make testing user isolation easier. I create a new file to test account-related things; all the deletions from test_batch were moved over to that test file. Stacked on #9579, #9585.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9553
https://github.com/hail-is/hail/pull/9553:267,Testability,test,test,267,"add endpoints for creating/deleting billing projects and adding/removing users from billing projects to let us add batch users with billing projects for tests without having to trigger a migration. This will make testing user isolation easier. I create a new file to test account-related things; all the deletions from test_batch were moved over to that test file. Stacked on #9579, #9585.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9553
https://github.com/hail-is/hail/pull/9553:354,Testability,test,test,354,"add endpoints for creating/deleting billing projects and adding/removing users from billing projects to let us add batch users with billing projects for tests without having to trigger a migration. This will make testing user isolation easier. I create a new file to test account-related things; all the deletions from test_batch were moved over to that test file. Stacked on #9579, #9585.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9553
https://github.com/hail-is/hail/pull/9554:1356,Availability,error,errors,1356,"ssl_context`. The client context is configured to seek certificates from its peers. Both; internal contexts load the Hail certificate chain specified in the Hail SSL; Config. The external client context does not load the hail certificate chain. I intend all Hail's HTTP(S) requests to use `httpx.py` (so named to not conflict; with modules named `http`). Again, I have simplified the landscape. We now have; two functions:. - `httpx.client_session`: The constructor for all asynchronous, HTTPS client; sessions.; - `httpx.blocking_client_session`: The constructor for all synchronous, HTTPS; client sessions. Both sessions have the exact same configuration parameters. The API is exactly; the same except the blocking client session replaces asynchronous methods with; synchronous ones. Both sessions accept the `aiohttp.ClientSession` constructor parameters. They; support one new parameter and modify the behavior of one old parameter.; - `retry_transient`: when set to `True` this parameter will retry all transient; errors in all requests made by this session. This defaults to `True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager. Its; `response_coroutine` field is a coroutine that includes the retry and; raise-for-status logic. - The `HailResolver` overrides domain name resolution to first consult the Hail; `address` service. `address` is effectively a domain name server. It watches; kubernetes services and publishes the pod IPs. It supports two name styles:;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:1531,Availability,error,error,1531," in the Hail SSL; Config. The external client context does not load the hail certificate chain. I intend all Hail's HTTP(S) requests to use `httpx.py` (so named to not conflict; with modules named `http`). Again, I have simplified the landscape. We now have; two functions:. - `httpx.client_session`: The constructor for all asynchronous, HTTPS client; sessions.; - `httpx.blocking_client_session`: The constructor for all synchronous, HTTPS; client sessions. Both sessions have the exact same configuration parameters. The API is exactly; the same except the blocking client session replaces asynchronous methods with; synchronous ones. Both sessions accept the `aiohttp.ClientSession` constructor parameters. They; support one new parameter and modify the behavior of one old parameter.; - `retry_transient`: when set to `True` this parameter will retry all transient; errors in all requests made by this session. This defaults to `True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager. Its; `response_coroutine` field is a coroutine that includes the retry and; raise-for-status logic. - The `HailResolver` overrides domain name resolution to first consult the Hail; `address` service. `address` is effectively a domain name server. It watches; kubernetes services and publishes the pod IPs. It supports two name styles:; `service` and `service.namespace`. The former uses the deploy config to; determine in which namespace to find the given service. Currently, the; cl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:979,Deployability,configurat,configuration,979,"This PR attempts to simplify the use of TLS and HTTP(S) in Hail. The big changes; are in `hail/python/hailtop`. In particular I removed several functions with; confusingly overlapping functionality in `tls.py`. Instead, we now have three; functions:. - `internal_server_ssl_context`; - `internal_client_ssl_context`; - `external_client_ssl_context`. The client context is configured to seek certificates from its peers. Both; internal contexts load the Hail certificate chain specified in the Hail SSL; Config. The external client context does not load the hail certificate chain. I intend all Hail's HTTP(S) requests to use `httpx.py` (so named to not conflict; with modules named `http`). Again, I have simplified the landscape. We now have; two functions:. - `httpx.client_session`: The constructor for all asynchronous, HTTPS client; sessions.; - `httpx.blocking_client_session`: The constructor for all synchronous, HTTPS; client sessions. Both sessions have the exact same configuration parameters. The API is exactly; the same except the blocking client session replaces asynchronous methods with; synchronous ones. Both sessions accept the `aiohttp.ClientSession` constructor parameters. They; support one new parameter and modify the behavior of one old parameter.; - `retry_transient`: when set to `True` this parameter will retry all transient; errors in all requests made by this session. This defaults to `True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:2393,Deployability,deploy,deploy,2393,"True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager. Its; `response_coroutine` field is a coroutine that includes the retry and; raise-for-status logic. - The `HailResolver` overrides domain name resolution to first consult the Hail; `address` service. `address` is effectively a domain name server. It watches; kubernetes services and publishes the pod IPs. It supports two name styles:; `service` and `service.namespace`. The former uses the deploy config to; determine in which namespace to find the given service. Currently, the; client-side library only looks up IPs for `shuffler` and `address`. - `BlockingClientSession` and `BlockingContextManager` wrap the; aforementioned `httpx` classes. `BlockingClientResponse` wraps an; `aiohttp.ClientResponse`. ---. Examples of correct usage:. A blocking HTTPS request:. ```python3; with httpx.blocking_client_session() as session:; with session.post(url, json=config, headers=headers) as resp:; assert resp.status == 200; print(resp.text()); ```. An asynchronous HTTPS request to auth:; ```python3; async with httpx.client_session() as session:; async with session.get(; deploy_config.url('auth', '/api/v1alpha/userinfo'),; headers=headers) as resp:; assert resp.status == 200; print(await resp.json()); ```. A blocking HTTPS session with a large default timeout:. ```python3; httpx.blocking_client_session(; headers=service_auth_headers(deploy_config, 'query'),; timeout=aiohttp.ClientTimeout(total=600)); ```. cc: @cat",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:1537,Integrability,message,message,1537," in the Hail SSL; Config. The external client context does not load the hail certificate chain. I intend all Hail's HTTP(S) requests to use `httpx.py` (so named to not conflict; with modules named `http`). Again, I have simplified the landscape. We now have; two functions:. - `httpx.client_session`: The constructor for all asynchronous, HTTPS client; sessions.; - `httpx.blocking_client_session`: The constructor for all synchronous, HTTPS; client sessions. Both sessions have the exact same configuration parameters. The API is exactly; the same except the blocking client session replaces asynchronous methods with; synchronous ones. Both sessions accept the `aiohttp.ClientSession` constructor parameters. They; support one new parameter and modify the behavior of one old parameter.; - `retry_transient`: when set to `True` this parameter will retry all transient; errors in all requests made by this session. This defaults to `True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager. Its; `response_coroutine` field is a coroutine that includes the retry and; raise-for-status logic. - The `HailResolver` overrides domain name resolution to first consult the Hail; `address` service. `address` is effectively a domain name server. It watches; kubernetes services and publishes the pod IPs. It supports two name styles:; `service` and `service.namespace`. The former uses the deploy config to; determine in which namespace to find the given service. Currently, the; cl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:2606,Integrability,wrap,wrap,2606,"s`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager. Its; `response_coroutine` field is a coroutine that includes the retry and; raise-for-status logic. - The `HailResolver` overrides domain name resolution to first consult the Hail; `address` service. `address` is effectively a domain name server. It watches; kubernetes services and publishes the pod IPs. It supports two name styles:; `service` and `service.namespace`. The former uses the deploy config to; determine in which namespace to find the given service. Currently, the; client-side library only looks up IPs for `shuffler` and `address`. - `BlockingClientSession` and `BlockingContextManager` wrap the; aforementioned `httpx` classes. `BlockingClientResponse` wraps an; `aiohttp.ClientResponse`. ---. Examples of correct usage:. A blocking HTTPS request:. ```python3; with httpx.blocking_client_session() as session:; with session.post(url, json=config, headers=headers) as resp:; assert resp.status == 200; print(resp.text()); ```. An asynchronous HTTPS request to auth:; ```python3; async with httpx.client_session() as session:; async with session.get(; deploy_config.url('auth', '/api/v1alpha/userinfo'),; headers=headers) as resp:; assert resp.status == 200; print(await resp.json()); ```. A blocking HTTPS session with a large default timeout:. ```python3; httpx.blocking_client_session(; headers=service_auth_headers(deploy_config, 'query'),; timeout=aiohttp.ClientTimeout(total=600)); ```. cc: @catoverdrive @Dania-Abuhijleh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:2673,Integrability,wrap,wraps,2673,"s`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager. Its; `response_coroutine` field is a coroutine that includes the retry and; raise-for-status logic. - The `HailResolver` overrides domain name resolution to first consult the Hail; `address` service. `address` is effectively a domain name server. It watches; kubernetes services and publishes the pod IPs. It supports two name styles:; `service` and `service.namespace`. The former uses the deploy config to; determine in which namespace to find the given service. Currently, the; client-side library only looks up IPs for `shuffler` and `address`. - `BlockingClientSession` and `BlockingContextManager` wrap the; aforementioned `httpx` classes. `BlockingClientResponse` wraps an; `aiohttp.ClientResponse`. ---. Examples of correct usage:. A blocking HTTPS request:. ```python3; with httpx.blocking_client_session() as session:; with session.post(url, json=config, headers=headers) as resp:; assert resp.status == 200; print(resp.text()); ```. An asynchronous HTTPS request to auth:; ```python3; async with httpx.client_session() as session:; async with session.get(; deploy_config.url('auth', '/api/v1alpha/userinfo'),; headers=headers) as resp:; assert resp.status == 200; print(await resp.json()); ```. A blocking HTTPS session with a large default timeout:. ```python3; httpx.blocking_client_session(; headers=service_auth_headers(deploy_config, 'query'),; timeout=aiohttp.ClientTimeout(total=600)); ```. cc: @catoverdrive @Dania-Abuhijleh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:372,Modifiability,config,configured,372,"This PR attempts to simplify the use of TLS and HTTP(S) in Hail. The big changes; are in `hail/python/hailtop`. In particular I removed several functions with; confusingly overlapping functionality in `tls.py`. Instead, we now have three; functions:. - `internal_server_ssl_context`; - `internal_client_ssl_context`; - `external_client_ssl_context`. The client context is configured to seek certificates from its peers. Both; internal contexts load the Hail certificate chain specified in the Hail SSL; Config. The external client context does not load the hail certificate chain. I intend all Hail's HTTP(S) requests to use `httpx.py` (so named to not conflict; with modules named `http`). Again, I have simplified the landscape. We now have; two functions:. - `httpx.client_session`: The constructor for all asynchronous, HTTPS client; sessions.; - `httpx.blocking_client_session`: The constructor for all synchronous, HTTPS; client sessions. Both sessions have the exact same configuration parameters. The API is exactly; the same except the blocking client session replaces asynchronous methods with; synchronous ones. Both sessions accept the `aiohttp.ClientSession` constructor parameters. They; support one new parameter and modify the behavior of one old parameter.; - `retry_transient`: when set to `True` this parameter will retry all transient; errors in all requests made by this session. This defaults to `True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:503,Modifiability,Config,Config,503,"This PR attempts to simplify the use of TLS and HTTP(S) in Hail. The big changes; are in `hail/python/hailtop`. In particular I removed several functions with; confusingly overlapping functionality in `tls.py`. Instead, we now have three; functions:. - `internal_server_ssl_context`; - `internal_client_ssl_context`; - `external_client_ssl_context`. The client context is configured to seek certificates from its peers. Both; internal contexts load the Hail certificate chain specified in the Hail SSL; Config. The external client context does not load the hail certificate chain. I intend all Hail's HTTP(S) requests to use `httpx.py` (so named to not conflict; with modules named `http`). Again, I have simplified the landscape. We now have; two functions:. - `httpx.client_session`: The constructor for all asynchronous, HTTPS client; sessions.; - `httpx.blocking_client_session`: The constructor for all synchronous, HTTPS; client sessions. Both sessions have the exact same configuration parameters. The API is exactly; the same except the blocking client session replaces asynchronous methods with; synchronous ones. Both sessions accept the `aiohttp.ClientSession` constructor parameters. They; support one new parameter and modify the behavior of one old parameter.; - `retry_transient`: when set to `True` this parameter will retry all transient; errors in all requests made by this session. This defaults to `True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:979,Modifiability,config,configuration,979,"This PR attempts to simplify the use of TLS and HTTP(S) in Hail. The big changes; are in `hail/python/hailtop`. In particular I removed several functions with; confusingly overlapping functionality in `tls.py`. Instead, we now have three; functions:. - `internal_server_ssl_context`; - `internal_client_ssl_context`; - `external_client_ssl_context`. The client context is configured to seek certificates from its peers. Both; internal contexts load the Hail certificate chain specified in the Hail SSL; Config. The external client context does not load the hail certificate chain. I intend all Hail's HTTP(S) requests to use `httpx.py` (so named to not conflict; with modules named `http`). Again, I have simplified the landscape. We now have; two functions:. - `httpx.client_session`: The constructor for all asynchronous, HTTPS client; sessions.; - `httpx.blocking_client_session`: The constructor for all synchronous, HTTPS; client sessions. Both sessions have the exact same configuration parameters. The API is exactly; the same except the blocking client session replaces asynchronous methods with; synchronous ones. Both sessions accept the `aiohttp.ClientSession` constructor parameters. They; support one new parameter and modify the behavior of one old parameter.; - `retry_transient`: when set to `True` this parameter will retry all transient; errors in all requests made by this session. This defaults to `True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:2400,Modifiability,config,config,2400,"True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager. Its; `response_coroutine` field is a coroutine that includes the retry and; raise-for-status logic. - The `HailResolver` overrides domain name resolution to first consult the Hail; `address` service. `address` is effectively a domain name server. It watches; kubernetes services and publishes the pod IPs. It supports two name styles:; `service` and `service.namespace`. The former uses the deploy config to; determine in which namespace to find the given service. Currently, the; client-side library only looks up IPs for `shuffler` and `address`. - `BlockingClientSession` and `BlockingContextManager` wrap the; aforementioned `httpx` classes. `BlockingClientResponse` wraps an; `aiohttp.ClientResponse`. ---. Examples of correct usage:. A blocking HTTPS request:. ```python3; with httpx.blocking_client_session() as session:; with session.post(url, json=config, headers=headers) as resp:; assert resp.status == 200; print(resp.text()); ```. An asynchronous HTTPS request to auth:; ```python3; async with httpx.client_session() as session:; async with session.get(; deploy_config.url('auth', '/api/v1alpha/userinfo'),; headers=headers) as resp:; assert resp.status == 200; print(await resp.json()); ```. A blocking HTTPS session with a large default timeout:. ```python3; httpx.blocking_client_session(; headers=service_auth_headers(deploy_config, 'query'),; timeout=aiohttp.ClientTimeout(total=600)); ```. cc: @cat",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:2859,Modifiability,config,config,2859,"s`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager. Its; `response_coroutine` field is a coroutine that includes the retry and; raise-for-status logic. - The `HailResolver` overrides domain name resolution to first consult the Hail; `address` service. `address` is effectively a domain name server. It watches; kubernetes services and publishes the pod IPs. It supports two name styles:; `service` and `service.namespace`. The former uses the deploy config to; determine in which namespace to find the given service. Currently, the; client-side library only looks up IPs for `shuffler` and `address`. - `BlockingClientSession` and `BlockingContextManager` wrap the; aforementioned `httpx` classes. `BlockingClientResponse` wraps an; `aiohttp.ClientResponse`. ---. Examples of correct usage:. A blocking HTTPS request:. ```python3; with httpx.blocking_client_session() as session:; with session.post(url, json=config, headers=headers) as resp:; assert resp.status == 200; print(resp.text()); ```. An asynchronous HTTPS request to auth:; ```python3; async with httpx.client_session() as session:; async with session.get(; deploy_config.url('auth', '/api/v1alpha/userinfo'),; headers=headers) as resp:; assert resp.status == 200; print(await resp.json()); ```. A blocking HTTPS session with a large default timeout:. ```python3; httpx.blocking_client_session(; headers=service_auth_headers(deploy_config, 'query'),; timeout=aiohttp.ClientTimeout(total=600)); ```. cc: @catoverdrive @Dania-Abuhijleh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:444,Performance,load,load,444,"This PR attempts to simplify the use of TLS and HTTP(S) in Hail. The big changes; are in `hail/python/hailtop`. In particular I removed several functions with; confusingly overlapping functionality in `tls.py`. Instead, we now have three; functions:. - `internal_server_ssl_context`; - `internal_client_ssl_context`; - `external_client_ssl_context`. The client context is configured to seek certificates from its peers. Both; internal contexts load the Hail certificate chain specified in the Hail SSL; Config. The external client context does not load the hail certificate chain. I intend all Hail's HTTP(S) requests to use `httpx.py` (so named to not conflict; with modules named `http`). Again, I have simplified the landscape. We now have; two functions:. - `httpx.client_session`: The constructor for all asynchronous, HTTPS client; sessions.; - `httpx.blocking_client_session`: The constructor for all synchronous, HTTPS; client sessions. Both sessions have the exact same configuration parameters. The API is exactly; the same except the blocking client session replaces asynchronous methods with; synchronous ones. Both sessions accept the `aiohttp.ClientSession` constructor parameters. They; support one new parameter and modify the behavior of one old parameter.; - `retry_transient`: when set to `True` this parameter will retry all transient; errors in all requests made by this session. This defaults to `True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:548,Performance,load,load,548,"This PR attempts to simplify the use of TLS and HTTP(S) in Hail. The big changes; are in `hail/python/hailtop`. In particular I removed several functions with; confusingly overlapping functionality in `tls.py`. Instead, we now have three; functions:. - `internal_server_ssl_context`; - `internal_client_ssl_context`; - `external_client_ssl_context`. The client context is configured to seek certificates from its peers. Both; internal contexts load the Hail certificate chain specified in the Hail SSL; Config. The external client context does not load the hail certificate chain. I intend all Hail's HTTP(S) requests to use `httpx.py` (so named to not conflict; with modules named `http`). Again, I have simplified the landscape. We now have; two functions:. - `httpx.client_session`: The constructor for all asynchronous, HTTPS client; sessions.; - `httpx.blocking_client_session`: The constructor for all synchronous, HTTPS; client sessions. Both sessions have the exact same configuration parameters. The API is exactly; the same except the blocking client session replaces asynchronous methods with; synchronous ones. Both sessions accept the `aiohttp.ClientSession` constructor parameters. They; support one new parameter and modify the behavior of one old parameter.; - `retry_transient`: when set to `True` this parameter will retry all transient; errors in all requests made by this session. This defaults to `True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:3254,Safety,timeout,timeout,3254,"s`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager. Its; `response_coroutine` field is a coroutine that includes the retry and; raise-for-status logic. - The `HailResolver` overrides domain name resolution to first consult the Hail; `address` service. `address` is effectively a domain name server. It watches; kubernetes services and publishes the pod IPs. It supports two name styles:; `service` and `service.namespace`. The former uses the deploy config to; determine in which namespace to find the given service. Currently, the; client-side library only looks up IPs for `shuffler` and `address`. - `BlockingClientSession` and `BlockingContextManager` wrap the; aforementioned `httpx` classes. `BlockingClientResponse` wraps an; `aiohttp.ClientResponse`. ---. Examples of correct usage:. A blocking HTTPS request:. ```python3; with httpx.blocking_client_session() as session:; with session.post(url, json=config, headers=headers) as resp:; assert resp.status == 200; print(resp.text()); ```. An asynchronous HTTPS request to auth:; ```python3; async with httpx.client_session() as session:; async with session.get(; deploy_config.url('auth', '/api/v1alpha/userinfo'),; headers=headers) as resp:; assert resp.status == 200; print(await resp.json()); ```. A blocking HTTPS session with a large default timeout:. ```python3; httpx.blocking_client_session(; headers=service_auth_headers(deploy_config, 'query'),; timeout=aiohttp.ClientTimeout(total=600)); ```. cc: @catoverdrive @Dania-Abuhijleh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:3363,Safety,timeout,timeout,3363,"s`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager. Its; `response_coroutine` field is a coroutine that includes the retry and; raise-for-status logic. - The `HailResolver` overrides domain name resolution to first consult the Hail; `address` service. `address` is effectively a domain name server. It watches; kubernetes services and publishes the pod IPs. It supports two name styles:; `service` and `service.namespace`. The former uses the deploy config to; determine in which namespace to find the given service. Currently, the; client-side library only looks up IPs for `shuffler` and `address`. - `BlockingClientSession` and `BlockingContextManager` wrap the; aforementioned `httpx` classes. `BlockingClientResponse` wraps an; `aiohttp.ClientResponse`. ---. Examples of correct usage:. A blocking HTTPS request:. ```python3; with httpx.blocking_client_session() as session:; with session.post(url, json=config, headers=headers) as resp:; assert resp.status == 200; print(resp.text()); ```. An asynchronous HTTPS request to auth:; ```python3; async with httpx.client_session() as session:; async with session.get(; deploy_config.url('auth', '/api/v1alpha/userinfo'),; headers=headers) as resp:; assert resp.status == 200; print(await resp.json()); ```. A blocking HTTPS session with a large default timeout:. ```python3; httpx.blocking_client_session(; headers=service_auth_headers(deploy_config, 'query'),; timeout=aiohttp.ClientTimeout(total=600)); ```. cc: @catoverdrive @Dania-Abuhijleh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:391,Security,certificate,certificates,391,"This PR attempts to simplify the use of TLS and HTTP(S) in Hail. The big changes; are in `hail/python/hailtop`. In particular I removed several functions with; confusingly overlapping functionality in `tls.py`. Instead, we now have three; functions:. - `internal_server_ssl_context`; - `internal_client_ssl_context`; - `external_client_ssl_context`. The client context is configured to seek certificates from its peers. Both; internal contexts load the Hail certificate chain specified in the Hail SSL; Config. The external client context does not load the hail certificate chain. I intend all Hail's HTTP(S) requests to use `httpx.py` (so named to not conflict; with modules named `http`). Again, I have simplified the landscape. We now have; two functions:. - `httpx.client_session`: The constructor for all asynchronous, HTTPS client; sessions.; - `httpx.blocking_client_session`: The constructor for all synchronous, HTTPS; client sessions. Both sessions have the exact same configuration parameters. The API is exactly; the same except the blocking client session replaces asynchronous methods with; synchronous ones. Both sessions accept the `aiohttp.ClientSession` constructor parameters. They; support one new parameter and modify the behavior of one old parameter.; - `retry_transient`: when set to `True` this parameter will retry all transient; errors in all requests made by this session. This defaults to `True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:458,Security,certificate,certificate,458,"This PR attempts to simplify the use of TLS and HTTP(S) in Hail. The big changes; are in `hail/python/hailtop`. In particular I removed several functions with; confusingly overlapping functionality in `tls.py`. Instead, we now have three; functions:. - `internal_server_ssl_context`; - `internal_client_ssl_context`; - `external_client_ssl_context`. The client context is configured to seek certificates from its peers. Both; internal contexts load the Hail certificate chain specified in the Hail SSL; Config. The external client context does not load the hail certificate chain. I intend all Hail's HTTP(S) requests to use `httpx.py` (so named to not conflict; with modules named `http`). Again, I have simplified the landscape. We now have; two functions:. - `httpx.client_session`: The constructor for all asynchronous, HTTPS client; sessions.; - `httpx.blocking_client_session`: The constructor for all synchronous, HTTPS; client sessions. Both sessions have the exact same configuration parameters. The API is exactly; the same except the blocking client session replaces asynchronous methods with; synchronous ones. Both sessions accept the `aiohttp.ClientSession` constructor parameters. They; support one new parameter and modify the behavior of one old parameter.; - `retry_transient`: when set to `True` this parameter will retry all transient; errors in all requests made by this session. This defaults to `True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:562,Security,certificate,certificate,562,"This PR attempts to simplify the use of TLS and HTTP(S) in Hail. The big changes; are in `hail/python/hailtop`. In particular I removed several functions with; confusingly overlapping functionality in `tls.py`. Instead, we now have three; functions:. - `internal_server_ssl_context`; - `internal_client_ssl_context`; - `external_client_ssl_context`. The client context is configured to seek certificates from its peers. Both; internal contexts load the Hail certificate chain specified in the Hail SSL; Config. The external client context does not load the hail certificate chain. I intend all Hail's HTTP(S) requests to use `httpx.py` (so named to not conflict; with modules named `http`). Again, I have simplified the landscape. We now have; two functions:. - `httpx.client_session`: The constructor for all asynchronous, HTTPS client; sessions.; - `httpx.blocking_client_session`: The constructor for all synchronous, HTTPS; client sessions. Both sessions have the exact same configuration parameters. The API is exactly; the same except the blocking client session replaces asynchronous methods with; synchronous ones. Both sessions accept the `aiohttp.ClientSession` constructor parameters. They; support one new parameter and modify the behavior of one old parameter.; - `retry_transient`: when set to `True` this parameter will retry all transient; errors in all requests made by this session. This defaults to `True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:2095,Testability,log,logic,2095,"ng client session replaces asynchronous methods with; synchronous ones. Both sessions accept the `aiohttp.ClientSession` constructor parameters. They; support one new parameter and modify the behavior of one old parameter.; - `retry_transient`: when set to `True` this parameter will retry all transient; errors in all requests made by this session. This defaults to `True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager. Its; `response_coroutine` field is a coroutine that includes the retry and; raise-for-status logic. - The `HailResolver` overrides domain name resolution to first consult the Hail; `address` service. `address` is effectively a domain name server. It watches; kubernetes services and publishes the pod IPs. It supports two name styles:; `service` and `service.namespace`. The former uses the deploy config to; determine in which namespace to find the given service. Currently, the; client-side library only looks up IPs for `shuffler` and `address`. - `BlockingClientSession` and `BlockingContextManager` wrap the; aforementioned `httpx` classes. `BlockingClientResponse` wraps an; `aiohttp.ClientResponse`. ---. Examples of correct usage:. A blocking HTTPS request:. ```python3; with httpx.blocking_client_session() as session:; with session.post(url, json=config, headers=headers) as resp:; assert resp.status == 200; print(resp.text()); ```. An asynchronous HTTPS request to auth:; ```python3; async with httpx.client_session() as session:; async ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:2894,Testability,assert,assert,2894,"s`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager. Its; `response_coroutine` field is a coroutine that includes the retry and; raise-for-status logic. - The `HailResolver` overrides domain name resolution to first consult the Hail; `address` service. `address` is effectively a domain name server. It watches; kubernetes services and publishes the pod IPs. It supports two name styles:; `service` and `service.namespace`. The former uses the deploy config to; determine in which namespace to find the given service. Currently, the; client-side library only looks up IPs for `shuffler` and `address`. - `BlockingClientSession` and `BlockingContextManager` wrap the; aforementioned `httpx` classes. `BlockingClientResponse` wraps an; `aiohttp.ClientResponse`. ---. Examples of correct usage:. A blocking HTTPS request:. ```python3; with httpx.blocking_client_session() as session:; with session.post(url, json=config, headers=headers) as resp:; assert resp.status == 200; print(resp.text()); ```. An asynchronous HTTPS request to auth:; ```python3; async with httpx.client_session() as session:; async with session.get(; deploy_config.url('auth', '/api/v1alpha/userinfo'),; headers=headers) as resp:; assert resp.status == 200; print(await resp.json()); ```. A blocking HTTPS session with a large default timeout:. ```python3; httpx.blocking_client_session(; headers=service_auth_headers(deploy_config, 'query'),; timeout=aiohttp.ClientTimeout(total=600)); ```. cc: @catoverdrive @Dania-Abuhijleh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:3150,Testability,assert,assert,3150,"s`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager. Its; `response_coroutine` field is a coroutine that includes the retry and; raise-for-status logic. - The `HailResolver` overrides domain name resolution to first consult the Hail; `address` service. `address` is effectively a domain name server. It watches; kubernetes services and publishes the pod IPs. It supports two name styles:; `service` and `service.namespace`. The former uses the deploy config to; determine in which namespace to find the given service. Currently, the; client-side library only looks up IPs for `shuffler` and `address`. - `BlockingClientSession` and `BlockingContextManager` wrap the; aforementioned `httpx` classes. `BlockingClientResponse` wraps an; `aiohttp.ClientResponse`. ---. Examples of correct usage:. A blocking HTTPS request:. ```python3; with httpx.blocking_client_session() as session:; with session.post(url, json=config, headers=headers) as resp:; assert resp.status == 200; print(resp.text()); ```. An asynchronous HTTPS request to auth:; ```python3; async with httpx.client_session() as session:; async with session.get(; deploy_config.url('auth', '/api/v1alpha/userinfo'),; headers=headers) as resp:; assert resp.status == 200; print(await resp.json()); ```. A blocking HTTPS session with a large default timeout:. ```python3; httpx.blocking_client_session(; headers=service_auth_headers(deploy_config, 'query'),; timeout=aiohttp.ClientTimeout(total=600)); ```. cc: @catoverdrive @Dania-Abuhijleh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:20,Usability,simpl,simplify,20,"This PR attempts to simplify the use of TLS and HTTP(S) in Hail. The big changes; are in `hail/python/hailtop`. In particular I removed several functions with; confusingly overlapping functionality in `tls.py`. Instead, we now have three; functions:. - `internal_server_ssl_context`; - `internal_client_ssl_context`; - `external_client_ssl_context`. The client context is configured to seek certificates from its peers. Both; internal contexts load the Hail certificate chain specified in the Hail SSL; Config. The external client context does not load the hail certificate chain. I intend all Hail's HTTP(S) requests to use `httpx.py` (so named to not conflict; with modules named `http`). Again, I have simplified the landscape. We now have; two functions:. - `httpx.client_session`: The constructor for all asynchronous, HTTPS client; sessions.; - `httpx.blocking_client_session`: The constructor for all synchronous, HTTPS; client sessions. Both sessions have the exact same configuration parameters. The API is exactly; the same except the blocking client session replaces asynchronous methods with; synchronous ones. Both sessions accept the `aiohttp.ClientSession` constructor parameters. They; support one new parameter and modify the behavior of one old parameter.; - `retry_transient`: when set to `True` this parameter will retry all transient; errors in all requests made by this session. This defaults to `True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9554:705,Usability,simpl,simplified,705,"This PR attempts to simplify the use of TLS and HTTP(S) in Hail. The big changes; are in `hail/python/hailtop`. In particular I removed several functions with; confusingly overlapping functionality in `tls.py`. Instead, we now have three; functions:. - `internal_server_ssl_context`; - `internal_client_ssl_context`; - `external_client_ssl_context`. The client context is configured to seek certificates from its peers. Both; internal contexts load the Hail certificate chain specified in the Hail SSL; Config. The external client context does not load the hail certificate chain. I intend all Hail's HTTP(S) requests to use `httpx.py` (so named to not conflict; with modules named `http`). Again, I have simplified the landscape. We now have; two functions:. - `httpx.client_session`: The constructor for all asynchronous, HTTPS client; sessions.; - `httpx.blocking_client_session`: The constructor for all synchronous, HTTPS; client sessions. Both sessions have the exact same configuration parameters. The API is exactly; the same except the blocking client session replaces asynchronous methods with; synchronous ones. Both sessions accept the `aiohttp.ClientSession` constructor parameters. They; support one new parameter and modify the behavior of one old parameter.; - `retry_transient`: when set to `True` this parameter will retry all transient; errors in all requests made by this session. This defaults to `True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9554
https://github.com/hail-is/hail/pull/9556:112,Availability,echo,echo,112,"The semantics of setting a variable in make are kinda weird, example:. ```make; FOO := foo; BAR ?= bar; .PHONY: echo; echo:; 	echo $(FOO) $(BAR); ```. ```sh; $ FOO=baz make; echo foo bar; foo bar; $ make FOO=baz; echo baz bar; baz bar; $ BAR=baz make; echo foo baz; foo baz; ```. This will fix an issue where ci wasn't actually building with spark 3.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9556
https://github.com/hail-is/hail/pull/9556:118,Availability,echo,echo,118,"The semantics of setting a variable in make are kinda weird, example:. ```make; FOO := foo; BAR ?= bar; .PHONY: echo; echo:; 	echo $(FOO) $(BAR); ```. ```sh; $ FOO=baz make; echo foo bar; foo bar; $ make FOO=baz; echo baz bar; baz bar; $ BAR=baz make; echo foo baz; foo baz; ```. This will fix an issue where ci wasn't actually building with spark 3.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9556
https://github.com/hail-is/hail/pull/9556:126,Availability,echo,echo,126,"The semantics of setting a variable in make are kinda weird, example:. ```make; FOO := foo; BAR ?= bar; .PHONY: echo; echo:; 	echo $(FOO) $(BAR); ```. ```sh; $ FOO=baz make; echo foo bar; foo bar; $ make FOO=baz; echo baz bar; baz bar; $ BAR=baz make; echo foo baz; foo baz; ```. This will fix an issue where ci wasn't actually building with spark 3.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9556
https://github.com/hail-is/hail/pull/9556:174,Availability,echo,echo,174,"The semantics of setting a variable in make are kinda weird, example:. ```make; FOO := foo; BAR ?= bar; .PHONY: echo; echo:; 	echo $(FOO) $(BAR); ```. ```sh; $ FOO=baz make; echo foo bar; foo bar; $ make FOO=baz; echo baz bar; baz bar; $ BAR=baz make; echo foo baz; foo baz; ```. This will fix an issue where ci wasn't actually building with spark 3.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9556
https://github.com/hail-is/hail/pull/9556:213,Availability,echo,echo,213,"The semantics of setting a variable in make are kinda weird, example:. ```make; FOO := foo; BAR ?= bar; .PHONY: echo; echo:; 	echo $(FOO) $(BAR); ```. ```sh; $ FOO=baz make; echo foo bar; foo bar; $ make FOO=baz; echo baz bar; baz bar; $ BAR=baz make; echo foo baz; foo baz; ```. This will fix an issue where ci wasn't actually building with spark 3.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9556
https://github.com/hail-is/hail/pull/9556:252,Availability,echo,echo,252,"The semantics of setting a variable in make are kinda weird, example:. ```make; FOO := foo; BAR ?= bar; .PHONY: echo; echo:; 	echo $(FOO) $(BAR); ```. ```sh; $ FOO=baz make; echo foo bar; foo bar; $ make FOO=baz; echo baz bar; baz bar; $ BAR=baz make; echo foo baz; foo baz; ```. This will fix an issue where ci wasn't actually building with spark 3.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9556
https://github.com/hail-is/hail/pull/9556:27,Modifiability,variab,variable,27,"The semantics of setting a variable in make are kinda weird, example:. ```make; FOO := foo; BAR ?= bar; .PHONY: echo; echo:; 	echo $(FOO) $(BAR); ```. ```sh; $ FOO=baz make; echo foo bar; foo bar; $ make FOO=baz; echo baz bar; baz bar; $ BAR=baz make; echo foo baz; foo baz; ```. This will fix an issue where ci wasn't actually building with spark 3.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9556
https://github.com/hail-is/hail/pull/9557:222,Integrability,message,message,222,"Summary: hailctl batch list --help; ```; usage: hailctl batch list [-h] [--query QUERY] [--limit LIMIT] [--all] [--before BEFORE] [--full] [--no-header] [-o O]. List batches. optional arguments:; -h, --help show this help message and exit; --query QUERY, -q QUERY; see docs at https://batch.hail.is/batches; --limit LIMIT, -l LIMIT; number of batches to return (default 50); --all, -a list all batches (overrides --limit); --before BEFORE start listing before supplied id; --full when output is tabular, print more information; --no-header do not print a table header; -o O specify output format (json, yaml, csv, tsv, or any tabulate format); ```. Details:; * Default listing to a limit of 50 records, once batch statuses are; cached from `list_batches`, this should result in 1 http request for the; default behavior of this tool.; * Teach --limit option to cap the number of records returned; * Teach --all to override --limit; * Teach --before to pass a last_batch_id query parameter to list_batches; * Teach --full to print all status information; * Teach --no-header to enable not printing a header for tabular output; * Teach -o {format} to change the output format the following are supported:; - json: always full json output, like hitting the list enpoint manually; - yaml: like json, but yaml!; - csv/tsv: simple comma/tab separated output for machine processing; - any python-tabulate output format, listed here:; https://github.com/astanin/python-tabulate#table-format. The only default that has been changed is the listing limit.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9557
https://github.com/hail-is/hail/pull/9557:728,Performance,cache,cached,728,"Summary: hailctl batch list --help; ```; usage: hailctl batch list [-h] [--query QUERY] [--limit LIMIT] [--all] [--before BEFORE] [--full] [--no-header] [-o O]. List batches. optional arguments:; -h, --help show this help message and exit; --query QUERY, -q QUERY; see docs at https://batch.hail.is/batches; --limit LIMIT, -l LIMIT; number of batches to return (default 50); --all, -a list all batches (overrides --limit); --before BEFORE start listing before supplied id; --full when output is tabular, print more information; --no-header do not print a table header; -o O specify output format (json, yaml, csv, tsv, or any tabulate format); ```. Details:; * Default listing to a limit of 50 records, once batch statuses are; cached from `list_batches`, this should result in 1 http request for the; default behavior of this tool.; * Teach --limit option to cap the number of records returned; * Teach --all to override --limit; * Teach --before to pass a last_batch_id query parameter to list_batches; * Teach --full to print all status information; * Teach --no-header to enable not printing a header for tabular output; * Teach -o {format} to change the output format the following are supported:; - json: always full json output, like hitting the list enpoint manually; - yaml: like json, but yaml!; - csv/tsv: simple comma/tab separated output for machine processing; - any python-tabulate output format, listed here:; https://github.com/astanin/python-tabulate#table-format. The only default that has been changed is the listing limit.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9557
https://github.com/hail-is/hail/pull/9557:1317,Usability,simpl,simple,1317,"Summary: hailctl batch list --help; ```; usage: hailctl batch list [-h] [--query QUERY] [--limit LIMIT] [--all] [--before BEFORE] [--full] [--no-header] [-o O]. List batches. optional arguments:; -h, --help show this help message and exit; --query QUERY, -q QUERY; see docs at https://batch.hail.is/batches; --limit LIMIT, -l LIMIT; number of batches to return (default 50); --all, -a list all batches (overrides --limit); --before BEFORE start listing before supplied id; --full when output is tabular, print more information; --no-header do not print a table header; -o O specify output format (json, yaml, csv, tsv, or any tabulate format); ```. Details:; * Default listing to a limit of 50 records, once batch statuses are; cached from `list_batches`, this should result in 1 http request for the; default behavior of this tool.; * Teach --limit option to cap the number of records returned; * Teach --all to override --limit; * Teach --before to pass a last_batch_id query parameter to list_batches; * Teach --full to print all status information; * Teach --no-header to enable not printing a header for tabular output; * Teach -o {format} to change the output format the following are supported:; - json: always full json output, like hitting the list enpoint manually; - yaml: like json, but yaml!; - csv/tsv: simple comma/tab separated output for machine processing; - any python-tabulate output format, listed here:; https://github.com/astanin/python-tabulate#table-format. The only default that has been changed is the listing limit.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9557
https://github.com/hail-is/hail/pull/9560:44,Energy Efficiency,Monitor,Monitoring,44,"We previously used `estimated-current.txt`. Monitoring is using; `estimated-current.sql`. The sql extension gives me syntax highlighting in; Emacs, so I decided to rename the txts to sqls.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9560
https://github.com/hail-is/hail/pull/9562:12,Energy Efficiency,reduce,reduce,12,This should reduce the number of requests clients are making.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9562
https://github.com/hail-is/hail/pull/9567:13,Deployability,update,update,13,#9500 didn't update the `hail/hail` makefile,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9567
https://github.com/hail-is/hail/pull/9568:32,Testability,test,tests,32,"This PR:. - Switches all python tests to run in debug mode on the checked allocator.; - Adds a pytest mark, `unchecked_allocator`. Anything with this mark will be rerun with the unchecked allocator as a way of testing the unchecked allocator",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9568
https://github.com/hail-is/hail/pull/9568:210,Testability,test,testing,210,"This PR:. - Switches all python tests to run in debug mode on the checked allocator.; - Adds a pytest mark, `unchecked_allocator`. Anything with this mark will be rerun with the unchecked allocator as a way of testing the unchecked allocator",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9568
https://github.com/hail-is/hail/pull/9569:82,Availability,error,error,82,"This PR updates the LocalBackend to match the behavior of the SparkBackend w.r.t. error handling. . - `handle_java_exception` and `execute` are lifted into the parent file, `Py4JBackend`. ; - Tests in `test_ndarrays` that were marked as failing local tests are now passing, since the only failure was inconsistent handling of errors. . The error handling changes in question here were introduced in #9398",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9569
https://github.com/hail-is/hail/pull/9569:289,Availability,failure,failure,289,"This PR updates the LocalBackend to match the behavior of the SparkBackend w.r.t. error handling. . - `handle_java_exception` and `execute` are lifted into the parent file, `Py4JBackend`. ; - Tests in `test_ndarrays` that were marked as failing local tests are now passing, since the only failure was inconsistent handling of errors. . The error handling changes in question here were introduced in #9398",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9569
https://github.com/hail-is/hail/pull/9569:326,Availability,error,errors,326,"This PR updates the LocalBackend to match the behavior of the SparkBackend w.r.t. error handling. . - `handle_java_exception` and `execute` are lifted into the parent file, `Py4JBackend`. ; - Tests in `test_ndarrays` that were marked as failing local tests are now passing, since the only failure was inconsistent handling of errors. . The error handling changes in question here were introduced in #9398",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9569
https://github.com/hail-is/hail/pull/9569:340,Availability,error,error,340,"This PR updates the LocalBackend to match the behavior of the SparkBackend w.r.t. error handling. . - `handle_java_exception` and `execute` are lifted into the parent file, `Py4JBackend`. ; - Tests in `test_ndarrays` that were marked as failing local tests are now passing, since the only failure was inconsistent handling of errors. . The error handling changes in question here were introduced in #9398",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9569
https://github.com/hail-is/hail/pull/9569:8,Deployability,update,updates,8,"This PR updates the LocalBackend to match the behavior of the SparkBackend w.r.t. error handling. . - `handle_java_exception` and `execute` are lifted into the parent file, `Py4JBackend`. ; - Tests in `test_ndarrays` that were marked as failing local tests are now passing, since the only failure was inconsistent handling of errors. . The error handling changes in question here were introduced in #9398",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9569
https://github.com/hail-is/hail/pull/9569:192,Testability,Test,Tests,192,"This PR updates the LocalBackend to match the behavior of the SparkBackend w.r.t. error handling. . - `handle_java_exception` and `execute` are lifted into the parent file, `Py4JBackend`. ; - Tests in `test_ndarrays` that were marked as failing local tests are now passing, since the only failure was inconsistent handling of errors. . The error handling changes in question here were introduced in #9398",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9569
https://github.com/hail-is/hail/pull/9569:251,Testability,test,tests,251,"This PR updates the LocalBackend to match the behavior of the SparkBackend w.r.t. error handling. . - `handle_java_exception` and `execute` are lifted into the parent file, `Py4JBackend`. ; - Tests in `test_ndarrays` that were marked as failing local tests are now passing, since the only failure was inconsistent handling of errors. . The error handling changes in question here were introduced in #9398",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9569
https://github.com/hail-is/hail/pull/9570:174,Availability,error,error,174,"Previously, when we did `hl.agg.group_by(group_expr, aggregation_expr)`, we were only tracking the indices picked up from the `aggregation_expr`. This led to us throwing bad error messages.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9570
https://github.com/hail-is/hail/pull/9570:180,Integrability,message,messages,180,"Previously, when we did `hl.agg.group_by(group_expr, aggregation_expr)`, we were only tracking the indices picked up from the `aggregation_expr`. This led to us throwing bad error messages.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9570
https://github.com/hail-is/hail/pull/9574:108,Testability,test,tests,108,If query has to pull its image fresh each job takes ~2 minutes. I also fixed some; whitespace issues in the tests and a little bug in `retry_response_returning_functions`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9574
https://github.com/hail-is/hail/pull/9575:42,Availability,avail,available,42,CHANGELOG: The Resource class is now also available at hailtop.batch.Resource. I screwed up my branches. This is just #9515.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9575
https://github.com/hail-is/hail/pull/9577:452,Deployability,integrat,integrated,452,"Add async-profiler support to hail-bench. Add options:; * `--profile` (`-p`). Can be `-p cpu` or `-p alloc`; `-p` alone defaults to `cpu`.; * `--prof-fmt` (`-f`). Can be `-f html`, `-f flame`, or `-f jfr`. If not specified, defaults to `html`. `html` writes a collapsible tree as you would see in a profiler gui. `flame` writes an svg format flame graph. `jfr` writes a Java Flight Recorder format file which can be read by Java Mission Control or the integrated IntelliJ profiler. Uses [async-profiler](https://github.com/jvm-profiling-tools/async-profiler), which must be installed at the path `$ASYNC_PROFILER_HOME`. It attaches to the spark JVM using the JVMTI argument interface. The JVMTI async-profiler arguments are described [here](https://github.com/jvm-profiling-tools/async-profiler/blob/v1.8.1/src/arguments.cpp#L49).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9577
https://github.com/hail-is/hail/pull/9577:574,Deployability,install,installed,574,"Add async-profiler support to hail-bench. Add options:; * `--profile` (`-p`). Can be `-p cpu` or `-p alloc`; `-p` alone defaults to `cpu`.; * `--prof-fmt` (`-f`). Can be `-f html`, `-f flame`, or `-f jfr`. If not specified, defaults to `html`. `html` writes a collapsible tree as you would see in a profiler gui. `flame` writes an svg format flame graph. `jfr` writes a Java Flight Recorder format file which can be read by Java Mission Control or the integrated IntelliJ profiler. Uses [async-profiler](https://github.com/jvm-profiling-tools/async-profiler), which must be installed at the path `$ASYNC_PROFILER_HOME`. It attaches to the spark JVM using the JVMTI argument interface. The JVMTI async-profiler arguments are described [here](https://github.com/jvm-profiling-tools/async-profiler/blob/v1.8.1/src/arguments.cpp#L49).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9577
https://github.com/hail-is/hail/pull/9577:452,Integrability,integrat,integrated,452,"Add async-profiler support to hail-bench. Add options:; * `--profile` (`-p`). Can be `-p cpu` or `-p alloc`; `-p` alone defaults to `cpu`.; * `--prof-fmt` (`-f`). Can be `-f html`, `-f flame`, or `-f jfr`. If not specified, defaults to `html`. `html` writes a collapsible tree as you would see in a profiler gui. `flame` writes an svg format flame graph. `jfr` writes a Java Flight Recorder format file which can be read by Java Mission Control or the integrated IntelliJ profiler. Uses [async-profiler](https://github.com/jvm-profiling-tools/async-profiler), which must be installed at the path `$ASYNC_PROFILER_HOME`. It attaches to the spark JVM using the JVMTI argument interface. The JVMTI async-profiler arguments are described [here](https://github.com/jvm-profiling-tools/async-profiler/blob/v1.8.1/src/arguments.cpp#L49).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9577
https://github.com/hail-is/hail/pull/9577:674,Integrability,interface,interface,674,"Add async-profiler support to hail-bench. Add options:; * `--profile` (`-p`). Can be `-p cpu` or `-p alloc`; `-p` alone defaults to `cpu`.; * `--prof-fmt` (`-f`). Can be `-f html`, `-f flame`, or `-f jfr`. If not specified, defaults to `html`. `html` writes a collapsible tree as you would see in a profiler gui. `flame` writes an svg format flame graph. `jfr` writes a Java Flight Recorder format file which can be read by Java Mission Control or the integrated IntelliJ profiler. Uses [async-profiler](https://github.com/jvm-profiling-tools/async-profiler), which must be installed at the path `$ASYNC_PROFILER_HOME`. It attaches to the spark JVM using the JVMTI argument interface. The JVMTI async-profiler arguments are described [here](https://github.com/jvm-profiling-tools/async-profiler/blob/v1.8.1/src/arguments.cpp#L49).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9577
https://github.com/hail-is/hail/pull/9578:390,Energy Efficiency,efficient,efficient,390,"`_linear_regression_rows_nd` now supports chained linear regression correctly. Also added support for pass through arguments. This should now support everything that regular linear regression supports, but all written in Python. This allows a few more tests to run on local backend. . I'd be particularly interested in whether you think there's a way to write this that would generate more efficient IR. It seems hacky to have to map over the range of rows and index into it, but I didn't see a better way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9578
https://github.com/hail-is/hail/pull/9578:252,Testability,test,tests,252,"`_linear_regression_rows_nd` now supports chained linear regression correctly. Also added support for pass through arguments. This should now support everything that regular linear regression supports, but all written in Python. This allows a few more tests to run on local backend. . I'd be particularly interested in whether you think there's a way to write this that would generate more efficient IR. It seems hacky to have to map over the range of rows and index into it, but I didn't see a better way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9578
https://github.com/hail-is/hail/pull/9579:423,Deployability,deploy,deployed,423,"@jigold this is more-or-less as we talked about yesterday. I added a check within batch creation so it can only open a batch against an open billing project, and when we close a billing project we check that there all of the batches associated with it are completed (can't close a billing project mid-batch). I don't have automated tests for this yet (planning on exposing the API in the billing project test PR) but I dev-deployed it and clicked the buttons and it does the right thing.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9579
https://github.com/hail-is/hail/pull/9579:332,Testability,test,tests,332,"@jigold this is more-or-less as we talked about yesterday. I added a check within batch creation so it can only open a batch against an open billing project, and when we close a billing project we check that there all of the batches associated with it are completed (can't close a billing project mid-batch). I don't have automated tests for this yet (planning on exposing the API in the billing project test PR) but I dev-deployed it and clicked the buttons and it does the right thing.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9579
https://github.com/hail-is/hail/pull/9579:404,Testability,test,test,404,"@jigold this is more-or-less as we talked about yesterday. I added a check within batch creation so it can only open a batch against an open billing project, and when we close a billing project we check that there all of the batches associated with it are completed (can't close a billing project mid-batch). I don't have automated tests for this yet (planning on exposing the API in the billing project test PR) but I dev-deployed it and clicked the buttons and it does the right thing.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9579
https://github.com/hail-is/hail/pull/9581:94,Testability,test,tests,94,This is for @catoverdrive and I to be able to manipulate billing projects and their limits in tests. But we don't want to litter the default namespace with a bunch of bogus projects. We also need to reset the accrued costs to 0 in order for the billing limit tests to work. @danking -- FYI,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9581
https://github.com/hail-is/hail/pull/9581:259,Testability,test,tests,259,This is for @catoverdrive and I to be able to manipulate billing projects and their limits in tests. But we don't want to litter the default namespace with a bunch of bogus projects. We also need to reset the accrued costs to 0 in order for the billing limit tests to work. @danking -- FYI,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9581
https://github.com/hail-is/hail/pull/9585:21,Performance,load,load,21,I need to be able to load tokens for multiple users for #9553 and would like to pipe it through the auth utilities in a reasonable way so I can use them. Let me know if this looks ok or if there's a better way to do it?,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9585
https://github.com/hail-is/hail/pull/9586:7,Testability,test,tests,7,11 new tests passing. Can briefly walk you through the change in 1:1.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9586
https://github.com/hail-is/hail/issues/9587:43,Deployability,configurat,configurations,43,"`hailctl dataproc` can pass through gcloud configurations specified with `--configuration` to the `gcloud dataproc` commands that it runs. However, that argument is often not respected for other `gcloud` commands that `hailctl dataproc` may run. For example, `hailctl dataproc start --configuration some_config` gets the project ID for requester pays configuration from the default gcloud configuration, not the specified configuration. https://github.com/hail-is/hail/blob/9706dd493515bce5aa88c623a83f899e8f8b801b/hail/python/hailtop/hailctl/dataproc/start.py#L262-L265. Hail version: 0.2.57-3f3afaa1d7bd. Zulip chat for context; https://hail.zulipchat.com/#narrow/stream/128581-Cloud-support/topic/403.20on.20public.20file",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9587
https://github.com/hail-is/hail/issues/9587:76,Deployability,configurat,configuration,76,"`hailctl dataproc` can pass through gcloud configurations specified with `--configuration` to the `gcloud dataproc` commands that it runs. However, that argument is often not respected for other `gcloud` commands that `hailctl dataproc` may run. For example, `hailctl dataproc start --configuration some_config` gets the project ID for requester pays configuration from the default gcloud configuration, not the specified configuration. https://github.com/hail-is/hail/blob/9706dd493515bce5aa88c623a83f899e8f8b801b/hail/python/hailtop/hailctl/dataproc/start.py#L262-L265. Hail version: 0.2.57-3f3afaa1d7bd. Zulip chat for context; https://hail.zulipchat.com/#narrow/stream/128581-Cloud-support/topic/403.20on.20public.20file",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9587
https://github.com/hail-is/hail/issues/9587:285,Deployability,configurat,configuration,285,"`hailctl dataproc` can pass through gcloud configurations specified with `--configuration` to the `gcloud dataproc` commands that it runs. However, that argument is often not respected for other `gcloud` commands that `hailctl dataproc` may run. For example, `hailctl dataproc start --configuration some_config` gets the project ID for requester pays configuration from the default gcloud configuration, not the specified configuration. https://github.com/hail-is/hail/blob/9706dd493515bce5aa88c623a83f899e8f8b801b/hail/python/hailtop/hailctl/dataproc/start.py#L262-L265. Hail version: 0.2.57-3f3afaa1d7bd. Zulip chat for context; https://hail.zulipchat.com/#narrow/stream/128581-Cloud-support/topic/403.20on.20public.20file",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9587
https://github.com/hail-is/hail/issues/9587:351,Deployability,configurat,configuration,351,"`hailctl dataproc` can pass through gcloud configurations specified with `--configuration` to the `gcloud dataproc` commands that it runs. However, that argument is often not respected for other `gcloud` commands that `hailctl dataproc` may run. For example, `hailctl dataproc start --configuration some_config` gets the project ID for requester pays configuration from the default gcloud configuration, not the specified configuration. https://github.com/hail-is/hail/blob/9706dd493515bce5aa88c623a83f899e8f8b801b/hail/python/hailtop/hailctl/dataproc/start.py#L262-L265. Hail version: 0.2.57-3f3afaa1d7bd. Zulip chat for context; https://hail.zulipchat.com/#narrow/stream/128581-Cloud-support/topic/403.20on.20public.20file",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9587
https://github.com/hail-is/hail/issues/9587:389,Deployability,configurat,configuration,389,"`hailctl dataproc` can pass through gcloud configurations specified with `--configuration` to the `gcloud dataproc` commands that it runs. However, that argument is often not respected for other `gcloud` commands that `hailctl dataproc` may run. For example, `hailctl dataproc start --configuration some_config` gets the project ID for requester pays configuration from the default gcloud configuration, not the specified configuration. https://github.com/hail-is/hail/blob/9706dd493515bce5aa88c623a83f899e8f8b801b/hail/python/hailtop/hailctl/dataproc/start.py#L262-L265. Hail version: 0.2.57-3f3afaa1d7bd. Zulip chat for context; https://hail.zulipchat.com/#narrow/stream/128581-Cloud-support/topic/403.20on.20public.20file",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9587
https://github.com/hail-is/hail/issues/9587:422,Deployability,configurat,configuration,422,"`hailctl dataproc` can pass through gcloud configurations specified with `--configuration` to the `gcloud dataproc` commands that it runs. However, that argument is often not respected for other `gcloud` commands that `hailctl dataproc` may run. For example, `hailctl dataproc start --configuration some_config` gets the project ID for requester pays configuration from the default gcloud configuration, not the specified configuration. https://github.com/hail-is/hail/blob/9706dd493515bce5aa88c623a83f899e8f8b801b/hail/python/hailtop/hailctl/dataproc/start.py#L262-L265. Hail version: 0.2.57-3f3afaa1d7bd. Zulip chat for context; https://hail.zulipchat.com/#narrow/stream/128581-Cloud-support/topic/403.20on.20public.20file",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9587
https://github.com/hail-is/hail/issues/9587:43,Modifiability,config,configurations,43,"`hailctl dataproc` can pass through gcloud configurations specified with `--configuration` to the `gcloud dataproc` commands that it runs. However, that argument is often not respected for other `gcloud` commands that `hailctl dataproc` may run. For example, `hailctl dataproc start --configuration some_config` gets the project ID for requester pays configuration from the default gcloud configuration, not the specified configuration. https://github.com/hail-is/hail/blob/9706dd493515bce5aa88c623a83f899e8f8b801b/hail/python/hailtop/hailctl/dataproc/start.py#L262-L265. Hail version: 0.2.57-3f3afaa1d7bd. Zulip chat for context; https://hail.zulipchat.com/#narrow/stream/128581-Cloud-support/topic/403.20on.20public.20file",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9587
https://github.com/hail-is/hail/issues/9587:76,Modifiability,config,configuration,76,"`hailctl dataproc` can pass through gcloud configurations specified with `--configuration` to the `gcloud dataproc` commands that it runs. However, that argument is often not respected for other `gcloud` commands that `hailctl dataproc` may run. For example, `hailctl dataproc start --configuration some_config` gets the project ID for requester pays configuration from the default gcloud configuration, not the specified configuration. https://github.com/hail-is/hail/blob/9706dd493515bce5aa88c623a83f899e8f8b801b/hail/python/hailtop/hailctl/dataproc/start.py#L262-L265. Hail version: 0.2.57-3f3afaa1d7bd. Zulip chat for context; https://hail.zulipchat.com/#narrow/stream/128581-Cloud-support/topic/403.20on.20public.20file",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9587
https://github.com/hail-is/hail/issues/9587:285,Modifiability,config,configuration,285,"`hailctl dataproc` can pass through gcloud configurations specified with `--configuration` to the `gcloud dataproc` commands that it runs. However, that argument is often not respected for other `gcloud` commands that `hailctl dataproc` may run. For example, `hailctl dataproc start --configuration some_config` gets the project ID for requester pays configuration from the default gcloud configuration, not the specified configuration. https://github.com/hail-is/hail/blob/9706dd493515bce5aa88c623a83f899e8f8b801b/hail/python/hailtop/hailctl/dataproc/start.py#L262-L265. Hail version: 0.2.57-3f3afaa1d7bd. Zulip chat for context; https://hail.zulipchat.com/#narrow/stream/128581-Cloud-support/topic/403.20on.20public.20file",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9587
https://github.com/hail-is/hail/issues/9587:351,Modifiability,config,configuration,351,"`hailctl dataproc` can pass through gcloud configurations specified with `--configuration` to the `gcloud dataproc` commands that it runs. However, that argument is often not respected for other `gcloud` commands that `hailctl dataproc` may run. For example, `hailctl dataproc start --configuration some_config` gets the project ID for requester pays configuration from the default gcloud configuration, not the specified configuration. https://github.com/hail-is/hail/blob/9706dd493515bce5aa88c623a83f899e8f8b801b/hail/python/hailtop/hailctl/dataproc/start.py#L262-L265. Hail version: 0.2.57-3f3afaa1d7bd. Zulip chat for context; https://hail.zulipchat.com/#narrow/stream/128581-Cloud-support/topic/403.20on.20public.20file",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9587
https://github.com/hail-is/hail/issues/9587:389,Modifiability,config,configuration,389,"`hailctl dataproc` can pass through gcloud configurations specified with `--configuration` to the `gcloud dataproc` commands that it runs. However, that argument is often not respected for other `gcloud` commands that `hailctl dataproc` may run. For example, `hailctl dataproc start --configuration some_config` gets the project ID for requester pays configuration from the default gcloud configuration, not the specified configuration. https://github.com/hail-is/hail/blob/9706dd493515bce5aa88c623a83f899e8f8b801b/hail/python/hailtop/hailctl/dataproc/start.py#L262-L265. Hail version: 0.2.57-3f3afaa1d7bd. Zulip chat for context; https://hail.zulipchat.com/#narrow/stream/128581-Cloud-support/topic/403.20on.20public.20file",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9587
https://github.com/hail-is/hail/issues/9587:422,Modifiability,config,configuration,422,"`hailctl dataproc` can pass through gcloud configurations specified with `--configuration` to the `gcloud dataproc` commands that it runs. However, that argument is often not respected for other `gcloud` commands that `hailctl dataproc` may run. For example, `hailctl dataproc start --configuration some_config` gets the project ID for requester pays configuration from the default gcloud configuration, not the specified configuration. https://github.com/hail-is/hail/blob/9706dd493515bce5aa88c623a83f899e8f8b801b/hail/python/hailtop/hailctl/dataproc/start.py#L262-L265. Hail version: 0.2.57-3f3afaa1d7bd. Zulip chat for context; https://hail.zulipchat.com/#narrow/stream/128581-Cloud-support/topic/403.20on.20public.20file",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9587
https://github.com/hail-is/hail/pull/9591:10,Testability,test,tested,10,Currently tested with TableLiteral on the Spark backend.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9591
https://github.com/hail-is/hail/pull/9593:586,Availability,error,errors,586,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9593
https://github.com/hail-is/hail/pull/9593:1048,Availability,down,downloads,1048,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9593
https://github.com/hail-is/hail/pull/9593:133,Deployability,install,install,133,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9593
https://github.com/hail-is/hail/pull/9593:249,Deployability,install,installed,249,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9593
https://github.com/hail-is/hail/pull/9593:318,Deployability,install,installed,318,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9593
https://github.com/hail-is/hail/pull/9593:398,Deployability,install,installed,398,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9593
https://github.com/hail-is/hail/pull/9593:471,Deployability,install,installed,471,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9593
https://github.com/hail-is/hail/pull/9593:636,Deployability,install,installed,636,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9593
https://github.com/hail-is/hail/pull/9593:695,Deployability,install,install,695,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9593
https://github.com/hail-is/hail/pull/9593:756,Deployability,install,install,756,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9593
https://github.com/hail-is/hail/pull/9593:774,Deployability,configurat,configuration,774,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9593
https://github.com/hail-is/hail/pull/9593:853,Deployability,install,install,853,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9593
https://github.com/hail-is/hail/pull/9593:903,Deployability,install,install,903,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9593
https://github.com/hail-is/hail/pull/9593:1316,Deployability,install,install,1316,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9593
https://github.com/hail-is/hail/pull/9593:1484,Deployability,install,installed,1484,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9593
https://github.com/hail-is/hail/pull/9593:191,Integrability,message,message,191,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9593
https://github.com/hail-is/hail/pull/9593:1102,Integrability,depend,depend,1102,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9593
https://github.com/hail-is/hail/pull/9593:1379,Integrability,depend,depend,1379,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9593
https://github.com/hail-is/hail/pull/9593:774,Modifiability,config,configuration,774,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9593
https://github.com/hail-is/hail/pull/9593:1219,Testability,benchmark,benchmark,1219,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9593
https://github.com/hail-is/hail/pull/9594:227,Availability,down,download,227,This PR is stacked on #9593. The key files to look at are in `docker/hail-ubuntu`. I introduced `hail-apt-get-install` which packages up the `apt-get update` and the removal of temporary files. I also set the number of package-download retries to 5.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9594
https://github.com/hail-is/hail/pull/9594:110,Deployability,install,install,110,This PR is stacked on #9593. The key files to look at are in `docker/hail-ubuntu`. I introduced `hail-apt-get-install` which packages up the `apt-get update` and the removal of temporary files. I also set the number of package-download retries to 5.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9594
https://github.com/hail-is/hail/pull/9594:150,Deployability,update,update,150,This PR is stacked on #9593. The key files to look at are in `docker/hail-ubuntu`. I introduced `hail-apt-get-install` which packages up the `apt-get update` and the removal of temporary files. I also set the number of package-download retries to 5.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9594
https://github.com/hail-is/hail/pull/9596:47,Availability,error,error,47,"- Expose init_local.; - Fix formatting of some error messages (stray }).; - Fix index paths, they don't have a ""parts"" component, have "".idx"" suffix. This showed up as an issue interopreating between Spark and local modes. FYI @tpoterba rather than just testing them independently, it might be worthwhile to have write/read interop tests between the various backends. Spark to local is partially tested by the pre-existing (matrix)tables tests, but not the other way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9596
https://github.com/hail-is/hail/pull/9596:53,Integrability,message,messages,53,"- Expose init_local.; - Fix formatting of some error messages (stray }).; - Fix index paths, they don't have a ""parts"" component, have "".idx"" suffix. This showed up as an issue interopreating between Spark and local modes. FYI @tpoterba rather than just testing them independently, it might be worthwhile to have write/read interop tests between the various backends. Spark to local is partially tested by the pre-existing (matrix)tables tests, but not the other way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9596
https://github.com/hail-is/hail/pull/9596:2,Security,Expose,Expose,2,"- Expose init_local.; - Fix formatting of some error messages (stray }).; - Fix index paths, they don't have a ""parts"" component, have "".idx"" suffix. This showed up as an issue interopreating between Spark and local modes. FYI @tpoterba rather than just testing them independently, it might be worthwhile to have write/read interop tests between the various backends. Spark to local is partially tested by the pre-existing (matrix)tables tests, but not the other way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9596
https://github.com/hail-is/hail/pull/9596:254,Testability,test,testing,254,"- Expose init_local.; - Fix formatting of some error messages (stray }).; - Fix index paths, they don't have a ""parts"" component, have "".idx"" suffix. This showed up as an issue interopreating between Spark and local modes. FYI @tpoterba rather than just testing them independently, it might be worthwhile to have write/read interop tests between the various backends. Spark to local is partially tested by the pre-existing (matrix)tables tests, but not the other way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9596
https://github.com/hail-is/hail/pull/9596:332,Testability,test,tests,332,"- Expose init_local.; - Fix formatting of some error messages (stray }).; - Fix index paths, they don't have a ""parts"" component, have "".idx"" suffix. This showed up as an issue interopreating between Spark and local modes. FYI @tpoterba rather than just testing them independently, it might be worthwhile to have write/read interop tests between the various backends. Spark to local is partially tested by the pre-existing (matrix)tables tests, but not the other way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9596
https://github.com/hail-is/hail/pull/9596:396,Testability,test,tested,396,"- Expose init_local.; - Fix formatting of some error messages (stray }).; - Fix index paths, they don't have a ""parts"" component, have "".idx"" suffix. This showed up as an issue interopreating between Spark and local modes. FYI @tpoterba rather than just testing them independently, it might be worthwhile to have write/read interop tests between the various backends. Spark to local is partially tested by the pre-existing (matrix)tables tests, but not the other way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9596
https://github.com/hail-is/hail/pull/9596:438,Testability,test,tests,438,"- Expose init_local.; - Fix formatting of some error messages (stray }).; - Fix index paths, they don't have a ""parts"" component, have "".idx"" suffix. This showed up as an issue interopreating between Spark and local modes. FYI @tpoterba rather than just testing them independently, it might be worthwhile to have write/read interop tests between the various backends. Spark to local is partially tested by the pre-existing (matrix)tables tests, but not the other way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9596
https://github.com/hail-is/hail/pull/9597:834,Integrability,depend,dependencies,834,"High level take-aways:. - Hail docs now have syntax highlighting (we just needed to import pygments.css).; - Search works again.; - There are now only two root HTML templates: `site/templates/base.html` and; `web_common/web_common/templates/layout.html`. I cannot unify these further; because our services and our main websites actually differ significantly.; - The search/nav bar is now present in the HTML, no JS nonsense to; asynchronously load it into place after HTML rendering.; - Site now has a `make watch` which watches for changes and automatically; re-renders the HTML.; - Site now has a few make rules that facilitate experimenting with how the docs; are displayed within the context of the current development version of site's; CSS & HTML.; - XSLT is now only used by the C++ tests. Smaller things:. - Removed bootstrap dependencies. Did we ever actually use these?; - Removed ""clipboard.js"" dependency. Also not clear from where this came.; - Removed use of the `subtitle` tag, which isn't actually an HTML tag?. Future work:. - Simplify our CSS. It's not possible to logically reason about our CSS. And it; interacts in bad ways with the latent RTD themes. I want a unified Hail visual; theme.; - Clean up the search-related JavaScript in nav-bottom.html and; search.html. These both seem too complicated to just make search work. ---. The thrust of this PR is to restructure Hail's website and documentation to; entirely rely on Jinja2 templates. Previously, we used a mix of Jinja2, XSLT,; and in-browser JavaScript DOM manipulation to piece together a web page. Now, all of Hail's non-service website derives from; `site/templates/base.html`. It is a Jinja2 template with four blocks: title,; meta_description, head, and content. It ensures that:; - Hail's CSS is loaded,; - the Hail icon is set,; - the fonts are loaded,; - the source code highlighter is loaded (prism.js, only used outside the docs); - the nav bar is present and configured.; The nav bar is somewhat complicated. ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9597
https://github.com/hail-is/hail/pull/9597:906,Integrability,depend,dependency,906,"High level take-aways:. - Hail docs now have syntax highlighting (we just needed to import pygments.css).; - Search works again.; - There are now only two root HTML templates: `site/templates/base.html` and; `web_common/web_common/templates/layout.html`. I cannot unify these further; because our services and our main websites actually differ significantly.; - The search/nav bar is now present in the HTML, no JS nonsense to; asynchronously load it into place after HTML rendering.; - Site now has a `make watch` which watches for changes and automatically; re-renders the HTML.; - Site now has a few make rules that facilitate experimenting with how the docs; are displayed within the context of the current development version of site's; CSS & HTML.; - XSLT is now only used by the C++ tests. Smaller things:. - Removed bootstrap dependencies. Did we ever actually use these?; - Removed ""clipboard.js"" dependency. Also not clear from where this came.; - Removed use of the `subtitle` tag, which isn't actually an HTML tag?. Future work:. - Simplify our CSS. It's not possible to logically reason about our CSS. And it; interacts in bad ways with the latent RTD themes. I want a unified Hail visual; theme.; - Clean up the search-related JavaScript in nav-bottom.html and; search.html. These both seem too complicated to just make search work. ---. The thrust of this PR is to restructure Hail's website and documentation to; entirely rely on Jinja2 templates. Previously, we used a mix of Jinja2, XSLT,; and in-browser JavaScript DOM manipulation to piece together a web page. Now, all of Hail's non-service website derives from; `site/templates/base.html`. It is a Jinja2 template with four blocks: title,; meta_description, head, and content. It ensures that:; - Hail's CSS is loaded,; - the Hail icon is set,; - the fonts are loaded,; - the source code highlighter is loaded (prism.js, only used outside the docs); - the nav bar is present and configured.; The nav bar is somewhat complicated. ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9597
https://github.com/hail-is/hail/pull/9597:1951,Modifiability,config,configured,1951,"t clear from where this came.; - Removed use of the `subtitle` tag, which isn't actually an HTML tag?. Future work:. - Simplify our CSS. It's not possible to logically reason about our CSS. And it; interacts in bad ways with the latent RTD themes. I want a unified Hail visual; theme.; - Clean up the search-related JavaScript in nav-bottom.html and; search.html. These both seem too complicated to just make search work. ---. The thrust of this PR is to restructure Hail's website and documentation to; entirely rely on Jinja2 templates. Previously, we used a mix of Jinja2, XSLT,; and in-browser JavaScript DOM manipulation to piece together a web page. Now, all of Hail's non-service website derives from; `site/templates/base.html`. It is a Jinja2 template with four blocks: title,; meta_description, head, and content. It ensures that:; - Hail's CSS is loaded,; - the Hail icon is set,; - the fonts are loaded,; - the source code highlighter is loaded (prism.js, only used outside the docs); - the nav bar is present and configured.; The nav bar is somewhat complicated. There are two pieces. `nav-top.html`; contains the nav bar HTML elements. `nav-bottom.html` contains the JavaScript; code that hooks the search bar up to Algolia and sets the active page in the; navigation. I believe JavaScript which modifies the HTML DOM is traditionally; placed at the bottom of the `body` tag so that it is executed *after* the HTML; DOM is mostly rendered. That's why the navigation/search bar is split across two; files. I also load the `prism.js` source code highlighter at the end of the; body. All of the non-docs pages are defined by html files in `pages`. Each one of; these is a Jinja2 template which derives from the base template. `make render`; converts every template in `pages` into a real HTML file in `www`. Check out; 404.html for a simple example. Once I had the site in working order, I turned my eyes to the docs. I converted; `docs/_templates/layout.html`, the base template for our do",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9597
https://github.com/hail-is/hail/pull/9597:443,Performance,load,load,443,"High level take-aways:. - Hail docs now have syntax highlighting (we just needed to import pygments.css).; - Search works again.; - There are now only two root HTML templates: `site/templates/base.html` and; `web_common/web_common/templates/layout.html`. I cannot unify these further; because our services and our main websites actually differ significantly.; - The search/nav bar is now present in the HTML, no JS nonsense to; asynchronously load it into place after HTML rendering.; - Site now has a `make watch` which watches for changes and automatically; re-renders the HTML.; - Site now has a few make rules that facilitate experimenting with how the docs; are displayed within the context of the current development version of site's; CSS & HTML.; - XSLT is now only used by the C++ tests. Smaller things:. - Removed bootstrap dependencies. Did we ever actually use these?; - Removed ""clipboard.js"" dependency. Also not clear from where this came.; - Removed use of the `subtitle` tag, which isn't actually an HTML tag?. Future work:. - Simplify our CSS. It's not possible to logically reason about our CSS. And it; interacts in bad ways with the latent RTD themes. I want a unified Hail visual; theme.; - Clean up the search-related JavaScript in nav-bottom.html and; search.html. These both seem too complicated to just make search work. ---. The thrust of this PR is to restructure Hail's website and documentation to; entirely rely on Jinja2 templates. Previously, we used a mix of Jinja2, XSLT,; and in-browser JavaScript DOM manipulation to piece together a web page. Now, all of Hail's non-service website derives from; `site/templates/base.html`. It is a Jinja2 template with four blocks: title,; meta_description, head, and content. It ensures that:; - Hail's CSS is loaded,; - the Hail icon is set,; - the fonts are loaded,; - the source code highlighter is loaded (prism.js, only used outside the docs); - the nav bar is present and configured.; The nav bar is somewhat complicated. ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9597
https://github.com/hail-is/hail/pull/9597:1783,Performance,load,loaded,1783,"moved bootstrap dependencies. Did we ever actually use these?; - Removed ""clipboard.js"" dependency. Also not clear from where this came.; - Removed use of the `subtitle` tag, which isn't actually an HTML tag?. Future work:. - Simplify our CSS. It's not possible to logically reason about our CSS. And it; interacts in bad ways with the latent RTD themes. I want a unified Hail visual; theme.; - Clean up the search-related JavaScript in nav-bottom.html and; search.html. These both seem too complicated to just make search work. ---. The thrust of this PR is to restructure Hail's website and documentation to; entirely rely on Jinja2 templates. Previously, we used a mix of Jinja2, XSLT,; and in-browser JavaScript DOM manipulation to piece together a web page. Now, all of Hail's non-service website derives from; `site/templates/base.html`. It is a Jinja2 template with four blocks: title,; meta_description, head, and content. It ensures that:; - Hail's CSS is loaded,; - the Hail icon is set,; - the fonts are loaded,; - the source code highlighter is loaded (prism.js, only used outside the docs); - the nav bar is present and configured.; The nav bar is somewhat complicated. There are two pieces. `nav-top.html`; contains the nav bar HTML elements. `nav-bottom.html` contains the JavaScript; code that hooks the search bar up to Algolia and sets the active page in the; navigation. I believe JavaScript which modifies the HTML DOM is traditionally; placed at the bottom of the `body` tag so that it is executed *after* the HTML; DOM is mostly rendered. That's why the navigation/search bar is split across two; files. I also load the `prism.js` source code highlighter at the end of the; body. All of the non-docs pages are defined by html files in `pages`. Each one of; these is a Jinja2 template which derives from the base template. `make render`; converts every template in `pages` into a real HTML file in `www`. Check out; 404.html for a simple example. Once I had the site in working or",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9597
https://github.com/hail-is/hail/pull/9597:1833,Performance,load,loaded,1833,"moved bootstrap dependencies. Did we ever actually use these?; - Removed ""clipboard.js"" dependency. Also not clear from where this came.; - Removed use of the `subtitle` tag, which isn't actually an HTML tag?. Future work:. - Simplify our CSS. It's not possible to logically reason about our CSS. And it; interacts in bad ways with the latent RTD themes. I want a unified Hail visual; theme.; - Clean up the search-related JavaScript in nav-bottom.html and; search.html. These both seem too complicated to just make search work. ---. The thrust of this PR is to restructure Hail's website and documentation to; entirely rely on Jinja2 templates. Previously, we used a mix of Jinja2, XSLT,; and in-browser JavaScript DOM manipulation to piece together a web page. Now, all of Hail's non-service website derives from; `site/templates/base.html`. It is a Jinja2 template with four blocks: title,; meta_description, head, and content. It ensures that:; - Hail's CSS is loaded,; - the Hail icon is set,; - the fonts are loaded,; - the source code highlighter is loaded (prism.js, only used outside the docs); - the nav bar is present and configured.; The nav bar is somewhat complicated. There are two pieces. `nav-top.html`; contains the nav bar HTML elements. `nav-bottom.html` contains the JavaScript; code that hooks the search bar up to Algolia and sets the active page in the; navigation. I believe JavaScript which modifies the HTML DOM is traditionally; placed at the bottom of the `body` tag so that it is executed *after* the HTML; DOM is mostly rendered. That's why the navigation/search bar is split across two; files. I also load the `prism.js` source code highlighter at the end of the; body. All of the non-docs pages are defined by html files in `pages`. Each one of; these is a Jinja2 template which derives from the base template. `make render`; converts every template in `pages` into a real HTML file in `www`. Check out; 404.html for a simple example. Once I had the site in working or",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9597
https://github.com/hail-is/hail/pull/9597:1875,Performance,load,loaded,1875,"moved bootstrap dependencies. Did we ever actually use these?; - Removed ""clipboard.js"" dependency. Also not clear from where this came.; - Removed use of the `subtitle` tag, which isn't actually an HTML tag?. Future work:. - Simplify our CSS. It's not possible to logically reason about our CSS. And it; interacts in bad ways with the latent RTD themes. I want a unified Hail visual; theme.; - Clean up the search-related JavaScript in nav-bottom.html and; search.html. These both seem too complicated to just make search work. ---. The thrust of this PR is to restructure Hail's website and documentation to; entirely rely on Jinja2 templates. Previously, we used a mix of Jinja2, XSLT,; and in-browser JavaScript DOM manipulation to piece together a web page. Now, all of Hail's non-service website derives from; `site/templates/base.html`. It is a Jinja2 template with four blocks: title,; meta_description, head, and content. It ensures that:; - Hail's CSS is loaded,; - the Hail icon is set,; - the fonts are loaded,; - the source code highlighter is loaded (prism.js, only used outside the docs); - the nav bar is present and configured.; The nav bar is somewhat complicated. There are two pieces. `nav-top.html`; contains the nav bar HTML elements. `nav-bottom.html` contains the JavaScript; code that hooks the search bar up to Algolia and sets the active page in the; navigation. I believe JavaScript which modifies the HTML DOM is traditionally; placed at the bottom of the `body` tag so that it is executed *after* the HTML; DOM is mostly rendered. That's why the navigation/search bar is split across two; files. I also load the `prism.js` source code highlighter at the end of the; body. All of the non-docs pages are defined by html files in `pages`. Each one of; these is a Jinja2 template which derives from the base template. `make render`; converts every template in `pages` into a real HTML file in `www`. Check out; 404.html for a simple example. Once I had the site in working or",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9597
https://github.com/hail-is/hail/pull/9597:2451,Performance,load,load,2451,"mplates. Previously, we used a mix of Jinja2, XSLT,; and in-browser JavaScript DOM manipulation to piece together a web page. Now, all of Hail's non-service website derives from; `site/templates/base.html`. It is a Jinja2 template with four blocks: title,; meta_description, head, and content. It ensures that:; - Hail's CSS is loaded,; - the Hail icon is set,; - the fonts are loaded,; - the source code highlighter is loaded (prism.js, only used outside the docs); - the nav bar is present and configured.; The nav bar is somewhat complicated. There are two pieces. `nav-top.html`; contains the nav bar HTML elements. `nav-bottom.html` contains the JavaScript; code that hooks the search bar up to Algolia and sets the active page in the; navigation. I believe JavaScript which modifies the HTML DOM is traditionally; placed at the bottom of the `body` tag so that it is executed *after* the HTML; DOM is mostly rendered. That's why the navigation/search bar is split across two; files. I also load the `prism.js` source code highlighter at the end of the; body. All of the non-docs pages are defined by html files in `pages`. Each one of; these is a Jinja2 template which derives from the base template. `make render`; converts every template in `pages` into a real HTML file in `www`. Check out; 404.html for a simple example. Once I had the site in working order, I turned my eyes to the docs. I converted; `docs/_templates/layout.html`, the base template for our docs, into a template; which derives from `site/templates/base.html`. That ensures everyone is using; the same CSS, the same navigation/search bar, same icon set, etc. Convincing; Sphinx to work like this was actually really easy because Sphinx already uses; Jinja2 templates! I just added site's templates folder to the Sphinx; `templates_path`. I eliminated a few conditionals that are only relevant if your docs are also; rendered on RTD's server, which ours are not. Finally, in order to experiment quickly with this, I changed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9597
https://github.com/hail-is/hail/pull/9597:790,Testability,test,tests,790,"High level take-aways:. - Hail docs now have syntax highlighting (we just needed to import pygments.css).; - Search works again.; - There are now only two root HTML templates: `site/templates/base.html` and; `web_common/web_common/templates/layout.html`. I cannot unify these further; because our services and our main websites actually differ significantly.; - The search/nav bar is now present in the HTML, no JS nonsense to; asynchronously load it into place after HTML rendering.; - Site now has a `make watch` which watches for changes and automatically; re-renders the HTML.; - Site now has a few make rules that facilitate experimenting with how the docs; are displayed within the context of the current development version of site's; CSS & HTML.; - XSLT is now only used by the C++ tests. Smaller things:. - Removed bootstrap dependencies. Did we ever actually use these?; - Removed ""clipboard.js"" dependency. Also not clear from where this came.; - Removed use of the `subtitle` tag, which isn't actually an HTML tag?. Future work:. - Simplify our CSS. It's not possible to logically reason about our CSS. And it; interacts in bad ways with the latent RTD themes. I want a unified Hail visual; theme.; - Clean up the search-related JavaScript in nav-bottom.html and; search.html. These both seem too complicated to just make search work. ---. The thrust of this PR is to restructure Hail's website and documentation to; entirely rely on Jinja2 templates. Previously, we used a mix of Jinja2, XSLT,; and in-browser JavaScript DOM manipulation to piece together a web page. Now, all of Hail's non-service website derives from; `site/templates/base.html`. It is a Jinja2 template with four blocks: title,; meta_description, head, and content. It ensures that:; - Hail's CSS is loaded,; - the Hail icon is set,; - the fonts are loaded,; - the source code highlighter is loaded (prism.js, only used outside the docs); - the nav bar is present and configured.; The nav bar is somewhat complicated. ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9597
https://github.com/hail-is/hail/pull/9597:1083,Testability,log,logically,1083,"ort pygments.css).; - Search works again.; - There are now only two root HTML templates: `site/templates/base.html` and; `web_common/web_common/templates/layout.html`. I cannot unify these further; because our services and our main websites actually differ significantly.; - The search/nav bar is now present in the HTML, no JS nonsense to; asynchronously load it into place after HTML rendering.; - Site now has a `make watch` which watches for changes and automatically; re-renders the HTML.; - Site now has a few make rules that facilitate experimenting with how the docs; are displayed within the context of the current development version of site's; CSS & HTML.; - XSLT is now only used by the C++ tests. Smaller things:. - Removed bootstrap dependencies. Did we ever actually use these?; - Removed ""clipboard.js"" dependency. Also not clear from where this came.; - Removed use of the `subtitle` tag, which isn't actually an HTML tag?. Future work:. - Simplify our CSS. It's not possible to logically reason about our CSS. And it; interacts in bad ways with the latent RTD themes. I want a unified Hail visual; theme.; - Clean up the search-related JavaScript in nav-bottom.html and; search.html. These both seem too complicated to just make search work. ---. The thrust of this PR is to restructure Hail's website and documentation to; entirely rely on Jinja2 templates. Previously, we used a mix of Jinja2, XSLT,; and in-browser JavaScript DOM manipulation to piece together a web page. Now, all of Hail's non-service website derives from; `site/templates/base.html`. It is a Jinja2 template with four blocks: title,; meta_description, head, and content. It ensures that:; - Hail's CSS is loaded,; - the Hail icon is set,; - the fonts are loaded,; - the source code highlighter is loaded (prism.js, only used outside the docs); - the nav bar is present and configured.; The nav bar is somewhat complicated. There are two pieces. `nav-top.html`; contains the nav bar HTML elements. `nav-bottom.h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9597
https://github.com/hail-is/hail/pull/9597:927,Usability,clear,clear,927,"High level take-aways:. - Hail docs now have syntax highlighting (we just needed to import pygments.css).; - Search works again.; - There are now only two root HTML templates: `site/templates/base.html` and; `web_common/web_common/templates/layout.html`. I cannot unify these further; because our services and our main websites actually differ significantly.; - The search/nav bar is now present in the HTML, no JS nonsense to; asynchronously load it into place after HTML rendering.; - Site now has a `make watch` which watches for changes and automatically; re-renders the HTML.; - Site now has a few make rules that facilitate experimenting with how the docs; are displayed within the context of the current development version of site's; CSS & HTML.; - XSLT is now only used by the C++ tests. Smaller things:. - Removed bootstrap dependencies. Did we ever actually use these?; - Removed ""clipboard.js"" dependency. Also not clear from where this came.; - Removed use of the `subtitle` tag, which isn't actually an HTML tag?. Future work:. - Simplify our CSS. It's not possible to logically reason about our CSS. And it; interacts in bad ways with the latent RTD themes. I want a unified Hail visual; theme.; - Clean up the search-related JavaScript in nav-bottom.html and; search.html. These both seem too complicated to just make search work. ---. The thrust of this PR is to restructure Hail's website and documentation to; entirely rely on Jinja2 templates. Previously, we used a mix of Jinja2, XSLT,; and in-browser JavaScript DOM manipulation to piece together a web page. Now, all of Hail's non-service website derives from; `site/templates/base.html`. It is a Jinja2 template with four blocks: title,; meta_description, head, and content. It ensures that:; - Hail's CSS is loaded,; - the Hail icon is set,; - the fonts are loaded,; - the source code highlighter is loaded (prism.js, only used outside the docs); - the nav bar is present and configured.; The nav bar is somewhat complicated. ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9597
https://github.com/hail-is/hail/pull/9597:1044,Usability,Simpl,Simplify,1044," highlighting (we just needed to import pygments.css).; - Search works again.; - There are now only two root HTML templates: `site/templates/base.html` and; `web_common/web_common/templates/layout.html`. I cannot unify these further; because our services and our main websites actually differ significantly.; - The search/nav bar is now present in the HTML, no JS nonsense to; asynchronously load it into place after HTML rendering.; - Site now has a `make watch` which watches for changes and automatically; re-renders the HTML.; - Site now has a few make rules that facilitate experimenting with how the docs; are displayed within the context of the current development version of site's; CSS & HTML.; - XSLT is now only used by the C++ tests. Smaller things:. - Removed bootstrap dependencies. Did we ever actually use these?; - Removed ""clipboard.js"" dependency. Also not clear from where this came.; - Removed use of the `subtitle` tag, which isn't actually an HTML tag?. Future work:. - Simplify our CSS. It's not possible to logically reason about our CSS. And it; interacts in bad ways with the latent RTD themes. I want a unified Hail visual; theme.; - Clean up the search-related JavaScript in nav-bottom.html and; search.html. These both seem too complicated to just make search work. ---. The thrust of this PR is to restructure Hail's website and documentation to; entirely rely on Jinja2 templates. Previously, we used a mix of Jinja2, XSLT,; and in-browser JavaScript DOM manipulation to piece together a web page. Now, all of Hail's non-service website derives from; `site/templates/base.html`. It is a Jinja2 template with four blocks: title,; meta_description, head, and content. It ensures that:; - Hail's CSS is loaded,; - the Hail icon is set,; - the fonts are loaded,; - the source code highlighter is loaded (prism.js, only used outside the docs); - the nav bar is present and configured.; The nav bar is somewhat complicated. There are two pieces. `nav-top.html`; contains the",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9597
https://github.com/hail-is/hail/pull/9597:2770,Usability,simpl,simple,2770,"web page. Now, all of Hail's non-service website derives from; `site/templates/base.html`. It is a Jinja2 template with four blocks: title,; meta_description, head, and content. It ensures that:; - Hail's CSS is loaded,; - the Hail icon is set,; - the fonts are loaded,; - the source code highlighter is loaded (prism.js, only used outside the docs); - the nav bar is present and configured.; The nav bar is somewhat complicated. There are two pieces. `nav-top.html`; contains the nav bar HTML elements. `nav-bottom.html` contains the JavaScript; code that hooks the search bar up to Algolia and sets the active page in the; navigation. I believe JavaScript which modifies the HTML DOM is traditionally; placed at the bottom of the `body` tag so that it is executed *after* the HTML; DOM is mostly rendered. That's why the navigation/search bar is split across two; files. I also load the `prism.js` source code highlighter at the end of the; body. All of the non-docs pages are defined by html files in `pages`. Each one of; these is a Jinja2 template which derives from the base template. `make render`; converts every template in `pages` into a real HTML file in `www`. Check out; 404.html for a simple example. Once I had the site in working order, I turned my eyes to the docs. I converted; `docs/_templates/layout.html`, the base template for our docs, into a template; which derives from `site/templates/base.html`. That ensures everyone is using; the same CSS, the same navigation/search bar, same icon set, etc. Convincing; Sphinx to work like this was actually really easy because Sphinx already uses; Jinja2 templates! I just added site's templates folder to the Sphinx; `templates_path`. I eliminated a few conditionals that are only relevant if your docs are also; rendered on RTD's server, which ours are not. Finally, in order to experiment quickly with this, I changed site's Makefile to; add some rules that keep the automatically render the site and docs in response; to file edits.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9597
https://github.com/hail-is/hail/pull/9598:96,Testability,test,tests,96,I think this PR is mostly there. We might want to make the docs more explicit. I didn't add any tests yet to assert everything is working. I was testing it by hand by not using a local SSD and making the disk size 25 GB so the reserved space is 0 GB. I watched the worker logs in stack driver to make sure it was working. I'd appreciate ideas for tests. Feel free to work on this while I'm away. I checked the disks in the google console to make sure I didn't have any garbage.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9598
https://github.com/hail-is/hail/pull/9598:109,Testability,assert,assert,109,I think this PR is mostly there. We might want to make the docs more explicit. I didn't add any tests yet to assert everything is working. I was testing it by hand by not using a local SSD and making the disk size 25 GB so the reserved space is 0 GB. I watched the worker logs in stack driver to make sure it was working. I'd appreciate ideas for tests. Feel free to work on this while I'm away. I checked the disks in the google console to make sure I didn't have any garbage.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9598
https://github.com/hail-is/hail/pull/9598:145,Testability,test,testing,145,I think this PR is mostly there. We might want to make the docs more explicit. I didn't add any tests yet to assert everything is working. I was testing it by hand by not using a local SSD and making the disk size 25 GB so the reserved space is 0 GB. I watched the worker logs in stack driver to make sure it was working. I'd appreciate ideas for tests. Feel free to work on this while I'm away. I checked the disks in the google console to make sure I didn't have any garbage.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9598
https://github.com/hail-is/hail/pull/9598:272,Testability,log,logs,272,I think this PR is mostly there. We might want to make the docs more explicit. I didn't add any tests yet to assert everything is working. I was testing it by hand by not using a local SSD and making the disk size 25 GB so the reserved space is 0 GB. I watched the worker logs in stack driver to make sure it was working. I'd appreciate ideas for tests. Feel free to work on this while I'm away. I checked the disks in the google console to make sure I didn't have any garbage.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9598
https://github.com/hail-is/hail/pull/9598:347,Testability,test,tests,347,I think this PR is mostly there. We might want to make the docs more explicit. I didn't add any tests yet to assert everything is working. I was testing it by hand by not using a local SSD and making the disk size 25 GB so the reserved space is 0 GB. I watched the worker logs in stack driver to make sure it was working. I'd appreciate ideas for tests. Feel free to work on this while I'm away. I checked the disks in the google console to make sure I didn't have any garbage.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9598
https://github.com/hail-is/hail/issues/9600:1138,Availability,Error,Error,1138,"--------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-3-ca1bc15ebb3c> in <module>; ----> 1 hl.hadoop_ls(""gs://bw2/bla""). /Library/Python/3.7/site-packages/hail/utils/hadoop_utils.py in hadoop_ls(path); 212 :obj:`list` [:obj:`dict`]; 213 """"""; --> 214 return Env.fs().ls(path); 215; 216. /Library/Python/3.7/site-packages/hail/fs/hadoop_fs.py in ls(self, path); 40; 41 def ls(self, path: str) -> List[Dict]:; ---> 42 return json.loads(self._utils_package_object.ls(self._jfs, path)); 43; 44 def mkdir(self, path: str) -> None:. /Library/Python/3.7/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258; 1259 for temp_arg in temp_args:. /Library/Python/3.7/site-packages/hail/backend/spark_backend.py in deco(*args, **kwargs); 49 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 50 'Hail version: %s\n'; ---> 51 'Error summary: %s' % (deepest, full, hail.__version__, deepest), error_id) from None; 52 except pyspark.sql.utils.CapturedException as e:; 53 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: NullPointerException: null. Java stack trace:; java.lang.NullPointerException: null; 	at scala.collection.mutable.ArrayOps$ofRef$.length$extension(ArrayOps.scala:192); 	at scala.collection.mutable.ArrayOps$ofRef.length(ArrayOps.scala:192); 	at scala.collection.SeqLike$class.size(SeqLike.scala:106); 	at scala.collection.mutable.ArrayOps$ofRef.size(ArrayOps.scala:186); 	at scala.collection.mutable.Builder$class.sizeHint(Builder.scala:69); 	at scala.collection.mutable.ArrayBuilder.sizeHint(ArrayBuilder.scala:22); 	at scala.collection.TraversableLike$class.builder$1(TraversableLike.scala:230); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:233); 	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); 	at is.hail.io.fs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9600
https://github.com/hail-is/hail/issues/9600:2995,Availability,Error,Error,2995,"*kwargs); 49 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 50 'Hail version: %s\n'; ---> 51 'Error summary: %s' % (deepest, full, hail.__version__, deepest), error_id) from None; 52 except pyspark.sql.utils.CapturedException as e:; 53 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: NullPointerException: null. Java stack trace:; java.lang.NullPointerException: null; 	at scala.collection.mutable.ArrayOps$ofRef$.length$extension(ArrayOps.scala:192); 	at scala.collection.mutable.ArrayOps$ofRef.length(ArrayOps.scala:192); 	at scala.collection.SeqLike$class.size(SeqLike.scala:106); 	at scala.collection.mutable.ArrayOps$ofRef.size(ArrayOps.scala:186); 	at scala.collection.mutable.Builder$class.sizeHint(Builder.scala:69); 	at scala.collection.mutable.ArrayBuilder.sizeHint(ArrayBuilder.scala:22); 	at scala.collection.TraversableLike$class.builder$1(TraversableLike.scala:230); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:233); 	at scala.collection.mutable.ArrayOps$ofRef.map(ArrayOps.scala:186); 	at is.hail.io.fs.HadoopFS.listStatus(HadoopFS.scala:105); 	at is.hail.utils.Py4jUtils$class.ls(Py4jUtils.scala:55); 	at is.hail.utils.package$.ls(package.scala:77); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.58-3f304aae6ce2; Error summary: NullPointerException: null; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9600
https://github.com/hail-is/hail/issues/9600:581,Performance,load,loads,581,"```; In [1]: import hail as hl; In [2]: hl.hadoop_ls(""gs://bw2/bla""); ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-3-ca1bc15ebb3c> in <module>; ----> 1 hl.hadoop_ls(""gs://bw2/bla""). /Library/Python/3.7/site-packages/hail/utils/hadoop_utils.py in hadoop_ls(path); 212 :obj:`list` [:obj:`dict`]; 213 """"""; --> 214 return Env.fs().ls(path); 215; 216. /Library/Python/3.7/site-packages/hail/fs/hadoop_fs.py in ls(self, path); 40; 41 def ls(self, path: str) -> List[Dict]:; ---> 42 return json.loads(self._utils_package_object.ls(self._jfs, path)); 43; 44 def mkdir(self, path: str) -> None:. /Library/Python/3.7/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258; 1259 for temp_arg in temp_args:. /Library/Python/3.7/site-packages/hail/backend/spark_backend.py in deco(*args, **kwargs); 49 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 50 'Hail version: %s\n'; ---> 51 'Error summary: %s' % (deepest, full, hail.__version__, deepest), error_id) from None; 52 except pyspark.sql.utils.CapturedException as e:; 53 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: NullPointerException: null. Java stack trace:; java.lang.NullPointerException: null; 	at scala.collection.mutable.ArrayOps$ofRef$.length$extension(ArrayOps.scala:192); 	at scala.collection.mutable.ArrayOps$ofRef.length(ArrayOps.scala:192); 	at scala.collection.SeqLike$class.size(SeqLike.scala:106); 	at scala.collection.mutable.ArrayOps$ofRef.size(ArrayOps.scala:186); 	at scala.collection.mutable.Builder$class.sizeHint(Builder.scala:69); 	at scala.collection.mutable.ArrayBuilder.sizeHint(ArrayBuilder.scala:22); 	at scala.collection.TraversableLike$class.builder$1(TraversableLike.scala:230); 	at scala.collection.TraversableLike$class.map(TraversableLike",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9600
https://github.com/hail-is/hail/pull/9605:334,Deployability,install,installed,334,"This allows the user to specify the cloud platform ('gcp' or 'aws') they are using when accessing datasets via the datasets API and annotation DB. A user running hail on AWS would read from the s3 bucket, and a user running on GCP would read from the gs bucket (can also still read locally from gs bucket with cloud storage connector installed). Not intended for cross-platform use like running a dataproc cluster and trying to access the s3 bucket, or trying to access the gs bucket on an EMR cluster. Will assume user on AWS has their configuration set with their credentials. . Did not have permissions to set up a cluster or EC2 instance on AWS to test, but was able to access all the datasets without issue on a dataproc cluster when using s3a:// prefixes and providing my AWS credentials in the spark config. So these changes should (hopefully) work fine on an EMR cluster with the s3:// client. Everything worked as expected on GCP. Overview of changes:; - Added missing type hints to `load_dataset()` function and methods in `db.py`.; - In `datasets.json`:; - Added AWS urls so now for each version of a dataset in dataset[""versions""], the url entry looks like:; ```; ""url"": {; ""aws"": {; ""us"": ""s3://hail-datasets-us-east-1/...""; },; ""gcp"": {; ""eu"": ""gs://hail-datasets-eu/..."",; ""us"": ""gs://hail-datasets-us/...; }; ```; - In `load_dataset()` function:; - Added `cloud` parameter, set default values to `region='us'` and `cloud='gcp`.; - In `DB` class:; - Added `cloud` parameter to constructor, set default values to `region='us'` and `cloud='gcp`.; - All datasets in `datasets.json` currently end up in the `_DB__by_name` dictionary, even if not annotation datasets. Added line 279 in `db.py` to fix this and filter out datasets that are not annotation datasets (datasets missing ""annotation_db"" key).; - In `Dataset` class:; - Added `cloud` and `custom_config` parameters to `Dataset.from_name_and_json()` to pass to `DatasetVersion.from_json()` to grab correct urls for platform.; - Refac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9605
https://github.com/hail-is/hail/pull/9605:537,Deployability,configurat,configuration,537,"This allows the user to specify the cloud platform ('gcp' or 'aws') they are using when accessing datasets via the datasets API and annotation DB. A user running hail on AWS would read from the s3 bucket, and a user running on GCP would read from the gs bucket (can also still read locally from gs bucket with cloud storage connector installed). Not intended for cross-platform use like running a dataproc cluster and trying to access the s3 bucket, or trying to access the gs bucket on an EMR cluster. Will assume user on AWS has their configuration set with their credentials. . Did not have permissions to set up a cluster or EC2 instance on AWS to test, but was able to access all the datasets without issue on a dataproc cluster when using s3a:// prefixes and providing my AWS credentials in the spark config. So these changes should (hopefully) work fine on an EMR cluster with the s3:// client. Everything worked as expected on GCP. Overview of changes:; - Added missing type hints to `load_dataset()` function and methods in `db.py`.; - In `datasets.json`:; - Added AWS urls so now for each version of a dataset in dataset[""versions""], the url entry looks like:; ```; ""url"": {; ""aws"": {; ""us"": ""s3://hail-datasets-us-east-1/...""; },; ""gcp"": {; ""eu"": ""gs://hail-datasets-eu/..."",; ""us"": ""gs://hail-datasets-us/...; }; ```; - In `load_dataset()` function:; - Added `cloud` parameter, set default values to `region='us'` and `cloud='gcp`.; - In `DB` class:; - Added `cloud` parameter to constructor, set default values to `region='us'` and `cloud='gcp`.; - All datasets in `datasets.json` currently end up in the `_DB__by_name` dictionary, even if not annotation datasets. Added line 279 in `db.py` to fix this and filter out datasets that are not annotation datasets (datasets missing ""annotation_db"" key).; - In `Dataset` class:; - Added `cloud` and `custom_config` parameters to `Dataset.from_name_and_json()` to pass to `DatasetVersion.from_json()` to grab correct urls for platform.; - Refac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9605
https://github.com/hail-is/hail/pull/9605:537,Modifiability,config,configuration,537,"This allows the user to specify the cloud platform ('gcp' or 'aws') they are using when accessing datasets via the datasets API and annotation DB. A user running hail on AWS would read from the s3 bucket, and a user running on GCP would read from the gs bucket (can also still read locally from gs bucket with cloud storage connector installed). Not intended for cross-platform use like running a dataproc cluster and trying to access the s3 bucket, or trying to access the gs bucket on an EMR cluster. Will assume user on AWS has their configuration set with their credentials. . Did not have permissions to set up a cluster or EC2 instance on AWS to test, but was able to access all the datasets without issue on a dataproc cluster when using s3a:// prefixes and providing my AWS credentials in the spark config. So these changes should (hopefully) work fine on an EMR cluster with the s3:// client. Everything worked as expected on GCP. Overview of changes:; - Added missing type hints to `load_dataset()` function and methods in `db.py`.; - In `datasets.json`:; - Added AWS urls so now for each version of a dataset in dataset[""versions""], the url entry looks like:; ```; ""url"": {; ""aws"": {; ""us"": ""s3://hail-datasets-us-east-1/...""; },; ""gcp"": {; ""eu"": ""gs://hail-datasets-eu/..."",; ""us"": ""gs://hail-datasets-us/...; }; ```; - In `load_dataset()` function:; - Added `cloud` parameter, set default values to `region='us'` and `cloud='gcp`.; - In `DB` class:; - Added `cloud` parameter to constructor, set default values to `region='us'` and `cloud='gcp`.; - All datasets in `datasets.json` currently end up in the `_DB__by_name` dictionary, even if not annotation datasets. Added line 279 in `db.py` to fix this and filter out datasets that are not annotation datasets (datasets missing ""annotation_db"" key).; - In `Dataset` class:; - Added `cloud` and `custom_config` parameters to `Dataset.from_name_and_json()` to pass to `DatasetVersion.from_json()` to grab correct urls for platform.; - Refac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9605
https://github.com/hail-is/hail/pull/9605:807,Modifiability,config,config,807,"This allows the user to specify the cloud platform ('gcp' or 'aws') they are using when accessing datasets via the datasets API and annotation DB. A user running hail on AWS would read from the s3 bucket, and a user running on GCP would read from the gs bucket (can also still read locally from gs bucket with cloud storage connector installed). Not intended for cross-platform use like running a dataproc cluster and trying to access the s3 bucket, or trying to access the gs bucket on an EMR cluster. Will assume user on AWS has their configuration set with their credentials. . Did not have permissions to set up a cluster or EC2 instance on AWS to test, but was able to access all the datasets without issue on a dataproc cluster when using s3a:// prefixes and providing my AWS credentials in the spark config. So these changes should (hopefully) work fine on an EMR cluster with the s3:// client. Everything worked as expected on GCP. Overview of changes:; - Added missing type hints to `load_dataset()` function and methods in `db.py`.; - In `datasets.json`:; - Added AWS urls so now for each version of a dataset in dataset[""versions""], the url entry looks like:; ```; ""url"": {; ""aws"": {; ""us"": ""s3://hail-datasets-us-east-1/...""; },; ""gcp"": {; ""eu"": ""gs://hail-datasets-eu/..."",; ""us"": ""gs://hail-datasets-us/...; }; ```; - In `load_dataset()` function:; - Added `cloud` parameter, set default values to `region='us'` and `cloud='gcp`.; - In `DB` class:; - Added `cloud` parameter to constructor, set default values to `region='us'` and `cloud='gcp`.; - All datasets in `datasets.json` currently end up in the `_DB__by_name` dictionary, even if not annotation datasets. Added line 279 in `db.py` to fix this and filter out datasets that are not annotation datasets (datasets missing ""annotation_db"" key).; - In `Dataset` class:; - Added `cloud` and `custom_config` parameters to `Dataset.from_name_and_json()` to pass to `DatasetVersion.from_json()` to grab correct urls for platform.; - Refac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9605
https://github.com/hail-is/hail/pull/9605:1996,Modifiability,Refactor,Refactored,1996," and providing my AWS credentials in the spark config. So these changes should (hopefully) work fine on an EMR cluster with the s3:// client. Everything worked as expected on GCP. Overview of changes:; - Added missing type hints to `load_dataset()` function and methods in `db.py`.; - In `datasets.json`:; - Added AWS urls so now for each version of a dataset in dataset[""versions""], the url entry looks like:; ```; ""url"": {; ""aws"": {; ""us"": ""s3://hail-datasets-us-east-1/...""; },; ""gcp"": {; ""eu"": ""gs://hail-datasets-eu/..."",; ""us"": ""gs://hail-datasets-us/...; }; ```; - In `load_dataset()` function:; - Added `cloud` parameter, set default values to `region='us'` and `cloud='gcp`.; - In `DB` class:; - Added `cloud` parameter to constructor, set default values to `region='us'` and `cloud='gcp`.; - All datasets in `datasets.json` currently end up in the `_DB__by_name` dictionary, even if not annotation datasets. Added line 279 in `db.py` to fix this and filter out datasets that are not annotation datasets (datasets missing ""annotation_db"" key).; - In `Dataset` class:; - Added `cloud` and `custom_config` parameters to `Dataset.from_name_and_json()` to pass to `DatasetVersion.from_json()` to grab correct urls for platform.; - Refactored `Dataset.from_name_and_json()`. Will require users passing a custom config to be of same format as what is in `datasets.json` for now. So each key: value pair in a user provided config should be as below:; ```; ""dataset_name"": {; ""annotation_db"": {""key_properties"": [""...""]},; ""description"": ""..."",; ""url"": ""..."",; ""versions"": [; {; ""reference_genome"": ""..."",; ""url"": {""aws"": {""eu"": ""..."", ""us"": ""...""},; ""gcp"": {""eu"": ""..."", ""us"": ""...""}},; ""version"": ""...""; }]}; ```; - In `DatasetVersion` class:; - Added `reference_genome` attribute, now that the version and reference genome are two separate fields in `datasets.json`.; - Modified `DatasetVersion.from_json()` to handle cloud parameter to grab correct version url when using checked-in config file.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9605
https://github.com/hail-is/hail/pull/9605:2075,Modifiability,config,config,2075," and providing my AWS credentials in the spark config. So these changes should (hopefully) work fine on an EMR cluster with the s3:// client. Everything worked as expected on GCP. Overview of changes:; - Added missing type hints to `load_dataset()` function and methods in `db.py`.; - In `datasets.json`:; - Added AWS urls so now for each version of a dataset in dataset[""versions""], the url entry looks like:; ```; ""url"": {; ""aws"": {; ""us"": ""s3://hail-datasets-us-east-1/...""; },; ""gcp"": {; ""eu"": ""gs://hail-datasets-eu/..."",; ""us"": ""gs://hail-datasets-us/...; }; ```; - In `load_dataset()` function:; - Added `cloud` parameter, set default values to `region='us'` and `cloud='gcp`.; - In `DB` class:; - Added `cloud` parameter to constructor, set default values to `region='us'` and `cloud='gcp`.; - All datasets in `datasets.json` currently end up in the `_DB__by_name` dictionary, even if not annotation datasets. Added line 279 in `db.py` to fix this and filter out datasets that are not annotation datasets (datasets missing ""annotation_db"" key).; - In `Dataset` class:; - Added `cloud` and `custom_config` parameters to `Dataset.from_name_and_json()` to pass to `DatasetVersion.from_json()` to grab correct urls for platform.; - Refactored `Dataset.from_name_and_json()`. Will require users passing a custom config to be of same format as what is in `datasets.json` for now. So each key: value pair in a user provided config should be as below:; ```; ""dataset_name"": {; ""annotation_db"": {""key_properties"": [""...""]},; ""description"": ""..."",; ""url"": ""..."",; ""versions"": [; {; ""reference_genome"": ""..."",; ""url"": {""aws"": {""eu"": ""..."", ""us"": ""...""},; ""gcp"": {""eu"": ""..."", ""us"": ""...""}},; ""version"": ""...""; }]}; ```; - In `DatasetVersion` class:; - Added `reference_genome` attribute, now that the version and reference genome are two separate fields in `datasets.json`.; - Modified `DatasetVersion.from_json()` to handle cloud parameter to grab correct version url when using checked-in config file.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9605
https://github.com/hail-is/hail/pull/9605:2185,Modifiability,config,config,2185," and providing my AWS credentials in the spark config. So these changes should (hopefully) work fine on an EMR cluster with the s3:// client. Everything worked as expected on GCP. Overview of changes:; - Added missing type hints to `load_dataset()` function and methods in `db.py`.; - In `datasets.json`:; - Added AWS urls so now for each version of a dataset in dataset[""versions""], the url entry looks like:; ```; ""url"": {; ""aws"": {; ""us"": ""s3://hail-datasets-us-east-1/...""; },; ""gcp"": {; ""eu"": ""gs://hail-datasets-eu/..."",; ""us"": ""gs://hail-datasets-us/...; }; ```; - In `load_dataset()` function:; - Added `cloud` parameter, set default values to `region='us'` and `cloud='gcp`.; - In `DB` class:; - Added `cloud` parameter to constructor, set default values to `region='us'` and `cloud='gcp`.; - All datasets in `datasets.json` currently end up in the `_DB__by_name` dictionary, even if not annotation datasets. Added line 279 in `db.py` to fix this and filter out datasets that are not annotation datasets (datasets missing ""annotation_db"" key).; - In `Dataset` class:; - Added `cloud` and `custom_config` parameters to `Dataset.from_name_and_json()` to pass to `DatasetVersion.from_json()` to grab correct urls for platform.; - Refactored `Dataset.from_name_and_json()`. Will require users passing a custom config to be of same format as what is in `datasets.json` for now. So each key: value pair in a user provided config should be as below:; ```; ""dataset_name"": {; ""annotation_db"": {""key_properties"": [""...""]},; ""description"": ""..."",; ""url"": ""..."",; ""versions"": [; {; ""reference_genome"": ""..."",; ""url"": {""aws"": {""eu"": ""..."", ""us"": ""...""},; ""gcp"": {""eu"": ""..."", ""us"": ""...""}},; ""version"": ""...""; }]}; ```; - In `DatasetVersion` class:; - Added `reference_genome` attribute, now that the version and reference genome are two separate fields in `datasets.json`.; - Modified `DatasetVersion.from_json()` to handle cloud parameter to grab correct version url when using checked-in config file.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9605
https://github.com/hail-is/hail/pull/9605:2748,Modifiability,config,config,2748," and providing my AWS credentials in the spark config. So these changes should (hopefully) work fine on an EMR cluster with the s3:// client. Everything worked as expected on GCP. Overview of changes:; - Added missing type hints to `load_dataset()` function and methods in `db.py`.; - In `datasets.json`:; - Added AWS urls so now for each version of a dataset in dataset[""versions""], the url entry looks like:; ```; ""url"": {; ""aws"": {; ""us"": ""s3://hail-datasets-us-east-1/...""; },; ""gcp"": {; ""eu"": ""gs://hail-datasets-eu/..."",; ""us"": ""gs://hail-datasets-us/...; }; ```; - In `load_dataset()` function:; - Added `cloud` parameter, set default values to `region='us'` and `cloud='gcp`.; - In `DB` class:; - Added `cloud` parameter to constructor, set default values to `region='us'` and `cloud='gcp`.; - All datasets in `datasets.json` currently end up in the `_DB__by_name` dictionary, even if not annotation datasets. Added line 279 in `db.py` to fix this and filter out datasets that are not annotation datasets (datasets missing ""annotation_db"" key).; - In `Dataset` class:; - Added `cloud` and `custom_config` parameters to `Dataset.from_name_and_json()` to pass to `DatasetVersion.from_json()` to grab correct urls for platform.; - Refactored `Dataset.from_name_and_json()`. Will require users passing a custom config to be of same format as what is in `datasets.json` for now. So each key: value pair in a user provided config should be as below:; ```; ""dataset_name"": {; ""annotation_db"": {""key_properties"": [""...""]},; ""description"": ""..."",; ""url"": ""..."",; ""versions"": [; {; ""reference_genome"": ""..."",; ""url"": {""aws"": {""eu"": ""..."", ""us"": ""...""},; ""gcp"": {""eu"": ""..."", ""us"": ""...""}},; ""version"": ""...""; }]}; ```; - In `DatasetVersion` class:; - Added `reference_genome` attribute, now that the version and reference genome are two separate fields in `datasets.json`.; - Modified `DatasetVersion.from_json()` to handle cloud parameter to grab correct version url when using checked-in config file.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9605
https://github.com/hail-is/hail/pull/9605:88,Security,access,accessing,88,"This allows the user to specify the cloud platform ('gcp' or 'aws') they are using when accessing datasets via the datasets API and annotation DB. A user running hail on AWS would read from the s3 bucket, and a user running on GCP would read from the gs bucket (can also still read locally from gs bucket with cloud storage connector installed). Not intended for cross-platform use like running a dataproc cluster and trying to access the s3 bucket, or trying to access the gs bucket on an EMR cluster. Will assume user on AWS has their configuration set with their credentials. . Did not have permissions to set up a cluster or EC2 instance on AWS to test, but was able to access all the datasets without issue on a dataproc cluster when using s3a:// prefixes and providing my AWS credentials in the spark config. So these changes should (hopefully) work fine on an EMR cluster with the s3:// client. Everything worked as expected on GCP. Overview of changes:; - Added missing type hints to `load_dataset()` function and methods in `db.py`.; - In `datasets.json`:; - Added AWS urls so now for each version of a dataset in dataset[""versions""], the url entry looks like:; ```; ""url"": {; ""aws"": {; ""us"": ""s3://hail-datasets-us-east-1/...""; },; ""gcp"": {; ""eu"": ""gs://hail-datasets-eu/..."",; ""us"": ""gs://hail-datasets-us/...; }; ```; - In `load_dataset()` function:; - Added `cloud` parameter, set default values to `region='us'` and `cloud='gcp`.; - In `DB` class:; - Added `cloud` parameter to constructor, set default values to `region='us'` and `cloud='gcp`.; - All datasets in `datasets.json` currently end up in the `_DB__by_name` dictionary, even if not annotation datasets. Added line 279 in `db.py` to fix this and filter out datasets that are not annotation datasets (datasets missing ""annotation_db"" key).; - In `Dataset` class:; - Added `cloud` and `custom_config` parameters to `Dataset.from_name_and_json()` to pass to `DatasetVersion.from_json()` to grab correct urls for platform.; - Refac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9605
https://github.com/hail-is/hail/pull/9605:428,Security,access,access,428,"This allows the user to specify the cloud platform ('gcp' or 'aws') they are using when accessing datasets via the datasets API and annotation DB. A user running hail on AWS would read from the s3 bucket, and a user running on GCP would read from the gs bucket (can also still read locally from gs bucket with cloud storage connector installed). Not intended for cross-platform use like running a dataproc cluster and trying to access the s3 bucket, or trying to access the gs bucket on an EMR cluster. Will assume user on AWS has their configuration set with their credentials. . Did not have permissions to set up a cluster or EC2 instance on AWS to test, but was able to access all the datasets without issue on a dataproc cluster when using s3a:// prefixes and providing my AWS credentials in the spark config. So these changes should (hopefully) work fine on an EMR cluster with the s3:// client. Everything worked as expected on GCP. Overview of changes:; - Added missing type hints to `load_dataset()` function and methods in `db.py`.; - In `datasets.json`:; - Added AWS urls so now for each version of a dataset in dataset[""versions""], the url entry looks like:; ```; ""url"": {; ""aws"": {; ""us"": ""s3://hail-datasets-us-east-1/...""; },; ""gcp"": {; ""eu"": ""gs://hail-datasets-eu/..."",; ""us"": ""gs://hail-datasets-us/...; }; ```; - In `load_dataset()` function:; - Added `cloud` parameter, set default values to `region='us'` and `cloud='gcp`.; - In `DB` class:; - Added `cloud` parameter to constructor, set default values to `region='us'` and `cloud='gcp`.; - All datasets in `datasets.json` currently end up in the `_DB__by_name` dictionary, even if not annotation datasets. Added line 279 in `db.py` to fix this and filter out datasets that are not annotation datasets (datasets missing ""annotation_db"" key).; - In `Dataset` class:; - Added `cloud` and `custom_config` parameters to `Dataset.from_name_and_json()` to pass to `DatasetVersion.from_json()` to grab correct urls for platform.; - Refac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9605
https://github.com/hail-is/hail/pull/9605:463,Security,access,access,463,"This allows the user to specify the cloud platform ('gcp' or 'aws') they are using when accessing datasets via the datasets API and annotation DB. A user running hail on AWS would read from the s3 bucket, and a user running on GCP would read from the gs bucket (can also still read locally from gs bucket with cloud storage connector installed). Not intended for cross-platform use like running a dataproc cluster and trying to access the s3 bucket, or trying to access the gs bucket on an EMR cluster. Will assume user on AWS has their configuration set with their credentials. . Did not have permissions to set up a cluster or EC2 instance on AWS to test, but was able to access all the datasets without issue on a dataproc cluster when using s3a:// prefixes and providing my AWS credentials in the spark config. So these changes should (hopefully) work fine on an EMR cluster with the s3:// client. Everything worked as expected on GCP. Overview of changes:; - Added missing type hints to `load_dataset()` function and methods in `db.py`.; - In `datasets.json`:; - Added AWS urls so now for each version of a dataset in dataset[""versions""], the url entry looks like:; ```; ""url"": {; ""aws"": {; ""us"": ""s3://hail-datasets-us-east-1/...""; },; ""gcp"": {; ""eu"": ""gs://hail-datasets-eu/..."",; ""us"": ""gs://hail-datasets-us/...; }; ```; - In `load_dataset()` function:; - Added `cloud` parameter, set default values to `region='us'` and `cloud='gcp`.; - In `DB` class:; - Added `cloud` parameter to constructor, set default values to `region='us'` and `cloud='gcp`.; - All datasets in `datasets.json` currently end up in the `_DB__by_name` dictionary, even if not annotation datasets. Added line 279 in `db.py` to fix this and filter out datasets that are not annotation datasets (datasets missing ""annotation_db"" key).; - In `Dataset` class:; - Added `cloud` and `custom_config` parameters to `Dataset.from_name_and_json()` to pass to `DatasetVersion.from_json()` to grab correct urls for platform.; - Refac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9605
https://github.com/hail-is/hail/pull/9605:674,Security,access,access,674,"This allows the user to specify the cloud platform ('gcp' or 'aws') they are using when accessing datasets via the datasets API and annotation DB. A user running hail on AWS would read from the s3 bucket, and a user running on GCP would read from the gs bucket (can also still read locally from gs bucket with cloud storage connector installed). Not intended for cross-platform use like running a dataproc cluster and trying to access the s3 bucket, or trying to access the gs bucket on an EMR cluster. Will assume user on AWS has their configuration set with their credentials. . Did not have permissions to set up a cluster or EC2 instance on AWS to test, but was able to access all the datasets without issue on a dataproc cluster when using s3a:// prefixes and providing my AWS credentials in the spark config. So these changes should (hopefully) work fine on an EMR cluster with the s3:// client. Everything worked as expected on GCP. Overview of changes:; - Added missing type hints to `load_dataset()` function and methods in `db.py`.; - In `datasets.json`:; - Added AWS urls so now for each version of a dataset in dataset[""versions""], the url entry looks like:; ```; ""url"": {; ""aws"": {; ""us"": ""s3://hail-datasets-us-east-1/...""; },; ""gcp"": {; ""eu"": ""gs://hail-datasets-eu/..."",; ""us"": ""gs://hail-datasets-us/...; }; ```; - In `load_dataset()` function:; - Added `cloud` parameter, set default values to `region='us'` and `cloud='gcp`.; - In `DB` class:; - Added `cloud` parameter to constructor, set default values to `region='us'` and `cloud='gcp`.; - All datasets in `datasets.json` currently end up in the `_DB__by_name` dictionary, even if not annotation datasets. Added line 279 in `db.py` to fix this and filter out datasets that are not annotation datasets (datasets missing ""annotation_db"" key).; - In `Dataset` class:; - Added `cloud` and `custom_config` parameters to `Dataset.from_name_and_json()` to pass to `DatasetVersion.from_json()` to grab correct urls for platform.; - Refac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9605
https://github.com/hail-is/hail/pull/9605:652,Testability,test,test,652,"This allows the user to specify the cloud platform ('gcp' or 'aws') they are using when accessing datasets via the datasets API and annotation DB. A user running hail on AWS would read from the s3 bucket, and a user running on GCP would read from the gs bucket (can also still read locally from gs bucket with cloud storage connector installed). Not intended for cross-platform use like running a dataproc cluster and trying to access the s3 bucket, or trying to access the gs bucket on an EMR cluster. Will assume user on AWS has their configuration set with their credentials. . Did not have permissions to set up a cluster or EC2 instance on AWS to test, but was able to access all the datasets without issue on a dataproc cluster when using s3a:// prefixes and providing my AWS credentials in the spark config. So these changes should (hopefully) work fine on an EMR cluster with the s3:// client. Everything worked as expected on GCP. Overview of changes:; - Added missing type hints to `load_dataset()` function and methods in `db.py`.; - In `datasets.json`:; - Added AWS urls so now for each version of a dataset in dataset[""versions""], the url entry looks like:; ```; ""url"": {; ""aws"": {; ""us"": ""s3://hail-datasets-us-east-1/...""; },; ""gcp"": {; ""eu"": ""gs://hail-datasets-eu/..."",; ""us"": ""gs://hail-datasets-us/...; }; ```; - In `load_dataset()` function:; - Added `cloud` parameter, set default values to `region='us'` and `cloud='gcp`.; - In `DB` class:; - Added `cloud` parameter to constructor, set default values to `region='us'` and `cloud='gcp`.; - All datasets in `datasets.json` currently end up in the `_DB__by_name` dictionary, even if not annotation datasets. Added line 279 in `db.py` to fix this and filter out datasets that are not annotation datasets (datasets missing ""annotation_db"" key).; - In `Dataset` class:; - Added `cloud` and `custom_config` parameters to `Dataset.from_name_and_json()` to pass to `DatasetVersion.from_json()` to grab correct urls for platform.; - Refac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9605
https://github.com/hail-is/hail/issues/9607:0,Availability,Error,Error,0,"Error summary: URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz. ```; In [4]: tsvs = hl.hadoop_ls(""gs://my-bucket/*.tsv*""); ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-4-3a6cee08b392> in <module>; ----> 1 tsvs = hl.hadoop_ls(""gs://my-bucket/*.tsv*""). /Library/Python/3.7/site-packages/hail/utils/hadoop_utils.py in hadoop_ls(path); 212 :obj:`list` [:obj:`dict`]; 213 """"""; --> 214 return Env.fs().ls(path); 215; 216. /Library/Python/3.7/site-packages/hail/fs/hadoop_fs.py in ls(self, path); 40; 41 def ls(self, path: str) -> List[Dict]:; ---> 42 return json.loads(self._utils_package_object.ls(self._jfs, path)); 43; 44 def mkdir(self, path: str) -> None:. /Library/Python/3.7/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258; 1259 for temp_arg in temp_args:. /Library/Python/3.7/site-packages/hail/backend/spark_backend.py in deco(*args, **kwargs); 49 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 50 'Hail version: %s\n'; ---> 51 'Error summary: %s' % (deepest, full, hail.__version__, deepest), error_id) from None; 52 except pyspark.sql.utils.CapturedException as e:; 53 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz. Java stack trace:; java.io.IOException: java.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.concurrentGlobInternal(GoogleHadoopFileSystemBase.java:1284); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1261); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globS",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:1228,Availability,Error,Error,1228,"----------------------------; FatalError Traceback (most recent call last); <ipython-input-4-3a6cee08b392> in <module>; ----> 1 tsvs = hl.hadoop_ls(""gs://my-bucket/*.tsv*""). /Library/Python/3.7/site-packages/hail/utils/hadoop_utils.py in hadoop_ls(path); 212 :obj:`list` [:obj:`dict`]; 213 """"""; --> 214 return Env.fs().ls(path); 215; 216. /Library/Python/3.7/site-packages/hail/fs/hadoop_fs.py in ls(self, path); 40; 41 def ls(self, path: str) -> List[Dict]:; ---> 42 return json.loads(self._utils_package_object.ls(self._jfs, path)); 43; 44 def mkdir(self, path: str) -> None:. /Library/Python/3.7/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258; 1259 for temp_arg in temp_args:. /Library/Python/3.7/site-packages/hail/backend/spark_backend.py in deco(*args, **kwargs); 49 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 50 'Hail version: %s\n'; ---> 51 'Error summary: %s' % (deepest, full, hail.__version__, deepest), error_id) from None; 52 except pyspark.sql.utils.CapturedException as e:; 53 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz. Java stack trace:; java.io.IOException: java.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.concurrentGlobInternal(GoogleHadoopFileSystemBase.java:1284); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1261); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1229); 	at is.hail.io.fs.HadoopFS.listStatus(HadoopFS.scala:104); 	at is.hail.utils.Py4jUtils$class.ls(Py4jUtils.scala:55); 	at is.hail.utils.package$.l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:6832,Availability,Error,Error,6832,fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at java.net.URI.checkPath(URI.java:1823); 	at java.net.URI.<init>(URI.java:745); 	at org.apache.hadoop.fs.Path.initialize(Path.java:202); 	at org.apache.hadoop.fs.Path.<init>(Path.java:171); 	at org.apache.hadoop.fs.Path.<init>(Path.java:93); 	at org.apache.hadoop.fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.58-3f304aae6ce2; Error summary: URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:671,Performance,load,loads,671,"Error summary: URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz. ```; In [4]: tsvs = hl.hadoop_ls(""gs://my-bucket/*.tsv*""); ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-4-3a6cee08b392> in <module>; ----> 1 tsvs = hl.hadoop_ls(""gs://my-bucket/*.tsv*""). /Library/Python/3.7/site-packages/hail/utils/hadoop_utils.py in hadoop_ls(path); 212 :obj:`list` [:obj:`dict`]; 213 """"""; --> 214 return Env.fs().ls(path); 215; 216. /Library/Python/3.7/site-packages/hail/fs/hadoop_fs.py in ls(self, path); 40; 41 def ls(self, path: str) -> List[Dict]:; ---> 42 return json.loads(self._utils_package_object.ls(self._jfs, path)); 43; 44 def mkdir(self, path: str) -> None:. /Library/Python/3.7/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258; 1259 for temp_arg in temp_args:. /Library/Python/3.7/site-packages/hail/backend/spark_backend.py in deco(*args, **kwargs); 49 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 50 'Hail version: %s\n'; ---> 51 'Error summary: %s' % (deepest, full, hail.__version__, deepest), error_id) from None; 52 except pyspark.sql.utils.CapturedException as e:; 53 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz. Java stack trace:; java.io.IOException: java.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.concurrentGlobInternal(GoogleHadoopFileSystemBase.java:1284); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1261); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globS",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:1552,Performance,concurren,concurrent,1552,"ckages/hail/fs/hadoop_fs.py in ls(self, path); 40; 41 def ls(self, path: str) -> List[Dict]:; ---> 42 return json.loads(self._utils_package_object.ls(self._jfs, path)); 43; 44 def mkdir(self, path: str) -> None:. /Library/Python/3.7/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258; 1259 for temp_arg in temp_args:. /Library/Python/3.7/site-packages/hail/backend/spark_backend.py in deco(*args, **kwargs); 49 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 50 'Hail version: %s\n'; ---> 51 'Error summary: %s' % (deepest, full, hail.__version__, deepest), error_id) from None; 52 except pyspark.sql.utils.CapturedException as e:; 53 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz. Java stack trace:; java.io.IOException: java.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.concurrentGlobInternal(GoogleHadoopFileSystemBase.java:1284); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1261); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1229); 	at is.hail.io.fs.HadoopFS.listStatus(HadoopFS.scala:104); 	at is.hail.utils.Py4jUtils$class.ls(Py4jUtils.scala:55); 	at is.hail.utils.package$.ls(package.scala:77); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoke",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:1760,Performance,concurren,concurrentGlobInternal,1760,"/3.7/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258; 1259 for temp_arg in temp_args:. /Library/Python/3.7/site-packages/hail/backend/spark_backend.py in deco(*args, **kwargs); 49 raise FatalError('%s\n\nJava stack trace:\n%s\n'; 50 'Hail version: %s\n'; ---> 51 'Error summary: %s' % (deepest, full, hail.__version__, deepest), error_id) from None; 52 except pyspark.sql.utils.CapturedException as e:; 53 raise FatalError('%s\n\nJava stack trace:\n%s\n'. FatalError: URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz. Java stack trace:; java.io.IOException: java.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.concurrentGlobInternal(GoogleHadoopFileSystemBase.java:1284); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1261); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1229); 	at is.hail.io.fs.HadoopFS.listStatus(HadoopFS.scala:104); 	at is.hail.utils.Py4jUtils$class.ls(Py4jUtils.scala:55); 	at is.hail.utils.package$.ls(package.scala:77); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCom",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:2933,Performance,concurren,concurrent,2933,com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1229); 	at is.hail.io.fs.HadoopFS.listStatus(HadoopFS.scala:104); 	at is.hail.utils.Py4jUtils$class.ls(Py4jUtils.scala:55); 	at is.hail.utils.package$.ls(package.scala:77); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). java.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at java.util.concurrent.AbstractExecutorService.doInvokeAny(AbstractExecutorService.java:193); 	at java.util.concurrent.AbstractExecutorService.invokeAny(AbstractExecutorService.java:215); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.concurrentGlobInternal(GoogleHadoopFileSystemBase.java:1282); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1261); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1229); 	at is.hail.io.fs.HadoopFS.listStatus(HadoopFS.scala:104); 	at is.hail.utils.Py4jUtils$class.ls(Py4jUtils.scala:55); 	at is.hail.utils.package$.ls(package.scala:77); 	at sun.reflect.NativeMethodA,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:3093,Performance,concurren,concurrent,3093,:104); 	at is.hail.utils.Py4jUtils$class.ls(Py4jUtils.scala:55); 	at is.hail.utils.package$.ls(package.scala:77); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). java.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at java.util.concurrent.AbstractExecutorService.doInvokeAny(AbstractExecutorService.java:193); 	at java.util.concurrent.AbstractExecutorService.invokeAny(AbstractExecutorService.java:215); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.concurrentGlobInternal(GoogleHadoopFileSystemBase.java:1282); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1261); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1229); 	at is.hail.io.fs.HadoopFS.listStatus(HadoopFS.scala:104); 	at is.hail.utils.Py4jUtils$class.ls(Py4jUtils.scala:55); 	at is.hail.utils.package$.ls(package.scala:77); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorI,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:3158,Performance,concurren,concurrent,3158,	at is.hail.utils.package$.ls(package.scala:77); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). java.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at java.util.concurrent.AbstractExecutorService.doInvokeAny(AbstractExecutorService.java:193); 	at java.util.concurrent.AbstractExecutorService.invokeAny(AbstractExecutorService.java:215); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.concurrentGlobInternal(GoogleHadoopFileSystemBase.java:1282); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1261); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1229); 	at is.hail.io.fs.HadoopFS.listStatus(HadoopFS.scala:104); 	at is.hail.utils.Py4jUtils$class.ls(Py4jUtils.scala:55); 	at is.hail.utils.package$.ls(package.scala:77); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.r,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:3220,Performance,concurren,concurrent,3220,ct.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). java.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at java.util.concurrent.AbstractExecutorService.doInvokeAny(AbstractExecutorService.java:193); 	at java.util.concurrent.AbstractExecutorService.invokeAny(AbstractExecutorService.java:215); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.concurrentGlobInternal(GoogleHadoopFileSystemBase.java:1282); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1261); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1229); 	at is.hail.io.fs.HadoopFS.listStatus(HadoopFS.scala:104); 	at is.hail.utils.Py4jUtils$class.ls(Py4jUtils.scala:55); 	at is.hail.utils.package$.ls(package.scala:77); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.Met,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:3316,Performance,concurren,concurrent,3316,oke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). java.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at java.util.concurrent.AbstractExecutorService.doInvokeAny(AbstractExecutorService.java:193); 	at java.util.concurrent.AbstractExecutorService.invokeAny(AbstractExecutorService.java:215); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.concurrentGlobInternal(GoogleHadoopFileSystemBase.java:1282); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1261); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1229); 	at is.hail.io.fs.HadoopFS.listStatus(HadoopFS.scala:104); 	at is.hail.utils.Py4jUtils$class.ls(Py4jUtils.scala:55); 	at is.hail.utils.package$.ls(package.scala:77); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(Reflectio,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:3458,Performance,concurren,concurrentGlobInternal,3458,oke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). java.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at java.util.concurrent.FutureTask.report(FutureTask.java:122); 	at java.util.concurrent.FutureTask.get(FutureTask.java:192); 	at java.util.concurrent.AbstractExecutorService.doInvokeAny(AbstractExecutorService.java:193); 	at java.util.concurrent.AbstractExecutorService.invokeAny(AbstractExecutorService.java:215); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.concurrentGlobInternal(GoogleHadoopFileSystemBase.java:1282); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1261); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globStatus(GoogleHadoopFileSystemBase.java:1229); 	at is.hail.io.fs.HadoopFS.listStatus(HadoopFS.scala:104); 	at is.hail.utils.Py4jUtils$class.ls(Py4jUtils.scala:55); 	at is.hail.utils.package$.ls(package.scala:77); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCom,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:5208,Performance,concurren,concurrentGlobInternal,5208,nvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at org.apache.hadoop.fs.Path.initialize(Path.java:205); 	at org.apache.hadoop.fs.Path.<init>(Path.java:171); 	at org.apache.hadoop.fs.Path.<init>(Path.java:93); 	at org.apache.hadoop.fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at java.net.URI.checkPath(URI.java:1823); 	at java.net.URI.<init>(URI.java:745); 	at org.apache.hadoop.fs.Path.initialize(Path.java:202); 	at org.apache.hadoop.fs.Path.<init>(Path.java:171); 	at org.apache.hadoop.fs.Path.<init>(Path.java:93); 	at org.apache.hadoop.fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSyst,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:5286,Performance,concurren,concurrent,5286,flectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at org.apache.hadoop.fs.Path.initialize(Path.java:205); 	at org.apache.hadoop.fs.Path.<init>(Path.java:171); 	at org.apache.hadoop.fs.Path.<init>(Path.java:93); 	at org.apache.hadoop.fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at java.net.URI.checkPath(URI.java:1823); 	at java.net.URI.<init>(URI.java:745); 	at org.apache.hadoop.fs.Path.initialize(Path.java:202); 	at org.apache.hadoop.fs.Path.<init>(Path.java:171); 	at org.apache.hadoop.fs.Path.<init>(Path.java:93); 	at org.apache.hadoop.fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleH,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:5348,Performance,concurren,concurrent,5348,eway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at org.apache.hadoop.fs.Path.initialize(Path.java:205); 	at org.apache.hadoop.fs.Path.<init>(Path.java:171); 	at org.apache.hadoop.fs.Path.<init>(Path.java:93); 	at org.apache.hadoop.fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at java.net.URI.checkPath(URI.java:1823); 	at java.net.URI.<init>(URI.java:745); 	at org.apache.hadoop.fs.Path.initialize(Path.java:202); 	at org.apache.hadoop.fs.Path.<init>(Path.java:171); 	at org.apache.hadoop.fs.Path.<init>(Path.java:93); 	at org.apache.hadoop.fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHado,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:5425,Performance,concurren,concurrent,5425,(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at org.apache.hadoop.fs.Path.initialize(Path.java:205); 	at org.apache.hadoop.fs.Path.<init>(Path.java:171); 	at org.apache.hadoop.fs.Path.<init>(Path.java:93); 	at org.apache.hadoop.fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at java.net.URI.checkPath(URI.java:1823); 	at java.net.URI.<init>(URI.java:745); 	at org.apache.hadoop.fs.Path.initialize(Path.java:202); 	at org.apache.hadoop.fs.Path.<init>(Path.java:171); 	at org.apache.hadoop.fs.Path.<init>(Path.java:93); 	at org.apache.hadoop.fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTa,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:5487,Performance,concurren,concurrent,5487,ute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at org.apache.hadoop.fs.Path.initialize(Path.java:205); 	at org.apache.hadoop.fs.Path.<init>(Path.java:171); 	at org.apache.hadoop.fs.Path.<init>(Path.java:93); 	at org.apache.hadoop.fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at java.net.URI.checkPath(URI.java:1823); 	at java.net.URI.<init>(URI.java:745); 	at org.apache.hadoop.fs.Path.initialize(Path.java:202); 	at org.apache.hadoop.fs.Path.<init>(Path.java:171); 	at org.apache.hadoop.fs.Path.<init>(Path.java:93); 	at org.apache.hadoop.fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapt,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:5572,Performance,concurren,concurrent,5572, 	at java.lang.Thread.run(Thread.java:748). java.lang.IllegalArgumentException: java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at org.apache.hadoop.fs.Path.initialize(Path.java:205); 	at org.apache.hadoop.fs.Path.<init>(Path.java:171); 	at org.apache.hadoop.fs.Path.<init>(Path.java:93); 	at org.apache.hadoop.fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at java.net.URI.checkPath(URI.java:1823); 	at java.net.URI.<init>(URI.java:745); 	at org.apache.hadoop.fs.Path.initialize(Path.java:202); 	at org.apache.hadoop.fs.Path.<init>(Path.java:171); 	at org.apache.hadoop.fs.Path.<init>(Path.java:93); 	at org.apache.hadoop.fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:6319,Performance,concurren,concurrentGlobInternal,6319,fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at java.net.URI.checkPath(URI.java:1823); 	at java.net.URI.<init>(URI.java:745); 	at org.apache.hadoop.fs.Path.initialize(Path.java:202); 	at org.apache.hadoop.fs.Path.<init>(Path.java:171); 	at org.apache.hadoop.fs.Path.<init>(Path.java:93); 	at org.apache.hadoop.fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.58-3f304aae6ce2; Error summary: URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:6397,Performance,concurren,concurrent,6397,fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at java.net.URI.checkPath(URI.java:1823); 	at java.net.URI.<init>(URI.java:745); 	at org.apache.hadoop.fs.Path.initialize(Path.java:202); 	at org.apache.hadoop.fs.Path.<init>(Path.java:171); 	at org.apache.hadoop.fs.Path.<init>(Path.java:93); 	at org.apache.hadoop.fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.58-3f304aae6ce2; Error summary: URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:6459,Performance,concurren,concurrent,6459,fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at java.net.URI.checkPath(URI.java:1823); 	at java.net.URI.<init>(URI.java:745); 	at org.apache.hadoop.fs.Path.initialize(Path.java:202); 	at org.apache.hadoop.fs.Path.<init>(Path.java:171); 	at org.apache.hadoop.fs.Path.<init>(Path.java:93); 	at org.apache.hadoop.fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.58-3f304aae6ce2; Error summary: URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:6536,Performance,concurren,concurrent,6536,fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at java.net.URI.checkPath(URI.java:1823); 	at java.net.URI.<init>(URI.java:745); 	at org.apache.hadoop.fs.Path.initialize(Path.java:202); 	at org.apache.hadoop.fs.Path.<init>(Path.java:171); 	at org.apache.hadoop.fs.Path.<init>(Path.java:93); 	at org.apache.hadoop.fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.58-3f304aae6ce2; Error summary: URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:6598,Performance,concurren,concurrent,6598,fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at java.net.URI.checkPath(URI.java:1823); 	at java.net.URI.<init>(URI.java:745); 	at org.apache.hadoop.fs.Path.initialize(Path.java:202); 	at org.apache.hadoop.fs.Path.<init>(Path.java:171); 	at org.apache.hadoop.fs.Path.<init>(Path.java:93); 	at org.apache.hadoop.fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.58-3f304aae6ce2; Error summary: URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/issues/9607:6683,Performance,concurren,concurrent,6683,fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). java.net.URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; 	at java.net.URI.checkPath(URI.java:1823); 	at java.net.URI.<init>(URI.java:745); 	at org.apache.hadoop.fs.Path.initialize(Path.java:202); 	at org.apache.hadoop.fs.Path.<init>(Path.java:171); 	at org.apache.hadoop.fs.Path.<init>(Path.java:93); 	at org.apache.hadoop.fs.Globber.glob(Globber.java:241); 	at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1676); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.globInternal(GoogleHadoopFileSystemBase.java:1370); 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.lambda$concurrentGlobInternal$4(GoogleHadoopFileSystemBase.java:1279); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.58-3f304aae6ce2; Error summary: URISyntaxException: Relative path in absolute URI: CCDG::133.tsv.bgz; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9607
https://github.com/hail-is/hail/pull/9609:129,Deployability,update,update,129,"Currently, the `hailctl dataproc modify` does not print the first (after the cluster name) argument to `gcloud dataproc clusters update`. This bug was introduced in [#9078](https://github.com/hail-is/hail/pull/9078/files#diff-498f7c9ef8feab597e2213c7cbf2ca3d7f11c2f2427eea44850156ffc4c44fb0L54-R51). For example:; ```; $ hailctl dataproc modify some-cluster --num-workers 2 --dry-run; gcloud dataproc clusters update some-cluster \. ```. With this change, the `--num-workers` argument is printed.; ```; $ hailctl dataproc modify some-cluster --num-workers 2 --dry-run; gcloud dataproc clusters update some-cluster \; --num-workers=2; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9609
https://github.com/hail-is/hail/pull/9609:410,Deployability,update,update,410,"Currently, the `hailctl dataproc modify` does not print the first (after the cluster name) argument to `gcloud dataproc clusters update`. This bug was introduced in [#9078](https://github.com/hail-is/hail/pull/9078/files#diff-498f7c9ef8feab597e2213c7cbf2ca3d7f11c2f2427eea44850156ffc4c44fb0L54-R51). For example:; ```; $ hailctl dataproc modify some-cluster --num-workers 2 --dry-run; gcloud dataproc clusters update some-cluster \. ```. With this change, the `--num-workers` argument is printed.; ```; $ hailctl dataproc modify some-cluster --num-workers 2 --dry-run; gcloud dataproc clusters update some-cluster \; --num-workers=2; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9609
https://github.com/hail-is/hail/pull/9609:594,Deployability,update,update,594,"Currently, the `hailctl dataproc modify` does not print the first (after the cluster name) argument to `gcloud dataproc clusters update`. This bug was introduced in [#9078](https://github.com/hail-is/hail/pull/9078/files#diff-498f7c9ef8feab597e2213c7cbf2ca3d7f11c2f2427eea44850156ffc4c44fb0L54-R51). For example:; ```; $ hailctl dataproc modify some-cluster --num-workers 2 --dry-run; gcloud dataproc clusters update some-cluster \. ```. With this change, the `--num-workers` argument is printed.; ```; $ hailctl dataproc modify some-cluster --num-workers 2 --dry-run; gcloud dataproc clusters update some-cluster \; --num-workers=2; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9609
https://github.com/hail-is/hail/pull/9610:248,Testability,test,test,248,"`hailctl dataproc describe` does not currently display point types for interval fields. For example, with this table:; ```; ds = hl.utils.range_table(10); ds = ds.annotate(interval=hl.parse_locus_interval(hl.str(ds.idx + 1) + "":1-100"")); ds.write(""test.ht""); ```. ```; $ hailctl dataproc describe test.ht; ...; ----------------------------------------; Row fields:; 'idx': int32; 'interval': interval<>; ----------------------------------------; ...; ```. With this change,; ```; $ hailctl dataproc describe test.ht; ...; ----------------------------------------; Row fields:; 'idx': int32; 'interval': interval<locus<grch37>>; ----------------------------------------; ...; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9610
https://github.com/hail-is/hail/pull/9610:297,Testability,test,test,297,"`hailctl dataproc describe` does not currently display point types for interval fields. For example, with this table:; ```; ds = hl.utils.range_table(10); ds = ds.annotate(interval=hl.parse_locus_interval(hl.str(ds.idx + 1) + "":1-100"")); ds.write(""test.ht""); ```. ```; $ hailctl dataproc describe test.ht; ...; ----------------------------------------; Row fields:; 'idx': int32; 'interval': interval<>; ----------------------------------------; ...; ```. With this change,; ```; $ hailctl dataproc describe test.ht; ...; ----------------------------------------; Row fields:; 'idx': int32; 'interval': interval<locus<grch37>>; ----------------------------------------; ...; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9610
https://github.com/hail-is/hail/pull/9610:508,Testability,test,test,508,"`hailctl dataproc describe` does not currently display point types for interval fields. For example, with this table:; ```; ds = hl.utils.range_table(10); ds = ds.annotate(interval=hl.parse_locus_interval(hl.str(ds.idx + 1) + "":1-100"")); ds.write(""test.ht""); ```. ```; $ hailctl dataproc describe test.ht; ...; ----------------------------------------; Row fields:; 'idx': int32; 'interval': interval<>; ----------------------------------------; ...; ```. With this change,; ```; $ hailctl dataproc describe test.ht; ...; ----------------------------------------; Row fields:; 'idx': int32; 'interval': interval<locus<grch37>>; ----------------------------------------; ...; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9610
https://github.com/hail-is/hail/pull/9612:26,Performance,optimiz,optimized,26,The `Consume` was getting optimized away in (StreamLen(StreamMap ...)),MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9612
https://github.com/hail-is/hail/pull/9616:243,Testability,log,log,243,"FYI @tpoterba . Rework `ExecutionTimer` with two goals in mind:. Report total time, children time, self time (total - children) and % in children for each timed section. I think this improves clarity of reporting vs the old format. The timing log lines now look like:. ```; 2020-10-20 12:10:38 root: INFO: timing SparkBackend.executeJSON total 43.597ms self 0.941ms children 42.655ms %children 97.84%; ```. Decouple the timer from the execution context so we can time more than just the execution. In particular, I want timings starting from entering the JVM from Python (and in fact, I plan to write an ExecutionTimer in Python so we can time e.g. a call to Backend.execute and include timings from the JVM, but also printing the IR, unserializing the response, etc.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9616
https://github.com/hail-is/hail/pull/9622:203,Deployability,deploy,deployment,203,"`asyncio.ensure_future` creates background tasks. When a service is shutdown by; kubernetes, these background tasks keep the service up for the full 30 second; grace-period. This impedes development and deployment velocity. This change eliminates all uses of `asyncio.ensure_future` which ignore the; returned future. Instead, all these futures are managed by a; `aiotools.BackgroundTaskManager`. This is a new class which holds a (weak); reference to all of its created tasks and provides `shutdown` to cancel all the; tasks. Canceling the tasks ensures a speedy shutdown. The use of a weak reference is critical to enable the garbage collector to clean; up tasks that have completed successfully. In particular, the batch worker; creates short-lived, background tasks. cc: @catoverdrive @Dania-Abuhijleh",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9622
https://github.com/hail-is/hail/pull/9627:184,Testability,test,test,184,"`TableMapPartitions` needs to insert a TableKeyBy if any element of its child's key is not in the rebuilt body. This is the same thing TableMapRows does. I can figure out a PruneSuite test for this if you want, but the incoming chained linear regression PR will test this behavior as well, I'm just trying to break things up.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9627
https://github.com/hail-is/hail/pull/9627:262,Testability,test,test,262,"`TableMapPartitions` needs to insert a TableKeyBy if any element of its child's key is not in the rebuilt body. This is the same thing TableMapRows does. I can figure out a PruneSuite test for this if you want, but the incoming chained linear regression PR will test this behavior as well, I'm just trying to break things up.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9627
https://github.com/hail-is/hail/pull/9630:28,Deployability,update,updates,28,"Pretty light on user facing updates this time, but we want to release to redeploy the docs to fix search.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9630
https://github.com/hail-is/hail/pull/9630:62,Deployability,release,release,62,"Pretty light on user facing updates this time, but we want to release to redeploy the docs to fix search.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9630
https://github.com/hail-is/hail/pull/9631:249,Integrability,depend,depends,249,"This assertion was getting triggered by the ref `inner` in a perfectly correct IR of the form `StreamMap(inner, StreamGrouped(...), ...)`. There's no way to avoid the unrealizable ref when mapping over a nested stream, and I don't see why `extract` depends on this assertion.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9631
https://github.com/hail-is/hail/pull/9631:157,Safety,avoid,avoid,157,"This assertion was getting triggered by the ref `inner` in a perfectly correct IR of the form `StreamMap(inner, StreamGrouped(...), ...)`. There's no way to avoid the unrealizable ref when mapping over a nested stream, and I don't see why `extract` depends on this assertion.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9631
https://github.com/hail-is/hail/pull/9631:5,Testability,assert,assertion,5,"This assertion was getting triggered by the ref `inner` in a perfectly correct IR of the form `StreamMap(inner, StreamGrouped(...), ...)`. There's no way to avoid the unrealizable ref when mapping over a nested stream, and I don't see why `extract` depends on this assertion.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9631
https://github.com/hail-is/hail/pull/9631:265,Testability,assert,assertion,265,"This assertion was getting triggered by the ref `inner` in a perfectly correct IR of the form `StreamMap(inner, StreamGrouped(...), ...)`. There's no way to avoid the unrealizable ref when mapping over a nested stream, and I don't see why `extract` depends on this assertion.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9631
https://github.com/hail-is/hail/pull/9632:131,Usability,Guid,Guide,131,"This sends a literal tab character to grep, taking advantage of Bash ANSI-C style quoting (see https://tldp.org/LDP/Bash-Beginners-Guide/html/sect_03_03.html)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9632
https://github.com/hail-is/hail/pull/9633:513,Safety,avoid,avoid,513,"I added a test to demonstrate the problem. The `InsertFields` is overwriting the type of a field that is not part of the requested type. Previously we would just not insert anything and leave the rebuilt child alone. But when the child is a `Ref` or a `Literal` or something that doesn't actually get rebuilt differently, the old way would lead to a situation where the rebuilt IR is not a supertype of the original IR. By inserting a `SelectFields` to subset away the fields that would have been overwritten, we avoid this problem. . Happy to further elaborate if the above isn't clear.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9633
https://github.com/hail-is/hail/pull/9633:10,Testability,test,test,10,"I added a test to demonstrate the problem. The `InsertFields` is overwriting the type of a field that is not part of the requested type. Previously we would just not insert anything and leave the rebuilt child alone. But when the child is a `Ref` or a `Literal` or something that doesn't actually get rebuilt differently, the old way would lead to a situation where the rebuilt IR is not a supertype of the original IR. By inserting a `SelectFields` to subset away the fields that would have been overwritten, we avoid this problem. . Happy to further elaborate if the above isn't clear.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9633
https://github.com/hail-is/hail/pull/9633:581,Usability,clear,clear,581,"I added a test to demonstrate the problem. The `InsertFields` is overwriting the type of a field that is not part of the requested type. Previously we would just not insert anything and leave the rebuilt child alone. But when the child is a `Ref` or a `Literal` or something that doesn't actually get rebuilt differently, the old way would lead to a situation where the rebuilt IR is not a supertype of the original IR. By inserting a `SelectFields` to subset away the fields that would have been overwritten, we avoid this problem. . Happy to further elaborate if the above isn't clear.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9633
https://github.com/hail-is/hail/pull/9634:404,Energy Efficiency,efficient,efficient,404,"Replacing #9578 . _linear_regression_rows_nd now supports chained linear regression correctly. Also added support for pass through arguments. This should now support everything that regular linear regression supports, but all written in Python. This allows a few more tests to run on local backend. I'd be particularly interested in whether you think there's a way to write this that would generate more efficient IR. It seems hacky to have to map over the range of rows and index into it, but I didn't see a better way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9634
https://github.com/hail-is/hail/pull/9634:268,Testability,test,tests,268,"Replacing #9578 . _linear_regression_rows_nd now supports chained linear regression correctly. Also added support for pass through arguments. This should now support everything that regular linear regression supports, but all written in Python. This allows a few more tests to run on local backend. I'd be particularly interested in whether you think there's a way to write this that would generate more efficient IR. It seems hacky to have to map over the range of rows and index into it, but I didn't see a better way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9634
https://github.com/hail-is/hail/pull/9636:376,Availability,heartbeat,heartbeat,376,"Implements existing query service endpoints using websockets instead of long-running http requests. I open a new socket for each request instead of attempting to hold one open for each client to send all its requests; not sure if one is preferable to the other, but this one seemed easier to handle and more in line with what we were doing before. ~~I haven't put any sort of heartbeat on either end for now for simplicity; the `blocking_to_async` wrapper around the jvm execution interferes with the server's ability to send/receive pings and pongs, and I'm not currently handling retries for timeouts anyways; would love suggestions on how to make this more robust.~~. Since nginx's default behavior is to close the websocket after 60s of non-activity (which seems pretty reasonable), I have a 30s heartbeat on the server-side websocket connection. This meant rewriting the flow to split a task off to execute the blocking JVM function and keeping the websocket task open to handle the heartbeat. Currently, we rely on the client to close the connection once the jvm task is completed and the result response is received; if the connection is closed/something errors for some other reason, we check to see if the task is completed and cancel it if it's not. The client side still doesn't poll the server for existence, but if the socket is unexpectedly closed we'll retry the request.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9636
https://github.com/hail-is/hail/pull/9636:534,Availability,ping,pings,534,"Implements existing query service endpoints using websockets instead of long-running http requests. I open a new socket for each request instead of attempting to hold one open for each client to send all its requests; not sure if one is preferable to the other, but this one seemed easier to handle and more in line with what we were doing before. ~~I haven't put any sort of heartbeat on either end for now for simplicity; the `blocking_to_async` wrapper around the jvm execution interferes with the server's ability to send/receive pings and pongs, and I'm not currently handling retries for timeouts anyways; would love suggestions on how to make this more robust.~~. Since nginx's default behavior is to close the websocket after 60s of non-activity (which seems pretty reasonable), I have a 30s heartbeat on the server-side websocket connection. This meant rewriting the flow to split a task off to execute the blocking JVM function and keeping the websocket task open to handle the heartbeat. Currently, we rely on the client to close the connection once the jvm task is completed and the result response is received; if the connection is closed/something errors for some other reason, we check to see if the task is completed and cancel it if it's not. The client side still doesn't poll the server for existence, but if the socket is unexpectedly closed we'll retry the request.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9636
https://github.com/hail-is/hail/pull/9636:660,Availability,robust,robust,660,"Implements existing query service endpoints using websockets instead of long-running http requests. I open a new socket for each request instead of attempting to hold one open for each client to send all its requests; not sure if one is preferable to the other, but this one seemed easier to handle and more in line with what we were doing before. ~~I haven't put any sort of heartbeat on either end for now for simplicity; the `blocking_to_async` wrapper around the jvm execution interferes with the server's ability to send/receive pings and pongs, and I'm not currently handling retries for timeouts anyways; would love suggestions on how to make this more robust.~~. Since nginx's default behavior is to close the websocket after 60s of non-activity (which seems pretty reasonable), I have a 30s heartbeat on the server-side websocket connection. This meant rewriting the flow to split a task off to execute the blocking JVM function and keeping the websocket task open to handle the heartbeat. Currently, we rely on the client to close the connection once the jvm task is completed and the result response is received; if the connection is closed/something errors for some other reason, we check to see if the task is completed and cancel it if it's not. The client side still doesn't poll the server for existence, but if the socket is unexpectedly closed we'll retry the request.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9636
https://github.com/hail-is/hail/pull/9636:800,Availability,heartbeat,heartbeat,800,"Implements existing query service endpoints using websockets instead of long-running http requests. I open a new socket for each request instead of attempting to hold one open for each client to send all its requests; not sure if one is preferable to the other, but this one seemed easier to handle and more in line with what we were doing before. ~~I haven't put any sort of heartbeat on either end for now for simplicity; the `blocking_to_async` wrapper around the jvm execution interferes with the server's ability to send/receive pings and pongs, and I'm not currently handling retries for timeouts anyways; would love suggestions on how to make this more robust.~~. Since nginx's default behavior is to close the websocket after 60s of non-activity (which seems pretty reasonable), I have a 30s heartbeat on the server-side websocket connection. This meant rewriting the flow to split a task off to execute the blocking JVM function and keeping the websocket task open to handle the heartbeat. Currently, we rely on the client to close the connection once the jvm task is completed and the result response is received; if the connection is closed/something errors for some other reason, we check to see if the task is completed and cancel it if it's not. The client side still doesn't poll the server for existence, but if the socket is unexpectedly closed we'll retry the request.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9636
https://github.com/hail-is/hail/pull/9636:988,Availability,heartbeat,heartbeat,988,"Implements existing query service endpoints using websockets instead of long-running http requests. I open a new socket for each request instead of attempting to hold one open for each client to send all its requests; not sure if one is preferable to the other, but this one seemed easier to handle and more in line with what we were doing before. ~~I haven't put any sort of heartbeat on either end for now for simplicity; the `blocking_to_async` wrapper around the jvm execution interferes with the server's ability to send/receive pings and pongs, and I'm not currently handling retries for timeouts anyways; would love suggestions on how to make this more robust.~~. Since nginx's default behavior is to close the websocket after 60s of non-activity (which seems pretty reasonable), I have a 30s heartbeat on the server-side websocket connection. This meant rewriting the flow to split a task off to execute the blocking JVM function and keeping the websocket task open to handle the heartbeat. Currently, we rely on the client to close the connection once the jvm task is completed and the result response is received; if the connection is closed/something errors for some other reason, we check to see if the task is completed and cancel it if it's not. The client side still doesn't poll the server for existence, but if the socket is unexpectedly closed we'll retry the request.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9636
https://github.com/hail-is/hail/pull/9636:1162,Availability,error,errors,1162,"Implements existing query service endpoints using websockets instead of long-running http requests. I open a new socket for each request instead of attempting to hold one open for each client to send all its requests; not sure if one is preferable to the other, but this one seemed easier to handle and more in line with what we were doing before. ~~I haven't put any sort of heartbeat on either end for now for simplicity; the `blocking_to_async` wrapper around the jvm execution interferes with the server's ability to send/receive pings and pongs, and I'm not currently handling retries for timeouts anyways; would love suggestions on how to make this more robust.~~. Since nginx's default behavior is to close the websocket after 60s of non-activity (which seems pretty reasonable), I have a 30s heartbeat on the server-side websocket connection. This meant rewriting the flow to split a task off to execute the blocking JVM function and keeping the websocket task open to handle the heartbeat. Currently, we rely on the client to close the connection once the jvm task is completed and the result response is received; if the connection is closed/something errors for some other reason, we check to see if the task is completed and cancel it if it's not. The client side still doesn't poll the server for existence, but if the socket is unexpectedly closed we'll retry the request.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9636
https://github.com/hail-is/hail/pull/9636:448,Integrability,wrap,wrapper,448,"Implements existing query service endpoints using websockets instead of long-running http requests. I open a new socket for each request instead of attempting to hold one open for each client to send all its requests; not sure if one is preferable to the other, but this one seemed easier to handle and more in line with what we were doing before. ~~I haven't put any sort of heartbeat on either end for now for simplicity; the `blocking_to_async` wrapper around the jvm execution interferes with the server's ability to send/receive pings and pongs, and I'm not currently handling retries for timeouts anyways; would love suggestions on how to make this more robust.~~. Since nginx's default behavior is to close the websocket after 60s of non-activity (which seems pretty reasonable), I have a 30s heartbeat on the server-side websocket connection. This meant rewriting the flow to split a task off to execute the blocking JVM function and keeping the websocket task open to handle the heartbeat. Currently, we rely on the client to close the connection once the jvm task is completed and the result response is received; if the connection is closed/something errors for some other reason, we check to see if the task is completed and cancel it if it's not. The client side still doesn't poll the server for existence, but if the socket is unexpectedly closed we'll retry the request.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9636
https://github.com/hail-is/hail/pull/9636:594,Safety,timeout,timeouts,594,"Implements existing query service endpoints using websockets instead of long-running http requests. I open a new socket for each request instead of attempting to hold one open for each client to send all its requests; not sure if one is preferable to the other, but this one seemed easier to handle and more in line with what we were doing before. ~~I haven't put any sort of heartbeat on either end for now for simplicity; the `blocking_to_async` wrapper around the jvm execution interferes with the server's ability to send/receive pings and pongs, and I'm not currently handling retries for timeouts anyways; would love suggestions on how to make this more robust.~~. Since nginx's default behavior is to close the websocket after 60s of non-activity (which seems pretty reasonable), I have a 30s heartbeat on the server-side websocket connection. This meant rewriting the flow to split a task off to execute the blocking JVM function and keeping the websocket task open to handle the heartbeat. Currently, we rely on the client to close the connection once the jvm task is completed and the result response is received; if the connection is closed/something errors for some other reason, we check to see if the task is completed and cancel it if it's not. The client side still doesn't poll the server for existence, but if the socket is unexpectedly closed we'll retry the request.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9636
https://github.com/hail-is/hail/pull/9636:412,Usability,simpl,simplicity,412,"Implements existing query service endpoints using websockets instead of long-running http requests. I open a new socket for each request instead of attempting to hold one open for each client to send all its requests; not sure if one is preferable to the other, but this one seemed easier to handle and more in line with what we were doing before. ~~I haven't put any sort of heartbeat on either end for now for simplicity; the `blocking_to_async` wrapper around the jvm execution interferes with the server's ability to send/receive pings and pongs, and I'm not currently handling retries for timeouts anyways; would love suggestions on how to make this more robust.~~. Since nginx's default behavior is to close the websocket after 60s of non-activity (which seems pretty reasonable), I have a 30s heartbeat on the server-side websocket connection. This meant rewriting the flow to split a task off to execute the blocking JVM function and keeping the websocket task open to handle the heartbeat. Currently, we rely on the client to close the connection once the jvm task is completed and the result response is received; if the connection is closed/something errors for some other reason, we check to see if the task is completed and cancel it if it's not. The client side still doesn't poll the server for existence, but if the socket is unexpectedly closed we'll retry the request.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9636
https://github.com/hail-is/hail/pull/9637:0,Performance,Optimiz,Optimize,0,"Optimize lowered TableHead to not scan a partition past the requested number of rows. Currently TableHead performs a loop, calculating the lengths of the first 4 partitions, then the first 16, etc. If we fix it to not count a partition multiple times, instead starting each loop at the first uncounted partition, we can further optimize to stop scanning a partition after the number of rows still needed (requested number minus sum of partitions counted so far). Note that there is no similar optimization to TableTail. We must compute the full length of each partition, to compute how many rows to drop.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9637
https://github.com/hail-is/hail/pull/9637:106,Performance,perform,performs,106,"Optimize lowered TableHead to not scan a partition past the requested number of rows. Currently TableHead performs a loop, calculating the lengths of the first 4 partitions, then the first 16, etc. If we fix it to not count a partition multiple times, instead starting each loop at the first uncounted partition, we can further optimize to stop scanning a partition after the number of rows still needed (requested number minus sum of partitions counted so far). Note that there is no similar optimization to TableTail. We must compute the full length of each partition, to compute how many rows to drop.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9637
https://github.com/hail-is/hail/pull/9637:328,Performance,optimiz,optimize,328,"Optimize lowered TableHead to not scan a partition past the requested number of rows. Currently TableHead performs a loop, calculating the lengths of the first 4 partitions, then the first 16, etc. If we fix it to not count a partition multiple times, instead starting each loop at the first uncounted partition, we can further optimize to stop scanning a partition after the number of rows still needed (requested number minus sum of partitions counted so far). Note that there is no similar optimization to TableTail. We must compute the full length of each partition, to compute how many rows to drop.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9637
https://github.com/hail-is/hail/pull/9637:493,Performance,optimiz,optimization,493,"Optimize lowered TableHead to not scan a partition past the requested number of rows. Currently TableHead performs a loop, calculating the lengths of the first 4 partitions, then the first 16, etc. If we fix it to not count a partition multiple times, instead starting each loop at the first uncounted partition, we can further optimize to stop scanning a partition after the number of rows still needed (requested number minus sum of partitions counted so far). Note that there is no similar optimization to TableTail. We must compute the full length of each partition, to compute how many rows to drop.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9637
https://github.com/hail-is/hail/issues/9640:31,Testability,test,test,31,"Pick a backwards compatibility test table, `1.5.0/6.ht` is the simplest one. ```; In [2]: ht = hl.read_table('hail/src/test/resources/backward_compatability/1.5.0/table/6.ht/'. In [3]: ht.aggregate(hl.agg.collect(ht.nd)); Out[3]:; [array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32),; array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32),; array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32),; array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32),; array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32)]. In [4]: ht.select('nd').show(); +-------+----------------------------------------------------------------+; | idx | nd |; +-------+----------------------------------------------------------------+; | int32 | ndarray<int32, 2> |; +-------+----------------------------------------------------------------+; | 0 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; | 1 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; | 2 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; | 3 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; | 4 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; +-------+----------------------------------------------------------------+; ```. The first result looks more correct to mine eyes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9640
https://github.com/hail-is/hail/issues/9640:119,Testability,test,test,119,"Pick a backwards compatibility test table, `1.5.0/6.ht` is the simplest one. ```; In [2]: ht = hl.read_table('hail/src/test/resources/backward_compatability/1.5.0/table/6.ht/'. In [3]: ht.aggregate(hl.agg.collect(ht.nd)); Out[3]:; [array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32),; array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32),; array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32),; array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32),; array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32)]. In [4]: ht.select('nd').show(); +-------+----------------------------------------------------------------+; | idx | nd |; +-------+----------------------------------------------------------------+; | int32 | ndarray<int32, 2> |; +-------+----------------------------------------------------------------+; | 0 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; | 1 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; | 2 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; | 3 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; | 4 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; +-------+----------------------------------------------------------------+; ```. The first result looks more correct to mine eyes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9640
https://github.com/hail-is/hail/issues/9640:63,Usability,simpl,simplest,63,"Pick a backwards compatibility test table, `1.5.0/6.ht` is the simplest one. ```; In [2]: ht = hl.read_table('hail/src/test/resources/backward_compatability/1.5.0/table/6.ht/'. In [3]: ht.aggregate(hl.agg.collect(ht.nd)); Out[3]:; [array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32),; array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32),; array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32),; array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32),; array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32)]. In [4]: ht.select('nd').show(); +-------+----------------------------------------------------------------+; | idx | nd |; +-------+----------------------------------------------------------------+; | int32 | ndarray<int32, 2> |; +-------+----------------------------------------------------------------+; | 0 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; | 1 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; | 2 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; | 3 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; | 4 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; +-------+----------------------------------------------------------------+; ```. The first result looks more correct to mine eyes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9640
https://github.com/hail-is/hail/pull/9641:825,Integrability,wrap,wrapper,825,"Fixes #9640. CHANGELOG: Fixed bug where show output for ndarrays was not correct. `TNDArray` shouldn't store strides on it. It only existed because of the old world where `PTypes` weren't fully fleshed out. Especially since `strides` is a series of offsets in bytes, and at the virtual type level we have no idea what elements of the ndarray will actually be. . The way I've fixed this for now is by making all incoming ndarray literals row major and all Java `Row` representation style things use `UnsafeIndexedSeqRowMajorView` to make them indexable in arow major way. I mostly just did this since row by row is the way you'd want to display data for `show`. My eventual plan is reorganize the ndarray emitter so we know that all ndarrays are being emitted column major all the time, and then we won't have to do this view wrapper thing since we will know what striding to expect. . This change is also good because now that strides are off of `TNDArray`/literals, there should be nothing preventing us from passing ndarrays of arbitrary data types back to Python from the JVM (currently we only support collecting ndarrays of primitives).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9641
https://github.com/hail-is/hail/pull/9641:499,Safety,Unsafe,UnsafeIndexedSeqRowMajorView,499,"Fixes #9640. CHANGELOG: Fixed bug where show output for ndarrays was not correct. `TNDArray` shouldn't store strides on it. It only existed because of the old world where `PTypes` weren't fully fleshed out. Especially since `strides` is a series of offsets in bytes, and at the virtual type level we have no idea what elements of the ndarray will actually be. . The way I've fixed this for now is by making all incoming ndarray literals row major and all Java `Row` representation style things use `UnsafeIndexedSeqRowMajorView` to make them indexable in arow major way. I mostly just did this since row by row is the way you'd want to display data for `show`. My eventual plan is reorganize the ndarray emitter so we know that all ndarrays are being emitted column major all the time, and then we won't have to do this view wrapper thing since we will know what striding to expect. . This change is also good because now that strides are off of `TNDArray`/literals, there should be nothing preventing us from passing ndarrays of arbitrary data types back to Python from the JVM (currently we only support collecting ndarrays of primitives).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9641
https://github.com/hail-is/hail/issues/9645:743,Availability,redundant,redundant,743,"Hi,. Thanks so much for setting up a tutorial for Batch, and for all your work on Hail as a service - it's a really great project and I'm excited to try it out!. I'm following the tutorial and was wondering if this line is there by mistake?. https://github.com/hail-is/hail/blob/8140f17d926235470b1ed1cdefd591c3b41838a5/hail/python/hailtop/batch/docs/cookbook/files/batch_clumping.py#L73. It throws `AttributeError: 'InputResourceFile' object has no attribute 'add_extension'`, and the method is not defined for `InputResourceFile` indeed. However it is defined for `JobResourceFile`, which, if I understand, Batch uses to find the job output? If so, I guess, for the input resource with an explicitly defined name, calling `add_extension` is redundant? . I'm on Hail `0.2.59-63cf625e29e5`. Vlad",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9645
https://github.com/hail-is/hail/issues/9645:743,Safety,redund,redundant,743,"Hi,. Thanks so much for setting up a tutorial for Batch, and for all your work on Hail as a service - it's a really great project and I'm excited to try it out!. I'm following the tutorial and was wondering if this line is there by mistake?. https://github.com/hail-is/hail/blob/8140f17d926235470b1ed1cdefd591c3b41838a5/hail/python/hailtop/batch/docs/cookbook/files/batch_clumping.py#L73. It throws `AttributeError: 'InputResourceFile' object has no attribute 'add_extension'`, and the method is not defined for `InputResourceFile` indeed. However it is defined for `JobResourceFile`, which, if I understand, Batch uses to find the job output? If so, I guess, for the input resource with an explicitly defined name, calling `add_extension` is redundant? . I'm on Hail `0.2.59-63cf625e29e5`. Vlad",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9645
https://github.com/hail-is/hail/pull/9652:552,Availability,down,down,552,"This PR introduces a generic pretty-printing package, which for now is only used in `ir.Pretty`. The primary motivation was to separate format specification from rendering, to simplify the formatting code, and make it easier to add multiple formatting options, including forms with line number references. Some nice properties of the new pretty-printer:; * Generic. Should be able to be used for all pretty-printing in hail scala code. This simplifies the codebase by making client pretty-printers easy to understand and modify, without getting bogged down in low-level details.; * Composable. Formatting specifications are trivially combinable, without needing to manually track context like the current indentation level, max line length, etc.; * Stack safe. Uses constant stack space.; * Uses constant heap space. Only keeps in memory text which might print in the current line, if it fits. (The pretty printer writes to a `java.io.Writer`, and I'm ignoring any heap space used by the writer.); * Lazy. If the number of lines to print is capped, doesn't scan more of the tree than is needed to print those lines.; * Produces more readable output, printing nodes on a single line where possible. As we work to increase visibility into the compiler, I think this will be very helpful. A formatted document is represented by the `Doc` type. This defines a `render` method, which takes three parameters to control the output:; * `width`: the maximum length of a line, including indentation; * `ribbonLength`: the maximum length of a line, not including indentation (too many characters on a line is hard to read, regardless of indentation); * `maxLines`: the maximum number of lines to print. There are only a few `Doc` constructors, which suffice to define all methods in the richer api contained in the `prettyPrint` package object.; * `Text(t: String)`; * `Line(ifFlat: String)`; * `Indent(i: Int, body: Doc)`; * `Concat(it: Iterable[Doc])`; * `Group(body: Doc)`. Ignoring `Group` for the moment, th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9652
https://github.com/hail-is/hail/pull/9652:2935,Modifiability,enhance,enhancements,2935,"at(it: Iterable[Doc])`; * `Group(body: Doc)`. Ignoring `Group` for the moment, the first four constructors define formatted documents with only one possible layout, regardless of `width` or `ribbonLength`. `Text` simply prints the string `t`; `Line` prints a newline, followed by the current level of indentation (`ifFlat` is explained when we discuss `Group`); `Indent` increases the indentation of all `Line`s contained in `body` by `i`; and `Concat` simply prints all documents in `it` sequentially. `Group` is the sole source of alternatives which `render` must choose between. `Group(body)` can be rendered in one of two ways:; * replace all `Line`s contained in `body` (including in nested `Group`s) by their `ifFlat` alternative (almost always either "" "" or """"), or, if that would cause the line to exceed `width`; * print `body` normally, as described in the previous paragraph, allowing nested `Group`s to print either flat or normally. This pretty-printer DSL has become fairly standard, with some common enhancements that I don't think we need. It was first described in [A prettier printer](https://homepages.inf.ed.ac.uk/wadler/papers/prettier/prettier.pdf) by Wadler (though my implementation is completely different). This achieves stack safety by `Concat` taking an `Iterable`, so each contained `Doc` can be produced on demand. `render` pulls from these iterators, keeping in memory only things that might print to the current line, but where the format hasn't been decided yet. As soon as the formatting of a group is decided, as much of its body as possible is written to the `java.io.Writer`. A very quick and dirty performance comparison had the new pretty printer about 20% slower. That's paying for both the stack safety and the added smarts. And I think there's still room for optimization if it becomes necessary. Here is a snippet of the IR generated by `test_ld_score_regression`, first on master, then this PR:; ```; (InsertFields; (SelectFields (SNP A1 A2 N Z); (Ref row)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9652
https://github.com/hail-is/hail/pull/9652:3556,Performance,perform,performance,3556,"ntained in `body` (including in nested `Group`s) by their `ifFlat` alternative (almost always either "" "" or """"), or, if that would cause the line to exceed `width`; * print `body` normally, as described in the previous paragraph, allowing nested `Group`s to print either flat or normally. This pretty-printer DSL has become fairly standard, with some common enhancements that I don't think we need. It was first described in [A prettier printer](https://homepages.inf.ed.ac.uk/wadler/papers/prettier/prettier.pdf) by Wadler (though my implementation is completely different). This achieves stack safety by `Concat` taking an `Iterable`, so each contained `Doc` can be produced on demand. `render` pulls from these iterators, keeping in memory only things that might print to the current line, but where the format hasn't been decided yet. As soon as the formatting of a group is decided, as much of its body as possible is written to the `java.io.Writer`. A very quick and dirty performance comparison had the new pretty printer about 20% slower. That's paying for both the stack safety and the added smarts. And I think there's still room for optimization if it becomes necessary. Here is a snippet of the IR generated by `test_ld_score_regression`, first on master, then this PR:; ```; (InsertFields; (SelectFields (SNP A1 A2 N Z); (Ref row)); None; (chi_squared; (Apply pow () Float64; (GetField Z; (Ref row)); (ApplyIR toFloat64 () Float64; (I32 2)))); (n; (GetField N; (Ref row))); (ld_score; (GetField L2; (GetField __uid_3; (Ref row)))); (locus; (Apply Locus () Locus(GRCh37); (GetField CHR; (GetField __uid_4; (Ref row))); (GetField BP; (GetField __uid_5; (Ref row))))); (alleles; (MakeArray Array[String]; (GetField A2; (Ref row)); (GetField A1; (Ref row)))); (phenotype; (Str ""50_irnt""))))); (InsertFields; (SelectFields (locus alleles chi_squared n ld_score phenotype); (SelectFields (SNP A1 A2 N Z chi_squared n ld_score locus alleles phenotype); (Ref row))); None)); ```; ```; (InsertFiel",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9652
https://github.com/hail-is/hail/pull/9652:3721,Performance,optimiz,optimization,3721,"e to exceed `width`; * print `body` normally, as described in the previous paragraph, allowing nested `Group`s to print either flat or normally. This pretty-printer DSL has become fairly standard, with some common enhancements that I don't think we need. It was first described in [A prettier printer](https://homepages.inf.ed.ac.uk/wadler/papers/prettier/prettier.pdf) by Wadler (though my implementation is completely different). This achieves stack safety by `Concat` taking an `Iterable`, so each contained `Doc` can be produced on demand. `render` pulls from these iterators, keeping in memory only things that might print to the current line, but where the format hasn't been decided yet. As soon as the formatting of a group is decided, as much of its body as possible is written to the `java.io.Writer`. A very quick and dirty performance comparison had the new pretty printer about 20% slower. That's paying for both the stack safety and the added smarts. And I think there's still room for optimization if it becomes necessary. Here is a snippet of the IR generated by `test_ld_score_regression`, first on master, then this PR:; ```; (InsertFields; (SelectFields (SNP A1 A2 N Z); (Ref row)); None; (chi_squared; (Apply pow () Float64; (GetField Z; (Ref row)); (ApplyIR toFloat64 () Float64; (I32 2)))); (n; (GetField N; (Ref row))); (ld_score; (GetField L2; (GetField __uid_3; (Ref row)))); (locus; (Apply Locus () Locus(GRCh37); (GetField CHR; (GetField __uid_4; (Ref row))); (GetField BP; (GetField __uid_5; (Ref row))))); (alleles; (MakeArray Array[String]; (GetField A2; (Ref row)); (GetField A1; (Ref row)))); (phenotype; (Str ""50_irnt""))))); (InsertFields; (SelectFields (locus alleles chi_squared n ld_score phenotype); (SelectFields (SNP A1 A2 N Z chi_squared n ld_score locus alleles phenotype); (Ref row))); None)); ```; ```; (InsertFields; (SelectFields (SNP A1 A2 N Z) (Ref row)); None; (chi_squared; (Apply pow () Float64; (GetField Z (Ref row)); (ApplyIR toFloat64 () Float64 (",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9652
https://github.com/hail-is/hail/pull/9652:755,Safety,safe,safe,755,"This PR introduces a generic pretty-printing package, which for now is only used in `ir.Pretty`. The primary motivation was to separate format specification from rendering, to simplify the formatting code, and make it easier to add multiple formatting options, including forms with line number references. Some nice properties of the new pretty-printer:; * Generic. Should be able to be used for all pretty-printing in hail scala code. This simplifies the codebase by making client pretty-printers easy to understand and modify, without getting bogged down in low-level details.; * Composable. Formatting specifications are trivially combinable, without needing to manually track context like the current indentation level, max line length, etc.; * Stack safe. Uses constant stack space.; * Uses constant heap space. Only keeps in memory text which might print in the current line, if it fits. (The pretty printer writes to a `java.io.Writer`, and I'm ignoring any heap space used by the writer.); * Lazy. If the number of lines to print is capped, doesn't scan more of the tree than is needed to print those lines.; * Produces more readable output, printing nodes on a single line where possible. As we work to increase visibility into the compiler, I think this will be very helpful. A formatted document is represented by the `Doc` type. This defines a `render` method, which takes three parameters to control the output:; * `width`: the maximum length of a line, including indentation; * `ribbonLength`: the maximum length of a line, not including indentation (too many characters on a line is hard to read, regardless of indentation); * `maxLines`: the maximum number of lines to print. There are only a few `Doc` constructors, which suffice to define all methods in the richer api contained in the `prettyPrint` package object.; * `Text(t: String)`; * `Line(ifFlat: String)`; * `Indent(i: Int, body: Doc)`; * `Concat(it: Iterable[Doc])`; * `Group(body: Doc)`. Ignoring `Group` for the moment, th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9652
https://github.com/hail-is/hail/pull/9652:3173,Safety,safe,safety,3173,"ent level of indentation (`ifFlat` is explained when we discuss `Group`); `Indent` increases the indentation of all `Line`s contained in `body` by `i`; and `Concat` simply prints all documents in `it` sequentially. `Group` is the sole source of alternatives which `render` must choose between. `Group(body)` can be rendered in one of two ways:; * replace all `Line`s contained in `body` (including in nested `Group`s) by their `ifFlat` alternative (almost always either "" "" or """"), or, if that would cause the line to exceed `width`; * print `body` normally, as described in the previous paragraph, allowing nested `Group`s to print either flat or normally. This pretty-printer DSL has become fairly standard, with some common enhancements that I don't think we need. It was first described in [A prettier printer](https://homepages.inf.ed.ac.uk/wadler/papers/prettier/prettier.pdf) by Wadler (though my implementation is completely different). This achieves stack safety by `Concat` taking an `Iterable`, so each contained `Doc` can be produced on demand. `render` pulls from these iterators, keeping in memory only things that might print to the current line, but where the format hasn't been decided yet. As soon as the formatting of a group is decided, as much of its body as possible is written to the `java.io.Writer`. A very quick and dirty performance comparison had the new pretty printer about 20% slower. That's paying for both the stack safety and the added smarts. And I think there's still room for optimization if it becomes necessary. Here is a snippet of the IR generated by `test_ld_score_regression`, first on master, then this PR:; ```; (InsertFields; (SelectFields (SNP A1 A2 N Z); (Ref row)); None; (chi_squared; (Apply pow () Float64; (GetField Z; (Ref row)); (ApplyIR toFloat64 () Float64; (I32 2)))); (n; (GetField N; (Ref row))); (ld_score; (GetField L2; (GetField __uid_3; (Ref row)))); (locus; (Apply Locus () Locus(GRCh37); (GetField CHR; (GetField __uid_4; (Ref row))); ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9652
https://github.com/hail-is/hail/pull/9652:3657,Safety,safe,safety,3657,"e (almost always either "" "" or """"), or, if that would cause the line to exceed `width`; * print `body` normally, as described in the previous paragraph, allowing nested `Group`s to print either flat or normally. This pretty-printer DSL has become fairly standard, with some common enhancements that I don't think we need. It was first described in [A prettier printer](https://homepages.inf.ed.ac.uk/wadler/papers/prettier/prettier.pdf) by Wadler (though my implementation is completely different). This achieves stack safety by `Concat` taking an `Iterable`, so each contained `Doc` can be produced on demand. `render` pulls from these iterators, keeping in memory only things that might print to the current line, but where the format hasn't been decided yet. As soon as the formatting of a group is decided, as much of its body as possible is written to the `java.io.Writer`. A very quick and dirty performance comparison had the new pretty printer about 20% slower. That's paying for both the stack safety and the added smarts. And I think there's still room for optimization if it becomes necessary. Here is a snippet of the IR generated by `test_ld_score_regression`, first on master, then this PR:; ```; (InsertFields; (SelectFields (SNP A1 A2 N Z); (Ref row)); None; (chi_squared; (Apply pow () Float64; (GetField Z; (Ref row)); (ApplyIR toFloat64 () Float64; (I32 2)))); (n; (GetField N; (Ref row))); (ld_score; (GetField L2; (GetField __uid_3; (Ref row)))); (locus; (Apply Locus () Locus(GRCh37); (GetField CHR; (GetField __uid_4; (Ref row))); (GetField BP; (GetField __uid_5; (Ref row))))); (alleles; (MakeArray Array[String]; (GetField A2; (Ref row)); (GetField A1; (Ref row)))); (phenotype; (Str ""50_irnt""))))); (InsertFields; (SelectFields (locus alleles chi_squared n ld_score phenotype); (SelectFields (SNP A1 A2 N Z chi_squared n ld_score locus alleles phenotype); (Ref row))); None)); ```; ```; (InsertFields; (SelectFields (SNP A1 A2 N Z) (Ref row)); None; (chi_squared; (Apply pow",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9652
https://github.com/hail-is/hail/pull/9652:176,Usability,simpl,simplify,176,"This PR introduces a generic pretty-printing package, which for now is only used in `ir.Pretty`. The primary motivation was to separate format specification from rendering, to simplify the formatting code, and make it easier to add multiple formatting options, including forms with line number references. Some nice properties of the new pretty-printer:; * Generic. Should be able to be used for all pretty-printing in hail scala code. This simplifies the codebase by making client pretty-printers easy to understand and modify, without getting bogged down in low-level details.; * Composable. Formatting specifications are trivially combinable, without needing to manually track context like the current indentation level, max line length, etc.; * Stack safe. Uses constant stack space.; * Uses constant heap space. Only keeps in memory text which might print in the current line, if it fits. (The pretty printer writes to a `java.io.Writer`, and I'm ignoring any heap space used by the writer.); * Lazy. If the number of lines to print is capped, doesn't scan more of the tree than is needed to print those lines.; * Produces more readable output, printing nodes on a single line where possible. As we work to increase visibility into the compiler, I think this will be very helpful. A formatted document is represented by the `Doc` type. This defines a `render` method, which takes three parameters to control the output:; * `width`: the maximum length of a line, including indentation; * `ribbonLength`: the maximum length of a line, not including indentation (too many characters on a line is hard to read, regardless of indentation); * `maxLines`: the maximum number of lines to print. There are only a few `Doc` constructors, which suffice to define all methods in the richer api contained in the `prettyPrint` package object.; * `Text(t: String)`; * `Line(ifFlat: String)`; * `Indent(i: Int, body: Doc)`; * `Concat(it: Iterable[Doc])`; * `Group(body: Doc)`. Ignoring `Group` for the moment, th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9652
https://github.com/hail-is/hail/pull/9652:441,Usability,simpl,simplifies,441,"This PR introduces a generic pretty-printing package, which for now is only used in `ir.Pretty`. The primary motivation was to separate format specification from rendering, to simplify the formatting code, and make it easier to add multiple formatting options, including forms with line number references. Some nice properties of the new pretty-printer:; * Generic. Should be able to be used for all pretty-printing in hail scala code. This simplifies the codebase by making client pretty-printers easy to understand and modify, without getting bogged down in low-level details.; * Composable. Formatting specifications are trivially combinable, without needing to manually track context like the current indentation level, max line length, etc.; * Stack safe. Uses constant stack space.; * Uses constant heap space. Only keeps in memory text which might print in the current line, if it fits. (The pretty printer writes to a `java.io.Writer`, and I'm ignoring any heap space used by the writer.); * Lazy. If the number of lines to print is capped, doesn't scan more of the tree than is needed to print those lines.; * Produces more readable output, printing nodes on a single line where possible. As we work to increase visibility into the compiler, I think this will be very helpful. A formatted document is represented by the `Doc` type. This defines a `render` method, which takes three parameters to control the output:; * `width`: the maximum length of a line, including indentation; * `ribbonLength`: the maximum length of a line, not including indentation (too many characters on a line is hard to read, regardless of indentation); * `maxLines`: the maximum number of lines to print. There are only a few `Doc` constructors, which suffice to define all methods in the richer api contained in the `prettyPrint` package object.; * `Text(t: String)`; * `Line(ifFlat: String)`; * `Indent(i: Int, body: Doc)`; * `Concat(it: Iterable[Doc])`; * `Group(body: Doc)`. Ignoring `Group` for the moment, th",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9652
https://github.com/hail-is/hail/pull/9652:2133,Usability,simpl,simply,2133,"ery helpful. A formatted document is represented by the `Doc` type. This defines a `render` method, which takes three parameters to control the output:; * `width`: the maximum length of a line, including indentation; * `ribbonLength`: the maximum length of a line, not including indentation (too many characters on a line is hard to read, regardless of indentation); * `maxLines`: the maximum number of lines to print. There are only a few `Doc` constructors, which suffice to define all methods in the richer api contained in the `prettyPrint` package object.; * `Text(t: String)`; * `Line(ifFlat: String)`; * `Indent(i: Int, body: Doc)`; * `Concat(it: Iterable[Doc])`; * `Group(body: Doc)`. Ignoring `Group` for the moment, the first four constructors define formatted documents with only one possible layout, regardless of `width` or `ribbonLength`. `Text` simply prints the string `t`; `Line` prints a newline, followed by the current level of indentation (`ifFlat` is explained when we discuss `Group`); `Indent` increases the indentation of all `Line`s contained in `body` by `i`; and `Concat` simply prints all documents in `it` sequentially. `Group` is the sole source of alternatives which `render` must choose between. `Group(body)` can be rendered in one of two ways:; * replace all `Line`s contained in `body` (including in nested `Group`s) by their `ifFlat` alternative (almost always either "" "" or """"), or, if that would cause the line to exceed `width`; * print `body` normally, as described in the previous paragraph, allowing nested `Group`s to print either flat or normally. This pretty-printer DSL has become fairly standard, with some common enhancements that I don't think we need. It was first described in [A prettier printer](https://homepages.inf.ed.ac.uk/wadler/papers/prettier/prettier.pdf) by Wadler (though my implementation is completely different). This achieves stack safety by `Concat` taking an `Iterable`, so each contained `Doc` can be produced on demand. `render` ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9652
https://github.com/hail-is/hail/pull/9652:2373,Usability,simpl,simply,2373,"ery helpful. A formatted document is represented by the `Doc` type. This defines a `render` method, which takes three parameters to control the output:; * `width`: the maximum length of a line, including indentation; * `ribbonLength`: the maximum length of a line, not including indentation (too many characters on a line is hard to read, regardless of indentation); * `maxLines`: the maximum number of lines to print. There are only a few `Doc` constructors, which suffice to define all methods in the richer api contained in the `prettyPrint` package object.; * `Text(t: String)`; * `Line(ifFlat: String)`; * `Indent(i: Int, body: Doc)`; * `Concat(it: Iterable[Doc])`; * `Group(body: Doc)`. Ignoring `Group` for the moment, the first four constructors define formatted documents with only one possible layout, regardless of `width` or `ribbonLength`. `Text` simply prints the string `t`; `Line` prints a newline, followed by the current level of indentation (`ifFlat` is explained when we discuss `Group`); `Indent` increases the indentation of all `Line`s contained in `body` by `i`; and `Concat` simply prints all documents in `it` sequentially. `Group` is the sole source of alternatives which `render` must choose between. `Group(body)` can be rendered in one of two ways:; * replace all `Line`s contained in `body` (including in nested `Group`s) by their `ifFlat` alternative (almost always either "" "" or """"), or, if that would cause the line to exceed `width`; * print `body` normally, as described in the previous paragraph, allowing nested `Group`s to print either flat or normally. This pretty-printer DSL has become fairly standard, with some common enhancements that I don't think we need. It was first described in [A prettier printer](https://homepages.inf.ed.ac.uk/wadler/papers/prettier/prettier.pdf) by Wadler (though my implementation is completely different). This achieves stack safety by `Concat` taking an `Iterable`, so each contained `Doc` can be produced on demand. `render` ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9652
https://github.com/hail-is/hail/pull/9653:73,Availability,repair,repaired,73,Not sure if this will help make GKE move the pod if the node needs to be repaired rather than waiting for the node to repair.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9653
https://github.com/hail-is/hail/pull/9653:118,Availability,repair,repair,118,Not sure if this will help make GKE move the pod if the node needs to be repaired rather than waiting for the node to repair.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9653
https://github.com/hail-is/hail/pull/9654:79,Testability,test,test,79,"Very much WIP, this just adds a ptype that isn't yet fully implemented, plus a test that checks that some reference counting is happening. @tpoterba , mostly posting to make sure that I understood our conversation and that this is what you had in mind.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9654
https://github.com/hail-is/hail/pull/9658:528,Integrability,depend,dependent,528,"- Signup page with web socket and spinner while waiting for account to create; - Upon account creation, a billing project named `{username}-trial` is created with $10 limit and a user `{username}`; - When deleting an account, the billing project is reopened if it's closed, then remove the user, and finally close the billing project. This behavior might be debatable. We may not need to remove the user from the billing project. I think it's better to be safe in case the billing project is reopened. Auth-driver is implicitly dependent on the batch front end, but this dependency isn't stated in build.yaml. An event queue is a future solution. I can get rid of my personal email being whitelisted, but I think it will be useful if we need to debug later and for a possible demo on Monday (although I'll probably just use some screenshots). If you want to test it in your namespace, make sure to comment out all the create and delete steps that are not related to billing projects.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9658
https://github.com/hail-is/hail/pull/9658:571,Integrability,depend,dependency,571,"- Signup page with web socket and spinner while waiting for account to create; - Upon account creation, a billing project named `{username}-trial` is created with $10 limit and a user `{username}`; - When deleting an account, the billing project is reopened if it's closed, then remove the user, and finally close the billing project. This behavior might be debatable. We may not need to remove the user from the billing project. I think it's better to be safe in case the billing project is reopened. Auth-driver is implicitly dependent on the batch front end, but this dependency isn't stated in build.yaml. An event queue is a future solution. I can get rid of my personal email being whitelisted, but I think it will be useful if we need to debug later and for a possible demo on Monday (although I'll probably just use some screenshots). If you want to test it in your namespace, make sure to comment out all the create and delete steps that are not related to billing projects.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9658
https://github.com/hail-is/hail/pull/9658:619,Performance,queue,queue,619,"- Signup page with web socket and spinner while waiting for account to create; - Upon account creation, a billing project named `{username}-trial` is created with $10 limit and a user `{username}`; - When deleting an account, the billing project is reopened if it's closed, then remove the user, and finally close the billing project. This behavior might be debatable. We may not need to remove the user from the billing project. I think it's better to be safe in case the billing project is reopened. Auth-driver is implicitly dependent on the batch front end, but this dependency isn't stated in build.yaml. An event queue is a future solution. I can get rid of my personal email being whitelisted, but I think it will be useful if we need to debug later and for a possible demo on Monday (although I'll probably just use some screenshots). If you want to test it in your namespace, make sure to comment out all the create and delete steps that are not related to billing projects.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9658
https://github.com/hail-is/hail/pull/9658:456,Safety,safe,safe,456,"- Signup page with web socket and spinner while waiting for account to create; - Upon account creation, a billing project named `{username}-trial` is created with $10 limit and a user `{username}`; - When deleting an account, the billing project is reopened if it's closed, then remove the user, and finally close the billing project. This behavior might be debatable. We may not need to remove the user from the billing project. I think it's better to be safe in case the billing project is reopened. Auth-driver is implicitly dependent on the batch front end, but this dependency isn't stated in build.yaml. An event queue is a future solution. I can get rid of my personal email being whitelisted, but I think it will be useful if we need to debug later and for a possible demo on Monday (although I'll probably just use some screenshots). If you want to test it in your namespace, make sure to comment out all the create and delete steps that are not related to billing projects.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9658
https://github.com/hail-is/hail/pull/9658:858,Testability,test,test,858,"- Signup page with web socket and spinner while waiting for account to create; - Upon account creation, a billing project named `{username}-trial` is created with $10 limit and a user `{username}`; - When deleting an account, the billing project is reopened if it's closed, then remove the user, and finally close the billing project. This behavior might be debatable. We may not need to remove the user from the billing project. I think it's better to be safe in case the billing project is reopened. Auth-driver is implicitly dependent on the batch front end, but this dependency isn't stated in build.yaml. An event queue is a future solution. I can get rid of my personal email being whitelisted, but I think it will be useful if we need to debug later and for a possible demo on Monday (although I'll probably just use some screenshots). If you want to test it in your namespace, make sure to comment out all the create and delete steps that are not related to billing projects.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9658
https://github.com/hail-is/hail/pull/9663:298,Availability,avail,available,298,"Made changes to clean up/add to the documentation for the datasets API and annotation DB. Changes to documentation:. - Moved raw html in `annotation_database_ui.rst` into `hail/python/hail/docs/_static/annotationdb/annotationdb.html`.; - Added html table to bottom of datasets doc page to show all available datasets, similar to what is currently on annotation DB doc page. Added relevant files to `hail/python/hail/docs/_static/datasets`.; - Moved schemas currently on datasets doc page to their own page. Datasets doc page links to this new page.; - Moved some minor styling from html files to `annotationdb.css`, and cleaned up formatting of html.; - Added doc page for the `DB` class, referenced on the Python API doc page for the experimental module. Only exposes the `available_datasets` attribute and `annotate_rows_db` method, as I didn't think most users need to see any internal methods or the `Dataset` and `DatasetVersion` classes/methods. Most of diff is just formatting changes to `db.py` and `datasets.py` for consistency/readability that did not change functionality. Also added docstrings to methods in `db.py` that were missing them. Added a check in `DB` constructor to make sure the cloud and region combination is valid. To prevent an empty annotation DB instance from being created if user specifies `db = hl.experimental.DB(region='eu', cloud='aws')`, since we don't have an EU bucket on AWS.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9663
https://github.com/hail-is/hail/pull/9663:761,Security,expose,exposes,761,"Made changes to clean up/add to the documentation for the datasets API and annotation DB. Changes to documentation:. - Moved raw html in `annotation_database_ui.rst` into `hail/python/hail/docs/_static/annotationdb/annotationdb.html`.; - Added html table to bottom of datasets doc page to show all available datasets, similar to what is currently on annotation DB doc page. Added relevant files to `hail/python/hail/docs/_static/datasets`.; - Moved schemas currently on datasets doc page to their own page. Datasets doc page links to this new page.; - Moved some minor styling from html files to `annotationdb.css`, and cleaned up formatting of html.; - Added doc page for the `DB` class, referenced on the Python API doc page for the experimental module. Only exposes the `available_datasets` attribute and `annotate_rows_db` method, as I didn't think most users need to see any internal methods or the `Dataset` and `DatasetVersion` classes/methods. Most of diff is just formatting changes to `db.py` and `datasets.py` for consistency/readability that did not change functionality. Also added docstrings to methods in `db.py` that were missing them. Added a check in `DB` constructor to make sure the cloud and region combination is valid. To prevent an empty annotation DB instance from being created if user specifies `db = hl.experimental.DB(region='eu', cloud='aws')`, since we don't have an EU bucket on AWS.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9663
https://github.com/hail-is/hail/pull/9666:1018,Deployability,release,release,1018,"#9634 Introduced a large performance regression in the `linear_regression_rows_nd` benchmark (making it about 4x slower). This PR fixes that by doing two things:. 1. Move all the global into one single `annotate_globals` expression, so that CSE can work properly. This required fixing a bug in some ndarray expressions that were not correctly tracking their source tables. To make sure I was only referencing the global versions of this computed things, rather accidentally recomputing, I wrapped the global setup in a function to scope the variables. This improvement was minor, didn't hit the real root of the problem. 2. Much more significantly, and not 100% clear why: `process_y_group` is now a function that returns a python dictionary, instead of a hail struct. I can guess that the allocation required by making a struct was wasteful, but it seems crazy that it was ""make the benchmark 4x slower"" amounts of wasteful. . While this is not user facing yet, would be good to get this in before an eventual 0.2.60 release if we want to avoid benchmarks regressing between versions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9666
https://github.com/hail-is/hail/pull/9666:489,Integrability,wrap,wrapped,489,"#9634 Introduced a large performance regression in the `linear_regression_rows_nd` benchmark (making it about 4x slower). This PR fixes that by doing two things:. 1. Move all the global into one single `annotate_globals` expression, so that CSE can work properly. This required fixing a bug in some ndarray expressions that were not correctly tracking their source tables. To make sure I was only referencing the global versions of this computed things, rather accidentally recomputing, I wrapped the global setup in a function to scope the variables. This improvement was minor, didn't hit the real root of the problem. 2. Much more significantly, and not 100% clear why: `process_y_group` is now a function that returns a python dictionary, instead of a hail struct. I can guess that the allocation required by making a struct was wasteful, but it seems crazy that it was ""make the benchmark 4x slower"" amounts of wasteful. . While this is not user facing yet, would be good to get this in before an eventual 0.2.60 release if we want to avoid benchmarks regressing between versions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9666
https://github.com/hail-is/hail/pull/9666:541,Modifiability,variab,variables,541,"#9634 Introduced a large performance regression in the `linear_regression_rows_nd` benchmark (making it about 4x slower). This PR fixes that by doing two things:. 1. Move all the global into one single `annotate_globals` expression, so that CSE can work properly. This required fixing a bug in some ndarray expressions that were not correctly tracking their source tables. To make sure I was only referencing the global versions of this computed things, rather accidentally recomputing, I wrapped the global setup in a function to scope the variables. This improvement was minor, didn't hit the real root of the problem. 2. Much more significantly, and not 100% clear why: `process_y_group` is now a function that returns a python dictionary, instead of a hail struct. I can guess that the allocation required by making a struct was wasteful, but it seems crazy that it was ""make the benchmark 4x slower"" amounts of wasteful. . While this is not user facing yet, would be good to get this in before an eventual 0.2.60 release if we want to avoid benchmarks regressing between versions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9666
https://github.com/hail-is/hail/pull/9666:25,Performance,perform,performance,25,"#9634 Introduced a large performance regression in the `linear_regression_rows_nd` benchmark (making it about 4x slower). This PR fixes that by doing two things:. 1. Move all the global into one single `annotate_globals` expression, so that CSE can work properly. This required fixing a bug in some ndarray expressions that were not correctly tracking their source tables. To make sure I was only referencing the global versions of this computed things, rather accidentally recomputing, I wrapped the global setup in a function to scope the variables. This improvement was minor, didn't hit the real root of the problem. 2. Much more significantly, and not 100% clear why: `process_y_group` is now a function that returns a python dictionary, instead of a hail struct. I can guess that the allocation required by making a struct was wasteful, but it seems crazy that it was ""make the benchmark 4x slower"" amounts of wasteful. . While this is not user facing yet, would be good to get this in before an eventual 0.2.60 release if we want to avoid benchmarks regressing between versions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9666
https://github.com/hail-is/hail/pull/9666:1040,Safety,avoid,avoid,1040,"#9634 Introduced a large performance regression in the `linear_regression_rows_nd` benchmark (making it about 4x slower). This PR fixes that by doing two things:. 1. Move all the global into one single `annotate_globals` expression, so that CSE can work properly. This required fixing a bug in some ndarray expressions that were not correctly tracking their source tables. To make sure I was only referencing the global versions of this computed things, rather accidentally recomputing, I wrapped the global setup in a function to scope the variables. This improvement was minor, didn't hit the real root of the problem. 2. Much more significantly, and not 100% clear why: `process_y_group` is now a function that returns a python dictionary, instead of a hail struct. I can guess that the allocation required by making a struct was wasteful, but it seems crazy that it was ""make the benchmark 4x slower"" amounts of wasteful. . While this is not user facing yet, would be good to get this in before an eventual 0.2.60 release if we want to avoid benchmarks regressing between versions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9666
https://github.com/hail-is/hail/pull/9666:83,Testability,benchmark,benchmark,83,"#9634 Introduced a large performance regression in the `linear_regression_rows_nd` benchmark (making it about 4x slower). This PR fixes that by doing two things:. 1. Move all the global into one single `annotate_globals` expression, so that CSE can work properly. This required fixing a bug in some ndarray expressions that were not correctly tracking their source tables. To make sure I was only referencing the global versions of this computed things, rather accidentally recomputing, I wrapped the global setup in a function to scope the variables. This improvement was minor, didn't hit the real root of the problem. 2. Much more significantly, and not 100% clear why: `process_y_group` is now a function that returns a python dictionary, instead of a hail struct. I can guess that the allocation required by making a struct was wasteful, but it seems crazy that it was ""make the benchmark 4x slower"" amounts of wasteful. . While this is not user facing yet, would be good to get this in before an eventual 0.2.60 release if we want to avoid benchmarks regressing between versions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9666
https://github.com/hail-is/hail/pull/9666:884,Testability,benchmark,benchmark,884,"#9634 Introduced a large performance regression in the `linear_regression_rows_nd` benchmark (making it about 4x slower). This PR fixes that by doing two things:. 1. Move all the global into one single `annotate_globals` expression, so that CSE can work properly. This required fixing a bug in some ndarray expressions that were not correctly tracking their source tables. To make sure I was only referencing the global versions of this computed things, rather accidentally recomputing, I wrapped the global setup in a function to scope the variables. This improvement was minor, didn't hit the real root of the problem. 2. Much more significantly, and not 100% clear why: `process_y_group` is now a function that returns a python dictionary, instead of a hail struct. I can guess that the allocation required by making a struct was wasteful, but it seems crazy that it was ""make the benchmark 4x slower"" amounts of wasteful. . While this is not user facing yet, would be good to get this in before an eventual 0.2.60 release if we want to avoid benchmarks regressing between versions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9666
https://github.com/hail-is/hail/pull/9666:1046,Testability,benchmark,benchmarks,1046,"#9634 Introduced a large performance regression in the `linear_regression_rows_nd` benchmark (making it about 4x slower). This PR fixes that by doing two things:. 1. Move all the global into one single `annotate_globals` expression, so that CSE can work properly. This required fixing a bug in some ndarray expressions that were not correctly tracking their source tables. To make sure I was only referencing the global versions of this computed things, rather accidentally recomputing, I wrapped the global setup in a function to scope the variables. This improvement was minor, didn't hit the real root of the problem. 2. Much more significantly, and not 100% clear why: `process_y_group` is now a function that returns a python dictionary, instead of a hail struct. I can guess that the allocation required by making a struct was wasteful, but it seems crazy that it was ""make the benchmark 4x slower"" amounts of wasteful. . While this is not user facing yet, would be good to get this in before an eventual 0.2.60 release if we want to avoid benchmarks regressing between versions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9666
https://github.com/hail-is/hail/pull/9666:662,Usability,clear,clear,662,"#9634 Introduced a large performance regression in the `linear_regression_rows_nd` benchmark (making it about 4x slower). This PR fixes that by doing two things:. 1. Move all the global into one single `annotate_globals` expression, so that CSE can work properly. This required fixing a bug in some ndarray expressions that were not correctly tracking their source tables. To make sure I was only referencing the global versions of this computed things, rather accidentally recomputing, I wrapped the global setup in a function to scope the variables. This improvement was minor, didn't hit the real root of the problem. 2. Much more significantly, and not 100% clear why: `process_y_group` is now a function that returns a python dictionary, instead of a hail struct. I can guess that the allocation required by making a struct was wasteful, but it seems crazy that it was ""make the benchmark 4x slower"" amounts of wasteful. . While this is not user facing yet, would be good to get this in before an eventual 0.2.60 release if we want to avoid benchmarks regressing between versions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9666
https://github.com/hail-is/hail/pull/9668:49,Testability,benchmark,benchmark,49,"@Dania-Abuhijleh This is infrastructure for your benchmark project. Once this goes in, you can change your Batch Client billing project to be benchmark instead of test.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9668
https://github.com/hail-is/hail/pull/9668:142,Testability,benchmark,benchmark,142,"@Dania-Abuhijleh This is infrastructure for your benchmark project. Once this goes in, you can change your Batch Client billing project to be benchmark instead of test.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9668
https://github.com/hail-is/hail/pull/9668:163,Testability,test,test,163,"@Dania-Abuhijleh This is infrastructure for your benchmark project. Once this goes in, you can change your Batch Client billing project to be benchmark instead of test.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9668
https://github.com/hail-is/hail/pull/9672:162,Deployability,deploy,deploy,162,"This adds roles to the auth service. They are not used yet, but they are stored in the database and I created a simple UI for adding them. I tested with this dev deploy. FYI @danking @jigold",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9672
https://github.com/hail-is/hail/pull/9672:141,Testability,test,tested,141,"This adds roles to the auth service. They are not used yet, but they are stored in the database and I created a simple UI for adding them. I tested with this dev deploy. FYI @danking @jigold",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9672
https://github.com/hail-is/hail/pull/9672:112,Usability,simpl,simple,112,"This adds roles to the auth service. They are not used yet, but they are stored in the database and I created a simple UI for adding them. I tested with this dev deploy. FYI @danking @jigold",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9672
https://github.com/hail-is/hail/pull/9675:180,Deployability,pipeline,pipeline,180,"This PR moves us from having thread local `RegionPool`s, to ""task local"" `RegionPool`s, based on Spark tasks. This should make it easier for us to track peak memory usage across a pipeline.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9675
https://github.com/hail-is/hail/pull/9681:7,Testability,test,test,7,I will test this with a forthcoming PR which adds a TCP gateway.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9681
https://github.com/hail-is/hail/pull/9684:1008,Deployability,deploy,deploy,1008,"This is the initial version of the ATGU intranet service. Currently, it has a curated list of resources which can be created, viewed, edited and deleted. Resources can have attachments, which I store on Google storage. I used the async Google Storage client and it worked very nicely with aiohttp. Right now this developers only. I may give access to the admins to start curating resources. I'll follow up with roles and add roles for atgu-viewer and atgu-editor that I'll use in the service. I think the code is mostly straightforward, but a few remarks:. This is built on Bootstrap. It doesn't share the the styling with web common (which I probably want to convert). On the resources page, for client side search I use fuse.js: https://fusejs.io/ (so fast). For a rich text box (the resource content), I use quill.js: https://quilljs.com/. Quill doesn't allow you to post its contents in a form, so I use a JS event handler to populate a hidden input with the contents on submission. I tested it with dev deploy. I suggest you do the same before reviewing to get a sense of what's here. Feedback on the UI welcome.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9684
https://github.com/hail-is/hail/pull/9684:341,Security,access,access,341,"This is the initial version of the ATGU intranet service. Currently, it has a curated list of resources which can be created, viewed, edited and deleted. Resources can have attachments, which I store on Google storage. I used the async Google Storage client and it worked very nicely with aiohttp. Right now this developers only. I may give access to the admins to start curating resources. I'll follow up with roles and add roles for atgu-viewer and atgu-editor that I'll use in the service. I think the code is mostly straightforward, but a few remarks:. This is built on Bootstrap. It doesn't share the the styling with web common (which I probably want to convert). On the resources page, for client side search I use fuse.js: https://fusejs.io/ (so fast). For a rich text box (the resource content), I use quill.js: https://quilljs.com/. Quill doesn't allow you to post its contents in a form, so I use a JS event handler to populate a hidden input with the contents on submission. I tested it with dev deploy. I suggest you do the same before reviewing to get a sense of what's here. Feedback on the UI welcome.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9684
https://github.com/hail-is/hail/pull/9684:989,Testability,test,tested,989,"This is the initial version of the ATGU intranet service. Currently, it has a curated list of resources which can be created, viewed, edited and deleted. Resources can have attachments, which I store on Google storage. I used the async Google Storage client and it worked very nicely with aiohttp. Right now this developers only. I may give access to the admins to start curating resources. I'll follow up with roles and add roles for atgu-viewer and atgu-editor that I'll use in the service. I think the code is mostly straightforward, but a few remarks:. This is built on Bootstrap. It doesn't share the the styling with web common (which I probably want to convert). On the resources page, for client side search I use fuse.js: https://fusejs.io/ (so fast). For a rich text box (the resource content), I use quill.js: https://quilljs.com/. Quill doesn't allow you to post its contents in a form, so I use a JS event handler to populate a hidden input with the contents on submission. I tested it with dev deploy. I suggest you do the same before reviewing to get a sense of what's here. Feedback on the UI welcome.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9684
https://github.com/hail-is/hail/pull/9684:1090,Usability,Feedback,Feedback,1090,"This is the initial version of the ATGU intranet service. Currently, it has a curated list of resources which can be created, viewed, edited and deleted. Resources can have attachments, which I store on Google storage. I used the async Google Storage client and it worked very nicely with aiohttp. Right now this developers only. I may give access to the admins to start curating resources. I'll follow up with roles and add roles for atgu-viewer and atgu-editor that I'll use in the service. I think the code is mostly straightforward, but a few remarks:. This is built on Bootstrap. It doesn't share the the styling with web common (which I probably want to convert). On the resources page, for client side search I use fuse.js: https://fusejs.io/ (so fast). For a rich text box (the resource content), I use quill.js: https://quilljs.com/. Quill doesn't allow you to post its contents in a form, so I use a JS event handler to populate a hidden input with the contents on submission. I tested it with dev deploy. I suggest you do the same before reviewing to get a sense of what's here. Feedback on the UI welcome.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9684
https://github.com/hail-is/hail/issues/9685:532,Availability,error,error,532,"Dear hail team,. I am trying to get familiar with hail by filtering and doing simple stuff I usually do on VCFs with softwares like bcftools.; I am working with Hail version 0.2.57-582b2e31b8bd; I splitted my VCF from multiallelic to biallelic with:; `data_tmp_bi = hl.split_multi_hts(data_tmp)`; Then I want to update the allele counts the same way as what I saw in your documentation:; `data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC=data_tmp_bi.info.AC[data_tmp_bi.a_index - 1],**data_tmp_bi.info))`; but I get this error:; ```; File ""<ipython-input-29-3595a23add68>"", line 1, in <module>; data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC=data_tmp_bi.info.AC[data_tmp_bi.a_index - 1],**data_tmp_bi.info)). TypeError: struct() got multiple values for keyword argument 'AC'; ```; The workaround I have been using is then to create a new info field called 'AC2', to then drop the 'AC' field and then recreate the 'AC' field with `annotate_rows` with to finally drop 'AC2'. Which is a long workaround:; ```; data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC2=data_tmp_bi.info.AC[data_tmp_bi.a_index - 1],**data_tmp_bi.info)); data_tmp_bi = data_tmp_bi.annotate_rows(info=data_tmp_bi.info.drop('AC')); data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC=data_tmp_bi.info.AC2, **data_tmp_bi.info)); data_tmp_bi = data_tmp_bi.annotate_rows(info=data_tmp_bi.info.drop('AC2')); ```. On top of this, I filter by column some samples with `filter_cols`, so then, I want to update fields like allele count again, so I would still need to use the same workaround as above, otherwise I get the same error. Do you have an idea of what the problem might be? Or a better way of doing this than what I am using?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9685
https://github.com/hail-is/hail/issues/9685:1629,Availability,error,error,1629,"Dear hail team,. I am trying to get familiar with hail by filtering and doing simple stuff I usually do on VCFs with softwares like bcftools.; I am working with Hail version 0.2.57-582b2e31b8bd; I splitted my VCF from multiallelic to biallelic with:; `data_tmp_bi = hl.split_multi_hts(data_tmp)`; Then I want to update the allele counts the same way as what I saw in your documentation:; `data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC=data_tmp_bi.info.AC[data_tmp_bi.a_index - 1],**data_tmp_bi.info))`; but I get this error:; ```; File ""<ipython-input-29-3595a23add68>"", line 1, in <module>; data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC=data_tmp_bi.info.AC[data_tmp_bi.a_index - 1],**data_tmp_bi.info)). TypeError: struct() got multiple values for keyword argument 'AC'; ```; The workaround I have been using is then to create a new info field called 'AC2', to then drop the 'AC' field and then recreate the 'AC' field with `annotate_rows` with to finally drop 'AC2'. Which is a long workaround:; ```; data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC2=data_tmp_bi.info.AC[data_tmp_bi.a_index - 1],**data_tmp_bi.info)); data_tmp_bi = data_tmp_bi.annotate_rows(info=data_tmp_bi.info.drop('AC')); data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC=data_tmp_bi.info.AC2, **data_tmp_bi.info)); data_tmp_bi = data_tmp_bi.annotate_rows(info=data_tmp_bi.info.drop('AC2')); ```. On top of this, I filter by column some samples with `filter_cols`, so then, I want to update fields like allele count again, so I would still need to use the same workaround as above, otherwise I get the same error. Do you have an idea of what the problem might be? Or a better way of doing this than what I am using?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9685
https://github.com/hail-is/hail/issues/9685:312,Deployability,update,update,312,"Dear hail team,. I am trying to get familiar with hail by filtering and doing simple stuff I usually do on VCFs with softwares like bcftools.; I am working with Hail version 0.2.57-582b2e31b8bd; I splitted my VCF from multiallelic to biallelic with:; `data_tmp_bi = hl.split_multi_hts(data_tmp)`; Then I want to update the allele counts the same way as what I saw in your documentation:; `data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC=data_tmp_bi.info.AC[data_tmp_bi.a_index - 1],**data_tmp_bi.info))`; but I get this error:; ```; File ""<ipython-input-29-3595a23add68>"", line 1, in <module>; data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC=data_tmp_bi.info.AC[data_tmp_bi.a_index - 1],**data_tmp_bi.info)). TypeError: struct() got multiple values for keyword argument 'AC'; ```; The workaround I have been using is then to create a new info field called 'AC2', to then drop the 'AC' field and then recreate the 'AC' field with `annotate_rows` with to finally drop 'AC2'. Which is a long workaround:; ```; data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC2=data_tmp_bi.info.AC[data_tmp_bi.a_index - 1],**data_tmp_bi.info)); data_tmp_bi = data_tmp_bi.annotate_rows(info=data_tmp_bi.info.drop('AC')); data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC=data_tmp_bi.info.AC2, **data_tmp_bi.info)); data_tmp_bi = data_tmp_bi.annotate_rows(info=data_tmp_bi.info.drop('AC2')); ```. On top of this, I filter by column some samples with `filter_cols`, so then, I want to update fields like allele count again, so I would still need to use the same workaround as above, otherwise I get the same error. Do you have an idea of what the problem might be? Or a better way of doing this than what I am using?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9685
https://github.com/hail-is/hail/issues/9685:1506,Deployability,update,update,1506,"Dear hail team,. I am trying to get familiar with hail by filtering and doing simple stuff I usually do on VCFs with softwares like bcftools.; I am working with Hail version 0.2.57-582b2e31b8bd; I splitted my VCF from multiallelic to biallelic with:; `data_tmp_bi = hl.split_multi_hts(data_tmp)`; Then I want to update the allele counts the same way as what I saw in your documentation:; `data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC=data_tmp_bi.info.AC[data_tmp_bi.a_index - 1],**data_tmp_bi.info))`; but I get this error:; ```; File ""<ipython-input-29-3595a23add68>"", line 1, in <module>; data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC=data_tmp_bi.info.AC[data_tmp_bi.a_index - 1],**data_tmp_bi.info)). TypeError: struct() got multiple values for keyword argument 'AC'; ```; The workaround I have been using is then to create a new info field called 'AC2', to then drop the 'AC' field and then recreate the 'AC' field with `annotate_rows` with to finally drop 'AC2'. Which is a long workaround:; ```; data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC2=data_tmp_bi.info.AC[data_tmp_bi.a_index - 1],**data_tmp_bi.info)); data_tmp_bi = data_tmp_bi.annotate_rows(info=data_tmp_bi.info.drop('AC')); data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC=data_tmp_bi.info.AC2, **data_tmp_bi.info)); data_tmp_bi = data_tmp_bi.annotate_rows(info=data_tmp_bi.info.drop('AC2')); ```. On top of this, I filter by column some samples with `filter_cols`, so then, I want to update fields like allele count again, so I would still need to use the same workaround as above, otherwise I get the same error. Do you have an idea of what the problem might be? Or a better way of doing this than what I am using?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9685
https://github.com/hail-is/hail/issues/9685:78,Usability,simpl,simple,78,"Dear hail team,. I am trying to get familiar with hail by filtering and doing simple stuff I usually do on VCFs with softwares like bcftools.; I am working with Hail version 0.2.57-582b2e31b8bd; I splitted my VCF from multiallelic to biallelic with:; `data_tmp_bi = hl.split_multi_hts(data_tmp)`; Then I want to update the allele counts the same way as what I saw in your documentation:; `data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC=data_tmp_bi.info.AC[data_tmp_bi.a_index - 1],**data_tmp_bi.info))`; but I get this error:; ```; File ""<ipython-input-29-3595a23add68>"", line 1, in <module>; data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC=data_tmp_bi.info.AC[data_tmp_bi.a_index - 1],**data_tmp_bi.info)). TypeError: struct() got multiple values for keyword argument 'AC'; ```; The workaround I have been using is then to create a new info field called 'AC2', to then drop the 'AC' field and then recreate the 'AC' field with `annotate_rows` with to finally drop 'AC2'. Which is a long workaround:; ```; data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC2=data_tmp_bi.info.AC[data_tmp_bi.a_index - 1],**data_tmp_bi.info)); data_tmp_bi = data_tmp_bi.annotate_rows(info=data_tmp_bi.info.drop('AC')); data_tmp_bi = data_tmp_bi.annotate_rows(info = hl.struct(AC=data_tmp_bi.info.AC2, **data_tmp_bi.info)); data_tmp_bi = data_tmp_bi.annotate_rows(info=data_tmp_bi.info.drop('AC2')); ```. On top of this, I filter by column some samples with `filter_cols`, so then, I want to update fields like allele count again, so I would still need to use the same workaround as above, otherwise I get the same error. Do you have an idea of what the problem might be? Or a better way of doing this than what I am using?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9685
https://github.com/hail-is/hail/pull/9686:63,Availability,error,error,63,More info here: https://discuss.hail.is/t/export-elasticsearch-error/1755/4,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9686
https://github.com/hail-is/hail/pull/9687:41,Testability,test,test,41,"I have no idea why we were skipping this test, but it was not a good idea to skip it, as the example was incorrect. We can't use `**split_ds.info` because that will contain `AC`, and so we will be trying to make a struct with two fields called `AC`. . I also replaced `vds` with `mt`, which we should do pervasively everywhere at some point.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9687
https://github.com/hail-is/hail/pull/9689:0,Testability,test,tested,0,"tested 3 cases, when a commit has a results file, doesn't have a results file but has a running batch, or no file and no running batch.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9689
https://github.com/hail-is/hail/pull/9693:0,Deployability,Update,Updated,0,"Updated the paths in `datasets.json` for `gnomad_exome_sites` and `gnomad_genome_sites` to use the `gs://gcp-public-data--gnomad` bucket. . Added the Hail Table for version 3.1 of genome sites to `datasets.json`, as well as the gnomad HGDP + 1KG callset MatrixTable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9693
https://github.com/hail-is/hail/pull/9694:352,Availability,error,error,352,"GENCODE GTF files have contigs ""chr1"", ""chr2"", ... , ""chrX"", ""chrY"", ""chrM"". Currently, when `reference_genome` is set to GRCh37, `import_gtf` removes the ""chr"" prefix. This works for chromosomes 1-22, X, and Y. However, for the mitochondrial contig, Hail expects ""MT"" instead of ""M"" and attempting to do anything with the imported table results in an error: `HailException: Invalid interval '[...]' found. Contig 'M' is not in the reference genome 'GRCh37'.`. With this change, `import_gtf` recodes ""M"" and ""chrM"" as ""MT"" so that the intervals are valid for GRCh37.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9694
https://github.com/hail-is/hail/pull/9695:134,Availability,error,error,134,There were a few places where things that had `NAMESPACE` didn't use it in certain places. I also fixed that. I also standardized the error verbiage.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9695
https://github.com/hail-is/hail/pull/9696:143,Integrability,depend,depending,143,Users want to be able to use elasticsearch 7. This adds an argument to make so that we pull in a different version of `elasticsearch-spark-20` depending on what they specify for `ELASTIC_MAJOR_VERSION`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9696
https://github.com/hail-is/hail/pull/9703:0,Deployability,Release,Release,0,"Release 0.2.60. Updated hail query change log. Didn't see any user changes for hail batch, let me know if I'm wrong @jigold",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9703
https://github.com/hail-is/hail/pull/9703:16,Deployability,Update,Updated,16,"Release 0.2.60. Updated hail query change log. Didn't see any user changes for hail batch, let me know if I'm wrong @jigold",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9703
https://github.com/hail-is/hail/pull/9703:42,Testability,log,log,42,"Release 0.2.60. Updated hail query change log. Didn't see any user changes for hail batch, let me know if I'm wrong @jigold",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9703
https://github.com/hail-is/hail/issues/9704:204,Availability,error,error,204,"Hail Version: `0.2.53-8140f17d9262`. I've got a matrix table where I have added a row and col index to, and am trying to select a field from the table using the following syntax and getting the following error:. `mt[1, 1].GT`. ```; The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last); <ipython-input-65-47ed69d0881f> in <module>; 1 for header in headers:; ----> 2 ext = ext.annotate(newHeader = filtered[header.row_idx, ext.idx].GT); 3 ext = ext.rename({ 'newHeader': header.header }). /usr/local/lib/python3.6/site-packages/hail/matrixtable.py in __getitem__(self, item); 626 return self.index_entries(row_key, col_key); 627 except TypeError as e:; --> 628 raise invalid_usage from e; 629 raise invalid_usage; 630. TypeError: MatrixTable.__getitem__: invalid index argument(s); Usage 1: field selection: mt['field']; Usage 2: Entry joining: mt[mt2.row_key, mt2.col_key]. To join row or column fields, use one of the following:; rows:; mt.index_rows(mt2.row_key); mt.rows().index(mt2.row_key); mt.rows()[mt2.row_key]; cols:; mt.index_cols(mt2.col_key); mt.cols().index(mt2.col_key); mt.cols()[mt2.col_key]; ```. Please let me know if you need any further information. The zulip topic name is `Error accessing entry by row/col key`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9704
https://github.com/hail-is/hail/issues/9704:1255,Availability,Error,Error,1255,"Hail Version: `0.2.53-8140f17d9262`. I've got a matrix table where I have added a row and col index to, and am trying to select a field from the table using the following syntax and getting the following error:. `mt[1, 1].GT`. ```; The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last); <ipython-input-65-47ed69d0881f> in <module>; 1 for header in headers:; ----> 2 ext = ext.annotate(newHeader = filtered[header.row_idx, ext.idx].GT); 3 ext = ext.rename({ 'newHeader': header.header }). /usr/local/lib/python3.6/site-packages/hail/matrixtable.py in __getitem__(self, item); 626 return self.index_entries(row_key, col_key); 627 except TypeError as e:; --> 628 raise invalid_usage from e; 629 raise invalid_usage; 630. TypeError: MatrixTable.__getitem__: invalid index argument(s); Usage 1: field selection: mt['field']; Usage 2: Entry joining: mt[mt2.row_key, mt2.col_key]. To join row or column fields, use one of the following:; rows:; mt.index_rows(mt2.row_key); mt.rows().index(mt2.row_key); mt.rows()[mt2.row_key]; cols:; mt.index_cols(mt2.col_key); mt.cols().index(mt2.col_key); mt.cols()[mt2.col_key]; ```. Please let me know if you need any further information. The zulip topic name is `Error accessing entry by row/col key`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9704
https://github.com/hail-is/hail/issues/9704:1261,Security,access,accessing,1261,"Hail Version: `0.2.53-8140f17d9262`. I've got a matrix table where I have added a row and col index to, and am trying to select a field from the table using the following syntax and getting the following error:. `mt[1, 1].GT`. ```; The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last); <ipython-input-65-47ed69d0881f> in <module>; 1 for header in headers:; ----> 2 ext = ext.annotate(newHeader = filtered[header.row_idx, ext.idx].GT); 3 ext = ext.rename({ 'newHeader': header.header }). /usr/local/lib/python3.6/site-packages/hail/matrixtable.py in __getitem__(self, item); 626 return self.index_entries(row_key, col_key); 627 except TypeError as e:; --> 628 raise invalid_usage from e; 629 raise invalid_usage; 630. TypeError: MatrixTable.__getitem__: invalid index argument(s); Usage 1: field selection: mt['field']; Usage 2: Entry joining: mt[mt2.row_key, mt2.col_key]. To join row or column fields, use one of the following:; rows:; mt.index_rows(mt2.row_key); mt.rows().index(mt2.row_key); mt.rows()[mt2.row_key]; cols:; mt.index_cols(mt2.col_key); mt.cols().index(mt2.col_key); mt.cols()[mt2.col_key]; ```. Please let me know if you need any further information. The zulip topic name is `Error accessing entry by row/col key`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9704
https://github.com/hail-is/hail/pull/9708:12,Performance,perform,performance,12,"I detect no performance difference on blanczos running the benchmark; locally. This pattern appears a lot in the NDArrayEmitter, though,; so we should fix it everywhere and see what happens!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9708
https://github.com/hail-is/hail/pull/9708:2,Safety,detect,detect,2,"I detect no performance difference on blanczos running the benchmark; locally. This pattern appears a lot in the NDArrayEmitter, though,; so we should fix it everywhere and see what happens!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9708
https://github.com/hail-is/hail/pull/9708:59,Testability,benchmark,benchmark,59,"I detect no performance difference on blanczos running the benchmark; locally. This pattern appears a lot in the NDArrayEmitter, though,; so we should fix it everywhere and see what happens!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9708
https://github.com/hail-is/hail/pull/9711:127,Security,encrypt,encrypt,127,This works in the sense that I didn't get a 404 or 502 contacting the server in my namespace. I think we need to redeploy lets encrypt -- can't remember.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9711
https://github.com/hail-is/hail/pull/9713:101,Modifiability,config,config,101,"Right now this spins up K8s, a database, some of the networking stuff,; and creates a default/global-config secret that includes the; information stored in $HAIL/config.mk. This isn't used yet and will; probably change.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9713
https://github.com/hail-is/hail/pull/9713:162,Modifiability,config,config,162,"Right now this spins up K8s, a database, some of the networking stuff,; and creates a default/global-config secret that includes the; information stored in $HAIL/config.mk. This isn't used yet and will; probably change.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9713
https://github.com/hail-is/hail/pull/9715:2,Deployability,update,updated,2,"I updated every call site to match the new parameters. This refactoring removes some code duplication, changes a stack trace in `hailctl auth user` to a nice print message, and adds a parameter (`client_session`) which I will use in my forthcoming TCP Proxy PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9715
https://github.com/hail-is/hail/pull/9715:164,Integrability,message,message,164,"I updated every call site to match the new parameters. This refactoring removes some code duplication, changes a stack trace in `hailctl auth user` to a nice print message, and adds a parameter (`client_session`) which I will use in my forthcoming TCP Proxy PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9715
https://github.com/hail-is/hail/pull/9715:60,Modifiability,refactor,refactoring,60,"I updated every call site to match the new parameters. This refactoring removes some code duplication, changes a stack trace in `hailctl auth user` to a nice print message, and adds a parameter (`client_session`) which I will use in my forthcoming TCP Proxy PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9715
https://github.com/hail-is/hail/pull/9717:51,Testability,test,tests,51,Without this it is a huge pain to run the services tests locally.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9717
https://github.com/hail-is/hail/pull/9722:8,Deployability,update,update,8,"Apt-get update does not use the retries parameter used by; apt-get install. In fact, I could not find any retry configuration; for apt-get update. This is a cheap hack that retries 5 times with; exponential back-off.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9722
https://github.com/hail-is/hail/pull/9722:67,Deployability,install,install,67,"Apt-get update does not use the retries parameter used by; apt-get install. In fact, I could not find any retry configuration; for apt-get update. This is a cheap hack that retries 5 times with; exponential back-off.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9722
https://github.com/hail-is/hail/pull/9722:112,Deployability,configurat,configuration,112,"Apt-get update does not use the retries parameter used by; apt-get install. In fact, I could not find any retry configuration; for apt-get update. This is a cheap hack that retries 5 times with; exponential back-off.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9722
https://github.com/hail-is/hail/pull/9722:139,Deployability,update,update,139,"Apt-get update does not use the retries parameter used by; apt-get install. In fact, I could not find any retry configuration; for apt-get update. This is a cheap hack that retries 5 times with; exponential back-off.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9722
https://github.com/hail-is/hail/pull/9722:112,Modifiability,config,configuration,112,"Apt-get update does not use the retries parameter used by; apt-get install. In fact, I could not find any retry configuration; for apt-get update. This is a cheap hack that retries 5 times with; exponential back-off.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9722
https://github.com/hail-is/hail/pull/9725:224,Availability,failure,failure,224,"We cancel in two cases:; 1. A (dev|) deploy failed.; 2. A batch was found open but unknown to us. In the former case, we should delete the batch. The batch contains no extra information; everything we need to know is in the failure message. In the latter case, an open batch does not cost us anything and; cannot be cancelled anyway, so we choose to ignore them. Such a batch; should only come into existence when CI dies in the middle of submission; which should be quite rare.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9725
https://github.com/hail-is/hail/pull/9725:37,Deployability,deploy,deploy,37,"We cancel in two cases:; 1. A (dev|) deploy failed.; 2. A batch was found open but unknown to us. In the former case, we should delete the batch. The batch contains no extra information; everything we need to know is in the failure message. In the latter case, an open batch does not cost us anything and; cannot be cancelled anyway, so we choose to ignore them. Such a batch; should only come into existence when CI dies in the middle of submission; which should be quite rare.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9725
https://github.com/hail-is/hail/pull/9725:232,Integrability,message,message,232,"We cancel in two cases:; 1. A (dev|) deploy failed.; 2. A batch was found open but unknown to us. In the former case, we should delete the batch. The batch contains no extra information; everything we need to know is in the failure message. In the latter case, an open batch does not cost us anything and; cannot be cancelled anyway, so we choose to ignore them. Such a batch; should only come into existence when CI dies in the middle of submission; which should be quite rare.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9725
https://github.com/hail-is/hail/pull/9726:51,Deployability,deploy,deploys,51,"Since the first build.py we have had two bugs. Dev deploys would regularly; re-deploy the router service in the default namespace. The more recent bug; is that the router port ought to be 443, not 80. Any time we dev deploy,; I suppose we have broken the mainline, but this must have been resolved by; deploys that came shortly thereafter.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9726
https://github.com/hail-is/hail/pull/9726:79,Deployability,deploy,deploy,79,"Since the first build.py we have had two bugs. Dev deploys would regularly; re-deploy the router service in the default namespace. The more recent bug; is that the router port ought to be 443, not 80. Any time we dev deploy,; I suppose we have broken the mainline, but this must have been resolved by; deploys that came shortly thereafter.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9726
https://github.com/hail-is/hail/pull/9726:217,Deployability,deploy,deploy,217,"Since the first build.py we have had two bugs. Dev deploys would regularly; re-deploy the router service in the default namespace. The more recent bug; is that the router port ought to be 443, not 80. Any time we dev deploy,; I suppose we have broken the mainline, but this must have been resolved by; deploys that came shortly thereafter.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9726
https://github.com/hail-is/hail/pull/9726:302,Deployability,deploy,deploys,302,"Since the first build.py we have had two bugs. Dev deploys would regularly; re-deploy the router service in the default namespace. The more recent bug; is that the router port ought to be 443, not 80. Any time we dev deploy,; I suppose we have broken the mainline, but this must have been resolved by; deploys that came shortly thereafter.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9726
https://github.com/hail-is/hail/pull/9726:90,Integrability,rout,router,90,"Since the first build.py we have had two bugs. Dev deploys would regularly; re-deploy the router service in the default namespace. The more recent bug; is that the router port ought to be 443, not 80. Any time we dev deploy,; I suppose we have broken the mainline, but this must have been resolved by; deploys that came shortly thereafter.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9726
https://github.com/hail-is/hail/pull/9726:164,Integrability,rout,router,164,"Since the first build.py we have had two bugs. Dev deploys would regularly; re-deploy the router service in the default namespace. The more recent bug; is that the router port ought to be 443, not 80. Any time we dev deploy,; I suppose we have broken the mainline, but this must have been resolved by; deploys that came shortly thereafter.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9726
https://github.com/hail-is/hail/pull/9727:152,Testability,test,tests,152,"If hail and numpy use two different lapack implementations, might not get the same sign on the singular vectors. This PR switches our vector comparison tests to check the absolute values of the matrices, plus make sure they multiply back together properly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9727
https://github.com/hail-is/hail/pull/9729:205,Performance,perform,performance-improving,205,"This commit introduces the SCode hierarchy. How are SCodes different; from PCodes? SCodes are what we want PCodes to be. They don't have; the methods `code / tcode`, which gives us a way to implement new; performance-improving types like SStackStruct with well-defined; boundaries around that functionality. Currently, the `asPCode` and `IEmitCode.typecast` methods break this; boundary, and I added these as a short-term mechanism to avoid another; very spicy meatball. This commit is entirely reorganizational, with no semantic changes; to the compiler.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9729
https://github.com/hail-is/hail/pull/9729:435,Safety,avoid,avoid,435,"This commit introduces the SCode hierarchy. How are SCodes different; from PCodes? SCodes are what we want PCodes to be. They don't have; the methods `code / tcode`, which gives us a way to implement new; performance-improving types like SStackStruct with well-defined; boundaries around that functionality. Currently, the `asPCode` and `IEmitCode.typecast` methods break this; boundary, and I added these as a short-term mechanism to avoid another; very spicy meatball. This commit is entirely reorganizational, with no semantic changes; to the compiler.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9729
https://github.com/hail-is/hail/pull/9733:41,Availability,error,error,41,I just added a slightly more informative error message. Do you want something more than this?,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9733
https://github.com/hail-is/hail/pull/9733:47,Integrability,message,message,47,I just added a slightly more informative error message. Do you want something more than this?,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9733
https://github.com/hail-is/hail/pull/9737:17,Modifiability,variab,variable,17,gcloud uses this variable to find the tokens file. We should set it so; that users do not need to configure anything. I also fixed some; missing arguments in the non-async get_userinfo.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9737
https://github.com/hail-is/hail/pull/9737:98,Modifiability,config,configure,98,gcloud uses this variable to find the tokens file. We should set it so; that users do not need to configure anything. I also fixed some; missing arguments in the non-async get_userinfo.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9737
https://github.com/hail-is/hail/pull/9740:129,Integrability,interface,interface,129,"We'll talk more about this during our meeting. This provides a skeleton for an LSM tree. Your first job will be to implement the interface using just C++'s `std::map`, an ordered key-value mapping. I implemented a simple command line interface that accepts a key-value language:. - `p k v`, put the value `v` at the key `k` (overwriting any value that currently exists); - `g k`, print the value associated with key `k`; if there is no value print an empty line; - `r l r`, print, on one line, all the key-value pairs between `l` (inclusive) and `r` (exclusive); - `d k`, remove any value associated with the key `k`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9740
https://github.com/hail-is/hail/pull/9740:234,Integrability,interface,interface,234,"We'll talk more about this during our meeting. This provides a skeleton for an LSM tree. Your first job will be to implement the interface using just C++'s `std::map`, an ordered key-value mapping. I implemented a simple command line interface that accepts a key-value language:. - `p k v`, put the value `v` at the key `k` (overwriting any value that currently exists); - `g k`, print the value associated with key `k`; if there is no value print an empty line; - `r l r`, print, on one line, all the key-value pairs between `l` (inclusive) and `r` (exclusive); - `d k`, remove any value associated with the key `k`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9740
https://github.com/hail-is/hail/pull/9740:214,Usability,simpl,simple,214,"We'll talk more about this during our meeting. This provides a skeleton for an LSM tree. Your first job will be to implement the interface using just C++'s `std::map`, an ordered key-value mapping. I implemented a simple command line interface that accepts a key-value language:. - `p k v`, put the value `v` at the key `k` (overwriting any value that currently exists); - `g k`, print the value associated with key `k`; if there is no value print an empty line; - `r l r`, print, on one line, all the key-value pairs between `l` (inclusive) and `r` (exclusive); - `d k`, remove any value associated with the key `k`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9740
https://github.com/hail-is/hail/issues/9742:325,Availability,ERROR,ERROR,325,"I use a Mac and try to install hail.; I use Mojave; I installed pyenv to modify my python versions.; I installed Python 3.7.9 since you recommend to use Python 3.7 as the latest version.; I then did a pip install hail, and it fails with pyspark:. Collecting pyspark<2.4.2,>=2.4; Using cached pyspark-2.4.1.tar.gz (215.7 MB); ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-pip-egg-info-vlaj8k6d; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/; Complete output (47 lines):; Could not import pypandoc - required to package PySpark; WARNING: The wheel package is not available.; ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-ggmq8ipk; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/; Complete output (8 lines):; no pandoc found, building platform unspecific wheel.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:340,Availability,error,errored,340,"I use a Mac and try to install hail.; I use Mojave; I installed pyenv to modify my python versions.; I installed Python 3.7.9 since you recommend to use Python 3.7 as the latest version.; I then did a pip install hail, and it fails with pyspark:. Collecting pyspark<2.4.2,>=2.4; Using cached pyspark-2.4.1.tar.gz (215.7 MB); ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-pip-egg-info-vlaj8k6d; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/; Complete output (47 lines):; Could not import pypandoc - required to package PySpark; WARNING: The wheel package is not available.; ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-ggmq8ipk; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/; Complete output (8 lines):; no pandoc found, building platform unspecific wheel.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:1183,Availability,avail,available,1183,"use a Mac and try to install hail.; I use Mojave; I installed pyenv to modify my python versions.; I installed Python 3.7.9 since you recommend to use Python 3.7 as the latest version.; I then did a pip install hail, and it fails with pyspark:. Collecting pyspark<2.4.2,>=2.4; Using cached pyspark-2.4.1.tar.gz (215.7 MB); ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-pip-egg-info-vlaj8k6d; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/; Complete output (47 lines):; Could not import pypandoc - required to package PySpark; WARNING: The wheel package is not available.; ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-ggmq8ipk; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/; Complete output (8 lines):; no pandoc found, building platform unspecific wheel..",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:1195,Availability,ERROR,ERROR,1195,"s with pyspark:. Collecting pyspark<2.4.2,>=2.4; Using cached pyspark-2.4.1.tar.gz (215.7 MB); ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-pip-egg-info-vlaj8k6d; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/; Complete output (47 lines):; Could not import pypandoc - required to package PySpark; WARNING: The wheel package is not available.; ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-ggmq8ipk; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/; Complete output (8 lines):; no pandoc found, building platform unspecific wheel...; use 'python setup.py download_pandoc' to download pandoc.; usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]; or: setup.py --help [cmd1 cmd2 ...]; or: setup.py --help-commands; or: setup.py cmd --help; ; er",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:1210,Availability,error,errored,1210,"s with pyspark:. Collecting pyspark<2.4.2,>=2.4; Using cached pyspark-2.4.1.tar.gz (215.7 MB); ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-pip-egg-info-vlaj8k6d; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/; Complete output (47 lines):; Could not import pypandoc - required to package PySpark; WARNING: The wheel package is not available.; ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-ggmq8ipk; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/; Complete output (8 lines):; no pandoc found, building platform unspecific wheel...; use 'python setup.py download_pandoc' to download pandoc.; usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]; or: setup.py --help [cmd1 cmd2 ...]; or: setup.py --help-commands; or: setup.py cmd --help; ; er",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:2046,Availability,down,download,2046,"l-0g3aqft5/pyspark/; Complete output (47 lines):; Could not import pypandoc - required to package PySpark; WARNING: The wheel package is not available.; ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-ggmq8ipk; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/; Complete output (8 lines):; no pandoc found, building platform unspecific wheel...; use 'python setup.py download_pandoc' to download pandoc.; usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]; or: setup.py --help [cmd1 cmd2 ...]; or: setup.py --help-commands; or: setup.py cmd --help; ; error: invalid command 'bdist_wheel'; ----------------------------------------; ERROR: Failed building wheel for pypandoc; ERROR: Failed to build one or more wheels; Traceback (most recent call last):; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/installer.py"", line 128, in fetch_build_egg; subprocess.check_call(cmd); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/subprocess.py"", line 363, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['/Users/spascal/.pyenv/versions/3.7.9/bin/python3.7', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/tmpspi2awj3', '--quiet', 'pypandoc']' returned non-zero exit status 1.; ; During handling of the above",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:2229,Availability,error,error,2229,", tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-ggmq8ipk; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/; Complete output (8 lines):; no pandoc found, building platform unspecific wheel...; use 'python setup.py download_pandoc' to download pandoc.; usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]; or: setup.py --help [cmd1 cmd2 ...]; or: setup.py --help-commands; or: setup.py cmd --help; ; error: invalid command 'bdist_wheel'; ----------------------------------------; ERROR: Failed building wheel for pypandoc; ERROR: Failed to build one or more wheels; Traceback (most recent call last):; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/installer.py"", line 128, in fetch_build_egg; subprocess.check_call(cmd); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/subprocess.py"", line 363, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['/Users/spascal/.pyenv/versions/3.7.9/bin/python3.7', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/tmpspi2awj3', '--quiet', 'pypandoc']' returned non-zero exit status 1.; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py"", line 224, in <module>; 'Programming Language :: Python :: Implementati",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:2309,Availability,ERROR,ERROR,2309,", tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-ggmq8ipk; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/; Complete output (8 lines):; no pandoc found, building platform unspecific wheel...; use 'python setup.py download_pandoc' to download pandoc.; usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]; or: setup.py --help [cmd1 cmd2 ...]; or: setup.py --help-commands; or: setup.py cmd --help; ; error: invalid command 'bdist_wheel'; ----------------------------------------; ERROR: Failed building wheel for pypandoc; ERROR: Failed to build one or more wheels; Traceback (most recent call last):; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/installer.py"", line 128, in fetch_build_egg; subprocess.check_call(cmd); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/subprocess.py"", line 363, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['/Users/spascal/.pyenv/versions/3.7.9/bin/python3.7', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/tmpspi2awj3', '--quiet', 'pypandoc']' returned non-zero exit status 1.; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py"", line 224, in <module>; 'Programming Language :: Python :: Implementati",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:2352,Availability,ERROR,ERROR,2352,", tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-ggmq8ipk; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/; Complete output (8 lines):; no pandoc found, building platform unspecific wheel...; use 'python setup.py download_pandoc' to download pandoc.; usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]; or: setup.py --help [cmd1 cmd2 ...]; or: setup.py --help-commands; or: setup.py cmd --help; ; error: invalid command 'bdist_wheel'; ----------------------------------------; ERROR: Failed building wheel for pypandoc; ERROR: Failed to build one or more wheels; Traceback (most recent call last):; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/installer.py"", line 128, in fetch_build_egg; subprocess.check_call(cmd); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/subprocess.py"", line 363, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['/Users/spascal/.pyenv/versions/3.7.9/bin/python3.7', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/tmpspi2awj3', '--quiet', 'pypandoc']' returned non-zero exit status 1.; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py"", line 224, in <module>; 'Programming Language :: Python :: Implementati",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:4622,Availability,error,errors,4622,"nother exception occurred:; ; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py"", line 224, in <module>; 'Programming Language :: Python :: Implementation :: PyPy']; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/__init__.py"", line 143, in setup; _install_setup_requires(attrs); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/__init__.py"", line 138, in _install_setup_requires; dist.fetch_build_eggs(dist.setup_requires); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/dist.py"", line 698, in fetch_build_eggs; replace_conflicting=True,; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 783, in resolve; replace_conflicting=replace_conflicting; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 1066, in best_match; return self.obtain(req, installer); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 1078, in obtain; return installer(requirement); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/dist.py"", line 754, in fetch_build_egg; return fetch_build_egg(self, req); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/installer.py"", line 130, in fetch_build_egg; raise DistutilsError(str(e)); distutils.errors.DistutilsError: Command '['/Users/spascal/.pyenv/versions/3.7.9/bin/python3.7', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/tmpspi2awj3', '--quiet', 'pypandoc']' returned non-zero exit status 1.; ----------------------------------------; ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:4945,Availability,ERROR,ERROR,4945,"nother exception occurred:; ; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py"", line 224, in <module>; 'Programming Language :: Python :: Implementation :: PyPy']; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/__init__.py"", line 143, in setup; _install_setup_requires(attrs); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/__init__.py"", line 138, in _install_setup_requires; dist.fetch_build_eggs(dist.setup_requires); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/dist.py"", line 698, in fetch_build_eggs; replace_conflicting=True,; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 783, in resolve; replace_conflicting=replace_conflicting; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 1066, in best_match; return self.obtain(req, installer); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 1078, in obtain; return installer(requirement); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/dist.py"", line 754, in fetch_build_egg; return fetch_build_egg(self, req); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/installer.py"", line 130, in fetch_build_egg; raise DistutilsError(str(e)); distutils.errors.DistutilsError: Command '['/Users/spascal/.pyenv/versions/3.7.9/bin/python3.7', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/tmpspi2awj3', '--quiet', 'pypandoc']' returned non-zero exit status 1.; ----------------------------------------; ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:4960,Availability,error,errored,4960,"nother exception occurred:; ; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py"", line 224, in <module>; 'Programming Language :: Python :: Implementation :: PyPy']; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/__init__.py"", line 143, in setup; _install_setup_requires(attrs); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/__init__.py"", line 138, in _install_setup_requires; dist.fetch_build_eggs(dist.setup_requires); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/dist.py"", line 698, in fetch_build_eggs; replace_conflicting=True,; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 783, in resolve; replace_conflicting=replace_conflicting; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 1066, in best_match; return self.obtain(req, installer); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 1078, in obtain; return installer(requirement); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/dist.py"", line 754, in fetch_build_egg; return fetch_build_egg(self, req); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/installer.py"", line 130, in fetch_build_egg; raise DistutilsError(str(e)); distutils.errors.DistutilsError: Command '['/Users/spascal/.pyenv/versions/3.7.9/bin/python3.7', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/tmpspi2awj3', '--quiet', 'pypandoc']' returned non-zero exit status 1.; ----------------------------------------; ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:23,Deployability,install,install,23,"I use a Mac and try to install hail.; I use Mojave; I installed pyenv to modify my python versions.; I installed Python 3.7.9 since you recommend to use Python 3.7 as the latest version.; I then did a pip install hail, and it fails with pyspark:. Collecting pyspark<2.4.2,>=2.4; Using cached pyspark-2.4.1.tar.gz (215.7 MB); ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-pip-egg-info-vlaj8k6d; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/; Complete output (47 lines):; Could not import pypandoc - required to package PySpark; WARNING: The wheel package is not available.; ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-ggmq8ipk; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/; Complete output (8 lines):; no pandoc found, building platform unspecific wheel.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:54,Deployability,install,installed,54,"I use a Mac and try to install hail.; I use Mojave; I installed pyenv to modify my python versions.; I installed Python 3.7.9 since you recommend to use Python 3.7 as the latest version.; I then did a pip install hail, and it fails with pyspark:. Collecting pyspark<2.4.2,>=2.4; Using cached pyspark-2.4.1.tar.gz (215.7 MB); ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-pip-egg-info-vlaj8k6d; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/; Complete output (47 lines):; Could not import pypandoc - required to package PySpark; WARNING: The wheel package is not available.; ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-ggmq8ipk; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/; Complete output (8 lines):; no pandoc found, building platform unspecific wheel.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:103,Deployability,install,installed,103,"I use a Mac and try to install hail.; I use Mojave; I installed pyenv to modify my python versions.; I installed Python 3.7.9 since you recommend to use Python 3.7 as the latest version.; I then did a pip install hail, and it fails with pyspark:. Collecting pyspark<2.4.2,>=2.4; Using cached pyspark-2.4.1.tar.gz (215.7 MB); ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-pip-egg-info-vlaj8k6d; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/; Complete output (47 lines):; Could not import pypandoc - required to package PySpark; WARNING: The wheel package is not available.; ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-ggmq8ipk; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/; Complete output (8 lines):; no pandoc found, building platform unspecific wheel.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:205,Deployability,install,install,205,"I use a Mac and try to install hail.; I use Mojave; I installed pyenv to modify my python versions.; I installed Python 3.7.9 since you recommend to use Python 3.7 as the latest version.; I then did a pip install hail, and it fails with pyspark:. Collecting pyspark<2.4.2,>=2.4; Using cached pyspark-2.4.1.tar.gz (215.7 MB); ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-pip-egg-info-vlaj8k6d; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/; Complete output (47 lines):; Could not import pypandoc - required to package PySpark; WARNING: The wheel package is not available.; ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-ggmq8ipk; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/; Complete output (8 lines):; no pandoc found, building platform unspecific wheel.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:551,Deployability,install,install-,551,"I use a Mac and try to install hail.; I use Mojave; I installed pyenv to modify my python versions.; I installed Python 3.7.9 since you recommend to use Python 3.7 as the latest version.; I then did a pip install hail, and it fails with pyspark:. Collecting pyspark<2.4.2,>=2.4; Using cached pyspark-2.4.1.tar.gz (215.7 MB); ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-pip-egg-info-vlaj8k6d; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/; Complete output (47 lines):; Could not import pypandoc - required to package PySpark; WARNING: The wheel package is not available.; ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-ggmq8ipk; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/; Complete output (8 lines):; no pandoc found, building platform unspecific wheel.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:666,Deployability,install,install-,666,"I use a Mac and try to install hail.; I use Mojave; I installed pyenv to modify my python versions.; I installed Python 3.7.9 since you recommend to use Python 3.7 as the latest version.; I then did a pip install hail, and it fails with pyspark:. Collecting pyspark<2.4.2,>=2.4; Using cached pyspark-2.4.1.tar.gz (215.7 MB); ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-pip-egg-info-vlaj8k6d; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/; Complete output (47 lines):; Could not import pypandoc - required to package PySpark; WARNING: The wheel package is not available.; ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-ggmq8ipk; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/; Complete output (8 lines):; no pandoc found, building platform unspecific wheel.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:1036,Deployability,install,install-,1036,"use a Mac and try to install hail.; I use Mojave; I installed pyenv to modify my python versions.; I installed Python 3.7.9 since you recommend to use Python 3.7 as the latest version.; I then did a pip install hail, and it fails with pyspark:. Collecting pyspark<2.4.2,>=2.4; Using cached pyspark-2.4.1.tar.gz (215.7 MB); ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-pip-egg-info-vlaj8k6d; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/; Complete output (47 lines):; Could not import pypandoc - required to package PySpark; WARNING: The wheel package is not available.; ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-ggmq8ipk; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/; Complete output (8 lines):; no pandoc found, building platform unspecific wheel..",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:2513,Deployability,install,installer,2513,"ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-ggmq8ipk; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/; Complete output (8 lines):; no pandoc found, building platform unspecific wheel...; use 'python setup.py download_pandoc' to download pandoc.; usage: setup.py [global_opts] cmd1 [cmd1_opts] [cmd2 [cmd2_opts] ...]; or: setup.py --help [cmd1 cmd2 ...]; or: setup.py --help-commands; or: setup.py cmd --help; ; error: invalid command 'bdist_wheel'; ----------------------------------------; ERROR: Failed building wheel for pypandoc; ERROR: Failed to build one or more wheels; Traceback (most recent call last):; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/installer.py"", line 128, in fetch_build_egg; subprocess.check_call(cmd); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/subprocess.py"", line 363, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['/Users/spascal/.pyenv/versions/3.7.9/bin/python3.7', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/tmpspi2awj3', '--quiet', 'pypandoc']' returned non-zero exit status 1.; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py"", line 224, in <module>; 'Programming Language :: Python :: Implementation :: PyPy']; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/__init__.py"", line 143, in setup; _install_setup_requires(attrs); File ""/Use",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:3227,Deployability,install,install-,3227," or: setup.py --help [cmd1 cmd2 ...]; or: setup.py --help-commands; or: setup.py cmd --help; ; error: invalid command 'bdist_wheel'; ----------------------------------------; ERROR: Failed building wheel for pypandoc; ERROR: Failed to build one or more wheels; Traceback (most recent call last):; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/installer.py"", line 128, in fetch_build_egg; subprocess.check_call(cmd); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/subprocess.py"", line 363, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError: Command '['/Users/spascal/.pyenv/versions/3.7.9/bin/python3.7', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/tmpspi2awj3', '--quiet', 'pypandoc']' returned non-zero exit status 1.; ; During handling of the above exception, another exception occurred:; ; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py"", line 224, in <module>; 'Programming Language :: Python :: Implementation :: PyPy']; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/__init__.py"", line 143, in setup; _install_setup_requires(attrs); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/__init__.py"", line 138, in _install_setup_requires; dist.fetch_build_eggs(dist.setup_requires); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/dist.py"", line 698, in fetch_build_eggs; replace_conflicting=True,; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 783, in resolve; replace_conflicting=replace_conflicting; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 1066, in best_match; return self.obtain(req, i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:4134,Deployability,install,installer,4134,"nother exception occurred:; ; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py"", line 224, in <module>; 'Programming Language :: Python :: Implementation :: PyPy']; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/__init__.py"", line 143, in setup; _install_setup_requires(attrs); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/__init__.py"", line 138, in _install_setup_requires; dist.fetch_build_eggs(dist.setup_requires); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/dist.py"", line 698, in fetch_build_eggs; replace_conflicting=True,; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 783, in resolve; replace_conflicting=replace_conflicting; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 1066, in best_match; return self.obtain(req, installer); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 1078, in obtain; return installer(requirement); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/dist.py"", line 754, in fetch_build_egg; return fetch_build_egg(self, req); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/installer.py"", line 130, in fetch_build_egg; raise DistutilsError(str(e)); distutils.errors.DistutilsError: Command '['/Users/spascal/.pyenv/versions/3.7.9/bin/python3.7', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/tmpspi2awj3', '--quiet', 'pypandoc']' returned non-zero exit status 1.; ----------------------------------------; ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:4274,Deployability,install,installer,4274,"nother exception occurred:; ; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py"", line 224, in <module>; 'Programming Language :: Python :: Implementation :: PyPy']; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/__init__.py"", line 143, in setup; _install_setup_requires(attrs); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/__init__.py"", line 138, in _install_setup_requires; dist.fetch_build_eggs(dist.setup_requires); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/dist.py"", line 698, in fetch_build_eggs; replace_conflicting=True,; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 783, in resolve; replace_conflicting=replace_conflicting; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 1066, in best_match; return self.obtain(req, installer); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 1078, in obtain; return installer(requirement); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/dist.py"", line 754, in fetch_build_egg; return fetch_build_egg(self, req); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/installer.py"", line 130, in fetch_build_egg; raise DistutilsError(str(e)); distutils.errors.DistutilsError: Command '['/Users/spascal/.pyenv/versions/3.7.9/bin/python3.7', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/tmpspi2awj3', '--quiet', 'pypandoc']' returned non-zero exit status 1.; ----------------------------------------; ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:4537,Deployability,install,installer,4537,"nother exception occurred:; ; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py"", line 224, in <module>; 'Programming Language :: Python :: Implementation :: PyPy']; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/__init__.py"", line 143, in setup; _install_setup_requires(attrs); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/__init__.py"", line 138, in _install_setup_requires; dist.fetch_build_eggs(dist.setup_requires); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/dist.py"", line 698, in fetch_build_eggs; replace_conflicting=True,; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 783, in resolve; replace_conflicting=replace_conflicting; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 1066, in best_match; return self.obtain(req, installer); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 1078, in obtain; return installer(requirement); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/dist.py"", line 754, in fetch_build_egg; return fetch_build_egg(self, req); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/installer.py"", line 130, in fetch_build_egg; raise DistutilsError(str(e)); distutils.errors.DistutilsError: Command '['/Users/spascal/.pyenv/versions/3.7.9/bin/python3.7', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/tmpspi2awj3', '--quiet', 'pypandoc']' returned non-zero exit status 1.; ----------------------------------------; ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:285,Performance,cache,cached,285,"I use a Mac and try to install hail.; I use Mojave; I installed pyenv to modify my python versions.; I installed Python 3.7.9 since you recommend to use Python 3.7 as the latest version.; I then did a pip install hail, and it fails with pyspark:. Collecting pyspark<2.4.2,>=2.4; Using cached pyspark-2.4.1.tar.gz (215.7 MB); ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-pip-egg-info-vlaj8k6d; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/; Complete output (47 lines):; Could not import pypandoc - required to package PySpark; WARNING: The wheel package is not available.; ERROR: Command errored out with exit status 1:; command: /Users/spascal/.pyenv/versions/3.7.9/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""'; __file__='""'""'/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-ggmq8ipk; cwd: /private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-wheel-hsj5k2xb/pypandoc/; Complete output (8 lines):; no pandoc found, building platform unspecific wheel.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/issues/9742:5027,Testability,log,logs,5027,"nother exception occurred:; ; Traceback (most recent call last):; File ""<string>"", line 1, in <module>; File ""/private/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/pip-install-0g3aqft5/pyspark/setup.py"", line 224, in <module>; 'Programming Language :: Python :: Implementation :: PyPy']; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/__init__.py"", line 143, in setup; _install_setup_requires(attrs); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/__init__.py"", line 138, in _install_setup_requires; dist.fetch_build_eggs(dist.setup_requires); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/dist.py"", line 698, in fetch_build_eggs; replace_conflicting=True,; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 783, in resolve; replace_conflicting=replace_conflicting; File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 1066, in best_match; return self.obtain(req, installer); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/pkg_resources/__init__.py"", line 1078, in obtain; return installer(requirement); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/dist.py"", line 754, in fetch_build_egg; return fetch_build_egg(self, req); File ""/Users/spascal/.pyenv/versions/3.7.9/lib/python3.7/site-packages/setuptools/installer.py"", line 130, in fetch_build_egg; raise DistutilsError(str(e)); distutils.errors.DistutilsError: Command '['/Users/spascal/.pyenv/versions/3.7.9/bin/python3.7', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', '/var/folders/br/f16ml9tx5z32fhsdd1nqpymm0000gn/T/tmpspi2awj3', '--quiet', 'pypandoc']' returned non-zero exit status 1.; ----------------------------------------; ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9742
https://github.com/hail-is/hail/pull/9743:2,Usability,simpl,simplified,2,"I simplified the TLS context methods into three cases: internal server, external; client session, internal client. I added a blocking shim around aiohttp so that all our HTTP goes through; aiohttp. I added automatic retrying directly into the httpx library.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9743
https://github.com/hail-is/hail/pull/9744:208,Deployability,deploy,deploy-config,208,"At this point, every job that needs the private network specifies; it (https://github.com/hail-is/hail/pull/9380). This change moves jobs with; unspecified `network` to the private network. I removed the gce-deploy-config because jobs should not, by default, assume they; are on the private network. The GCE Deploy Config instructs you to enter GKE; using the internal-gateway, which is on our private network.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9744
https://github.com/hail-is/hail/pull/9744:308,Deployability,Deploy,Deploy,308,"At this point, every job that needs the private network specifies; it (https://github.com/hail-is/hail/pull/9380). This change moves jobs with; unspecified `network` to the private network. I removed the gce-deploy-config because jobs should not, by default, assume they; are on the private network. The GCE Deploy Config instructs you to enter GKE; using the internal-gateway, which is on our private network.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9744
https://github.com/hail-is/hail/pull/9744:215,Modifiability,config,config,215,"At this point, every job that needs the private network specifies; it (https://github.com/hail-is/hail/pull/9380). This change moves jobs with; unspecified `network` to the private network. I removed the gce-deploy-config because jobs should not, by default, assume they; are on the private network. The GCE Deploy Config instructs you to enter GKE; using the internal-gateway, which is on our private network.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9744
https://github.com/hail-is/hail/pull/9744:315,Modifiability,Config,Config,315,"At this point, every job that needs the private network specifies; it (https://github.com/hail-is/hail/pull/9380). This change moves jobs with; unspecified `network` to the private network. I removed the gce-deploy-config because jobs should not, by default, assume they; are on the private network. The GCE Deploy Config instructs you to enter GKE; using the internal-gateway, which is on our private network.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9744
https://github.com/hail-is/hail/pull/9745:208,Deployability,deploy,deploy-config,208,"At this point, every job that needs the private network specifies; it (https://github.com/hail-is/hail/pull/9380). This change moves jobs with; unspecified `network` to the private network. I removed the gce-deploy-config because jobs should not, by default, assume they; are on the private network. The GCE Deploy Config instructs you to enter GKE; using the internal-gateway, which is on our private network.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9745
https://github.com/hail-is/hail/pull/9745:308,Deployability,Deploy,Deploy,308,"At this point, every job that needs the private network specifies; it (https://github.com/hail-is/hail/pull/9380). This change moves jobs with; unspecified `network` to the private network. I removed the gce-deploy-config because jobs should not, by default, assume they; are on the private network. The GCE Deploy Config instructs you to enter GKE; using the internal-gateway, which is on our private network.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9745
https://github.com/hail-is/hail/pull/9745:215,Modifiability,config,config,215,"At this point, every job that needs the private network specifies; it (https://github.com/hail-is/hail/pull/9380). This change moves jobs with; unspecified `network` to the private network. I removed the gce-deploy-config because jobs should not, by default, assume they; are on the private network. The GCE Deploy Config instructs you to enter GKE; using the internal-gateway, which is on our private network.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9745
https://github.com/hail-is/hail/pull/9745:315,Modifiability,Config,Config,315,"At this point, every job that needs the private network specifies; it (https://github.com/hail-is/hail/pull/9380). This change moves jobs with; unspecified `network` to the private network. I removed the gce-deploy-config because jobs should not, by default, assume they; are on the private network. The GCE Deploy Config instructs you to enter GKE; using the internal-gateway, which is on our private network.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9745
https://github.com/hail-is/hail/pull/9749:49,Availability,error,error,49,"CaseBuilder has an `or_error` method to throw an error if no `when` conditions are true. Currently, SwitchBuilder does not have an equivalent method: it only supports returning a default value or missing. The option to throw an error on an unhandled value can be useful for making sure that all possible values for an enum expression have been accounted for in switch cases.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9749
https://github.com/hail-is/hail/pull/9749:228,Availability,error,error,228,"CaseBuilder has an `or_error` method to throw an error if no `when` conditions are true. Currently, SwitchBuilder does not have an equivalent method: it only supports returning a default value or missing. The option to throw an error on an unhandled value can be useful for making sure that all possible values for an enum expression have been accounted for in switch cases.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9749
https://github.com/hail-is/hail/issues/9750:1676,Integrability,wrap,wrapper,1676,": Hail does not support heterogeneous arrays: found list with elements of types [dtype('struct{}')]. The above exception was the direct cause of the following exception:; Traceback (most recent call last):; File ""/Users/dking/miniconda3/lib/python3.7/site-packages/hail/typecheck/check.py"", line 541, in check_all; args_.append(checker.check(arg, name, arg_name)); File ""/Users/dking/miniconda3/lib/python3.7/site-packages/hail/expr/expressions/expression_typecheck.py"", line 79, in check; raise TypecheckFailure from e; TypecheckFailure. The above exception was the direct cause of the following exception:; Traceback (most recent call last):; File ""<ipython-input-12-6b36d92c4f6e>"", line 1, in <module>; hl.array([hl.struct()]); File ""</Users/dking/miniconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-970>"", line 2, in array; File ""/Users/dking/miniconda3/lib/python3.7/site-packages/hail/typecheck/check.py"", line 613, in wrapper; args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); File ""/Users/dking/miniconda3/lib/python3.7/site-packages/hail/typecheck/check.py"", line 567, in check_all; )) from e; TypeError: array: parameter 'collection': expected expression of type set<any> or array<any> or dict<('any', 'any')>, found list: [<StructExpression of type struct{}>]; ```; possible root cause:; ```; In [14]: hl.literal([hl.struct()]); Traceback (most recent call last):; File ""<ipython-input-14-8dfd7d4c634b>"", line 1, in <module>; hl.literal([hl.struct()]); File ""</Users/dking/miniconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-744>"", line 2, in literal; File ""/Users/dking/miniconda3/lib/python3.7/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/dking/miniconda3/lib/python3.7/site-packages/hail/expr/functions.py"", line 203, in literal; dtype = impute_type(x); File ""/Users/dking/miniconda3/lib/python3.7/site-packages/hail/expr/expressions/base_express",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9750
https://github.com/hail-is/hail/issues/9750:2465,Integrability,wrap,wrapper,2465,"s/dking/miniconda3/lib/python3.7/site-packages/hail/typecheck/check.py"", line 541, in check_all; args_.append(checker.check(arg, name, arg_name)); File ""/Users/dking/miniconda3/lib/python3.7/site-packages/hail/expr/expressions/expression_typecheck.py"", line 79, in check; raise TypecheckFailure from e; TypecheckFailure. The above exception was the direct cause of the following exception:; Traceback (most recent call last):; File ""<ipython-input-12-6b36d92c4f6e>"", line 1, in <module>; hl.array([hl.struct()]); File ""</Users/dking/miniconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-970>"", line 2, in array; File ""/Users/dking/miniconda3/lib/python3.7/site-packages/hail/typecheck/check.py"", line 613, in wrapper; args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); File ""/Users/dking/miniconda3/lib/python3.7/site-packages/hail/typecheck/check.py"", line 567, in check_all; )) from e; TypeError: array: parameter 'collection': expected expression of type set<any> or array<any> or dict<('any', 'any')>, found list: [<StructExpression of type struct{}>]; ```; possible root cause:; ```; In [14]: hl.literal([hl.struct()]); Traceback (most recent call last):; File ""<ipython-input-14-8dfd7d4c634b>"", line 1, in <module>; hl.literal([hl.struct()]); File ""</Users/dking/miniconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-744>"", line 2, in literal; File ""/Users/dking/miniconda3/lib/python3.7/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/dking/miniconda3/lib/python3.7/site-packages/hail/expr/functions.py"", line 203, in literal; dtype = impute_type(x); File ""/Users/dking/miniconda3/lib/python3.7/site-packages/hail/expr/expressions/base_expression.py"", line 163, in impute_type; ""found list with elements of types {} "".format(list(ts))); ExpressionException: Hail does not support heterogeneous arrays: found list with elements of types [dtype('struct{}')]; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9750
https://github.com/hail-is/hail/pull/9752:90,Integrability,message,message,90,"Add a note that commits with user facing changes should include ""CHANGELOG"" in the commit message (see https://github.com/hail-is/hail/pull/9749#pullrequestreview-541110277). Also adds a link to the development forum as in the readme (https://github.com/hail-is/hail#contribute).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9752
https://github.com/hail-is/hail/pull/9758:132,Usability,simpl,simple,132,"1. Add `dictfix`, a little tool for wrangling json-like data into a sensible,; standardized format. 2. Modify job.html to include a simple table of important parts of the job; specification such as the command and the requests of cpu, memory, and; storage. 3. Modify job.html to include a simple table summarizing the status and runtime; of each step of the job. My apologies for reformatting the whole file to have no excess spaces. Use the no whitespace diff option in GitHub for a better diff.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9758
https://github.com/hail-is/hail/pull/9758:289,Usability,simpl,simple,289,"1. Add `dictfix`, a little tool for wrangling json-like data into a sensible,; standardized format. 2. Modify job.html to include a simple table of important parts of the job; specification such as the command and the requests of cpu, memory, and; storage. 3. Modify job.html to include a simple table summarizing the status and runtime; of each step of the job. My apologies for reformatting the whole file to have no excess spaces. Use the no whitespace diff option in GitHub for a better diff.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9758
https://github.com/hail-is/hail/pull/9759:526,Deployability,deploy,deployment,526,"I got fed up with ksync not working the way I wanted and wrote my own; version. Assuming `repo/devbin` is on your path, then:. ```; sync.sh batch dking; ```. will keep the web_common, gear, hailtop, and batch repositories all up to date; in k8s. It just copies all the files over from your local machine, so its not; the fastest thing in the world. It takes maybe 2 seconds to get back to a; working container. It also assumes there's one container per-pod. It is completely disabled in the default namespace (I remove it in; deployment.yaml if we are in deploy mode).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9759
https://github.com/hail-is/hail/pull/9759:555,Deployability,deploy,deploy,555,"I got fed up with ksync not working the way I wanted and wrote my own; version. Assuming `repo/devbin` is on your path, then:. ```; sync.sh batch dking; ```. will keep the web_common, gear, hailtop, and batch repositories all up to date; in k8s. It just copies all the files over from your local machine, so its not; the fastest thing in the world. It takes maybe 2 seconds to get back to a; working container. It also assumes there's one container per-pod. It is completely disabled in the default namespace (I remove it in; deployment.yaml if we are in deploy mode).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9759
https://github.com/hail-is/hail/pull/9761:68,Deployability,update,update,68,"Set the home directory, otherwise docker-credential-gcr fails. Also update to a non-deprecated Ubuntu image version.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9761
https://github.com/hail-is/hail/pull/9765:9,Testability,test,test,9,I didn't test the getting the logs code.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9765
https://github.com/hail-is/hail/pull/9765:30,Testability,log,logs,30,I didn't test the getting the logs code.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9765
https://github.com/hail-is/hail/issues/9767:212,Deployability,install,installation,212,Relevant line from build.gradle:. ```; bundled 'org.elasticsearch:elasticsearch-spark-20_2.11:' + elasticHadoopVersion(); ```. The `spark-20` and Scala `2.11` are hardcoded. These need to vary based on requested installation version.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9767
https://github.com/hail-is/hail/pull/9768:280,Testability,Benchmark,Benchmark,280,"There were two bugs when checking if an ndarray is column major, causing it to always return false. This method is used to decide whether we need to copy the ndarray into a column major form. By fixing this bug, we now don't have to copy both arrays before every matrix multiply. Benchmark: linear_regression_rows_nd. Before fix timings:. [50.794169104999995, 51.562208821, 60.402329871999996]. After fix timings: . [38.504665161, 39.919831891, 37.882298633999994]",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9768
https://github.com/hail-is/hail/pull/9769:79,Testability,test,tested,79,"This PR is the first towards the goal of supporting arbitrary machine types. I tested both code paths where we create zones from a static list versus if there's over 4000 cores, creating it with east and west regions as well. I thought about putting the regions and init_zones in the database, but figured that could be a follow up PR. I wasn't sure what the best way to do that was.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9769
https://github.com/hail-is/hail/pull/9771:160,Availability,error,error,160,"From the logs:; ```; WARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9771
https://github.com/hail-is/hail/pull/9771:112,Integrability,depend,dependency,112,"From the logs:; ```; WARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9771
https://github.com/hail-is/hail/pull/9771:9,Testability,log,logs,9,"From the logs:; ```; WARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9771
https://github.com/hail-is/hail/pull/9772:242,Energy Efficiency,monitor,monitor,242,"Stacked on #9769 . I tried to make the code changes as small as possible and this is just a refactoring. I split the current instance_pool into the instance_monitor and the instance_pool. The main difference is the instance pool and instance monitor are recording two exact copies of the instances by state and live total cores etc which are linked via `adjust_for_*_instance`. Eventually with multiple pools, these numbers won't be identical and one will be for all instances and the other will be pool specific.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9772
https://github.com/hail-is/hail/pull/9772:92,Modifiability,refactor,refactoring,92,"Stacked on #9769 . I tried to make the code changes as small as possible and this is just a refactoring. I split the current instance_pool into the instance_monitor and the instance_pool. The main difference is the instance pool and instance monitor are recording two exact copies of the instances by state and live total cores etc which are linked via `adjust_for_*_instance`. Eventually with multiple pools, these numbers won't be identical and one will be for all instances and the other will be pool specific.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9772
https://github.com/hail-is/hail/pull/9774:44,Energy Efficiency,schedul,scheduler,44,"Stacked on #9772 . This code accounts for a scheduler per instance pool even though right now there is only one instance pool. In the future when we add job private instance scheduling, then we'll need to rethink how this code is structured. For now, it should be fine.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9774
https://github.com/hail-is/hail/pull/9774:174,Energy Efficiency,schedul,scheduling,174,"Stacked on #9772 . This code accounts for a scheduler per instance pool even though right now there is only one instance pool. In the future when we add job private instance scheduling, then we'll need to rethink how this code is structured. For now, it should be fine.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9774
https://github.com/hail-is/hail/pull/9777:54,Deployability,configurat,configuration,54,"Motivation for this change: I want to keep the global configuration information in one place, and that's going to be the K8s default/global-config secret. In particular, I want to get rid of config.mk and just pull the relevant information from K8s. The secret currently like this:. ```; $ k get -o json secret global-config | jq '.data | map_values(@base64d)'; {; ""default_namespace"": ""..."",; ""docker_root_image"": ""..."",; ""domain"": ""..."",; ""gcp_project"": ""..."",; ""gcp_region"": ""..."",; ""gcp_zone"": ""..."",; ""gsuite_organization"": ""..."",; ""internal_ip"": ""..."",; ""ip"": ""..."",; ""kubernetes_server_url"": ""...""; }; ```. default_namespace will always be the name of the namespace the secret is in. This adds gsuite_organization which will be used by auth to restrict logins to a fixed GSuite organization, e.g. broadinstitute.org. I have created this secret on our production K8s cluster. The Terraform script will also create it. With this change, CI creates global-config in test and dev ""default"" namespaces based on the one from where CI is operating. The only field that currently needs to be updated is default_namespace. The plan is to pull from global-config in deployments instead of threading these global configuration(s) through CI. I made this change in the CI tests. FYI @lgruen. I'm going to break up the infra-1 work into a few separate PRs to keep it all clear and manageable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9777
https://github.com/hail-is/hail/pull/9777:1091,Deployability,update,updated,1091,"Motivation for this change: I want to keep the global configuration information in one place, and that's going to be the K8s default/global-config secret. In particular, I want to get rid of config.mk and just pull the relevant information from K8s. The secret currently like this:. ```; $ k get -o json secret global-config | jq '.data | map_values(@base64d)'; {; ""default_namespace"": ""..."",; ""docker_root_image"": ""..."",; ""domain"": ""..."",; ""gcp_project"": ""..."",; ""gcp_region"": ""..."",; ""gcp_zone"": ""..."",; ""gsuite_organization"": ""..."",; ""internal_ip"": ""..."",; ""ip"": ""..."",; ""kubernetes_server_url"": ""...""; }; ```. default_namespace will always be the name of the namespace the secret is in. This adds gsuite_organization which will be used by auth to restrict logins to a fixed GSuite organization, e.g. broadinstitute.org. I have created this secret on our production K8s cluster. The Terraform script will also create it. With this change, CI creates global-config in test and dev ""default"" namespaces based on the one from where CI is operating. The only field that currently needs to be updated is default_namespace. The plan is to pull from global-config in deployments instead of threading these global configuration(s) through CI. I made this change in the CI tests. FYI @lgruen. I'm going to break up the infra-1 work into a few separate PRs to keep it all clear and manageable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9777
https://github.com/hail-is/hail/pull/9777:1163,Deployability,deploy,deployments,1163,"Motivation for this change: I want to keep the global configuration information in one place, and that's going to be the K8s default/global-config secret. In particular, I want to get rid of config.mk and just pull the relevant information from K8s. The secret currently like this:. ```; $ k get -o json secret global-config | jq '.data | map_values(@base64d)'; {; ""default_namespace"": ""..."",; ""docker_root_image"": ""..."",; ""domain"": ""..."",; ""gcp_project"": ""..."",; ""gcp_region"": ""..."",; ""gcp_zone"": ""..."",; ""gsuite_organization"": ""..."",; ""internal_ip"": ""..."",; ""ip"": ""..."",; ""kubernetes_server_url"": ""...""; }; ```. default_namespace will always be the name of the namespace the secret is in. This adds gsuite_organization which will be used by auth to restrict logins to a fixed GSuite organization, e.g. broadinstitute.org. I have created this secret on our production K8s cluster. The Terraform script will also create it. With this change, CI creates global-config in test and dev ""default"" namespaces based on the one from where CI is operating. The only field that currently needs to be updated is default_namespace. The plan is to pull from global-config in deployments instead of threading these global configuration(s) through CI. I made this change in the CI tests. FYI @lgruen. I'm going to break up the infra-1 work into a few separate PRs to keep it all clear and manageable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9777
https://github.com/hail-is/hail/pull/9777:1209,Deployability,configurat,configuration,1209,"Motivation for this change: I want to keep the global configuration information in one place, and that's going to be the K8s default/global-config secret. In particular, I want to get rid of config.mk and just pull the relevant information from K8s. The secret currently like this:. ```; $ k get -o json secret global-config | jq '.data | map_values(@base64d)'; {; ""default_namespace"": ""..."",; ""docker_root_image"": ""..."",; ""domain"": ""..."",; ""gcp_project"": ""..."",; ""gcp_region"": ""..."",; ""gcp_zone"": ""..."",; ""gsuite_organization"": ""..."",; ""internal_ip"": ""..."",; ""ip"": ""..."",; ""kubernetes_server_url"": ""...""; }; ```. default_namespace will always be the name of the namespace the secret is in. This adds gsuite_organization which will be used by auth to restrict logins to a fixed GSuite organization, e.g. broadinstitute.org. I have created this secret on our production K8s cluster. The Terraform script will also create it. With this change, CI creates global-config in test and dev ""default"" namespaces based on the one from where CI is operating. The only field that currently needs to be updated is default_namespace. The plan is to pull from global-config in deployments instead of threading these global configuration(s) through CI. I made this change in the CI tests. FYI @lgruen. I'm going to break up the infra-1 work into a few separate PRs to keep it all clear and manageable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9777
https://github.com/hail-is/hail/pull/9777:54,Modifiability,config,configuration,54,"Motivation for this change: I want to keep the global configuration information in one place, and that's going to be the K8s default/global-config secret. In particular, I want to get rid of config.mk and just pull the relevant information from K8s. The secret currently like this:. ```; $ k get -o json secret global-config | jq '.data | map_values(@base64d)'; {; ""default_namespace"": ""..."",; ""docker_root_image"": ""..."",; ""domain"": ""..."",; ""gcp_project"": ""..."",; ""gcp_region"": ""..."",; ""gcp_zone"": ""..."",; ""gsuite_organization"": ""..."",; ""internal_ip"": ""..."",; ""ip"": ""..."",; ""kubernetes_server_url"": ""...""; }; ```. default_namespace will always be the name of the namespace the secret is in. This adds gsuite_organization which will be used by auth to restrict logins to a fixed GSuite organization, e.g. broadinstitute.org. I have created this secret on our production K8s cluster. The Terraform script will also create it. With this change, CI creates global-config in test and dev ""default"" namespaces based on the one from where CI is operating. The only field that currently needs to be updated is default_namespace. The plan is to pull from global-config in deployments instead of threading these global configuration(s) through CI. I made this change in the CI tests. FYI @lgruen. I'm going to break up the infra-1 work into a few separate PRs to keep it all clear and manageable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9777
https://github.com/hail-is/hail/pull/9777:140,Modifiability,config,config,140,"Motivation for this change: I want to keep the global configuration information in one place, and that's going to be the K8s default/global-config secret. In particular, I want to get rid of config.mk and just pull the relevant information from K8s. The secret currently like this:. ```; $ k get -o json secret global-config | jq '.data | map_values(@base64d)'; {; ""default_namespace"": ""..."",; ""docker_root_image"": ""..."",; ""domain"": ""..."",; ""gcp_project"": ""..."",; ""gcp_region"": ""..."",; ""gcp_zone"": ""..."",; ""gsuite_organization"": ""..."",; ""internal_ip"": ""..."",; ""ip"": ""..."",; ""kubernetes_server_url"": ""...""; }; ```. default_namespace will always be the name of the namespace the secret is in. This adds gsuite_organization which will be used by auth to restrict logins to a fixed GSuite organization, e.g. broadinstitute.org. I have created this secret on our production K8s cluster. The Terraform script will also create it. With this change, CI creates global-config in test and dev ""default"" namespaces based on the one from where CI is operating. The only field that currently needs to be updated is default_namespace. The plan is to pull from global-config in deployments instead of threading these global configuration(s) through CI. I made this change in the CI tests. FYI @lgruen. I'm going to break up the infra-1 work into a few separate PRs to keep it all clear and manageable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9777
https://github.com/hail-is/hail/pull/9777:191,Modifiability,config,config,191,"Motivation for this change: I want to keep the global configuration information in one place, and that's going to be the K8s default/global-config secret. In particular, I want to get rid of config.mk and just pull the relevant information from K8s. The secret currently like this:. ```; $ k get -o json secret global-config | jq '.data | map_values(@base64d)'; {; ""default_namespace"": ""..."",; ""docker_root_image"": ""..."",; ""domain"": ""..."",; ""gcp_project"": ""..."",; ""gcp_region"": ""..."",; ""gcp_zone"": ""..."",; ""gsuite_organization"": ""..."",; ""internal_ip"": ""..."",; ""ip"": ""..."",; ""kubernetes_server_url"": ""...""; }; ```. default_namespace will always be the name of the namespace the secret is in. This adds gsuite_organization which will be used by auth to restrict logins to a fixed GSuite organization, e.g. broadinstitute.org. I have created this secret on our production K8s cluster. The Terraform script will also create it. With this change, CI creates global-config in test and dev ""default"" namespaces based on the one from where CI is operating. The only field that currently needs to be updated is default_namespace. The plan is to pull from global-config in deployments instead of threading these global configuration(s) through CI. I made this change in the CI tests. FYI @lgruen. I'm going to break up the infra-1 work into a few separate PRs to keep it all clear and manageable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9777
https://github.com/hail-is/hail/pull/9777:318,Modifiability,config,config,318,"Motivation for this change: I want to keep the global configuration information in one place, and that's going to be the K8s default/global-config secret. In particular, I want to get rid of config.mk and just pull the relevant information from K8s. The secret currently like this:. ```; $ k get -o json secret global-config | jq '.data | map_values(@base64d)'; {; ""default_namespace"": ""..."",; ""docker_root_image"": ""..."",; ""domain"": ""..."",; ""gcp_project"": ""..."",; ""gcp_region"": ""..."",; ""gcp_zone"": ""..."",; ""gsuite_organization"": ""..."",; ""internal_ip"": ""..."",; ""ip"": ""..."",; ""kubernetes_server_url"": ""...""; }; ```. default_namespace will always be the name of the namespace the secret is in. This adds gsuite_organization which will be used by auth to restrict logins to a fixed GSuite organization, e.g. broadinstitute.org. I have created this secret on our production K8s cluster. The Terraform script will also create it. With this change, CI creates global-config in test and dev ""default"" namespaces based on the one from where CI is operating. The only field that currently needs to be updated is default_namespace. The plan is to pull from global-config in deployments instead of threading these global configuration(s) through CI. I made this change in the CI tests. FYI @lgruen. I'm going to break up the infra-1 work into a few separate PRs to keep it all clear and manageable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9777
https://github.com/hail-is/hail/pull/9777:960,Modifiability,config,config,960,"Motivation for this change: I want to keep the global configuration information in one place, and that's going to be the K8s default/global-config secret. In particular, I want to get rid of config.mk and just pull the relevant information from K8s. The secret currently like this:. ```; $ k get -o json secret global-config | jq '.data | map_values(@base64d)'; {; ""default_namespace"": ""..."",; ""docker_root_image"": ""..."",; ""domain"": ""..."",; ""gcp_project"": ""..."",; ""gcp_region"": ""..."",; ""gcp_zone"": ""..."",; ""gsuite_organization"": ""..."",; ""internal_ip"": ""..."",; ""ip"": ""..."",; ""kubernetes_server_url"": ""...""; }; ```. default_namespace will always be the name of the namespace the secret is in. This adds gsuite_organization which will be used by auth to restrict logins to a fixed GSuite organization, e.g. broadinstitute.org. I have created this secret on our production K8s cluster. The Terraform script will also create it. With this change, CI creates global-config in test and dev ""default"" namespaces based on the one from where CI is operating. The only field that currently needs to be updated is default_namespace. The plan is to pull from global-config in deployments instead of threading these global configuration(s) through CI. I made this change in the CI tests. FYI @lgruen. I'm going to break up the infra-1 work into a few separate PRs to keep it all clear and manageable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9777
https://github.com/hail-is/hail/pull/9777:1153,Modifiability,config,config,1153,"Motivation for this change: I want to keep the global configuration information in one place, and that's going to be the K8s default/global-config secret. In particular, I want to get rid of config.mk and just pull the relevant information from K8s. The secret currently like this:. ```; $ k get -o json secret global-config | jq '.data | map_values(@base64d)'; {; ""default_namespace"": ""..."",; ""docker_root_image"": ""..."",; ""domain"": ""..."",; ""gcp_project"": ""..."",; ""gcp_region"": ""..."",; ""gcp_zone"": ""..."",; ""gsuite_organization"": ""..."",; ""internal_ip"": ""..."",; ""ip"": ""..."",; ""kubernetes_server_url"": ""...""; }; ```. default_namespace will always be the name of the namespace the secret is in. This adds gsuite_organization which will be used by auth to restrict logins to a fixed GSuite organization, e.g. broadinstitute.org. I have created this secret on our production K8s cluster. The Terraform script will also create it. With this change, CI creates global-config in test and dev ""default"" namespaces based on the one from where CI is operating. The only field that currently needs to be updated is default_namespace. The plan is to pull from global-config in deployments instead of threading these global configuration(s) through CI. I made this change in the CI tests. FYI @lgruen. I'm going to break up the infra-1 work into a few separate PRs to keep it all clear and manageable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9777
https://github.com/hail-is/hail/pull/9777:1209,Modifiability,config,configuration,1209,"Motivation for this change: I want to keep the global configuration information in one place, and that's going to be the K8s default/global-config secret. In particular, I want to get rid of config.mk and just pull the relevant information from K8s. The secret currently like this:. ```; $ k get -o json secret global-config | jq '.data | map_values(@base64d)'; {; ""default_namespace"": ""..."",; ""docker_root_image"": ""..."",; ""domain"": ""..."",; ""gcp_project"": ""..."",; ""gcp_region"": ""..."",; ""gcp_zone"": ""..."",; ""gsuite_organization"": ""..."",; ""internal_ip"": ""..."",; ""ip"": ""..."",; ""kubernetes_server_url"": ""...""; }; ```. default_namespace will always be the name of the namespace the secret is in. This adds gsuite_organization which will be used by auth to restrict logins to a fixed GSuite organization, e.g. broadinstitute.org. I have created this secret on our production K8s cluster. The Terraform script will also create it. With this change, CI creates global-config in test and dev ""default"" namespaces based on the one from where CI is operating. The only field that currently needs to be updated is default_namespace. The plan is to pull from global-config in deployments instead of threading these global configuration(s) through CI. I made this change in the CI tests. FYI @lgruen. I'm going to break up the infra-1 work into a few separate PRs to keep it all clear and manageable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9777
https://github.com/hail-is/hail/pull/9777:760,Testability,log,logins,760,"Motivation for this change: I want to keep the global configuration information in one place, and that's going to be the K8s default/global-config secret. In particular, I want to get rid of config.mk and just pull the relevant information from K8s. The secret currently like this:. ```; $ k get -o json secret global-config | jq '.data | map_values(@base64d)'; {; ""default_namespace"": ""..."",; ""docker_root_image"": ""..."",; ""domain"": ""..."",; ""gcp_project"": ""..."",; ""gcp_region"": ""..."",; ""gcp_zone"": ""..."",; ""gsuite_organization"": ""..."",; ""internal_ip"": ""..."",; ""ip"": ""..."",; ""kubernetes_server_url"": ""...""; }; ```. default_namespace will always be the name of the namespace the secret is in. This adds gsuite_organization which will be used by auth to restrict logins to a fixed GSuite organization, e.g. broadinstitute.org. I have created this secret on our production K8s cluster. The Terraform script will also create it. With this change, CI creates global-config in test and dev ""default"" namespaces based on the one from where CI is operating. The only field that currently needs to be updated is default_namespace. The plan is to pull from global-config in deployments instead of threading these global configuration(s) through CI. I made this change in the CI tests. FYI @lgruen. I'm going to break up the infra-1 work into a few separate PRs to keep it all clear and manageable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9777
https://github.com/hail-is/hail/pull/9777:970,Testability,test,test,970,"Motivation for this change: I want to keep the global configuration information in one place, and that's going to be the K8s default/global-config secret. In particular, I want to get rid of config.mk and just pull the relevant information from K8s. The secret currently like this:. ```; $ k get -o json secret global-config | jq '.data | map_values(@base64d)'; {; ""default_namespace"": ""..."",; ""docker_root_image"": ""..."",; ""domain"": ""..."",; ""gcp_project"": ""..."",; ""gcp_region"": ""..."",; ""gcp_zone"": ""..."",; ""gsuite_organization"": ""..."",; ""internal_ip"": ""..."",; ""ip"": ""..."",; ""kubernetes_server_url"": ""...""; }; ```. default_namespace will always be the name of the namespace the secret is in. This adds gsuite_organization which will be used by auth to restrict logins to a fixed GSuite organization, e.g. broadinstitute.org. I have created this secret on our production K8s cluster. The Terraform script will also create it. With this change, CI creates global-config in test and dev ""default"" namespaces based on the one from where CI is operating. The only field that currently needs to be updated is default_namespace. The plan is to pull from global-config in deployments instead of threading these global configuration(s) through CI. I made this change in the CI tests. FYI @lgruen. I'm going to break up the infra-1 work into a few separate PRs to keep it all clear and manageable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9777
https://github.com/hail-is/hail/pull/9777:1267,Testability,test,tests,1267,"Motivation for this change: I want to keep the global configuration information in one place, and that's going to be the K8s default/global-config secret. In particular, I want to get rid of config.mk and just pull the relevant information from K8s. The secret currently like this:. ```; $ k get -o json secret global-config | jq '.data | map_values(@base64d)'; {; ""default_namespace"": ""..."",; ""docker_root_image"": ""..."",; ""domain"": ""..."",; ""gcp_project"": ""..."",; ""gcp_region"": ""..."",; ""gcp_zone"": ""..."",; ""gsuite_organization"": ""..."",; ""internal_ip"": ""..."",; ""ip"": ""..."",; ""kubernetes_server_url"": ""...""; }; ```. default_namespace will always be the name of the namespace the secret is in. This adds gsuite_organization which will be used by auth to restrict logins to a fixed GSuite organization, e.g. broadinstitute.org. I have created this secret on our production K8s cluster. The Terraform script will also create it. With this change, CI creates global-config in test and dev ""default"" namespaces based on the one from where CI is operating. The only field that currently needs to be updated is default_namespace. The plan is to pull from global-config in deployments instead of threading these global configuration(s) through CI. I made this change in the CI tests. FYI @lgruen. I'm going to break up the infra-1 work into a few separate PRs to keep it all clear and manageable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9777
https://github.com/hail-is/hail/pull/9777:1365,Usability,clear,clear,1365,"Motivation for this change: I want to keep the global configuration information in one place, and that's going to be the K8s default/global-config secret. In particular, I want to get rid of config.mk and just pull the relevant information from K8s. The secret currently like this:. ```; $ k get -o json secret global-config | jq '.data | map_values(@base64d)'; {; ""default_namespace"": ""..."",; ""docker_root_image"": ""..."",; ""domain"": ""..."",; ""gcp_project"": ""..."",; ""gcp_region"": ""..."",; ""gcp_zone"": ""..."",; ""gsuite_organization"": ""..."",; ""internal_ip"": ""..."",; ""ip"": ""..."",; ""kubernetes_server_url"": ""...""; }; ```. default_namespace will always be the name of the namespace the secret is in. This adds gsuite_organization which will be used by auth to restrict logins to a fixed GSuite organization, e.g. broadinstitute.org. I have created this secret on our production K8s cluster. The Terraform script will also create it. With this change, CI creates global-config in test and dev ""default"" namespaces based on the one from where CI is operating. The only field that currently needs to be updated is default_namespace. The plan is to pull from global-config in deployments instead of threading these global configuration(s) through CI. I made this change in the CI tests. FYI @lgruen. I'm going to break up the infra-1 work into a few separate PRs to keep it all clear and manageable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9777
https://github.com/hail-is/hail/pull/9778:20,Testability,log,logs,20,Unused since worker logs go into GCP logging now,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9778
https://github.com/hail-is/hail/pull/9778:37,Testability,log,logging,37,Unused since worker logs go into GCP logging now,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9778
https://github.com/hail-is/hail/pull/9779:186,Modifiability,variab,variables,186,"Stacked on #9774 . This PR leaves the system in a state that has multiple pools in the SQL code, but the instance pool is hard coded as standard and there's only one of them. The global variables of local ssd, standing worker cores, etc. are still in globals and not per pool yet. This is because I need to write the code for the instance pool manager which will be in subsequent PRs so that we can configure each pool individually. The goal of this PR is to make sure the incremental data structures are correct for supporting multiple pools.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9779
https://github.com/hail-is/hail/pull/9779:399,Modifiability,config,configure,399,"Stacked on #9774 . This PR leaves the system in a state that has multiple pools in the SQL code, but the instance pool is hard coded as standard and there's only one of them. The global variables of local ssd, standing worker cores, etc. are still in globals and not per pool yet. This is because I need to write the code for the instance pool manager which will be in subsequent PRs so that we can configure each pool individually. The goal of this PR is to make sure the incremental data structures are correct for supporting multiple pools.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9779
https://github.com/hail-is/hail/pull/9781:46,Availability,failure,failures,46,Both Cotton and I have PRs failing due to pod failures that are impossible to debug without this.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9781
https://github.com/hail-is/hail/issues/9782:326,Testability,test,test,326,"The [VCF 4.2 spec](https://samtools.github.io/hts-specs/VCFv4.2.pdf) says:; > The Description value must be surrounded by double-quotes. Double-quote character can be escaped with backslash \ and backslash as \\\\. `hl.export_vcf` does not escape double quotes in descriptions. For example:; ```; ds = hl.import_vcf(""hail/src/test/resources/sample.vcf""); meta = hl.get_vcf_metadata(""hail/src/test/resources/sample.vcf""); meta[""info""][""AF""][""Description""] = 'foo ""bar""'; hl.export_vcf(ds, ""test.vcf"", metadata=meta); ```. ```; $ grep ID=AF test.vcf; ##INFO=<ID=AF,Number=A,Type=Float,Description=""foo ""bar"""">. $ bcftools view -h test.vcf; [E::bcf_hdr_parse_line] Could not parse the header line: ""##INFO=<ID=AF,Number=A,Type=Float,Description=""foo ""bar"""">""; [W::bcf_hdr_parse] Could not parse header line: ##INFO=<ID=AF,Number=A,Type=Float,Description=""foo ""bar"""">; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9782
https://github.com/hail-is/hail/issues/9782:392,Testability,test,test,392,"The [VCF 4.2 spec](https://samtools.github.io/hts-specs/VCFv4.2.pdf) says:; > The Description value must be surrounded by double-quotes. Double-quote character can be escaped with backslash \ and backslash as \\\\. `hl.export_vcf` does not escape double quotes in descriptions. For example:; ```; ds = hl.import_vcf(""hail/src/test/resources/sample.vcf""); meta = hl.get_vcf_metadata(""hail/src/test/resources/sample.vcf""); meta[""info""][""AF""][""Description""] = 'foo ""bar""'; hl.export_vcf(ds, ""test.vcf"", metadata=meta); ```. ```; $ grep ID=AF test.vcf; ##INFO=<ID=AF,Number=A,Type=Float,Description=""foo ""bar"""">. $ bcftools view -h test.vcf; [E::bcf_hdr_parse_line] Could not parse the header line: ""##INFO=<ID=AF,Number=A,Type=Float,Description=""foo ""bar"""">""; [W::bcf_hdr_parse] Could not parse header line: ##INFO=<ID=AF,Number=A,Type=Float,Description=""foo ""bar"""">; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9782
https://github.com/hail-is/hail/issues/9782:489,Testability,test,test,489,"The [VCF 4.2 spec](https://samtools.github.io/hts-specs/VCFv4.2.pdf) says:; > The Description value must be surrounded by double-quotes. Double-quote character can be escaped with backslash \ and backslash as \\\\. `hl.export_vcf` does not escape double quotes in descriptions. For example:; ```; ds = hl.import_vcf(""hail/src/test/resources/sample.vcf""); meta = hl.get_vcf_metadata(""hail/src/test/resources/sample.vcf""); meta[""info""][""AF""][""Description""] = 'foo ""bar""'; hl.export_vcf(ds, ""test.vcf"", metadata=meta); ```. ```; $ grep ID=AF test.vcf; ##INFO=<ID=AF,Number=A,Type=Float,Description=""foo ""bar"""">. $ bcftools view -h test.vcf; [E::bcf_hdr_parse_line] Could not parse the header line: ""##INFO=<ID=AF,Number=A,Type=Float,Description=""foo ""bar"""">""; [W::bcf_hdr_parse] Could not parse header line: ##INFO=<ID=AF,Number=A,Type=Float,Description=""foo ""bar"""">; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9782
https://github.com/hail-is/hail/issues/9782:539,Testability,test,test,539,"The [VCF 4.2 spec](https://samtools.github.io/hts-specs/VCFv4.2.pdf) says:; > The Description value must be surrounded by double-quotes. Double-quote character can be escaped with backslash \ and backslash as \\\\. `hl.export_vcf` does not escape double quotes in descriptions. For example:; ```; ds = hl.import_vcf(""hail/src/test/resources/sample.vcf""); meta = hl.get_vcf_metadata(""hail/src/test/resources/sample.vcf""); meta[""info""][""AF""][""Description""] = 'foo ""bar""'; hl.export_vcf(ds, ""test.vcf"", metadata=meta); ```. ```; $ grep ID=AF test.vcf; ##INFO=<ID=AF,Number=A,Type=Float,Description=""foo ""bar"""">. $ bcftools view -h test.vcf; [E::bcf_hdr_parse_line] Could not parse the header line: ""##INFO=<ID=AF,Number=A,Type=Float,Description=""foo ""bar"""">""; [W::bcf_hdr_parse] Could not parse header line: ##INFO=<ID=AF,Number=A,Type=Float,Description=""foo ""bar"""">; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9782
https://github.com/hail-is/hail/issues/9782:628,Testability,test,test,628,"The [VCF 4.2 spec](https://samtools.github.io/hts-specs/VCFv4.2.pdf) says:; > The Description value must be surrounded by double-quotes. Double-quote character can be escaped with backslash \ and backslash as \\\\. `hl.export_vcf` does not escape double quotes in descriptions. For example:; ```; ds = hl.import_vcf(""hail/src/test/resources/sample.vcf""); meta = hl.get_vcf_metadata(""hail/src/test/resources/sample.vcf""); meta[""info""][""AF""][""Description""] = 'foo ""bar""'; hl.export_vcf(ds, ""test.vcf"", metadata=meta); ```. ```; $ grep ID=AF test.vcf; ##INFO=<ID=AF,Number=A,Type=Float,Description=""foo ""bar"""">. $ bcftools view -h test.vcf; [E::bcf_hdr_parse_line] Could not parse the header line: ""##INFO=<ID=AF,Number=A,Type=Float,Description=""foo ""bar"""">""; [W::bcf_hdr_parse] Could not parse header line: ##INFO=<ID=AF,Number=A,Type=Float,Description=""foo ""bar"""">; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9782
https://github.com/hail-is/hail/pull/9783:52,Integrability,interface,interface,52,"`strides` shouldn't be a public field on `PNDArray` interface, just an internal detail of `PCanonicalNDArray`. . `dimensionLength` was just loading the shape, should never have been its own method. There's a lot more interface clean up to do, these two were just easy",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9783
https://github.com/hail-is/hail/pull/9783:217,Integrability,interface,interface,217,"`strides` shouldn't be a public field on `PNDArray` interface, just an internal detail of `PCanonicalNDArray`. . `dimensionLength` was just loading the shape, should never have been its own method. There's a lot more interface clean up to do, these two were just easy",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9783
https://github.com/hail-is/hail/pull/9783:140,Performance,load,loading,140,"`strides` shouldn't be a public field on `PNDArray` interface, just an internal detail of `PCanonicalNDArray`. . `dimensionLength` was just loading the shape, should never have been its own method. There's a lot more interface clean up to do, these two were just easy",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9783
https://github.com/hail-is/hail/pull/9784:39,Testability,test,tests,39,I tried this locally. Let's see if the tests pass.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9784
https://github.com/hail-is/hail/pull/9786:71,Modifiability,config,config,71,... and use in batch instead of hard-coded regions. There a new global-config key batch_gpc_regions which is a JSON list of region names to use.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9786
https://github.com/hail-is/hail/pull/9791:71,Integrability,interface,interface,71,"Modify hailctl dev config to let you set the domain. Note, this is an; interface change since I changed `hailctl dev config` to act like; gcloud/kubectl `... set property value`. The hardest part of this was getting a doubly-nested subcommand to work in argprase. The existing code is wack, but I will change everything to work like hailctl dev/dev config does below.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9791
https://github.com/hail-is/hail/pull/9791:19,Modifiability,config,config,19,"Modify hailctl dev config to let you set the domain. Note, this is an; interface change since I changed `hailctl dev config` to act like; gcloud/kubectl `... set property value`. The hardest part of this was getting a doubly-nested subcommand to work in argprase. The existing code is wack, but I will change everything to work like hailctl dev/dev config does below.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9791
https://github.com/hail-is/hail/pull/9791:117,Modifiability,config,config,117,"Modify hailctl dev config to let you set the domain. Note, this is an; interface change since I changed `hailctl dev config` to act like; gcloud/kubectl `... set property value`. The hardest part of this was getting a doubly-nested subcommand to work in argprase. The existing code is wack, but I will change everything to work like hailctl dev/dev config does below.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9791
https://github.com/hail-is/hail/pull/9791:349,Modifiability,config,config,349,"Modify hailctl dev config to let you set the domain. Note, this is an; interface change since I changed `hailctl dev config` to act like; gcloud/kubectl `... set property value`. The hardest part of this was getting a doubly-nested subcommand to work in argprase. The existing code is wack, but I will change everything to work like hailctl dev/dev config does below.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9791
https://github.com/hail-is/hail/pull/9799:0,Deployability,Update,Updated,0,"Updated bokeh to a better documented version, last 1.x release. This required some changes to use of `legend` mentioned here: `https://docs.bokeh.org/en/latest/docs/releases.html#release-1-4-0-migration`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9799
https://github.com/hail-is/hail/pull/9799:55,Deployability,release,release,55,"Updated bokeh to a better documented version, last 1.x release. This required some changes to use of `legend` mentioned here: `https://docs.bokeh.org/en/latest/docs/releases.html#release-1-4-0-migration`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9799
https://github.com/hail-is/hail/pull/9799:165,Deployability,release,releases,165,"Updated bokeh to a better documented version, last 1.x release. This required some changes to use of `legend` mentioned here: `https://docs.bokeh.org/en/latest/docs/releases.html#release-1-4-0-migration`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9799
https://github.com/hail-is/hail/pull/9799:179,Deployability,release,release-,179,"Updated bokeh to a better documented version, last 1.x release. This required some changes to use of `legend` mentioned here: `https://docs.bokeh.org/en/latest/docs/releases.html#release-1-4-0-migration`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9799
https://github.com/hail-is/hail/pull/9804:20,Deployability,update,update,20,Let's see if we can update to newest pandas.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9804
https://github.com/hail-is/hail/pull/9807:58,Testability,benchmark,benchmark,58,"There was a typo in the term `mean_impute`. I assume this benchmark has never actually worked, so it's troubling we haven't ever noticed it was broken for such a silly reason.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9807
https://github.com/hail-is/hail/pull/9808:110,Testability,test,tests,110,"This file is a distraction. We should always use the pylintrc in the root of the repo. All; our Makefiles and tests use that. cc: @tpoterba AFAIK, this file is unused.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9808
https://github.com/hail-is/hail/pull/9818:39,Integrability,depend,dependent,39,"Existence of directories is filesystem dependent, and they exist on Google if there is an object with that directory name a prefix. This required a little refactoring that changed fs.listfiles to return a coroutine that gives an iterator, rather than returning an iterator directly. This is because, if you use the `async def foo ... yield ...` syntax, it is not possible to write any code that will run between calling the async genreator function `foo` and the first call to `__anext__`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9818
https://github.com/hail-is/hail/pull/9818:155,Modifiability,refactor,refactoring,155,"Existence of directories is filesystem dependent, and they exist on Google if there is an object with that directory name a prefix. This required a little refactoring that changed fs.listfiles to return a coroutine that gives an iterator, rather than returning an iterator directly. This is because, if you use the `async def foo ... yield ...` syntax, it is not possible to write any code that will run between calling the async genreator function `foo` and the first call to `__anext__`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9818
https://github.com/hail-is/hail/pull/9819:12,Deployability,release,releases,12,Pandas only releases [breaking changes in major versions](https://pandas.pydata.org/docs/development/policies.html). It seems safe; to be flexible on patch version. Just today I had an issue where I ran `pip install pandas` to; upgrade from an old pandas version and I landed on 1.1.5.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9819
https://github.com/hail-is/hail/pull/9819:150,Deployability,patch,patch,150,Pandas only releases [breaking changes in major versions](https://pandas.pydata.org/docs/development/policies.html). It seems safe; to be flexible on patch version. Just today I had an issue where I ran `pip install pandas` to; upgrade from an old pandas version and I landed on 1.1.5.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9819
https://github.com/hail-is/hail/pull/9819:208,Deployability,install,install,208,Pandas only releases [breaking changes in major versions](https://pandas.pydata.org/docs/development/policies.html). It seems safe; to be flexible on patch version. Just today I had an issue where I ran `pip install pandas` to; upgrade from an old pandas version and I landed on 1.1.5.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9819
https://github.com/hail-is/hail/pull/9819:228,Deployability,upgrade,upgrade,228,Pandas only releases [breaking changes in major versions](https://pandas.pydata.org/docs/development/policies.html). It seems safe; to be flexible on patch version. Just today I had an issue where I ran `pip install pandas` to; upgrade from an old pandas version and I landed on 1.1.5.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9819
https://github.com/hail-is/hail/pull/9819:138,Modifiability,flexible,flexible,138,Pandas only releases [breaking changes in major versions](https://pandas.pydata.org/docs/development/policies.html). It seems safe; to be flexible on patch version. Just today I had an issue where I ran `pip install pandas` to; upgrade from an old pandas version and I landed on 1.1.5.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9819
https://github.com/hail-is/hail/pull/9819:126,Safety,safe,safe,126,Pandas only releases [breaking changes in major versions](https://pandas.pydata.org/docs/development/policies.html). It seems safe; to be flexible on patch version. Just today I had an issue where I ran `pip install pandas` to; upgrade from an old pandas version and I landed on 1.1.5.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9819
https://github.com/hail-is/hail/pull/9821:32,Deployability,integrat,integration,32,"I also added some flair to our ""integration tests"" (test.sh).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9821
https://github.com/hail-is/hail/pull/9821:32,Integrability,integrat,integration,32,"I also added some flair to our ""integration tests"" (test.sh).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9821
https://github.com/hail-is/hail/pull/9821:44,Testability,test,tests,44,"I also added some flair to our ""integration tests"" (test.sh).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9821
https://github.com/hail-is/hail/pull/9821:52,Testability,test,test,52,"I also added some flair to our ""integration tests"" (test.sh).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9821
https://github.com/hail-is/hail/pull/9822:451,Availability,error,error,451,"This PR is the first iteration of an AsyncFS-based copy interface. It adds RouterAsyncFS.copy. The goal of these changes is to establish the interface and behavior. I expect several follow-on PRs:. - Revise the original copy interface proposal and add to dev-docs.; - ~~Parallelizes the transfers concurrently with async and across multiple threads.~~; - ~~After parallizing, copy will involve a lot of paralellism. Throwing an exception on the first error will be very non-deterministic. Instead, copy will return a report that collects all the errors that were encountered in the course of copying, and summarizes how many files/bytes were copied.~~; - Use multi-process parallelism; - Avoid overwriting the destination if it exists and has a matching checksum (or size).; - ~~Introduce multi-part transfers~~; - add a post-pass for Google Storage to detect file-and-directory errors.; - Adds support for S3.; - Add `hailctl cp ...` (PR); - Use copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the sour",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:546,Availability,error,errors,546,"This PR is the first iteration of an AsyncFS-based copy interface. It adds RouterAsyncFS.copy. The goal of these changes is to establish the interface and behavior. I expect several follow-on PRs:. - Revise the original copy interface proposal and add to dev-docs.; - ~~Parallelizes the transfers concurrently with async and across multiple threads.~~; - ~~After parallizing, copy will involve a lot of paralellism. Throwing an exception on the first error will be very non-deterministic. Instead, copy will return a report that collects all the errors that were encountered in the course of copying, and summarizes how many files/bytes were copied.~~; - Use multi-process parallelism; - Avoid overwriting the destination if it exists and has a matching checksum (or size).; - ~~Introduce multi-part transfers~~; - add a post-pass for Google Storage to detect file-and-directory errors.; - Adds support for S3.; - Add `hailctl cp ...` (PR); - Use copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the sour",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:879,Availability,error,errors,879,"This PR is the first iteration of an AsyncFS-based copy interface. It adds RouterAsyncFS.copy. The goal of these changes is to establish the interface and behavior. I expect several follow-on PRs:. - Revise the original copy interface proposal and add to dev-docs.; - ~~Parallelizes the transfers concurrently with async and across multiple threads.~~; - ~~After parallizing, copy will involve a lot of paralellism. Throwing an exception on the first error will be very non-deterministic. Instead, copy will return a report that collects all the errors that were encountered in the course of copying, and summarizes how many files/bytes were copied.~~; - Use multi-process parallelism; - Avoid overwriting the destination if it exists and has a matching checksum (or size).; - ~~Introduce multi-part transfers~~; - add a post-pass for Google Storage to detect file-and-directory errors.; - Adds support for S3.; - Add `hailctl cp ...` (PR); - Use copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the sour",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:1158,Availability,error,error,1158," to establish the interface and behavior. I expect several follow-on PRs:. - Revise the original copy interface proposal and add to dev-docs.; - ~~Parallelizes the transfers concurrently with async and across multiple threads.~~; - ~~After parallizing, copy will involve a lot of paralellism. Throwing an exception on the first error will be very non-deterministic. Instead, copy will return a report that collects all the errors that were encountered in the course of copying, and summarizes how many files/bytes were copied.~~; - Use multi-process parallelism; - Avoid overwriting the destination if it exists and has a matching checksum (or size).; - ~~Introduce multi-part transfers~~; - add a post-pass for Google Storage to detect file-and-directory errors.; - Adds support for S3.; - Add `hailctl cp ...` (PR); - Use copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the source, so stat'ing the sources and destinations are all overlapping. This avoids dependencies where I have to e.g. stat the i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:1518,Availability,error,error,1518,"Instead, copy will return a report that collects all the errors that were encountered in the course of copying, and summarizes how many files/bytes were copied.~~; - Use multi-process parallelism; - Avoid overwriting the destination if it exists and has a matching checksum (or size).; - ~~Introduce multi-part transfers~~; - add a post-pass for Google Storage to detect file-and-directory errors.; - Adds support for S3.; - Add `hailctl cp ...` (PR); - Use copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the source, so stat'ing the sources and destinations are all overlapping. This avoids dependencies where I have to e.g. stat the input, decide what to do, and then perform a second action. I approached testing two ways: First, hand test common operations and errors (copy file, copy dir, overwrite, overwrite dir with file and vice versa, the various treat_dest_as settings, large files, detecting copy-and-files on input on Google Storage, etc.) Second, I enumerated essentially all single input ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:2252,Availability,error,errors,2252,"e copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the source, so stat'ing the sources and destinations are all overlapping. This avoids dependencies where I have to e.g. stat the input, decide what to do, and then perform a second action. I approached testing two ways: First, hand test common operations and errors (copy file, copy dir, overwrite, overwrite dir with file and vice versa, the various treat_dest_as settings, large files, detecting copy-and-files on input on Google Storage, etc.) Second, I enumerated essentially all single input transfers and recorded the results. These are then tested on every pair of file systems: file to file, file to gs, gs to file, etc. To make this run reasonably, I parallelize using xdist and the full tests (1364 tests) now take about 2 minutes. (If you restrict to the just the local filesystem, the tests just take a couple seconds.) The second test verifies that all cases run without unexpected errors, and that the behavior is file system independent.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:2888,Availability,error,errors,2888,"e copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the source, so stat'ing the sources and destinations are all overlapping. This avoids dependencies where I have to e.g. stat the input, decide what to do, and then perform a second action. I approached testing two ways: First, hand test common operations and errors (copy file, copy dir, overwrite, overwrite dir with file and vice versa, the various treat_dest_as settings, large files, detecting copy-and-files on input on Google Storage, etc.) Second, I enumerated essentially all single input transfers and recorded the results. These are then tested on every pair of file systems: file to file, file to gs, gs to file, etc. To make this run reasonably, I parallelize using xdist and the full tests (1364 tests) now take about 2 minutes. (If you restrict to the just the local filesystem, the tests just take a couple seconds.) The second test verifies that all cases run without unexpected errors, and that the behavior is file system independent.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:56,Integrability,interface,interface,56,"This PR is the first iteration of an AsyncFS-based copy interface. It adds RouterAsyncFS.copy. The goal of these changes is to establish the interface and behavior. I expect several follow-on PRs:. - Revise the original copy interface proposal and add to dev-docs.; - ~~Parallelizes the transfers concurrently with async and across multiple threads.~~; - ~~After parallizing, copy will involve a lot of paralellism. Throwing an exception on the first error will be very non-deterministic. Instead, copy will return a report that collects all the errors that were encountered in the course of copying, and summarizes how many files/bytes were copied.~~; - Use multi-process parallelism; - Avoid overwriting the destination if it exists and has a matching checksum (or size).; - ~~Introduce multi-part transfers~~; - add a post-pass for Google Storage to detect file-and-directory errors.; - Adds support for S3.; - Add `hailctl cp ...` (PR); - Use copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the sour",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:75,Integrability,Rout,RouterAsyncFS,75,"This PR is the first iteration of an AsyncFS-based copy interface. It adds RouterAsyncFS.copy. The goal of these changes is to establish the interface and behavior. I expect several follow-on PRs:. - Revise the original copy interface proposal and add to dev-docs.; - ~~Parallelizes the transfers concurrently with async and across multiple threads.~~; - ~~After parallizing, copy will involve a lot of paralellism. Throwing an exception on the first error will be very non-deterministic. Instead, copy will return a report that collects all the errors that were encountered in the course of copying, and summarizes how many files/bytes were copied.~~; - Use multi-process parallelism; - Avoid overwriting the destination if it exists and has a matching checksum (or size).; - ~~Introduce multi-part transfers~~; - add a post-pass for Google Storage to detect file-and-directory errors.; - Adds support for S3.; - Add `hailctl cp ...` (PR); - Use copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the sour",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:141,Integrability,interface,interface,141,"This PR is the first iteration of an AsyncFS-based copy interface. It adds RouterAsyncFS.copy. The goal of these changes is to establish the interface and behavior. I expect several follow-on PRs:. - Revise the original copy interface proposal and add to dev-docs.; - ~~Parallelizes the transfers concurrently with async and across multiple threads.~~; - ~~After parallizing, copy will involve a lot of paralellism. Throwing an exception on the first error will be very non-deterministic. Instead, copy will return a report that collects all the errors that were encountered in the course of copying, and summarizes how many files/bytes were copied.~~; - Use multi-process parallelism; - Avoid overwriting the destination if it exists and has a matching checksum (or size).; - ~~Introduce multi-part transfers~~; - add a post-pass for Google Storage to detect file-and-directory errors.; - Adds support for S3.; - Add `hailctl cp ...` (PR); - Use copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the sour",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:225,Integrability,interface,interface,225,"This PR is the first iteration of an AsyncFS-based copy interface. It adds RouterAsyncFS.copy. The goal of these changes is to establish the interface and behavior. I expect several follow-on PRs:. - Revise the original copy interface proposal and add to dev-docs.; - ~~Parallelizes the transfers concurrently with async and across multiple threads.~~; - ~~After parallizing, copy will involve a lot of paralellism. Throwing an exception on the first error will be very non-deterministic. Instead, copy will return a report that collects all the errors that were encountered in the course of copying, and summarizes how many files/bytes were copied.~~; - Use multi-process parallelism; - Avoid overwriting the destination if it exists and has a matching checksum (or size).; - ~~Introduce multi-part transfers~~; - add a post-pass for Google Storage to detect file-and-directory errors.; - Adds support for S3.; - Add `hailctl cp ...` (PR); - Use copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the sour",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:2079,Integrability,depend,dependencies,2079,"e copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the source, so stat'ing the sources and destinations are all overlapping. This avoids dependencies where I have to e.g. stat the input, decide what to do, and then perform a second action. I approached testing two ways: First, hand test common operations and errors (copy file, copy dir, overwrite, overwrite dir with file and vice versa, the various treat_dest_as settings, large files, detecting copy-and-files on input on Google Storage, etc.) Second, I enumerated essentially all single input transfers and recorded the results. These are then tested on every pair of file systems: file to file, file to gs, gs to file, etc. To make this run reasonably, I parallelize using xdist and the full tests (1364 tests) now take about 2 minutes. (If you restrict to the just the local filesystem, the tests just take a couple seconds.) The second test verifies that all cases run without unexpected errors, and that the behavior is file system independent.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:297,Performance,concurren,concurrently,297,"This PR is the first iteration of an AsyncFS-based copy interface. It adds RouterAsyncFS.copy. The goal of these changes is to establish the interface and behavior. I expect several follow-on PRs:. - Revise the original copy interface proposal and add to dev-docs.; - ~~Parallelizes the transfers concurrently with async and across multiple threads.~~; - ~~After parallizing, copy will involve a lot of paralellism. Throwing an exception on the first error will be very non-deterministic. Instead, copy will return a report that collects all the errors that were encountered in the course of copying, and summarizes how many files/bytes were copied.~~; - Use multi-process parallelism; - Avoid overwriting the destination if it exists and has a matching checksum (or size).; - ~~Introduce multi-part transfers~~; - add a post-pass for Google Storage to detect file-and-directory errors.; - Adds support for S3.; - Add `hailctl cp ...` (PR); - Use copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the sour",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:1077,Performance,perform,perform,1077," to establish the interface and behavior. I expect several follow-on PRs:. - Revise the original copy interface proposal and add to dev-docs.; - ~~Parallelizes the transfers concurrently with async and across multiple threads.~~; - ~~After parallizing, copy will involve a lot of paralellism. Throwing an exception on the first error will be very non-deterministic. Instead, copy will return a report that collects all the errors that were encountered in the course of copying, and summarizes how many files/bytes were copied.~~; - Use multi-process parallelism; - Avoid overwriting the destination if it exists and has a matching checksum (or size).; - ~~Introduce multi-part transfers~~; - add a post-pass for Google Storage to detect file-and-directory errors.; - Adds support for S3.; - Add `hailctl cp ...` (PR); - Use copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the source, so stat'ing the sources and destinations are all overlapping. This avoids dependencies where I have to e.g. stat the i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:2157,Performance,perform,perform,2157,"e copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the source, so stat'ing the sources and destinations are all overlapping. This avoids dependencies where I have to e.g. stat the input, decide what to do, and then perform a second action. I approached testing two ways: First, hand test common operations and errors (copy file, copy dir, overwrite, overwrite dir with file and vice versa, the various treat_dest_as settings, large files, detecting copy-and-files on input on Google Storage, etc.) Second, I enumerated essentially all single input transfers and recorded the results. These are then tested on every pair of file systems: file to file, file to gs, gs to file, etc. To make this run reasonably, I parallelize using xdist and the full tests (1364 tests) now take about 2 minutes. (If you restrict to the just the local filesystem, the tests just take a couple seconds.) The second test verifies that all cases run without unexpected errors, and that the behavior is file system independent.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:688,Safety,Avoid,Avoid,688,"This PR is the first iteration of an AsyncFS-based copy interface. It adds RouterAsyncFS.copy. The goal of these changes is to establish the interface and behavior. I expect several follow-on PRs:. - Revise the original copy interface proposal and add to dev-docs.; - ~~Parallelizes the transfers concurrently with async and across multiple threads.~~; - ~~After parallizing, copy will involve a lot of paralellism. Throwing an exception on the first error will be very non-deterministic. Instead, copy will return a report that collects all the errors that were encountered in the course of copying, and summarizes how many files/bytes were copied.~~; - Use multi-process parallelism; - Avoid overwriting the destination if it exists and has a matching checksum (or size).; - ~~Introduce multi-part transfers~~; - add a post-pass for Google Storage to detect file-and-directory errors.; - Adds support for S3.; - Add `hailctl cp ...` (PR); - Use copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the sour",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:853,Safety,detect,detect,853,"This PR is the first iteration of an AsyncFS-based copy interface. It adds RouterAsyncFS.copy. The goal of these changes is to establish the interface and behavior. I expect several follow-on PRs:. - Revise the original copy interface proposal and add to dev-docs.; - ~~Parallelizes the transfers concurrently with async and across multiple threads.~~; - ~~After parallizing, copy will involve a lot of paralellism. Throwing an exception on the first error will be very non-deterministic. Instead, copy will return a report that collects all the errors that were encountered in the course of copying, and summarizes how many files/bytes were copied.~~; - Use multi-process parallelism; - Avoid overwriting the destination if it exists and has a matching checksum (or size).; - ~~Introduce multi-part transfers~~; - add a post-pass for Google Storage to detect file-and-directory errors.; - Adds support for S3.; - Add `hailctl cp ...` (PR); - Use copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the sour",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:2072,Safety,avoid,avoids,2072,"e copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the source, so stat'ing the sources and destinations are all overlapping. This avoids dependencies where I have to e.g. stat the input, decide what to do, and then perform a second action. I approached testing two ways: First, hand test common operations and errors (copy file, copy dir, overwrite, overwrite dir with file and vice versa, the various treat_dest_as settings, large files, detecting copy-and-files on input on Google Storage, etc.) Second, I enumerated essentially all single input transfers and recorded the results. These are then tested on every pair of file systems: file to file, file to gs, gs to file, etc. To make this run reasonably, I parallelize using xdist and the full tests (1364 tests) now take about 2 minutes. (If you restrict to the just the local filesystem, the tests just take a couple seconds.) The second test verifies that all cases run without unexpected errors, and that the behavior is file system independent.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:2381,Safety,detect,detecting,2381,"e copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the source, so stat'ing the sources and destinations are all overlapping. This avoids dependencies where I have to e.g. stat the input, decide what to do, and then perform a second action. I approached testing two ways: First, hand test common operations and errors (copy file, copy dir, overwrite, overwrite dir with file and vice versa, the various treat_dest_as settings, large files, detecting copy-and-files on input on Google Storage, etc.) Second, I enumerated essentially all single input transfers and recorded the results. These are then tested on every pair of file systems: file to file, file to gs, gs to file, etc. To make this run reasonably, I parallelize using xdist and the full tests (1364 tests) now take about 2 minutes. (If you restrict to the just the local filesystem, the tests just take a couple seconds.) The second test verifies that all cases run without unexpected errors, and that the behavior is file system independent.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:754,Security,checksum,checksum,754,"This PR is the first iteration of an AsyncFS-based copy interface. It adds RouterAsyncFS.copy. The goal of these changes is to establish the interface and behavior. I expect several follow-on PRs:. - Revise the original copy interface proposal and add to dev-docs.; - ~~Parallelizes the transfers concurrently with async and across multiple threads.~~; - ~~After parallizing, copy will involve a lot of paralellism. Throwing an exception on the first error will be very non-deterministic. Instead, copy will return a report that collects all the errors that were encountered in the course of copying, and summarizes how many files/bytes were copied.~~; - Use multi-process parallelism; - Avoid overwriting the destination if it exists and has a matching checksum (or size).; - ~~Introduce multi-part transfers~~; - add a post-pass for Google Storage to detect file-and-directory errors.; - Adds support for S3.; - Add `hailctl cp ...` (PR); - Use copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the sour",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:2195,Testability,test,testing,2195,"e copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the source, so stat'ing the sources and destinations are all overlapping. This avoids dependencies where I have to e.g. stat the input, decide what to do, and then perform a second action. I approached testing two ways: First, hand test common operations and errors (copy file, copy dir, overwrite, overwrite dir with file and vice versa, the various treat_dest_as settings, large files, detecting copy-and-files on input on Google Storage, etc.) Second, I enumerated essentially all single input transfers and recorded the results. These are then tested on every pair of file systems: file to file, file to gs, gs to file, etc. To make this run reasonably, I parallelize using xdist and the full tests (1364 tests) now take about 2 minutes. (If you restrict to the just the local filesystem, the tests just take a couple seconds.) The second test verifies that all cases run without unexpected errors, and that the behavior is file system independent.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:2225,Testability,test,test,2225,"e copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the source, so stat'ing the sources and destinations are all overlapping. This avoids dependencies where I have to e.g. stat the input, decide what to do, and then perform a second action. I approached testing two ways: First, hand test common operations and errors (copy file, copy dir, overwrite, overwrite dir with file and vice versa, the various treat_dest_as settings, large files, detecting copy-and-files on input on Google Storage, etc.) Second, I enumerated essentially all single input transfers and recorded the results. These are then tested on every pair of file systems: file to file, file to gs, gs to file, etc. To make this run reasonably, I parallelize using xdist and the full tests (1364 tests) now take about 2 minutes. (If you restrict to the just the local filesystem, the tests just take a couple seconds.) The second test verifies that all cases run without unexpected errors, and that the behavior is file system independent.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:2541,Testability,test,tested,2541,"e copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the source, so stat'ing the sources and destinations are all overlapping. This avoids dependencies where I have to e.g. stat the input, decide what to do, and then perform a second action. I approached testing two ways: First, hand test common operations and errors (copy file, copy dir, overwrite, overwrite dir with file and vice versa, the various treat_dest_as settings, large files, detecting copy-and-files on input on Google Storage, etc.) Second, I enumerated essentially all single input transfers and recorded the results. These are then tested on every pair of file systems: file to file, file to gs, gs to file, etc. To make this run reasonably, I parallelize using xdist and the full tests (1364 tests) now take about 2 minutes. (If you restrict to the just the local filesystem, the tests just take a couple seconds.) The second test verifies that all cases run without unexpected errors, and that the behavior is file system independent.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:2690,Testability,test,tests,2690,"e copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the source, so stat'ing the sources and destinations are all overlapping. This avoids dependencies where I have to e.g. stat the input, decide what to do, and then perform a second action. I approached testing two ways: First, hand test common operations and errors (copy file, copy dir, overwrite, overwrite dir with file and vice versa, the various treat_dest_as settings, large files, detecting copy-and-files on input on Google Storage, etc.) Second, I enumerated essentially all single input transfers and recorded the results. These are then tested on every pair of file systems: file to file, file to gs, gs to file, etc. To make this run reasonably, I parallelize using xdist and the full tests (1364 tests) now take about 2 minutes. (If you restrict to the just the local filesystem, the tests just take a couple seconds.) The second test verifies that all cases run without unexpected errors, and that the behavior is file system independent.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:2702,Testability,test,tests,2702,"e copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the source, so stat'ing the sources and destinations are all overlapping. This avoids dependencies where I have to e.g. stat the input, decide what to do, and then perform a second action. I approached testing two ways: First, hand test common operations and errors (copy file, copy dir, overwrite, overwrite dir with file and vice versa, the various treat_dest_as settings, large files, detecting copy-and-files on input on Google Storage, etc.) Second, I enumerated essentially all single input transfers and recorded the results. These are then tested on every pair of file systems: file to file, file to gs, gs to file, etc. To make this run reasonably, I parallelize using xdist and the full tests (1364 tests) now take about 2 minutes. (If you restrict to the just the local filesystem, the tests just take a couple seconds.) The second test verifies that all cases run without unexpected errors, and that the behavior is file system independent.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:2790,Testability,test,tests,2790,"e copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the source, so stat'ing the sources and destinations are all overlapping. This avoids dependencies where I have to e.g. stat the input, decide what to do, and then perform a second action. I approached testing two ways: First, hand test common operations and errors (copy file, copy dir, overwrite, overwrite dir with file and vice versa, the various treat_dest_as settings, large files, detecting copy-and-files on input on Google Storage, etc.) Second, I enumerated essentially all single input transfers and recorded the results. These are then tested on every pair of file systems: file to file, file to gs, gs to file, etc. To make this run reasonably, I parallelize using xdist and the full tests (1364 tests) now take about 2 minutes. (If you restrict to the just the local filesystem, the tests just take a couple seconds.) The second test verifies that all cases run without unexpected errors, and that the behavior is file system independent.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:2836,Testability,test,test,2836,"e copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the source, so stat'ing the sources and destinations are all overlapping. This avoids dependencies where I have to e.g. stat the input, decide what to do, and then perform a second action. I approached testing two ways: First, hand test common operations and errors (copy file, copy dir, overwrite, overwrite dir with file and vice versa, the various treat_dest_as settings, large files, detecting copy-and-files on input on Google Storage, etc.) Second, I enumerated essentially all single input transfers and recorded the results. These are then tested on every pair of file systems: file to file, file to gs, gs to file, etc. To make this run reasonably, I parallelize using xdist and the full tests (1364 tests) now take about 2 minutes. (If you restrict to the just the local filesystem, the tests just take a couple seconds.) The second test verifies that all cases run without unexpected errors, and that the behavior is file system independent.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9822:1042,Usability,guid,guided,1042," to establish the interface and behavior. I expect several follow-on PRs:. - Revise the original copy interface proposal and add to dev-docs.; - ~~Parallelizes the transfers concurrently with async and across multiple threads.~~; - ~~After parallizing, copy will involve a lot of paralellism. Throwing an exception on the first error will be very non-deterministic. Instead, copy will return a report that collects all the errors that were encountered in the course of copying, and summarizes how many files/bytes were copied.~~; - Use multi-process parallelism; - Avoid overwriting the destination if it exists and has a matching checksum (or size).; - ~~Introduce multi-part transfers~~; - add a post-pass for Google Storage to detect file-and-directory errors.; - Adds support for S3.; - Add `hailctl cp ...` (PR); - Use copy in Batch. After this goes in, these can mostly be developed in parallel. A few principles guided the implementation of copy: perform the minimal number of system calls or API requests per copy, and only do error checking when it doesn't involve additional FS operations. For example, it is too expensive to exhaustively check if we're creating a path that is a file and a directory in Google Storage. I considered doing additional and exhaustive checking for the actual copy arguments. For example, currently, `cp -T /path/to/file /path/to/dir` will not generate an error on Google Storage. In the end, I decided to go with the current behavior and I will add an option to do a postpass to check for file-and-dir paths. To achieve this, for each transfer, I simultaneously stat the destination (if needd) to determine if it is a file, directory or doesn't exist. For each source, I simultaneously try to copy it as a file and a directory. When copying each source, we don't need to know the type of the destination until after we've stat'ed the source, so stat'ing the sources and destinations are all overlapping. This avoids dependencies where I have to e.g. stat the i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9822
https://github.com/hail-is/hail/pull/9824:1049,Availability,down,down,1049,"This PR updates a lot of NDArray code that was using the old `Code[T]` and emit triplet interface in favor of using code builders and `IEmitCode`. This is going to make it easier to update the `PNDArray` interface to not use `Code[Long]` everywhere, among other things. . Before this PR, there existed `NDArrayEmitter`, which did the old thing, and `NDArrayEmitter2`, which was a prototype of a new emitter. . After this PR, a tweaked version of `NDArrayEmitter2` has become the new `NDArrayEmitter`. `outputElement` now returns a `PCode`, and all the missingness problems are handled by carrying a `IEmitCodeGen[NDArrayEmitter]` around throughout the deforesting process, meaning the `NDArrayEmitter` no longer needs internal state about missingness. . I think the diff for `Emit.scala` is going to be pretty confusing. I'd at least opt for a side by side view instead of the intermingled one, as I've mostly implemented the same logic, just on top of our new code builder primitives. . All tests pass, but marking WIP since I'm noticing some slow down in the slice test that I want to look into. . This PR also adds a `get` function to `EmitValue` that gets the underlying `PValue` and moves two functions off of the `PNDArray` interface into `LinalgCodeUtils`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9824
https://github.com/hail-is/hail/pull/9824:8,Deployability,update,updates,8,"This PR updates a lot of NDArray code that was using the old `Code[T]` and emit triplet interface in favor of using code builders and `IEmitCode`. This is going to make it easier to update the `PNDArray` interface to not use `Code[Long]` everywhere, among other things. . Before this PR, there existed `NDArrayEmitter`, which did the old thing, and `NDArrayEmitter2`, which was a prototype of a new emitter. . After this PR, a tweaked version of `NDArrayEmitter2` has become the new `NDArrayEmitter`. `outputElement` now returns a `PCode`, and all the missingness problems are handled by carrying a `IEmitCodeGen[NDArrayEmitter]` around throughout the deforesting process, meaning the `NDArrayEmitter` no longer needs internal state about missingness. . I think the diff for `Emit.scala` is going to be pretty confusing. I'd at least opt for a side by side view instead of the intermingled one, as I've mostly implemented the same logic, just on top of our new code builder primitives. . All tests pass, but marking WIP since I'm noticing some slow down in the slice test that I want to look into. . This PR also adds a `get` function to `EmitValue` that gets the underlying `PValue` and moves two functions off of the `PNDArray` interface into `LinalgCodeUtils`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9824
https://github.com/hail-is/hail/pull/9824:182,Deployability,update,update,182,"This PR updates a lot of NDArray code that was using the old `Code[T]` and emit triplet interface in favor of using code builders and `IEmitCode`. This is going to make it easier to update the `PNDArray` interface to not use `Code[Long]` everywhere, among other things. . Before this PR, there existed `NDArrayEmitter`, which did the old thing, and `NDArrayEmitter2`, which was a prototype of a new emitter. . After this PR, a tweaked version of `NDArrayEmitter2` has become the new `NDArrayEmitter`. `outputElement` now returns a `PCode`, and all the missingness problems are handled by carrying a `IEmitCodeGen[NDArrayEmitter]` around throughout the deforesting process, meaning the `NDArrayEmitter` no longer needs internal state about missingness. . I think the diff for `Emit.scala` is going to be pretty confusing. I'd at least opt for a side by side view instead of the intermingled one, as I've mostly implemented the same logic, just on top of our new code builder primitives. . All tests pass, but marking WIP since I'm noticing some slow down in the slice test that I want to look into. . This PR also adds a `get` function to `EmitValue` that gets the underlying `PValue` and moves two functions off of the `PNDArray` interface into `LinalgCodeUtils`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9824
https://github.com/hail-is/hail/pull/9824:88,Integrability,interface,interface,88,"This PR updates a lot of NDArray code that was using the old `Code[T]` and emit triplet interface in favor of using code builders and `IEmitCode`. This is going to make it easier to update the `PNDArray` interface to not use `Code[Long]` everywhere, among other things. . Before this PR, there existed `NDArrayEmitter`, which did the old thing, and `NDArrayEmitter2`, which was a prototype of a new emitter. . After this PR, a tweaked version of `NDArrayEmitter2` has become the new `NDArrayEmitter`. `outputElement` now returns a `PCode`, and all the missingness problems are handled by carrying a `IEmitCodeGen[NDArrayEmitter]` around throughout the deforesting process, meaning the `NDArrayEmitter` no longer needs internal state about missingness. . I think the diff for `Emit.scala` is going to be pretty confusing. I'd at least opt for a side by side view instead of the intermingled one, as I've mostly implemented the same logic, just on top of our new code builder primitives. . All tests pass, but marking WIP since I'm noticing some slow down in the slice test that I want to look into. . This PR also adds a `get` function to `EmitValue` that gets the underlying `PValue` and moves two functions off of the `PNDArray` interface into `LinalgCodeUtils`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9824
https://github.com/hail-is/hail/pull/9824:204,Integrability,interface,interface,204,"This PR updates a lot of NDArray code that was using the old `Code[T]` and emit triplet interface in favor of using code builders and `IEmitCode`. This is going to make it easier to update the `PNDArray` interface to not use `Code[Long]` everywhere, among other things. . Before this PR, there existed `NDArrayEmitter`, which did the old thing, and `NDArrayEmitter2`, which was a prototype of a new emitter. . After this PR, a tweaked version of `NDArrayEmitter2` has become the new `NDArrayEmitter`. `outputElement` now returns a `PCode`, and all the missingness problems are handled by carrying a `IEmitCodeGen[NDArrayEmitter]` around throughout the deforesting process, meaning the `NDArrayEmitter` no longer needs internal state about missingness. . I think the diff for `Emit.scala` is going to be pretty confusing. I'd at least opt for a side by side view instead of the intermingled one, as I've mostly implemented the same logic, just on top of our new code builder primitives. . All tests pass, but marking WIP since I'm noticing some slow down in the slice test that I want to look into. . This PR also adds a `get` function to `EmitValue` that gets the underlying `PValue` and moves two functions off of the `PNDArray` interface into `LinalgCodeUtils`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9824
https://github.com/hail-is/hail/pull/9824:1230,Integrability,interface,interface,1230,"This PR updates a lot of NDArray code that was using the old `Code[T]` and emit triplet interface in favor of using code builders and `IEmitCode`. This is going to make it easier to update the `PNDArray` interface to not use `Code[Long]` everywhere, among other things. . Before this PR, there existed `NDArrayEmitter`, which did the old thing, and `NDArrayEmitter2`, which was a prototype of a new emitter. . After this PR, a tweaked version of `NDArrayEmitter2` has become the new `NDArrayEmitter`. `outputElement` now returns a `PCode`, and all the missingness problems are handled by carrying a `IEmitCodeGen[NDArrayEmitter]` around throughout the deforesting process, meaning the `NDArrayEmitter` no longer needs internal state about missingness. . I think the diff for `Emit.scala` is going to be pretty confusing. I'd at least opt for a side by side view instead of the intermingled one, as I've mostly implemented the same logic, just on top of our new code builder primitives. . All tests pass, but marking WIP since I'm noticing some slow down in the slice test that I want to look into. . This PR also adds a `get` function to `EmitValue` that gets the underlying `PValue` and moves two functions off of the `PNDArray` interface into `LinalgCodeUtils`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9824
https://github.com/hail-is/hail/pull/9824:931,Testability,log,logic,931,"This PR updates a lot of NDArray code that was using the old `Code[T]` and emit triplet interface in favor of using code builders and `IEmitCode`. This is going to make it easier to update the `PNDArray` interface to not use `Code[Long]` everywhere, among other things. . Before this PR, there existed `NDArrayEmitter`, which did the old thing, and `NDArrayEmitter2`, which was a prototype of a new emitter. . After this PR, a tweaked version of `NDArrayEmitter2` has become the new `NDArrayEmitter`. `outputElement` now returns a `PCode`, and all the missingness problems are handled by carrying a `IEmitCodeGen[NDArrayEmitter]` around throughout the deforesting process, meaning the `NDArrayEmitter` no longer needs internal state about missingness. . I think the diff for `Emit.scala` is going to be pretty confusing. I'd at least opt for a side by side view instead of the intermingled one, as I've mostly implemented the same logic, just on top of our new code builder primitives. . All tests pass, but marking WIP since I'm noticing some slow down in the slice test that I want to look into. . This PR also adds a `get` function to `EmitValue` that gets the underlying `PValue` and moves two functions off of the `PNDArray` interface into `LinalgCodeUtils`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9824
https://github.com/hail-is/hail/pull/9824:992,Testability,test,tests,992,"This PR updates a lot of NDArray code that was using the old `Code[T]` and emit triplet interface in favor of using code builders and `IEmitCode`. This is going to make it easier to update the `PNDArray` interface to not use `Code[Long]` everywhere, among other things. . Before this PR, there existed `NDArrayEmitter`, which did the old thing, and `NDArrayEmitter2`, which was a prototype of a new emitter. . After this PR, a tweaked version of `NDArrayEmitter2` has become the new `NDArrayEmitter`. `outputElement` now returns a `PCode`, and all the missingness problems are handled by carrying a `IEmitCodeGen[NDArrayEmitter]` around throughout the deforesting process, meaning the `NDArrayEmitter` no longer needs internal state about missingness. . I think the diff for `Emit.scala` is going to be pretty confusing. I'd at least opt for a side by side view instead of the intermingled one, as I've mostly implemented the same logic, just on top of our new code builder primitives. . All tests pass, but marking WIP since I'm noticing some slow down in the slice test that I want to look into. . This PR also adds a `get` function to `EmitValue` that gets the underlying `PValue` and moves two functions off of the `PNDArray` interface into `LinalgCodeUtils`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9824
https://github.com/hail-is/hail/pull/9824:1067,Testability,test,test,1067,"This PR updates a lot of NDArray code that was using the old `Code[T]` and emit triplet interface in favor of using code builders and `IEmitCode`. This is going to make it easier to update the `PNDArray` interface to not use `Code[Long]` everywhere, among other things. . Before this PR, there existed `NDArrayEmitter`, which did the old thing, and `NDArrayEmitter2`, which was a prototype of a new emitter. . After this PR, a tweaked version of `NDArrayEmitter2` has become the new `NDArrayEmitter`. `outputElement` now returns a `PCode`, and all the missingness problems are handled by carrying a `IEmitCodeGen[NDArrayEmitter]` around throughout the deforesting process, meaning the `NDArrayEmitter` no longer needs internal state about missingness. . I think the diff for `Emit.scala` is going to be pretty confusing. I'd at least opt for a side by side view instead of the intermingled one, as I've mostly implemented the same logic, just on top of our new code builder primitives. . All tests pass, but marking WIP since I'm noticing some slow down in the slice test that I want to look into. . This PR also adds a `get` function to `EmitValue` that gets the underlying `PValue` and moves two functions off of the `PNDArray` interface into `LinalgCodeUtils`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9824
https://github.com/hail-is/hail/pull/9825:773,Availability,error,error,773,"This is not this interface's final form, but it is an important; transitionary step in moving the entire code generation codebase away; from Code[T]. The CodeOrdering interface now (as before) has 12 methods, but before; the function signatures looked like:. def compare(lhs: (Code[Boolean], Code[T]), rhs: (Code[Boolean], Code[T])) -> Code[Int]. They now look like:. def compare(cb: EmitCodeBuilder, lhs: EmitCode, rhs: EmitCode) -> Code[Int]. There have been a lot of miscellaneous changes needed to get this to; work. There's some stuff that needs to be cleaned up, notably in Emit,; it's not always the case that the type of the IR/Aggregator is the same; as the type of the EmitCode that emit produces. I've tried to add; assertions where possible, but if there is an error, then a rather; cryptic 'Cannot pop value off of empty stack' exception is thrown,; generally indicating that an ordering expected an optional value, but; a required emitcode was provided.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9825
https://github.com/hail-is/hail/pull/9825:17,Integrability,interface,interface,17,"This is not this interface's final form, but it is an important; transitionary step in moving the entire code generation codebase away; from Code[T]. The CodeOrdering interface now (as before) has 12 methods, but before; the function signatures looked like:. def compare(lhs: (Code[Boolean], Code[T]), rhs: (Code[Boolean], Code[T])) -> Code[Int]. They now look like:. def compare(cb: EmitCodeBuilder, lhs: EmitCode, rhs: EmitCode) -> Code[Int]. There have been a lot of miscellaneous changes needed to get this to; work. There's some stuff that needs to be cleaned up, notably in Emit,; it's not always the case that the type of the IR/Aggregator is the same; as the type of the EmitCode that emit produces. I've tried to add; assertions where possible, but if there is an error, then a rather; cryptic 'Cannot pop value off of empty stack' exception is thrown,; generally indicating that an ordering expected an optional value, but; a required emitcode was provided.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9825
https://github.com/hail-is/hail/pull/9825:167,Integrability,interface,interface,167,"This is not this interface's final form, but it is an important; transitionary step in moving the entire code generation codebase away; from Code[T]. The CodeOrdering interface now (as before) has 12 methods, but before; the function signatures looked like:. def compare(lhs: (Code[Boolean], Code[T]), rhs: (Code[Boolean], Code[T])) -> Code[Int]. They now look like:. def compare(cb: EmitCodeBuilder, lhs: EmitCode, rhs: EmitCode) -> Code[Int]. There have been a lot of miscellaneous changes needed to get this to; work. There's some stuff that needs to be cleaned up, notably in Emit,; it's not always the case that the type of the IR/Aggregator is the same; as the type of the EmitCode that emit produces. I've tried to add; assertions where possible, but if there is an error, then a rather; cryptic 'Cannot pop value off of empty stack' exception is thrown,; generally indicating that an ordering expected an optional value, but; a required emitcode was provided.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9825
https://github.com/hail-is/hail/pull/9825:727,Testability,assert,assertions,727,"This is not this interface's final form, but it is an important; transitionary step in moving the entire code generation codebase away; from Code[T]. The CodeOrdering interface now (as before) has 12 methods, but before; the function signatures looked like:. def compare(lhs: (Code[Boolean], Code[T]), rhs: (Code[Boolean], Code[T])) -> Code[Int]. They now look like:. def compare(cb: EmitCodeBuilder, lhs: EmitCode, rhs: EmitCode) -> Code[Int]. There have been a lot of miscellaneous changes needed to get this to; work. There's some stuff that needs to be cleaned up, notably in Emit,; it's not always the case that the type of the IR/Aggregator is the same; as the type of the EmitCode that emit produces. I've tried to add; assertions where possible, but if there is an error, then a rather; cryptic 'Cannot pop value off of empty stack' exception is thrown,; generally indicating that an ordering expected an optional value, but; a required emitcode was provided.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9825
https://github.com/hail-is/hail/pull/9832:973,Deployability,update,updated,973,"This PR introduces a couple of new concepts:; - InstanceCollection which is a generic class that keeps track of instances in its collection; - Pool which is a shared, growable pool of instances with a control loop and fair share scheduler and is a subclass of InstanceCollection; - InstanceCollectionManager which keeps track of all instance collections. The cancel code remains the same and operates globally and is now in canceller.py. The GCE event monitor is in gce.py. The original instance_pool.py code has been split amongst zone_monitor.py, pool.py, gce.py, create_instance.py, and instance_collection.py. The scheduler code is now in PoolScheduler in pool.py. The SQL code has vectorized user_resources by instance_collection as well as batch_cancellable_resources and batches_staging. There are also two new tables: inst_colls and pools. Each job and instance must belong to an instance collection noted by the field `inst_coll`. The job_update trigger had to be updated to insert into user_resources to the correct pool. The cancel_batch and close_batch functions changed to vectorize by instance collection. I deleted the global `ready_cores` table. The front end code does not change except looking for a `worker_type` field in the resources field of the job spec (default if undefined is standard). I added a PoolSelector class which is overkill for now, but will be used in the future for more complicated scenarios. There was an issue with our existing code for converting between memory in bytes to memory in MB in the worker_config.py code for the `resources()` function. For the highcpu case, it is impossible for the memory in bytes to be divisible by 1024**2. The utils.py code now rounds up bytes using math.ceil. The hailtop.batch library adds a `worker_type` method on Job. I didn't change the interface significantly at this time as I think this is fine for now. More significant changes will come when we change how cpu and memory and storage are interpreted by the worker. I",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9832
https://github.com/hail-is/hail/pull/9832:2301,Deployability,configurat,configuration,2301,"e_pool.py code has been split amongst zone_monitor.py, pool.py, gce.py, create_instance.py, and instance_collection.py. The scheduler code is now in PoolScheduler in pool.py. The SQL code has vectorized user_resources by instance_collection as well as batch_cancellable_resources and batches_staging. There are also two new tables: inst_colls and pools. Each job and instance must belong to an instance collection noted by the field `inst_coll`. The job_update trigger had to be updated to insert into user_resources to the correct pool. The cancel_batch and close_batch functions changed to vectorize by instance collection. I deleted the global `ready_cores` table. The front end code does not change except looking for a `worker_type` field in the resources field of the job spec (default if undefined is standard). I added a PoolSelector class which is overkill for now, but will be used in the future for more complicated scenarios. There was an issue with our existing code for converting between memory in bytes to memory in MB in the worker_config.py code for the `resources()` function. For the highcpu case, it is impossible for the memory in bytes to be divisible by 1024**2. The utils.py code now rounds up bytes using math.ceil. The hailtop.batch library adds a `worker_type` method on Job. I didn't change the interface significantly at this time as I think this is fine for now. More significant changes will come when we change how cpu and memory and storage are interpreted by the worker. I added 3 new tests: we spin up a highmem and highcpu machine in test_batch.py. In the hailtop.batch tests, I check the `worker_type` interface. The driver UI page has changed such that there's a list of pools with links to a pools.html page, which gives information on the instances in the pool, the configuration updates, and the current user resources for that pool. Things to double check:; - SQL code especially cancel_batch where I had to use temporary variables and recompute_incremental",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9832
https://github.com/hail-is/hail/pull/9832:2315,Deployability,update,updates,2315,"e_pool.py code has been split amongst zone_monitor.py, pool.py, gce.py, create_instance.py, and instance_collection.py. The scheduler code is now in PoolScheduler in pool.py. The SQL code has vectorized user_resources by instance_collection as well as batch_cancellable_resources and batches_staging. There are also two new tables: inst_colls and pools. Each job and instance must belong to an instance collection noted by the field `inst_coll`. The job_update trigger had to be updated to insert into user_resources to the correct pool. The cancel_batch and close_batch functions changed to vectorize by instance collection. I deleted the global `ready_cores` table. The front end code does not change except looking for a `worker_type` field in the resources field of the job spec (default if undefined is standard). I added a PoolSelector class which is overkill for now, but will be used in the future for more complicated scenarios. There was an issue with our existing code for converting between memory in bytes to memory in MB in the worker_config.py code for the `resources()` function. For the highcpu case, it is impossible for the memory in bytes to be divisible by 1024**2. The utils.py code now rounds up bytes using math.ceil. The hailtop.batch library adds a `worker_type` method on Job. I didn't change the interface significantly at this time as I think this is fine for now. More significant changes will come when we change how cpu and memory and storage are interpreted by the worker. I added 3 new tests: we spin up a highmem and highcpu machine in test_batch.py. In the hailtop.batch tests, I check the `worker_type` interface. The driver UI page has changed such that there's a list of pools with links to a pools.html page, which gives information on the instances in the pool, the configuration updates, and the current user resources for that pool. Things to double check:; - SQL code especially cancel_batch where I had to use temporary variables and recompute_incremental",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9832
https://github.com/hail-is/hail/pull/9832:229,Energy Efficiency,schedul,scheduler,229,"This PR introduces a couple of new concepts:; - InstanceCollection which is a generic class that keeps track of instances in its collection; - Pool which is a shared, growable pool of instances with a control loop and fair share scheduler and is a subclass of InstanceCollection; - InstanceCollectionManager which keeps track of all instance collections. The cancel code remains the same and operates globally and is now in canceller.py. The GCE event monitor is in gce.py. The original instance_pool.py code has been split amongst zone_monitor.py, pool.py, gce.py, create_instance.py, and instance_collection.py. The scheduler code is now in PoolScheduler in pool.py. The SQL code has vectorized user_resources by instance_collection as well as batch_cancellable_resources and batches_staging. There are also two new tables: inst_colls and pools. Each job and instance must belong to an instance collection noted by the field `inst_coll`. The job_update trigger had to be updated to insert into user_resources to the correct pool. The cancel_batch and close_batch functions changed to vectorize by instance collection. I deleted the global `ready_cores` table. The front end code does not change except looking for a `worker_type` field in the resources field of the job spec (default if undefined is standard). I added a PoolSelector class which is overkill for now, but will be used in the future for more complicated scenarios. There was an issue with our existing code for converting between memory in bytes to memory in MB in the worker_config.py code for the `resources()` function. For the highcpu case, it is impossible for the memory in bytes to be divisible by 1024**2. The utils.py code now rounds up bytes using math.ceil. The hailtop.batch library adds a `worker_type` method on Job. I didn't change the interface significantly at this time as I think this is fine for now. More significant changes will come when we change how cpu and memory and storage are interpreted by the worker. I",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9832
https://github.com/hail-is/hail/pull/9832:452,Energy Efficiency,monitor,monitor,452,"This PR introduces a couple of new concepts:; - InstanceCollection which is a generic class that keeps track of instances in its collection; - Pool which is a shared, growable pool of instances with a control loop and fair share scheduler and is a subclass of InstanceCollection; - InstanceCollectionManager which keeps track of all instance collections. The cancel code remains the same and operates globally and is now in canceller.py. The GCE event monitor is in gce.py. The original instance_pool.py code has been split amongst zone_monitor.py, pool.py, gce.py, create_instance.py, and instance_collection.py. The scheduler code is now in PoolScheduler in pool.py. The SQL code has vectorized user_resources by instance_collection as well as batch_cancellable_resources and batches_staging. There are also two new tables: inst_colls and pools. Each job and instance must belong to an instance collection noted by the field `inst_coll`. The job_update trigger had to be updated to insert into user_resources to the correct pool. The cancel_batch and close_batch functions changed to vectorize by instance collection. I deleted the global `ready_cores` table. The front end code does not change except looking for a `worker_type` field in the resources field of the job spec (default if undefined is standard). I added a PoolSelector class which is overkill for now, but will be used in the future for more complicated scenarios. There was an issue with our existing code for converting between memory in bytes to memory in MB in the worker_config.py code for the `resources()` function. For the highcpu case, it is impossible for the memory in bytes to be divisible by 1024**2. The utils.py code now rounds up bytes using math.ceil. The hailtop.batch library adds a `worker_type` method on Job. I didn't change the interface significantly at this time as I think this is fine for now. More significant changes will come when we change how cpu and memory and storage are interpreted by the worker. I",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9832
https://github.com/hail-is/hail/pull/9832:618,Energy Efficiency,schedul,scheduler,618,"This PR introduces a couple of new concepts:; - InstanceCollection which is a generic class that keeps track of instances in its collection; - Pool which is a shared, growable pool of instances with a control loop and fair share scheduler and is a subclass of InstanceCollection; - InstanceCollectionManager which keeps track of all instance collections. The cancel code remains the same and operates globally and is now in canceller.py. The GCE event monitor is in gce.py. The original instance_pool.py code has been split amongst zone_monitor.py, pool.py, gce.py, create_instance.py, and instance_collection.py. The scheduler code is now in PoolScheduler in pool.py. The SQL code has vectorized user_resources by instance_collection as well as batch_cancellable_resources and batches_staging. There are also two new tables: inst_colls and pools. Each job and instance must belong to an instance collection noted by the field `inst_coll`. The job_update trigger had to be updated to insert into user_resources to the correct pool. The cancel_batch and close_batch functions changed to vectorize by instance collection. I deleted the global `ready_cores` table. The front end code does not change except looking for a `worker_type` field in the resources field of the job spec (default if undefined is standard). I added a PoolSelector class which is overkill for now, but will be used in the future for more complicated scenarios. There was an issue with our existing code for converting between memory in bytes to memory in MB in the worker_config.py code for the `resources()` function. For the highcpu case, it is impossible for the memory in bytes to be divisible by 1024**2. The utils.py code now rounds up bytes using math.ceil. The hailtop.batch library adds a `worker_type` method on Job. I didn't change the interface significantly at this time as I think this is fine for now. More significant changes will come when we change how cpu and memory and storage are interpreted by the worker. I",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9832
https://github.com/hail-is/hail/pull/9832:1818,Integrability,interface,interface,1818,"e_pool.py code has been split amongst zone_monitor.py, pool.py, gce.py, create_instance.py, and instance_collection.py. The scheduler code is now in PoolScheduler in pool.py. The SQL code has vectorized user_resources by instance_collection as well as batch_cancellable_resources and batches_staging. There are also two new tables: inst_colls and pools. Each job and instance must belong to an instance collection noted by the field `inst_coll`. The job_update trigger had to be updated to insert into user_resources to the correct pool. The cancel_batch and close_batch functions changed to vectorize by instance collection. I deleted the global `ready_cores` table. The front end code does not change except looking for a `worker_type` field in the resources field of the job spec (default if undefined is standard). I added a PoolSelector class which is overkill for now, but will be used in the future for more complicated scenarios. There was an issue with our existing code for converting between memory in bytes to memory in MB in the worker_config.py code for the `resources()` function. For the highcpu case, it is impossible for the memory in bytes to be divisible by 1024**2. The utils.py code now rounds up bytes using math.ceil. The hailtop.batch library adds a `worker_type` method on Job. I didn't change the interface significantly at this time as I think this is fine for now. More significant changes will come when we change how cpu and memory and storage are interpreted by the worker. I added 3 new tests: we spin up a highmem and highcpu machine in test_batch.py. In the hailtop.batch tests, I check the `worker_type` interface. The driver UI page has changed such that there's a list of pools with links to a pools.html page, which gives information on the instances in the pool, the configuration updates, and the current user resources for that pool. Things to double check:; - SQL code especially cancel_batch where I had to use temporary variables and recompute_incremental",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9832
https://github.com/hail-is/hail/pull/9832:2134,Integrability,interface,interface,2134,"e_pool.py code has been split amongst zone_monitor.py, pool.py, gce.py, create_instance.py, and instance_collection.py. The scheduler code is now in PoolScheduler in pool.py. The SQL code has vectorized user_resources by instance_collection as well as batch_cancellable_resources and batches_staging. There are also two new tables: inst_colls and pools. Each job and instance must belong to an instance collection noted by the field `inst_coll`. The job_update trigger had to be updated to insert into user_resources to the correct pool. The cancel_batch and close_batch functions changed to vectorize by instance collection. I deleted the global `ready_cores` table. The front end code does not change except looking for a `worker_type` field in the resources field of the job spec (default if undefined is standard). I added a PoolSelector class which is overkill for now, but will be used in the future for more complicated scenarios. There was an issue with our existing code for converting between memory in bytes to memory in MB in the worker_config.py code for the `resources()` function. For the highcpu case, it is impossible for the memory in bytes to be divisible by 1024**2. The utils.py code now rounds up bytes using math.ceil. The hailtop.batch library adds a `worker_type` method on Job. I didn't change the interface significantly at this time as I think this is fine for now. More significant changes will come when we change how cpu and memory and storage are interpreted by the worker. I added 3 new tests: we spin up a highmem and highcpu machine in test_batch.py. In the hailtop.batch tests, I check the `worker_type` interface. The driver UI page has changed such that there's a list of pools with links to a pools.html page, which gives information on the instances in the pool, the configuration updates, and the current user resources for that pool. Things to double check:; - SQL code especially cancel_batch where I had to use temporary variables and recompute_incremental",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9832
https://github.com/hail-is/hail/pull/9832:2301,Modifiability,config,configuration,2301,"e_pool.py code has been split amongst zone_monitor.py, pool.py, gce.py, create_instance.py, and instance_collection.py. The scheduler code is now in PoolScheduler in pool.py. The SQL code has vectorized user_resources by instance_collection as well as batch_cancellable_resources and batches_staging. There are also two new tables: inst_colls and pools. Each job and instance must belong to an instance collection noted by the field `inst_coll`. The job_update trigger had to be updated to insert into user_resources to the correct pool. The cancel_batch and close_batch functions changed to vectorize by instance collection. I deleted the global `ready_cores` table. The front end code does not change except looking for a `worker_type` field in the resources field of the job spec (default if undefined is standard). I added a PoolSelector class which is overkill for now, but will be used in the future for more complicated scenarios. There was an issue with our existing code for converting between memory in bytes to memory in MB in the worker_config.py code for the `resources()` function. For the highcpu case, it is impossible for the memory in bytes to be divisible by 1024**2. The utils.py code now rounds up bytes using math.ceil. The hailtop.batch library adds a `worker_type` method on Job. I didn't change the interface significantly at this time as I think this is fine for now. More significant changes will come when we change how cpu and memory and storage are interpreted by the worker. I added 3 new tests: we spin up a highmem and highcpu machine in test_batch.py. In the hailtop.batch tests, I check the `worker_type` interface. The driver UI page has changed such that there's a list of pools with links to a pools.html page, which gives information on the instances in the pool, the configuration updates, and the current user resources for that pool. Things to double check:; - SQL code especially cancel_batch where I had to use temporary variables and recompute_incremental",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9832
https://github.com/hail-is/hail/pull/9832:2459,Modifiability,variab,variables,2459,"e_pool.py code has been split amongst zone_monitor.py, pool.py, gce.py, create_instance.py, and instance_collection.py. The scheduler code is now in PoolScheduler in pool.py. The SQL code has vectorized user_resources by instance_collection as well as batch_cancellable_resources and batches_staging. There are also two new tables: inst_colls and pools. Each job and instance must belong to an instance collection noted by the field `inst_coll`. The job_update trigger had to be updated to insert into user_resources to the correct pool. The cancel_batch and close_batch functions changed to vectorize by instance collection. I deleted the global `ready_cores` table. The front end code does not change except looking for a `worker_type` field in the resources field of the job spec (default if undefined is standard). I added a PoolSelector class which is overkill for now, but will be used in the future for more complicated scenarios. There was an issue with our existing code for converting between memory in bytes to memory in MB in the worker_config.py code for the `resources()` function. For the highcpu case, it is impossible for the memory in bytes to be divisible by 1024**2. The utils.py code now rounds up bytes using math.ceil. The hailtop.batch library adds a `worker_type` method on Job. I didn't change the interface significantly at this time as I think this is fine for now. More significant changes will come when we change how cpu and memory and storage are interpreted by the worker. I added 3 new tests: we spin up a highmem and highcpu machine in test_batch.py. In the hailtop.batch tests, I check the `worker_type` interface. The driver UI page has changed such that there's a list of pools with links to a pools.html page, which gives information on the instances in the pool, the configuration updates, and the current user resources for that pool. Things to double check:; - SQL code especially cancel_batch where I had to use temporary variables and recompute_incremental",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9832
https://github.com/hail-is/hail/pull/9832:2014,Testability,test,tests,2014,"e_pool.py code has been split amongst zone_monitor.py, pool.py, gce.py, create_instance.py, and instance_collection.py. The scheduler code is now in PoolScheduler in pool.py. The SQL code has vectorized user_resources by instance_collection as well as batch_cancellable_resources and batches_staging. There are also two new tables: inst_colls and pools. Each job and instance must belong to an instance collection noted by the field `inst_coll`. The job_update trigger had to be updated to insert into user_resources to the correct pool. The cancel_batch and close_batch functions changed to vectorize by instance collection. I deleted the global `ready_cores` table. The front end code does not change except looking for a `worker_type` field in the resources field of the job spec (default if undefined is standard). I added a PoolSelector class which is overkill for now, but will be used in the future for more complicated scenarios. There was an issue with our existing code for converting between memory in bytes to memory in MB in the worker_config.py code for the `resources()` function. For the highcpu case, it is impossible for the memory in bytes to be divisible by 1024**2. The utils.py code now rounds up bytes using math.ceil. The hailtop.batch library adds a `worker_type` method on Job. I didn't change the interface significantly at this time as I think this is fine for now. More significant changes will come when we change how cpu and memory and storage are interpreted by the worker. I added 3 new tests: we spin up a highmem and highcpu machine in test_batch.py. In the hailtop.batch tests, I check the `worker_type` interface. The driver UI page has changed such that there's a list of pools with links to a pools.html page, which gives information on the instances in the pool, the configuration updates, and the current user resources for that pool. Things to double check:; - SQL code especially cancel_batch where I had to use temporary variables and recompute_incremental",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9832
https://github.com/hail-is/hail/pull/9832:2101,Testability,test,tests,2101,"e_pool.py code has been split amongst zone_monitor.py, pool.py, gce.py, create_instance.py, and instance_collection.py. The scheduler code is now in PoolScheduler in pool.py. The SQL code has vectorized user_resources by instance_collection as well as batch_cancellable_resources and batches_staging. There are also two new tables: inst_colls and pools. Each job and instance must belong to an instance collection noted by the field `inst_coll`. The job_update trigger had to be updated to insert into user_resources to the correct pool. The cancel_batch and close_batch functions changed to vectorize by instance collection. I deleted the global `ready_cores` table. The front end code does not change except looking for a `worker_type` field in the resources field of the job spec (default if undefined is standard). I added a PoolSelector class which is overkill for now, but will be used in the future for more complicated scenarios. There was an issue with our existing code for converting between memory in bytes to memory in MB in the worker_config.py code for the `resources()` function. For the highcpu case, it is impossible for the memory in bytes to be divisible by 1024**2. The utils.py code now rounds up bytes using math.ceil. The hailtop.batch library adds a `worker_type` method on Job. I didn't change the interface significantly at this time as I think this is fine for now. More significant changes will come when we change how cpu and memory and storage are interpreted by the worker. I added 3 new tests: we spin up a highmem and highcpu machine in test_batch.py. In the hailtop.batch tests, I check the `worker_type` interface. The driver UI page has changed such that there's a list of pools with links to a pools.html page, which gives information on the instances in the pool, the configuration updates, and the current user resources for that pool. Things to double check:; - SQL code especially cancel_batch where I had to use temporary variables and recompute_incremental",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9832
https://github.com/hail-is/hail/issues/9833:809,Availability,error,error,809,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------; version 0.2.54-8526838bf99f. When importing matrix table from VCF, the rows have the following schema. ```text; ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'locus': locus<GRCh38> ; 'alleles': array<str> ; 'rsid': str ; 'qual': float64 ; 'filters': set<str> ; 'info': struct {} ; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------; ```. When running `mt.rows().show()` the following error is observed. ```text; ---------------------------------------------------------------------------; ValueError Traceback (most recent call last); /opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py in __call__(self, obj); 343 method = get_real_method(obj, self.print_method); 344 if method is not None:; --> 345 return method(); 346 return None; 347 else:. /opt/hail/python/hail/table.py in _repr_html_(self); 1279 ; 1280 def _repr_html_(self):; -> 1281 return self._html_str(); 1282 ; 1283 def _ascii_str(self):. /opt/hail/python/hail/table.py in _html_str(self); 1381 return (f'<tr><td style=""{style}"">' + f'</td><td style=""{style}"">'.join(values) + '</td></tr>\n'); 1382 ; -> 1383 arranged_field_names = PlacementTree.from_named_type('row', self.table.row.dtype); 1384 ; 1385 s = '<table>'. /opt/hail/python/hail/utils/placement_tree.py in from_named_type(name, dtype); 16 if not isinstance(dtype, tstruct):; 17 return PlacementTree(name, 1, 0, []); ---> 18 children = [PlacementTree.from_named_type(name, dtype) for name, dtype in dtype.items()]; 19 width = sum(child.width for child in children); 20 height = max(child.height for child in children) + 1. /opt/hail/pyth",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9833
https://github.com/hail-is/hail/pull/9834:84,Availability,error,error,84,"Proposed fix for https://github.com/hail-is/hail/issues/9833. Summary: fix run time error when a matrix table row has an empty struct. Example: `info` field below is an empty struct; ```; ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'locus': locus<GRCh38> ; 'alleles': array<str> ; 'rsid': str ; 'qual': float64 ; 'filters': set<str> ; 'info': struct {} ; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------; ```. The function `max` will throw this error; ```; ValueError: max() arg is an empty sequence; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9834
https://github.com/hail-is/hail/pull/9834:581,Availability,error,error,581,"Proposed fix for https://github.com/hail-is/hail/issues/9833. Summary: fix run time error when a matrix table row has an empty struct. Example: `info` field below is an empty struct; ```; ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'locus': locus<GRCh38> ; 'alleles': array<str> ; 'rsid': str ; 'qual': float64 ; 'filters': set<str> ; 'info': struct {} ; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------; ```. The function `max` will throw this error; ```; ValueError: max() arg is an empty sequence; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9834
https://github.com/hail-is/hail/pull/9836:305,Availability,error,error,305,"for better or worse. I believe the behavior is the same and the code and user ergonomics seem better. The one known issue I haven't figured out to fix is the usage output on unknown flags:. ```; $ hailctl --fleep auth login; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --fleep. $ hailctl auth --fleep login; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --fleep; ```. This implies argparse should allow hailctl flags to appear after auth, but that isn't the case. For example:. ```; $ hailctl dataproc connect --beta foo nb; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --beta; ```. I will keep investigating a fix for this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9836
https://github.com/hail-is/hail/pull/9836:455,Availability,error,error,455,"for better or worse. I believe the behavior is the same and the code and user ergonomics seem better. The one known issue I haven't figured out to fix is the usage output on unknown flags:. ```; $ hailctl --fleep auth login; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --fleep. $ hailctl auth --fleep login; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --fleep; ```. This implies argparse should allow hailctl flags to appear after auth, but that isn't the case. For example:. ```; $ hailctl dataproc connect --beta foo nb; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --beta; ```. I will keep investigating a fix for this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9836
https://github.com/hail-is/hail/pull/9836:737,Availability,error,error,737,"for better or worse. I believe the behavior is the same and the code and user ergonomics seem better. The one known issue I haven't figured out to fix is the usage output on unknown flags:. ```; $ hailctl --fleep auth login; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --fleep. $ hailctl auth --fleep login; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --fleep; ```. This implies argparse should allow hailctl flags to appear after auth, but that isn't the case. For example:. ```; $ hailctl dataproc connect --beta foo nb; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --beta; ```. I will keep investigating a fix for this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9836
https://github.com/hail-is/hail/pull/9836:283,Modifiability,config,config,283,"for better or worse. I believe the behavior is the same and the code and user ergonomics seem better. The one known issue I haven't figured out to fix is the usage output on unknown flags:. ```; $ hailctl --fleep auth login; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --fleep. $ hailctl auth --fleep login; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --fleep; ```. This implies argparse should allow hailctl flags to appear after auth, but that isn't the case. For example:. ```; $ hailctl dataproc connect --beta foo nb; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --beta; ```. I will keep investigating a fix for this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9836
https://github.com/hail-is/hail/pull/9836:433,Modifiability,config,config,433,"for better or worse. I believe the behavior is the same and the code and user ergonomics seem better. The one known issue I haven't figured out to fix is the usage output on unknown flags:. ```; $ hailctl --fleep auth login; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --fleep. $ hailctl auth --fleep login; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --fleep; ```. This implies argparse should allow hailctl flags to appear after auth, but that isn't the case. For example:. ```; $ hailctl dataproc connect --beta foo nb; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --beta; ```. I will keep investigating a fix for this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9836
https://github.com/hail-is/hail/pull/9836:715,Modifiability,config,config,715,"for better or worse. I believe the behavior is the same and the code and user ergonomics seem better. The one known issue I haven't figured out to fix is the usage output on unknown flags:. ```; $ hailctl --fleep auth login; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --fleep. $ hailctl auth --fleep login; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --fleep; ```. This implies argparse should allow hailctl flags to appear after auth, but that isn't the case. For example:. ```; $ hailctl dataproc connect --beta foo nb; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --beta; ```. I will keep investigating a fix for this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9836
https://github.com/hail-is/hail/pull/9836:218,Testability,log,login,218,"for better or worse. I believe the behavior is the same and the code and user ergonomics seem better. The one known issue I haven't figured out to fix is the usage output on unknown flags:. ```; $ hailctl --fleep auth login; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --fleep. $ hailctl auth --fleep login; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --fleep; ```. This implies argparse should allow hailctl flags to appear after auth, but that isn't the case. For example:. ```; $ hailctl dataproc connect --beta foo nb; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --beta; ```. I will keep investigating a fix for this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9836
https://github.com/hail-is/hail/pull/9836:368,Testability,log,login,368,"for better or worse. I believe the behavior is the same and the code and user ergonomics seem better. The one known issue I haven't figured out to fix is the usage output on unknown flags:. ```; $ hailctl --fleep auth login; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --fleep. $ hailctl auth --fleep login; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --fleep; ```. This implies argparse should allow hailctl flags to appear after auth, but that isn't the case. For example:. ```; $ hailctl dataproc connect --beta foo nb; usage: hailctl [-h] {version,dataproc,auth,dev,batch,curl,config} ...; hailctl: error: unrecognized arguments: --beta; ```. I will keep investigating a fix for this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9836
https://github.com/hail-is/hail/issues/9837:400,Availability,avail,available,400,"Hi all,; I used hail 0.2 and made my own hail referene genome for a plant other than human by faking the X, Y and Par. But I can not find anywhere to setup my own reference genome even I know there is hl.init method which can set different version of human reference genome, and there is no set_reference method which is the counterpart of hl.get_reference().; How can I make my own reference genome available in hail0.2? Thanks a lot!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9837
https://github.com/hail-is/hail/pull/9842:784,Availability,error,error,784,"This PR rewrites the hailctl command line argument parsing code. While the interface remains largely the same, a few changes were made to how options are handled. We first introduce a bit of terminology. In a shell command invocation like `$ cmd a -o c`, `a`, `-o` and `c` are called parameters. `a` and `c` which do not start with dashes, are called arguments. `-o`, which starts with a dash, is an option. This PR makes the following changes:. - For dataproc commands taking extra gcloud parameters, all parameters after a double-dash (--) are passed to gcloud.; - The actual rule is slightly more complicated, but I think the above rule is the right take away. In detail, extra parameters are passed to gcloud. Unknown options (starting with a dash) before `--` are reported as an error. So arguments (not options) before `--` and all parameters after are passed to gcloud. ; - Short options don't need a `=` when specifying a value. It is now `-p2`, not `-p=2`.; - While I was making breaking changes, I changed `dataproc submit` `--gcloud_configuration` to `--gcloud-configuration`. I am happy to undo this one.; - Group arguments must go before the next command. Write `hailctl dataproc --beta start ...` not `hailctl dataproc start --beta ...`, which is an error since `start` has no option `--beta`. This PR rewrites argument parsing to use click instead of argparse: https://click.palletsprojects.com/en/7.x/. Things you need to know about click:; - A group is a group of commands or subgroups, like `hailctl dataproc`, `hailctl batch`, etc. Groups are defined like this:; ; ```; @hailctl.group(; help=""Manage the Hail Batch service.""); def batch():; pass; ```; - A command in a group is defined like this:. ```; @batch.command(; help=""Get a particular batch's info.""); @click.argument('batch_id', type=int); @click.option('--output-format', '-o',; type=click.Choice(['yaml', 'json']),; default='yaml', show_default=True,; help=""Specify output format"",); def get(batch_id, output_format):; ..",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9842
https://github.com/hail-is/hail/pull/9842:1264,Availability,error,error,1264,"alled parameters. `a` and `c` which do not start with dashes, are called arguments. `-o`, which starts with a dash, is an option. This PR makes the following changes:. - For dataproc commands taking extra gcloud parameters, all parameters after a double-dash (--) are passed to gcloud.; - The actual rule is slightly more complicated, but I think the above rule is the right take away. In detail, extra parameters are passed to gcloud. Unknown options (starting with a dash) before `--` are reported as an error. So arguments (not options) before `--` and all parameters after are passed to gcloud. ; - Short options don't need a `=` when specifying a value. It is now `-p2`, not `-p=2`.; - While I was making breaking changes, I changed `dataproc submit` `--gcloud_configuration` to `--gcloud-configuration`. I am happy to undo this one.; - Group arguments must go before the next command. Write `hailctl dataproc --beta start ...` not `hailctl dataproc start --beta ...`, which is an error since `start` has no option `--beta`. This PR rewrites argument parsing to use click instead of argparse: https://click.palletsprojects.com/en/7.x/. Things you need to know about click:; - A group is a group of commands or subgroups, like `hailctl dataproc`, `hailctl batch`, etc. Groups are defined like this:; ; ```; @hailctl.group(; help=""Manage the Hail Batch service.""); def batch():; pass; ```; - A command in a group is defined like this:. ```; @batch.command(; help=""Get a particular batch's info.""); @click.argument('batch_id', type=int); @click.option('--output-format', '-o',; type=click.Choice(['yaml', 'json']),; default='yaml', show_default=True,; help=""Specify output format"",); def get(batch_id, output_format):; ...; ```. The command decorator replaces the function with one that takes a `List[str]` of command line parameters, parses them, and calls the original function. The option options are pretty self-explanatory. - To access an argument to a group (like `dataproc --beta`) in a (sub",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9842
https://github.com/hail-is/hail/pull/9842:3194,Availability,down,down,3194,"ormat):; ...; ```. The command decorator replaces the function with one that takes a `List[str]` of command line parameters, parses them, and calls the original function. The option options are pretty self-explanatory. - To access an argument to a group (like `dataproc --beta`) in a (sub)command, use the decorator `click.pass_context` to pass the click context which allows you to access parent group parameters. `dataproc start` is an example:. ```; @dataproc.command(; help=""Start a Dataproc cluster configured for Hail.""); @click.argument('cluster_name'); ...; @click.pass_context; def start(ctx, cluster_name, ...):; beta = ctx.parent.params['beta']; ```. The help output for a group looks like this:. ```; $ hailctl dataproc --help; Usage: hailctl dataproc [OPTIONS] COMMAND [ARGS]... Manage and monitor Hail deployments. Options:; --beta Force use of `beta` in gcloud commands; --help Show this message and exit. Commands:; connect Connect to a running Dataproc cluster; describe Gather information about a Hail (Table or MatrixTable) file...; diagnose Diagnose problems in a Dataproc cluster.; list List Dataproc clusters.; modify; start Start a Dataproc cluster configured for Hail.; stop Shut down a Dataproc cluster.; submit Submit a Python script to a running Dataproc cluster.; ```. The help output for a command looks like:. ```; $ hailctl batch get --help; Usage: hailctl batch get [OPTIONS] BATCH_ID. Get a particular batch's info. Options:; -o, --output-format [yaml|json]; Specify output format [default: yaml]; --help Show this message and exit.; ```. I also made `BatchClient` a context manager and made the default limit unbounded in `BatchClient.list_batches`. I have marked this WIP until we are happy with the interface changes and how we're going to communicate them to the users. CHANGELOG: Rewrote the hailctl argument parsing code, which made some incompatible changes to the way hailctl handles arguments. For more details, see [the URL of this PR]. Spice level: medium.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9842
https://github.com/hail-is/hail/pull/9842:1072,Deployability,configurat,configuration,1072,"tl command line argument parsing code. While the interface remains largely the same, a few changes were made to how options are handled. We first introduce a bit of terminology. In a shell command invocation like `$ cmd a -o c`, `a`, `-o` and `c` are called parameters. `a` and `c` which do not start with dashes, are called arguments. `-o`, which starts with a dash, is an option. This PR makes the following changes:. - For dataproc commands taking extra gcloud parameters, all parameters after a double-dash (--) are passed to gcloud.; - The actual rule is slightly more complicated, but I think the above rule is the right take away. In detail, extra parameters are passed to gcloud. Unknown options (starting with a dash) before `--` are reported as an error. So arguments (not options) before `--` and all parameters after are passed to gcloud. ; - Short options don't need a `=` when specifying a value. It is now `-p2`, not `-p=2`.; - While I was making breaking changes, I changed `dataproc submit` `--gcloud_configuration` to `--gcloud-configuration`. I am happy to undo this one.; - Group arguments must go before the next command. Write `hailctl dataproc --beta start ...` not `hailctl dataproc start --beta ...`, which is an error since `start` has no option `--beta`. This PR rewrites argument parsing to use click instead of argparse: https://click.palletsprojects.com/en/7.x/. Things you need to know about click:; - A group is a group of commands or subgroups, like `hailctl dataproc`, `hailctl batch`, etc. Groups are defined like this:; ; ```; @hailctl.group(; help=""Manage the Hail Batch service.""); def batch():; pass; ```; - A command in a group is defined like this:. ```; @batch.command(; help=""Get a particular batch's info.""); @click.argument('batch_id', type=int); @click.option('--output-format', '-o',; type=click.Choice(['yaml', 'json']),; default='yaml', show_default=True,; help=""Specify output format"",); def get(batch_id, output_format):; ...; ```. The command decor",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9842
https://github.com/hail-is/hail/pull/9842:2806,Deployability,deploy,deployments,2806,"ch_id', type=int); @click.option('--output-format', '-o',; type=click.Choice(['yaml', 'json']),; default='yaml', show_default=True,; help=""Specify output format"",); def get(batch_id, output_format):; ...; ```. The command decorator replaces the function with one that takes a `List[str]` of command line parameters, parses them, and calls the original function. The option options are pretty self-explanatory. - To access an argument to a group (like `dataproc --beta`) in a (sub)command, use the decorator `click.pass_context` to pass the click context which allows you to access parent group parameters. `dataproc start` is an example:. ```; @dataproc.command(; help=""Start a Dataproc cluster configured for Hail.""); @click.argument('cluster_name'); ...; @click.pass_context; def start(ctx, cluster_name, ...):; beta = ctx.parent.params['beta']; ```. The help output for a group looks like this:. ```; $ hailctl dataproc --help; Usage: hailctl dataproc [OPTIONS] COMMAND [ARGS]... Manage and monitor Hail deployments. Options:; --beta Force use of `beta` in gcloud commands; --help Show this message and exit. Commands:; connect Connect to a running Dataproc cluster; describe Gather information about a Hail (Table or MatrixTable) file...; diagnose Diagnose problems in a Dataproc cluster.; list List Dataproc clusters.; modify; start Start a Dataproc cluster configured for Hail.; stop Shut down a Dataproc cluster.; submit Submit a Python script to a running Dataproc cluster.; ```. The help output for a command looks like:. ```; $ hailctl batch get --help; Usage: hailctl batch get [OPTIONS] BATCH_ID. Get a particular batch's info. Options:; -o, --output-format [yaml|json]; Specify output format [default: yaml]; --help Show this message and exit.; ```. I also made `BatchClient` a context manager and made the default limit unbounded in `BatchClient.list_batches`. I have marked this WIP until we are happy with the interface changes and how we're going to communicate them to the users. CHA",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9842
https://github.com/hail-is/hail/pull/9842:2793,Energy Efficiency,monitor,monitor,2793,"ch_id', type=int); @click.option('--output-format', '-o',; type=click.Choice(['yaml', 'json']),; default='yaml', show_default=True,; help=""Specify output format"",); def get(batch_id, output_format):; ...; ```. The command decorator replaces the function with one that takes a `List[str]` of command line parameters, parses them, and calls the original function. The option options are pretty self-explanatory. - To access an argument to a group (like `dataproc --beta`) in a (sub)command, use the decorator `click.pass_context` to pass the click context which allows you to access parent group parameters. `dataproc start` is an example:. ```; @dataproc.command(; help=""Start a Dataproc cluster configured for Hail.""); @click.argument('cluster_name'); ...; @click.pass_context; def start(ctx, cluster_name, ...):; beta = ctx.parent.params['beta']; ```. The help output for a group looks like this:. ```; $ hailctl dataproc --help; Usage: hailctl dataproc [OPTIONS] COMMAND [ARGS]... Manage and monitor Hail deployments. Options:; --beta Force use of `beta` in gcloud commands; --help Show this message and exit. Commands:; connect Connect to a running Dataproc cluster; describe Gather information about a Hail (Table or MatrixTable) file...; diagnose Diagnose problems in a Dataproc cluster.; list List Dataproc clusters.; modify; start Start a Dataproc cluster configured for Hail.; stop Shut down a Dataproc cluster.; submit Submit a Python script to a running Dataproc cluster.; ```. The help output for a command looks like:. ```; $ hailctl batch get --help; Usage: hailctl batch get [OPTIONS] BATCH_ID. Get a particular batch's info. Options:; -o, --output-format [yaml|json]; Specify output format [default: yaml]; --help Show this message and exit.; ```. I also made `BatchClient` a context manager and made the default limit unbounded in `BatchClient.list_batches`. I have marked this WIP until we are happy with the interface changes and how we're going to communicate them to the users. CHA",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9842
https://github.com/hail-is/hail/pull/9842:75,Integrability,interface,interface,75,"This PR rewrites the hailctl command line argument parsing code. While the interface remains largely the same, a few changes were made to how options are handled. We first introduce a bit of terminology. In a shell command invocation like `$ cmd a -o c`, `a`, `-o` and `c` are called parameters. `a` and `c` which do not start with dashes, are called arguments. `-o`, which starts with a dash, is an option. This PR makes the following changes:. - For dataproc commands taking extra gcloud parameters, all parameters after a double-dash (--) are passed to gcloud.; - The actual rule is slightly more complicated, but I think the above rule is the right take away. In detail, extra parameters are passed to gcloud. Unknown options (starting with a dash) before `--` are reported as an error. So arguments (not options) before `--` and all parameters after are passed to gcloud. ; - Short options don't need a `=` when specifying a value. It is now `-p2`, not `-p=2`.; - While I was making breaking changes, I changed `dataproc submit` `--gcloud_configuration` to `--gcloud-configuration`. I am happy to undo this one.; - Group arguments must go before the next command. Write `hailctl dataproc --beta start ...` not `hailctl dataproc start --beta ...`, which is an error since `start` has no option `--beta`. This PR rewrites argument parsing to use click instead of argparse: https://click.palletsprojects.com/en/7.x/. Things you need to know about click:; - A group is a group of commands or subgroups, like `hailctl dataproc`, `hailctl batch`, etc. Groups are defined like this:; ; ```; @hailctl.group(; help=""Manage the Hail Batch service.""); def batch():; pass; ```; - A command in a group is defined like this:. ```; @batch.command(; help=""Get a particular batch's info.""); @click.argument('batch_id', type=int); @click.option('--output-format', '-o',; type=click.Choice(['yaml', 'json']),; default='yaml', show_default=True,; help=""Specify output format"",); def get(batch_id, output_format):; ..",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9842
https://github.com/hail-is/hail/pull/9842:2893,Integrability,message,message,2893,"lick.Choice(['yaml', 'json']),; default='yaml', show_default=True,; help=""Specify output format"",); def get(batch_id, output_format):; ...; ```. The command decorator replaces the function with one that takes a `List[str]` of command line parameters, parses them, and calls the original function. The option options are pretty self-explanatory. - To access an argument to a group (like `dataproc --beta`) in a (sub)command, use the decorator `click.pass_context` to pass the click context which allows you to access parent group parameters. `dataproc start` is an example:. ```; @dataproc.command(; help=""Start a Dataproc cluster configured for Hail.""); @click.argument('cluster_name'); ...; @click.pass_context; def start(ctx, cluster_name, ...):; beta = ctx.parent.params['beta']; ```. The help output for a group looks like this:. ```; $ hailctl dataproc --help; Usage: hailctl dataproc [OPTIONS] COMMAND [ARGS]... Manage and monitor Hail deployments. Options:; --beta Force use of `beta` in gcloud commands; --help Show this message and exit. Commands:; connect Connect to a running Dataproc cluster; describe Gather information about a Hail (Table or MatrixTable) file...; diagnose Diagnose problems in a Dataproc cluster.; list List Dataproc clusters.; modify; start Start a Dataproc cluster configured for Hail.; stop Shut down a Dataproc cluster.; submit Submit a Python script to a running Dataproc cluster.; ```. The help output for a command looks like:. ```; $ hailctl batch get --help; Usage: hailctl batch get [OPTIONS] BATCH_ID. Get a particular batch's info. Options:; -o, --output-format [yaml|json]; Specify output format [default: yaml]; --help Show this message and exit.; ```. I also made `BatchClient` a context manager and made the default limit unbounded in `BatchClient.list_batches`. I have marked this WIP until we are happy with the interface changes and how we're going to communicate them to the users. CHANGELOG: Rewrote the hailctl argument parsing code, which made so",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9842
https://github.com/hail-is/hail/pull/9842:3538,Integrability,message,message,3538,"ormat):; ...; ```. The command decorator replaces the function with one that takes a `List[str]` of command line parameters, parses them, and calls the original function. The option options are pretty self-explanatory. - To access an argument to a group (like `dataproc --beta`) in a (sub)command, use the decorator `click.pass_context` to pass the click context which allows you to access parent group parameters. `dataproc start` is an example:. ```; @dataproc.command(; help=""Start a Dataproc cluster configured for Hail.""); @click.argument('cluster_name'); ...; @click.pass_context; def start(ctx, cluster_name, ...):; beta = ctx.parent.params['beta']; ```. The help output for a group looks like this:. ```; $ hailctl dataproc --help; Usage: hailctl dataproc [OPTIONS] COMMAND [ARGS]... Manage and monitor Hail deployments. Options:; --beta Force use of `beta` in gcloud commands; --help Show this message and exit. Commands:; connect Connect to a running Dataproc cluster; describe Gather information about a Hail (Table or MatrixTable) file...; diagnose Diagnose problems in a Dataproc cluster.; list List Dataproc clusters.; modify; start Start a Dataproc cluster configured for Hail.; stop Shut down a Dataproc cluster.; submit Submit a Python script to a running Dataproc cluster.; ```. The help output for a command looks like:. ```; $ hailctl batch get --help; Usage: hailctl batch get [OPTIONS] BATCH_ID. Get a particular batch's info. Options:; -o, --output-format [yaml|json]; Specify output format [default: yaml]; --help Show this message and exit.; ```. I also made `BatchClient` a context manager and made the default limit unbounded in `BatchClient.list_batches`. I have marked this WIP until we are happy with the interface changes and how we're going to communicate them to the users. CHANGELOG: Rewrote the hailctl argument parsing code, which made some incompatible changes to the way hailctl handles arguments. For more details, see [the URL of this PR]. Spice level: medium.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9842
https://github.com/hail-is/hail/pull/9842:3725,Integrability,interface,interface,3725,"ormat):; ...; ```. The command decorator replaces the function with one that takes a `List[str]` of command line parameters, parses them, and calls the original function. The option options are pretty self-explanatory. - To access an argument to a group (like `dataproc --beta`) in a (sub)command, use the decorator `click.pass_context` to pass the click context which allows you to access parent group parameters. `dataproc start` is an example:. ```; @dataproc.command(; help=""Start a Dataproc cluster configured for Hail.""); @click.argument('cluster_name'); ...; @click.pass_context; def start(ctx, cluster_name, ...):; beta = ctx.parent.params['beta']; ```. The help output for a group looks like this:. ```; $ hailctl dataproc --help; Usage: hailctl dataproc [OPTIONS] COMMAND [ARGS]... Manage and monitor Hail deployments. Options:; --beta Force use of `beta` in gcloud commands; --help Show this message and exit. Commands:; connect Connect to a running Dataproc cluster; describe Gather information about a Hail (Table or MatrixTable) file...; diagnose Diagnose problems in a Dataproc cluster.; list List Dataproc clusters.; modify; start Start a Dataproc cluster configured for Hail.; stop Shut down a Dataproc cluster.; submit Submit a Python script to a running Dataproc cluster.; ```. The help output for a command looks like:. ```; $ hailctl batch get --help; Usage: hailctl batch get [OPTIONS] BATCH_ID. Get a particular batch's info. Options:; -o, --output-format [yaml|json]; Specify output format [default: yaml]; --help Show this message and exit.; ```. I also made `BatchClient` a context manager and made the default limit unbounded in `BatchClient.list_batches`. I have marked this WIP until we are happy with the interface changes and how we're going to communicate them to the users. CHANGELOG: Rewrote the hailctl argument parsing code, which made some incompatible changes to the way hailctl handles arguments. For more details, see [the URL of this PR]. Spice level: medium.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9842
https://github.com/hail-is/hail/pull/9842:8,Modifiability,rewrite,rewrites,8,"This PR rewrites the hailctl command line argument parsing code. While the interface remains largely the same, a few changes were made to how options are handled. We first introduce a bit of terminology. In a shell command invocation like `$ cmd a -o c`, `a`, `-o` and `c` are called parameters. `a` and `c` which do not start with dashes, are called arguments. `-o`, which starts with a dash, is an option. This PR makes the following changes:. - For dataproc commands taking extra gcloud parameters, all parameters after a double-dash (--) are passed to gcloud.; - The actual rule is slightly more complicated, but I think the above rule is the right take away. In detail, extra parameters are passed to gcloud. Unknown options (starting with a dash) before `--` are reported as an error. So arguments (not options) before `--` and all parameters after are passed to gcloud. ; - Short options don't need a `=` when specifying a value. It is now `-p2`, not `-p=2`.; - While I was making breaking changes, I changed `dataproc submit` `--gcloud_configuration` to `--gcloud-configuration`. I am happy to undo this one.; - Group arguments must go before the next command. Write `hailctl dataproc --beta start ...` not `hailctl dataproc start --beta ...`, which is an error since `start` has no option `--beta`. This PR rewrites argument parsing to use click instead of argparse: https://click.palletsprojects.com/en/7.x/. Things you need to know about click:; - A group is a group of commands or subgroups, like `hailctl dataproc`, `hailctl batch`, etc. Groups are defined like this:; ; ```; @hailctl.group(; help=""Manage the Hail Batch service.""); def batch():; pass; ```; - A command in a group is defined like this:. ```; @batch.command(; help=""Get a particular batch's info.""); @click.argument('batch_id', type=int); @click.option('--output-format', '-o',; type=click.Choice(['yaml', 'json']),; default='yaml', show_default=True,; help=""Specify output format"",); def get(batch_id, output_format):; ..",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9842
https://github.com/hail-is/hail/pull/9842:1072,Modifiability,config,configuration,1072,"tl command line argument parsing code. While the interface remains largely the same, a few changes were made to how options are handled. We first introduce a bit of terminology. In a shell command invocation like `$ cmd a -o c`, `a`, `-o` and `c` are called parameters. `a` and `c` which do not start with dashes, are called arguments. `-o`, which starts with a dash, is an option. This PR makes the following changes:. - For dataproc commands taking extra gcloud parameters, all parameters after a double-dash (--) are passed to gcloud.; - The actual rule is slightly more complicated, but I think the above rule is the right take away. In detail, extra parameters are passed to gcloud. Unknown options (starting with a dash) before `--` are reported as an error. So arguments (not options) before `--` and all parameters after are passed to gcloud. ; - Short options don't need a `=` when specifying a value. It is now `-p2`, not `-p=2`.; - While I was making breaking changes, I changed `dataproc submit` `--gcloud_configuration` to `--gcloud-configuration`. I am happy to undo this one.; - Group arguments must go before the next command. Write `hailctl dataproc --beta start ...` not `hailctl dataproc start --beta ...`, which is an error since `start` has no option `--beta`. This PR rewrites argument parsing to use click instead of argparse: https://click.palletsprojects.com/en/7.x/. Things you need to know about click:; - A group is a group of commands or subgroups, like `hailctl dataproc`, `hailctl batch`, etc. Groups are defined like this:; ; ```; @hailctl.group(; help=""Manage the Hail Batch service.""); def batch():; pass; ```; - A command in a group is defined like this:. ```; @batch.command(; help=""Get a particular batch's info.""); @click.argument('batch_id', type=int); @click.option('--output-format', '-o',; type=click.Choice(['yaml', 'json']),; default='yaml', show_default=True,; help=""Specify output format"",); def get(batch_id, output_format):; ...; ```. The command decor",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9842
https://github.com/hail-is/hail/pull/9842:1316,Modifiability,rewrite,rewrites,1316,"ed arguments. `-o`, which starts with a dash, is an option. This PR makes the following changes:. - For dataproc commands taking extra gcloud parameters, all parameters after a double-dash (--) are passed to gcloud.; - The actual rule is slightly more complicated, but I think the above rule is the right take away. In detail, extra parameters are passed to gcloud. Unknown options (starting with a dash) before `--` are reported as an error. So arguments (not options) before `--` and all parameters after are passed to gcloud. ; - Short options don't need a `=` when specifying a value. It is now `-p2`, not `-p=2`.; - While I was making breaking changes, I changed `dataproc submit` `--gcloud_configuration` to `--gcloud-configuration`. I am happy to undo this one.; - Group arguments must go before the next command. Write `hailctl dataproc --beta start ...` not `hailctl dataproc start --beta ...`, which is an error since `start` has no option `--beta`. This PR rewrites argument parsing to use click instead of argparse: https://click.palletsprojects.com/en/7.x/. Things you need to know about click:; - A group is a group of commands or subgroups, like `hailctl dataproc`, `hailctl batch`, etc. Groups are defined like this:; ; ```; @hailctl.group(; help=""Manage the Hail Batch service.""); def batch():; pass; ```; - A command in a group is defined like this:. ```; @batch.command(; help=""Get a particular batch's info.""); @click.argument('batch_id', type=int); @click.option('--output-format', '-o',; type=click.Choice(['yaml', 'json']),; default='yaml', show_default=True,; help=""Specify output format"",); def get(batch_id, output_format):; ...; ```. The command decorator replaces the function with one that takes a `List[str]` of command line parameters, parses them, and calls the original function. The option options are pretty self-explanatory. - To access an argument to a group (like `dataproc --beta`) in a (sub)command, use the decorator `click.pass_context` to pass the click cont",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9842
https://github.com/hail-is/hail/pull/9842:2494,Modifiability,config,configured,2494,"mmands or subgroups, like `hailctl dataproc`, `hailctl batch`, etc. Groups are defined like this:; ; ```; @hailctl.group(; help=""Manage the Hail Batch service.""); def batch():; pass; ```; - A command in a group is defined like this:. ```; @batch.command(; help=""Get a particular batch's info.""); @click.argument('batch_id', type=int); @click.option('--output-format', '-o',; type=click.Choice(['yaml', 'json']),; default='yaml', show_default=True,; help=""Specify output format"",); def get(batch_id, output_format):; ...; ```. The command decorator replaces the function with one that takes a `List[str]` of command line parameters, parses them, and calls the original function. The option options are pretty self-explanatory. - To access an argument to a group (like `dataproc --beta`) in a (sub)command, use the decorator `click.pass_context` to pass the click context which allows you to access parent group parameters. `dataproc start` is an example:. ```; @dataproc.command(; help=""Start a Dataproc cluster configured for Hail.""); @click.argument('cluster_name'); ...; @click.pass_context; def start(ctx, cluster_name, ...):; beta = ctx.parent.params['beta']; ```. The help output for a group looks like this:. ```; $ hailctl dataproc --help; Usage: hailctl dataproc [OPTIONS] COMMAND [ARGS]... Manage and monitor Hail deployments. Options:; --beta Force use of `beta` in gcloud commands; --help Show this message and exit. Commands:; connect Connect to a running Dataproc cluster; describe Gather information about a Hail (Table or MatrixTable) file...; diagnose Diagnose problems in a Dataproc cluster.; list List Dataproc clusters.; modify; start Start a Dataproc cluster configured for Hail.; stop Shut down a Dataproc cluster.; submit Submit a Python script to a running Dataproc cluster.; ```. The help output for a command looks like:. ```; $ hailctl batch get --help; Usage: hailctl batch get [OPTIONS] BATCH_ID. Get a particular batch's info. Options:; -o, --output-format [yaml|json]; Sp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9842
https://github.com/hail-is/hail/pull/9842:3162,Modifiability,config,configured,3162,"ormat):; ...; ```. The command decorator replaces the function with one that takes a `List[str]` of command line parameters, parses them, and calls the original function. The option options are pretty self-explanatory. - To access an argument to a group (like `dataproc --beta`) in a (sub)command, use the decorator `click.pass_context` to pass the click context which allows you to access parent group parameters. `dataproc start` is an example:. ```; @dataproc.command(; help=""Start a Dataproc cluster configured for Hail.""); @click.argument('cluster_name'); ...; @click.pass_context; def start(ctx, cluster_name, ...):; beta = ctx.parent.params['beta']; ```. The help output for a group looks like this:. ```; $ hailctl dataproc --help; Usage: hailctl dataproc [OPTIONS] COMMAND [ARGS]... Manage and monitor Hail deployments. Options:; --beta Force use of `beta` in gcloud commands; --help Show this message and exit. Commands:; connect Connect to a running Dataproc cluster; describe Gather information about a Hail (Table or MatrixTable) file...; diagnose Diagnose problems in a Dataproc cluster.; list List Dataproc clusters.; modify; start Start a Dataproc cluster configured for Hail.; stop Shut down a Dataproc cluster.; submit Submit a Python script to a running Dataproc cluster.; ```. The help output for a command looks like:. ```; $ hailctl batch get --help; Usage: hailctl batch get [OPTIONS] BATCH_ID. Get a particular batch's info. Options:; -o, --output-format [yaml|json]; Specify output format [default: yaml]; --help Show this message and exit.; ```. I also made `BatchClient` a context manager and made the default limit unbounded in `BatchClient.list_batches`. I have marked this WIP until we are happy with the interface changes and how we're going to communicate them to the users. CHANGELOG: Rewrote the hailctl argument parsing code, which made some incompatible changes to the way hailctl handles arguments. For more details, see [the URL of this PR]. Spice level: medium.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9842
https://github.com/hail-is/hail/pull/9842:2214,Security,access,access,2214," an error since `start` has no option `--beta`. This PR rewrites argument parsing to use click instead of argparse: https://click.palletsprojects.com/en/7.x/. Things you need to know about click:; - A group is a group of commands or subgroups, like `hailctl dataproc`, `hailctl batch`, etc. Groups are defined like this:; ; ```; @hailctl.group(; help=""Manage the Hail Batch service.""); def batch():; pass; ```; - A command in a group is defined like this:. ```; @batch.command(; help=""Get a particular batch's info.""); @click.argument('batch_id', type=int); @click.option('--output-format', '-o',; type=click.Choice(['yaml', 'json']),; default='yaml', show_default=True,; help=""Specify output format"",); def get(batch_id, output_format):; ...; ```. The command decorator replaces the function with one that takes a `List[str]` of command line parameters, parses them, and calls the original function. The option options are pretty self-explanatory. - To access an argument to a group (like `dataproc --beta`) in a (sub)command, use the decorator `click.pass_context` to pass the click context which allows you to access parent group parameters. `dataproc start` is an example:. ```; @dataproc.command(; help=""Start a Dataproc cluster configured for Hail.""); @click.argument('cluster_name'); ...; @click.pass_context; def start(ctx, cluster_name, ...):; beta = ctx.parent.params['beta']; ```. The help output for a group looks like this:. ```; $ hailctl dataproc --help; Usage: hailctl dataproc [OPTIONS] COMMAND [ARGS]... Manage and monitor Hail deployments. Options:; --beta Force use of `beta` in gcloud commands; --help Show this message and exit. Commands:; connect Connect to a running Dataproc cluster; describe Gather information about a Hail (Table or MatrixTable) file...; diagnose Diagnose problems in a Dataproc cluster.; list List Dataproc clusters.; modify; start Start a Dataproc cluster configured for Hail.; stop Shut down a Dataproc cluster.; submit Submit a Python script to a runnin",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9842
https://github.com/hail-is/hail/pull/9842:2373,Security,access,access,2373,"tead of argparse: https://click.palletsprojects.com/en/7.x/. Things you need to know about click:; - A group is a group of commands or subgroups, like `hailctl dataproc`, `hailctl batch`, etc. Groups are defined like this:; ; ```; @hailctl.group(; help=""Manage the Hail Batch service.""); def batch():; pass; ```; - A command in a group is defined like this:. ```; @batch.command(; help=""Get a particular batch's info.""); @click.argument('batch_id', type=int); @click.option('--output-format', '-o',; type=click.Choice(['yaml', 'json']),; default='yaml', show_default=True,; help=""Specify output format"",); def get(batch_id, output_format):; ...; ```. The command decorator replaces the function with one that takes a `List[str]` of command line parameters, parses them, and calls the original function. The option options are pretty self-explanatory. - To access an argument to a group (like `dataproc --beta`) in a (sub)command, use the decorator `click.pass_context` to pass the click context which allows you to access parent group parameters. `dataproc start` is an example:. ```; @dataproc.command(; help=""Start a Dataproc cluster configured for Hail.""); @click.argument('cluster_name'); ...; @click.pass_context; def start(ctx, cluster_name, ...):; beta = ctx.parent.params['beta']; ```. The help output for a group looks like this:. ```; $ hailctl dataproc --help; Usage: hailctl dataproc [OPTIONS] COMMAND [ARGS]... Manage and monitor Hail deployments. Options:; --beta Force use of `beta` in gcloud commands; --help Show this message and exit. Commands:; connect Connect to a running Dataproc cluster; describe Gather information about a Hail (Table or MatrixTable) file...; diagnose Diagnose problems in a Dataproc cluster.; list List Dataproc clusters.; modify; start Start a Dataproc cluster configured for Hail.; stop Shut down a Dataproc cluster.; submit Submit a Python script to a running Dataproc cluster.; ```. The help output for a command looks like:. ```; $ hailctl batch get --he",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9842
https://github.com/hail-is/hail/pull/9842:1102,Usability,undo,undo,1102,"the same, a few changes were made to how options are handled. We first introduce a bit of terminology. In a shell command invocation like `$ cmd a -o c`, `a`, `-o` and `c` are called parameters. `a` and `c` which do not start with dashes, are called arguments. `-o`, which starts with a dash, is an option. This PR makes the following changes:. - For dataproc commands taking extra gcloud parameters, all parameters after a double-dash (--) are passed to gcloud.; - The actual rule is slightly more complicated, but I think the above rule is the right take away. In detail, extra parameters are passed to gcloud. Unknown options (starting with a dash) before `--` are reported as an error. So arguments (not options) before `--` and all parameters after are passed to gcloud. ; - Short options don't need a `=` when specifying a value. It is now `-p2`, not `-p=2`.; - While I was making breaking changes, I changed `dataproc submit` `--gcloud_configuration` to `--gcloud-configuration`. I am happy to undo this one.; - Group arguments must go before the next command. Write `hailctl dataproc --beta start ...` not `hailctl dataproc start --beta ...`, which is an error since `start` has no option `--beta`. This PR rewrites argument parsing to use click instead of argparse: https://click.palletsprojects.com/en/7.x/. Things you need to know about click:; - A group is a group of commands or subgroups, like `hailctl dataproc`, `hailctl batch`, etc. Groups are defined like this:; ; ```; @hailctl.group(; help=""Manage the Hail Batch service.""); def batch():; pass; ```; - A command in a group is defined like this:. ```; @batch.command(; help=""Get a particular batch's info.""); @click.argument('batch_id', type=int); @click.option('--output-format', '-o',; type=click.Choice(['yaml', 'json']),; default='yaml', show_default=True,; help=""Specify output format"",); def get(batch_id, output_format):; ...; ```. The command decorator replaces the function with one that takes a `List[str]` of command line",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9842
https://github.com/hail-is/hail/pull/9843:58,Availability,error,error,58,"Currently, attempting to bit shift by zero bits throws an error. ```; $ hl.eval(hl.bit_rshift(4, 0)); HailUserError: Error summary: HailException: cannot shift by a negative value: 4 >> 0; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9843
https://github.com/hail-is/hail/pull/9843:117,Availability,Error,Error,117,"Currently, attempting to bit shift by zero bits throws an error. ```; $ hl.eval(hl.bit_rshift(4, 0)); HailUserError: Error summary: HailException: cannot shift by a negative value: 4 >> 0; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9843
https://github.com/hail-is/hail/pull/9844:55,Deployability,deploy,deploys,55,"This particularly important for rapid iteration in dev deploys. I can enable the standing worker; while I am working. I disable it when I head off to a series of meetings and then re-enable it; when I return. @jigold I think this will conflict with your worker pool change because I replace ""1 means boolean true"" with a checkbox.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9844
https://github.com/hail-is/hail/pull/9845:53,Availability,error,error,53,Google considers any message written to stderr as an error.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9845
https://github.com/hail-is/hail/pull/9845:21,Integrability,message,message,21,Google considers any message written to stderr as an error.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9845
https://github.com/hail-is/hail/pull/9848:804,Deployability,configurat,configuration,804,"This PR enables shuffling in the service. It is stacked on several other PRs, so look only at the; most recent commit. Some highlights:; - Open the public network back up. We should probably make query jobs special so that they can; access the internal network. To do that, batch would need to accept a ""acting on behalf of"" user; account: Query submits the job using its account ""acting on behalf of"" the user. Batch allows; query to use the private network, but for all other purposes, the job is owned by the user. - Allow public access to some the `gcr.io/hail-vdc/query` Docker image. - Automatically rewrite uses of `hailgenetics/` Docker images to their `gcr.io` equivalents. - Move `deploy_address` above `deploy_query` so that query can depend on address (necessary for; shufles). - Fix logging configuration. Services team wants all logs all the time to go to stdout. - Implement lowerDistributedSort using the shuffler. - Allow shuffle ids to be encoded so they can be used in `Literal`.; Unified Split",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9848
https://github.com/hail-is/hail/pull/9848:746,Integrability,depend,depend,746,"This PR enables shuffling in the service. It is stacked on several other PRs, so look only at the; most recent commit. Some highlights:; - Open the public network back up. We should probably make query jobs special so that they can; access the internal network. To do that, batch would need to accept a ""acting on behalf of"" user; account: Query submits the job using its account ""acting on behalf of"" the user. Batch allows; query to use the private network, but for all other purposes, the job is owned by the user. - Allow public access to some the `gcr.io/hail-vdc/query` Docker image. - Automatically rewrite uses of `hailgenetics/` Docker images to their `gcr.io` equivalents. - Move `deploy_address` above `deploy_query` so that query can depend on address (necessary for; shufles). - Fix logging configuration. Services team wants all logs all the time to go to stdout. - Implement lowerDistributedSort using the shuffler. - Allow shuffle ids to be encoded so they can be used in `Literal`.; Unified Split",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9848
https://github.com/hail-is/hail/pull/9848:606,Modifiability,rewrite,rewrite,606,"This PR enables shuffling in the service. It is stacked on several other PRs, so look only at the; most recent commit. Some highlights:; - Open the public network back up. We should probably make query jobs special so that they can; access the internal network. To do that, batch would need to accept a ""acting on behalf of"" user; account: Query submits the job using its account ""acting on behalf of"" the user. Batch allows; query to use the private network, but for all other purposes, the job is owned by the user. - Allow public access to some the `gcr.io/hail-vdc/query` Docker image. - Automatically rewrite uses of `hailgenetics/` Docker images to their `gcr.io` equivalents. - Move `deploy_address` above `deploy_query` so that query can depend on address (necessary for; shufles). - Fix logging configuration. Services team wants all logs all the time to go to stdout. - Implement lowerDistributedSort using the shuffler. - Allow shuffle ids to be encoded so they can be used in `Literal`.; Unified Split",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9848
https://github.com/hail-is/hail/pull/9848:804,Modifiability,config,configuration,804,"This PR enables shuffling in the service. It is stacked on several other PRs, so look only at the; most recent commit. Some highlights:; - Open the public network back up. We should probably make query jobs special so that they can; access the internal network. To do that, batch would need to accept a ""acting on behalf of"" user; account: Query submits the job using its account ""acting on behalf of"" the user. Batch allows; query to use the private network, but for all other purposes, the job is owned by the user. - Allow public access to some the `gcr.io/hail-vdc/query` Docker image. - Automatically rewrite uses of `hailgenetics/` Docker images to their `gcr.io` equivalents. - Move `deploy_address` above `deploy_query` so that query can depend on address (necessary for; shufles). - Fix logging configuration. Services team wants all logs all the time to go to stdout. - Implement lowerDistributedSort using the shuffler. - Allow shuffle ids to be encoded so they can be used in `Literal`.; Unified Split",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9848
https://github.com/hail-is/hail/pull/9848:233,Security,access,access,233,"This PR enables shuffling in the service. It is stacked on several other PRs, so look only at the; most recent commit. Some highlights:; - Open the public network back up. We should probably make query jobs special so that they can; access the internal network. To do that, batch would need to accept a ""acting on behalf of"" user; account: Query submits the job using its account ""acting on behalf of"" the user. Batch allows; query to use the private network, but for all other purposes, the job is owned by the user. - Allow public access to some the `gcr.io/hail-vdc/query` Docker image. - Automatically rewrite uses of `hailgenetics/` Docker images to their `gcr.io` equivalents. - Move `deploy_address` above `deploy_query` so that query can depend on address (necessary for; shufles). - Fix logging configuration. Services team wants all logs all the time to go to stdout. - Implement lowerDistributedSort using the shuffler. - Allow shuffle ids to be encoded so they can be used in `Literal`.; Unified Split",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9848
https://github.com/hail-is/hail/pull/9848:533,Security,access,access,533,"This PR enables shuffling in the service. It is stacked on several other PRs, so look only at the; most recent commit. Some highlights:; - Open the public network back up. We should probably make query jobs special so that they can; access the internal network. To do that, batch would need to accept a ""acting on behalf of"" user; account: Query submits the job using its account ""acting on behalf of"" the user. Batch allows; query to use the private network, but for all other purposes, the job is owned by the user. - Allow public access to some the `gcr.io/hail-vdc/query` Docker image. - Automatically rewrite uses of `hailgenetics/` Docker images to their `gcr.io` equivalents. - Move `deploy_address` above `deploy_query` so that query can depend on address (necessary for; shufles). - Fix logging configuration. Services team wants all logs all the time to go to stdout. - Implement lowerDistributedSort using the shuffler. - Allow shuffle ids to be encoded so they can be used in `Literal`.; Unified Split",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9848
https://github.com/hail-is/hail/pull/9848:796,Testability,log,logging,796,"This PR enables shuffling in the service. It is stacked on several other PRs, so look only at the; most recent commit. Some highlights:; - Open the public network back up. We should probably make query jobs special so that they can; access the internal network. To do that, batch would need to accept a ""acting on behalf of"" user; account: Query submits the job using its account ""acting on behalf of"" the user. Batch allows; query to use the private network, but for all other purposes, the job is owned by the user. - Allow public access to some the `gcr.io/hail-vdc/query` Docker image. - Automatically rewrite uses of `hailgenetics/` Docker images to their `gcr.io` equivalents. - Move `deploy_address` above `deploy_query` so that query can depend on address (necessary for; shufles). - Fix logging configuration. Services team wants all logs all the time to go to stdout. - Implement lowerDistributedSort using the shuffler. - Allow shuffle ids to be encoded so they can be used in `Literal`.; Unified Split",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9848
https://github.com/hail-is/hail/pull/9848:843,Testability,log,logs,843,"This PR enables shuffling in the service. It is stacked on several other PRs, so look only at the; most recent commit. Some highlights:; - Open the public network back up. We should probably make query jobs special so that they can; access the internal network. To do that, batch would need to accept a ""acting on behalf of"" user; account: Query submits the job using its account ""acting on behalf of"" the user. Batch allows; query to use the private network, but for all other purposes, the job is owned by the user. - Allow public access to some the `gcr.io/hail-vdc/query` Docker image. - Automatically rewrite uses of `hailgenetics/` Docker images to their `gcr.io` equivalents. - Move `deploy_address` above `deploy_query` so that query can depend on address (necessary for; shufles). - Fix logging configuration. Services team wants all logs all the time to go to stdout. - Implement lowerDistributedSort using the shuffler. - Allow shuffle ids to be encoded so they can be used in `Literal`.; Unified Split",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9848
https://github.com/hail-is/hail/issues/9849:304,Availability,error,error,304,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Hello. The error has occurred during bulid. I installed all the necessary libraries and matched the jdk version and Python version.; And I also installed gcc, blas, and lapack. The error is as follows. Exception in thread ""main"" java.io.IOException: Function not implemented; at sun.nio.ch.FileDispatcherImpl.lock0(Native Method); at sun.nio.ch.FileDispatcherImpl.lock(FileDispatcherImpl.java:90); at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1114); at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155); at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:55); at org.gradle.wrapper.Install.createDist(Install.java:48); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); make: *** [Makefile:75: build/libs/hail-all-spark.jar] Error 1. An error occurs while compilation is in progress. There seems to be an error in the 'exec ""$JAVACMD"" ""$@"" section the gradlew file at the end. My server OS is centos7. Is there a solution?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9849
https://github.com/hail-is/hail/issues/9849:474,Availability,error,error,474,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Hello. The error has occurred during bulid. I installed all the necessary libraries and matched the jdk version and Python version.; And I also installed gcc, blas, and lapack. The error is as follows. Exception in thread ""main"" java.io.IOException: Function not implemented; at sun.nio.ch.FileDispatcherImpl.lock0(Native Method); at sun.nio.ch.FileDispatcherImpl.lock(FileDispatcherImpl.java:90); at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1114); at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155); at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:55); at org.gradle.wrapper.Install.createDist(Install.java:48); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); make: *** [Makefile:75: build/libs/hail-all-spark.jar] Error 1. An error occurs while compilation is in progress. There seems to be an error in the 'exec ""$JAVACMD"" ""$@"" section the gradlew file at the end. My server OS is centos7. Is there a solution?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9849
https://github.com/hail-is/hail/issues/9849:1175,Availability,Error,Error,1175,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Hello. The error has occurred during bulid. I installed all the necessary libraries and matched the jdk version and Python version.; And I also installed gcc, blas, and lapack. The error is as follows. Exception in thread ""main"" java.io.IOException: Function not implemented; at sun.nio.ch.FileDispatcherImpl.lock0(Native Method); at sun.nio.ch.FileDispatcherImpl.lock(FileDispatcherImpl.java:90); at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1114); at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155); at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:55); at org.gradle.wrapper.Install.createDist(Install.java:48); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); make: *** [Makefile:75: build/libs/hail-all-spark.jar] Error 1. An error occurs while compilation is in progress. There seems to be an error in the 'exec ""$JAVACMD"" ""$@"" section the gradlew file at the end. My server OS is centos7. Is there a solution?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9849
https://github.com/hail-is/hail/issues/9849:1187,Availability,error,error,1187,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Hello. The error has occurred during bulid. I installed all the necessary libraries and matched the jdk version and Python version.; And I also installed gcc, blas, and lapack. The error is as follows. Exception in thread ""main"" java.io.IOException: Function not implemented; at sun.nio.ch.FileDispatcherImpl.lock0(Native Method); at sun.nio.ch.FileDispatcherImpl.lock(FileDispatcherImpl.java:90); at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1114); at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155); at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:55); at org.gradle.wrapper.Install.createDist(Install.java:48); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); make: *** [Makefile:75: build/libs/hail-all-spark.jar] Error 1. An error occurs while compilation is in progress. There seems to be an error in the 'exec ""$JAVACMD"" ""$@"" section the gradlew file at the end. My server OS is centos7. Is there a solution?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9849
https://github.com/hail-is/hail/issues/9849:1255,Availability,error,error,1255,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Hello. The error has occurred during bulid. I installed all the necessary libraries and matched the jdk version and Python version.; And I also installed gcc, blas, and lapack. The error is as follows. Exception in thread ""main"" java.io.IOException: Function not implemented; at sun.nio.ch.FileDispatcherImpl.lock0(Native Method); at sun.nio.ch.FileDispatcherImpl.lock(FileDispatcherImpl.java:90); at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1114); at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155); at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:55); at org.gradle.wrapper.Install.createDist(Install.java:48); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); make: *** [Makefile:75: build/libs/hail-all-spark.jar] Error 1. An error occurs while compilation is in progress. There seems to be an error in the 'exec ""$JAVACMD"" ""$@"" section the gradlew file at the end. My server OS is centos7. Is there a solution?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9849
https://github.com/hail-is/hail/issues/9849:339,Deployability,install,installed,339,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Hello. The error has occurred during bulid. I installed all the necessary libraries and matched the jdk version and Python version.; And I also installed gcc, blas, and lapack. The error is as follows. Exception in thread ""main"" java.io.IOException: Function not implemented; at sun.nio.ch.FileDispatcherImpl.lock0(Native Method); at sun.nio.ch.FileDispatcherImpl.lock(FileDispatcherImpl.java:90); at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1114); at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155); at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:55); at org.gradle.wrapper.Install.createDist(Install.java:48); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); make: *** [Makefile:75: build/libs/hail-all-spark.jar] Error 1. An error occurs while compilation is in progress. There seems to be an error in the 'exec ""$JAVACMD"" ""$@"" section the gradlew file at the end. My server OS is centos7. Is there a solution?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9849
https://github.com/hail-is/hail/issues/9849:437,Deployability,install,installed,437,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Hello. The error has occurred during bulid. I installed all the necessary libraries and matched the jdk version and Python version.; And I also installed gcc, blas, and lapack. The error is as follows. Exception in thread ""main"" java.io.IOException: Function not implemented; at sun.nio.ch.FileDispatcherImpl.lock0(Native Method); at sun.nio.ch.FileDispatcherImpl.lock(FileDispatcherImpl.java:90); at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1114); at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155); at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:55); at org.gradle.wrapper.Install.createDist(Install.java:48); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); make: *** [Makefile:75: build/libs/hail-all-spark.jar] Error 1. An error occurs while compilation is in progress. There seems to be an error in the 'exec ""$JAVACMD"" ""$@"" section the gradlew file at the end. My server OS is centos7. Is there a solution?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9849
https://github.com/hail-is/hail/issues/9849:937,Deployability,Install,Install,937,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Hello. The error has occurred during bulid. I installed all the necessary libraries and matched the jdk version and Python version.; And I also installed gcc, blas, and lapack. The error is as follows. Exception in thread ""main"" java.io.IOException: Function not implemented; at sun.nio.ch.FileDispatcherImpl.lock0(Native Method); at sun.nio.ch.FileDispatcherImpl.lock(FileDispatcherImpl.java:90); at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1114); at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155); at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:55); at org.gradle.wrapper.Install.createDist(Install.java:48); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); make: *** [Makefile:75: build/libs/hail-all-spark.jar] Error 1. An error occurs while compilation is in progress. There seems to be an error in the 'exec ""$JAVACMD"" ""$@"" section the gradlew file at the end. My server OS is centos7. Is there a solution?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9849
https://github.com/hail-is/hail/issues/9849:956,Deployability,Install,Install,956,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Hello. The error has occurred during bulid. I installed all the necessary libraries and matched the jdk version and Python version.; And I also installed gcc, blas, and lapack. The error is as follows. Exception in thread ""main"" java.io.IOException: Function not implemented; at sun.nio.ch.FileDispatcherImpl.lock0(Native Method); at sun.nio.ch.FileDispatcherImpl.lock(FileDispatcherImpl.java:90); at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1114); at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155); at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:55); at org.gradle.wrapper.Install.createDist(Install.java:48); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); make: *** [Makefile:75: build/libs/hail-all-spark.jar] Error 1. An error occurs while compilation is in progress. There seems to be an error in the 'exec ""$JAVACMD"" ""$@"" section the gradlew file at the end. My server OS is centos7. Is there a solution?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9849
https://github.com/hail-is/hail/issues/9849:836,Integrability,wrap,wrapper,836,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Hello. The error has occurred during bulid. I installed all the necessary libraries and matched the jdk version and Python version.; And I also installed gcc, blas, and lapack. The error is as follows. Exception in thread ""main"" java.io.IOException: Function not implemented; at sun.nio.ch.FileDispatcherImpl.lock0(Native Method); at sun.nio.ch.FileDispatcherImpl.lock(FileDispatcherImpl.java:90); at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1114); at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155); at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:55); at org.gradle.wrapper.Install.createDist(Install.java:48); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); make: *** [Makefile:75: build/libs/hail-all-spark.jar] Error 1. An error occurs while compilation is in progress. There seems to be an error in the 'exec ""$JAVACMD"" ""$@"" section the gradlew file at the end. My server OS is centos7. Is there a solution?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9849
https://github.com/hail-is/hail/issues/9849:929,Integrability,wrap,wrapper,929,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Hello. The error has occurred during bulid. I installed all the necessary libraries and matched the jdk version and Python version.; And I also installed gcc, blas, and lapack. The error is as follows. Exception in thread ""main"" java.io.IOException: Function not implemented; at sun.nio.ch.FileDispatcherImpl.lock0(Native Method); at sun.nio.ch.FileDispatcherImpl.lock(FileDispatcherImpl.java:90); at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1114); at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155); at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:55); at org.gradle.wrapper.Install.createDist(Install.java:48); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); make: *** [Makefile:75: build/libs/hail-all-spark.jar] Error 1. An error occurs while compilation is in progress. There seems to be an error in the 'exec ""$JAVACMD"" ""$@"" section the gradlew file at the end. My server OS is centos7. Is there a solution?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9849
https://github.com/hail-is/hail/issues/9849:988,Integrability,wrap,wrapper,988,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Hello. The error has occurred during bulid. I installed all the necessary libraries and matched the jdk version and Python version.; And I also installed gcc, blas, and lapack. The error is as follows. Exception in thread ""main"" java.io.IOException: Function not implemented; at sun.nio.ch.FileDispatcherImpl.lock0(Native Method); at sun.nio.ch.FileDispatcherImpl.lock(FileDispatcherImpl.java:90); at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1114); at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155); at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:55); at org.gradle.wrapper.Install.createDist(Install.java:48); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); make: *** [Makefile:75: build/libs/hail-all-spark.jar] Error 1. An error occurs while compilation is in progress. There seems to be an error in the 'exec ""$JAVACMD"" ""$@"" section the gradlew file at the end. My server OS is centos7. Is there a solution?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9849
https://github.com/hail-is/hail/issues/9849:996,Integrability,Wrap,WrapperExecutor,996,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Hello. The error has occurred during bulid. I installed all the necessary libraries and matched the jdk version and Python version.; And I also installed gcc, blas, and lapack. The error is as follows. Exception in thread ""main"" java.io.IOException: Function not implemented; at sun.nio.ch.FileDispatcherImpl.lock0(Native Method); at sun.nio.ch.FileDispatcherImpl.lock(FileDispatcherImpl.java:90); at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1114); at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155); at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:55); at org.gradle.wrapper.Install.createDist(Install.java:48); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); make: *** [Makefile:75: build/libs/hail-all-spark.jar] Error 1. An error occurs while compilation is in progress. There seems to be an error in the 'exec ""$JAVACMD"" ""$@"" section the gradlew file at the end. My server OS is centos7. Is there a solution?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9849
https://github.com/hail-is/hail/issues/9849:1020,Integrability,Wrap,WrapperExecutor,1020,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Hello. The error has occurred during bulid. I installed all the necessary libraries and matched the jdk version and Python version.; And I also installed gcc, blas, and lapack. The error is as follows. Exception in thread ""main"" java.io.IOException: Function not implemented; at sun.nio.ch.FileDispatcherImpl.lock0(Native Method); at sun.nio.ch.FileDispatcherImpl.lock(FileDispatcherImpl.java:90); at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1114); at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155); at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:55); at org.gradle.wrapper.Install.createDist(Install.java:48); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); make: *** [Makefile:75: build/libs/hail-all-spark.jar] Error 1. An error occurs while compilation is in progress. There seems to be an error in the 'exec ""$JAVACMD"" ""$@"" section the gradlew file at the end. My server OS is centos7. Is there a solution?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9849
https://github.com/hail-is/hail/issues/9849:1061,Integrability,wrap,wrapper,1061,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Hello. The error has occurred during bulid. I installed all the necessary libraries and matched the jdk version and Python version.; And I also installed gcc, blas, and lapack. The error is as follows. Exception in thread ""main"" java.io.IOException: Function not implemented; at sun.nio.ch.FileDispatcherImpl.lock0(Native Method); at sun.nio.ch.FileDispatcherImpl.lock(FileDispatcherImpl.java:90); at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1114); at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155); at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:55); at org.gradle.wrapper.Install.createDist(Install.java:48); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); make: *** [Makefile:75: build/libs/hail-all-spark.jar] Error 1. An error occurs while compilation is in progress. There seems to be an error in the 'exec ""$JAVACMD"" ""$@"" section the gradlew file at the end. My server OS is centos7. Is there a solution?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9849
https://github.com/hail-is/hail/issues/9849:871,Security,access,access,871,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------. Hello. The error has occurred during bulid. I installed all the necessary libraries and matched the jdk version and Python version.; And I also installed gcc, blas, and lapack. The error is as follows. Exception in thread ""main"" java.io.IOException: Function not implemented; at sun.nio.ch.FileDispatcherImpl.lock0(Native Method); at sun.nio.ch.FileDispatcherImpl.lock(FileDispatcherImpl.java:90); at sun.nio.ch.FileChannelImpl.tryLock(FileChannelImpl.java:1114); at java.nio.channels.FileChannel.tryLock(FileChannel.java:1155); at org.gradle.wrapper.ExclusiveFileAccessManager.access(ExclusiveFileAccessManager.java:55); at org.gradle.wrapper.Install.createDist(Install.java:48); at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:107); at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:61); make: *** [Makefile:75: build/libs/hail-all-spark.jar] Error 1. An error occurs while compilation is in progress. There seems to be an error in the 'exec ""$JAVACMD"" ""$@"" section the gradlew file at the end. My server OS is centos7. Is there a solution?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9849
https://github.com/hail-is/hail/pull/9850:26,Modifiability,refactor,refactorings,26,"This is a series of small refactorings in AppendOnlyBTree that removes; the folds in code generation, replacing a pattern that I find difficult; to follow with a more imperative CodeBuilder style that is necessary for; future changes to proceed as the folding style does not work well with; functions that need code builders.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9850
https://github.com/hail-is/hail/pull/9854:10,Modifiability,refactor,refactoring,10,"Part of a refactoring effort. I need to break the model that a `TNDArray` is represented by an underlying `TStruct` and `TArray`. This adds an `UnsafeNDArray` Java representation, rather than the old model which was just to use`UnsafeRow` like it was a struct. . cc @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9854
https://github.com/hail-is/hail/pull/9854:144,Safety,Unsafe,UnsafeNDArray,144,"Part of a refactoring effort. I need to break the model that a `TNDArray` is represented by an underlying `TStruct` and `TArray`. This adds an `UnsafeNDArray` Java representation, rather than the old model which was just to use`UnsafeRow` like it was a struct. . cc @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9854
https://github.com/hail-is/hail/pull/9854:228,Safety,Unsafe,UnsafeRow,228,"Part of a refactoring effort. I need to break the model that a `TNDArray` is represented by an underlying `TStruct` and `TArray`. This adds an `UnsafeNDArray` Java representation, rather than the old model which was just to use`UnsafeRow` like it was a struct. . cc @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9854
https://github.com/hail-is/hail/issues/9856:1849,Availability,Error,Error,1849,"rojects/hail/hail/python/hail/matrixtable.py"", line 2528, in write; Env.backend().execute(ir.MatrixWrite(self._mir, writer)); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 103, in execute; bucket=self._bucket); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 48, in request; return async_to_blocking(retry_transient_errors(self.async_request, endpoint, **data)); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 114, in async_to_blocking; return asyncio.get_event_loop().run_until_complete(coro); File ""/Users/dking/miniconda3/lib/python3.7/asyncio/base_events.py"", line 587, in run_until_complete; return future.result(); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 379, in retry_transient_errors; return await f(*args, **kwargs); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 44, in async_request; raise FatalError(f'Error from server: {result[""value""]}'); FatalError: Error from server: java.util.NoSuchElementException: key not found: RefEquality(WriteMetadata(WriteMetadata(WriteMetadata(WriteMetadata(WriteMetadata(Let(__iruid_368,WritePartition(ToStream(Literal(array<struct{s: str}>,WrappedArray([HG00096], [HG00099], [HG00105], [HG00118], [HG00129], [HG00148], [HG00177], [HG00182], [HG00242], [HG00254], [HG00265], [HG00271], [HG00274], [HG00332], [HG00335], [HG00369], [HG00421], [HG00436], [HG00452], [HG00472], [HG00530], [HG00534], [HG00583], [HG00590], [HG00598], [HG00607], [HG00619], [HG00623], [HG00657], [HG00663], [HG00704], [HG00705], [HG00733], [HG00864], [HG00881], [HG01052], [HG01070], [HG01075], [HG01164], [HG01174], [HG01241], [HG01248], [HG01256], [HG01275], [HG01284], [HG01334], [HG01348], [HG01396], [HG01443], [HG01491], [HG01498], [HG01537], [HG01572], [HG01606], [HG01623], [HG01630], [HG01783], [HG01784], [HG01790], [HG01799], [HG01801], [HG01806], [HG01812], [HG01813], [HG01817], [HG01848], [H",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:1901,Availability,Error,Error,1901,"rojects/hail/hail/python/hail/matrixtable.py"", line 2528, in write; Env.backend().execute(ir.MatrixWrite(self._mir, writer)); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 103, in execute; bucket=self._bucket); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 48, in request; return async_to_blocking(retry_transient_errors(self.async_request, endpoint, **data)); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 114, in async_to_blocking; return asyncio.get_event_loop().run_until_complete(coro); File ""/Users/dking/miniconda3/lib/python3.7/asyncio/base_events.py"", line 587, in run_until_complete; return future.result(); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 379, in retry_transient_errors; return await f(*args, **kwargs); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 44, in async_request; raise FatalError(f'Error from server: {result[""value""]}'); FatalError: Error from server: java.util.NoSuchElementException: key not found: RefEquality(WriteMetadata(WriteMetadata(WriteMetadata(WriteMetadata(WriteMetadata(Let(__iruid_368,WritePartition(ToStream(Literal(array<struct{s: str}>,WrappedArray([HG00096], [HG00099], [HG00105], [HG00118], [HG00129], [HG00148], [HG00177], [HG00182], [HG00242], [HG00254], [HG00265], [HG00271], [HG00274], [HG00332], [HG00335], [HG00369], [HG00421], [HG00436], [HG00452], [HG00472], [HG00530], [HG00534], [HG00583], [HG00590], [HG00598], [HG00607], [HG00619], [HG00623], [HG00657], [HG00663], [HG00704], [HG00705], [HG00733], [HG00864], [HG00881], [HG01052], [HG01070], [HG01075], [HG01164], [HG01174], [HG01241], [HG01248], [HG01256], [HG01275], [HG01284], [HG01334], [HG01348], [HG01396], [HG01443], [HG01491], [HG01498], [HG01537], [HG01572], [HG01606], [HG01623], [HG01630], [HG01783], [HG01784], [HG01790], [HG01799], [HG01801], [HG01806], [HG01812], [HG01813], [HG01817], [HG01848], [H",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:789,Integrability,wrap,wrapper,789,"```; In [1]: import hail as hl ; ...: ; ...: temp = hl.import_vcf('gs://hail-tutorial/1kg.vcf.bgz', min_partitions=4) ; ...: temp.write('gs://danking/workshop-test/1kg.mt', overwrite=True) ; Initializing Hail with default parameters...; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.61-c548354b6e81; LOGGING: writing to /Users/dking/projects/hail/hail-20210107-1034-0.2.61-c548354b6e81.log; Traceback (most recent call last):; File ""<ipython-input-1-1702ec4a8e3c>"", line 4, in <module>; temp.write('gs://danking/workshop-test/1kg.mt', overwrite=True); File ""</Users/dking/miniconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-1228>"", line 2, in write; File ""/Users/dking/projects/hail/hail/python/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/dking/projects/hail/hail/python/hail/matrixtable.py"", line 2528, in write; Env.backend().execute(ir.MatrixWrite(self._mir, writer)); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 103, in execute; bucket=self._bucket); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 48, in request; return async_to_blocking(retry_transient_errors(self.async_request, endpoint, **data)); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 114, in async_to_blocking; return asyncio.get_event_loop().run_until_complete(coro); File ""/Users/dking/miniconda3/lib/python3.7/asyncio/base_events.py"", line 587, in run_until_complete; return future.result(); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 379, in retry_transient_errors; return await f(*args, **kwargs); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 44, in async_request; raise FatalError(f'Error from server: {result[""value""]}'); FatalError: Error from server: java.util.NoSuchElementException: key not found: RefEquality(WriteMetadata(WriteM",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:2121,Integrability,Wrap,WrappedArray,2121,NoSuchElementException: key not found: RefEquality(WriteMetadata(WriteM,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:7229,Integrability,Wrap,WrappedArray,7229,"4, MLEAC: array<int32>, MLEAF: array<float64>, MQ: float64, MQ0: int32, MQRankSum: float64, QD: float64, ReadPosRankSum: float64, set: str}, `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`: array<struct{GT: call, AD: array<int32>, DP: int32, GQ: int32, PL: array<int32>}>},is.hail.expr.ir.PartitionIteratorLongReader@3da0d80),Apply(concat,WrappedArray(),ArrayBuffer(GetField(Ref(__iruid_370,struct{oldCtx: struct{index: int32, file: str, start: int64, end: int64, split: bool}, writeCtx: str}),writeCtx), UUID4(__iruid_277)),str),SplitPartitionNativeWriter({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{locus:+EBaseStruct{contig:+EBinary,position:+EInt32},alleles:+EArray[+EBinary],rsid:EBinary,qual:EFloat64,filters:EArray[+EBinary],info:+EBaseStruct{AC:EArray[EInt32],AF:EArray[EFloat64],AN:EInt32,BaseQRankSum:EFloat64,ClippingRankSum:EFloat64,DP:EInt32,DS:+EBoolean,FS:EFloat64,HaplotypeScore:EFloat64,InbreedingCoeff:EFloat64,MLEAC:EArray[EInt32],MLEAF:EArray[EFloat64],MQ:EFloat64,MQ0:EInt32,MQRankSum:EFloat64,QD:EFloat64,ReadPosRankSum:EFloat64,set:EBinary}}"",""_vType"":""Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Float64,InbreedingCoeff:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/rows/rows/parts/,{""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[+EBaseStruct{GT:EInt32,AD:EArray[+EInt32],DP:EInt32,GQ:EInt32,PL:EArray[+EInt32]}]}"",""_vType"":""Struct{`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:9347,Integrability,Wrap,WrappedArray,9347,"mBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/rows/rows/parts/,{""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[+EBaseStruct{GT:EInt32,AD:EArray[+EInt32],DP:EInt32,GQ:EInt32,PL:EArray[+EInt32]}]}"",""_vType"":""Struct{`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{GT:Call,AD:Array[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}]}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/entries/rows/parts/,Some((gs://danking/workshop-test/1kg.mt/index/,+PCStruct{locus:+PCLocus(GRCh37),alleles:+PCArray[+PCString]})),None)),Some(TableStageDependency(WrappedArray()))),Begin(ArrayBuffer(WriteMetadata(MakeArray(ArrayBuffer(GetField(WritePartition(MakeStream(ArrayBuffer(Literal(struct{},[])),stream<struct{}>,false),Str(""part-0""),PartitionNativeWriter({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/globals/globals/parts/,None,None)),filePath)),array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/globals/globals,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map()))), WriteMetadata(MakeArray(ArrayBuffer(GetField(WritePartition(MakeStream(ArrayBuffer(Literal(struct{},[])),stream<struct{}>,false),",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:10255,Integrability,Wrap,WrappedArray,10255,"r(GetField(WritePartition(MakeStream(ArrayBuffer(Literal(struct{},[])),stream<struct{}>,false),Str(""part-0""),PartitionNativeWriter({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/globals/globals/parts/,None,None)),filePath)),array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/globals/globals,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map()))), WriteMetadata(MakeArray(ArrayBuffer(GetField(WritePartition(MakeStream(ArrayBuffer(Literal(struct{},[])),stream<struct{}>,false),Str(""part-0""),PartitionNativeWriter({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/globals/rows/parts/,None,None)),filePath)),array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/globals/rows,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(tr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:11281,Integrability,Wrap,WrappedArray,11281,"dArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map()))), WriteMetadata(MakeArray(ArrayBuffer(GetField(WritePartition(MakeStream(ArrayBuffer(Literal(struct{},[])),stream<struct{}>,false),Str(""part-0""),PartitionNativeWriter({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/globals/rows/parts/,None,None)),filePath)),array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/globals/rows,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map()))), WriteMetadata(Literal(array<int64>,ArrayBuffer(1)),TableSpecWriter(gs://danking/workshop-test/1kg.mt/globals,Table{global:Struct{},key:[],row:Struct{}},rows,globals,../references,false)), WriteMetadata(MakeArray(ArrayBuffer(GetField(Ref(__iruid_368,struct{filePath: str, partitionCounts: int64}),filePath)),array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/cols/rows,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""EBaseStruct{s:EBinary}"",""_vType"":""Struct{s:String}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:12116,Integrability,Wrap,WrappedArray,12116,"name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map()))), WriteMetadata(Literal(array<int64>,ArrayBuffer(1)),TableSpecWriter(gs://danking/workshop-test/1kg.mt/globals,Table{global:Struct{},key:[],row:Struct{}},rows,globals,../references,false)), WriteMetadata(MakeArray(ArrayBuffer(GetField(Ref(__iruid_368,struct{filePath: str, partitionCounts: int64}),filePath)),array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/cols/rows,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""EBaseStruct{s:EBinary}"",""_vType"":""Struct{s:String}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map()))), WriteMetadata(MakeArray(ArrayBuffer(GetField(Ref(__iruid_368,struct{filePath: str, partitionCounts: int64}),partitionCounts)),array<int64>),TableSpecWriter(gs://danking/workshop-test/1kg.mt/cols,Table{global:Struct{},key:[s],row:Struct{s:String}},rows,../globals/rows,../references,false)), Let(__iruid_374,ToArray(StreamMap(ToStream(Ref(__iruid_369,array<struct{filePath: str, partitionCounts: int64}>),false),__iruid_375,GetField(Ref(__iruid_375,struct{filePath: str, partitionCounts: int64}),filePath))),Begin(ArrayBuffer(WriteMetadata(Ref(__iruid_374,array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/rows/rows,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{locus:+EBaseStruct{contig:+EBinary,position:+EInt32},alleles:+EArray[+EBinary],rsid:EBinary,qual:EFloat64,filters:EArray[+EBinary],info:+EBaseStruct{AC:EArray[EInt32],AF:EA",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:14034,Integrability,Wrap,WrappedArray,14034,",rsid:EBinary,qual:EFloat64,filters:EArray[+EBinary],info:+EBaseStruct{AC:EArray[EInt32],AF:EArray[EFloat64],AN:EInt32,BaseQRankSum:EFloat64,ClippingRankSum:EFloat64,DP:EInt32,DS:+EBoolean,FS:EFloat64,HaplotypeScore:EFloat64,InbreedingCoeff:EFloat64,MLEAC:EArray[EInt32],MLEAF:EArray[EFloat64],MQ:EFloat64,MQ0:EInt32,MQRankSum:EFloat64,QD:EFloat64,ReadPosRankSum:EFloat64,set:EBinary}}"",""_vType"":""Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Float64,InbreedingCoeff:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(locus, alleles),JArray(List(JObject(List((start,JObject(List((locus,JObject(List((contig,JString(1)), (position,JInt(904165))))), (alleles,JArray(List(JString(G), JString(A))))))), (end,JObject(List((locus,JObject(List((contig,JString(4)), (position,JInt(70592790))))), (alleles,JArray(List(JString(G), JString(T))))))), (includeStart,JBool(true)), (includeEnd,JBool(true)))), JObject(List((start,JObject(List((locus,JObject(List((contig,JString(4)), (position,JInt(70899111))))), (alleles,JArray(List(JString(G), JString(A))))))), (end,JObject(List((locus,JObject(List((contig,JString(8)), (position,JInt(126013303))))), (alleles,JArray(List(JString(G), JString(A))))))), (includeStart,JBool(true)), (includeEnd,JBool(true)))), JObject(List((start,JObject(List((locus,JObject(List((contig,JString(8)), (position,JInt(126888589))))), (alleles,JArray(List(JString(G), JString(A))))))), (end,JObject(List((locus,JObject(List((contig,JString(14)), (position,JInt(75037676))))), (alleles,JArray(Lis",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:16145,Integrability,Wrap,WrappedArray,16145,"d,JObject(List((locus,JObject(List((contig,JString(X)), (position,JInt(154087368))))), (alleles,JArray(List(JString(T), JString(A))))))), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map()))), WriteMetadata(Ref(__iruid_374,array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/entries/rows,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[+EBaseStruct{GT:EInt32,AD:EArray[+EInt32],DP:EInt32,GQ:EInt32,PL:EArray[+EInt32]}]}"",""_vType"":""Struct{`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{GT:Call,AD:Array[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}]}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))), JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))), JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))), JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map())))))), Let(__iruid_376,ToArray(StreamMap(ToStream(Ref(__iruid_369,array<struct{filePath: str, partitionCounts: int64}>),false),__iruid_377,GetField(Ref(__iruid_377,struct{filePath: str, partitionCounts: int64}),partitionCounts))),Begin(ArrayBuffer(WriteMetadata(Ref(__iruid_376,array<int64>),TableSpecWriter(gs://danking/workshop-test/1kg.mt/rows,Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Flo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:21157,Integrability,Wrap,WrappedArray,21157,s.scala:95); 	at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3$$anonfun$1.apply(LoweringPass.scala:15); 	at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3$$anonfun$1.apply(LoweringPass.scala:15); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3.apply(LoweringPass.scala:15); 	at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3.apply(LoweringPass.scala:13); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass$class.apply(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LowerArrayAggsToRunAggsPass$.apply(LoweringPass.scala:89); 	at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:14); 	at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:12); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:12); 	at is.hail.expr.ir.Compile$.apply(Compile.scala:45); 	at is.hail.backend.service.ServiceBackend$$anonfun$execute$1$$anonfun$apply$11$$anonfun$apply$12.apply(ServiceBackend.scala:314); 	at is.hail.backend.service.ServiceBackend$$anonfun$execute$1$$anonfun$apply$11$$anonfun$apply$12.apply(ServiceBackend.scala:308); 	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25); 	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23); 	at is.hail.utils.package$.using(package.scala:618); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:12); 	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23); 	at is.hail.backend.service.ServiceBackend.userContext(ServiceBackend.scala:122); 	at is.hail.backend.service.ServiceBackend$$anonfun$execute$1$$anonfun$apply$11.apply(ServiceBackend.scala:308); 	at is.hail.ba,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:21178,Integrability,Wrap,WrappedArray,21178,is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3$$anonfun$1.apply(LoweringPass.scala:15); 	at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3$$anonfun$1.apply(LoweringPass.scala:15); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3.apply(LoweringPass.scala:15); 	at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3.apply(LoweringPass.scala:13); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass$class.apply(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LowerArrayAggsToRunAggsPass$.apply(LoweringPass.scala:89); 	at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:14); 	at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:12); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:12); 	at is.hail.expr.ir.Compile$.apply(Compile.scala:45); 	at is.hail.backend.service.ServiceBackend$$anonfun$execute$1$$anonfun$apply$11$$anonfun$apply$12.apply(ServiceBackend.scala:314); 	at is.hail.backend.service.ServiceBackend$$anonfun$execute$1$$anonfun$apply$11$$anonfun$apply$12.apply(ServiceBackend.scala:308); 	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25); 	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23); 	at is.hail.utils.package$.using(package.scala:618); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:12); 	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23); 	at is.hail.backend.service.ServiceBackend.userContext(ServiceBackend.scala:122); 	at is.hail.backend.service.ServiceBackend$$anonfun$execute$1$$anonfun$apply$11.apply(ServiceBackend.scala:308); 	at is.hail.backend.service.Ser,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:19172,Security,Hash,HashMap,19172,"loat64,filters:Set[String],info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Float64,InbreedingCoeff:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}},entry:Struct{GT:Call,AD:Array[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}},rows/rows,globals/rows,cols/rows,entries/rows,references,true))))))))),RelationalWriter(gs://danking/workshop-test/1kg.mt/entries,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/rows,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/cols,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/globals,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt,true,Some((references,Set(GRCh37)))))); 	at scala.collection.MapLike$class.default(MapLike.scala:228); 	at scala.collection.AbstractMap.default(Map.scala:59); 	at scala.collection.mutable.HashMap.apply(HashMap.scala:65); 	at is.hail.expr.ir.Memo.lookup(RefEquality.scala:38); 	at is.hail.expr.ir.Memo.lookup(RefEquality.scala:37); 	at is.hail.expr.ir.Memo.apply(RefEquality.scala:40); 	at is.hail.expr.ir.Requiredness.lookup(Requiredness.scala:41); 	at is.hail.expr.ir.Requiredness$$anonfun$analyzeIR$16.apply(Requiredness.scala:616); 	at is.hail.expr.ir.Requiredness$$anonfun$analyzeIR$16.apply(Requiredness.scala:615); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at is.hail.expr.ir.Requiredness.analyzeIR(Requiredness.scala:615); 	at is.hail.expr.ir.Requiredness.analyze(Requiredness.scala:265); 	at is.hail.expr.ir.Requiredness.run(Requiredness.scala:91); 	at is.hail.expr.ir.Requiredness$.apply(Requiredness.scala:16); 	at is.hail.expr.ir.Requiredness$.apply(Requiredness.scala:21); 	at is.hail.expr.ir.lowering.LowerArrayAggsToRunAggsPass$.transform(LoweringPass.scala:95); ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:19186,Security,Hash,HashMap,19186,"ers:Set[String],info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Float64,InbreedingCoeff:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}},entry:Struct{GT:Call,AD:Array[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}},rows/rows,globals/rows,cols/rows,entries/rows,references,true))))))))),RelationalWriter(gs://danking/workshop-test/1kg.mt/entries,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/rows,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/cols,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/globals,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt,true,Some((references,Set(GRCh37)))))); 	at scala.collection.MapLike$class.default(MapLike.scala:228); 	at scala.collection.AbstractMap.default(Map.scala:59); 	at scala.collection.mutable.HashMap.apply(HashMap.scala:65); 	at is.hail.expr.ir.Memo.lookup(RefEquality.scala:38); 	at is.hail.expr.ir.Memo.lookup(RefEquality.scala:37); 	at is.hail.expr.ir.Memo.apply(RefEquality.scala:40); 	at is.hail.expr.ir.Requiredness.lookup(Requiredness.scala:41); 	at is.hail.expr.ir.Requiredness$$anonfun$analyzeIR$16.apply(Requiredness.scala:616); 	at is.hail.expr.ir.Requiredness$$anonfun$analyzeIR$16.apply(Requiredness.scala:615); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at is.hail.expr.ir.Requiredness.analyzeIR(Requiredness.scala:615); 	at is.hail.expr.ir.Requiredness.analyze(Requiredness.scala:265); 	at is.hail.expr.ir.Requiredness.run(Requiredness.scala:91); 	at is.hail.expr.ir.Requiredness$.apply(Requiredness.scala:16); 	at is.hail.expr.ir.Requiredness$.apply(Requiredness.scala:21); 	at is.hail.expr.ir.lowering.LowerArrayAggsToRunAggsPass$.transform(LoweringPass.scala:95); 	at is.hail",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:159,Testability,test,test,159,"```; In [1]: import hail as hl ; ...: ; ...: temp = hl.import_vcf('gs://hail-tutorial/1kg.vcf.bgz', min_partitions=4) ; ...: temp.write('gs://danking/workshop-test/1kg.mt', overwrite=True) ; Initializing Hail with default parameters...; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.61-c548354b6e81; LOGGING: writing to /Users/dking/projects/hail/hail-20210107-1034-0.2.61-c548354b6e81.log; Traceback (most recent call last):; File ""<ipython-input-1-1702ec4a8e3c>"", line 4, in <module>; temp.write('gs://danking/workshop-test/1kg.mt', overwrite=True); File ""</Users/dking/miniconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-1228>"", line 2, in write; File ""/Users/dking/projects/hail/hail/python/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/dking/projects/hail/hail/python/hail/matrixtable.py"", line 2528, in write; Env.backend().execute(ir.MatrixWrite(self._mir, writer)); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 103, in execute; bucket=self._bucket); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 48, in request; return async_to_blocking(retry_transient_errors(self.async_request, endpoint, **data)); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 114, in async_to_blocking; return asyncio.get_event_loop().run_until_complete(coro); File ""/Users/dking/miniconda3/lib/python3.7/asyncio/base_events.py"", line 587, in run_until_complete; return future.result(); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 379, in retry_transient_errors; return await f(*args, **kwargs); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 44, in async_request; raise FatalError(f'Error from server: {result[""value""]}'); FatalError: Error from server: java.util.NoSuchElementException: key not found: RefEquality(WriteMetadata(WriteM",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:341,Testability,LOG,LOGGING,341,"```; In [1]: import hail as hl ; ...: ; ...: temp = hl.import_vcf('gs://hail-tutorial/1kg.vcf.bgz', min_partitions=4) ; ...: temp.write('gs://danking/workshop-test/1kg.mt', overwrite=True) ; Initializing Hail with default parameters...; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.61-c548354b6e81; LOGGING: writing to /Users/dking/projects/hail/hail-20210107-1034-0.2.61-c548354b6e81.log; Traceback (most recent call last):; File ""<ipython-input-1-1702ec4a8e3c>"", line 4, in <module>; temp.write('gs://danking/workshop-test/1kg.mt', overwrite=True); File ""</Users/dking/miniconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-1228>"", line 2, in write; File ""/Users/dking/projects/hail/hail/python/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/dking/projects/hail/hail/python/hail/matrixtable.py"", line 2528, in write; Env.backend().execute(ir.MatrixWrite(self._mir, writer)); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 103, in execute; bucket=self._bucket); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 48, in request; return async_to_blocking(retry_transient_errors(self.async_request, endpoint, **data)); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 114, in async_to_blocking; return asyncio.get_event_loop().run_until_complete(coro); File ""/Users/dking/miniconda3/lib/python3.7/asyncio/base_events.py"", line 587, in run_until_complete; return future.result(); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 379, in retry_transient_errors; return await f(*args, **kwargs); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 44, in async_request; raise FatalError(f'Error from server: {result[""value""]}'); FatalError: Error from server: java.util.NoSuchElementException: key not found: RefEquality(WriteMetadata(WriteM",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:427,Testability,log,log,427,"```; In [1]: import hail as hl ; ...: ; ...: temp = hl.import_vcf('gs://hail-tutorial/1kg.vcf.bgz', min_partitions=4) ; ...: temp.write('gs://danking/workshop-test/1kg.mt', overwrite=True) ; Initializing Hail with default parameters...; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.61-c548354b6e81; LOGGING: writing to /Users/dking/projects/hail/hail-20210107-1034-0.2.61-c548354b6e81.log; Traceback (most recent call last):; File ""<ipython-input-1-1702ec4a8e3c>"", line 4, in <module>; temp.write('gs://danking/workshop-test/1kg.mt', overwrite=True); File ""</Users/dking/miniconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-1228>"", line 2, in write; File ""/Users/dking/projects/hail/hail/python/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/dking/projects/hail/hail/python/hail/matrixtable.py"", line 2528, in write; Env.backend().execute(ir.MatrixWrite(self._mir, writer)); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 103, in execute; bucket=self._bucket); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 48, in request; return async_to_blocking(retry_transient_errors(self.async_request, endpoint, **data)); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 114, in async_to_blocking; return asyncio.get_event_loop().run_until_complete(coro); File ""/Users/dking/miniconda3/lib/python3.7/asyncio/base_events.py"", line 587, in run_until_complete; return future.result(); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 379, in retry_transient_errors; return await f(*args, **kwargs); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 44, in async_request; raise FatalError(f'Error from server: {result[""value""]}'); FatalError: Error from server: java.util.NoSuchElementException: key not found: RefEquality(WriteMetadata(WriteM",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:562,Testability,test,test,562,"```; In [1]: import hail as hl ; ...: ; ...: temp = hl.import_vcf('gs://hail-tutorial/1kg.vcf.bgz', min_partitions=4) ; ...: temp.write('gs://danking/workshop-test/1kg.mt', overwrite=True) ; Initializing Hail with default parameters...; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.61-c548354b6e81; LOGGING: writing to /Users/dking/projects/hail/hail-20210107-1034-0.2.61-c548354b6e81.log; Traceback (most recent call last):; File ""<ipython-input-1-1702ec4a8e3c>"", line 4, in <module>; temp.write('gs://danking/workshop-test/1kg.mt', overwrite=True); File ""</Users/dking/miniconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-1228>"", line 2, in write; File ""/Users/dking/projects/hail/hail/python/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/dking/projects/hail/hail/python/hail/matrixtable.py"", line 2528, in write; Env.backend().execute(ir.MatrixWrite(self._mir, writer)); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 103, in execute; bucket=self._bucket); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 48, in request; return async_to_blocking(retry_transient_errors(self.async_request, endpoint, **data)); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 114, in async_to_blocking; return asyncio.get_event_loop().run_until_complete(coro); File ""/Users/dking/miniconda3/lib/python3.7/asyncio/base_events.py"", line 587, in run_until_complete; return future.result(); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 379, in retry_transient_errors; return await f(*args, **kwargs); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 44, in async_request; raise FatalError(f'Error from server: {result[""value""]}'); FatalError: Error from server: java.util.NoSuchElementException: key not found: RefEquality(WriteMetadata(WriteM",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:5609,Testability,test,test,5609,", [HG03074], [HG03091], [HG03105], [HG03127], [HG03193], [HG03224], [HG03237], [HG03241], [HG03247], [HG03259], [HG03267], [HG03354], [HG03366], [HG03367], [HG03380], [HG03419], [HG03449], [HG03451], [HG03458], [HG03490], [HG03491], [HG03511], [HG03556], [HG03563], [HG03598], [HG03603], [HG03607], [HG03636], [HG03684], [HG03686], [HG03690], [HG03731], [HG03740], [HG03755], [HG03800], [HG03815], [HG03832], [HG03850], [HG03873], [HG03897], [HG03905], [HG03937], [HG03948], [HG03973], [HG04054], [HG04059], [HG04063], [HG04096], [HG04099], [HG04140], [HG04171], [HG04209], [HG04210], [HG04229], [HG04239], [NA07347], [NA11918], [NA11919], [NA12045], [NA12273], [NA12342], [NA12414], [NA12546], [NA12760], [NA12878], [NA18516], [NA18525], [NA18534], [NA18541], [NA18557], [NA18565], [NA18616], [NA18619], [NA18623], [NA18630], [NA18631], [NA18740], [NA18853], [NA18865], [NA18873], [NA18874], [NA18916], [NA18960], [NA18966], [NA18975], [NA18976], [NA18978], [NA18990], [NA19060], [NA19063], [NA19076], [NA19086], [NA19087], [NA19096], [NA19113], [NA19118], [NA19185], [NA19209], [NA19311], [NA19314], [NA19317], [NA19321], [NA19379], [NA19384], [NA19390], [NA19397], [NA19399], [NA19404], [NA19446], [NA19448], [NA19455], [NA19456], [NA19466], [NA19655], [NA19657], [NA19670], [NA19678], [NA19679], [NA19701], [NA19720], [NA19756], [NA19761], [NA19764], [NA19786], [NA20318], [NA20351], [NA20517], [NA20518], [NA20529], [NA20587], [NA20757], [NA20798], [NA20799], [NA20800], [NA20810], [NA20826], [NA20858], [NA20864], [NA20869], [NA20877], [NA20888], [NA20910], [NA21101], [NA21113], [NA21114], [NA21116], [NA21118], [NA21133], [NA21143])),false),Str(""part-0""),PartitionNativeWriter({""name"":""TypedCodecSpec"",""_eType"":""EBaseStruct{s:EBinary}"",""_vType"":""Struct{s:String}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:6372,Testability,Assert,AssertSameLength,6372,"ng/workshop-test/1kg.mt/cols/rows/parts/,None,None)),Let(__iruid_369,CollectDistributedArray(StreamZip(ArrayBuffer(ToStream(Literal(array<struct{index: int32, file: str, start: int64, end: int64, split: bool}>,ArrayBuffer([0,gs://hail-tutorial/1kg.vcf.bgz,0,261965807616,true], [1,gs://hail-tutorial/1kg.vcf.bgz,3997281,523931615232,true], [2,gs://hail-tutorial/1kg.vcf.bgz,7994562,785897422848,true], [3,gs://hail-tutorial/1kg.vcf.bgz,11991843,1047863164928,true])),false), MakeStream(ArrayBuffer(Str(""part-0-""), Str(""part-1-""), Str(""part-2-""), Str(""part-3-"")),stream<str>,false)),ArrayBuffer(__iruid_372, __iruid_373),MakeStruct(ArrayBuffer((oldCtx,Ref(__iruid_372,struct{index: int32, file: str, start: int64, end: int64, split: bool})), (writeCtx,Ref(__iruid_373,str)))),AssertSameLength),Literal(struct{},[]),__iruid_370,__iruid_371,WritePartition(ReadPartition(GetField(Ref(__iruid_370,struct{oldCtx: struct{index: int32, file: str, start: int64, end: int64, split: bool}, writeCtx: str}),oldCtx),struct{locus: locus<GRCh37>, alleles: array<str>, rsid: str, qual: float64, filters: set<str>, info: struct{AC: array<int32>, AF: array<float64>, AN: int32, BaseQRankSum: float64, ClippingRankSum: float64, DP: int32, DS: bool, FS: float64, HaplotypeScore: float64, InbreedingCoeff: float64, MLEAC: array<int32>, MLEAF: array<float64>, MQ: float64, MQ0: int32, MQRankSum: float64, QD: float64, ReadPosRankSum: float64, set: str}, `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`: array<struct{GT: call, AD: array<int32>, DP: int32, GQ: int32, PL: array<int32>}>},is.hail.expr.ir.PartitionIteratorLongReader@3da0d80),Apply(concat,WrappedArray(),ArrayBuffer(GetField(Ref(__iruid_370,struct{oldCtx: struct{index: int32, file: str, start: int64, end: int64, split: bool}, writeCtx: str}),writeCtx), UUID4(__iruid_277)),str),SplitPartitionNativeWriter({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{locus:+EBaseStruct{contig:+EBinary,position:+EInt32},alleles:+EArray[+EBinary],rsid:EBinary,qual:EFloat",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:8589,Testability,test,test,8589,"4, MLEAC: array<int32>, MLEAF: array<float64>, MQ: float64, MQ0: int32, MQRankSum: float64, QD: float64, ReadPosRankSum: float64, set: str}, `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`: array<struct{GT: call, AD: array<int32>, DP: int32, GQ: int32, PL: array<int32>}>},is.hail.expr.ir.PartitionIteratorLongReader@3da0d80),Apply(concat,WrappedArray(),ArrayBuffer(GetField(Ref(__iruid_370,struct{oldCtx: struct{index: int32, file: str, start: int64, end: int64, split: bool}, writeCtx: str}),writeCtx), UUID4(__iruid_277)),str),SplitPartitionNativeWriter({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{locus:+EBaseStruct{contig:+EBinary,position:+EInt32},alleles:+EArray[+EBinary],rsid:EBinary,qual:EFloat64,filters:EArray[+EBinary],info:+EBaseStruct{AC:EArray[EInt32],AF:EArray[EFloat64],AN:EInt32,BaseQRankSum:EFloat64,ClippingRankSum:EFloat64,DP:EInt32,DS:+EBoolean,FS:EFloat64,HaplotypeScore:EFloat64,InbreedingCoeff:EFloat64,MLEAC:EArray[EInt32],MLEAF:EArray[EFloat64],MQ:EFloat64,MQ0:EInt32,MQRankSum:EFloat64,QD:EFloat64,ReadPosRankSum:EFloat64,set:EBinary}}"",""_vType"":""Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Float64,InbreedingCoeff:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/rows/rows/parts/,{""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[+EBaseStruct{GT:EInt32,AD:EArray[+EInt32],DP:EInt32,GQ:EInt32,PL:EArray[+EInt32]}]}"",""_vType"":""Struct{`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:9171,Testability,test,test,9171,",MQRankSum:EFloat64,QD:EFloat64,ReadPosRankSum:EFloat64,set:EBinary}}"",""_vType"":""Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Float64,InbreedingCoeff:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/rows/rows/parts/,{""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[+EBaseStruct{GT:EInt32,AD:EArray[+EInt32],DP:EInt32,GQ:EInt32,PL:EArray[+EInt32]}]}"",""_vType"":""Struct{`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{GT:Call,AD:Array[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}]}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/entries/rows/parts/,Some((gs://danking/workshop-test/1kg.mt/index/,+PCStruct{locus:+PCLocus(GRCh37),alleles:+PCArray[+PCString]})),None)),Some(TableStageDependency(WrappedArray()))),Begin(ArrayBuffer(WriteMetadata(MakeArray(ArrayBuffer(GetField(WritePartition(MakeStream(ArrayBuffer(Literal(struct{},[])),stream<struct{}>,false),Str(""part-0""),PartitionNativeWriter({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/globals/globals/parts/,None,None)),fil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:9231,Testability,test,test,9231,"Float64,InbreedingCoeff:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/rows/rows/parts/,{""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[+EBaseStruct{GT:EInt32,AD:EArray[+EInt32],DP:EInt32,GQ:EInt32,PL:EArray[+EInt32]}]}"",""_vType"":""Struct{`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{GT:Call,AD:Array[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}]}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/entries/rows/parts/,Some((gs://danking/workshop-test/1kg.mt/index/,+PCStruct{locus:+PCLocus(GRCh37),alleles:+PCArray[+PCString]})),None)),Some(TableStageDependency(WrappedArray()))),Begin(ArrayBuffer(WriteMetadata(MakeArray(ArrayBuffer(GetField(WritePartition(MakeStream(ArrayBuffer(Literal(struct{},[])),stream<struct{}>,false),Str(""part-0""),PartitionNativeWriter({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/globals/globals/parts/,None,None)),filePath)),array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/globals/globals,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:9839,Testability,test,test,9839,"mBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/rows/rows/parts/,{""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[+EBaseStruct{GT:EInt32,AD:EArray[+EInt32],DP:EInt32,GQ:EInt32,PL:EArray[+EInt32]}]}"",""_vType"":""Struct{`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{GT:Call,AD:Array[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}]}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/entries/rows/parts/,Some((gs://danking/workshop-test/1kg.mt/index/,+PCStruct{locus:+PCLocus(GRCh37),alleles:+PCArray[+PCString]})),None)),Some(TableStageDependency(WrappedArray()))),Begin(ArrayBuffer(WriteMetadata(MakeArray(ArrayBuffer(GetField(WritePartition(MakeStream(ArrayBuffer(Literal(struct{},[])),stream<struct{}>,false),Str(""part-0""),PartitionNativeWriter({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/globals/globals/parts/,None,None)),filePath)),array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/globals/globals,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map()))), WriteMetadata(MakeArray(ArrayBuffer(GetField(WritePartition(MakeStream(ArrayBuffer(Literal(struct{},[])),stream<struct{}>,false),",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:9945,Testability,test,test,9945,"rray[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}]}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/entries/rows/parts/,Some((gs://danking/workshop-test/1kg.mt/index/,+PCStruct{locus:+PCLocus(GRCh37),alleles:+PCArray[+PCString]})),None)),Some(TableStageDependency(WrappedArray()))),Begin(ArrayBuffer(WriteMetadata(MakeArray(ArrayBuffer(GetField(WritePartition(MakeStream(ArrayBuffer(Literal(struct{},[])),stream<struct{}>,false),Str(""part-0""),PartitionNativeWriter({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/globals/globals/parts/,None,None)),filePath)),array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/globals/globals,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map()))), WriteMetadata(MakeArray(ArrayBuffer(GetField(WritePartition(MakeStream(ArrayBuffer(Literal(struct{},[])),stream<struct{}>,false),Str(""part-0""),PartitionNativeWriter({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/globals/rows/parts",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:10871,Testability,test,test,10871,"r(GetField(WritePartition(MakeStream(ArrayBuffer(Literal(struct{},[])),stream<struct{}>,false),Str(""part-0""),PartitionNativeWriter({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/globals/globals/parts/,None,None)),filePath)),array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/globals/globals,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map()))), WriteMetadata(MakeArray(ArrayBuffer(GetField(WritePartition(MakeStream(ArrayBuffer(Literal(struct{},[])),stream<struct{}>,false),Str(""part-0""),PartitionNativeWriter({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/globals/rows/parts/,None,None)),filePath)),array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/globals/rows,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(tr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:10974,Testability,test,test,10974,"king/workshop-test/1kg.mt/globals/globals,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map()))), WriteMetadata(MakeArray(ArrayBuffer(GetField(WritePartition(MakeStream(ArrayBuffer(Literal(struct{},[])),stream<struct{}>,false),Str(""part-0""),PartitionNativeWriter({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/globals/rows/parts/,None,None)),filePath)),array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/globals/rows,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map()))), WriteMetadata(Literal(array<int64>,ArrayBuffer(1)),TableSpecWriter(gs://danking/workshop-test/1kg.mt/globals,Table{global:Struct{},key:[],row:Struct{}},rows,globals,../references,false)), WriteMetadata(MakeArray(ArrayBuffer(GetField(Ref(__iruid_368,struct{filePath: str, partitionCounts: int64}),filePath)),array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/cols/rows,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""EBaseStruct{s:EBinary}"",""_vType"":""Struct{s:String}"",""_bufferSpec"":",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:11530,Testability,test,test,11530,"dArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map()))), WriteMetadata(MakeArray(ArrayBuffer(GetField(WritePartition(MakeStream(ArrayBuffer(Literal(struct{},[])),stream<struct{}>,false),Str(""part-0""),PartitionNativeWriter({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/globals/rows/parts/,None,None)),filePath)),array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/globals/rows,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map()))), WriteMetadata(Literal(array<int64>,ArrayBuffer(1)),TableSpecWriter(gs://danking/workshop-test/1kg.mt/globals,Table{global:Struct{},key:[],row:Struct{}},rows,globals,../references,false)), WriteMetadata(MakeArray(ArrayBuffer(GetField(Ref(__iruid_368,struct{filePath: str, partitionCounts: int64}),filePath)),array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/cols/rows,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""EBaseStruct{s:EBinary}"",""_vType"":""Struct{s:String}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:11796,Testability,test,test,11796,""":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/globals/rows/parts/,None,None)),filePath)),array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/globals/rows,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map()))), WriteMetadata(Literal(array<int64>,ArrayBuffer(1)),TableSpecWriter(gs://danking/workshop-test/1kg.mt/globals,Table{global:Struct{},key:[],row:Struct{}},rows,globals,../references,false)), WriteMetadata(MakeArray(ArrayBuffer(GetField(Ref(__iruid_368,struct{filePath: str, partitionCounts: int64}),filePath)),array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/cols/rows,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""EBaseStruct{s:EBinary}"",""_vType"":""Struct{s:String}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map()))), WriteMetadata(MakeArray(ArrayBuffer(GetField(Ref(__iruid_368,struct{filePath: str, partitionCounts: int64}),partitionCounts)),array<int64>),TableSpecWriter(gs://danking/workshop-test/1kg.mt/cols,Table{global:Struct{},key:[s],row:Struct{s:String}},rows,../globals/rows,../references,false)), Let(__iruid_374,ToArray(StreamMap(ToStream(Ref(__iruid_369,array<struct{filePath: str, partitionCounts: int64}>),false),__iruid_375,GetField",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:12454,Testability,test,test,12454,"name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map()))), WriteMetadata(Literal(array<int64>,ArrayBuffer(1)),TableSpecWriter(gs://danking/workshop-test/1kg.mt/globals,Table{global:Struct{},key:[],row:Struct{}},rows,globals,../references,false)), WriteMetadata(MakeArray(ArrayBuffer(GetField(Ref(__iruid_368,struct{filePath: str, partitionCounts: int64}),filePath)),array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/cols/rows,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""EBaseStruct{s:EBinary}"",""_vType"":""Struct{s:String}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map()))), WriteMetadata(MakeArray(ArrayBuffer(GetField(Ref(__iruid_368,struct{filePath: str, partitionCounts: int64}),partitionCounts)),array<int64>),TableSpecWriter(gs://danking/workshop-test/1kg.mt/cols,Table{global:Struct{},key:[s],row:Struct{s:String}},rows,../globals/rows,../references,false)), Let(__iruid_374,ToArray(StreamMap(ToStream(Ref(__iruid_369,array<struct{filePath: str, partitionCounts: int64}>),false),__iruid_375,GetField(Ref(__iruid_375,struct{filePath: str, partitionCounts: int64}),filePath))),Begin(ArrayBuffer(WriteMetadata(Ref(__iruid_374,array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/rows/rows,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{locus:+EBaseStruct{contig:+EBinary,position:+EInt32},alleles:+EArray[+EBinary],rsid:EBinary,qual:EFloat64,filters:EArray[+EBinary],info:+EBaseStruct{AC:EArray[EInt32],AF:EA",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:12879,Testability,test,test,12879,"tionCounts: int64}),filePath)),array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/cols/rows,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""EBaseStruct{s:EBinary}"",""_vType"":""Struct{s:String}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map()))), WriteMetadata(MakeArray(ArrayBuffer(GetField(Ref(__iruid_368,struct{filePath: str, partitionCounts: int64}),partitionCounts)),array<int64>),TableSpecWriter(gs://danking/workshop-test/1kg.mt/cols,Table{global:Struct{},key:[s],row:Struct{s:String}},rows,../globals/rows,../references,false)), Let(__iruid_374,ToArray(StreamMap(ToStream(Ref(__iruid_369,array<struct{filePath: str, partitionCounts: int64}>),false),__iruid_375,GetField(Ref(__iruid_375,struct{filePath: str, partitionCounts: int64}),filePath))),Begin(ArrayBuffer(WriteMetadata(Ref(__iruid_374,array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/rows/rows,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{locus:+EBaseStruct{contig:+EBinary,position:+EInt32},alleles:+EArray[+EBinary],rsid:EBinary,qual:EFloat64,filters:EArray[+EBinary],info:+EBaseStruct{AC:EArray[EInt32],AF:EArray[EFloat64],AN:EInt32,BaseQRankSum:EFloat64,ClippingRankSum:EFloat64,DP:EInt32,DS:+EBoolean,FS:EFloat64,HaplotypeScore:EFloat64,InbreedingCoeff:EFloat64,MLEAC:EArray[EInt32],MLEAF:EArray[EFloat64],MQ:EFloat64,MQ0:EInt32,MQRankSum:EFloat64,QD:EFloat64,ReadPosRankSum:EFloat64,set:EBinary}}"",""_vType"":""Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Float64,InbreedingCoeff:Float64,MLEAC:Ar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:15576,Testability,test,test,15576,"2,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Float64,InbreedingCoeff:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(locus, alleles),JArray(List(JObject(List((start,JObject(List((locus,JObject(List((contig,JString(1)), (position,JInt(904165))))), (alleles,JArray(List(JString(G), JString(A))))))), (end,JObject(List((locus,JObject(List((contig,JString(4)), (position,JInt(70592790))))), (alleles,JArray(List(JString(G), JString(T))))))), (includeStart,JBool(true)), (includeEnd,JBool(true)))), JObject(List((start,JObject(List((locus,JObject(List((contig,JString(4)), (position,JInt(70899111))))), (alleles,JArray(List(JString(G), JString(A))))))), (end,JObject(List((locus,JObject(List((contig,JString(8)), (position,JInt(126013303))))), (alleles,JArray(List(JString(G), JString(A))))))), (includeStart,JBool(true)), (includeEnd,JBool(true)))), JObject(List((start,JObject(List((locus,JObject(List((contig,JString(8)), (position,JInt(126888589))))), (alleles,JArray(List(JString(G), JString(A))))))), (end,JObject(List((locus,JObject(List((contig,JString(14)), (position,JInt(75037676))))), (alleles,JArray(List(JString(T), JString(C))))))), (includeStart,JBool(true)), (includeEnd,JBool(true)))), JObject(List((start,JObject(List((locus,JObject(List((contig,JString(14)), (position,JInt(75234101))))), (alleles,JArray(List(JString(T), JString(G))))))), (end,JObject(List((locus,JObject(List((contig,JString(X)), (position,JInt(154087368))))), (alleles,JArray(List(JString(T), JString(A))))))), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map()))), WriteMetadata(Ref(__iruid_374,array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:16982,Testability,test,test,16982,"d,JObject(List((locus,JObject(List((contig,JString(X)), (position,JInt(154087368))))), (alleles,JArray(List(JString(T), JString(A))))))), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map()))), WriteMetadata(Ref(__iruid_374,array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/entries/rows,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[+EBaseStruct{GT:EInt32,AD:EArray[+EInt32],DP:EInt32,GQ:EInt32,PL:EArray[+EInt32]}]}"",""_vType"":""Struct{`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{GT:Call,AD:Array[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}]}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},WrappedArray(),JArray(List(JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))), JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))), JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))), JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map())))))), Let(__iruid_376,ToArray(StreamMap(ToStream(Ref(__iruid_369,array<struct{filePath: str, partitionCounts: int64}>),false),__iruid_377,GetField(Ref(__iruid_377,struct{filePath: str, partitionCounts: int64}),partitionCounts))),Begin(ArrayBuffer(WriteMetadata(Ref(__iruid_376,array<int64>),TableSpecWriter(gs://danking/workshop-test/1kg.mt/rows,Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Flo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:17570,Testability,test,test,17570,"JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map())))))), Let(__iruid_376,ToArray(StreamMap(ToStream(Ref(__iruid_369,array<struct{filePath: str, partitionCounts: int64}>),false),__iruid_377,GetField(Ref(__iruid_377,struct{filePath: str, partitionCounts: int64}),partitionCounts))),Begin(ArrayBuffer(WriteMetadata(Ref(__iruid_376,array<int64>),TableSpecWriter(gs://danking/workshop-test/1kg.mt/rows,Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Float64,InbreedingCoeff:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}}},rows,../globals/rows,../references,false)), WriteMetadata(Ref(__iruid_376,array<int64>),TableSpecWriter(gs://danking/workshop-test/1kg.mt/entries,Table{global:Struct{},key:[],row:Struct{`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{GT:Call,AD:Array[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}]}},rows,../globals/rows,../references,false)), WriteMetadata(MakeStruct(ArrayBuffer((cols,GetField(Ref(__iruid_368,struct{filePath: str, partitionCounts: int64}),partitionCounts)), (rows,Ref(__iruid_376,array<int64>)))),MatrixSpecWriter(gs://danking/workshop-test/1kg.mt,Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Float64,InbreedingCoeff:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}},entry:Struct{GT:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:18011,Testability,test,test,18011,"(WriteMetadata(Ref(__iruid_376,array<int64>),TableSpecWriter(gs://danking/workshop-test/1kg.mt/rows,Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Float64,InbreedingCoeff:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}}},rows,../globals/rows,../references,false)), WriteMetadata(Ref(__iruid_376,array<int64>),TableSpecWriter(gs://danking/workshop-test/1kg.mt/entries,Table{global:Struct{},key:[],row:Struct{`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{GT:Call,AD:Array[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}]}},rows,../globals/rows,../references,false)), WriteMetadata(MakeStruct(ArrayBuffer((cols,GetField(Ref(__iruid_368,struct{filePath: str, partitionCounts: int64}),partitionCounts)), (rows,Ref(__iruid_376,array<int64>)))),MatrixSpecWriter(gs://danking/workshop-test/1kg.mt,Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Float64,InbreedingCoeff:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}},entry:Struct{GT:Call,AD:Array[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}},rows/rows,globals/rows,cols/rows,entries/rows,references,true))))))))),RelationalWriter(gs://danking/workshop-test/1kg.mt/entries,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/rows,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/cols,false,None)),RelationalWriter(gs://danking/workshop",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:18690,Testability,test,test,18690,":Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}}},rows,../globals/rows,../references,false)), WriteMetadata(Ref(__iruid_376,array<int64>),TableSpecWriter(gs://danking/workshop-test/1kg.mt/entries,Table{global:Struct{},key:[],row:Struct{`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{GT:Call,AD:Array[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}]}},rows,../globals/rows,../references,false)), WriteMetadata(MakeStruct(ArrayBuffer((cols,GetField(Ref(__iruid_368,struct{filePath: str, partitionCounts: int64}),partitionCounts)), (rows,Ref(__iruid_376,array<int64>)))),MatrixSpecWriter(gs://danking/workshop-test/1kg.mt,Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Float64,InbreedingCoeff:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}},entry:Struct{GT:Call,AD:Array[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}},rows/rows,globals/rows,cols/rows,entries/rows,references,true))))))))),RelationalWriter(gs://danking/workshop-test/1kg.mt/entries,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/rows,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/cols,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/globals,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt,true,Some((references,Set(GRCh37)))))); 	at scala.collection.MapLike$class.default(MapLike.scala:228); 	at scala.collection.AbstractMap.default(Map.scala:59); 	at scala.collection.mutable.HashMap.apply(HashMap.scala:65); 	at is.hail.expr.ir.Memo.lookup(RefEquality.scala:38); 	at is.hail.expr.ir.Memo.lookup(RefEquality.scala:37); 	at is.hail.expr.ir.Memo.apply(RefEquality.sc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:18762,Testability,test,test,18762,"PL:Array[Int32]}]}},rows,../globals/rows,../references,false)), WriteMetadata(MakeStruct(ArrayBuffer((cols,GetField(Ref(__iruid_368,struct{filePath: str, partitionCounts: int64}),partitionCounts)), (rows,Ref(__iruid_376,array<int64>)))),MatrixSpecWriter(gs://danking/workshop-test/1kg.mt,Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Float64,InbreedingCoeff:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}},entry:Struct{GT:Call,AD:Array[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}},rows/rows,globals/rows,cols/rows,entries/rows,references,true))))))))),RelationalWriter(gs://danking/workshop-test/1kg.mt/entries,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/rows,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/cols,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/globals,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt,true,Some((references,Set(GRCh37)))))); 	at scala.collection.MapLike$class.default(MapLike.scala:228); 	at scala.collection.AbstractMap.default(Map.scala:59); 	at scala.collection.mutable.HashMap.apply(HashMap.scala:65); 	at is.hail.expr.ir.Memo.lookup(RefEquality.scala:38); 	at is.hail.expr.ir.Memo.lookup(RefEquality.scala:37); 	at is.hail.expr.ir.Memo.apply(RefEquality.scala:40); 	at is.hail.expr.ir.Requiredness.lookup(Requiredness.scala:41); 	at is.hail.expr.ir.Requiredness$$anonfun$analyzeIR$16.apply(Requiredness.scala:616); 	at is.hail.expr.ir.Requiredness$$anonfun$analyzeIR$16.apply(Requiredness.scala:615); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.forea",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:18831,Testability,test,test,18831,"etadata(MakeStruct(ArrayBuffer((cols,GetField(Ref(__iruid_368,struct{filePath: str, partitionCounts: int64}),partitionCounts)), (rows,Ref(__iruid_376,array<int64>)))),MatrixSpecWriter(gs://danking/workshop-test/1kg.mt,Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Float64,InbreedingCoeff:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}},entry:Struct{GT:Call,AD:Array[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}},rows/rows,globals/rows,cols/rows,entries/rows,references,true))))))))),RelationalWriter(gs://danking/workshop-test/1kg.mt/entries,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/rows,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/cols,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/globals,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt,true,Some((references,Set(GRCh37)))))); 	at scala.collection.MapLike$class.default(MapLike.scala:228); 	at scala.collection.AbstractMap.default(Map.scala:59); 	at scala.collection.mutable.HashMap.apply(HashMap.scala:65); 	at is.hail.expr.ir.Memo.lookup(RefEquality.scala:38); 	at is.hail.expr.ir.Memo.lookup(RefEquality.scala:37); 	at is.hail.expr.ir.Memo.apply(RefEquality.scala:40); 	at is.hail.expr.ir.Requiredness.lookup(Requiredness.scala:41); 	at is.hail.expr.ir.Requiredness$$anonfun$analyzeIR$16.apply(Requiredness.scala:616); 	at is.hail.expr.ir.Requiredness$$anonfun$analyzeIR$16.apply(Requiredness.scala:615); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at is.hail.expr.ir.Requiredness.analyzeIR(Re",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:18900,Testability,test,test,18900,"filePath: str, partitionCounts: int64}),partitionCounts)), (rows,Ref(__iruid_376,array<int64>)))),MatrixSpecWriter(gs://danking/workshop-test/1kg.mt,Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Float64,InbreedingCoeff:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}},entry:Struct{GT:Call,AD:Array[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}},rows/rows,globals/rows,cols/rows,entries/rows,references,true))))))))),RelationalWriter(gs://danking/workshop-test/1kg.mt/entries,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/rows,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/cols,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/globals,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt,true,Some((references,Set(GRCh37)))))); 	at scala.collection.MapLike$class.default(MapLike.scala:228); 	at scala.collection.AbstractMap.default(Map.scala:59); 	at scala.collection.mutable.HashMap.apply(HashMap.scala:65); 	at is.hail.expr.ir.Memo.lookup(RefEquality.scala:38); 	at is.hail.expr.ir.Memo.lookup(RefEquality.scala:37); 	at is.hail.expr.ir.Memo.apply(RefEquality.scala:40); 	at is.hail.expr.ir.Requiredness.lookup(Requiredness.scala:41); 	at is.hail.expr.ir.Requiredness$$anonfun$analyzeIR$16.apply(Requiredness.scala:616); 	at is.hail.expr.ir.Requiredness$$anonfun$analyzeIR$16.apply(Requiredness.scala:615); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at is.hail.expr.ir.Requiredness.analyzeIR(Requiredness.scala:615); 	at is.hail.expr.ir.Requiredness.analyze(Requi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:18972,Testability,test,test,18972,"iruid_376,array<int64>)))),MatrixSpecWriter(gs://danking/workshop-test/1kg.mt,Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Float64,InbreedingCoeff:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}},entry:Struct{GT:Call,AD:Array[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}},rows/rows,globals/rows,cols/rows,entries/rows,references,true))))))))),RelationalWriter(gs://danking/workshop-test/1kg.mt/entries,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/rows,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/cols,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/globals,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt,true,Some((references,Set(GRCh37)))))); 	at scala.collection.MapLike$class.default(MapLike.scala:228); 	at scala.collection.AbstractMap.default(Map.scala:59); 	at scala.collection.mutable.HashMap.apply(HashMap.scala:65); 	at is.hail.expr.ir.Memo.lookup(RefEquality.scala:38); 	at is.hail.expr.ir.Memo.lookup(RefEquality.scala:37); 	at is.hail.expr.ir.Memo.apply(RefEquality.scala:40); 	at is.hail.expr.ir.Requiredness.lookup(Requiredness.scala:41); 	at is.hail.expr.ir.Requiredness$$anonfun$analyzeIR$16.apply(Requiredness.scala:616); 	at is.hail.expr.ir.Requiredness$$anonfun$analyzeIR$16.apply(Requiredness.scala:615); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); 	at is.hail.expr.ir.Requiredness.analyzeIR(Requiredness.scala:615); 	at is.hail.expr.ir.Requiredness.analyze(Requiredness.scala:265); 	at is.hail.expr.ir.Requiredness.run(Requiredness.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/issues/9856:22362,Testability,log,logTime,22362,ckend$$anonfun$execute$1$$anonfun$apply$11$$anonfun$apply$12.apply(ServiceBackend.scala:314); 	at is.hail.backend.service.ServiceBackend$$anonfun$execute$1$$anonfun$apply$11$$anonfun$apply$12.apply(ServiceBackend.scala:308); 	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25); 	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23); 	at is.hail.utils.package$.using(package.scala:618); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:12); 	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23); 	at is.hail.backend.service.ServiceBackend.userContext(ServiceBackend.scala:122); 	at is.hail.backend.service.ServiceBackend$$anonfun$execute$1$$anonfun$apply$11.apply(ServiceBackend.scala:308); 	at is.hail.backend.service.ServiceBackend$$anonfun$execute$1$$anonfun$apply$11.apply(ServiceBackend.scala:307); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59); 	at is.hail.backend.service.ServiceBackend$$anonfun$execute$1.apply(ServiceBackend.scala:307); 	at is.hail.backend.service.ServiceBackend$$anonfun$execute$1.apply(ServiceBackend.scala:307); 	at is.hail.backend.service.ServiceBackend.statusForException(ServiceBackend.scala:230); 	at is.hail.backend.service.ServiceBackend.execute(ServiceBackend.scala:306); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.Gate,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9856
https://github.com/hail-is/hail/pull/9857:173,Security,validat,validation,173,"Pulled out `command`, `image` and `mount_docker_socket` as docker-job-specific keys that don't apply to non-docker jobs. Also pushed handling of deprecated keys into schema validation.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9857
https://github.com/hail-is/hail/pull/9858:221,Availability,error,error,221,"If a pod is unreachable for any reason, we previously retried forever. However,; a pods are ephemeral; we cannot assume they will return. Instead, if we fail to; contact a pod, we remove it from the pods list and log the error. If the pod; really does exist, the monitor_pods loop will attempt to initialize it again.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9858
https://github.com/hail-is/hail/pull/9858:213,Testability,log,log,213,"If a pod is unreachable for any reason, we previously retried forever. However,; a pods are ephemeral; we cannot assume they will return. Instead, if we fail to; contact a pod, we remove it from the pods list and log the error. If the pod; really does exist, the monitor_pods loop will attempt to initialize it again.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9858
https://github.com/hail-is/hail/pull/9861:364,Security,validat,validating,364,"I thought about porting some of the typechecker stuff from hail, but they don't serve quite the same purpose, and the functions themselves are pretty simple. This does move the schema definitions to the bottom of the file rather than at the top, but this way we have a schema description that includes requiredness and is guaranteed to be the thing we're actually validating on.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9861
https://github.com/hail-is/hail/pull/9861:150,Usability,simpl,simple,150,"I thought about porting some of the typechecker stuff from hail, but they don't serve quite the same purpose, and the functions themselves are pretty simple. This does move the schema definitions to the bottom of the file rather than at the top, but this way we have a schema description that includes requiredness and is guaranteed to be the thing we're actually validating on.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9861
https://github.com/hail-is/hail/pull/9862:441,Deployability,deploy,deploy,441,"`tls.py` has many different functions with long names. This change reduces it to three functions:. - internal_server_ssl_context; - internal_client_ssl_context; - external_client_ssl_context. I also added `httpx.py` which contains the HTTPS-related functions that `tls.py` previously; contained. I also simplified the HTTPS-related functions to just:. - client_session; - blocking_client_session. I determine internal vs. external using the deploy config. ---. An [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext) defines how a; network library (such as `aiohttp`) should perform SSL/TLS. Let's look at an example:. ```python3; server_ssl_context = ssl.create_default_context(; purpose=Purpose.CLIENT_AUTH,; cafile='/incoming.cacerts'); server_ssl_context.load_cert_chain(ssl_config['cert'],; keyfile=ssl_config['key'],; password=None); server_ssl_context.verify_mode = ssl.CERT_OPTIONAL; server_ssl_context.check_hostname = False; ```. The first function call states that we are a *server* performing *client; authentication* (`Purpose.CLIENT_AUTH`). We also state that anyone who sends requests to us will be; identified by a certificate that is trusted by our certificate database: `/incoming.cacerts` (which; is a file). `load_cert_chain` states where to find the certificates and secret key that prove who we are. The; certificate and secret key together are like a property title that proves someone owns a house. The; `password=None` means that our secret key has no password. Some keys are themselves locked by a; password. `verify_mode` means what do we expect our clients to have. `CERT_OPTIONAL` means anonymous clients; are OK. This is how servers normally operate (https://google.com does not care who you are). `check_hostname` means should we verify that the client certificate matches the client's; hostname. Since we allow anonymous clients, this must be `False`. ---. `test-address.py` is a gross hack. It will disappear in subsequent PRs. For now, I push",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9862
https://github.com/hail-is/hail/pull/9862:67,Energy Efficiency,reduce,reduces,67,"`tls.py` has many different functions with long names. This change reduces it to three functions:. - internal_server_ssl_context; - internal_client_ssl_context; - external_client_ssl_context. I also added `httpx.py` which contains the HTTPS-related functions that `tls.py` previously; contained. I also simplified the HTTPS-related functions to just:. - client_session; - blocking_client_session. I determine internal vs. external using the deploy config. ---. An [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext) defines how a; network library (such as `aiohttp`) should perform SSL/TLS. Let's look at an example:. ```python3; server_ssl_context = ssl.create_default_context(; purpose=Purpose.CLIENT_AUTH,; cafile='/incoming.cacerts'); server_ssl_context.load_cert_chain(ssl_config['cert'],; keyfile=ssl_config['key'],; password=None); server_ssl_context.verify_mode = ssl.CERT_OPTIONAL; server_ssl_context.check_hostname = False; ```. The first function call states that we are a *server* performing *client; authentication* (`Purpose.CLIENT_AUTH`). We also state that anyone who sends requests to us will be; identified by a certificate that is trusted by our certificate database: `/incoming.cacerts` (which; is a file). `load_cert_chain` states where to find the certificates and secret key that prove who we are. The; certificate and secret key together are like a property title that proves someone owns a house. The; `password=None` means that our secret key has no password. Some keys are themselves locked by a; password. `verify_mode` means what do we expect our clients to have. `CERT_OPTIONAL` means anonymous clients; are OK. This is how servers normally operate (https://google.com does not care who you are). `check_hostname` means should we verify that the client certificate matches the client's; hostname. Since we allow anonymous clients, this must be `False`. ---. `test-address.py` is a gross hack. It will disappear in subsequent PRs. For now, I push",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9862
https://github.com/hail-is/hail/pull/9862:448,Modifiability,config,config,448,"`tls.py` has many different functions with long names. This change reduces it to three functions:. - internal_server_ssl_context; - internal_client_ssl_context; - external_client_ssl_context. I also added `httpx.py` which contains the HTTPS-related functions that `tls.py` previously; contained. I also simplified the HTTPS-related functions to just:. - client_session; - blocking_client_session. I determine internal vs. external using the deploy config. ---. An [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext) defines how a; network library (such as `aiohttp`) should perform SSL/TLS. Let's look at an example:. ```python3; server_ssl_context = ssl.create_default_context(; purpose=Purpose.CLIENT_AUTH,; cafile='/incoming.cacerts'); server_ssl_context.load_cert_chain(ssl_config['cert'],; keyfile=ssl_config['key'],; password=None); server_ssl_context.verify_mode = ssl.CERT_OPTIONAL; server_ssl_context.check_hostname = False; ```. The first function call states that we are a *server* performing *client; authentication* (`Purpose.CLIENT_AUTH`). We also state that anyone who sends requests to us will be; identified by a certificate that is trusted by our certificate database: `/incoming.cacerts` (which; is a file). `load_cert_chain` states where to find the certificates and secret key that prove who we are. The; certificate and secret key together are like a property title that proves someone owns a house. The; `password=None` means that our secret key has no password. Some keys are themselves locked by a; password. `verify_mode` means what do we expect our clients to have. `CERT_OPTIONAL` means anonymous clients; are OK. This is how servers normally operate (https://google.com does not care who you are). `check_hostname` means should we verify that the client certificate matches the client's; hostname. Since we allow anonymous clients, this must be `False`. ---. `test-address.py` is a gross hack. It will disappear in subsequent PRs. For now, I push",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9862
https://github.com/hail-is/hail/pull/9862:600,Performance,perform,perform,600,"`tls.py` has many different functions with long names. This change reduces it to three functions:. - internal_server_ssl_context; - internal_client_ssl_context; - external_client_ssl_context. I also added `httpx.py` which contains the HTTPS-related functions that `tls.py` previously; contained. I also simplified the HTTPS-related functions to just:. - client_session; - blocking_client_session. I determine internal vs. external using the deploy config. ---. An [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext) defines how a; network library (such as `aiohttp`) should perform SSL/TLS. Let's look at an example:. ```python3; server_ssl_context = ssl.create_default_context(; purpose=Purpose.CLIENT_AUTH,; cafile='/incoming.cacerts'); server_ssl_context.load_cert_chain(ssl_config['cert'],; keyfile=ssl_config['key'],; password=None); server_ssl_context.verify_mode = ssl.CERT_OPTIONAL; server_ssl_context.check_hostname = False; ```. The first function call states that we are a *server* performing *client; authentication* (`Purpose.CLIENT_AUTH`). We also state that anyone who sends requests to us will be; identified by a certificate that is trusted by our certificate database: `/incoming.cacerts` (which; is a file). `load_cert_chain` states where to find the certificates and secret key that prove who we are. The; certificate and secret key together are like a property title that proves someone owns a house. The; `password=None` means that our secret key has no password. Some keys are themselves locked by a; password. `verify_mode` means what do we expect our clients to have. `CERT_OPTIONAL` means anonymous clients; are OK. This is how servers normally operate (https://google.com does not care who you are). `check_hostname` means should we verify that the client certificate matches the client's; hostname. Since we allow anonymous clients, this must be `False`. ---. `test-address.py` is a gross hack. It will disappear in subsequent PRs. For now, I push",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9862
https://github.com/hail-is/hail/pull/9862:1019,Performance,perform,performing,1019,"any different functions with long names. This change reduces it to three functions:. - internal_server_ssl_context; - internal_client_ssl_context; - external_client_ssl_context. I also added `httpx.py` which contains the HTTPS-related functions that `tls.py` previously; contained. I also simplified the HTTPS-related functions to just:. - client_session; - blocking_client_session. I determine internal vs. external using the deploy config. ---. An [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext) defines how a; network library (such as `aiohttp`) should perform SSL/TLS. Let's look at an example:. ```python3; server_ssl_context = ssl.create_default_context(; purpose=Purpose.CLIENT_AUTH,; cafile='/incoming.cacerts'); server_ssl_context.load_cert_chain(ssl_config['cert'],; keyfile=ssl_config['key'],; password=None); server_ssl_context.verify_mode = ssl.CERT_OPTIONAL; server_ssl_context.check_hostname = False; ```. The first function call states that we are a *server* performing *client; authentication* (`Purpose.CLIENT_AUTH`). We also state that anyone who sends requests to us will be; identified by a certificate that is trusted by our certificate database: `/incoming.cacerts` (which; is a file). `load_cert_chain` states where to find the certificates and secret key that prove who we are. The; certificate and secret key together are like a property title that proves someone owns a house. The; `password=None` means that our secret key has no password. Some keys are themselves locked by a; password. `verify_mode` means what do we expect our clients to have. `CERT_OPTIONAL` means anonymous clients; are OK. This is how servers normally operate (https://google.com does not care who you are). `check_hostname` means should we verify that the client certificate matches the client's; hostname. Since we allow anonymous clients, this must be `False`. ---. `test-address.py` is a gross hack. It will disappear in subsequent PRs. For now, I pushed all the; gr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9862
https://github.com/hail-is/hail/pull/9862:849,Security,password,password,849,"`tls.py` has many different functions with long names. This change reduces it to three functions:. - internal_server_ssl_context; - internal_client_ssl_context; - external_client_ssl_context. I also added `httpx.py` which contains the HTTPS-related functions that `tls.py` previously; contained. I also simplified the HTTPS-related functions to just:. - client_session; - blocking_client_session. I determine internal vs. external using the deploy config. ---. An [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext) defines how a; network library (such as `aiohttp`) should perform SSL/TLS. Let's look at an example:. ```python3; server_ssl_context = ssl.create_default_context(; purpose=Purpose.CLIENT_AUTH,; cafile='/incoming.cacerts'); server_ssl_context.load_cert_chain(ssl_config['cert'],; keyfile=ssl_config['key'],; password=None); server_ssl_context.verify_mode = ssl.CERT_OPTIONAL; server_ssl_context.check_hostname = False; ```. The first function call states that we are a *server* performing *client; authentication* (`Purpose.CLIENT_AUTH`). We also state that anyone who sends requests to us will be; identified by a certificate that is trusted by our certificate database: `/incoming.cacerts` (which; is a file). `load_cert_chain` states where to find the certificates and secret key that prove who we are. The; certificate and secret key together are like a property title that proves someone owns a house. The; `password=None` means that our secret key has no password. Some keys are themselves locked by a; password. `verify_mode` means what do we expect our clients to have. `CERT_OPTIONAL` means anonymous clients; are OK. This is how servers normally operate (https://google.com does not care who you are). `check_hostname` means should we verify that the client certificate matches the client's; hostname. Since we allow anonymous clients, this must be `False`. ---. `test-address.py` is a gross hack. It will disappear in subsequent PRs. For now, I push",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9862
https://github.com/hail-is/hail/pull/9862:1039,Security,authenticat,authentication,1039,"any different functions with long names. This change reduces it to three functions:. - internal_server_ssl_context; - internal_client_ssl_context; - external_client_ssl_context. I also added `httpx.py` which contains the HTTPS-related functions that `tls.py` previously; contained. I also simplified the HTTPS-related functions to just:. - client_session; - blocking_client_session. I determine internal vs. external using the deploy config. ---. An [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext) defines how a; network library (such as `aiohttp`) should perform SSL/TLS. Let's look at an example:. ```python3; server_ssl_context = ssl.create_default_context(; purpose=Purpose.CLIENT_AUTH,; cafile='/incoming.cacerts'); server_ssl_context.load_cert_chain(ssl_config['cert'],; keyfile=ssl_config['key'],; password=None); server_ssl_context.verify_mode = ssl.CERT_OPTIONAL; server_ssl_context.check_hostname = False; ```. The first function call states that we are a *server* performing *client; authentication* (`Purpose.CLIENT_AUTH`). We also state that anyone who sends requests to us will be; identified by a certificate that is trusted by our certificate database: `/incoming.cacerts` (which; is a file). `load_cert_chain` states where to find the certificates and secret key that prove who we are. The; certificate and secret key together are like a property title that proves someone owns a house. The; `password=None` means that our secret key has no password. Some keys are themselves locked by a; password. `verify_mode` means what do we expect our clients to have. `CERT_OPTIONAL` means anonymous clients; are OK. This is how servers normally operate (https://google.com does not care who you are). `check_hostname` means should we verify that the client certificate matches the client's; hostname. Since we allow anonymous clients, this must be `False`. ---. `test-address.py` is a gross hack. It will disappear in subsequent PRs. For now, I pushed all the; gr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9862
https://github.com/hail-is/hail/pull/9862:1156,Security,certificate,certificate,1156,"es. This change reduces it to three functions:. - internal_server_ssl_context; - internal_client_ssl_context; - external_client_ssl_context. I also added `httpx.py` which contains the HTTPS-related functions that `tls.py` previously; contained. I also simplified the HTTPS-related functions to just:. - client_session; - blocking_client_session. I determine internal vs. external using the deploy config. ---. An [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext) defines how a; network library (such as `aiohttp`) should perform SSL/TLS. Let's look at an example:. ```python3; server_ssl_context = ssl.create_default_context(; purpose=Purpose.CLIENT_AUTH,; cafile='/incoming.cacerts'); server_ssl_context.load_cert_chain(ssl_config['cert'],; keyfile=ssl_config['key'],; password=None); server_ssl_context.verify_mode = ssl.CERT_OPTIONAL; server_ssl_context.check_hostname = False; ```. The first function call states that we are a *server* performing *client; authentication* (`Purpose.CLIENT_AUTH`). We also state that anyone who sends requests to us will be; identified by a certificate that is trusted by our certificate database: `/incoming.cacerts` (which; is a file). `load_cert_chain` states where to find the certificates and secret key that prove who we are. The; certificate and secret key together are like a property title that proves someone owns a house. The; `password=None` means that our secret key has no password. Some keys are themselves locked by a; password. `verify_mode` means what do we expect our clients to have. `CERT_OPTIONAL` means anonymous clients; are OK. This is how servers normally operate (https://google.com does not care who you are). `check_hostname` means should we verify that the client certificate matches the client's; hostname. Since we allow anonymous clients, this must be `False`. ---. `test-address.py` is a gross hack. It will disappear in subsequent PRs. For now, I pushed all the; gross hack stuff into that file alone.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9862
https://github.com/hail-is/hail/pull/9862:1191,Security,certificate,certificate,1191,"es. This change reduces it to three functions:. - internal_server_ssl_context; - internal_client_ssl_context; - external_client_ssl_context. I also added `httpx.py` which contains the HTTPS-related functions that `tls.py` previously; contained. I also simplified the HTTPS-related functions to just:. - client_session; - blocking_client_session. I determine internal vs. external using the deploy config. ---. An [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext) defines how a; network library (such as `aiohttp`) should perform SSL/TLS. Let's look at an example:. ```python3; server_ssl_context = ssl.create_default_context(; purpose=Purpose.CLIENT_AUTH,; cafile='/incoming.cacerts'); server_ssl_context.load_cert_chain(ssl_config['cert'],; keyfile=ssl_config['key'],; password=None); server_ssl_context.verify_mode = ssl.CERT_OPTIONAL; server_ssl_context.check_hostname = False; ```. The first function call states that we are a *server* performing *client; authentication* (`Purpose.CLIENT_AUTH`). We also state that anyone who sends requests to us will be; identified by a certificate that is trusted by our certificate database: `/incoming.cacerts` (which; is a file). `load_cert_chain` states where to find the certificates and secret key that prove who we are. The; certificate and secret key together are like a property title that proves someone owns a house. The; `password=None` means that our secret key has no password. Some keys are themselves locked by a; password. `verify_mode` means what do we expect our clients to have. `CERT_OPTIONAL` means anonymous clients; are OK. This is how servers normally operate (https://google.com does not care who you are). `check_hostname` means should we verify that the client certificate matches the client's; hostname. Since we allow anonymous clients, this must be `False`. ---. `test-address.py` is a gross hack. It will disappear in subsequent PRs. For now, I pushed all the; gross hack stuff into that file alone.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9862
https://github.com/hail-is/hail/pull/9862:1296,Security,certificate,certificates,1296,"es. This change reduces it to three functions:. - internal_server_ssl_context; - internal_client_ssl_context; - external_client_ssl_context. I also added `httpx.py` which contains the HTTPS-related functions that `tls.py` previously; contained. I also simplified the HTTPS-related functions to just:. - client_session; - blocking_client_session. I determine internal vs. external using the deploy config. ---. An [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext) defines how a; network library (such as `aiohttp`) should perform SSL/TLS. Let's look at an example:. ```python3; server_ssl_context = ssl.create_default_context(; purpose=Purpose.CLIENT_AUTH,; cafile='/incoming.cacerts'); server_ssl_context.load_cert_chain(ssl_config['cert'],; keyfile=ssl_config['key'],; password=None); server_ssl_context.verify_mode = ssl.CERT_OPTIONAL; server_ssl_context.check_hostname = False; ```. The first function call states that we are a *server* performing *client; authentication* (`Purpose.CLIENT_AUTH`). We also state that anyone who sends requests to us will be; identified by a certificate that is trusted by our certificate database: `/incoming.cacerts` (which; is a file). `load_cert_chain` states where to find the certificates and secret key that prove who we are. The; certificate and secret key together are like a property title that proves someone owns a house. The; `password=None` means that our secret key has no password. Some keys are themselves locked by a; password. `verify_mode` means what do we expect our clients to have. `CERT_OPTIONAL` means anonymous clients; are OK. This is how servers normally operate (https://google.com does not care who you are). `check_hostname` means should we verify that the client certificate matches the client's; hostname. Since we allow anonymous clients, this must be `False`. ---. `test-address.py` is a gross hack. It will disappear in subsequent PRs. For now, I pushed all the; gross hack stuff into that file alone.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9862
https://github.com/hail-is/hail/pull/9862:1352,Security,certificate,certificate,1352,"es. This change reduces it to three functions:. - internal_server_ssl_context; - internal_client_ssl_context; - external_client_ssl_context. I also added `httpx.py` which contains the HTTPS-related functions that `tls.py` previously; contained. I also simplified the HTTPS-related functions to just:. - client_session; - blocking_client_session. I determine internal vs. external using the deploy config. ---. An [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext) defines how a; network library (such as `aiohttp`) should perform SSL/TLS. Let's look at an example:. ```python3; server_ssl_context = ssl.create_default_context(; purpose=Purpose.CLIENT_AUTH,; cafile='/incoming.cacerts'); server_ssl_context.load_cert_chain(ssl_config['cert'],; keyfile=ssl_config['key'],; password=None); server_ssl_context.verify_mode = ssl.CERT_OPTIONAL; server_ssl_context.check_hostname = False; ```. The first function call states that we are a *server* performing *client; authentication* (`Purpose.CLIENT_AUTH`). We also state that anyone who sends requests to us will be; identified by a certificate that is trusted by our certificate database: `/incoming.cacerts` (which; is a file). `load_cert_chain` states where to find the certificates and secret key that prove who we are. The; certificate and secret key together are like a property title that proves someone owns a house. The; `password=None` means that our secret key has no password. Some keys are themselves locked by a; password. `verify_mode` means what do we expect our clients to have. `CERT_OPTIONAL` means anonymous clients; are OK. This is how servers normally operate (https://google.com does not care who you are). `check_hostname` means should we verify that the client certificate matches the client's; hostname. Since we allow anonymous clients, this must be `False`. ---. `test-address.py` is a gross hack. It will disappear in subsequent PRs. For now, I pushed all the; gross hack stuff into that file alone.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9862
https://github.com/hail-is/hail/pull/9862:1454,Security,password,password,1454,"es. This change reduces it to three functions:. - internal_server_ssl_context; - internal_client_ssl_context; - external_client_ssl_context. I also added `httpx.py` which contains the HTTPS-related functions that `tls.py` previously; contained. I also simplified the HTTPS-related functions to just:. - client_session; - blocking_client_session. I determine internal vs. external using the deploy config. ---. An [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext) defines how a; network library (such as `aiohttp`) should perform SSL/TLS. Let's look at an example:. ```python3; server_ssl_context = ssl.create_default_context(; purpose=Purpose.CLIENT_AUTH,; cafile='/incoming.cacerts'); server_ssl_context.load_cert_chain(ssl_config['cert'],; keyfile=ssl_config['key'],; password=None); server_ssl_context.verify_mode = ssl.CERT_OPTIONAL; server_ssl_context.check_hostname = False; ```. The first function call states that we are a *server* performing *client; authentication* (`Purpose.CLIENT_AUTH`). We also state that anyone who sends requests to us will be; identified by a certificate that is trusted by our certificate database: `/incoming.cacerts` (which; is a file). `load_cert_chain` states where to find the certificates and secret key that prove who we are. The; certificate and secret key together are like a property title that proves someone owns a house. The; `password=None` means that our secret key has no password. Some keys are themselves locked by a; password. `verify_mode` means what do we expect our clients to have. `CERT_OPTIONAL` means anonymous clients; are OK. This is how servers normally operate (https://google.com does not care who you are). `check_hostname` means should we verify that the client certificate matches the client's; hostname. Since we allow anonymous clients, this must be `False`. ---. `test-address.py` is a gross hack. It will disappear in subsequent PRs. For now, I pushed all the; gross hack stuff into that file alone.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9862
https://github.com/hail-is/hail/pull/9862:1502,Security,password,password,1502,"es. This change reduces it to three functions:. - internal_server_ssl_context; - internal_client_ssl_context; - external_client_ssl_context. I also added `httpx.py` which contains the HTTPS-related functions that `tls.py` previously; contained. I also simplified the HTTPS-related functions to just:. - client_session; - blocking_client_session. I determine internal vs. external using the deploy config. ---. An [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext) defines how a; network library (such as `aiohttp`) should perform SSL/TLS. Let's look at an example:. ```python3; server_ssl_context = ssl.create_default_context(; purpose=Purpose.CLIENT_AUTH,; cafile='/incoming.cacerts'); server_ssl_context.load_cert_chain(ssl_config['cert'],; keyfile=ssl_config['key'],; password=None); server_ssl_context.verify_mode = ssl.CERT_OPTIONAL; server_ssl_context.check_hostname = False; ```. The first function call states that we are a *server* performing *client; authentication* (`Purpose.CLIENT_AUTH`). We also state that anyone who sends requests to us will be; identified by a certificate that is trusted by our certificate database: `/incoming.cacerts` (which; is a file). `load_cert_chain` states where to find the certificates and secret key that prove who we are. The; certificate and secret key together are like a property title that proves someone owns a house. The; `password=None` means that our secret key has no password. Some keys are themselves locked by a; password. `verify_mode` means what do we expect our clients to have. `CERT_OPTIONAL` means anonymous clients; are OK. This is how servers normally operate (https://google.com does not care who you are). `check_hostname` means should we verify that the client certificate matches the client's; hostname. Since we allow anonymous clients, this must be `False`. ---. `test-address.py` is a gross hack. It will disappear in subsequent PRs. For now, I pushed all the; gross hack stuff into that file alone.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9862
https://github.com/hail-is/hail/pull/9862:1550,Security,password,password,1550,"es. This change reduces it to three functions:. - internal_server_ssl_context; - internal_client_ssl_context; - external_client_ssl_context. I also added `httpx.py` which contains the HTTPS-related functions that `tls.py` previously; contained. I also simplified the HTTPS-related functions to just:. - client_session; - blocking_client_session. I determine internal vs. external using the deploy config. ---. An [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext) defines how a; network library (such as `aiohttp`) should perform SSL/TLS. Let's look at an example:. ```python3; server_ssl_context = ssl.create_default_context(; purpose=Purpose.CLIENT_AUTH,; cafile='/incoming.cacerts'); server_ssl_context.load_cert_chain(ssl_config['cert'],; keyfile=ssl_config['key'],; password=None); server_ssl_context.verify_mode = ssl.CERT_OPTIONAL; server_ssl_context.check_hostname = False; ```. The first function call states that we are a *server* performing *client; authentication* (`Purpose.CLIENT_AUTH`). We also state that anyone who sends requests to us will be; identified by a certificate that is trusted by our certificate database: `/incoming.cacerts` (which; is a file). `load_cert_chain` states where to find the certificates and secret key that prove who we are. The; certificate and secret key together are like a property title that proves someone owns a house. The; `password=None` means that our secret key has no password. Some keys are themselves locked by a; password. `verify_mode` means what do we expect our clients to have. `CERT_OPTIONAL` means anonymous clients; are OK. This is how servers normally operate (https://google.com does not care who you are). `check_hostname` means should we verify that the client certificate matches the client's; hostname. Since we allow anonymous clients, this must be `False`. ---. `test-address.py` is a gross hack. It will disappear in subsequent PRs. For now, I pushed all the; gross hack stuff into that file alone.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9862
https://github.com/hail-is/hail/pull/9862:1809,Security,certificate,certificate,1809,"es. This change reduces it to three functions:. - internal_server_ssl_context; - internal_client_ssl_context; - external_client_ssl_context. I also added `httpx.py` which contains the HTTPS-related functions that `tls.py` previously; contained. I also simplified the HTTPS-related functions to just:. - client_session; - blocking_client_session. I determine internal vs. external using the deploy config. ---. An [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext) defines how a; network library (such as `aiohttp`) should perform SSL/TLS. Let's look at an example:. ```python3; server_ssl_context = ssl.create_default_context(; purpose=Purpose.CLIENT_AUTH,; cafile='/incoming.cacerts'); server_ssl_context.load_cert_chain(ssl_config['cert'],; keyfile=ssl_config['key'],; password=None); server_ssl_context.verify_mode = ssl.CERT_OPTIONAL; server_ssl_context.check_hostname = False; ```. The first function call states that we are a *server* performing *client; authentication* (`Purpose.CLIENT_AUTH`). We also state that anyone who sends requests to us will be; identified by a certificate that is trusted by our certificate database: `/incoming.cacerts` (which; is a file). `load_cert_chain` states where to find the certificates and secret key that prove who we are. The; certificate and secret key together are like a property title that proves someone owns a house. The; `password=None` means that our secret key has no password. Some keys are themselves locked by a; password. `verify_mode` means what do we expect our clients to have. `CERT_OPTIONAL` means anonymous clients; are OK. This is how servers normally operate (https://google.com does not care who you are). `check_hostname` means should we verify that the client certificate matches the client's; hostname. Since we allow anonymous clients, this must be `False`. ---. `test-address.py` is a gross hack. It will disappear in subsequent PRs. For now, I pushed all the; gross hack stuff into that file alone.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9862
https://github.com/hail-is/hail/pull/9862:1915,Testability,test,test-address,1915,"es. This change reduces it to three functions:. - internal_server_ssl_context; - internal_client_ssl_context; - external_client_ssl_context. I also added `httpx.py` which contains the HTTPS-related functions that `tls.py` previously; contained. I also simplified the HTTPS-related functions to just:. - client_session; - blocking_client_session. I determine internal vs. external using the deploy config. ---. An [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext) defines how a; network library (such as `aiohttp`) should perform SSL/TLS. Let's look at an example:. ```python3; server_ssl_context = ssl.create_default_context(; purpose=Purpose.CLIENT_AUTH,; cafile='/incoming.cacerts'); server_ssl_context.load_cert_chain(ssl_config['cert'],; keyfile=ssl_config['key'],; password=None); server_ssl_context.verify_mode = ssl.CERT_OPTIONAL; server_ssl_context.check_hostname = False; ```. The first function call states that we are a *server* performing *client; authentication* (`Purpose.CLIENT_AUTH`). We also state that anyone who sends requests to us will be; identified by a certificate that is trusted by our certificate database: `/incoming.cacerts` (which; is a file). `load_cert_chain` states where to find the certificates and secret key that prove who we are. The; certificate and secret key together are like a property title that proves someone owns a house. The; `password=None` means that our secret key has no password. Some keys are themselves locked by a; password. `verify_mode` means what do we expect our clients to have. `CERT_OPTIONAL` means anonymous clients; are OK. This is how servers normally operate (https://google.com does not care who you are). `check_hostname` means should we verify that the client certificate matches the client's; hostname. Since we allow anonymous clients, this must be `False`. ---. `test-address.py` is a gross hack. It will disappear in subsequent PRs. For now, I pushed all the; gross hack stuff into that file alone.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9862
https://github.com/hail-is/hail/pull/9862:303,Usability,simpl,simplified,303,"`tls.py` has many different functions with long names. This change reduces it to three functions:. - internal_server_ssl_context; - internal_client_ssl_context; - external_client_ssl_context. I also added `httpx.py` which contains the HTTPS-related functions that `tls.py` previously; contained. I also simplified the HTTPS-related functions to just:. - client_session; - blocking_client_session. I determine internal vs. external using the deploy config. ---. An [`ssl.SSLContext`](https://docs.python.org/3/library/ssl.html#ssl.SSLContext) defines how a; network library (such as `aiohttp`) should perform SSL/TLS. Let's look at an example:. ```python3; server_ssl_context = ssl.create_default_context(; purpose=Purpose.CLIENT_AUTH,; cafile='/incoming.cacerts'); server_ssl_context.load_cert_chain(ssl_config['cert'],; keyfile=ssl_config['key'],; password=None); server_ssl_context.verify_mode = ssl.CERT_OPTIONAL; server_ssl_context.check_hostname = False; ```. The first function call states that we are a *server* performing *client; authentication* (`Purpose.CLIENT_AUTH`). We also state that anyone who sends requests to us will be; identified by a certificate that is trusted by our certificate database: `/incoming.cacerts` (which; is a file). `load_cert_chain` states where to find the certificates and secret key that prove who we are. The; certificate and secret key together are like a property title that proves someone owns a house. The; `password=None` means that our secret key has no password. Some keys are themselves locked by a; password. `verify_mode` means what do we expect our clients to have. `CERT_OPTIONAL` means anonymous clients; are OK. This is how servers normally operate (https://google.com does not care who you are). `check_hostname` means should we verify that the client certificate matches the client's; hostname. Since we allow anonymous clients, this must be `False`. ---. `test-address.py` is a gross hack. It will disappear in subsequent PRs. For now, I push",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9862
https://github.com/hail-is/hail/pull/9863:379,Integrability,Wrap,Wraps,379,"This change replaces uses of `requests.Session` with uses of; `BlockingClientSession`. The latter is a class introduced by this; PR. BlockingClientSession is a shim around; [`aiohttp.ClientSession`](https://github.com/aio-libs/aiohttp/blob/master/aiohttp/client.py#L167). I; also needed these new classes:. - `BlockingClientResponse`, representing a response to an HTTP request. Wraps `aiohttp.ClientResponse`. - `BlockingClientWebSocketResponse`, representing a web socket session. Wraps; `aiohttp.ClientWebSocketResponse`. - `BlockingClientresponseContextManager` and; `BlockingClientWebSocketResponseContextManager` which wrap the context manager; returned by `aiohttp_client_session.post(...)` or; `....ws_connect(...)`. They wrap the `__aenter__` and `__aexit__` calls and; also wrap the value returned by `__aenter__`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9863
https://github.com/hail-is/hail/pull/9863:483,Integrability,Wrap,Wraps,483,"This change replaces uses of `requests.Session` with uses of; `BlockingClientSession`. The latter is a class introduced by this; PR. BlockingClientSession is a shim around; [`aiohttp.ClientSession`](https://github.com/aio-libs/aiohttp/blob/master/aiohttp/client.py#L167). I; also needed these new classes:. - `BlockingClientResponse`, representing a response to an HTTP request. Wraps `aiohttp.ClientResponse`. - `BlockingClientWebSocketResponse`, representing a web socket session. Wraps; `aiohttp.ClientWebSocketResponse`. - `BlockingClientresponseContextManager` and; `BlockingClientWebSocketResponseContextManager` which wrap the context manager; returned by `aiohttp_client_session.post(...)` or; `....ws_connect(...)`. They wrap the `__aenter__` and `__aexit__` calls and; also wrap the value returned by `__aenter__`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9863
https://github.com/hail-is/hail/pull/9863:625,Integrability,wrap,wrap,625,"This change replaces uses of `requests.Session` with uses of; `BlockingClientSession`. The latter is a class introduced by this; PR. BlockingClientSession is a shim around; [`aiohttp.ClientSession`](https://github.com/aio-libs/aiohttp/blob/master/aiohttp/client.py#L167). I; also needed these new classes:. - `BlockingClientResponse`, representing a response to an HTTP request. Wraps `aiohttp.ClientResponse`. - `BlockingClientWebSocketResponse`, representing a web socket session. Wraps; `aiohttp.ClientWebSocketResponse`. - `BlockingClientresponseContextManager` and; `BlockingClientWebSocketResponseContextManager` which wrap the context manager; returned by `aiohttp_client_session.post(...)` or; `....ws_connect(...)`. They wrap the `__aenter__` and `__aexit__` calls and; also wrap the value returned by `__aenter__`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9863
https://github.com/hail-is/hail/pull/9863:730,Integrability,wrap,wrap,730,"This change replaces uses of `requests.Session` with uses of; `BlockingClientSession`. The latter is a class introduced by this; PR. BlockingClientSession is a shim around; [`aiohttp.ClientSession`](https://github.com/aio-libs/aiohttp/blob/master/aiohttp/client.py#L167). I; also needed these new classes:. - `BlockingClientResponse`, representing a response to an HTTP request. Wraps `aiohttp.ClientResponse`. - `BlockingClientWebSocketResponse`, representing a web socket session. Wraps; `aiohttp.ClientWebSocketResponse`. - `BlockingClientresponseContextManager` and; `BlockingClientWebSocketResponseContextManager` which wrap the context manager; returned by `aiohttp_client_session.post(...)` or; `....ws_connect(...)`. They wrap the `__aenter__` and `__aexit__` calls and; also wrap the value returned by `__aenter__`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9863
https://github.com/hail-is/hail/pull/9863:784,Integrability,wrap,wrap,784,"This change replaces uses of `requests.Session` with uses of; `BlockingClientSession`. The latter is a class introduced by this; PR. BlockingClientSession is a shim around; [`aiohttp.ClientSession`](https://github.com/aio-libs/aiohttp/blob/master/aiohttp/client.py#L167). I; also needed these new classes:. - `BlockingClientResponse`, representing a response to an HTTP request. Wraps `aiohttp.ClientResponse`. - `BlockingClientWebSocketResponse`, representing a web socket session. Wraps; `aiohttp.ClientWebSocketResponse`. - `BlockingClientresponseContextManager` and; `BlockingClientWebSocketResponseContextManager` which wrap the context manager; returned by `aiohttp_client_session.post(...)` or; `....ws_connect(...)`. They wrap the `__aenter__` and `__aexit__` calls and; also wrap the value returned by `__aenter__`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9863
https://github.com/hail-is/hail/pull/9864:34,Availability,error,error,34,We almost always want to raise an error on a bad status.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9864
https://github.com/hail-is/hail/pull/9865:112,Testability,log,logic,112,A minute is an unacceptable amount of time to wait for another computer. The request should fail and; the retry logic will fire.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9865
https://github.com/hail-is/hail/issues/9867:170,Availability,error,error,170,"To replicate, replace the contents of `test_king.py::test_king_small` with:; ```; @fails_local_backend(); def test_king_small():; hl.init(idempotent=True) # Should be no error; hl.stop(); hl.init(idempotent=True) # Should be no error; hl.init(hl.spark_context(), idempotent=True) # Should be no error. plink_path = resource('balding-nichols-1024-variants-4-samples-3-populations'); mt = hl.import_plink(bed=f'{plink_path}.bed',; bim=f'{plink_path}.bim',; fam=f'{plink_path}.fam'); kinship = hl.king(mt.GT); assert_c_king_same_as_hail_king(; resource('balding-nichols-1024-variants-4-samples-3-populations.kin0'),; kinship); ```. Stack trace:; ```; E hail.utils.java.FatalError: IndexOutOfBoundsException: 0; E ; E Java stack trace:; E org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 18.0 failed 1 times, most recent failure: Lost task 7.0 in stage 18.0 (TID 34, localhost, executor driver): java.lang.IndexOutOfBoundsException: 0; E 	at scala.collection.immutable.NumericRange.apply(NumericRange.scala:112); E 	at is.hail.linalg.BlockMatrixReadRowBlockedRDD$$anonfun$compute$9.apply(BlockMatrix.scala:2131); E 	at is.hail.linalg.BlockMatrixReadRowBlockedRDD$$anonfun$compute$9.apply(BlockMatrix.scala:2127); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18$$anonfun$apply$19.apply(ContextRDD.scala:259); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18$$anonfun$apply$19.apply(ContextRDD.scala:259); E 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9867
https://github.com/hail-is/hail/issues/9867:228,Availability,error,error,228,"To replicate, replace the contents of `test_king.py::test_king_small` with:; ```; @fails_local_backend(); def test_king_small():; hl.init(idempotent=True) # Should be no error; hl.stop(); hl.init(idempotent=True) # Should be no error; hl.init(hl.spark_context(), idempotent=True) # Should be no error. plink_path = resource('balding-nichols-1024-variants-4-samples-3-populations'); mt = hl.import_plink(bed=f'{plink_path}.bed',; bim=f'{plink_path}.bim',; fam=f'{plink_path}.fam'); kinship = hl.king(mt.GT); assert_c_king_same_as_hail_king(; resource('balding-nichols-1024-variants-4-samples-3-populations.kin0'),; kinship); ```. Stack trace:; ```; E hail.utils.java.FatalError: IndexOutOfBoundsException: 0; E ; E Java stack trace:; E org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 18.0 failed 1 times, most recent failure: Lost task 7.0 in stage 18.0 (TID 34, localhost, executor driver): java.lang.IndexOutOfBoundsException: 0; E 	at scala.collection.immutable.NumericRange.apply(NumericRange.scala:112); E 	at is.hail.linalg.BlockMatrixReadRowBlockedRDD$$anonfun$compute$9.apply(BlockMatrix.scala:2131); E 	at is.hail.linalg.BlockMatrixReadRowBlockedRDD$$anonfun$compute$9.apply(BlockMatrix.scala:2127); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18$$anonfun$apply$19.apply(ContextRDD.scala:259); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18$$anonfun$apply$19.apply(ContextRDD.scala:259); E 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9867
https://github.com/hail-is/hail/issues/9867:295,Availability,error,error,295,"To replicate, replace the contents of `test_king.py::test_king_small` with:; ```; @fails_local_backend(); def test_king_small():; hl.init(idempotent=True) # Should be no error; hl.stop(); hl.init(idempotent=True) # Should be no error; hl.init(hl.spark_context(), idempotent=True) # Should be no error. plink_path = resource('balding-nichols-1024-variants-4-samples-3-populations'); mt = hl.import_plink(bed=f'{plink_path}.bed',; bim=f'{plink_path}.bim',; fam=f'{plink_path}.fam'); kinship = hl.king(mt.GT); assert_c_king_same_as_hail_king(; resource('balding-nichols-1024-variants-4-samples-3-populations.kin0'),; kinship); ```. Stack trace:; ```; E hail.utils.java.FatalError: IndexOutOfBoundsException: 0; E ; E Java stack trace:; E org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 18.0 failed 1 times, most recent failure: Lost task 7.0 in stage 18.0 (TID 34, localhost, executor driver): java.lang.IndexOutOfBoundsException: 0; E 	at scala.collection.immutable.NumericRange.apply(NumericRange.scala:112); E 	at is.hail.linalg.BlockMatrixReadRowBlockedRDD$$anonfun$compute$9.apply(BlockMatrix.scala:2131); E 	at is.hail.linalg.BlockMatrixReadRowBlockedRDD$$anonfun$compute$9.apply(BlockMatrix.scala:2127); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18$$anonfun$apply$19.apply(ContextRDD.scala:259); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18$$anonfun$apply$19.apply(ContextRDD.scala:259); E 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9867
https://github.com/hail-is/hail/issues/9867:793,Availability,failure,failure,793,"To replicate, replace the contents of `test_king.py::test_king_small` with:; ```; @fails_local_backend(); def test_king_small():; hl.init(idempotent=True) # Should be no error; hl.stop(); hl.init(idempotent=True) # Should be no error; hl.init(hl.spark_context(), idempotent=True) # Should be no error. plink_path = resource('balding-nichols-1024-variants-4-samples-3-populations'); mt = hl.import_plink(bed=f'{plink_path}.bed',; bim=f'{plink_path}.bim',; fam=f'{plink_path}.fam'); kinship = hl.king(mt.GT); assert_c_king_same_as_hail_king(; resource('balding-nichols-1024-variants-4-samples-3-populations.kin0'),; kinship); ```. Stack trace:; ```; E hail.utils.java.FatalError: IndexOutOfBoundsException: 0; E ; E Java stack trace:; E org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 18.0 failed 1 times, most recent failure: Lost task 7.0 in stage 18.0 (TID 34, localhost, executor driver): java.lang.IndexOutOfBoundsException: 0; E 	at scala.collection.immutable.NumericRange.apply(NumericRange.scala:112); E 	at is.hail.linalg.BlockMatrixReadRowBlockedRDD$$anonfun$compute$9.apply(BlockMatrix.scala:2131); E 	at is.hail.linalg.BlockMatrixReadRowBlockedRDD$$anonfun$compute$9.apply(BlockMatrix.scala:2127); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18$$anonfun$apply$19.apply(ContextRDD.scala:259); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18$$anonfun$apply$19.apply(ContextRDD.scala:259); E 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9867
https://github.com/hail-is/hail/issues/9867:851,Availability,failure,failure,851,"To replicate, replace the contents of `test_king.py::test_king_small` with:; ```; @fails_local_backend(); def test_king_small():; hl.init(idempotent=True) # Should be no error; hl.stop(); hl.init(idempotent=True) # Should be no error; hl.init(hl.spark_context(), idempotent=True) # Should be no error. plink_path = resource('balding-nichols-1024-variants-4-samples-3-populations'); mt = hl.import_plink(bed=f'{plink_path}.bed',; bim=f'{plink_path}.bim',; fam=f'{plink_path}.fam'); kinship = hl.king(mt.GT); assert_c_king_same_as_hail_king(; resource('balding-nichols-1024-variants-4-samples-3-populations.kin0'),; kinship); ```. Stack trace:; ```; E hail.utils.java.FatalError: IndexOutOfBoundsException: 0; E ; E Java stack trace:; E org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 18.0 failed 1 times, most recent failure: Lost task 7.0 in stage 18.0 (TID 34, localhost, executor driver): java.lang.IndexOutOfBoundsException: 0; E 	at scala.collection.immutable.NumericRange.apply(NumericRange.scala:112); E 	at is.hail.linalg.BlockMatrixReadRowBlockedRDD$$anonfun$compute$9.apply(BlockMatrix.scala:2131); E 	at is.hail.linalg.BlockMatrixReadRowBlockedRDD$$anonfun$compute$9.apply(BlockMatrix.scala:2127); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18$$anonfun$apply$19.apply(ContextRDD.scala:259); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18$$anonfun$apply$19.apply(ContextRDD.scala:259); E 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9867
https://github.com/hail-is/hail/issues/9867:8720,Energy Efficiency,schedul,scheduler,8720,dLeftJoinDistinct$1.apply(KeyedRVD.scala:152); E 	at is.hail.rvd.KeyedRVD$$anonfun$orderedLeftJoinDistinct$1.apply(KeyedRVD.scala:149); E 	at is.hail.sparkextras.ContextRDD$$anonfun$czipPartitions$1$$anonfun$apply$24.apply(ContextRDD.scala:316); E 	at is.hail.sparkextras.ContextRDD$$anonfun$czipPartitions$1$$anonfun$apply$24.apply(ContextRDD.scala:316); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$10$$anonfun$apply$11.apply(ContextRDD.scala:218); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$10$$anonfun$apply$11.apply(ContextRDD.scala:218); E 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at is.hail.rvd.RVD$$anonfun$34.apply(RVD.scala:1220); E 	at is.hail.rvd.RVD$$anonfun$34.apply(RVD.scala:1219); E 	at is.hail.sparkextras.ContextRDD$$anonfun$crunJobWithIndex$1.apply(ContextRDD.scala:242); E 	at is.hail.sparkextras.ContextRDD$$anonfun$crunJobWithIndex$1.apply(ContextRDD.scala:240); E 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); E 	at org.apache.spark.scheduler.Task.run(Task.scala:121); E 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:403); E 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); E 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:409); E 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); E 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); E 	at java.lang.Thread.run(Thread.java:748). ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9867
https://github.com/hail-is/hail/issues/9867:8794,Energy Efficiency,schedul,scheduler,8794,dLeftJoinDistinct$1.apply(KeyedRVD.scala:152); E 	at is.hail.rvd.KeyedRVD$$anonfun$orderedLeftJoinDistinct$1.apply(KeyedRVD.scala:149); E 	at is.hail.sparkextras.ContextRDD$$anonfun$czipPartitions$1$$anonfun$apply$24.apply(ContextRDD.scala:316); E 	at is.hail.sparkextras.ContextRDD$$anonfun$czipPartitions$1$$anonfun$apply$24.apply(ContextRDD.scala:316); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$10$$anonfun$apply$11.apply(ContextRDD.scala:218); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$10$$anonfun$apply$11.apply(ContextRDD.scala:218); E 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at is.hail.rvd.RVD$$anonfun$34.apply(RVD.scala:1220); E 	at is.hail.rvd.RVD$$anonfun$34.apply(RVD.scala:1219); E 	at is.hail.sparkextras.ContextRDD$$anonfun$crunJobWithIndex$1.apply(ContextRDD.scala:242); E 	at is.hail.sparkextras.ContextRDD$$anonfun$crunJobWithIndex$1.apply(ContextRDD.scala:240); E 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); E 	at org.apache.spark.scheduler.Task.run(Task.scala:121); E 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:403); E 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); E 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:409); E 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); E 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); E 	at java.lang.Thread.run(Thread.java:748). ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9867
https://github.com/hail-is/hail/issues/9867:9087,Performance,concurren,concurrent,9087,dLeftJoinDistinct$1.apply(KeyedRVD.scala:152); E 	at is.hail.rvd.KeyedRVD$$anonfun$orderedLeftJoinDistinct$1.apply(KeyedRVD.scala:149); E 	at is.hail.sparkextras.ContextRDD$$anonfun$czipPartitions$1$$anonfun$apply$24.apply(ContextRDD.scala:316); E 	at is.hail.sparkextras.ContextRDD$$anonfun$czipPartitions$1$$anonfun$apply$24.apply(ContextRDD.scala:316); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$10$$anonfun$apply$11.apply(ContextRDD.scala:218); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$10$$anonfun$apply$11.apply(ContextRDD.scala:218); E 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at is.hail.rvd.RVD$$anonfun$34.apply(RVD.scala:1220); E 	at is.hail.rvd.RVD$$anonfun$34.apply(RVD.scala:1219); E 	at is.hail.sparkextras.ContextRDD$$anonfun$crunJobWithIndex$1.apply(ContextRDD.scala:242); E 	at is.hail.sparkextras.ContextRDD$$anonfun$crunJobWithIndex$1.apply(ContextRDD.scala:240); E 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); E 	at org.apache.spark.scheduler.Task.run(Task.scala:121); E 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:403); E 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); E 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:409); E 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); E 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); E 	at java.lang.Thread.run(Thread.java:748). ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9867
https://github.com/hail-is/hail/issues/9867:9174,Performance,concurren,concurrent,9174,dLeftJoinDistinct$1.apply(KeyedRVD.scala:152); E 	at is.hail.rvd.KeyedRVD$$anonfun$orderedLeftJoinDistinct$1.apply(KeyedRVD.scala:149); E 	at is.hail.sparkextras.ContextRDD$$anonfun$czipPartitions$1$$anonfun$apply$24.apply(ContextRDD.scala:316); E 	at is.hail.sparkextras.ContextRDD$$anonfun$czipPartitions$1$$anonfun$apply$24.apply(ContextRDD.scala:316); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$10$$anonfun$apply$11.apply(ContextRDD.scala:218); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitions$1$$anonfun$apply$10$$anonfun$apply$11.apply(ContextRDD.scala:218); E 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at is.hail.rvd.RVD$$anonfun$34.apply(RVD.scala:1220); E 	at is.hail.rvd.RVD$$anonfun$34.apply(RVD.scala:1219); E 	at is.hail.sparkextras.ContextRDD$$anonfun$crunJobWithIndex$1.apply(ContextRDD.scala:242); E 	at is.hail.sparkextras.ContextRDD$$anonfun$crunJobWithIndex$1.apply(ContextRDD.scala:240); E 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); E 	at org.apache.spark.scheduler.Task.run(Task.scala:121); E 	at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:403); E 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); E 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:409); E 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); E 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); E 	at java.lang.Thread.run(Thread.java:748). ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9867
https://github.com/hail-is/hail/issues/9867:772,Safety,abort,aborted,772,"To replicate, replace the contents of `test_king.py::test_king_small` with:; ```; @fails_local_backend(); def test_king_small():; hl.init(idempotent=True) # Should be no error; hl.stop(); hl.init(idempotent=True) # Should be no error; hl.init(hl.spark_context(), idempotent=True) # Should be no error. plink_path = resource('balding-nichols-1024-variants-4-samples-3-populations'); mt = hl.import_plink(bed=f'{plink_path}.bed',; bim=f'{plink_path}.bim',; fam=f'{plink_path}.fam'); kinship = hl.king(mt.GT); assert_c_king_same_as_hail_king(; resource('balding-nichols-1024-variants-4-samples-3-populations.kin0'),; kinship); ```. Stack trace:; ```; E hail.utils.java.FatalError: IndexOutOfBoundsException: 0; E ; E Java stack trace:; E org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 18.0 failed 1 times, most recent failure: Lost task 7.0 in stage 18.0 (TID 34, localhost, executor driver): java.lang.IndexOutOfBoundsException: 0; E 	at scala.collection.immutable.NumericRange.apply(NumericRange.scala:112); E 	at is.hail.linalg.BlockMatrixReadRowBlockedRDD$$anonfun$compute$9.apply(BlockMatrix.scala:2131); E 	at is.hail.linalg.BlockMatrixReadRowBlockedRDD$$anonfun$compute$9.apply(BlockMatrix.scala:2127); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18$$anonfun$apply$19.apply(ContextRDD.scala:259); E 	at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18$$anonfun$apply$19.apply(ContextRDD.scala:259); E 	at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); E 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); E 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9867
https://github.com/hail-is/hail/pull/9868:174,Modifiability,parameteriz,parameterized,174,"This PR pushes aggregators much closer to where we want; them to be with regardes to SCodes/STypes. Here are the; important conceptual changes:; 1. Aggregators are no longer parameterized by the ptypes; of seqop and initop args. Instead, the state signature; contains a sequence of VirtualTypeWithRequiredness, which; is exactly what its name says. Aggregators use ptypes; internally, but this is not in the state signature.; 2. As a consequence of 1), we no longer cast argument types; to seqop/initops. We are still able to, for instance,pass a seqop; argument of a different type than the container type to; the collect aggregator because the collect aggregator accepts; an SCode argument, and uses the appropriate PType constructor to; store that SCode (with a possible conversion if necessary, as here).; 3. We codebuilder-ify most of the aggregator package. There are some; straggling bits, but I will clean that up in a followup since the; time to get a change in will scale super-linearly with its size. Benchmarks forthcoming. Agg SCodes hopefully done",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9868
https://github.com/hail-is/hail/pull/9868:1012,Testability,Benchmark,Benchmarks,1012,"This PR pushes aggregators much closer to where we want; them to be with regardes to SCodes/STypes. Here are the; important conceptual changes:; 1. Aggregators are no longer parameterized by the ptypes; of seqop and initop args. Instead, the state signature; contains a sequence of VirtualTypeWithRequiredness, which; is exactly what its name says. Aggregators use ptypes; internally, but this is not in the state signature.; 2. As a consequence of 1), we no longer cast argument types; to seqop/initops. We are still able to, for instance,pass a seqop; argument of a different type than the container type to; the collect aggregator because the collect aggregator accepts; an SCode argument, and uses the appropriate PType constructor to; store that SCode (with a possible conversion if necessary, as here).; 3. We codebuilder-ify most of the aggregator package. There are some; straggling bits, but I will clean that up in a followup since the; time to get a change in will scale super-linearly with its size. Benchmarks forthcoming. Agg SCodes hopefully done",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9868
https://github.com/hail-is/hail/pull/9870:123,Performance,optimiz,optimizing-subqueries,123,"Found the problem where EXISTS in a correlated subquery should be rewritten as IN; https://dev.mysql.com/doc/refman/5.7/en/optimizing-subqueries.html. ```; -> FROM jobs; -> INNER JOIN batches ON jobs.batch_id = batches.id; -> LEFT JOIN aggregated_job_resources; -> ON jobs.batch_id = aggregated_job_resources.batch_id AND; -> jobs.job_id = aggregated_job_resources.job_id; -> LEFT JOIN resources; -> ON aggregated_job_resources.resource = resources.resource; -> INNER JOIN job_attributes; -> ON jobs.batch_id = job_attributes.batch_id AND; -> jobs.job_id = job_attributes.job_id AND; -> job_attributes.`key` = 'name'; -> WHERE (jobs.batch_id = 14327) AND; -> (jobs.batch_id, jobs.job_id) IN (SELECT batch_id, job_id FROM job_attributes WHERE `key` = 'pheno' AND `value` = '50'); -> GROUP BY jobs.batch_id, jobs.job_id; -> ORDER BY jobs.batch_id, jobs.job_id ASC; -> LIMIT 50;; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; | 1 | SIMPLE | batches | NULL | const | PRIMARY | PRIMARY | 8 | const | 1 | 100.00 | Using temporary; Using filesort |; | 1 | SIMPLE | job_attributes | NULL | ref | PRIMARY,job_attributes_key_value | job_attributes_key_value | 1081 | const,const,const | 3057 | 100.00 | Using where |; | 1 | SIMPLE | jobs | NULL | eq_ref | PRIMARY,jobs_batch_id_state_always_run_cancelled | PRIMARY | 12 | const,batch.job_attributes.job_id | 1 | 100.00 | NULL |; | 1 | SIMPLE | job_attributes | NULL | eq_ref | PRIMARY,jo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9870
https://github.com/hail-is/hail/pull/9870:1503,Usability,SIMPL,SIMPLE,1503,"ches.id; -> LEFT JOIN aggregated_job_resources; -> ON jobs.batch_id = aggregated_job_resources.batch_id AND; -> jobs.job_id = aggregated_job_resources.job_id; -> LEFT JOIN resources; -> ON aggregated_job_resources.resource = resources.resource; -> INNER JOIN job_attributes; -> ON jobs.batch_id = job_attributes.batch_id AND; -> jobs.job_id = job_attributes.job_id AND; -> job_attributes.`key` = 'name'; -> WHERE (jobs.batch_id = 14327) AND; -> (jobs.batch_id, jobs.job_id) IN (SELECT batch_id, job_id FROM job_attributes WHERE `key` = 'pheno' AND `value` = '50'); -> GROUP BY jobs.batch_id, jobs.job_id; -> ORDER BY jobs.batch_id, jobs.job_id ASC; -> LIMIT 50;; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; | 1 | SIMPLE | batches | NULL | const | PRIMARY | PRIMARY | 8 | const | 1 | 100.00 | Using temporary; Using filesort |; | 1 | SIMPLE | job_attributes | NULL | ref | PRIMARY,job_attributes_key_value | job_attributes_key_value | 1081 | const,const,const | 3057 | 100.00 | Using where |; | 1 | SIMPLE | jobs | NULL | eq_ref | PRIMARY,jobs_batch_id_state_always_run_cancelled | PRIMARY | 12 | const,batch.job_attributes.job_id | 1 | 100.00 | NULL |; | 1 | SIMPLE | job_attributes | NULL | eq_ref | PRIMARY,job_attributes_key_value | PRIMARY | 314 | const,batch.job_attributes.job_id,const | 1 | 100.00 | NULL |; | 1 | SIMPLE | aggregated_job_resources | NULL | ref | PRIMARY | PRIMARY | 12 | const,batch.job_attributes.jo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9870
https://github.com/hail-is/hail/pull/9870:1623,Usability,SIMPL,SIMPLE,1623,"tch_id, jobs.job_id) IN (SELECT batch_id, job_id FROM job_attributes WHERE `key` = 'pheno' AND `value` = '50'); -> GROUP BY jobs.batch_id, jobs.job_id; -> ORDER BY jobs.batch_id, jobs.job_id ASC; -> LIMIT 50;; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; | 1 | SIMPLE | batches | NULL | const | PRIMARY | PRIMARY | 8 | const | 1 | 100.00 | Using temporary; Using filesort |; | 1 | SIMPLE | job_attributes | NULL | ref | PRIMARY,job_attributes_key_value | job_attributes_key_value | 1081 | const,const,const | 3057 | 100.00 | Using where |; | 1 | SIMPLE | jobs | NULL | eq_ref | PRIMARY,jobs_batch_id_state_always_run_cancelled | PRIMARY | 12 | const,batch.job_attributes.job_id | 1 | 100.00 | NULL |; | 1 | SIMPLE | job_attributes | NULL | eq_ref | PRIMARY,job_attributes_key_value | PRIMARY | 314 | const,batch.job_attributes.job_id,const | 1 | 100.00 | NULL |; | 1 | SIMPLE | aggregated_job_resources | NULL | ref | PRIMARY | PRIMARY | 12 | const,batch.job_attributes.job_id | 5 | 100.00 | NULL |; | 1 | SIMPLE | resources | NULL | eq_ref | PRIMARY | PRIMARY | 302 | batch.aggregated_job_resources.resource | 1 | 100.00 | NULL |; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; 6 rows in set, 1 warning (0.01 sec); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9870
https://github.com/hail-is/hail/pull/9870:1788,Usability,SIMPL,SIMPLE,1788,"tch_id, jobs.job_id) IN (SELECT batch_id, job_id FROM job_attributes WHERE `key` = 'pheno' AND `value` = '50'); -> GROUP BY jobs.batch_id, jobs.job_id; -> ORDER BY jobs.batch_id, jobs.job_id ASC; -> LIMIT 50;; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; | 1 | SIMPLE | batches | NULL | const | PRIMARY | PRIMARY | 8 | const | 1 | 100.00 | Using temporary; Using filesort |; | 1 | SIMPLE | job_attributes | NULL | ref | PRIMARY,job_attributes_key_value | job_attributes_key_value | 1081 | const,const,const | 3057 | 100.00 | Using where |; | 1 | SIMPLE | jobs | NULL | eq_ref | PRIMARY,jobs_batch_id_state_always_run_cancelled | PRIMARY | 12 | const,batch.job_attributes.job_id | 1 | 100.00 | NULL |; | 1 | SIMPLE | job_attributes | NULL | eq_ref | PRIMARY,job_attributes_key_value | PRIMARY | 314 | const,batch.job_attributes.job_id,const | 1 | 100.00 | NULL |; | 1 | SIMPLE | aggregated_job_resources | NULL | ref | PRIMARY | PRIMARY | 12 | const,batch.job_attributes.job_id | 5 | 100.00 | NULL |; | 1 | SIMPLE | resources | NULL | eq_ref | PRIMARY | PRIMARY | 302 | batch.aggregated_job_resources.resource | 1 | 100.00 | NULL |; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; 6 rows in set, 1 warning (0.01 sec); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9870
https://github.com/hail-is/hail/pull/9870:1949,Usability,SIMPL,SIMPLE,1949,"tch_id, jobs.job_id) IN (SELECT batch_id, job_id FROM job_attributes WHERE `key` = 'pheno' AND `value` = '50'); -> GROUP BY jobs.batch_id, jobs.job_id; -> ORDER BY jobs.batch_id, jobs.job_id ASC; -> LIMIT 50;; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; | 1 | SIMPLE | batches | NULL | const | PRIMARY | PRIMARY | 8 | const | 1 | 100.00 | Using temporary; Using filesort |; | 1 | SIMPLE | job_attributes | NULL | ref | PRIMARY,job_attributes_key_value | job_attributes_key_value | 1081 | const,const,const | 3057 | 100.00 | Using where |; | 1 | SIMPLE | jobs | NULL | eq_ref | PRIMARY,jobs_batch_id_state_always_run_cancelled | PRIMARY | 12 | const,batch.job_attributes.job_id | 1 | 100.00 | NULL |; | 1 | SIMPLE | job_attributes | NULL | eq_ref | PRIMARY,job_attributes_key_value | PRIMARY | 314 | const,batch.job_attributes.job_id,const | 1 | 100.00 | NULL |; | 1 | SIMPLE | aggregated_job_resources | NULL | ref | PRIMARY | PRIMARY | 12 | const,batch.job_attributes.job_id | 5 | 100.00 | NULL |; | 1 | SIMPLE | resources | NULL | eq_ref | PRIMARY | PRIMARY | 302 | batch.aggregated_job_resources.resource | 1 | 100.00 | NULL |; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; 6 rows in set, 1 warning (0.01 sec); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9870
https://github.com/hail-is/hail/pull/9870:2111,Usability,SIMPL,SIMPLE,2111,"tch_id, jobs.job_id) IN (SELECT batch_id, job_id FROM job_attributes WHERE `key` = 'pheno' AND `value` = '50'); -> GROUP BY jobs.batch_id, jobs.job_id; -> ORDER BY jobs.batch_id, jobs.job_id ASC; -> LIMIT 50;; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; | 1 | SIMPLE | batches | NULL | const | PRIMARY | PRIMARY | 8 | const | 1 | 100.00 | Using temporary; Using filesort |; | 1 | SIMPLE | job_attributes | NULL | ref | PRIMARY,job_attributes_key_value | job_attributes_key_value | 1081 | const,const,const | 3057 | 100.00 | Using where |; | 1 | SIMPLE | jobs | NULL | eq_ref | PRIMARY,jobs_batch_id_state_always_run_cancelled | PRIMARY | 12 | const,batch.job_attributes.job_id | 1 | 100.00 | NULL |; | 1 | SIMPLE | job_attributes | NULL | eq_ref | PRIMARY,job_attributes_key_value | PRIMARY | 314 | const,batch.job_attributes.job_id,const | 1 | 100.00 | NULL |; | 1 | SIMPLE | aggregated_job_resources | NULL | ref | PRIMARY | PRIMARY | 12 | const,batch.job_attributes.job_id | 5 | 100.00 | NULL |; | 1 | SIMPLE | resources | NULL | eq_ref | PRIMARY | PRIMARY | 302 | batch.aggregated_job_resources.resource | 1 | 100.00 | NULL |; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; 6 rows in set, 1 warning (0.01 sec); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9870
https://github.com/hail-is/hail/pull/9870:2248,Usability,SIMPL,SIMPLE,2248,"tch_id, jobs.job_id) IN (SELECT batch_id, job_id FROM job_attributes WHERE `key` = 'pheno' AND `value` = '50'); -> GROUP BY jobs.batch_id, jobs.job_id; -> ORDER BY jobs.batch_id, jobs.job_id ASC; -> LIMIT 50;; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; | 1 | SIMPLE | batches | NULL | const | PRIMARY | PRIMARY | 8 | const | 1 | 100.00 | Using temporary; Using filesort |; | 1 | SIMPLE | job_attributes | NULL | ref | PRIMARY,job_attributes_key_value | job_attributes_key_value | 1081 | const,const,const | 3057 | 100.00 | Using where |; | 1 | SIMPLE | jobs | NULL | eq_ref | PRIMARY,jobs_batch_id_state_always_run_cancelled | PRIMARY | 12 | const,batch.job_attributes.job_id | 1 | 100.00 | NULL |; | 1 | SIMPLE | job_attributes | NULL | eq_ref | PRIMARY,job_attributes_key_value | PRIMARY | 314 | const,batch.job_attributes.job_id,const | 1 | 100.00 | NULL |; | 1 | SIMPLE | aggregated_job_resources | NULL | ref | PRIMARY | PRIMARY | 12 | const,batch.job_attributes.job_id | 5 | 100.00 | NULL |; | 1 | SIMPLE | resources | NULL | eq_ref | PRIMARY | PRIMARY | 302 | batch.aggregated_job_resources.resource | 1 | 100.00 | NULL |; +----+-------------+--------------------------+------------+--------+--------------------------------------------------+--------------------------+---------+-----------------------------------------+------+----------+---------------------------------+; 6 rows in set, 1 warning (0.01 sec); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9870
https://github.com/hail-is/hail/pull/9871:3,Deployability,update,updated,3,We updated the job spec but forgot to update the display of jobs.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9871
https://github.com/hail-is/hail/pull/9871:38,Deployability,update,update,38,We updated the job spec but forgot to update the display of jobs.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9871
https://github.com/hail-is/hail/pull/9875:35,Safety,avoid,avoid,35,"The Artifact Registry is useful to avoid network egress costs for regions like Australia, where GCR doesn't provide local hosting. Partially addresses #9872.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9875
https://github.com/hail-is/hail/pull/9877:169,Performance,optimiz,optimization,169,"Reverts hail-is/hail#9874. This is invalid, doesn't handle the fact that negative ones can be present in the shape. Unless we handle that in python/IR, we can't do this optimization.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9877
https://github.com/hail-is/hail/pull/9880:14,Testability,log,logging,14,Also add more logging,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9880
https://github.com/hail-is/hail/pull/9882:156,Integrability,depend,dependency,156,Jupyter now requires tornado>=6. We added the tornado<6 requirement to prevent previous issues in; which the notebook package did not correctly specify its dependency on tornado<6.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9882
https://github.com/hail-is/hail/pull/9883:50,Integrability,interface,interface,50,"This PR:. - Pushes code builders through PNDArray interface instead of method builders; - Starts switching away from `PNDArray.data.load` to using methods like `dataPArrayPointer` and `dataFirstElementPointer`. All `dataPArrayPointer` calls will go away when ndarrays are no longer backed by `PArray`. ; - Speeds up repeated calls to `loadElement` on `SNDArrayPointerSettable`, which speeds up linear regression nd benchmark ~12%. Now we are approximately 60% slower than breeze linear regression.'; - Removes `CodePTuple`, since all instances of its use are removed now and it predated the current `PCode` system",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9883
https://github.com/hail-is/hail/pull/9883:132,Performance,load,load,132,"This PR:. - Pushes code builders through PNDArray interface instead of method builders; - Starts switching away from `PNDArray.data.load` to using methods like `dataPArrayPointer` and `dataFirstElementPointer`. All `dataPArrayPointer` calls will go away when ndarrays are no longer backed by `PArray`. ; - Speeds up repeated calls to `loadElement` on `SNDArrayPointerSettable`, which speeds up linear regression nd benchmark ~12%. Now we are approximately 60% slower than breeze linear regression.'; - Removes `CodePTuple`, since all instances of its use are removed now and it predated the current `PCode` system",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9883
https://github.com/hail-is/hail/pull/9883:335,Performance,load,loadElement,335,"This PR:. - Pushes code builders through PNDArray interface instead of method builders; - Starts switching away from `PNDArray.data.load` to using methods like `dataPArrayPointer` and `dataFirstElementPointer`. All `dataPArrayPointer` calls will go away when ndarrays are no longer backed by `PArray`. ; - Speeds up repeated calls to `loadElement` on `SNDArrayPointerSettable`, which speeds up linear regression nd benchmark ~12%. Now we are approximately 60% slower than breeze linear regression.'; - Removes `CodePTuple`, since all instances of its use are removed now and it predated the current `PCode` system",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9883
https://github.com/hail-is/hail/pull/9883:415,Testability,benchmark,benchmark,415,"This PR:. - Pushes code builders through PNDArray interface instead of method builders; - Starts switching away from `PNDArray.data.load` to using methods like `dataPArrayPointer` and `dataFirstElementPointer`. All `dataPArrayPointer` calls will go away when ndarrays are no longer backed by `PArray`. ; - Speeds up repeated calls to `loadElement` on `SNDArrayPointerSettable`, which speeds up linear regression nd benchmark ~12%. Now we are approximately 60% slower than breeze linear regression.'; - Removes `CodePTuple`, since all instances of its use are removed now and it predated the current `PCode` system",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9883
https://github.com/hail-is/hail/pull/9884:48,Safety,avoid,avoid,48,"Scala calls functions that match on the type to avoid boxing. This is; slightly better than allocating, but so much worse than plain array; operations. Benchmarks forthcoming.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9884
https://github.com/hail-is/hail/pull/9884:152,Testability,Benchmark,Benchmarks,152,"Scala calls functions that match on the type to avoid boxing. This is; slightly better than allocating, but so much worse than plain array; operations. Benchmarks forthcoming.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9884
https://github.com/hail-is/hail/pull/9892:59,Integrability,interface,interface,59,"I am trying to move towards removing the `fundamentalType` interface from `PType`s. As a first pass, this PR will remove RVB's use of `fundamentalType` by delegating the `addAnnotation`'s implementation to a new method, `unstagedStoreJavaObjectAtAddress`. WIP until I see tests are passing and clean up comments.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9892
https://github.com/hail-is/hail/pull/9892:272,Testability,test,tests,272,"I am trying to move towards removing the `fundamentalType` interface from `PType`s. As a first pass, this PR will remove RVB's use of `fundamentalType` by delegating the `addAnnotation`'s implementation to a new method, `unstagedStoreJavaObjectAtAddress`. WIP until I see tests are passing and clean up comments.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9892
https://github.com/hail-is/hail/pull/9899:111,Availability,down,downstream,111,"Without this empty file, mypy ignores the type annotations present in these modules. Adding; this file enables downstream modules (like CI and batch) to check the type annotations; provided by hailtop, gear, and web_common. See more information here: https://mypy.readthedocs.io/en/stable/installed_packages.html#making-pep-561-compatible-packages",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9899
https://github.com/hail-is/hail/pull/9902:1588,Integrability,wrap,wrapper,1588,"n from the Google metadata endpoint. The google; [documentation obliquely notes that the username should be; `oauth2accesstoken`](https://cloud.google.com/container-registry/docs/advanced-authentication). I; use this only for retrieving a ""public gcr image"" which I fix in this PR to be images whose; ""repository"" [1] is one of these:; - gcr.io/PROJECT/query; - gcr.io/PROJECT/hail; - gcr.io/PROJECT/python-dill. A previous Shuffler PR taught worker.py to translate our `hailgenetics` Docker image names to; `gcr.io/PROJECT` image names. I had to move the docker-worker into a new Docker network which allows it to access the metadata server. I think this is safe because we trust our own code. From a relevant Docker worker log:. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 359, in ensure_image_is_pulled; docker.images.get, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 46, in get; return await self.inspect(name); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 36, in inspect; response = await self.docker._query_json(""images/{name}/json"".format(name=name)); File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 223, in _query_json; path, method, params=params, data=data, headers=headers, timeout=timeout; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 206, in",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9902
https://github.com/hail-is/hail/pull/9902:3284,Integrability,wrap,wrapper,3284,"er.py"", line 223, in _query_json; path, method, params=params, data=data, headers=headers, timeout=timeout; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 206, in _do_query; raise DockerError(response.status, json.loads(what.decode(""utf8""))); aiodocker.exceptions.DockerError: DockerError(404, 'no such image: gcr.io/hail-vdc/query:tfkm2kev7zcf: No such image: gcr.io/hail-vdc/query:tfkm2kev7zcf'). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 372, in run; await self.ensure_image_is_pulled(); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 363, in ensure_image_is_pulled; docker.images.pull, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 104, in _handle_list; async with cm as response:; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 206, in _do_query; raise DockerError(response.status, json.loads(what.decode(""utf8""))); aiodocker.exceptions.DockerError: DockerError(500, ""unauthorized: You don't have the needed permissions to perform this operation, and you may have invalid credentials. To authenticate your request, follow the steps in: https://cloud.google.com/contai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9902
https://github.com/hail-is/hail/pull/9902:2646,Performance,load,loads,2646,"out); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 46, in get; return await self.inspect(name); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 36, in inspect; response = await self.docker._query_json(""images/{name}/json"".format(name=name)); File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 223, in _query_json; path, method, params=params, data=data, headers=headers, timeout=timeout; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 206, in _do_query; raise DockerError(response.status, json.loads(what.decode(""utf8""))); aiodocker.exceptions.DockerError: DockerError(404, 'no such image: gcr.io/hail-vdc/query:tfkm2kev7zcf: No such image: gcr.io/hail-vdc/query:tfkm2kev7zcf'). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 372, in run; await self.ensure_image_is_pulled(); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 363, in ensure_image_is_pulled; docker.images.pull, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9902
https://github.com/hail-is/hail/pull/9902:4010,Performance,load,loads,4010," gcr.io/hail-vdc/query:tfkm2kev7zcf'). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 372, in run; await self.ensure_image_is_pulled(); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 363, in ensure_image_is_pulled; docker.images.pull, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 104, in _handle_list; async with cm as response:; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 206, in _do_query; raise DockerError(response.status, json.loads(what.decode(""utf8""))); aiodocker.exceptions.DockerError: DockerError(500, ""unauthorized: You don't have the needed permissions to perform this operation, and you may have invalid credentials. To authenticate your request, follow the steps in: https://cloud.google.com/container-registry/docs/advanced-authentication""); ```. [1] The Docker specifications are confusing. After reading; [v1](https://github.com/moby/moby/blob/master/image/spec/v1.md) and; [v1.2](https://github.com/moby/moby/blob/master/image/spec/v1.2.md), it seems that the ""repository""; is everything before the last colon and the ""image name suffix"" is everything after the last; colon. For example, in `server:8080/abc/def:123`, the repository is `server:8080/abc/def` and the; ""image name suffix"" is `123`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9902
https://github.com/hail-is/hail/pull/9902:4146,Performance,perform,perform,4146," gcr.io/hail-vdc/query:tfkm2kev7zcf'). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 372, in run; await self.ensure_image_is_pulled(); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 363, in ensure_image_is_pulled; docker.images.pull, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 104, in _handle_list; async with cm as response:; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 206, in _do_query; raise DockerError(response.status, json.loads(what.decode(""utf8""))); aiodocker.exceptions.DockerError: DockerError(500, ""unauthorized: You don't have the needed permissions to perform this operation, and you may have invalid credentials. To authenticate your request, follow the steps in: https://cloud.google.com/container-registry/docs/advanced-authentication""); ```. [1] The Docker specifications are confusing. After reading; [v1](https://github.com/moby/moby/blob/master/image/spec/v1.md) and; [v1.2](https://github.com/moby/moby/blob/master/image/spec/v1.2.md), it seems that the ""repository""; is everything before the last colon and the ""image name suffix"" is everything after the last; colon. For example, in `server:8080/abc/def:123`, the repository is `server:8080/abc/def` and the; ""image name suffix"" is `123`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9902
https://github.com/hail-is/hail/pull/9902:1253,Safety,safe,safe,1253,"tain the credentials; themselves. The Docker docs note [""Authentication for registries is handled client side. The client; has to send authentication details to various endpoints that need to communicate with; registries""](https://docs.docker.com/engine/api/v1.41/#section/Authentication). I request a short-lived oauth2 access token from the Google metadata endpoint. The google; [documentation obliquely notes that the username should be; `oauth2accesstoken`](https://cloud.google.com/container-registry/docs/advanced-authentication). I; use this only for retrieving a ""public gcr image"" which I fix in this PR to be images whose; ""repository"" [1] is one of these:; - gcr.io/PROJECT/query; - gcr.io/PROJECT/hail; - gcr.io/PROJECT/python-dill. A previous Shuffler PR taught worker.py to translate our `hailgenetics` Docker image names to; `gcr.io/PROJECT` image names. I had to move the docker-worker into a new Docker network which allows it to access the metadata server. I think this is safe because we trust our own code. From a relevant Docker worker log:. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 359, in ensure_image_is_pulled; docker.images.get, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 46, in get; return await self.inspect(name); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 36, in inspect; response = await self.docker._query_json(""images/{name}/json"".format(name=name)); File ""/usr/local/lib/python3.7/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9902
https://github.com/hail-is/hail/pull/9902:1647,Safety,timeout,timeout,1647,"ation obliquely notes that the username should be; `oauth2accesstoken`](https://cloud.google.com/container-registry/docs/advanced-authentication). I; use this only for retrieving a ""public gcr image"" which I fix in this PR to be images whose; ""repository"" [1] is one of these:; - gcr.io/PROJECT/query; - gcr.io/PROJECT/hail; - gcr.io/PROJECT/python-dill. A previous Shuffler PR taught worker.py to translate our `hailgenetics` Docker image names to; `gcr.io/PROJECT` image names. I had to move the docker-worker into a new Docker network which allows it to access the metadata server. I think this is safe because we trust our own code. From a relevant Docker worker log:. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 359, in ensure_image_is_pulled; docker.images.get, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 46, in get; return await self.inspect(name); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 36, in inspect; response = await self.docker._query_json(""images/{name}/json"".format(name=name)); File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 223, in _query_json; path, method, params=params, data=data, headers=headers, timeout=timeout; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 206, in _do_query; raise DockerError(response.status, json.loads(",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9902
https://github.com/hail-is/hail/pull/9902:2381,Safety,timeout,timeout,2381,"st):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 359, in ensure_image_is_pulled; docker.images.get, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 46, in get; return await self.inspect(name); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 36, in inspect; response = await self.docker._query_json(""images/{name}/json"".format(name=name)); File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 223, in _query_json; path, method, params=params, data=data, headers=headers, timeout=timeout; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 206, in _do_query; raise DockerError(response.status, json.loads(what.decode(""utf8""))); aiodocker.exceptions.DockerError: DockerError(404, 'no such image: gcr.io/hail-vdc/query:tfkm2kev7zcf: No such image: gcr.io/hail-vdc/query:tfkm2kev7zcf'). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 372, in run; await self.ensure_image_is_pulled(); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 363, in ensure_image_is_pulled; docker.images.pull, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9902
https://github.com/hail-is/hail/pull/9902:2389,Safety,timeout,timeout,2389,"st):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 359, in ensure_image_is_pulled; docker.images.get, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 46, in get; return await self.inspect(name); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 36, in inspect; response = await self.docker._query_json(""images/{name}/json"".format(name=name)); File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 223, in _query_json; path, method, params=params, data=data, headers=headers, timeout=timeout; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 206, in _do_query; raise DockerError(response.status, json.loads(what.decode(""utf8""))); aiodocker.exceptions.DockerError: DockerError(404, 'no such image: gcr.io/hail-vdc/query:tfkm2kev7zcf: No such image: gcr.io/hail-vdc/query:tfkm2kev7zcf'). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 372, in run; await self.ensure_image_is_pulled(); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 363, in ensure_image_is_pulled; docker.images.pull, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9902
https://github.com/hail-is/hail/pull/9902:3343,Safety,timeout,timeout,3343,"ams, data=data, headers=headers, timeout=timeout; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 206, in _do_query; raise DockerError(response.status, json.loads(what.decode(""utf8""))); aiodocker.exceptions.DockerError: DockerError(404, 'no such image: gcr.io/hail-vdc/query:tfkm2kev7zcf: No such image: gcr.io/hail-vdc/query:tfkm2kev7zcf'). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 372, in run; await self.ensure_image_is_pulled(); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 363, in ensure_image_is_pulled; docker.images.pull, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 104, in _handle_list; async with cm as response:; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 206, in _do_query; raise DockerError(response.status, json.loads(what.decode(""utf8""))); aiodocker.exceptions.DockerError: DockerError(500, ""unauthorized: You don't have the needed permissions to perform this operation, and you may have invalid credentials. To authenticate your request, follow the steps in: https://cloud.google.com/container-registry/docs/advanced-authentication""); ```. [1] The ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9902
https://github.com/hail-is/hail/pull/9902:192,Security,authenticat,authentication,192,"I thought that pulling with no auth would use the credential helper to use the machine's; credentials. AFAICT, the Docker HTTP API has no way to use the credential helper. You *must* provide; authentication in the HTTP request which means the HTTP client must obtain the credentials; themselves. The Docker docs note [""Authentication for registries is handled client side. The client; has to send authentication details to various endpoints that need to communicate with; registries""](https://docs.docker.com/engine/api/v1.41/#section/Authentication). I request a short-lived oauth2 access token from the Google metadata endpoint. The google; [documentation obliquely notes that the username should be; `oauth2accesstoken`](https://cloud.google.com/container-registry/docs/advanced-authentication). I; use this only for retrieving a ""public gcr image"" which I fix in this PR to be images whose; ""repository"" [1] is one of these:; - gcr.io/PROJECT/query; - gcr.io/PROJECT/hail; - gcr.io/PROJECT/python-dill. A previous Shuffler PR taught worker.py to translate our `hailgenetics` Docker image names to; `gcr.io/PROJECT` image names. I had to move the docker-worker into a new Docker network which allows it to access the metadata server. I think this is safe because we trust our own code. From a relevant Docker worker log:. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 359, in ensure_image_is_pulled; docker.images.get, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/im",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9902
https://github.com/hail-is/hail/pull/9902:319,Security,Authenticat,Authentication,319,"I thought that pulling with no auth would use the credential helper to use the machine's; credentials. AFAICT, the Docker HTTP API has no way to use the credential helper. You *must* provide; authentication in the HTTP request which means the HTTP client must obtain the credentials; themselves. The Docker docs note [""Authentication for registries is handled client side. The client; has to send authentication details to various endpoints that need to communicate with; registries""](https://docs.docker.com/engine/api/v1.41/#section/Authentication). I request a short-lived oauth2 access token from the Google metadata endpoint. The google; [documentation obliquely notes that the username should be; `oauth2accesstoken`](https://cloud.google.com/container-registry/docs/advanced-authentication). I; use this only for retrieving a ""public gcr image"" which I fix in this PR to be images whose; ""repository"" [1] is one of these:; - gcr.io/PROJECT/query; - gcr.io/PROJECT/hail; - gcr.io/PROJECT/python-dill. A previous Shuffler PR taught worker.py to translate our `hailgenetics` Docker image names to; `gcr.io/PROJECT` image names. I had to move the docker-worker into a new Docker network which allows it to access the metadata server. I think this is safe because we trust our own code. From a relevant Docker worker log:. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 359, in ensure_image_is_pulled; docker.images.get, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/im",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9902
https://github.com/hail-is/hail/pull/9902:397,Security,authenticat,authentication,397,"I thought that pulling with no auth would use the credential helper to use the machine's; credentials. AFAICT, the Docker HTTP API has no way to use the credential helper. You *must* provide; authentication in the HTTP request which means the HTTP client must obtain the credentials; themselves. The Docker docs note [""Authentication for registries is handled client side. The client; has to send authentication details to various endpoints that need to communicate with; registries""](https://docs.docker.com/engine/api/v1.41/#section/Authentication). I request a short-lived oauth2 access token from the Google metadata endpoint. The google; [documentation obliquely notes that the username should be; `oauth2accesstoken`](https://cloud.google.com/container-registry/docs/advanced-authentication). I; use this only for retrieving a ""public gcr image"" which I fix in this PR to be images whose; ""repository"" [1] is one of these:; - gcr.io/PROJECT/query; - gcr.io/PROJECT/hail; - gcr.io/PROJECT/python-dill. A previous Shuffler PR taught worker.py to translate our `hailgenetics` Docker image names to; `gcr.io/PROJECT` image names. I had to move the docker-worker into a new Docker network which allows it to access the metadata server. I think this is safe because we trust our own code. From a relevant Docker worker log:. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 359, in ensure_image_is_pulled; docker.images.get, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/im",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9902
https://github.com/hail-is/hail/pull/9902:535,Security,Authenticat,Authentication,535,"I thought that pulling with no auth would use the credential helper to use the machine's; credentials. AFAICT, the Docker HTTP API has no way to use the credential helper. You *must* provide; authentication in the HTTP request which means the HTTP client must obtain the credentials; themselves. The Docker docs note [""Authentication for registries is handled client side. The client; has to send authentication details to various endpoints that need to communicate with; registries""](https://docs.docker.com/engine/api/v1.41/#section/Authentication). I request a short-lived oauth2 access token from the Google metadata endpoint. The google; [documentation obliquely notes that the username should be; `oauth2accesstoken`](https://cloud.google.com/container-registry/docs/advanced-authentication). I; use this only for retrieving a ""public gcr image"" which I fix in this PR to be images whose; ""repository"" [1] is one of these:; - gcr.io/PROJECT/query; - gcr.io/PROJECT/hail; - gcr.io/PROJECT/python-dill. A previous Shuffler PR taught worker.py to translate our `hailgenetics` Docker image names to; `gcr.io/PROJECT` image names. I had to move the docker-worker into a new Docker network which allows it to access the metadata server. I think this is safe because we trust our own code. From a relevant Docker worker log:. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 359, in ensure_image_is_pulled; docker.images.get, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/im",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9902
https://github.com/hail-is/hail/pull/9902:583,Security,access,access,583,"I thought that pulling with no auth would use the credential helper to use the machine's; credentials. AFAICT, the Docker HTTP API has no way to use the credential helper. You *must* provide; authentication in the HTTP request which means the HTTP client must obtain the credentials; themselves. The Docker docs note [""Authentication for registries is handled client side. The client; has to send authentication details to various endpoints that need to communicate with; registries""](https://docs.docker.com/engine/api/v1.41/#section/Authentication). I request a short-lived oauth2 access token from the Google metadata endpoint. The google; [documentation obliquely notes that the username should be; `oauth2accesstoken`](https://cloud.google.com/container-registry/docs/advanced-authentication). I; use this only for retrieving a ""public gcr image"" which I fix in this PR to be images whose; ""repository"" [1] is one of these:; - gcr.io/PROJECT/query; - gcr.io/PROJECT/hail; - gcr.io/PROJECT/python-dill. A previous Shuffler PR taught worker.py to translate our `hailgenetics` Docker image names to; `gcr.io/PROJECT` image names. I had to move the docker-worker into a new Docker network which allows it to access the metadata server. I think this is safe because we trust our own code. From a relevant Docker worker log:. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 359, in ensure_image_is_pulled; docker.images.get, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/im",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9902
https://github.com/hail-is/hail/pull/9902:782,Security,authenticat,authentication,782,"I thought that pulling with no auth would use the credential helper to use the machine's; credentials. AFAICT, the Docker HTTP API has no way to use the credential helper. You *must* provide; authentication in the HTTP request which means the HTTP client must obtain the credentials; themselves. The Docker docs note [""Authentication for registries is handled client side. The client; has to send authentication details to various endpoints that need to communicate with; registries""](https://docs.docker.com/engine/api/v1.41/#section/Authentication). I request a short-lived oauth2 access token from the Google metadata endpoint. The google; [documentation obliquely notes that the username should be; `oauth2accesstoken`](https://cloud.google.com/container-registry/docs/advanced-authentication). I; use this only for retrieving a ""public gcr image"" which I fix in this PR to be images whose; ""repository"" [1] is one of these:; - gcr.io/PROJECT/query; - gcr.io/PROJECT/hail; - gcr.io/PROJECT/python-dill. A previous Shuffler PR taught worker.py to translate our `hailgenetics` Docker image names to; `gcr.io/PROJECT` image names. I had to move the docker-worker into a new Docker network which allows it to access the metadata server. I think this is safe because we trust our own code. From a relevant Docker worker log:. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 359, in ensure_image_is_pulled; docker.images.get, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/im",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9902
https://github.com/hail-is/hail/pull/9902:1209,Security,access,access,1209,"provide; authentication in the HTTP request which means the HTTP client must obtain the credentials; themselves. The Docker docs note [""Authentication for registries is handled client side. The client; has to send authentication details to various endpoints that need to communicate with; registries""](https://docs.docker.com/engine/api/v1.41/#section/Authentication). I request a short-lived oauth2 access token from the Google metadata endpoint. The google; [documentation obliquely notes that the username should be; `oauth2accesstoken`](https://cloud.google.com/container-registry/docs/advanced-authentication). I; use this only for retrieving a ""public gcr image"" which I fix in this PR to be images whose; ""repository"" [1] is one of these:; - gcr.io/PROJECT/query; - gcr.io/PROJECT/hail; - gcr.io/PROJECT/python-dill. A previous Shuffler PR taught worker.py to translate our `hailgenetics` Docker image names to; `gcr.io/PROJECT` image names. I had to move the docker-worker into a new Docker network which allows it to access the metadata server. I think this is safe because we trust our own code. From a relevant Docker worker log:. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 359, in ensure_image_is_pulled; docker.images.get, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 46, in get; return await self.inspect(name); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 36, in inspect; response = await self.docker._query",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9902
https://github.com/hail-is/hail/pull/9902:4211,Security,authenticat,authenticate,4211," gcr.io/hail-vdc/query:tfkm2kev7zcf'). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 372, in run; await self.ensure_image_is_pulled(); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 363, in ensure_image_is_pulled; docker.images.pull, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 104, in _handle_list; async with cm as response:; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 206, in _do_query; raise DockerError(response.status, json.loads(what.decode(""utf8""))); aiodocker.exceptions.DockerError: DockerError(500, ""unauthorized: You don't have the needed permissions to perform this operation, and you may have invalid credentials. To authenticate your request, follow the steps in: https://cloud.google.com/container-registry/docs/advanced-authentication""); ```. [1] The Docker specifications are confusing. After reading; [v1](https://github.com/moby/moby/blob/master/image/spec/v1.md) and; [v1.2](https://github.com/moby/moby/blob/master/image/spec/v1.2.md), it seems that the ""repository""; is everything before the last colon and the ""image name suffix"" is everything after the last; colon. For example, in `server:8080/abc/def:123`, the repository is `server:8080/abc/def` and the; ""image name suffix"" is `123`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9902
https://github.com/hail-is/hail/pull/9902:4317,Security,authenticat,authentication,4317," gcr.io/hail-vdc/query:tfkm2kev7zcf'). During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 372, in run; await self.ensure_image_is_pulled(); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 363, in ensure_image_is_pulled; docker.images.pull, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 104, in _handle_list; async with cm as response:; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 206, in _do_query; raise DockerError(response.status, json.loads(what.decode(""utf8""))); aiodocker.exceptions.DockerError: DockerError(500, ""unauthorized: You don't have the needed permissions to perform this operation, and you may have invalid credentials. To authenticate your request, follow the steps in: https://cloud.google.com/container-registry/docs/advanced-authentication""); ```. [1] The Docker specifications are confusing. After reading; [v1](https://github.com/moby/moby/blob/master/image/spec/v1.md) and; [v1.2](https://github.com/moby/moby/blob/master/image/spec/v1.2.md), it seems that the ""repository""; is everything before the last colon and the ""image name suffix"" is everything after the last; colon. For example, in `server:8080/abc/def:123`, the repository is `server:8080/abc/def` and the; ""image name suffix"" is `123`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9902
https://github.com/hail-is/hail/pull/9902:1319,Testability,log,log,1319," docs note [""Authentication for registries is handled client side. The client; has to send authentication details to various endpoints that need to communicate with; registries""](https://docs.docker.com/engine/api/v1.41/#section/Authentication). I request a short-lived oauth2 access token from the Google metadata endpoint. The google; [documentation obliquely notes that the username should be; `oauth2accesstoken`](https://cloud.google.com/container-registry/docs/advanced-authentication). I; use this only for retrieving a ""public gcr image"" which I fix in this PR to be images whose; ""repository"" [1] is one of these:; - gcr.io/PROJECT/query; - gcr.io/PROJECT/hail; - gcr.io/PROJECT/python-dill. A previous Shuffler PR taught worker.py to translate our `hailgenetics` Docker image names to; `gcr.io/PROJECT` image names. I had to move the docker-worker into a new Docker network which allows it to access the metadata server. I think this is safe because we trust our own code. From a relevant Docker worker log:. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 359, in ensure_image_is_pulled; docker.images.get, self.image); File ""/usr/local/lib/python3.7/site-packages/batch/worker/worker.py"", line 111, in wrapper; return await asyncio.wait_for(f(*args, **kwargs), timeout); File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 442, in wait_for; return fut.result(); File ""/usr/local/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 46, in get; return await self.inspect(name); File ""/usr/local/lib/python3.7/site-packages/aiodocker/images.py"", line 36, in inspect; response = await self.docker._query_json(""images/{name}/json"".format(name=name)); File ""/usr/local/lib/python3.7/site-packages/aiodocker/docker.py"", line 223",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9902
https://github.com/hail-is/hail/pull/9906:296,Availability,resilien,resilient,296,"I do not know why the retries setting in pip.conf did not catch https://ci.hail.is/batches/167314/jobs/27, but more retries never hurt anyone. Another CI-related PR. This one changes the base image of everything else: hail-ubuntu. It's an ubuntu image with two scripts that make pip and apt more resilient. Take a look at docker/hail-ubuntu.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9906
https://github.com/hail-is/hail/pull/9909:33,Energy Efficiency,reduce,reduce,33,The changes in this pull request reduce the runtime of; read / densify / force_count_rows by approximately 30%. Before: 17m42s; After: 12m32s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9909
https://github.com/hail-is/hail/pull/9910:164,Availability,ERROR,ERROR,164,"GCP Logging attempts to infer the severity of a log entry and defaults to labelling everything written to `stdout` as `INFO` and everything written to `stderr` as `ERROR`. There are some [LogEntry fields](https://cloud.google.com/logging/docs/structured-logging) that can be overwritten by fields in our JSON output, including `severity`. Until now we had been logging the severity level as `levelname`, which is the expectation of `jsonlogger`, but this means GCP's levels and ours do not necessarily match. This adds another `severity` field to the logs so GCP can pick up the level. This should get rid of a swath of non-error log messages written to `stderr` (only JSON though) and lets other levels like `WARNING` get marked as such. GCP does quite literally extract the severity field though, so it does not appear in the `jsonPayload`. I've kept the `levelname` in then as a sanity check but am also happy to try to remove it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9910
https://github.com/hail-is/hail/pull/9910:624,Availability,error,error,624,"GCP Logging attempts to infer the severity of a log entry and defaults to labelling everything written to `stdout` as `INFO` and everything written to `stderr` as `ERROR`. There are some [LogEntry fields](https://cloud.google.com/logging/docs/structured-logging) that can be overwritten by fields in our JSON output, including `severity`. Until now we had been logging the severity level as `levelname`, which is the expectation of `jsonlogger`, but this means GCP's levels and ours do not necessarily match. This adds another `severity` field to the logs so GCP can pick up the level. This should get rid of a swath of non-error log messages written to `stderr` (only JSON though) and lets other levels like `WARNING` get marked as such. GCP does quite literally extract the severity field though, so it does not appear in the `jsonPayload`. I've kept the `levelname` in then as a sanity check but am also happy to try to remove it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9910
https://github.com/hail-is/hail/pull/9910:634,Integrability,message,messages,634,"GCP Logging attempts to infer the severity of a log entry and defaults to labelling everything written to `stdout` as `INFO` and everything written to `stderr` as `ERROR`. There are some [LogEntry fields](https://cloud.google.com/logging/docs/structured-logging) that can be overwritten by fields in our JSON output, including `severity`. Until now we had been logging the severity level as `levelname`, which is the expectation of `jsonlogger`, but this means GCP's levels and ours do not necessarily match. This adds another `severity` field to the logs so GCP can pick up the level. This should get rid of a swath of non-error log messages written to `stderr` (only JSON though) and lets other levels like `WARNING` get marked as such. GCP does quite literally extract the severity field though, so it does not appear in the `jsonPayload`. I've kept the `levelname` in then as a sanity check but am also happy to try to remove it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9910
https://github.com/hail-is/hail/pull/9910:882,Safety,sanity check,sanity check,882,"GCP Logging attempts to infer the severity of a log entry and defaults to labelling everything written to `stdout` as `INFO` and everything written to `stderr` as `ERROR`. There are some [LogEntry fields](https://cloud.google.com/logging/docs/structured-logging) that can be overwritten by fields in our JSON output, including `severity`. Until now we had been logging the severity level as `levelname`, which is the expectation of `jsonlogger`, but this means GCP's levels and ours do not necessarily match. This adds another `severity` field to the logs so GCP can pick up the level. This should get rid of a swath of non-error log messages written to `stderr` (only JSON though) and lets other levels like `WARNING` get marked as such. GCP does quite literally extract the severity field though, so it does not appear in the `jsonPayload`. I've kept the `levelname` in then as a sanity check but am also happy to try to remove it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9910
https://github.com/hail-is/hail/pull/9910:4,Testability,Log,Logging,4,"GCP Logging attempts to infer the severity of a log entry and defaults to labelling everything written to `stdout` as `INFO` and everything written to `stderr` as `ERROR`. There are some [LogEntry fields](https://cloud.google.com/logging/docs/structured-logging) that can be overwritten by fields in our JSON output, including `severity`. Until now we had been logging the severity level as `levelname`, which is the expectation of `jsonlogger`, but this means GCP's levels and ours do not necessarily match. This adds another `severity` field to the logs so GCP can pick up the level. This should get rid of a swath of non-error log messages written to `stderr` (only JSON though) and lets other levels like `WARNING` get marked as such. GCP does quite literally extract the severity field though, so it does not appear in the `jsonPayload`. I've kept the `levelname` in then as a sanity check but am also happy to try to remove it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9910
https://github.com/hail-is/hail/pull/9910:48,Testability,log,log,48,"GCP Logging attempts to infer the severity of a log entry and defaults to labelling everything written to `stdout` as `INFO` and everything written to `stderr` as `ERROR`. There are some [LogEntry fields](https://cloud.google.com/logging/docs/structured-logging) that can be overwritten by fields in our JSON output, including `severity`. Until now we had been logging the severity level as `levelname`, which is the expectation of `jsonlogger`, but this means GCP's levels and ours do not necessarily match. This adds another `severity` field to the logs so GCP can pick up the level. This should get rid of a swath of non-error log messages written to `stderr` (only JSON though) and lets other levels like `WARNING` get marked as such. GCP does quite literally extract the severity field though, so it does not appear in the `jsonPayload`. I've kept the `levelname` in then as a sanity check but am also happy to try to remove it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9910
https://github.com/hail-is/hail/pull/9910:188,Testability,Log,LogEntry,188,"GCP Logging attempts to infer the severity of a log entry and defaults to labelling everything written to `stdout` as `INFO` and everything written to `stderr` as `ERROR`. There are some [LogEntry fields](https://cloud.google.com/logging/docs/structured-logging) that can be overwritten by fields in our JSON output, including `severity`. Until now we had been logging the severity level as `levelname`, which is the expectation of `jsonlogger`, but this means GCP's levels and ours do not necessarily match. This adds another `severity` field to the logs so GCP can pick up the level. This should get rid of a swath of non-error log messages written to `stderr` (only JSON though) and lets other levels like `WARNING` get marked as such. GCP does quite literally extract the severity field though, so it does not appear in the `jsonPayload`. I've kept the `levelname` in then as a sanity check but am also happy to try to remove it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9910
https://github.com/hail-is/hail/pull/9910:230,Testability,log,logging,230,"GCP Logging attempts to infer the severity of a log entry and defaults to labelling everything written to `stdout` as `INFO` and everything written to `stderr` as `ERROR`. There are some [LogEntry fields](https://cloud.google.com/logging/docs/structured-logging) that can be overwritten by fields in our JSON output, including `severity`. Until now we had been logging the severity level as `levelname`, which is the expectation of `jsonlogger`, but this means GCP's levels and ours do not necessarily match. This adds another `severity` field to the logs so GCP can pick up the level. This should get rid of a swath of non-error log messages written to `stderr` (only JSON though) and lets other levels like `WARNING` get marked as such. GCP does quite literally extract the severity field though, so it does not appear in the `jsonPayload`. I've kept the `levelname` in then as a sanity check but am also happy to try to remove it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9910
https://github.com/hail-is/hail/pull/9910:254,Testability,log,logging,254,"GCP Logging attempts to infer the severity of a log entry and defaults to labelling everything written to `stdout` as `INFO` and everything written to `stderr` as `ERROR`. There are some [LogEntry fields](https://cloud.google.com/logging/docs/structured-logging) that can be overwritten by fields in our JSON output, including `severity`. Until now we had been logging the severity level as `levelname`, which is the expectation of `jsonlogger`, but this means GCP's levels and ours do not necessarily match. This adds another `severity` field to the logs so GCP can pick up the level. This should get rid of a swath of non-error log messages written to `stderr` (only JSON though) and lets other levels like `WARNING` get marked as such. GCP does quite literally extract the severity field though, so it does not appear in the `jsonPayload`. I've kept the `levelname` in then as a sanity check but am also happy to try to remove it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9910
https://github.com/hail-is/hail/pull/9910:361,Testability,log,logging,361,"GCP Logging attempts to infer the severity of a log entry and defaults to labelling everything written to `stdout` as `INFO` and everything written to `stderr` as `ERROR`. There are some [LogEntry fields](https://cloud.google.com/logging/docs/structured-logging) that can be overwritten by fields in our JSON output, including `severity`. Until now we had been logging the severity level as `levelname`, which is the expectation of `jsonlogger`, but this means GCP's levels and ours do not necessarily match. This adds another `severity` field to the logs so GCP can pick up the level. This should get rid of a swath of non-error log messages written to `stderr` (only JSON though) and lets other levels like `WARNING` get marked as such. GCP does quite literally extract the severity field though, so it does not appear in the `jsonPayload`. I've kept the `levelname` in then as a sanity check but am also happy to try to remove it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9910
https://github.com/hail-is/hail/pull/9910:551,Testability,log,logs,551,"GCP Logging attempts to infer the severity of a log entry and defaults to labelling everything written to `stdout` as `INFO` and everything written to `stderr` as `ERROR`. There are some [LogEntry fields](https://cloud.google.com/logging/docs/structured-logging) that can be overwritten by fields in our JSON output, including `severity`. Until now we had been logging the severity level as `levelname`, which is the expectation of `jsonlogger`, but this means GCP's levels and ours do not necessarily match. This adds another `severity` field to the logs so GCP can pick up the level. This should get rid of a swath of non-error log messages written to `stderr` (only JSON though) and lets other levels like `WARNING` get marked as such. GCP does quite literally extract the severity field though, so it does not appear in the `jsonPayload`. I've kept the `levelname` in then as a sanity check but am also happy to try to remove it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9910
https://github.com/hail-is/hail/pull/9910:630,Testability,log,log,630,"GCP Logging attempts to infer the severity of a log entry and defaults to labelling everything written to `stdout` as `INFO` and everything written to `stderr` as `ERROR`. There are some [LogEntry fields](https://cloud.google.com/logging/docs/structured-logging) that can be overwritten by fields in our JSON output, including `severity`. Until now we had been logging the severity level as `levelname`, which is the expectation of `jsonlogger`, but this means GCP's levels and ours do not necessarily match. This adds another `severity` field to the logs so GCP can pick up the level. This should get rid of a swath of non-error log messages written to `stderr` (only JSON though) and lets other levels like `WARNING` get marked as such. GCP does quite literally extract the severity field though, so it does not appear in the `jsonPayload`. I've kept the `levelname` in then as a sanity check but am also happy to try to remove it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9910
https://github.com/hail-is/hail/pull/9911:27,Integrability,rout,router-resolver,27,Use our `AccessLogger` in `router-resolver` too.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9911
https://github.com/hail-is/hail/pull/9911:9,Security,Access,AccessLogger,9,Use our `AccessLogger` in `router-resolver` too.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9911
https://github.com/hail-is/hail/pull/9913:67,Modifiability,rewrite,rewrites,67,This is stacked on https://github.com/hail-is/hail/pull/9842 which rewrites hailctl argument handling. Probably not worth reviewing until that is in.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9913
https://github.com/hail-is/hail/pull/9915:2,Usability,simpl,simplistic,2,A simplistic port that still uses an EmitCode for the element IR to keep; BinarySearch mostly happy,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9915
https://github.com/hail-is/hail/pull/9918:167,Energy Efficiency,efficient,efficiently,167,implement in LocalAsyncFS with test. AsynFS needs to support multi-part writes in order to parallelize transfers of large files. Next PR will implement this for gs:// efficiently using a temporary file and the compose operation.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9918
https://github.com/hail-is/hail/pull/9918:31,Testability,test,test,31,implement in LocalAsyncFS with test. AsynFS needs to support multi-part writes in order to parallelize transfers of large files. Next PR will implement this for gs:// efficiently using a temporary file and the compose operation.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9918
https://github.com/hail-is/hail/pull/9919:425,Availability,failure,failure,425,"The router resolver incorrectly assumed the contents of the `Authorization` header was a session; id. In fact, the structure of that header and X-Hail-Internal-Authorization is:. ```; Bearer SESSION_ID; ```. where `SESSION_ID` is a 44 base64 characters representing a 32 byte secret session id. I also took this opportunity to centralize the parsing of bearer headers as; `gear.maybe_parse_bearer_header`. ---. This caused a failure because router-resolver, when checking that a user is properly authenticated,; would send:. ```; Bearer Bearer SESSION_ID; ```. which failed the 44-byte length check in auth/front_end.py.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9919
https://github.com/hail-is/hail/pull/9919:4,Integrability,rout,router,4,"The router resolver incorrectly assumed the contents of the `Authorization` header was a session; id. In fact, the structure of that header and X-Hail-Internal-Authorization is:. ```; Bearer SESSION_ID; ```. where `SESSION_ID` is a 44 base64 characters representing a 32 byte secret session id. I also took this opportunity to centralize the parsing of bearer headers as; `gear.maybe_parse_bearer_header`. ---. This caused a failure because router-resolver, when checking that a user is properly authenticated,; would send:. ```; Bearer Bearer SESSION_ID; ```. which failed the 44-byte length check in auth/front_end.py.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9919
https://github.com/hail-is/hail/pull/9919:441,Integrability,rout,router-resolver,441,"The router resolver incorrectly assumed the contents of the `Authorization` header was a session; id. In fact, the structure of that header and X-Hail-Internal-Authorization is:. ```; Bearer SESSION_ID; ```. where `SESSION_ID` is a 44 base64 characters representing a 32 byte secret session id. I also took this opportunity to centralize the parsing of bearer headers as; `gear.maybe_parse_bearer_header`. ---. This caused a failure because router-resolver, when checking that a user is properly authenticated,; would send:. ```; Bearer Bearer SESSION_ID; ```. which failed the 44-byte length check in auth/front_end.py.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9919
https://github.com/hail-is/hail/pull/9919:61,Security,Authoriz,Authorization,61,"The router resolver incorrectly assumed the contents of the `Authorization` header was a session; id. In fact, the structure of that header and X-Hail-Internal-Authorization is:. ```; Bearer SESSION_ID; ```. where `SESSION_ID` is a 44 base64 characters representing a 32 byte secret session id. I also took this opportunity to centralize the parsing of bearer headers as; `gear.maybe_parse_bearer_header`. ---. This caused a failure because router-resolver, when checking that a user is properly authenticated,; would send:. ```; Bearer Bearer SESSION_ID; ```. which failed the 44-byte length check in auth/front_end.py.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9919
https://github.com/hail-is/hail/pull/9919:160,Security,Authoriz,Authorization,160,"The router resolver incorrectly assumed the contents of the `Authorization` header was a session; id. In fact, the structure of that header and X-Hail-Internal-Authorization is:. ```; Bearer SESSION_ID; ```. where `SESSION_ID` is a 44 base64 characters representing a 32 byte secret session id. I also took this opportunity to centralize the parsing of bearer headers as; `gear.maybe_parse_bearer_header`. ---. This caused a failure because router-resolver, when checking that a user is properly authenticated,; would send:. ```; Bearer Bearer SESSION_ID; ```. which failed the 44-byte length check in auth/front_end.py.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9919
https://github.com/hail-is/hail/pull/9919:496,Security,authenticat,authenticated,496,"The router resolver incorrectly assumed the contents of the `Authorization` header was a session; id. In fact, the structure of that header and X-Hail-Internal-Authorization is:. ```; Bearer SESSION_ID; ```. where `SESSION_ID` is a 44 base64 characters representing a 32 byte secret session id. I also took this opportunity to centralize the parsing of bearer headers as; `gear.maybe_parse_bearer_header`. ---. This caused a failure because router-resolver, when checking that a user is properly authenticated,; would send:. ```; Bearer Bearer SESSION_ID; ```. which failed the 44-byte length check in auth/front_end.py.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9919
https://github.com/hail-is/hail/pull/9926:0,Modifiability,Refactor,Refactor,0,Refactor `_emitStream` to a `EmitCodeBuilder -> IEmitCode` signature.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9926
https://github.com/hail-is/hail/pull/9928:462,Availability,failure,failure,462,"- Basic JSON format for NGINX access logs; - `message`, `remote_address`, `request_duration`, `response_status` and `x_real_ip` should match the Python Access logger so we should be able to query these fields all at once; - Unfortunately the NGINX `error_log` does not allow the same custom formatter, but we can create multiple, [custom access logs](https://www.nginx.com/blog/diagnostic-logging-nginx-javascript-module/#proxy_next_upstream) based on arbitrary failure criteria if there's a particular class of error logs we want to get in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9928
https://github.com/hail-is/hail/pull/9928:512,Availability,error,error,512,"- Basic JSON format for NGINX access logs; - `message`, `remote_address`, `request_duration`, `response_status` and `x_real_ip` should match the Python Access logger so we should be able to query these fields all at once; - Unfortunately the NGINX `error_log` does not allow the same custom formatter, but we can create multiple, [custom access logs](https://www.nginx.com/blog/diagnostic-logging-nginx-javascript-module/#proxy_next_upstream) based on arbitrary failure criteria if there's a particular class of error logs we want to get in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9928
https://github.com/hail-is/hail/pull/9928:46,Integrability,message,message,46,"- Basic JSON format for NGINX access logs; - `message`, `remote_address`, `request_duration`, `response_status` and `x_real_ip` should match the Python Access logger so we should be able to query these fields all at once; - Unfortunately the NGINX `error_log` does not allow the same custom formatter, but we can create multiple, [custom access logs](https://www.nginx.com/blog/diagnostic-logging-nginx-javascript-module/#proxy_next_upstream) based on arbitrary failure criteria if there's a particular class of error logs we want to get in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9928
https://github.com/hail-is/hail/pull/9928:30,Security,access,access,30,"- Basic JSON format for NGINX access logs; - `message`, `remote_address`, `request_duration`, `response_status` and `x_real_ip` should match the Python Access logger so we should be able to query these fields all at once; - Unfortunately the NGINX `error_log` does not allow the same custom formatter, but we can create multiple, [custom access logs](https://www.nginx.com/blog/diagnostic-logging-nginx-javascript-module/#proxy_next_upstream) based on arbitrary failure criteria if there's a particular class of error logs we want to get in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9928
https://github.com/hail-is/hail/pull/9928:152,Security,Access,Access,152,"- Basic JSON format for NGINX access logs; - `message`, `remote_address`, `request_duration`, `response_status` and `x_real_ip` should match the Python Access logger so we should be able to query these fields all at once; - Unfortunately the NGINX `error_log` does not allow the same custom formatter, but we can create multiple, [custom access logs](https://www.nginx.com/blog/diagnostic-logging-nginx-javascript-module/#proxy_next_upstream) based on arbitrary failure criteria if there's a particular class of error logs we want to get in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9928
https://github.com/hail-is/hail/pull/9928:338,Security,access,access,338,"- Basic JSON format for NGINX access logs; - `message`, `remote_address`, `request_duration`, `response_status` and `x_real_ip` should match the Python Access logger so we should be able to query these fields all at once; - Unfortunately the NGINX `error_log` does not allow the same custom formatter, but we can create multiple, [custom access logs](https://www.nginx.com/blog/diagnostic-logging-nginx-javascript-module/#proxy_next_upstream) based on arbitrary failure criteria if there's a particular class of error logs we want to get in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9928
https://github.com/hail-is/hail/pull/9928:37,Testability,log,logs,37,"- Basic JSON format for NGINX access logs; - `message`, `remote_address`, `request_duration`, `response_status` and `x_real_ip` should match the Python Access logger so we should be able to query these fields all at once; - Unfortunately the NGINX `error_log` does not allow the same custom formatter, but we can create multiple, [custom access logs](https://www.nginx.com/blog/diagnostic-logging-nginx-javascript-module/#proxy_next_upstream) based on arbitrary failure criteria if there's a particular class of error logs we want to get in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9928
https://github.com/hail-is/hail/pull/9928:159,Testability,log,logger,159,"- Basic JSON format for NGINX access logs; - `message`, `remote_address`, `request_duration`, `response_status` and `x_real_ip` should match the Python Access logger so we should be able to query these fields all at once; - Unfortunately the NGINX `error_log` does not allow the same custom formatter, but we can create multiple, [custom access logs](https://www.nginx.com/blog/diagnostic-logging-nginx-javascript-module/#proxy_next_upstream) based on arbitrary failure criteria if there's a particular class of error logs we want to get in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9928
https://github.com/hail-is/hail/pull/9928:345,Testability,log,logs,345,"- Basic JSON format for NGINX access logs; - `message`, `remote_address`, `request_duration`, `response_status` and `x_real_ip` should match the Python Access logger so we should be able to query these fields all at once; - Unfortunately the NGINX `error_log` does not allow the same custom formatter, but we can create multiple, [custom access logs](https://www.nginx.com/blog/diagnostic-logging-nginx-javascript-module/#proxy_next_upstream) based on arbitrary failure criteria if there's a particular class of error logs we want to get in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9928
https://github.com/hail-is/hail/pull/9928:389,Testability,log,logging-nginx-javascript-module,389,"- Basic JSON format for NGINX access logs; - `message`, `remote_address`, `request_duration`, `response_status` and `x_real_ip` should match the Python Access logger so we should be able to query these fields all at once; - Unfortunately the NGINX `error_log` does not allow the same custom formatter, but we can create multiple, [custom access logs](https://www.nginx.com/blog/diagnostic-logging-nginx-javascript-module/#proxy_next_upstream) based on arbitrary failure criteria if there's a particular class of error logs we want to get in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9928
https://github.com/hail-is/hail/pull/9928:518,Testability,log,logs,518,"- Basic JSON format for NGINX access logs; - `message`, `remote_address`, `request_duration`, `response_status` and `x_real_ip` should match the Python Access logger so we should be able to query these fields all at once; - Unfortunately the NGINX `error_log` does not allow the same custom formatter, but we can create multiple, [custom access logs](https://www.nginx.com/blog/diagnostic-logging-nginx-javascript-module/#proxy_next_upstream) based on arbitrary failure criteria if there's a particular class of error logs we want to get in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9928
https://github.com/hail-is/hail/pull/9930:51,Availability,error,error,51,"- Using `-x` prints every line of the script to an error log entry. The main thing we're concerned about here is if it can fetch from notebook, so capture that output in `image-fetch-output.log` and cat that out to `stderr` only if it failed so it shows up as errors in the logs. - Removed old templating from before the `jinja2` times. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9930
https://github.com/hail-is/hail/pull/9930:260,Availability,error,errors,260,"- Using `-x` prints every line of the script to an error log entry. The main thing we're concerned about here is if it can fetch from notebook, so capture that output in `image-fetch-output.log` and cat that out to `stderr` only if it failed so it shows up as errors in the logs. - Removed old templating from before the `jinja2` times. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9930
https://github.com/hail-is/hail/pull/9930:57,Testability,log,log,57,"- Using `-x` prints every line of the script to an error log entry. The main thing we're concerned about here is if it can fetch from notebook, so capture that output in `image-fetch-output.log` and cat that out to `stderr` only if it failed so it shows up as errors in the logs. - Removed old templating from before the `jinja2` times. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9930
https://github.com/hail-is/hail/pull/9930:190,Testability,log,log,190,"- Using `-x` prints every line of the script to an error log entry. The main thing we're concerned about here is if it can fetch from notebook, so capture that output in `image-fetch-output.log` and cat that out to `stderr` only if it failed so it shows up as errors in the logs. - Removed old templating from before the `jinja2` times. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9930
https://github.com/hail-is/hail/pull/9930:274,Testability,log,logs,274,"- Using `-x` prints every line of the script to an error log entry. The main thing we're concerned about here is if it can fetch from notebook, so capture that output in `image-fetch-output.log` and cat that out to `stderr` only if it failed so it shows up as errors in the logs. - Removed old templating from before the `jinja2` times. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9930
https://github.com/hail-is/hail/pull/9932:19,Testability,log,log,19,Eliminates the two log entries for unclosed connections/sessions on shutdown,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9932
https://github.com/hail-is/hail/pull/9933:4,Deployability,deploy,deploy,4,dev deploy isn't quite there yet with the 5 second rule and is timing out a lot.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9933
https://github.com/hail-is/hail/pull/9934:2942,Availability,down,download,2942,"ol). For example:. ```; sema = asyncio.Semaphore(50); async with sema:; await copy(sema, ...); ```. Then, to run a set of operations in parallel, subject to the global parallelism bound, use bounded_gather2:. ```; await bounded_gather2(sema, *aws); ```. The naive implementation of bounded_gather2 doesn't work: bounded_gather2 cannot spawn a task for each awaitable and have it try to acquiare the semaphore, because this can lead to deadlock: if 50 tasks launch and wait for children, but none of those children can run because the parents have all the threads of control, the algorithm will deadlock. The key is to make sure at least one child can always be running in a bounded_gather2. But the caller of bounded_gather2 had a reserved thread of execution and it is blocking, so that thread of execution should be transferred to the children while the bounded_gather2 is blocked. This is what bounded_gather2 does. There is also an ""online"" version of bounded_gather2 which lets you schedule an unbounded number of children (potentially generated asynchronously). OnlineBoundedGather2 is used in parallelizing file transfers generated by directory listings, for example, which are enumerated via an async generator, and are potentially very large. I will try to replace bounded_gather and the async worker pool with this mechanism in a future PR. The parameters will likely need additional tuning. I have done some rough timing, and already this is beating gsutil:. - Transfer 10GB spread over 40K files (times in ms):. {'upload': 95803,; 'download': 55240,; 'compare': 54117,; 'clean file': 632,; 'clean gs': 117263,; 'total': 323061}. vs the gsutil transfer:. real	11m14.153s; user	14m28.789s; sys	1m29.090s. and gsutil cleanup (removing 40K files in gs://):. real	10m12.236s; user	3m33.382s; sys	0m55.450s. - Transfer 10GB in one file takes ~20s (up) and ~30s (down) for copy vs ~1m for gsutil. I'm still working on the benchmark harness and will post more complete comparisons in a future PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9934
https://github.com/hail-is/hail/pull/9934:3266,Availability,down,down,3266,"ol). For example:. ```; sema = asyncio.Semaphore(50); async with sema:; await copy(sema, ...); ```. Then, to run a set of operations in parallel, subject to the global parallelism bound, use bounded_gather2:. ```; await bounded_gather2(sema, *aws); ```. The naive implementation of bounded_gather2 doesn't work: bounded_gather2 cannot spawn a task for each awaitable and have it try to acquiare the semaphore, because this can lead to deadlock: if 50 tasks launch and wait for children, but none of those children can run because the parents have all the threads of control, the algorithm will deadlock. The key is to make sure at least one child can always be running in a bounded_gather2. But the caller of bounded_gather2 had a reserved thread of execution and it is blocking, so that thread of execution should be transferred to the children while the bounded_gather2 is blocked. This is what bounded_gather2 does. There is also an ""online"" version of bounded_gather2 which lets you schedule an unbounded number of children (potentially generated asynchronously). OnlineBoundedGather2 is used in parallelizing file transfers generated by directory listings, for example, which are enumerated via an async generator, and are potentially very large. I will try to replace bounded_gather and the async worker pool with this mechanism in a future PR. The parameters will likely need additional tuning. I have done some rough timing, and already this is beating gsutil:. - Transfer 10GB spread over 40K files (times in ms):. {'upload': 95803,; 'download': 55240,; 'compare': 54117,; 'clean file': 632,; 'clean gs': 117263,; 'total': 323061}. vs the gsutil transfer:. real	11m14.153s; user	14m28.789s; sys	1m29.090s. and gsutil cleanup (removing 40K files in gs://):. real	10m12.236s; user	3m33.382s; sys	0m55.450s. - Transfer 10GB in one file takes ~20s (up) and ~30s (down) for copy vs ~1m for gsutil. I'm still working on the benchmark harness and will post more complete comparisons in a future PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9934
https://github.com/hail-is/hail/pull/9934:2385,Energy Efficiency,schedul,schedule,2385,"of control). For example:. ```; sema = asyncio.Semaphore(50); async with sema:; await copy(sema, ...); ```. Then, to run a set of operations in parallel, subject to the global parallelism bound, use bounded_gather2:. ```; await bounded_gather2(sema, *aws); ```. The naive implementation of bounded_gather2 doesn't work: bounded_gather2 cannot spawn a task for each awaitable and have it try to acquiare the semaphore, because this can lead to deadlock: if 50 tasks launch and wait for children, but none of those children can run because the parents have all the threads of control, the algorithm will deadlock. The key is to make sure at least one child can always be running in a bounded_gather2. But the caller of bounded_gather2 had a reserved thread of execution and it is blocking, so that thread of execution should be transferred to the children while the bounded_gather2 is blocked. This is what bounded_gather2 does. There is also an ""online"" version of bounded_gather2 which lets you schedule an unbounded number of children (potentially generated asynchronously). OnlineBoundedGather2 is used in parallelizing file transfers generated by directory listings, for example, which are enumerated via an async generator, and are potentially very large. I will try to replace bounded_gather and the async worker pool with this mechanism in a future PR. The parameters will likely need additional tuning. I have done some rough timing, and already this is beating gsutil:. - Transfer 10GB spread over 40K files (times in ms):. {'upload': 95803,; 'download': 55240,; 'compare': 54117,; 'clean file': 632,; 'clean gs': 117263,; 'total': 323061}. vs the gsutil transfer:. real	11m14.153s; user	14m28.789s; sys	1m29.090s. and gsutil cleanup (removing 40K files in gs://):. real	10m12.236s; user	3m33.382s; sys	0m55.450s. - Transfer 10GB in one file takes ~20s (up) and ~30s (down) for copy vs ~1m for gsutil. I'm still working on the benchmark harness and will post more complete comparisons in a fut",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9934
https://github.com/hail-is/hail/pull/9934:3325,Testability,benchmark,benchmark,3325,"ol). For example:. ```; sema = asyncio.Semaphore(50); async with sema:; await copy(sema, ...); ```. Then, to run a set of operations in parallel, subject to the global parallelism bound, use bounded_gather2:. ```; await bounded_gather2(sema, *aws); ```. The naive implementation of bounded_gather2 doesn't work: bounded_gather2 cannot spawn a task for each awaitable and have it try to acquiare the semaphore, because this can lead to deadlock: if 50 tasks launch and wait for children, but none of those children can run because the parents have all the threads of control, the algorithm will deadlock. The key is to make sure at least one child can always be running in a bounded_gather2. But the caller of bounded_gather2 had a reserved thread of execution and it is blocking, so that thread of execution should be transferred to the children while the bounded_gather2 is blocked. This is what bounded_gather2 does. There is also an ""online"" version of bounded_gather2 which lets you schedule an unbounded number of children (potentially generated asynchronously). OnlineBoundedGather2 is used in parallelizing file transfers generated by directory listings, for example, which are enumerated via an async generator, and are potentially very large. I will try to replace bounded_gather and the async worker pool with this mechanism in a future PR. The parameters will likely need additional tuning. I have done some rough timing, and already this is beating gsutil:. - Transfer 10GB spread over 40K files (times in ms):. {'upload': 95803,; 'download': 55240,; 'compare': 54117,; 'clean file': 632,; 'clean gs': 117263,; 'total': 323061}. vs the gsutil transfer:. real	11m14.153s; user	14m28.789s; sys	1m29.090s. and gsutil cleanup (removing 40K files in gs://):. real	10m12.236s; user	3m33.382s; sys	0m55.450s. - Transfer 10GB in one file takes ~20s (up) and ~30s (down) for copy vs ~1m for gsutil. I'm still working on the benchmark harness and will post more complete comparisons in a future PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9934
https://github.com/hail-is/hail/pull/9934:1151,Usability,resume,resume,1151,":; - add compose to aiogoogle StorageClient and use it to implement (hierarchical) multi-part write for the google AsyncFS; - add AsyncFS.open_from, to open a file starting at a given offset,; - PART_SIZE is the size of parts to transfer and the combine with a multi-part write when copying large files. PART_SIZE is currently 128MB.; - BUFFER_SIZE is the size we request when reading in the copy. Change this to 256KB (from 8KB).; - Copy files in parts and use multi-part writes when copying large files.; - Parallelize rmtree (it now takes a semaphore for controlling parallelism); - Add new primitives for parallelization, bounded_gather2 and OnlineBoundedGather2. bounded_gather2 was an interesting design problem. I would describe it like this:. Say you have serial asyncio code with I/O (which will block the serial algorithm when the I/O is pending) which you'd like to parallelize. You can't do this generically, so in addition I imagine there are parallelization fork/join points where you want to run a bunch of subcomputations in parallel, wait for them all to complete, and resume where you left off. The code begins by creating a asyncio.Semaphore that globally bounds the parallelism of the code, and acquiring the semaphore before executing the code (since the entrypoint into the code accounts for one thread of control). For example:. ```; sema = asyncio.Semaphore(50); async with sema:; await copy(sema, ...); ```. Then, to run a set of operations in parallel, subject to the global parallelism bound, use bounded_gather2:. ```; await bounded_gather2(sema, *aws); ```. The naive implementation of bounded_gather2 doesn't work: bounded_gather2 cannot spawn a task for each awaitable and have it try to acquiare the semaphore, because this can lead to deadlock: if 50 tasks launch and wait for children, but none of those children can run because the parents have all the threads of control, the algorithm will deadlock. The key is to make sure at least one child can always be running",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9934
https://github.com/hail-is/hail/pull/9935:60,Deployability,integrat,integrate,60,"Currently, this just spins up a new JVM instance; I need to integrate this with a different branch with a standing JVM server that listens on a TCP socket for incoming jobs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9935
https://github.com/hail-is/hail/pull/9935:60,Integrability,integrat,integrate,60,"Currently, this just spins up a new JVM instance; I need to integrate this with a different branch with a standing JVM server that listens on a TCP socket for incoming jobs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9935
https://github.com/hail-is/hail/issues/9939:372,Availability,avail,available,372,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------; Versions of software products:. Running on Apache Spark version 2.4.5; SparkUI available at http://vhabosgen72:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.61-3c86d3ba497a; LOGGING: writing to /dacs1/team/vhabhsxum/tasks/ancestryPainting/hail-20210125-1235-0.2.61-3c86d3ba497a.log. I am running the GWAS tutorial hosted at https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html#Let's-do-a-GWAS. Everything is OK until the line to do GWAS. The error I have is as follows:. -------------- start of error ------------------; 2021-01-25 12:36:11 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:802,Availability,error,error,802,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------; Versions of software products:. Running on Apache Spark version 2.4.5; SparkUI available at http://vhabosgen72:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.61-3c86d3ba497a; LOGGING: writing to /dacs1/team/vhabhsxum/tasks/ancestryPainting/hail-20210125-1235-0.2.61-3c86d3ba497a.log. I am running the GWAS tutorial hosted at https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html#Let's-do-a-GWAS. Everything is OK until the line to do GWAS. The error I have is as follows:. -------------- start of error ------------------; 2021-01-25 12:36:11 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:855,Availability,error,error,855,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------; Versions of software products:. Running on Apache Spark version 2.4.5; SparkUI available at http://vhabosgen72:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.61-3c86d3ba497a; LOGGING: writing to /dacs1/team/vhabhsxum/tasks/ancestryPainting/hail-20210125-1235-0.2.61-3c86d3ba497a.log. I am running the GWAS tutorial hosted at https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html#Let's-do-a-GWAS. Everything is OK until the line to do GWAS. The error I have is as follows:. -------------- start of error ------------------; 2021-01-25 12:36:11 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:1042,Availability,ERROR,ERROR,1042,"and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------; Versions of software products:. Running on Apache Spark version 2.4.5; SparkUI available at http://vhabosgen72:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.61-3c86d3ba497a; LOGGING: writing to /dacs1/team/vhabhsxum/tasks/ancestryPainting/hail-20210125-1235-0.2.61-3c86d3ba497a.log. I am running the GWAS tutorial hosted at https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html#Let's-do-a-GWAS. Everything is OK until the line to do GWAS. The error I have is as follows:. -------------- start of error ------------------; 2021-01-25 12:36:11 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:1749,Availability,Error,Error,1749,"GWAS. Everything is OK until the line to do GWAS. The error I have is as follows:. -------------- start of error ------------------; 2021-01-25 12:36:11 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-40-d6d936b012db>"", line 3, in <module>; covariates=[1.0]); File ""<decorator-gen-1697>"", line 2, in linear_regression_rows; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/methods/statgen.py"", line 370, in linear_regression_rows; return ht_result.persist(); File ""<decorator-gen-1111>"", line 2, in persist; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:1833,Availability,Error,Error,1833,"---- start of error ------------------; 2021-01-25 12:36:11 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-40-d6d936b012db>"", line 3, in <module>; covariates=[1.0]); File ""<decorator-gen-1697>"", line 2, in linear_regression_rows; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/methods/statgen.py"", line 370, in linear_regression_rows; return ht_result.persist(); File ""<decorator-gen-1111>"", line 2, in persist; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); F",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:1856,Availability,ERROR,ERROR,1856,"---- start of error ------------------; 2021-01-25 12:36:11 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-40-d6d936b012db>"", line 3, in <module>; covariates=[1.0]); File ""<decorator-gen-1697>"", line 2, in linear_regression_rows; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/methods/statgen.py"", line 370, in linear_regression_rows; return ht_result.persist(); File ""<decorator-gen-1111>"", line 2, in persist; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); F",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:1883,Availability,error,error,1883," INFO: linear_regression_rows: running on 250 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-40-d6d936b012db>"", line 3, in <module>; covariates=[1.0]); File ""<decorator-gen-1697>"", line 2, in linear_regression_rows; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/methods/statgen.py"", line 370, in linear_regression_rows; return ht_result.persist(); File ""<decorator-gen-1111>"", line 2, in persist; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:3723,Availability,error,error,3723,".6/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/table.py"", line 1870, in persist; return Env.backend().persist_table(self, storage_level); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/spark_backend.py"", line 285, in persist_table; return Table._from_java(self._jbackend.pyPersistTable(storage_level, self._to_java_table_ir(t._tir))); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py"", line 16, in deco; return f(*args, **kwargs); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py"", line 336, in get_return_value; format(target_id, ""."", name)); py4j.protocol.Py4JError: An error occurred while calling o1.pyPersistTable. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2044, in showtraceback; stb = value._render_traceback_(); AttributeError: 'Py4JError' object has no attribute '_render_traceback_'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 929, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1067, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ----",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:7510,Availability,error,error,7510,"e-packages/hail/backend/spark_backend.py in persist_table(self, t, storage_level); 283 ; 284 def persist_table(self, t, storage_level):; --> 285 return Table._from_java(self._jbackend.pyPersistTable(storage_level, self._to_java_table_ir(t._tir))); 286 ; 287 def unpersist_table(self, t):. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 14 import pyspark; 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:; 18 s = e.java_exception.toString(). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; --> 336 format(target_id, ""."", name)); 337 else:; 338 type = answer[1]. Py4JError: An error occurred while calling o1.pyPersistTable; --------------- end of error -------------------. The above is for running the GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:7638,Availability,error,error,7638,"java(self._jbackend.pyPersistTable(storage_level, self._to_java_table_ir(t._tir))); 286 ; 287 def unpersist_table(self, t):. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 14 import pyspark; 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:; 18 s = e.java_exception.toString(). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; --> 336 format(target_id, ""."", name)); 337 else:; 338 type = answer[1]. Py4JError: An error occurred while calling o1.pyPersistTable; --------------- end of error -------------------. The above is for running the GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:7709,Availability,error,error,7709,"to_java_table_ir(t._tir))); 286 ; 287 def unpersist_table(self, t):. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 14 import pyspark; 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:; 18 s = e.java_exception.toString(). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; --> 336 format(target_id, ""."", name)); 337 else:; 338 type = answer[1]. Py4JError: An error occurred while calling o1.pyPersistTable; --------------- end of error -------------------. The above is for running the GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:7836,Availability,error,error,7836,"ages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 14 import pyspark; 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:; 18 s = e.java_exception.toString(). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; --> 336 format(target_id, ""."", name)); 337 else:; 338 type = answer[1]. Py4JError: An error occurred while calling o1.pyPersistTable; --------------- end of error -------------------. The above is for running the GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (m",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:7984,Availability,error,error,7984,"gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 14 import pyspark; 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:; 18 s = e.java_exception.toString(). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; --> 336 format(target_id, ""."", name)); 337 else:; 338 type = answer[1]. Py4JError: An error occurred while calling o1.pyPersistTable; --------------- end of error -------------------. The above is for running the GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:8038,Availability,error,error,8038,"; 1258 ; 1259 for temp_arg in temp_args:. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 14 import pyspark; 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:; 18 s = e.java_exception.toString(). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; --> 336 format(target_id, ""."", name)); 337 else:; 338 type = answer[1]. Py4JError: An error occurred while calling o1.pyPersistTable; --------------- end of error -------------------. The above is for running the GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:8064,Availability,ERROR,ERROR,8064,"emp_args:. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 14 import pyspark; 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:; 18 s = e.java_exception.toString(). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; --> 336 format(target_id, ""."", name)); 337 else:; 338 type = answer[1]. Py4JError: An error occurred while calling o1.pyPersistTable; --------------- end of error -------------------. The above is for running the GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:8091,Availability,error,error,8091,"ib/python3.6/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 14 import pyspark; 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:; 18 s = e.java_exception.toString(). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; --> 336 format(target_id, ""."", name)); 337 else:; 338 type = answer[1]. Py4JError: An error occurred while calling o1.pyPersistTable; --------------- end of error -------------------. The above is for running the GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceb",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:8712,Availability,ERROR,ERROR,8712," --------------- end of error -------------------. The above is for running the GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:8739,Availability,error,error,8739,"he GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceb",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:9360,Availability,ERROR,ERROR,9360,"n = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:9387,Availability,error,error,9387," the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceb",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:10008,Availability,ERROR,ERROR,10008,"n = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:10035,Availability,error,error,10035," the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceb",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:10656,Availability,ERROR,ERROR,10656,"nect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; --------------- end of error -------------------. Again, it's related to java. Could you please help? Thanks so much!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:10683,Availability,error,error,10683,"nect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; --------------- end of error -------------------. Again, it's related to java. Could you please help? Thanks so much!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:11327,Availability,error,error,11327,"nect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; --------------- end of error -------------------. Again, it's related to java. Could you please help? Thanks so much!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:1304,Integrability,protocol,protocol,1304,"tware products:. Running on Apache Spark version 2.4.5; SparkUI available at http://vhabosgen72:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.61-3c86d3ba497a; LOGGING: writing to /dacs1/team/vhabhsxum/tasks/ancestryPainting/hail-20210125-1235-0.2.61-3c86d3ba497a.log. I am running the GWAS tutorial hosted at https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html#Let's-do-a-GWAS. Everything is OK until the line to do GWAS. The error I have is as follows:. -------------- start of error ------------------; 2021-01-25 12:36:11 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-40-d6d936b012db>"", line 3, in <module>; covariates=[1.0]); File ""<decorator-gen-1697>"", line 2, in linear_regressio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:1806,Integrability,protocol,protocol,1806,"have is as follows:. -------------- start of error ------------------; 2021-01-25 12:36:11 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-40-d6d936b012db>"", line 3, in <module>; covariates=[1.0]); File ""<decorator-gen-1697>"", line 2, in linear_regression_rows; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/methods/statgen.py"", line 370, in linear_regression_rows; return ht_result.persist(); File ""<decorator-gen-1111>"", line 2, in persist; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __origi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:2423,Integrability,wrap,wrapper,2423,":; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-40-d6d936b012db>"", line 3, in <module>; covariates=[1.0]); File ""<decorator-gen-1697>"", line 2, in linear_regression_rows; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/methods/statgen.py"", line 370, in linear_regression_rows; return ht_result.persist(); File ""<decorator-gen-1111>"", line 2, in persist; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/table.py"", line 1870, in persist; return Env.backend().persist_table(self, storage_level); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/spark_backend.py"", line 285, in persist_table; return Table._from_java(self._jbackend.pyPersistTable(storage_level, self._to_java_table_ir(t._tir))); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-pack",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:2788,Integrability,wrap,wrapper,2788,"r: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code; exec(code_obj, self.user_global_ns, self.user_ns); File ""<ipython-input-40-d6d936b012db>"", line 3, in <module>; covariates=[1.0]); File ""<decorator-gen-1697>"", line 2, in linear_regression_rows; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/methods/statgen.py"", line 370, in linear_regression_rows; return ht_result.persist(); File ""<decorator-gen-1111>"", line 2, in persist; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/table.py"", line 1870, in persist; return Env.backend().persist_table(self, storage_level); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/spark_backend.py"", line 285, in persist_table; return Table._from_java(self._jbackend.pyPersistTable(storage_level, self._to_java_table_ir(t._tir))); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py"", line 16, in deco; return f(*args, **kwargs); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py"", line 336, in get_return_value; format(target_id, ""."", name)); py4j.protocol.Py4JError: An error occurred while calling o1.pyPersistTable. During handling of the above exception, another exception oc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:3619,Integrability,protocol,protocol,3619,"t_result.persist(); File ""<decorator-gen-1111>"", line 2, in persist; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/table.py"", line 1870, in persist; return Env.backend().persist_table(self, storage_level); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/spark_backend.py"", line 285, in persist_table; return Table._from_java(self._jbackend.pyPersistTable(storage_level, self._to_java_table_ir(t._tir))); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py"", line 16, in deco; return f(*args, **kwargs); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py"", line 336, in get_return_value; format(target_id, ""."", name)); py4j.protocol.Py4JError: An error occurred while calling o1.pyPersistTable. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2044, in showtraceback; stb = value._render_traceback_(); AttributeError: 'Py4JError' object has no attribute '_render_traceback_'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 929, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1067,",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:3700,Integrability,protocol,protocol,3700,"onda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py"", line 614, in wrapper; return __original_func(*args_, **kwargs_); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/table.py"", line 1870, in persist; return Env.backend().persist_table(self, storage_level); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/spark_backend.py"", line 285, in persist_table; return Table._from_java(self._jbackend.pyPersistTable(storage_level, self._to_java_table_ir(t._tir))); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1257, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py"", line 16, in deco; return f(*args, **kwargs); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py"", line 336, in get_return_value; format(target_id, ""."", name)); py4j.protocol.Py4JError: An error occurred while calling o1.pyPersistTable. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 2044, in showtraceback; stb = value._render_traceback_(); AttributeError: 'Py4JError' object has no attribute '_render_traceback_'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 929, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1067, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 11",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:5221,Integrability,wrap,wrapper,5221," = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1067, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ---------------------------------------------------------------------------; Py4JError Traceback (most recent call last); <ipython-input-40-d6d936b012db> in <module>; 1 gwas = hl.linear_regression_rows(y=mt.pheno.CaffeineConsumption,; 2 x=mt.GT.n_alt_alleles(),; ----> 3 covariates=[1.0]); 4 gwas.row.describe(). <decorator-gen-1697> in linear_regression_rows(y, x, covariates, block_size, pass_through). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 612 def wrapper(__original_func, *args, **kwargs):; 613 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 614 return __original_func(*args_, **kwargs_); 615 ; 616 return wrapper. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/methods/statgen.py in linear_regression_rows(y, x, covariates, block_size, pass_through); 368 ht_result = ht_result.annotate(**{f: ht_result[f][0] for f in fields}); 369 ; --> 370 return ht_result.persist(); 371 ; 372 . <decorator-gen-1111> in persist(self, storage_level). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 612 def wrapper(__original_func, *args, **kwargs):; 613 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 614 return __original_func(*args_, **kwargs_); 615 ; 616 return wrapper. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/table.py in persist(self, storage_level); 1868 Persisted table.; 1869 """"""; -> 1870 return Env.backend().",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:5272,Integrability,wrap,wrapper,5272," = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1067, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ---------------------------------------------------------------------------; Py4JError Traceback (most recent call last); <ipython-input-40-d6d936b012db> in <module>; 1 gwas = hl.linear_regression_rows(y=mt.pheno.CaffeineConsumption,; 2 x=mt.GT.n_alt_alleles(),; ----> 3 covariates=[1.0]); 4 gwas.row.describe(). <decorator-gen-1697> in linear_regression_rows(y, x, covariates, block_size, pass_through). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 612 def wrapper(__original_func, *args, **kwargs):; 613 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 614 return __original_func(*args_, **kwargs_); 615 ; 616 return wrapper. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/methods/statgen.py in linear_regression_rows(y, x, covariates, block_size, pass_through); 368 ht_result = ht_result.annotate(**{f: ht_result[f][0] for f in fields}); 369 ; --> 370 return ht_result.persist(); 371 ; 372 . <decorator-gen-1111> in persist(self, storage_level). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 612 def wrapper(__original_func, *args, **kwargs):; 613 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 614 return __original_func(*args_, **kwargs_); 615 ; 616 return wrapper. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/table.py in persist(self, storage_level); 1868 Persisted table.; 1869 """"""; -> 1870 return Env.backend().",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:5478,Integrability,wrap,wrapper,5478," = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1067, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ---------------------------------------------------------------------------; Py4JError Traceback (most recent call last); <ipython-input-40-d6d936b012db> in <module>; 1 gwas = hl.linear_regression_rows(y=mt.pheno.CaffeineConsumption,; 2 x=mt.GT.n_alt_alleles(),; ----> 3 covariates=[1.0]); 4 gwas.row.describe(). <decorator-gen-1697> in linear_regression_rows(y, x, covariates, block_size, pass_through). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 612 def wrapper(__original_func, *args, **kwargs):; 613 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 614 return __original_func(*args_, **kwargs_); 615 ; 616 return wrapper. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/methods/statgen.py in linear_regression_rows(y, x, covariates, block_size, pass_through); 368 ht_result = ht_result.annotate(**{f: ht_result[f][0] for f in fields}); 369 ; --> 370 return ht_result.persist(); 371 ; 372 . <decorator-gen-1111> in persist(self, storage_level). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 612 def wrapper(__original_func, *args, **kwargs):; 613 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 614 return __original_func(*args_, **kwargs_); 615 ; 616 return wrapper. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/table.py in persist(self, storage_level); 1868 Persisted table.; 1869 """"""; -> 1870 return Env.backend().",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:5915,Integrability,wrap,wrapper,5915,"corator-gen-1697> in linear_regression_rows(y, x, covariates, block_size, pass_through). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 612 def wrapper(__original_func, *args, **kwargs):; 613 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 614 return __original_func(*args_, **kwargs_); 615 ; 616 return wrapper. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/methods/statgen.py in linear_regression_rows(y, x, covariates, block_size, pass_through); 368 ht_result = ht_result.annotate(**{f: ht_result[f][0] for f in fields}); 369 ; --> 370 return ht_result.persist(); 371 ; 372 . <decorator-gen-1111> in persist(self, storage_level). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 612 def wrapper(__original_func, *args, **kwargs):; 613 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 614 return __original_func(*args_, **kwargs_); 615 ; 616 return wrapper. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/table.py in persist(self, storage_level); 1868 Persisted table.; 1869 """"""; -> 1870 return Env.backend().persist_table(self, storage_level); 1871 ; 1872 def unpersist(self) -> 'Table':. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/spark_backend.py in persist_table(self, t, storage_level); 283 ; 284 def persist_table(self, t, storage_level):; --> 285 return Table._from_java(self._jbackend.pyPersistTable(storage_level, self._to_java_table_ir(t._tir))); 286 ; 287 def unpersist_table(self, t):. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:5966,Integrability,wrap,wrapper,5966,"corator-gen-1697> in linear_regression_rows(y, x, covariates, block_size, pass_through). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 612 def wrapper(__original_func, *args, **kwargs):; 613 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 614 return __original_func(*args_, **kwargs_); 615 ; 616 return wrapper. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/methods/statgen.py in linear_regression_rows(y, x, covariates, block_size, pass_through); 368 ht_result = ht_result.annotate(**{f: ht_result[f][0] for f in fields}); 369 ; --> 370 return ht_result.persist(); 371 ; 372 . <decorator-gen-1111> in persist(self, storage_level). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 612 def wrapper(__original_func, *args, **kwargs):; 613 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 614 return __original_func(*args_, **kwargs_); 615 ; 616 return wrapper. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/table.py in persist(self, storage_level); 1868 Persisted table.; 1869 """"""; -> 1870 return Env.backend().persist_table(self, storage_level); 1871 ; 1872 def unpersist(self) -> 'Table':. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/spark_backend.py in persist_table(self, t, storage_level); 283 ; 284 def persist_table(self, t, storage_level):; --> 285 return Table._from_java(self._jbackend.pyPersistTable(storage_level, self._to_java_table_ir(t._tir))); 286 ; 287 def unpersist_table(self, t):. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:6172,Integrability,wrap,wrapper,6172,"corator-gen-1697> in linear_regression_rows(y, x, covariates, block_size, pass_through). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 612 def wrapper(__original_func, *args, **kwargs):; 613 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 614 return __original_func(*args_, **kwargs_); 615 ; 616 return wrapper. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/methods/statgen.py in linear_regression_rows(y, x, covariates, block_size, pass_through); 368 ht_result = ht_result.annotate(**{f: ht_result[f][0] for f in fields}); 369 ; --> 370 return ht_result.persist(); 371 ; 372 . <decorator-gen-1111> in persist(self, storage_level). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 612 def wrapper(__original_func, *args, **kwargs):; 613 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 614 return __original_func(*args_, **kwargs_); 615 ; 616 return wrapper. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/table.py in persist(self, storage_level); 1868 Persisted table.; 1869 """"""; -> 1870 return Env.backend().persist_table(self, storage_level); 1871 ; 1872 def unpersist(self) -> 'Table':. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/spark_backend.py in persist_table(self, t, storage_level); 283 ; 284 def persist_table(self, t, storage_level):; --> 285 return Table._from_java(self._jbackend.pyPersistTable(storage_level, self._to_java_table_ir(t._tir))); 286 ; 287 def unpersist_table(self, t):. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:7274,Integrability,protocol,protocol,7274,"ge_level); 1868 Persisted table.; 1869 """"""; -> 1870 return Env.backend().persist_table(self, storage_level); 1871 ; 1872 def unpersist(self) -> 'Table':. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/spark_backend.py in persist_table(self, t, storage_level); 283 ; 284 def persist_table(self, t, storage_level):; --> 285 return Table._from_java(self._jbackend.pyPersistTable(storage_level, self._to_java_table_ir(t._tir))); 286 ; 287 def unpersist_table(self, t):. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 14 import pyspark; 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:; 18 s = e.java_exception.toString(). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; --> 336 format(target_id, ""."", name)); 337 else:; 338 type = answer[1]. Py4JError: An error occurred while calling o1.pyPersistTable; --------------- end of error -------------------. The above is for running the GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/jav",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:7406,Integrability,protocol,protocol,7406,"ef unpersist(self) -> 'Table':. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/spark_backend.py in persist_table(self, t, storage_level); 283 ; 284 def persist_table(self, t, storage_level):; --> 285 return Table._from_java(self._jbackend.pyPersistTable(storage_level, self._to_java_table_ir(t._tir))); 286 ; 287 def unpersist_table(self, t):. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py in __call__(self, *args); 1255 answer = self.gateway_client.send_command(command); 1256 return_value = get_return_value(; -> 1257 answer, self.gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 14 import pyspark; 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:; 18 s = e.java_exception.toString(). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; --> 336 format(target_id, ""."", name)); 337 else:; 338 type = answer[1]. Py4JError: An error occurred while calling o1.pyPersistTable; --------------- end of error -------------------. The above is for running the GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:7990,Integrability,message,message,7990,"gateway_client, self.target_id, self.name); 1258 ; 1259 for temp_arg in temp_args:. /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/hail/backend/py4j_backend.py in deco(*args, **kwargs); 14 import pyspark; 15 try:; ---> 16 return f(*args, **kwargs); 17 except py4j.protocol.Py4JJavaError as e:; 18 s = e.java_exception.toString(). /fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/protocol.py in get_return_value(answer, gateway_client, target_id, name); 334 raise Py4JError(; 335 ""An error occurred while calling {0}{1}{2}"".; --> 336 format(target_id, ""."", name)); 337 else:; 338 type = answer[1]. Py4JError: An error occurred while calling o1.pyPersistTable; --------------- end of error -------------------. The above is for running the GWAS tutorial. While running my own GWAS, I have encountered a similar error when running GWAS with the line :. gwas = hl.agg.linreg(hl.float(mt.phenos.height),; [1.0, mt.hapcounts0.x, mt.anc1dos.x, mt.anc2dos.x]). The error message is as follows:. -------------- start of error ------------------. ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.pop(); IndexError: pop from an empty deque. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1115, in start; self.socket.connect((self.address, self.port)); ConnectionRefusedError: [Errno 111] Connection refused; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:38197); Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 977, in _get_connection; connection = self.deque.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:975,Modifiability,variab,variable,975,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------; Versions of software products:. Running on Apache Spark version 2.4.5; SparkUI available at http://vhabosgen72:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.61-3c86d3ba497a; LOGGING: writing to /dacs1/team/vhabhsxum/tasks/ancestryPainting/hail-20210125-1235-0.2.61-3c86d3ba497a.log. I am running the GWAS tutorial hosted at https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html#Let's-do-a-GWAS. Everything is OK until the line to do GWAS. The error I have is as follows:. -------------- start of error ------------------; 2021-01-25 12:36:11 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:999,Modifiability,variab,variable,999,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------; Versions of software products:. Running on Apache Spark version 2.4.5; SparkUI available at http://vhabosgen72:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.61-3c86d3ba497a; LOGGING: writing to /dacs1/team/vhabhsxum/tasks/ancestryPainting/hail-20210125-1235-0.2.61-3c86d3ba497a.log. I am running the GWAS tutorial hosted at https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html#Let's-do-a-GWAS. Everything is OK until the line to do GWAS. The error I have is as follows:. -------------- start of error ------------------; 2021-01-25 12:36:11 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:514,Testability,LOG,LOGGING,514,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------; Versions of software products:. Running on Apache Spark version 2.4.5; SparkUI available at http://vhabosgen72:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.61-3c86d3ba497a; LOGGING: writing to /dacs1/team/vhabhsxum/tasks/ancestryPainting/hail-20210125-1235-0.2.61-3c86d3ba497a.log. I am running the GWAS tutorial hosted at https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html#Let's-do-a-GWAS. Everything is OK until the line to do GWAS. The error I have is as follows:. -------------- start of error ------------------; 2021-01-25 12:36:11 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/issues/9939:618,Testability,log,log,618,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------; Versions of software products:. Running on Apache Spark version 2.4.5; SparkUI available at http://vhabosgen72:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.61-3c86d3ba497a; LOGGING: writing to /dacs1/team/vhabhsxum/tasks/ancestryPainting/hail-20210125-1235-0.2.61-3c86d3ba497a.log. I am running the GWAS tutorial hosted at https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html#Let's-do-a-GWAS. Everything is OK until the line to do GWAS. The error I have is as follows:. -------------- start of error ------------------; 2021-01-25 12:36:11 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/9939
https://github.com/hail-is/hail/pull/9941:80,Availability,error,error,80,"FYI @danking . I wasn't sure if removing a previously deleted user should be an error. I think it should be, but I left it as idempotent for now.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9941
https://github.com/hail-is/hail/pull/9942:16,Availability,failure,failure,16,I'm seeing a PR failure that I can't debug further without the status information.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9942
https://github.com/hail-is/hail/pull/9943:43,Deployability,release,releases,43,"The site container polls regularly for new releases of hail and pulls the docs for the latest release. But we deploy site regularly enough that we can just include the latest release docs in the site build. Eventually, a deploy to PyPi should trigger a deploy of the site but this gets us part of the way there and simplifies things considerably.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9943
https://github.com/hail-is/hail/pull/9943:94,Deployability,release,release,94,"The site container polls regularly for new releases of hail and pulls the docs for the latest release. But we deploy site regularly enough that we can just include the latest release docs in the site build. Eventually, a deploy to PyPi should trigger a deploy of the site but this gets us part of the way there and simplifies things considerably.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9943
https://github.com/hail-is/hail/pull/9943:110,Deployability,deploy,deploy,110,"The site container polls regularly for new releases of hail and pulls the docs for the latest release. But we deploy site regularly enough that we can just include the latest release docs in the site build. Eventually, a deploy to PyPi should trigger a deploy of the site but this gets us part of the way there and simplifies things considerably.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9943
https://github.com/hail-is/hail/pull/9943:175,Deployability,release,release,175,"The site container polls regularly for new releases of hail and pulls the docs for the latest release. But we deploy site regularly enough that we can just include the latest release docs in the site build. Eventually, a deploy to PyPi should trigger a deploy of the site but this gets us part of the way there and simplifies things considerably.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9943
https://github.com/hail-is/hail/pull/9943:221,Deployability,deploy,deploy,221,"The site container polls regularly for new releases of hail and pulls the docs for the latest release. But we deploy site regularly enough that we can just include the latest release docs in the site build. Eventually, a deploy to PyPi should trigger a deploy of the site but this gets us part of the way there and simplifies things considerably.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9943
https://github.com/hail-is/hail/pull/9943:253,Deployability,deploy,deploy,253,"The site container polls regularly for new releases of hail and pulls the docs for the latest release. But we deploy site regularly enough that we can just include the latest release docs in the site build. Eventually, a deploy to PyPi should trigger a deploy of the site but this gets us part of the way there and simplifies things considerably.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9943
https://github.com/hail-is/hail/pull/9943:315,Usability,simpl,simplifies,315,"The site container polls regularly for new releases of hail and pulls the docs for the latest release. But we deploy site regularly enough that we can just include the latest release docs in the site build. Eventually, a deploy to PyPi should trigger a deploy of the site but this gets us part of the way there and simplifies things considerably.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9943
https://github.com/hail-is/hail/pull/9944:943,Availability,error,errors,943,"This ended up being a great lesson in `asyncio`!. `kubernetes_asyncio` has a deeply hidden `asyncio.ClientSession` that doesn't get properly closed when we restart services with `SIGINT`. Turns out the `__del__` method on the `RESTClient` deep inside the library that holds this client session sets up a future with asyncio to close the session, but I suspect that this object is getting deleted _after_ the event loop closes. As a result we get a bunch of garbage in the logs that; - the event loop is already closed when something is trying to happen; - a `ClientSession.close` was never properly awaited. I initially tried to explicitly close the client session but still dealt with the problem that the `k8s_client` was trying to interact with the even loop after it closed. Explicitly deleting the `k8s_client` on cleanup and then awaiting any remaining futures (so the client session `close`) appears to fix the problem as I get no more errors on shutdown, but let me know if this isn't kosher. If this is alright I'll see this through to the rest of the services.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9944
https://github.com/hail-is/hail/pull/9944:472,Testability,log,logs,472,"This ended up being a great lesson in `asyncio`!. `kubernetes_asyncio` has a deeply hidden `asyncio.ClientSession` that doesn't get properly closed when we restart services with `SIGINT`. Turns out the `__del__` method on the `RESTClient` deep inside the library that holds this client session sets up a future with asyncio to close the session, but I suspect that this object is getting deleted _after_ the event loop closes. As a result we get a bunch of garbage in the logs that; - the event loop is already closed when something is trying to happen; - a `ClientSession.close` was never properly awaited. I initially tried to explicitly close the client session but still dealt with the problem that the `k8s_client` was trying to interact with the even loop after it closed. Explicitly deleting the `k8s_client` on cleanup and then awaiting any remaining futures (so the client session `close`) appears to fix the problem as I get no more errors on shutdown, but let me know if this isn't kosher. If this is alright I'll see this through to the rest of the services.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9944
https://github.com/hail-is/hail/pull/9945:143,Availability,failure,failure,143,`-x` logs each line of `start-nginx.sh` that runs and I don't expect anything in here to fail / the code itself to provide useful context in a failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9945
https://github.com/hail-is/hail/pull/9945:5,Testability,log,logs,5,`-x` logs each line of `start-nginx.sh` that runs and I don't expect anything in here to fail / the code itself to provide useful context in a failure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9945
https://github.com/hail-is/hail/pull/9946:137,Deployability,patch,patch,137,"I have diagnosed the root cause of the issue observed by; both Patrick and Chris: incorrect spilling of method parameter variables. This patch makes the bug impossible to replicate using proper interfaces,; though does not fix the underlying issue in LIR. Here's a way to replicate:. ```; val mb = kb.genEmitMethod(""btree_foo"", FastIndexedSeq[ParamType](typeInfo[Long]), typeInfo[Unit]); mb.voidWithBuilder { cb =>; val arg = mb.getCodeParam[Long](1).asInstanceOf[Settable[Long]]. cb.assign(arg, arg + 1L). (0 until 100).foreach { i =>; cb.println(s""i=$i, arg="", arg.toS); }. }; cb.invokeVoid(mb,const( 0L)); ```. called with `0`, this prints `1` until i=84, then starts printing 0 again.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9946
https://github.com/hail-is/hail/pull/9946:194,Integrability,interface,interfaces,194,"I have diagnosed the root cause of the issue observed by; both Patrick and Chris: incorrect spilling of method parameter variables. This patch makes the bug impossible to replicate using proper interfaces,; though does not fix the underlying issue in LIR. Here's a way to replicate:. ```; val mb = kb.genEmitMethod(""btree_foo"", FastIndexedSeq[ParamType](typeInfo[Long]), typeInfo[Unit]); mb.voidWithBuilder { cb =>; val arg = mb.getCodeParam[Long](1).asInstanceOf[Settable[Long]]. cb.assign(arg, arg + 1L). (0 until 100).foreach { i =>; cb.println(s""i=$i, arg="", arg.toS); }. }; cb.invokeVoid(mb,const( 0L)); ```. called with `0`, this prints `1` until i=84, then starts printing 0 again.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9946
https://github.com/hail-is/hail/pull/9946:121,Modifiability,variab,variables,121,"I have diagnosed the root cause of the issue observed by; both Patrick and Chris: incorrect spilling of method parameter variables. This patch makes the bug impossible to replicate using proper interfaces,; though does not fix the underlying issue in LIR. Here's a way to replicate:. ```; val mb = kb.genEmitMethod(""btree_foo"", FastIndexedSeq[ParamType](typeInfo[Long]), typeInfo[Unit]); mb.voidWithBuilder { cb =>; val arg = mb.getCodeParam[Long](1).asInstanceOf[Settable[Long]]. cb.assign(arg, arg + 1L). (0 until 100).foreach { i =>; cb.println(s""i=$i, arg="", arg.toS); }. }; cb.invokeVoid(mb,const( 0L)); ```. called with `0`, this prints `1` until i=84, then starts printing 0 again.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9946
https://github.com/hail-is/hail/pull/9947:59,Modifiability,variab,variable,59,The match on method identity caused mismatches between the variable; stored in loaded across splits.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9947
https://github.com/hail-is/hail/pull/9947:79,Performance,load,loaded,79,The match on method identity caused mismatches between the variable; stored in loaded across splits.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9947
https://github.com/hail-is/hail/pull/9949:32,Availability,error,error,32,Think this should resolve this [error](https://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Aresource.labels.namespace_name%3D%22default%22%0Aresource.labels.container_name%3D%22auth-driver%22%0Aseverity%3DERROR;timeRange=PT3H?authuser=2&project=hail-vdc) where `auth-driver` is crashing on start,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9949
https://github.com/hail-is/hail/pull/9949:72,Testability,log,logs,72,Think this should resolve this [error](https://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Aresource.labels.namespace_name%3D%22default%22%0Aresource.labels.container_name%3D%22auth-driver%22%0Aseverity%3DERROR;timeRange=PT3H?authuser=2&project=hail-vdc) where `auth-driver` is crashing on start,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9949
https://github.com/hail-is/hail/pull/9951:59,Usability,simpl,simpler,59,This makes the interaction with other infrastructure a bit simpler.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9951
https://github.com/hail-is/hail/pull/9953:347,Usability,clear,clear,347,"Add information from https://discuss.hail.is/t/export-elasticsearch-function-documentation-for-updating-behavior/1899 to `export_elasticsearch` docs. This happens fairly often with preemptible Dataproc workers and has caused us some confusion in the past with the gnomAD browser. Without some understanding of how Hail works, it's not immediately clear why this happens.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9953
https://github.com/hail-is/hail/pull/9954:105,Integrability,rout,route,105,There might be an opportunity to also push NOT DELETED into the decorator as well. I chose the decorator route because it's cleaner and I expect a more complicated query for checking permissions in the future.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9954
https://github.com/hail-is/hail/pull/9955:73,Availability,avail,available,73,"To make existing gnomAD datasets (already in HailTable/MatrixTable form) available via `load_dataset`:; - For v2 now includes multinucleotide variants (MNVs), proportion expressed across transcript (pext), and linkage disequilibrium (LD); - For v3 now includes mitochondrial DNA (mtDNA). The `load_dataset` function now can open a `BlockMatrix` as well, so the gnomAD v2 LD matrices are available through the datasets API in addition to the tables. Also added try/except blocks to `load_datasets`, to handle errors. For example the `gnomad_annotation_pext` dataset has a url of `gs://gcp-public-data--gnomad/papers/2019-tx-annotation/pre_computed/all.possible.snvs.tx_annotated.021520.ht`, but this is actually a `MatrixTable`. So now when trying to open a `HailTable`, it will try to open as a `MatrixTable` if an error is encountered (and vice versa).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9955
https://github.com/hail-is/hail/pull/9955:387,Availability,avail,available,387,"To make existing gnomAD datasets (already in HailTable/MatrixTable form) available via `load_dataset`:; - For v2 now includes multinucleotide variants (MNVs), proportion expressed across transcript (pext), and linkage disequilibrium (LD); - For v3 now includes mitochondrial DNA (mtDNA). The `load_dataset` function now can open a `BlockMatrix` as well, so the gnomAD v2 LD matrices are available through the datasets API in addition to the tables. Also added try/except blocks to `load_datasets`, to handle errors. For example the `gnomad_annotation_pext` dataset has a url of `gs://gcp-public-data--gnomad/papers/2019-tx-annotation/pre_computed/all.possible.snvs.tx_annotated.021520.ht`, but this is actually a `MatrixTable`. So now when trying to open a `HailTable`, it will try to open as a `MatrixTable` if an error is encountered (and vice versa).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9955
https://github.com/hail-is/hail/pull/9955:508,Availability,error,errors,508,"To make existing gnomAD datasets (already in HailTable/MatrixTable form) available via `load_dataset`:; - For v2 now includes multinucleotide variants (MNVs), proportion expressed across transcript (pext), and linkage disequilibrium (LD); - For v3 now includes mitochondrial DNA (mtDNA). The `load_dataset` function now can open a `BlockMatrix` as well, so the gnomAD v2 LD matrices are available through the datasets API in addition to the tables. Also added try/except blocks to `load_datasets`, to handle errors. For example the `gnomad_annotation_pext` dataset has a url of `gs://gcp-public-data--gnomad/papers/2019-tx-annotation/pre_computed/all.possible.snvs.tx_annotated.021520.ht`, but this is actually a `MatrixTable`. So now when trying to open a `HailTable`, it will try to open as a `MatrixTable` if an error is encountered (and vice versa).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9955
https://github.com/hail-is/hail/pull/9955:815,Availability,error,error,815,"To make existing gnomAD datasets (already in HailTable/MatrixTable form) available via `load_dataset`:; - For v2 now includes multinucleotide variants (MNVs), proportion expressed across transcript (pext), and linkage disequilibrium (LD); - For v3 now includes mitochondrial DNA (mtDNA). The `load_dataset` function now can open a `BlockMatrix` as well, so the gnomAD v2 LD matrices are available through the datasets API in addition to the tables. Also added try/except blocks to `load_datasets`, to handle errors. For example the `gnomad_annotation_pext` dataset has a url of `gs://gcp-public-data--gnomad/papers/2019-tx-annotation/pre_computed/all.possible.snvs.tx_annotated.021520.ht`, but this is actually a `MatrixTable`. So now when trying to open a `HailTable`, it will try to open as a `MatrixTable` if an error is encountered (and vice versa).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9955
https://github.com/hail-is/hail/pull/9960:140,Integrability,interface,interface,140,"* construct doesn't take structs, takes IndexedSeq[Value[Long]]; * Implement the nested loops in one place; * Delete some methods from type interface, insert PCanonical casts",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9960
https://github.com/hail-is/hail/pull/9963:129,Availability,error,errors,129,"The IP address we got from `address` might be the IP of a pod that has been removed. When this happens; we get connection failed errors, which we treat as ""transient"". This change modifies the test to also; get a new IP address each time a transient error occurs. Not ideal, but more correct than previously.; There are forthcoming changes that I hope will more pervasively address this problem.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9963
https://github.com/hail-is/hail/pull/9963:250,Availability,error,error,250,"The IP address we got from `address` might be the IP of a pod that has been removed. When this happens; we get connection failed errors, which we treat as ""transient"". This change modifies the test to also; get a new IP address each time a transient error occurs. Not ideal, but more correct than previously.; There are forthcoming changes that I hope will more pervasively address this problem.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9963
https://github.com/hail-is/hail/pull/9963:193,Testability,test,test,193,"The IP address we got from `address` might be the IP of a pod that has been removed. When this happens; we get connection failed errors, which we treat as ""transient"". This change modifies the test to also; get a new IP address each time a transient error occurs. Not ideal, but more correct than previously.; There are forthcoming changes that I hope will more pervasively address this problem.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9963
https://github.com/hail-is/hail/pull/9970:97,Testability,Test,Testing,97,Nested another section layer under `Implementation` so now there is `Environment / Tooling` and `Testing / Debugging` with space in both to outline shared steps and then compiler & services-specific steps,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9970
https://github.com/hail-is/hail/pull/9971:318,Availability,mainten,maintenance,318,"Installing certbot is hard so I stopped doing that. Instead, I use the cerbot docker image. I also eliminated `sed` use in the letsencrypt directory. We now maintain the options-ssl-nginx.conf file ourselves. I copied the settings from certbot; GitHub. They're straightforward, as a part of regular package versioning maintenance we should also; reconsider our cipher suites and TLS versions. We now have a `make run DRY_RUN=true` option which can be run repeatedly without affecting the default certs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9971
https://github.com/hail-is/hail/pull/9971:0,Deployability,Install,Installing,0,"Installing certbot is hard so I stopped doing that. Instead, I use the cerbot docker image. I also eliminated `sed` use in the letsencrypt directory. We now maintain the options-ssl-nginx.conf file ourselves. I copied the settings from certbot; GitHub. They're straightforward, as a part of regular package versioning maintenance we should also; reconsider our cipher suites and TLS versions. We now have a `make run DRY_RUN=true` option which can be run repeatedly without affecting the default certs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9971
https://github.com/hail-is/hail/pull/9972:76,Deployability,configurat,configuration,76,"**User-facing Changes:**; - Added preemptible and machine_type to resources configuration in addition to existing worker_type (will get removed at some point in the future).; - machine_type and preemptible are hidden options in hailtop.batch (I put them in for testing purposes); - Can only specify one of worker_type and machine_type; - Preemptible is only valid for machine_type; - If you specify the machine_type, your storage gets rounded up to the nearest Gi with 10 Gi being the minimum (this is because we use a persistent-SSD as the worker data disk and the min for this is 10 Gi. **Billing Changes:**; - The list of possible machine types we currently support is in the globals -- we only support the n1 family. I insert new resource rates into the Resources SQL table to account for the new nonpreemptible resources.; - If you have a job private instance, you are billed for that instance at the time of the instance's creation (not when it's activated). This is done by modifying the trigger for the attempts table to take the minimum attempt start time rather than the maximum. I'm not sure why we needed the maximum to begin with as the attempt start time was always the same. This is probably a place to double check before merging. **Job State Changes:**; - We now support a new state ""Creating"" which represents an instance has been spun up for a job, but it has not been activated yet; - The SQL user resources table and cancellable resources table needed to be changed to add the n_creating_jobs, n_cancellable_creating_jobs, and the n_cancelled_creating_jobs; - Added a new SQL function `mark_job_creating` that is only called by the job private instance creator.; - A lot of the existing SQL functions had to change to account for the fact that an instance in the pending state can have job-specific operations done such as mark_job_complete if the job is cancelled. In addition, the ""Creating"" state is like ""Running"" for some operations in that an attempt has been created and ac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9972
https://github.com/hail-is/hail/pull/9972:2180,Deployability,configurat,configuration,2180,"aximum to begin with as the attempt start time was always the same. This is probably a place to double check before merging. **Job State Changes:**; - We now support a new state ""Creating"" which represents an instance has been spun up for a job, but it has not been activated yet; - The SQL user resources table and cancellable resources table needed to be changed to add the n_creating_jobs, n_cancellable_creating_jobs, and the n_cancelled_creating_jobs; - Added a new SQL function `mark_job_creating` that is only called by the job private instance creator.; - A lot of the existing SQL functions had to change to account for the fact that an instance in the pending state can have job-specific operations done such as mark_job_complete if the job is cancelled. In addition, the ""Creating"" state is like ""Running"" for some operations in that an attempt has been created and actions are happening on behalf of the user. **Driver Changes:**; - New cancel_creating_jobs event; - Two separate methods to get the pools or job private UI pages and two separate configuration methods. One each for pool and job-private. **JobPrivateInstanceCollection:**; - Has two new loops: an instance creation loop and a scheduling loop; - The instance creation loop does a fair share calculation that is almost identical to the pool one except the resource being allocated is n_ready_jobs compared to total_jobs rather than ready_cores_mcpu. ; - The instance creation loop needs to extract the machine_type, storage_gib, and preemptible from the spec without hitting GCS. Therefore, it is stored in the ""spec"" field in the database which required changing the batch format version a bit.; - We avoid double scheduling by requiring that there are no live instances assigned to attempts for that job before creating an instance.; - We mark a job as creating after creating the instance for the new attempt; - The number of instances that can be created is similar to the pool control loop. The total number of instances",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9972
https://github.com/hail-is/hail/pull/9972:4642,Deployability,deploy,deploy,4642," can be created is similar to the pool control loop. The total number of instances we can create is fed to the fair share allocator.; - I added an asyncio.wait(15) at the end of the instance creation loop body to make sure we didn't run past our GCE limits.; - The scheduling loop iterates over all attempts with active instances in order of time of activation (no user fair share here -- FIFO); - There is no possibility of double scheduling because there must only be one active instance per job based on the create instances loop. **Canceller:**; - There's a new canceller loop that looks for jobs that need to be cancelled in the creating state. It marks these jobs as complete ""cancelled"" in the database and then calls GCE to delete the instance. **Mark Job Complete:**; - I modified this function to kill a job private instance if the job is marked as complete and the instance is active. **Worker:**; - I added a kill function; - Note: I did not change how storage is computed. For job private instances, it's possible to be billed for 10Gi but only get 5 Gi if you requested 5 Gi in the XFS quotas. I decided that thinking through the storage here can be delayed until the storage PR since no one is going to be using this functionality yet. **Testing:**; - I added three new job private instance tests: preemptible, non preemptible, preemptible with cancellation in the creating state; - I also added the creating state to the check_incremental background test.; - I ran a chaos script and made sure everything was working with regards to cancellation.; - I looked at the UI pages in my dev deploy and made sure they were working. **Other:**; - The free cores for an instance is set to 0 at the time of instance creation. I wanted this behavior because we're billing for that time and the job has been allocated to that instance. So the free cores should be 0. It might be confusing. I also think of free cores as a resource we're wasting where as in this case, we're not wasting resources.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9972
https://github.com/hail-is/hail/pull/9972:2326,Energy Efficiency,schedul,scheduling,2326,"vated yet; - The SQL user resources table and cancellable resources table needed to be changed to add the n_creating_jobs, n_cancellable_creating_jobs, and the n_cancelled_creating_jobs; - Added a new SQL function `mark_job_creating` that is only called by the job private instance creator.; - A lot of the existing SQL functions had to change to account for the fact that an instance in the pending state can have job-specific operations done such as mark_job_complete if the job is cancelled. In addition, the ""Creating"" state is like ""Running"" for some operations in that an attempt has been created and actions are happening on behalf of the user. **Driver Changes:**; - New cancel_creating_jobs event; - Two separate methods to get the pools or job private UI pages and two separate configuration methods. One each for pool and job-private. **JobPrivateInstanceCollection:**; - Has two new loops: an instance creation loop and a scheduling loop; - The instance creation loop does a fair share calculation that is almost identical to the pool one except the resource being allocated is n_ready_jobs compared to total_jobs rather than ready_cores_mcpu. ; - The instance creation loop needs to extract the machine_type, storage_gib, and preemptible from the spec without hitting GCS. Therefore, it is stored in the ""spec"" field in the database which required changing the batch format version a bit.; - We avoid double scheduling by requiring that there are no live instances assigned to attempts for that job before creating an instance.; - We mark a job as creating after creating the instance for the new attempt; - The number of instances that can be created is similar to the pool control loop. The total number of instances we can create is fed to the fair share allocator.; - I added an asyncio.wait(15) at the end of the instance creation loop body to make sure we didn't run past our GCE limits.; - The scheduling loop iterates over all attempts with active instances in order of time of a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9972
https://github.com/hail-is/hail/pull/9972:2469,Energy Efficiency,allocate,allocated,2469,"vated yet; - The SQL user resources table and cancellable resources table needed to be changed to add the n_creating_jobs, n_cancellable_creating_jobs, and the n_cancelled_creating_jobs; - Added a new SQL function `mark_job_creating` that is only called by the job private instance creator.; - A lot of the existing SQL functions had to change to account for the fact that an instance in the pending state can have job-specific operations done such as mark_job_complete if the job is cancelled. In addition, the ""Creating"" state is like ""Running"" for some operations in that an attempt has been created and actions are happening on behalf of the user. **Driver Changes:**; - New cancel_creating_jobs event; - Two separate methods to get the pools or job private UI pages and two separate configuration methods. One each for pool and job-private. **JobPrivateInstanceCollection:**; - Has two new loops: an instance creation loop and a scheduling loop; - The instance creation loop does a fair share calculation that is almost identical to the pool one except the resource being allocated is n_ready_jobs compared to total_jobs rather than ready_cores_mcpu. ; - The instance creation loop needs to extract the machine_type, storage_gib, and preemptible from the spec without hitting GCS. Therefore, it is stored in the ""spec"" field in the database which required changing the batch format version a bit.; - We avoid double scheduling by requiring that there are no live instances assigned to attempts for that job before creating an instance.; - We mark a job as creating after creating the instance for the new attempt; - The number of instances that can be created is similar to the pool control loop. The total number of instances we can create is fed to the fair share allocator.; - I added an asyncio.wait(15) at the end of the instance creation loop body to make sure we didn't run past our GCE limits.; - The scheduling loop iterates over all attempts with active instances in order of time of a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9972
https://github.com/hail-is/hail/pull/9972:2813,Energy Efficiency,schedul,scheduling,2813,"if the job is cancelled. In addition, the ""Creating"" state is like ""Running"" for some operations in that an attempt has been created and actions are happening on behalf of the user. **Driver Changes:**; - New cancel_creating_jobs event; - Two separate methods to get the pools or job private UI pages and two separate configuration methods. One each for pool and job-private. **JobPrivateInstanceCollection:**; - Has two new loops: an instance creation loop and a scheduling loop; - The instance creation loop does a fair share calculation that is almost identical to the pool one except the resource being allocated is n_ready_jobs compared to total_jobs rather than ready_cores_mcpu. ; - The instance creation loop needs to extract the machine_type, storage_gib, and preemptible from the spec without hitting GCS. Therefore, it is stored in the ""spec"" field in the database which required changing the batch format version a bit.; - We avoid double scheduling by requiring that there are no live instances assigned to attempts for that job before creating an instance.; - We mark a job as creating after creating the instance for the new attempt; - The number of instances that can be created is similar to the pool control loop. The total number of instances we can create is fed to the fair share allocator.; - I added an asyncio.wait(15) at the end of the instance creation loop body to make sure we didn't run past our GCE limits.; - The scheduling loop iterates over all attempts with active instances in order of time of activation (no user fair share here -- FIFO); - There is no possibility of double scheduling because there must only be one active instance per job based on the create instances loop. **Canceller:**; - There's a new canceller loop that looks for jobs that need to be cancelled in the creating state. It marks these jobs as complete ""cancelled"" in the database and then calls GCE to delete the instance. **Mark Job Complete:**; - I modified this function to kill a job priv",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9972
https://github.com/hail-is/hail/pull/9972:3306,Energy Efficiency,schedul,scheduling,3306,"ol one except the resource being allocated is n_ready_jobs compared to total_jobs rather than ready_cores_mcpu. ; - The instance creation loop needs to extract the machine_type, storage_gib, and preemptible from the spec without hitting GCS. Therefore, it is stored in the ""spec"" field in the database which required changing the batch format version a bit.; - We avoid double scheduling by requiring that there are no live instances assigned to attempts for that job before creating an instance.; - We mark a job as creating after creating the instance for the new attempt; - The number of instances that can be created is similar to the pool control loop. The total number of instances we can create is fed to the fair share allocator.; - I added an asyncio.wait(15) at the end of the instance creation loop body to make sure we didn't run past our GCE limits.; - The scheduling loop iterates over all attempts with active instances in order of time of activation (no user fair share here -- FIFO); - There is no possibility of double scheduling because there must only be one active instance per job based on the create instances loop. **Canceller:**; - There's a new canceller loop that looks for jobs that need to be cancelled in the creating state. It marks these jobs as complete ""cancelled"" in the database and then calls GCE to delete the instance. **Mark Job Complete:**; - I modified this function to kill a job private instance if the job is marked as complete and the instance is active. **Worker:**; - I added a kill function; - Note: I did not change how storage is computed. For job private instances, it's possible to be billed for 10Gi but only get 5 Gi if you requested 5 Gi in the XFS quotas. I decided that thinking through the storage here can be delayed until the storage PR since no one is going to be using this functionality yet. **Testing:**; - I added three new job private instance tests: preemptible, non preemptible, preemptible with cancellation in the creating state;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9972
https://github.com/hail-is/hail/pull/9972:3473,Energy Efficiency,schedul,scheduling,3473,"ol one except the resource being allocated is n_ready_jobs compared to total_jobs rather than ready_cores_mcpu. ; - The instance creation loop needs to extract the machine_type, storage_gib, and preemptible from the spec without hitting GCS. Therefore, it is stored in the ""spec"" field in the database which required changing the batch format version a bit.; - We avoid double scheduling by requiring that there are no live instances assigned to attempts for that job before creating an instance.; - We mark a job as creating after creating the instance for the new attempt; - The number of instances that can be created is similar to the pool control loop. The total number of instances we can create is fed to the fair share allocator.; - I added an asyncio.wait(15) at the end of the instance creation loop body to make sure we didn't run past our GCE limits.; - The scheduling loop iterates over all attempts with active instances in order of time of activation (no user fair share here -- FIFO); - There is no possibility of double scheduling because there must only be one active instance per job based on the create instances loop. **Canceller:**; - There's a new canceller loop that looks for jobs that need to be cancelled in the creating state. It marks these jobs as complete ""cancelled"" in the database and then calls GCE to delete the instance. **Mark Job Complete:**; - I modified this function to kill a job private instance if the job is marked as complete and the instance is active. **Worker:**; - I added a kill function; - Note: I did not change how storage is computed. For job private instances, it's possible to be billed for 10Gi but only get 5 Gi if you requested 5 Gi in the XFS quotas. I decided that thinking through the storage here can be delayed until the storage PR since no one is going to be using this functionality yet. **Testing:**; - I added three new job private instance tests: preemptible, non preemptible, preemptible with cancellation in the creating state;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9972
https://github.com/hail-is/hail/pull/9972:4853,Energy Efficiency,allocate,allocated,4853," can be created is similar to the pool control loop. The total number of instances we can create is fed to the fair share allocator.; - I added an asyncio.wait(15) at the end of the instance creation loop body to make sure we didn't run past our GCE limits.; - The scheduling loop iterates over all attempts with active instances in order of time of activation (no user fair share here -- FIFO); - There is no possibility of double scheduling because there must only be one active instance per job based on the create instances loop. **Canceller:**; - There's a new canceller loop that looks for jobs that need to be cancelled in the creating state. It marks these jobs as complete ""cancelled"" in the database and then calls GCE to delete the instance. **Mark Job Complete:**; - I modified this function to kill a job private instance if the job is marked as complete and the instance is active. **Worker:**; - I added a kill function; - Note: I did not change how storage is computed. For job private instances, it's possible to be billed for 10Gi but only get 5 Gi if you requested 5 Gi in the XFS quotas. I decided that thinking through the storage here can be delayed until the storage PR since no one is going to be using this functionality yet. **Testing:**; - I added three new job private instance tests: preemptible, non preemptible, preemptible with cancellation in the creating state; - I also added the creating state to the check_incremental background test.; - I ran a chaos script and made sure everything was working with regards to cancellation.; - I looked at the UI pages in my dev deploy and made sure they were working. **Other:**; - The free cores for an instance is set to 0 at the time of instance creation. I wanted this behavior because we're billing for that time and the job has been allocated to that instance. So the free cores should be 0. It might be confusing. I also think of free cores as a resource we're wasting where as in this case, we're not wasting resources.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9972
https://github.com/hail-is/hail/pull/9972:76,Modifiability,config,configuration,76,"**User-facing Changes:**; - Added preemptible and machine_type to resources configuration in addition to existing worker_type (will get removed at some point in the future).; - machine_type and preemptible are hidden options in hailtop.batch (I put them in for testing purposes); - Can only specify one of worker_type and machine_type; - Preemptible is only valid for machine_type; - If you specify the machine_type, your storage gets rounded up to the nearest Gi with 10 Gi being the minimum (this is because we use a persistent-SSD as the worker data disk and the min for this is 10 Gi. **Billing Changes:**; - The list of possible machine types we currently support is in the globals -- we only support the n1 family. I insert new resource rates into the Resources SQL table to account for the new nonpreemptible resources.; - If you have a job private instance, you are billed for that instance at the time of the instance's creation (not when it's activated). This is done by modifying the trigger for the attempts table to take the minimum attempt start time rather than the maximum. I'm not sure why we needed the maximum to begin with as the attempt start time was always the same. This is probably a place to double check before merging. **Job State Changes:**; - We now support a new state ""Creating"" which represents an instance has been spun up for a job, but it has not been activated yet; - The SQL user resources table and cancellable resources table needed to be changed to add the n_creating_jobs, n_cancellable_creating_jobs, and the n_cancelled_creating_jobs; - Added a new SQL function `mark_job_creating` that is only called by the job private instance creator.; - A lot of the existing SQL functions had to change to account for the fact that an instance in the pending state can have job-specific operations done such as mark_job_complete if the job is cancelled. In addition, the ""Creating"" state is like ""Running"" for some operations in that an attempt has been created and ac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9972
https://github.com/hail-is/hail/pull/9972:2180,Modifiability,config,configuration,2180,"aximum to begin with as the attempt start time was always the same. This is probably a place to double check before merging. **Job State Changes:**; - We now support a new state ""Creating"" which represents an instance has been spun up for a job, but it has not been activated yet; - The SQL user resources table and cancellable resources table needed to be changed to add the n_creating_jobs, n_cancellable_creating_jobs, and the n_cancelled_creating_jobs; - Added a new SQL function `mark_job_creating` that is only called by the job private instance creator.; - A lot of the existing SQL functions had to change to account for the fact that an instance in the pending state can have job-specific operations done such as mark_job_complete if the job is cancelled. In addition, the ""Creating"" state is like ""Running"" for some operations in that an attempt has been created and actions are happening on behalf of the user. **Driver Changes:**; - New cancel_creating_jobs event; - Two separate methods to get the pools or job private UI pages and two separate configuration methods. One each for pool and job-private. **JobPrivateInstanceCollection:**; - Has two new loops: an instance creation loop and a scheduling loop; - The instance creation loop does a fair share calculation that is almost identical to the pool one except the resource being allocated is n_ready_jobs compared to total_jobs rather than ready_cores_mcpu. ; - The instance creation loop needs to extract the machine_type, storage_gib, and preemptible from the spec without hitting GCS. Therefore, it is stored in the ""spec"" field in the database which required changing the batch format version a bit.; - We avoid double scheduling by requiring that there are no live instances assigned to attempts for that job before creating an instance.; - We mark a job as creating after creating the instance for the new attempt; - The number of instances that can be created is similar to the pool control loop. The total number of instances",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9972
https://github.com/hail-is/hail/pull/9972:2800,Safety,avoid,avoid,2800,"if the job is cancelled. In addition, the ""Creating"" state is like ""Running"" for some operations in that an attempt has been created and actions are happening on behalf of the user. **Driver Changes:**; - New cancel_creating_jobs event; - Two separate methods to get the pools or job private UI pages and two separate configuration methods. One each for pool and job-private. **JobPrivateInstanceCollection:**; - Has two new loops: an instance creation loop and a scheduling loop; - The instance creation loop does a fair share calculation that is almost identical to the pool one except the resource being allocated is n_ready_jobs compared to total_jobs rather than ready_cores_mcpu. ; - The instance creation loop needs to extract the machine_type, storage_gib, and preemptible from the spec without hitting GCS. Therefore, it is stored in the ""spec"" field in the database which required changing the batch format version a bit.; - We avoid double scheduling by requiring that there are no live instances assigned to attempts for that job before creating an instance.; - We mark a job as creating after creating the instance for the new attempt; - The number of instances that can be created is similar to the pool control loop. The total number of instances we can create is fed to the fair share allocator.; - I added an asyncio.wait(15) at the end of the instance creation loop body to make sure we didn't run past our GCE limits.; - The scheduling loop iterates over all attempts with active instances in order of time of activation (no user fair share here -- FIFO); - There is no possibility of double scheduling because there must only be one active instance per job based on the create instances loop. **Canceller:**; - There's a new canceller loop that looks for jobs that need to be cancelled in the creating state. It marks these jobs as complete ""cancelled"" in the database and then calls GCE to delete the instance. **Mark Job Complete:**; - I modified this function to kill a job priv",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9972
https://github.com/hail-is/hail/pull/9972:261,Testability,test,testing,261,"**User-facing Changes:**; - Added preemptible and machine_type to resources configuration in addition to existing worker_type (will get removed at some point in the future).; - machine_type and preemptible are hidden options in hailtop.batch (I put them in for testing purposes); - Can only specify one of worker_type and machine_type; - Preemptible is only valid for machine_type; - If you specify the machine_type, your storage gets rounded up to the nearest Gi with 10 Gi being the minimum (this is because we use a persistent-SSD as the worker data disk and the min for this is 10 Gi. **Billing Changes:**; - The list of possible machine types we currently support is in the globals -- we only support the n1 family. I insert new resource rates into the Resources SQL table to account for the new nonpreemptible resources.; - If you have a job private instance, you are billed for that instance at the time of the instance's creation (not when it's activated). This is done by modifying the trigger for the attempts table to take the minimum attempt start time rather than the maximum. I'm not sure why we needed the maximum to begin with as the attempt start time was always the same. This is probably a place to double check before merging. **Job State Changes:**; - We now support a new state ""Creating"" which represents an instance has been spun up for a job, but it has not been activated yet; - The SQL user resources table and cancellable resources table needed to be changed to add the n_creating_jobs, n_cancellable_creating_jobs, and the n_cancelled_creating_jobs; - Added a new SQL function `mark_job_creating` that is only called by the job private instance creator.; - A lot of the existing SQL functions had to change to account for the fact that an instance in the pending state can have job-specific operations done such as mark_job_complete if the job is cancelled. In addition, the ""Creating"" state is like ""Running"" for some operations in that an attempt has been created and ac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9972
https://github.com/hail-is/hail/pull/9972:4294,Testability,Test,Testing,4294," can be created is similar to the pool control loop. The total number of instances we can create is fed to the fair share allocator.; - I added an asyncio.wait(15) at the end of the instance creation loop body to make sure we didn't run past our GCE limits.; - The scheduling loop iterates over all attempts with active instances in order of time of activation (no user fair share here -- FIFO); - There is no possibility of double scheduling because there must only be one active instance per job based on the create instances loop. **Canceller:**; - There's a new canceller loop that looks for jobs that need to be cancelled in the creating state. It marks these jobs as complete ""cancelled"" in the database and then calls GCE to delete the instance. **Mark Job Complete:**; - I modified this function to kill a job private instance if the job is marked as complete and the instance is active. **Worker:**; - I added a kill function; - Note: I did not change how storage is computed. For job private instances, it's possible to be billed for 10Gi but only get 5 Gi if you requested 5 Gi in the XFS quotas. I decided that thinking through the storage here can be delayed until the storage PR since no one is going to be using this functionality yet. **Testing:**; - I added three new job private instance tests: preemptible, non preemptible, preemptible with cancellation in the creating state; - I also added the creating state to the check_incremental background test.; - I ran a chaos script and made sure everything was working with regards to cancellation.; - I looked at the UI pages in my dev deploy and made sure they were working. **Other:**; - The free cores for an instance is set to 0 at the time of instance creation. I wanted this behavior because we're billing for that time and the job has been allocated to that instance. So the free cores should be 0. It might be confusing. I also think of free cores as a resource we're wasting where as in this case, we're not wasting resources.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9972
https://github.com/hail-is/hail/pull/9972:4347,Testability,test,tests,4347," can be created is similar to the pool control loop. The total number of instances we can create is fed to the fair share allocator.; - I added an asyncio.wait(15) at the end of the instance creation loop body to make sure we didn't run past our GCE limits.; - The scheduling loop iterates over all attempts with active instances in order of time of activation (no user fair share here -- FIFO); - There is no possibility of double scheduling because there must only be one active instance per job based on the create instances loop. **Canceller:**; - There's a new canceller loop that looks for jobs that need to be cancelled in the creating state. It marks these jobs as complete ""cancelled"" in the database and then calls GCE to delete the instance. **Mark Job Complete:**; - I modified this function to kill a job private instance if the job is marked as complete and the instance is active. **Worker:**; - I added a kill function; - Note: I did not change how storage is computed. For job private instances, it's possible to be billed for 10Gi but only get 5 Gi if you requested 5 Gi in the XFS quotas. I decided that thinking through the storage here can be delayed until the storage PR since no one is going to be using this functionality yet. **Testing:**; - I added three new job private instance tests: preemptible, non preemptible, preemptible with cancellation in the creating state; - I also added the creating state to the check_incremental background test.; - I ran a chaos script and made sure everything was working with regards to cancellation.; - I looked at the UI pages in my dev deploy and made sure they were working. **Other:**; - The free cores for an instance is set to 0 at the time of instance creation. I wanted this behavior because we're billing for that time and the job has been allocated to that instance. So the free cores should be 0. It might be confusing. I also think of free cores as a resource we're wasting where as in this case, we're not wasting resources.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9972
https://github.com/hail-is/hail/pull/9972:4507,Testability,test,test,4507," can be created is similar to the pool control loop. The total number of instances we can create is fed to the fair share allocator.; - I added an asyncio.wait(15) at the end of the instance creation loop body to make sure we didn't run past our GCE limits.; - The scheduling loop iterates over all attempts with active instances in order of time of activation (no user fair share here -- FIFO); - There is no possibility of double scheduling because there must only be one active instance per job based on the create instances loop. **Canceller:**; - There's a new canceller loop that looks for jobs that need to be cancelled in the creating state. It marks these jobs as complete ""cancelled"" in the database and then calls GCE to delete the instance. **Mark Job Complete:**; - I modified this function to kill a job private instance if the job is marked as complete and the instance is active. **Worker:**; - I added a kill function; - Note: I did not change how storage is computed. For job private instances, it's possible to be billed for 10Gi but only get 5 Gi if you requested 5 Gi in the XFS quotas. I decided that thinking through the storage here can be delayed until the storage PR since no one is going to be using this functionality yet. **Testing:**; - I added three new job private instance tests: preemptible, non preemptible, preemptible with cancellation in the creating state; - I also added the creating state to the check_incremental background test.; - I ran a chaos script and made sure everything was working with regards to cancellation.; - I looked at the UI pages in my dev deploy and made sure they were working. **Other:**; - The free cores for an instance is set to 0 at the time of instance creation. I wanted this behavior because we're billing for that time and the job has been allocated to that instance. So the free cores should be 0. It might be confusing. I also think of free cores as a resource we're wasting where as in this case, we're not wasting resources.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9972
https://github.com/hail-is/hail/pull/9973:22,Availability,error,errors,22,1. Don't ignore parse errors by default. These shouldn't be happening; with modern VEP versions anyway (they were caused by genes named NaN; or something in older versions); 2. Don't silently drop variants that don't have a match in VEP. All keys; coming in will have a row coming out with a VEP annotation (maybe NA); and a partition/block index.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9973
https://github.com/hail-is/hail/pull/9975:132,Security,access,access,132,"Without this change, we race against dockerd. If the chain does not exist; before we add the rules, then containers will be able to access the metadata server; other containers, etc.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9975
https://github.com/hail-is/hail/pull/9980:142,Availability,error,error,142,"If there is a true issue, we raise the exception which is caught and printed by; docker_call_retry, or, if that re-raises, it is stored as an error and serialized; back to the driver in Container.run",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9980
https://github.com/hail-is/hail/pull/9981:0,Usability,Simpl,Simpler,0,Simpler and more ergonomic!,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9981
https://github.com/hail-is/hail/pull/9987:23,Testability,test,tests,23,"These billing projects tests did not correctly handle multiple attempts. Instead,; we use one billing project prefix for the entire batch (based on the token) and; each attempt gets a unique prefix. After all batch tests are complete, a job runs; which deletes all billing projects for the current batch.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9987
https://github.com/hail-is/hail/pull/9987:215,Testability,test,tests,215,"These billing projects tests did not correctly handle multiple attempts. Instead,; we use one billing project prefix for the entire batch (based on the token) and; each attempt gets a unique prefix. After all batch tests are complete, a job runs; which deletes all billing projects for the current batch.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9987
https://github.com/hail-is/hail/pull/9988:106,Deployability,install,install,106,Matches up the `gcsfs` version between services and hail query. Right now services developers have to pip install the `docker/requirements.txt` to run stuff like `sync.py` or resolve imports in editor. Might not be ideal but this at least allows you to pip install all the different requirements together for now.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9988
https://github.com/hail-is/hail/pull/9988:257,Deployability,install,install,257,Matches up the `gcsfs` version between services and hail query. Right now services developers have to pip install the `docker/requirements.txt` to run stuff like `sync.py` or resolve imports in editor. Might not be ideal but this at least allows you to pip install all the different requirements together for now.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9988
https://github.com/hail-is/hail/pull/9991:63,Availability,error,errors,63,"the gcloud command write to `stderr` which gets interpreted as errors in the logs and causes [a lot of noise](https://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Aseverity%3DERROR%0Aresource.labels.namespace_name%3D%22default%22%0Aresource.labels.container_name%3D%22image-fetcher%22;timeRange=PT3H?project=hail-vdc&folder=true&organizationId=548622027621&query=%0A). . Added `gcr.io` because without it `configure-docker` would configure all the registries it can find, which is unnecessary. Also removed `-x` from the site script since each line of that goes to error logs and none of it is helpful. If errors occur they will show up in some other form.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9991
https://github.com/hail-is/hail/pull/9991:599,Availability,error,error,599,"the gcloud command write to `stderr` which gets interpreted as errors in the logs and causes [a lot of noise](https://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Aseverity%3DERROR%0Aresource.labels.namespace_name%3D%22default%22%0Aresource.labels.container_name%3D%22image-fetcher%22;timeRange=PT3H?project=hail-vdc&folder=true&organizationId=548622027621&query=%0A). . Added `gcr.io` because without it `configure-docker` would configure all the registries it can find, which is unnecessary. Also removed `-x` from the site script since each line of that goes to error logs and none of it is helpful. If errors occur they will show up in some other form.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9991
https://github.com/hail-is/hail/pull/9991:640,Availability,error,errors,640,"the gcloud command write to `stderr` which gets interpreted as errors in the logs and causes [a lot of noise](https://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Aseverity%3DERROR%0Aresource.labels.namespace_name%3D%22default%22%0Aresource.labels.container_name%3D%22image-fetcher%22;timeRange=PT3H?project=hail-vdc&folder=true&organizationId=548622027621&query=%0A). . Added `gcr.io` because without it `configure-docker` would configure all the registries it can find, which is unnecessary. Also removed `-x` from the site script since each line of that goes to error logs and none of it is helpful. If errors occur they will show up in some other form.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9991
https://github.com/hail-is/hail/pull/9991:440,Modifiability,config,configure-docker,440,"the gcloud command write to `stderr` which gets interpreted as errors in the logs and causes [a lot of noise](https://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Aseverity%3DERROR%0Aresource.labels.namespace_name%3D%22default%22%0Aresource.labels.container_name%3D%22image-fetcher%22;timeRange=PT3H?project=hail-vdc&folder=true&organizationId=548622027621&query=%0A). . Added `gcr.io` because without it `configure-docker` would configure all the registries it can find, which is unnecessary. Also removed `-x` from the site script since each line of that goes to error logs and none of it is helpful. If errors occur they will show up in some other form.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9991
https://github.com/hail-is/hail/pull/9991:464,Modifiability,config,configure,464,"the gcloud command write to `stderr` which gets interpreted as errors in the logs and causes [a lot of noise](https://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Aseverity%3DERROR%0Aresource.labels.namespace_name%3D%22default%22%0Aresource.labels.container_name%3D%22image-fetcher%22;timeRange=PT3H?project=hail-vdc&folder=true&organizationId=548622027621&query=%0A). . Added `gcr.io` because without it `configure-docker` would configure all the registries it can find, which is unnecessary. Also removed `-x` from the site script since each line of that goes to error logs and none of it is helpful. If errors occur they will show up in some other form.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9991
https://github.com/hail-is/hail/pull/9991:77,Testability,log,logs,77,"the gcloud command write to `stderr` which gets interpreted as errors in the logs and causes [a lot of noise](https://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Aseverity%3DERROR%0Aresource.labels.namespace_name%3D%22default%22%0Aresource.labels.container_name%3D%22image-fetcher%22;timeRange=PT3H?project=hail-vdc&folder=true&organizationId=548622027621&query=%0A). . Added `gcr.io` because without it `configure-docker` would configure all the registries it can find, which is unnecessary. Also removed `-x` from the site script since each line of that goes to error logs and none of it is helpful. If errors occur they will show up in some other form.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9991
https://github.com/hail-is/hail/pull/9991:143,Testability,log,logs,143,"the gcloud command write to `stderr` which gets interpreted as errors in the logs and causes [a lot of noise](https://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Aseverity%3DERROR%0Aresource.labels.namespace_name%3D%22default%22%0Aresource.labels.container_name%3D%22image-fetcher%22;timeRange=PT3H?project=hail-vdc&folder=true&organizationId=548622027621&query=%0A). . Added `gcr.io` because without it `configure-docker` would configure all the registries it can find, which is unnecessary. Also removed `-x` from the site script since each line of that goes to error logs and none of it is helpful. If errors occur they will show up in some other form.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9991
https://github.com/hail-is/hail/pull/9991:605,Testability,log,logs,605,"the gcloud command write to `stderr` which gets interpreted as errors in the logs and causes [a lot of noise](https://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Aseverity%3DERROR%0Aresource.labels.namespace_name%3D%22default%22%0Aresource.labels.container_name%3D%22image-fetcher%22;timeRange=PT3H?project=hail-vdc&folder=true&organizationId=548622027621&query=%0A). . Added `gcr.io` because without it `configure-docker` would configure all the registries it can find, which is unnecessary. Also removed `-x` from the site script since each line of that goes to error logs and none of it is helpful. If errors occur they will show up in some other form.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9991
https://github.com/hail-is/hail/pull/9992:5,Testability,benchmark,benchmarks,5,BGEN benchmarks before/after:; ```; $ hb compare 0.2.61-ffa3169a657f-bgen-cb-before.json 0.2.61-126a8c8d5147-bgen-cb.json; Benchmark Name Ratio Time 1 Time 2; -------------- ----- ------ ------; import_bgen_force_count_all 98.0% 144.232 141.289; import_bgen_filter_count 97.9% 142.950 139.965; import_bgen_force_count_just_gp 96.1% 146.766 141.000; import_bgen_info_score 95.0% 197.271 187.353; ----------------------; Harmonic mean: 96.7%; Geometric mean: 96.7%; Arithmetic mean: 96.7%; Median: 97.0%; ```. I think this is within noise of no change.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9992
https://github.com/hail-is/hail/pull/9992:123,Testability,Benchmark,Benchmark,123,BGEN benchmarks before/after:; ```; $ hb compare 0.2.61-ffa3169a657f-bgen-cb-before.json 0.2.61-126a8c8d5147-bgen-cb.json; Benchmark Name Ratio Time 1 Time 2; -------------- ----- ------ ------; import_bgen_force_count_all 98.0% 144.232 141.289; import_bgen_filter_count 97.9% 142.950 139.965; import_bgen_force_count_just_gp 96.1% 146.766 141.000; import_bgen_info_score 95.0% 197.271 187.353; ----------------------; Harmonic mean: 96.7%; Geometric mean: 96.7%; Arithmetic mean: 96.7%; Median: 97.0%; ```. I think this is within noise of no change.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9992
https://github.com/hail-is/hail/pull/9996:156,Deployability,deploy,deploying,156,"Previously, unauthenticated developers would get a 401 nginx page when hitting an internal url. This now sends them through the auth flow. In the spirit of deploying before merge, you can try this out!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9996
https://github.com/hail-is/hail/pull/9999:102,Testability,assert,assert,102,"Currently, this is done in parallel with the existing memory management; tracking (in ptypes), and we assert that the two produce the same; result. This can give us confidence that removing InferPType will not; change semantics.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/9999
https://github.com/hail-is/hail/pull/10001:535,Energy Efficiency,allocate,allocate,535,"This PR introduces reference counted ndarrays. . One consequence of this is that like arrays, ndarrays will now store a pointer inside of tuples / structs that points to their location. Many of the changes in this PR are just to support that change. . Unlike arrays, ndarrays will live outside of regions, allowing them to be moved between regions without copies by editing the reference count associated with them. This will allow us to spend significantly less time copying in operations like those generated by `hl.loop`. . When we allocate an ndarray, we store a 16 byte header in front of the ndarray. The first 8 bytes is a long storing the reference count. The second 8 bytes is the total number of bytes (minus the header) stored in this ndarray.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10001
https://github.com/hail-is/hail/pull/10004:141,Integrability,message,messages,141,"We deprecated `hl.null` in favor of `hl.missing`. I removed uses from code base but missed the tests, so we are printing lots of deprecation messages when we run the tests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10004
https://github.com/hail-is/hail/pull/10004:95,Testability,test,tests,95,"We deprecated `hl.null` in favor of `hl.missing`. I removed uses from code base but missed the tests, so we are printing lots of deprecation messages when we run the tests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10004
https://github.com/hail-is/hail/pull/10004:166,Testability,test,tests,166,"We deprecated `hl.null` in favor of `hl.missing`. I removed uses from code base but missed the tests, so we are printing lots of deprecation messages when we run the tests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10004
https://github.com/hail-is/hail/pull/10007:127,Availability,error,error,127,"As described in #9600, `hl.hadoop_ls` currently raises a NullPointerException when called with a path that does not exist. The error originates in `is.hail.io.fs.HadoopFS.listStatus`. The [hadoop.fs.FileSystem docs](https://hadoop.apache.org/docs/current/api/org/apache/hadoop/fs/FileSystem.html#globStatus-org.apache.hadoop.fs.Path-) list two forms of `globStatus`:; * public FileStatus[] globStatus(Path pathPattern); * public FileStatus[] globStatus(Path pathPattern, PathFilter filter). The first makes no mention of returning null. The second however, says:; > Returns: null if pathPattern has no glob and the path does not exist an empty array if pathPattern has a glob and no path matches it else an array of FileStatus objects matching the pattern. This matches the behavior seen with `hl.hadoop_ls`. This change checks for a null value returned from `globStatus` and raises a `FileNotFoundException` in that case. Resolves #9600",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10007
https://github.com/hail-is/hail/pull/10013:0,Deployability,Deploy,Deploying,0,"Deploying grafana in our GKE cluster gives us instant and easy access to the stackdriver backend with the same querying capabilities of our current front-end, but without the clutter and insanely slow load times. See [here](https://internal.hail.is/dgoldste/grafana/d/TVkleyLMk/detailed-service-resource-utilization?orgId=1) for some example dashboards I set up to look at resources across our services (credentials are the default admin/admin). This alleviates the immediate pain of using the console (for metrics only, not logging), but my longer aim is that getting more regular use out of our metrics can reveal deeper pain points of our monitoring stack and if/where we need to eat up more responsibility from google monitoring. This is a StatefulSet, so configuration through the UI will persist and is done manually. If we find that our dashboards are stable and boilerplate enough, I'd like to move to a code-based dashboard configuration. Sadly, `check-yaml` does not appreciate our jinja templating in yaml, so I've removed it for now. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10013
https://github.com/hail-is/hail/pull/10013:760,Deployability,configurat,configuration,760,"Deploying grafana in our GKE cluster gives us instant and easy access to the stackdriver backend with the same querying capabilities of our current front-end, but without the clutter and insanely slow load times. See [here](https://internal.hail.is/dgoldste/grafana/d/TVkleyLMk/detailed-service-resource-utilization?orgId=1) for some example dashboards I set up to look at resources across our services (credentials are the default admin/admin). This alleviates the immediate pain of using the console (for metrics only, not logging), but my longer aim is that getting more regular use out of our metrics can reveal deeper pain points of our monitoring stack and if/where we need to eat up more responsibility from google monitoring. This is a StatefulSet, so configuration through the UI will persist and is done manually. If we find that our dashboards are stable and boilerplate enough, I'd like to move to a code-based dashboard configuration. Sadly, `check-yaml` does not appreciate our jinja templating in yaml, so I've removed it for now. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10013
https://github.com/hail-is/hail/pull/10013:933,Deployability,configurat,configuration,933,"Deploying grafana in our GKE cluster gives us instant and easy access to the stackdriver backend with the same querying capabilities of our current front-end, but without the clutter and insanely slow load times. See [here](https://internal.hail.is/dgoldste/grafana/d/TVkleyLMk/detailed-service-resource-utilization?orgId=1) for some example dashboards I set up to look at resources across our services (credentials are the default admin/admin). This alleviates the immediate pain of using the console (for metrics only, not logging), but my longer aim is that getting more regular use out of our metrics can reveal deeper pain points of our monitoring stack and if/where we need to eat up more responsibility from google monitoring. This is a StatefulSet, so configuration through the UI will persist and is done manually. If we find that our dashboards are stable and boilerplate enough, I'd like to move to a code-based dashboard configuration. Sadly, `check-yaml` does not appreciate our jinja templating in yaml, so I've removed it for now. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10013
https://github.com/hail-is/hail/pull/10013:642,Energy Efficiency,monitor,monitoring,642,"Deploying grafana in our GKE cluster gives us instant and easy access to the stackdriver backend with the same querying capabilities of our current front-end, but without the clutter and insanely slow load times. See [here](https://internal.hail.is/dgoldste/grafana/d/TVkleyLMk/detailed-service-resource-utilization?orgId=1) for some example dashboards I set up to look at resources across our services (credentials are the default admin/admin). This alleviates the immediate pain of using the console (for metrics only, not logging), but my longer aim is that getting more regular use out of our metrics can reveal deeper pain points of our monitoring stack and if/where we need to eat up more responsibility from google monitoring. This is a StatefulSet, so configuration through the UI will persist and is done manually. If we find that our dashboards are stable and boilerplate enough, I'd like to move to a code-based dashboard configuration. Sadly, `check-yaml` does not appreciate our jinja templating in yaml, so I've removed it for now. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10013
https://github.com/hail-is/hail/pull/10013:722,Energy Efficiency,monitor,monitoring,722,"Deploying grafana in our GKE cluster gives us instant and easy access to the stackdriver backend with the same querying capabilities of our current front-end, but without the clutter and insanely slow load times. See [here](https://internal.hail.is/dgoldste/grafana/d/TVkleyLMk/detailed-service-resource-utilization?orgId=1) for some example dashboards I set up to look at resources across our services (credentials are the default admin/admin). This alleviates the immediate pain of using the console (for metrics only, not logging), but my longer aim is that getting more regular use out of our metrics can reveal deeper pain points of our monitoring stack and if/where we need to eat up more responsibility from google monitoring. This is a StatefulSet, so configuration through the UI will persist and is done manually. If we find that our dashboards are stable and boilerplate enough, I'd like to move to a code-based dashboard configuration. Sadly, `check-yaml` does not appreciate our jinja templating in yaml, so I've removed it for now. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10013
https://github.com/hail-is/hail/pull/10013:760,Modifiability,config,configuration,760,"Deploying grafana in our GKE cluster gives us instant and easy access to the stackdriver backend with the same querying capabilities of our current front-end, but without the clutter and insanely slow load times. See [here](https://internal.hail.is/dgoldste/grafana/d/TVkleyLMk/detailed-service-resource-utilization?orgId=1) for some example dashboards I set up to look at resources across our services (credentials are the default admin/admin). This alleviates the immediate pain of using the console (for metrics only, not logging), but my longer aim is that getting more regular use out of our metrics can reveal deeper pain points of our monitoring stack and if/where we need to eat up more responsibility from google monitoring. This is a StatefulSet, so configuration through the UI will persist and is done manually. If we find that our dashboards are stable and boilerplate enough, I'd like to move to a code-based dashboard configuration. Sadly, `check-yaml` does not appreciate our jinja templating in yaml, so I've removed it for now. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10013
https://github.com/hail-is/hail/pull/10013:933,Modifiability,config,configuration,933,"Deploying grafana in our GKE cluster gives us instant and easy access to the stackdriver backend with the same querying capabilities of our current front-end, but without the clutter and insanely slow load times. See [here](https://internal.hail.is/dgoldste/grafana/d/TVkleyLMk/detailed-service-resource-utilization?orgId=1) for some example dashboards I set up to look at resources across our services (credentials are the default admin/admin). This alleviates the immediate pain of using the console (for metrics only, not logging), but my longer aim is that getting more regular use out of our metrics can reveal deeper pain points of our monitoring stack and if/where we need to eat up more responsibility from google monitoring. This is a StatefulSet, so configuration through the UI will persist and is done manually. If we find that our dashboards are stable and boilerplate enough, I'd like to move to a code-based dashboard configuration. Sadly, `check-yaml` does not appreciate our jinja templating in yaml, so I've removed it for now. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10013
https://github.com/hail-is/hail/pull/10013:201,Performance,load,load,201,"Deploying grafana in our GKE cluster gives us instant and easy access to the stackdriver backend with the same querying capabilities of our current front-end, but without the clutter and insanely slow load times. See [here](https://internal.hail.is/dgoldste/grafana/d/TVkleyLMk/detailed-service-resource-utilization?orgId=1) for some example dashboards I set up to look at resources across our services (credentials are the default admin/admin). This alleviates the immediate pain of using the console (for metrics only, not logging), but my longer aim is that getting more regular use out of our metrics can reveal deeper pain points of our monitoring stack and if/where we need to eat up more responsibility from google monitoring. This is a StatefulSet, so configuration through the UI will persist and is done manually. If we find that our dashboards are stable and boilerplate enough, I'd like to move to a code-based dashboard configuration. Sadly, `check-yaml` does not appreciate our jinja templating in yaml, so I've removed it for now. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10013
https://github.com/hail-is/hail/pull/10013:63,Security,access,access,63,"Deploying grafana in our GKE cluster gives us instant and easy access to the stackdriver backend with the same querying capabilities of our current front-end, but without the clutter and insanely slow load times. See [here](https://internal.hail.is/dgoldste/grafana/d/TVkleyLMk/detailed-service-resource-utilization?orgId=1) for some example dashboards I set up to look at resources across our services (credentials are the default admin/admin). This alleviates the immediate pain of using the console (for metrics only, not logging), but my longer aim is that getting more regular use out of our metrics can reveal deeper pain points of our monitoring stack and if/where we need to eat up more responsibility from google monitoring. This is a StatefulSet, so configuration through the UI will persist and is done manually. If we find that our dashboards are stable and boilerplate enough, I'd like to move to a code-based dashboard configuration. Sadly, `check-yaml` does not appreciate our jinja templating in yaml, so I've removed it for now. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10013
https://github.com/hail-is/hail/pull/10013:525,Testability,log,logging,525,"Deploying grafana in our GKE cluster gives us instant and easy access to the stackdriver backend with the same querying capabilities of our current front-end, but without the clutter and insanely slow load times. See [here](https://internal.hail.is/dgoldste/grafana/d/TVkleyLMk/detailed-service-resource-utilization?orgId=1) for some example dashboards I set up to look at resources across our services (credentials are the default admin/admin). This alleviates the immediate pain of using the console (for metrics only, not logging), but my longer aim is that getting more regular use out of our metrics can reveal deeper pain points of our monitoring stack and if/where we need to eat up more responsibility from google monitoring. This is a StatefulSet, so configuration through the UI will persist and is done manually. If we find that our dashboards are stable and boilerplate enough, I'd like to move to a code-based dashboard configuration. Sadly, `check-yaml` does not appreciate our jinja templating in yaml, so I've removed it for now. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10013
https://github.com/hail-is/hail/pull/10020:227,Usability,feedback,feedback,227,"This doc introduces the entire Hail project to new software engineers. This is a response to; Carolin's and Daniel's critiques of our on-boarding documentation. I think there's a lot more to say, but I think it's time for some feedback before I continue. The other things I want to document:; - How we use git? Including practical examples.; - What does genetic data look like?; - What is a GWAS?; - What is PCA as applied to genetics?; - A Tour of Hail Query (in the spirit of Soustroup's a Tour of C++).; - A Bibliography of Hail Team's recommended books.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10020
https://github.com/hail-is/hail/pull/10023:30,Availability,failure,failures,30,"This should fix the test_copy failures. The problem was, we were sending a mutable byte iterator for data when inserting a new object. If that insert read some of the data, failed, and was retried, the data that was read was lost and the retry started where the failed insert left off. To retry writes, you need to keep around the data you've sent to resend in case of failure. So you don't have to keep around an unbounded amount of data, Google Storage supports resumable uploads: https://cloud.google.com/storage/docs/resumable-uploads. This allows us to send data in chunks, and release the data after Google reports back that the data has been committed. `StorageClient.insert_object`, when the upload type is resumable (the default), takes an additional argument `bufsize`. This is the amount the amount that the writer will buffer for retries, and the size of the chunks sent to GCS. I kept around the simpler media upload type since I actually want to use it in copy (copy doesn't need to buffer because it can retry by rereading the file being copied from). This code was actually kind of hard to organize. It would be better if the code immediately wrote any incoming data instead of just buffering it until we hit the chunk size, but I didn't find a manageable way to write that. Suggestions welcome, tho it would be good to get this fix in because of the test failures.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10023
https://github.com/hail-is/hail/pull/10023:369,Availability,failure,failure,369,"This should fix the test_copy failures. The problem was, we were sending a mutable byte iterator for data when inserting a new object. If that insert read some of the data, failed, and was retried, the data that was read was lost and the retry started where the failed insert left off. To retry writes, you need to keep around the data you've sent to resend in case of failure. So you don't have to keep around an unbounded amount of data, Google Storage supports resumable uploads: https://cloud.google.com/storage/docs/resumable-uploads. This allows us to send data in chunks, and release the data after Google reports back that the data has been committed. `StorageClient.insert_object`, when the upload type is resumable (the default), takes an additional argument `bufsize`. This is the amount the amount that the writer will buffer for retries, and the size of the chunks sent to GCS. I kept around the simpler media upload type since I actually want to use it in copy (copy doesn't need to buffer because it can retry by rereading the file being copied from). This code was actually kind of hard to organize. It would be better if the code immediately wrote any incoming data instead of just buffering it until we hit the chunk size, but I didn't find a manageable way to write that. Suggestions welcome, tho it would be good to get this fix in because of the test failures.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10023
https://github.com/hail-is/hail/pull/10023:1372,Availability,failure,failures,1372,"This should fix the test_copy failures. The problem was, we were sending a mutable byte iterator for data when inserting a new object. If that insert read some of the data, failed, and was retried, the data that was read was lost and the retry started where the failed insert left off. To retry writes, you need to keep around the data you've sent to resend in case of failure. So you don't have to keep around an unbounded amount of data, Google Storage supports resumable uploads: https://cloud.google.com/storage/docs/resumable-uploads. This allows us to send data in chunks, and release the data after Google reports back that the data has been committed. `StorageClient.insert_object`, when the upload type is resumable (the default), takes an additional argument `bufsize`. This is the amount the amount that the writer will buffer for retries, and the size of the chunks sent to GCS. I kept around the simpler media upload type since I actually want to use it in copy (copy doesn't need to buffer because it can retry by rereading the file being copied from). This code was actually kind of hard to organize. It would be better if the code immediately wrote any incoming data instead of just buffering it until we hit the chunk size, but I didn't find a manageable way to write that. Suggestions welcome, tho it would be good to get this fix in because of the test failures.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10023
https://github.com/hail-is/hail/pull/10023:583,Deployability,release,release,583,"This should fix the test_copy failures. The problem was, we were sending a mutable byte iterator for data when inserting a new object. If that insert read some of the data, failed, and was retried, the data that was read was lost and the retry started where the failed insert left off. To retry writes, you need to keep around the data you've sent to resend in case of failure. So you don't have to keep around an unbounded amount of data, Google Storage supports resumable uploads: https://cloud.google.com/storage/docs/resumable-uploads. This allows us to send data in chunks, and release the data after Google reports back that the data has been committed. `StorageClient.insert_object`, when the upload type is resumable (the default), takes an additional argument `bufsize`. This is the amount the amount that the writer will buffer for retries, and the size of the chunks sent to GCS. I kept around the simpler media upload type since I actually want to use it in copy (copy doesn't need to buffer because it can retry by rereading the file being copied from). This code was actually kind of hard to organize. It would be better if the code immediately wrote any incoming data instead of just buffering it until we hit the chunk size, but I didn't find a manageable way to write that. Suggestions welcome, tho it would be good to get this fix in because of the test failures.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10023
https://github.com/hail-is/hail/pull/10023:1367,Testability,test,test,1367,"This should fix the test_copy failures. The problem was, we were sending a mutable byte iterator for data when inserting a new object. If that insert read some of the data, failed, and was retried, the data that was read was lost and the retry started where the failed insert left off. To retry writes, you need to keep around the data you've sent to resend in case of failure. So you don't have to keep around an unbounded amount of data, Google Storage supports resumable uploads: https://cloud.google.com/storage/docs/resumable-uploads. This allows us to send data in chunks, and release the data after Google reports back that the data has been committed. `StorageClient.insert_object`, when the upload type is resumable (the default), takes an additional argument `bufsize`. This is the amount the amount that the writer will buffer for retries, and the size of the chunks sent to GCS. I kept around the simpler media upload type since I actually want to use it in copy (copy doesn't need to buffer because it can retry by rereading the file being copied from). This code was actually kind of hard to organize. It would be better if the code immediately wrote any incoming data instead of just buffering it until we hit the chunk size, but I didn't find a manageable way to write that. Suggestions welcome, tho it would be good to get this fix in because of the test failures.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10023
https://github.com/hail-is/hail/pull/10023:909,Usability,simpl,simpler,909,"This should fix the test_copy failures. The problem was, we were sending a mutable byte iterator for data when inserting a new object. If that insert read some of the data, failed, and was retried, the data that was read was lost and the retry started where the failed insert left off. To retry writes, you need to keep around the data you've sent to resend in case of failure. So you don't have to keep around an unbounded amount of data, Google Storage supports resumable uploads: https://cloud.google.com/storage/docs/resumable-uploads. This allows us to send data in chunks, and release the data after Google reports back that the data has been committed. `StorageClient.insert_object`, when the upload type is resumable (the default), takes an additional argument `bufsize`. This is the amount the amount that the writer will buffer for retries, and the size of the chunks sent to GCS. I kept around the simpler media upload type since I actually want to use it in copy (copy doesn't need to buffer because it can retry by rereading the file being copied from). This code was actually kind of hard to organize. It would be better if the code immediately wrote any incoming data instead of just buffering it until we hit the chunk size, but I didn't find a manageable way to write that. Suggestions welcome, tho it would be good to get this fix in because of the test failures.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10023
https://github.com/hail-is/hail/pull/10027:316,Deployability,integrat,integrated,316,"I don't think we should merge this. This PR got a bit out of hand and then died when I changed focus to the query service. There are two distinct changes that I had hoped to unify: nicely rendered dev-docs *and* generated docs for gear, web_common, & hailtop. I got stuck after getting each one rendering OK but not integrated with one another. I also never got to dynamic rendering of the header (i.e. logged in users see batch > batches, etc.). The first thing you should check out are the rendered library docs:; ```; (cd docs && make html && (cd build/html && python3 -m http.server)); # now navigate to http://localhost:8000/; ```; You'll notice the Hail CSS is missing a bunch of styles to make functions render nicely. Take a look at the generated HTML. Sphinx includes a few style tags that we should probably define. I also fixed a few docs issues. There are many more broken references to fix. ![Screen Shot 2021-02-09 at 11 07 34 PM](https://user-images.githubusercontent.com/106194/107463257-acb15280-6b2b-11eb-8a26-129697009ef8.png); ![Screen Shot 2021-02-09 at 11 07 50 PM](https://user-images.githubusercontent.com/106194/107463256-acb15280-6b2b-11eb-82ff-48b6d83f2f0f.png). Now you should check out the rendered dev docs:; ```; (cd site && make render && cd docs && python3 -m http.server); ```; ![Screen Shot 2021-02-09 at 11 11 07 PM](https://user-images.githubusercontent.com/106194/107463544-555fb200-6b2c-11eb-9b23-39f66f0f4b12.png); ![Screen Shot 2021-02-09 at 11 11 16 PM](https://user-images.githubusercontent.com/106194/107463545-555fb200-6b2c-11eb-9901-5af07effc814.png). ---. What's left to do?. 1. Make the header dynamic (i.e. logged-in users see their name, etc.)?; 2. Move the dev-docs and the python library docs into one location.; 3. Finish modifying `site` so that it hosts two servers: `hail.is` and `docs.hail.is`. `docs.hail.is` displays some landing page from which we can navigate to dev-docs or python library docs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10027
https://github.com/hail-is/hail/pull/10027:316,Integrability,integrat,integrated,316,"I don't think we should merge this. This PR got a bit out of hand and then died when I changed focus to the query service. There are two distinct changes that I had hoped to unify: nicely rendered dev-docs *and* generated docs for gear, web_common, & hailtop. I got stuck after getting each one rendering OK but not integrated with one another. I also never got to dynamic rendering of the header (i.e. logged in users see batch > batches, etc.). The first thing you should check out are the rendered library docs:; ```; (cd docs && make html && (cd build/html && python3 -m http.server)); # now navigate to http://localhost:8000/; ```; You'll notice the Hail CSS is missing a bunch of styles to make functions render nicely. Take a look at the generated HTML. Sphinx includes a few style tags that we should probably define. I also fixed a few docs issues. There are many more broken references to fix. ![Screen Shot 2021-02-09 at 11 07 34 PM](https://user-images.githubusercontent.com/106194/107463257-acb15280-6b2b-11eb-8a26-129697009ef8.png); ![Screen Shot 2021-02-09 at 11 07 50 PM](https://user-images.githubusercontent.com/106194/107463256-acb15280-6b2b-11eb-82ff-48b6d83f2f0f.png). Now you should check out the rendered dev docs:; ```; (cd site && make render && cd docs && python3 -m http.server); ```; ![Screen Shot 2021-02-09 at 11 11 07 PM](https://user-images.githubusercontent.com/106194/107463544-555fb200-6b2c-11eb-9b23-39f66f0f4b12.png); ![Screen Shot 2021-02-09 at 11 11 16 PM](https://user-images.githubusercontent.com/106194/107463545-555fb200-6b2c-11eb-9901-5af07effc814.png). ---. What's left to do?. 1. Make the header dynamic (i.e. logged-in users see their name, etc.)?; 2. Move the dev-docs and the python library docs into one location.; 3. Finish modifying `site` so that it hosts two servers: `hail.is` and `docs.hail.is`. `docs.hail.is` displays some landing page from which we can navigate to dev-docs or python library docs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10027
https://github.com/hail-is/hail/pull/10027:403,Testability,log,logged,403,"I don't think we should merge this. This PR got a bit out of hand and then died when I changed focus to the query service. There are two distinct changes that I had hoped to unify: nicely rendered dev-docs *and* generated docs for gear, web_common, & hailtop. I got stuck after getting each one rendering OK but not integrated with one another. I also never got to dynamic rendering of the header (i.e. logged in users see batch > batches, etc.). The first thing you should check out are the rendered library docs:; ```; (cd docs && make html && (cd build/html && python3 -m http.server)); # now navigate to http://localhost:8000/; ```; You'll notice the Hail CSS is missing a bunch of styles to make functions render nicely. Take a look at the generated HTML. Sphinx includes a few style tags that we should probably define. I also fixed a few docs issues. There are many more broken references to fix. ![Screen Shot 2021-02-09 at 11 07 34 PM](https://user-images.githubusercontent.com/106194/107463257-acb15280-6b2b-11eb-8a26-129697009ef8.png); ![Screen Shot 2021-02-09 at 11 07 50 PM](https://user-images.githubusercontent.com/106194/107463256-acb15280-6b2b-11eb-82ff-48b6d83f2f0f.png). Now you should check out the rendered dev docs:; ```; (cd site && make render && cd docs && python3 -m http.server); ```; ![Screen Shot 2021-02-09 at 11 11 07 PM](https://user-images.githubusercontent.com/106194/107463544-555fb200-6b2c-11eb-9b23-39f66f0f4b12.png); ![Screen Shot 2021-02-09 at 11 11 16 PM](https://user-images.githubusercontent.com/106194/107463545-555fb200-6b2c-11eb-9901-5af07effc814.png). ---. What's left to do?. 1. Make the header dynamic (i.e. logged-in users see their name, etc.)?; 2. Move the dev-docs and the python library docs into one location.; 3. Finish modifying `site` so that it hosts two servers: `hail.is` and `docs.hail.is`. `docs.hail.is` displays some landing page from which we can navigate to dev-docs or python library docs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10027
https://github.com/hail-is/hail/pull/10027:1656,Testability,log,logged-in,1656,"I don't think we should merge this. This PR got a bit out of hand and then died when I changed focus to the query service. There are two distinct changes that I had hoped to unify: nicely rendered dev-docs *and* generated docs for gear, web_common, & hailtop. I got stuck after getting each one rendering OK but not integrated with one another. I also never got to dynamic rendering of the header (i.e. logged in users see batch > batches, etc.). The first thing you should check out are the rendered library docs:; ```; (cd docs && make html && (cd build/html && python3 -m http.server)); # now navigate to http://localhost:8000/; ```; You'll notice the Hail CSS is missing a bunch of styles to make functions render nicely. Take a look at the generated HTML. Sphinx includes a few style tags that we should probably define. I also fixed a few docs issues. There are many more broken references to fix. ![Screen Shot 2021-02-09 at 11 07 34 PM](https://user-images.githubusercontent.com/106194/107463257-acb15280-6b2b-11eb-8a26-129697009ef8.png); ![Screen Shot 2021-02-09 at 11 07 50 PM](https://user-images.githubusercontent.com/106194/107463256-acb15280-6b2b-11eb-82ff-48b6d83f2f0f.png). Now you should check out the rendered dev docs:; ```; (cd site && make render && cd docs && python3 -m http.server); ```; ![Screen Shot 2021-02-09 at 11 11 07 PM](https://user-images.githubusercontent.com/106194/107463544-555fb200-6b2c-11eb-9b23-39f66f0f4b12.png); ![Screen Shot 2021-02-09 at 11 11 16 PM](https://user-images.githubusercontent.com/106194/107463545-555fb200-6b2c-11eb-9901-5af07effc814.png). ---. What's left to do?. 1. Make the header dynamic (i.e. logged-in users see their name, etc.)?; 2. Move the dev-docs and the python library docs into one location.; 3. Finish modifying `site` so that it hosts two servers: `hail.is` and `docs.hail.is`. `docs.hail.is` displays some landing page from which we can navigate to dev-docs or python library docs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10027
https://github.com/hail-is/hail/pull/10031:85,Availability,resilien,resilience,85,Adds a `pre-commit` linting rule to run on our html files that is jinja-aware. The ~ resilience ~ of html continues to astound me.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10031
https://github.com/hail-is/hail/pull/10032:128,Availability,error,error,128,Noticed that ArrayExpression.head was not documented as deprecated when it was deprecated in #9482. This also fixes a rendering error with one of its examples. https://hail.is/docs/0.2/hail.expr.ArrayExpression.html#hail.expr.ArrayExpression.head,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10032
https://github.com/hail-is/hail/pull/10034:69,Testability,assert,assert,69,"If we find out the write is complete during a status check, we would assert the buffer is empty before advancing the the offset to the end. This exit point now matches the exit point when we complete after a normal chunk write. Also assert _closed in _wait_closed. _write_chunk can only complete when we've closed and therefore know the final size, so make sure _closed so we don't accidentally get into an infinite loop waiting for _done.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10034
https://github.com/hail-is/hail/pull/10034:233,Testability,assert,assert,233,"If we find out the write is complete during a status check, we would assert the buffer is empty before advancing the the offset to the end. This exit point now matches the exit point when we complete after a normal chunk write. Also assert _closed in _wait_closed. _write_chunk can only complete when we've closed and therefore know the final size, so make sure _closed so we don't accidentally get into an infinite loop waiting for _done.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10034
https://github.com/hail-is/hail/pull/10036:74,Energy Efficiency,schedul,scheduling,74,"We had a bug yesterday where the return value for `delta_cores_mcpu` when scheduling a job was None instead of an integer. This messed up the instance collection data structures for that instance so we couldn't remove the instance and we couldn't handle the deactivate or delete events. Also, the instance was stuck with -1 free cores. I think until we figure out why this happened, this is a perfectly good solution. If the job was actually scheduled correctly, then MJS will happen and the free cores will be correct.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10036
https://github.com/hail-is/hail/pull/10036:442,Energy Efficiency,schedul,scheduled,442,"We had a bug yesterday where the return value for `delta_cores_mcpu` when scheduling a job was None instead of an integer. This messed up the instance collection data structures for that instance so we couldn't remove the instance and we couldn't handle the deactivate or delete events. Also, the instance was stuck with -1 free cores. I think until we figure out why this happened, this is a perfectly good solution. If the job was actually scheduled correctly, then MJS will happen and the free cores will be correct.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10036
https://github.com/hail-is/hail/pull/10037:76,Deployability,deploy,deploys,76,"- Makes a user page at `/me` showing your PRs and your most recent (10) dev deploys. I added a `dev_deploy: 1` attribute to dev deploy batches to identify them, as seemed consistent with `test` and `deploy` attributes, though it might make more sense to change these to `scope` in the future? Either way this will only select dev deploys going forward but that seems like a non-issue. Also needed a hail username to gh username mapping, which is annoying, but deploys are hail username and PRs are github username and I didn't see an existing mapping between the two. - Extracts the pr, job, and newly added dev deploy tables into macros for reuse across pages. As a result removed the duplicate code for the job table between PR and batch pages.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10037
https://github.com/hail-is/hail/pull/10037:128,Deployability,deploy,deploy,128,"- Makes a user page at `/me` showing your PRs and your most recent (10) dev deploys. I added a `dev_deploy: 1` attribute to dev deploy batches to identify them, as seemed consistent with `test` and `deploy` attributes, though it might make more sense to change these to `scope` in the future? Either way this will only select dev deploys going forward but that seems like a non-issue. Also needed a hail username to gh username mapping, which is annoying, but deploys are hail username and PRs are github username and I didn't see an existing mapping between the two. - Extracts the pr, job, and newly added dev deploy tables into macros for reuse across pages. As a result removed the duplicate code for the job table between PR and batch pages.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10037
https://github.com/hail-is/hail/pull/10037:199,Deployability,deploy,deploy,199,"- Makes a user page at `/me` showing your PRs and your most recent (10) dev deploys. I added a `dev_deploy: 1` attribute to dev deploy batches to identify them, as seemed consistent with `test` and `deploy` attributes, though it might make more sense to change these to `scope` in the future? Either way this will only select dev deploys going forward but that seems like a non-issue. Also needed a hail username to gh username mapping, which is annoying, but deploys are hail username and PRs are github username and I didn't see an existing mapping between the two. - Extracts the pr, job, and newly added dev deploy tables into macros for reuse across pages. As a result removed the duplicate code for the job table between PR and batch pages.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10037
https://github.com/hail-is/hail/pull/10037:330,Deployability,deploy,deploys,330,"- Makes a user page at `/me` showing your PRs and your most recent (10) dev deploys. I added a `dev_deploy: 1` attribute to dev deploy batches to identify them, as seemed consistent with `test` and `deploy` attributes, though it might make more sense to change these to `scope` in the future? Either way this will only select dev deploys going forward but that seems like a non-issue. Also needed a hail username to gh username mapping, which is annoying, but deploys are hail username and PRs are github username and I didn't see an existing mapping between the two. - Extracts the pr, job, and newly added dev deploy tables into macros for reuse across pages. As a result removed the duplicate code for the job table between PR and batch pages.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10037
https://github.com/hail-is/hail/pull/10037:460,Deployability,deploy,deploys,460,"- Makes a user page at `/me` showing your PRs and your most recent (10) dev deploys. I added a `dev_deploy: 1` attribute to dev deploy batches to identify them, as seemed consistent with `test` and `deploy` attributes, though it might make more sense to change these to `scope` in the future? Either way this will only select dev deploys going forward but that seems like a non-issue. Also needed a hail username to gh username mapping, which is annoying, but deploys are hail username and PRs are github username and I didn't see an existing mapping between the two. - Extracts the pr, job, and newly added dev deploy tables into macros for reuse across pages. As a result removed the duplicate code for the job table between PR and batch pages.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10037
https://github.com/hail-is/hail/pull/10037:612,Deployability,deploy,deploy,612,"- Makes a user page at `/me` showing your PRs and your most recent (10) dev deploys. I added a `dev_deploy: 1` attribute to dev deploy batches to identify them, as seemed consistent with `test` and `deploy` attributes, though it might make more sense to change these to `scope` in the future? Either way this will only select dev deploys going forward but that seems like a non-issue. Also needed a hail username to gh username mapping, which is annoying, but deploys are hail username and PRs are github username and I didn't see an existing mapping between the two. - Extracts the pr, job, and newly added dev deploy tables into macros for reuse across pages. As a result removed the duplicate code for the job table between PR and batch pages.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10037
https://github.com/hail-is/hail/pull/10037:188,Testability,test,test,188,"- Makes a user page at `/me` showing your PRs and your most recent (10) dev deploys. I added a `dev_deploy: 1` attribute to dev deploy batches to identify them, as seemed consistent with `test` and `deploy` attributes, though it might make more sense to change these to `scope` in the future? Either way this will only select dev deploys going forward but that seems like a non-issue. Also needed a hail username to gh username mapping, which is annoying, but deploys are hail username and PRs are github username and I didn't see an existing mapping between the two. - Extracts the pr, job, and newly added dev deploy tables into macros for reuse across pages. As a result removed the duplicate code for the job table between PR and batch pages.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10037
https://github.com/hail-is/hail/pull/10043:5,Energy Efficiency,reduce,reduced,5,"This reduced the time to run `hl.hadoop_ls` on a glob that matches 1000 files in a GCS bucket from ~55s to ~10s. Still not as good as `gsutil ls -l`, which takes ~3s. Related to #9895",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10043
https://github.com/hail-is/hail/pull/10044:66,Availability,failure,failure,66,I think this is the last one. The tests passed 30 times without a failure.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10044
https://github.com/hail-is/hail/pull/10044:34,Testability,test,tests,34,I think this is the last one. The tests passed 30 times without a failure.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10044
https://github.com/hail-is/hail/pull/10045:47,Modifiability,flexible,flexible,47,"CHANGELOG: `hl.Table.parallelize` is much more flexible and now successfully imports most Hail-compatible data. I really wanted to load the hail-is/hail pull requests into Hail. I did not want to specify; the types of all 271 fields. I souped up Hail's `impute_type`:. - If an empty array, set, dict or `None` appears at any nesting level, but a ""peer"" is non-empty and; non-missing, we accept the peer's type.; - We take the union of two struct types as long as they agree on their intersection.; - If we discover a dict that cannot be imputed as a Hail dict, we try to impute it as a struct. If you like this change, I'll add tests. Note: I had to change `HailType` to include `None`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10045
https://github.com/hail-is/hail/pull/10045:131,Performance,load,load,131,"CHANGELOG: `hl.Table.parallelize` is much more flexible and now successfully imports most Hail-compatible data. I really wanted to load the hail-is/hail pull requests into Hail. I did not want to specify; the types of all 271 fields. I souped up Hail's `impute_type`:. - If an empty array, set, dict or `None` appears at any nesting level, but a ""peer"" is non-empty and; non-missing, we accept the peer's type.; - We take the union of two struct types as long as they agree on their intersection.; - If we discover a dict that cannot be imputed as a Hail dict, we try to impute it as a struct. If you like this change, I'll add tests. Note: I had to change `HailType` to include `None`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10045
https://github.com/hail-is/hail/pull/10045:628,Testability,test,tests,628,"CHANGELOG: `hl.Table.parallelize` is much more flexible and now successfully imports most Hail-compatible data. I really wanted to load the hail-is/hail pull requests into Hail. I did not want to specify; the types of all 271 fields. I souped up Hail's `impute_type`:. - If an empty array, set, dict or `None` appears at any nesting level, but a ""peer"" is non-empty and; non-missing, we accept the peer's type.; - We take the union of two struct types as long as they agree on their intersection.; - If we discover a dict that cannot be imputed as a Hail dict, we try to impute it as a struct. If you like this change, I'll add tests. Note: I had to change `HailType` to include `None`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10045
https://github.com/hail-is/hail/pull/10047:104,Integrability,interface,interface,104,I removed PSubsetStructSuite because it is testing functionality that won't really be part of the SCode interface and will go away soon.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10047
https://github.com/hail-is/hail/pull/10047:43,Testability,test,testing,43,I removed PSubsetStructSuite because it is testing functionality that won't really be part of the SCode interface and will go away soon.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10047
https://github.com/hail-is/hail/pull/10049:110,Availability,robust,robust,110,I use these functions to monitor the k8s cluster. These are useful in the interim while we; move towards more robust monitoring solutions. To make these accessible modify your ~/.bashrc; or ~/.zshrc to have this line:. source /path/to/hail-repository/devbin/functions.sh. cc: services-team: @jigold @CDiaz96 @catoverdrive @cseed,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10049
https://github.com/hail-is/hail/pull/10049:25,Energy Efficiency,monitor,monitor,25,I use these functions to monitor the k8s cluster. These are useful in the interim while we; move towards more robust monitoring solutions. To make these accessible modify your ~/.bashrc; or ~/.zshrc to have this line:. source /path/to/hail-repository/devbin/functions.sh. cc: services-team: @jigold @CDiaz96 @catoverdrive @cseed,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10049
https://github.com/hail-is/hail/pull/10049:117,Energy Efficiency,monitor,monitoring,117,I use these functions to monitor the k8s cluster. These are useful in the interim while we; move towards more robust monitoring solutions. To make these accessible modify your ~/.bashrc; or ~/.zshrc to have this line:. source /path/to/hail-repository/devbin/functions.sh. cc: services-team: @jigold @CDiaz96 @catoverdrive @cseed,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10049
https://github.com/hail-is/hail/pull/10049:153,Security,access,accessible,153,I use these functions to monitor the k8s cluster. These are useful in the interim while we; move towards more robust monitoring solutions. To make these accessible modify your ~/.bashrc; or ~/.zshrc to have this line:. source /path/to/hail-repository/devbin/functions.sh. cc: services-team: @jigold @CDiaz96 @catoverdrive @cseed,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10049
https://github.com/hail-is/hail/pull/10052:358,Availability,error,error,358,"We're upsetting the robots of the world by not having a `robots.txt` to instruct how they should crawl the website. As retribution, they crawl everything, so this robots.txt doesn't change any indexing behavior but if there's anything we don't want indexed I can add here. Requests for `/robots.txt` and `/favicon.ico` make up a non-trivial amount of site's error logs now, so I also added a symlink to the image we use as our favicon. Hopefully this helps to further quiet the logs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10052
https://github.com/hail-is/hail/pull/10052:364,Testability,log,logs,364,"We're upsetting the robots of the world by not having a `robots.txt` to instruct how they should crawl the website. As retribution, they crawl everything, so this robots.txt doesn't change any indexing behavior but if there's anything we don't want indexed I can add here. Requests for `/robots.txt` and `/favicon.ico` make up a non-trivial amount of site's error logs now, so I also added a symlink to the image we use as our favicon. Hopefully this helps to further quiet the logs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10052
https://github.com/hail-is/hail/pull/10052:478,Testability,log,logs,478,"We're upsetting the robots of the world by not having a `robots.txt` to instruct how they should crawl the website. As retribution, they crawl everything, so this robots.txt doesn't change any indexing behavior but if there's anything we don't want indexed I can add here. Requests for `/robots.txt` and `/favicon.ico` make up a non-trivial amount of site's error logs now, so I also added a symlink to the image we use as our favicon. Hopefully this helps to further quiet the logs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10052
https://github.com/hail-is/hail/pull/10056:1200,Availability,down,down,1200,"Website is an aiohttp application which templates docs pages and normal pages. This opens the path; towards unifying the visual appearance of hail.is, the docs, and the services. I simplified documentation generation at the cost of building the docs twice per commit. A new step,; `make_pip_versioned_docs` builds the pip version of the docs without testing them. `make_docs`; continues to work as it did before. The website uses the docs from `make_pip_versioned_docs`. The; GCS docs location is now completely unused. Website has four key folders:. - `website/website/pages/`: Jinja2 templated HTML pages. Served at `/`. - `website/website/docs/`: Hail & Batch docs pages, all HTML pages are templated with Jinja2.; Served at `/docs`. - `website/website/templates/`: Jinaj2 templates that are used in pages or in docs. - `website/website/static/`: Non-templated files. Served at `/static`. The website can be developed locally in or outside of Docker:; ```; make -C website run; ```; or; ```; make -C website rundocker; ```. ---. I had to rename site to website due to a Python package conflict. I also deleted two unused css; files. I also removed PLINK from hail_run_image because it was slowing down my iteration speed; and was a long-term FIXME anyway.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10056
https://github.com/hail-is/hail/pull/10056:350,Testability,test,testing,350,"Website is an aiohttp application which templates docs pages and normal pages. This opens the path; towards unifying the visual appearance of hail.is, the docs, and the services. I simplified documentation generation at the cost of building the docs twice per commit. A new step,; `make_pip_versioned_docs` builds the pip version of the docs without testing them. `make_docs`; continues to work as it did before. The website uses the docs from `make_pip_versioned_docs`. The; GCS docs location is now completely unused. Website has four key folders:. - `website/website/pages/`: Jinja2 templated HTML pages. Served at `/`. - `website/website/docs/`: Hail & Batch docs pages, all HTML pages are templated with Jinja2.; Served at `/docs`. - `website/website/templates/`: Jinaj2 templates that are used in pages or in docs. - `website/website/static/`: Non-templated files. Served at `/static`. The website can be developed locally in or outside of Docker:; ```; make -C website run; ```; or; ```; make -C website rundocker; ```. ---. I had to rename site to website due to a Python package conflict. I also deleted two unused css; files. I also removed PLINK from hail_run_image because it was slowing down my iteration speed; and was a long-term FIXME anyway.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10056
https://github.com/hail-is/hail/pull/10056:181,Usability,simpl,simplified,181,"Website is an aiohttp application which templates docs pages and normal pages. This opens the path; towards unifying the visual appearance of hail.is, the docs, and the services. I simplified documentation generation at the cost of building the docs twice per commit. A new step,; `make_pip_versioned_docs` builds the pip version of the docs without testing them. `make_docs`; continues to work as it did before. The website uses the docs from `make_pip_versioned_docs`. The; GCS docs location is now completely unused. Website has four key folders:. - `website/website/pages/`: Jinja2 templated HTML pages. Served at `/`. - `website/website/docs/`: Hail & Batch docs pages, all HTML pages are templated with Jinja2.; Served at `/docs`. - `website/website/templates/`: Jinaj2 templates that are used in pages or in docs. - `website/website/static/`: Non-templated files. Served at `/static`. The website can be developed locally in or outside of Docker:; ```; make -C website run; ```; or; ```; make -C website rundocker; ```. ---. I had to rename site to website due to a Python package conflict. I also deleted two unused css; files. I also removed PLINK from hail_run_image because it was slowing down my iteration speed; and was a long-term FIXME anyway.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10056
https://github.com/hail-is/hail/pull/10058:330,Deployability,deploy,deploy,330,"Hi, just proposing a possible fix (at least it fixes things for me). After `raise_for_status=True` [was set](https://github.com/hail-is/hail/pull/9864/files) to default to True for `ClientSession` objects, [these lines](https://github.com/hail-is/hail/blob/9303a3aeccc3c374130b845bdaa5b22a84a64ea5/hail/python/hailtop/hailctl/dev/deploy/cli.py#L48-L53) that handle the response and redirect the remote traceback locally, are no longer reachable. This PR sets `raise_for_status=False` for dev deploy, similar to how it [was handled for dev query](https://github.com/hail-is/hail/pull/9864/files#diff-3d7267e81281c8027cba60607e398a7d5fbfcc16481cddf45017948889b15715). Thanks @lgruen for helping to locate the issue!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10058
https://github.com/hail-is/hail/pull/10058:492,Deployability,deploy,deploy,492,"Hi, just proposing a possible fix (at least it fixes things for me). After `raise_for_status=True` [was set](https://github.com/hail-is/hail/pull/9864/files) to default to True for `ClientSession` objects, [these lines](https://github.com/hail-is/hail/blob/9303a3aeccc3c374130b845bdaa5b22a84a64ea5/hail/python/hailtop/hailctl/dev/deploy/cli.py#L48-L53) that handle the response and redirect the remote traceback locally, are no longer reachable. This PR sets `raise_for_status=False` for dev deploy, similar to how it [was handled for dev query](https://github.com/hail-is/hail/pull/9864/files#diff-3d7267e81281c8027cba60607e398a7d5fbfcc16481cddf45017948889b15715). Thanks @lgruen for helping to locate the issue!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10058
https://github.com/hail-is/hail/pull/10066:22,Deployability,deploy,deploy,22,Secrets needed to dev deploy site.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10066
https://github.com/hail-is/hail/pull/10069:164,Deployability,update,update,164,"The issue is we start billing for instances as soon as they're created with the API. However, if an instance is stuck in provisioning and never activates, we never update the start billing time to account for the lack of resource. This PR uses the `lastStartTimestamp` in the [Google REST API](https://cloud.google.com/compute/docs/reference/rest/v1/instances/get). This value is in RFC3339 format. I think this is the same format the timestamp in the activity logs, so I copied how we parse that value. If we delete the instance due to activation timeout, then we set the attempt start time to NULL so it's not billed. I couldn't find good documentation on this, but it seems like the `lastStartTimestamp` approximates what we care about for the purposes of checking for stuck workers. I checked it on an instance that was provisioning and the value was missing. Once the instance was in starting, the value was about 10 seconds after the `creationTimestamp`. . QUESTION: This does raise a question on whether we should be using the `lastStartTimestamp` when billing users if the difference is around 10 seconds. That will be a harder change, but is probably doable. We can't access the `lastStartTimestamp` through the metadata on the worker which would have been the easiest solution. We can get the compute client on the worker and access the `lastStartTimestamp` that way and set the job start time to the instance start time. I'd need to change the database for the attempts trigger to account for this. For the scenario where a job private job is cancelled while creating the instance, we would either need to make the additional API call or we just leave the time we created the instance. Thoughts?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10069
https://github.com/hail-is/hail/pull/10069:548,Safety,timeout,timeout,548,"The issue is we start billing for instances as soon as they're created with the API. However, if an instance is stuck in provisioning and never activates, we never update the start billing time to account for the lack of resource. This PR uses the `lastStartTimestamp` in the [Google REST API](https://cloud.google.com/compute/docs/reference/rest/v1/instances/get). This value is in RFC3339 format. I think this is the same format the timestamp in the activity logs, so I copied how we parse that value. If we delete the instance due to activation timeout, then we set the attempt start time to NULL so it's not billed. I couldn't find good documentation on this, but it seems like the `lastStartTimestamp` approximates what we care about for the purposes of checking for stuck workers. I checked it on an instance that was provisioning and the value was missing. Once the instance was in starting, the value was about 10 seconds after the `creationTimestamp`. . QUESTION: This does raise a question on whether we should be using the `lastStartTimestamp` when billing users if the difference is around 10 seconds. That will be a harder change, but is probably doable. We can't access the `lastStartTimestamp` through the metadata on the worker which would have been the easiest solution. We can get the compute client on the worker and access the `lastStartTimestamp` that way and set the job start time to the instance start time. I'd need to change the database for the attempts trigger to account for this. For the scenario where a job private job is cancelled while creating the instance, we would either need to make the additional API call or we just leave the time we created the instance. Thoughts?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10069
https://github.com/hail-is/hail/pull/10069:1177,Security,access,access,1177,"The issue is we start billing for instances as soon as they're created with the API. However, if an instance is stuck in provisioning and never activates, we never update the start billing time to account for the lack of resource. This PR uses the `lastStartTimestamp` in the [Google REST API](https://cloud.google.com/compute/docs/reference/rest/v1/instances/get). This value is in RFC3339 format. I think this is the same format the timestamp in the activity logs, so I copied how we parse that value. If we delete the instance due to activation timeout, then we set the attempt start time to NULL so it's not billed. I couldn't find good documentation on this, but it seems like the `lastStartTimestamp` approximates what we care about for the purposes of checking for stuck workers. I checked it on an instance that was provisioning and the value was missing. Once the instance was in starting, the value was about 10 seconds after the `creationTimestamp`. . QUESTION: This does raise a question on whether we should be using the `lastStartTimestamp` when billing users if the difference is around 10 seconds. That will be a harder change, but is probably doable. We can't access the `lastStartTimestamp` through the metadata on the worker which would have been the easiest solution. We can get the compute client on the worker and access the `lastStartTimestamp` that way and set the job start time to the instance start time. I'd need to change the database for the attempts trigger to account for this. For the scenario where a job private job is cancelled while creating the instance, we would either need to make the additional API call or we just leave the time we created the instance. Thoughts?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10069
https://github.com/hail-is/hail/pull/10069:1336,Security,access,access,1336,"The issue is we start billing for instances as soon as they're created with the API. However, if an instance is stuck in provisioning and never activates, we never update the start billing time to account for the lack of resource. This PR uses the `lastStartTimestamp` in the [Google REST API](https://cloud.google.com/compute/docs/reference/rest/v1/instances/get). This value is in RFC3339 format. I think this is the same format the timestamp in the activity logs, so I copied how we parse that value. If we delete the instance due to activation timeout, then we set the attempt start time to NULL so it's not billed. I couldn't find good documentation on this, but it seems like the `lastStartTimestamp` approximates what we care about for the purposes of checking for stuck workers. I checked it on an instance that was provisioning and the value was missing. Once the instance was in starting, the value was about 10 seconds after the `creationTimestamp`. . QUESTION: This does raise a question on whether we should be using the `lastStartTimestamp` when billing users if the difference is around 10 seconds. That will be a harder change, but is probably doable. We can't access the `lastStartTimestamp` through the metadata on the worker which would have been the easiest solution. We can get the compute client on the worker and access the `lastStartTimestamp` that way and set the job start time to the instance start time. I'd need to change the database for the attempts trigger to account for this. For the scenario where a job private job is cancelled while creating the instance, we would either need to make the additional API call or we just leave the time we created the instance. Thoughts?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10069
https://github.com/hail-is/hail/pull/10069:461,Testability,log,logs,461,"The issue is we start billing for instances as soon as they're created with the API. However, if an instance is stuck in provisioning and never activates, we never update the start billing time to account for the lack of resource. This PR uses the `lastStartTimestamp` in the [Google REST API](https://cloud.google.com/compute/docs/reference/rest/v1/instances/get). This value is in RFC3339 format. I think this is the same format the timestamp in the activity logs, so I copied how we parse that value. If we delete the instance due to activation timeout, then we set the attempt start time to NULL so it's not billed. I couldn't find good documentation on this, but it seems like the `lastStartTimestamp` approximates what we care about for the purposes of checking for stuck workers. I checked it on an instance that was provisioning and the value was missing. Once the instance was in starting, the value was about 10 seconds after the `creationTimestamp`. . QUESTION: This does raise a question on whether we should be using the `lastStartTimestamp` when billing users if the difference is around 10 seconds. That will be a harder change, but is probably doable. We can't access the `lastStartTimestamp` through the metadata on the worker which would have been the easiest solution. We can get the compute client on the worker and access the `lastStartTimestamp` that way and set the job start time to the instance start time. I'd need to change the database for the attempts trigger to account for this. For the scenario where a job private job is cancelled while creating the instance, we would either need to make the additional API call or we just leave the time we created the instance. Thoughts?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10069
https://github.com/hail-is/hail/pull/10071:50,Energy Efficiency,schedul,scheduled,50,"This solves a problem we saw where an attempt was scheduled on the instance, but when entering the schedule event into the database it failed. In the meantime, the job is cancelled before the database call can be retried. Now the job is presumed cancelled even though there are still attempts running. I added a loop to find attempts that are orphaned and unschedule them. Please double check the SQL query here that I got all the conditions correct!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10071
https://github.com/hail-is/hail/pull/10071:99,Energy Efficiency,schedul,schedule,99,"This solves a problem we saw where an attempt was scheduled on the instance, but when entering the schedule event into the database it failed. In the meantime, the job is cancelled before the database call can be retried. Now the job is presumed cancelled even though there are still attempts running. I added a loop to find attempts that are orphaned and unschedule them. Please double check the SQL query here that I got all the conditions correct!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10071
https://github.com/hail-is/hail/pull/10072:814,Availability,error,error,814,"- [ ] (@tpoterba) caf1e1e673 add fails_service_backend; - [ ] (@tpoterba, @cseed) a979dfba58 [hail] introduce and use mktemp and mktempd; - [ ] (@tpoterba) dcf026b01c [hail] make is.hail.expr.ir.functions threadsafe; - [ ] (@tpoterba) 807f38c20e [hail] fix use of row requiredness in lowerDistributedSort; - [ ] (@catoverdrive) 12df8eb456 [query-service] handle void-typed IRs in query-service; - [ ] (@catoverdrive) 03357ee83d [query-service] make user cache thread-safe; - [ ] (@tpoterba) 6c6734bc71 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) a3d2572ce7 [shuffler] log ShuffleCodecSpec anytime it is created; - [ ] (@daniel-goldstein) 8949dfec3c [scala-lsm] bugfix: least key may equal greatest key; - [ ] (@daniel-goldstein) 6067bd8e51 [services] discovered new transient error; - [ ] (@daniel-goldstein) c8356d30bb [shuffler] more assertions in ShuffleClient; - [ ] (@daniel-goldstein) 9991da90f0 [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [ ] (@daniel-goldstein) bc0140ab6f [query-service] move hail.jar earlier in Dockerfile; - [ ] (@daniel-goldstein) f96c28174d [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 6ae26339fe [query-service] simplify socket handling; - [ ] (@jigold) f3db30e23f [batch] teach JVMJob where to find the hail configuration files; - [ ] (@daniel-goldstein) b5c6d85554 [query-service] switch to services team approved logging; - [ ] (@tpoterba) 35a306c066 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 051c89b8e7 [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) ad9ea73d7a [query-service] run tests against query service",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10072
https://github.com/hail-is/hail/pull/10072:1334,Deployability,configurat,configuration,1334,"- [ ] (@tpoterba) caf1e1e673 add fails_service_backend; - [ ] (@tpoterba, @cseed) a979dfba58 [hail] introduce and use mktemp and mktempd; - [ ] (@tpoterba) dcf026b01c [hail] make is.hail.expr.ir.functions threadsafe; - [ ] (@tpoterba) 807f38c20e [hail] fix use of row requiredness in lowerDistributedSort; - [ ] (@catoverdrive) 12df8eb456 [query-service] handle void-typed IRs in query-service; - [ ] (@catoverdrive) 03357ee83d [query-service] make user cache thread-safe; - [ ] (@tpoterba) 6c6734bc71 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) a3d2572ce7 [shuffler] log ShuffleCodecSpec anytime it is created; - [ ] (@daniel-goldstein) 8949dfec3c [scala-lsm] bugfix: least key may equal greatest key; - [ ] (@daniel-goldstein) 6067bd8e51 [services] discovered new transient error; - [ ] (@daniel-goldstein) c8356d30bb [shuffler] more assertions in ShuffleClient; - [ ] (@daniel-goldstein) 9991da90f0 [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [ ] (@daniel-goldstein) bc0140ab6f [query-service] move hail.jar earlier in Dockerfile; - [ ] (@daniel-goldstein) f96c28174d [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 6ae26339fe [query-service] simplify socket handling; - [ ] (@jigold) f3db30e23f [batch] teach JVMJob where to find the hail configuration files; - [ ] (@daniel-goldstein) b5c6d85554 [query-service] switch to services team approved logging; - [ ] (@tpoterba) 35a306c066 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 051c89b8e7 [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) ad9ea73d7a [query-service] run tests against query service",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10072
https://github.com/hail-is/hail/pull/10072:1334,Modifiability,config,configuration,1334,"- [ ] (@tpoterba) caf1e1e673 add fails_service_backend; - [ ] (@tpoterba, @cseed) a979dfba58 [hail] introduce and use mktemp and mktempd; - [ ] (@tpoterba) dcf026b01c [hail] make is.hail.expr.ir.functions threadsafe; - [ ] (@tpoterba) 807f38c20e [hail] fix use of row requiredness in lowerDistributedSort; - [ ] (@catoverdrive) 12df8eb456 [query-service] handle void-typed IRs in query-service; - [ ] (@catoverdrive) 03357ee83d [query-service] make user cache thread-safe; - [ ] (@tpoterba) 6c6734bc71 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) a3d2572ce7 [shuffler] log ShuffleCodecSpec anytime it is created; - [ ] (@daniel-goldstein) 8949dfec3c [scala-lsm] bugfix: least key may equal greatest key; - [ ] (@daniel-goldstein) 6067bd8e51 [services] discovered new transient error; - [ ] (@daniel-goldstein) c8356d30bb [shuffler] more assertions in ShuffleClient; - [ ] (@daniel-goldstein) 9991da90f0 [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [ ] (@daniel-goldstein) bc0140ab6f [query-service] move hail.jar earlier in Dockerfile; - [ ] (@daniel-goldstein) f96c28174d [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 6ae26339fe [query-service] simplify socket handling; - [ ] (@jigold) f3db30e23f [batch] teach JVMJob where to find the hail configuration files; - [ ] (@daniel-goldstein) b5c6d85554 [query-service] switch to services team approved logging; - [ ] (@tpoterba) 35a306c066 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 051c89b8e7 [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) ad9ea73d7a [query-service] run tests against query service",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10072
https://github.com/hail-is/hail/pull/10072:454,Performance,cache,cache,454,"- [ ] (@tpoterba) caf1e1e673 add fails_service_backend; - [ ] (@tpoterba, @cseed) a979dfba58 [hail] introduce and use mktemp and mktempd; - [ ] (@tpoterba) dcf026b01c [hail] make is.hail.expr.ir.functions threadsafe; - [ ] (@tpoterba) 807f38c20e [hail] fix use of row requiredness in lowerDistributedSort; - [ ] (@catoverdrive) 12df8eb456 [query-service] handle void-typed IRs in query-service; - [ ] (@catoverdrive) 03357ee83d [query-service] make user cache thread-safe; - [ ] (@tpoterba) 6c6734bc71 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) a3d2572ce7 [shuffler] log ShuffleCodecSpec anytime it is created; - [ ] (@daniel-goldstein) 8949dfec3c [scala-lsm] bugfix: least key may equal greatest key; - [ ] (@daniel-goldstein) 6067bd8e51 [services] discovered new transient error; - [ ] (@daniel-goldstein) c8356d30bb [shuffler] more assertions in ShuffleClient; - [ ] (@daniel-goldstein) 9991da90f0 [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [ ] (@daniel-goldstein) bc0140ab6f [query-service] move hail.jar earlier in Dockerfile; - [ ] (@daniel-goldstein) f96c28174d [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 6ae26339fe [query-service] simplify socket handling; - [ ] (@jigold) f3db30e23f [batch] teach JVMJob where to find the hail configuration files; - [ ] (@daniel-goldstein) b5c6d85554 [query-service] switch to services team approved logging; - [ ] (@tpoterba) 35a306c066 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 051c89b8e7 [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) ad9ea73d7a [query-service] run tests against query service",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10072
https://github.com/hail-is/hail/pull/10072:467,Safety,safe,safe,467,"- [ ] (@tpoterba) caf1e1e673 add fails_service_backend; - [ ] (@tpoterba, @cseed) a979dfba58 [hail] introduce and use mktemp and mktempd; - [ ] (@tpoterba) dcf026b01c [hail] make is.hail.expr.ir.functions threadsafe; - [ ] (@tpoterba) 807f38c20e [hail] fix use of row requiredness in lowerDistributedSort; - [ ] (@catoverdrive) 12df8eb456 [query-service] handle void-typed IRs in query-service; - [ ] (@catoverdrive) 03357ee83d [query-service] make user cache thread-safe; - [ ] (@tpoterba) 6c6734bc71 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) a3d2572ce7 [shuffler] log ShuffleCodecSpec anytime it is created; - [ ] (@daniel-goldstein) 8949dfec3c [scala-lsm] bugfix: least key may equal greatest key; - [ ] (@daniel-goldstein) 6067bd8e51 [services] discovered new transient error; - [ ] (@daniel-goldstein) c8356d30bb [shuffler] more assertions in ShuffleClient; - [ ] (@daniel-goldstein) 9991da90f0 [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [ ] (@daniel-goldstein) bc0140ab6f [query-service] move hail.jar earlier in Dockerfile; - [ ] (@daniel-goldstein) f96c28174d [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 6ae26339fe [query-service] simplify socket handling; - [ ] (@jigold) f3db30e23f [batch] teach JVMJob where to find the hail configuration files; - [ ] (@daniel-goldstein) b5c6d85554 [query-service] switch to services team approved logging; - [ ] (@tpoterba) 35a306c066 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 051c89b8e7 [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) ad9ea73d7a [query-service] run tests against query service",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10072
https://github.com/hail-is/hail/pull/10072:606,Testability,log,log,606,"- [ ] (@tpoterba) caf1e1e673 add fails_service_backend; - [ ] (@tpoterba, @cseed) a979dfba58 [hail] introduce and use mktemp and mktempd; - [ ] (@tpoterba) dcf026b01c [hail] make is.hail.expr.ir.functions threadsafe; - [ ] (@tpoterba) 807f38c20e [hail] fix use of row requiredness in lowerDistributedSort; - [ ] (@catoverdrive) 12df8eb456 [query-service] handle void-typed IRs in query-service; - [ ] (@catoverdrive) 03357ee83d [query-service] make user cache thread-safe; - [ ] (@tpoterba) 6c6734bc71 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) a3d2572ce7 [shuffler] log ShuffleCodecSpec anytime it is created; - [ ] (@daniel-goldstein) 8949dfec3c [scala-lsm] bugfix: least key may equal greatest key; - [ ] (@daniel-goldstein) 6067bd8e51 [services] discovered new transient error; - [ ] (@daniel-goldstein) c8356d30bb [shuffler] more assertions in ShuffleClient; - [ ] (@daniel-goldstein) 9991da90f0 [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [ ] (@daniel-goldstein) bc0140ab6f [query-service] move hail.jar earlier in Dockerfile; - [ ] (@daniel-goldstein) f96c28174d [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 6ae26339fe [query-service] simplify socket handling; - [ ] (@jigold) f3db30e23f [batch] teach JVMJob where to find the hail configuration files; - [ ] (@daniel-goldstein) b5c6d85554 [query-service] switch to services team approved logging; - [ ] (@tpoterba) 35a306c066 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 051c89b8e7 [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) ad9ea73d7a [query-service] run tests against query service",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10072
https://github.com/hail-is/hail/pull/10072:874,Testability,assert,assertions,874,"- [ ] (@tpoterba) caf1e1e673 add fails_service_backend; - [ ] (@tpoterba, @cseed) a979dfba58 [hail] introduce and use mktemp and mktempd; - [ ] (@tpoterba) dcf026b01c [hail] make is.hail.expr.ir.functions threadsafe; - [ ] (@tpoterba) 807f38c20e [hail] fix use of row requiredness in lowerDistributedSort; - [ ] (@catoverdrive) 12df8eb456 [query-service] handle void-typed IRs in query-service; - [ ] (@catoverdrive) 03357ee83d [query-service] make user cache thread-safe; - [ ] (@tpoterba) 6c6734bc71 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) a3d2572ce7 [shuffler] log ShuffleCodecSpec anytime it is created; - [ ] (@daniel-goldstein) 8949dfec3c [scala-lsm] bugfix: least key may equal greatest key; - [ ] (@daniel-goldstein) 6067bd8e51 [services] discovered new transient error; - [ ] (@daniel-goldstein) c8356d30bb [shuffler] more assertions in ShuffleClient; - [ ] (@daniel-goldstein) 9991da90f0 [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [ ] (@daniel-goldstein) bc0140ab6f [query-service] move hail.jar earlier in Dockerfile; - [ ] (@daniel-goldstein) f96c28174d [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 6ae26339fe [query-service] simplify socket handling; - [ ] (@jigold) f3db30e23f [batch] teach JVMJob where to find the hail configuration files; - [ ] (@daniel-goldstein) b5c6d85554 [query-service] switch to services team approved logging; - [ ] (@tpoterba) 35a306c066 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 051c89b8e7 [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) ad9ea73d7a [query-service] run tests against query service",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10072
https://github.com/hail-is/hail/pull/10072:1441,Testability,log,logging,1441,"- [ ] (@tpoterba) caf1e1e673 add fails_service_backend; - [ ] (@tpoterba, @cseed) a979dfba58 [hail] introduce and use mktemp and mktempd; - [ ] (@tpoterba) dcf026b01c [hail] make is.hail.expr.ir.functions threadsafe; - [ ] (@tpoterba) 807f38c20e [hail] fix use of row requiredness in lowerDistributedSort; - [ ] (@catoverdrive) 12df8eb456 [query-service] handle void-typed IRs in query-service; - [ ] (@catoverdrive) 03357ee83d [query-service] make user cache thread-safe; - [ ] (@tpoterba) 6c6734bc71 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) a3d2572ce7 [shuffler] log ShuffleCodecSpec anytime it is created; - [ ] (@daniel-goldstein) 8949dfec3c [scala-lsm] bugfix: least key may equal greatest key; - [ ] (@daniel-goldstein) 6067bd8e51 [services] discovered new transient error; - [ ] (@daniel-goldstein) c8356d30bb [shuffler] more assertions in ShuffleClient; - [ ] (@daniel-goldstein) 9991da90f0 [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [ ] (@daniel-goldstein) bc0140ab6f [query-service] move hail.jar earlier in Dockerfile; - [ ] (@daniel-goldstein) f96c28174d [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 6ae26339fe [query-service] simplify socket handling; - [ ] (@jigold) f3db30e23f [batch] teach JVMJob where to find the hail configuration files; - [ ] (@daniel-goldstein) b5c6d85554 [query-service] switch to services team approved logging; - [ ] (@tpoterba) 35a306c066 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 051c89b8e7 [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) ad9ea73d7a [query-service] run tests against query service",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10072
https://github.com/hail-is/hail/pull/10072:1723,Testability,test,tests,1723,"- [ ] (@tpoterba) caf1e1e673 add fails_service_backend; - [ ] (@tpoterba, @cseed) a979dfba58 [hail] introduce and use mktemp and mktempd; - [ ] (@tpoterba) dcf026b01c [hail] make is.hail.expr.ir.functions threadsafe; - [ ] (@tpoterba) 807f38c20e [hail] fix use of row requiredness in lowerDistributedSort; - [ ] (@catoverdrive) 12df8eb456 [query-service] handle void-typed IRs in query-service; - [ ] (@catoverdrive) 03357ee83d [query-service] make user cache thread-safe; - [ ] (@tpoterba) 6c6734bc71 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) a3d2572ce7 [shuffler] log ShuffleCodecSpec anytime it is created; - [ ] (@daniel-goldstein) 8949dfec3c [scala-lsm] bugfix: least key may equal greatest key; - [ ] (@daniel-goldstein) 6067bd8e51 [services] discovered new transient error; - [ ] (@daniel-goldstein) c8356d30bb [shuffler] more assertions in ShuffleClient; - [ ] (@daniel-goldstein) 9991da90f0 [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [ ] (@daniel-goldstein) bc0140ab6f [query-service] move hail.jar earlier in Dockerfile; - [ ] (@daniel-goldstein) f96c28174d [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 6ae26339fe [query-service] simplify socket handling; - [ ] (@jigold) f3db30e23f [batch] teach JVMJob where to find the hail configuration files; - [ ] (@daniel-goldstein) b5c6d85554 [query-service] switch to services team approved logging; - [ ] (@tpoterba) 35a306c066 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 051c89b8e7 [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) ad9ea73d7a [query-service] run tests against query service",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10072
https://github.com/hail-is/hail/pull/10072:1237,Usability,simpl,simplify,1237,"- [ ] (@tpoterba) caf1e1e673 add fails_service_backend; - [ ] (@tpoterba, @cseed) a979dfba58 [hail] introduce and use mktemp and mktempd; - [ ] (@tpoterba) dcf026b01c [hail] make is.hail.expr.ir.functions threadsafe; - [ ] (@tpoterba) 807f38c20e [hail] fix use of row requiredness in lowerDistributedSort; - [ ] (@catoverdrive) 12df8eb456 [query-service] handle void-typed IRs in query-service; - [ ] (@catoverdrive) 03357ee83d [query-service] make user cache thread-safe; - [ ] (@tpoterba) 6c6734bc71 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) a3d2572ce7 [shuffler] log ShuffleCodecSpec anytime it is created; - [ ] (@daniel-goldstein) 8949dfec3c [scala-lsm] bugfix: least key may equal greatest key; - [ ] (@daniel-goldstein) 6067bd8e51 [services] discovered new transient error; - [ ] (@daniel-goldstein) c8356d30bb [shuffler] more assertions in ShuffleClient; - [ ] (@daniel-goldstein) 9991da90f0 [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [ ] (@daniel-goldstein) bc0140ab6f [query-service] move hail.jar earlier in Dockerfile; - [ ] (@daniel-goldstein) f96c28174d [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 6ae26339fe [query-service] simplify socket handling; - [ ] (@jigold) f3db30e23f [batch] teach JVMJob where to find the hail configuration files; - [ ] (@daniel-goldstein) b5c6d85554 [query-service] switch to services team approved logging; - [ ] (@tpoterba) 35a306c066 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 051c89b8e7 [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) ad9ea73d7a [query-service] run tests against query service",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10072
https://github.com/hail-is/hail/pull/10075:27,Testability,log,logic,27,"This change simplifies the logic to create the various globals when computing linear regression, cuts the size of the IR in half, and makes the code faster in the process. Benchmark times for linear_regression_rows_nd on my laptop:. Before this PR: [37.80013062, 37.84073734200001, 38.025162351999995]; After this PR: [31.85279850500001, 33.12659071399999, 31.33206254000001]. So about 15% faster, but still not fast enough. Regular linear regression is 22 seconds on my laptop.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10075
https://github.com/hail-is/hail/pull/10075:172,Testability,Benchmark,Benchmark,172,"This change simplifies the logic to create the various globals when computing linear regression, cuts the size of the IR in half, and makes the code faster in the process. Benchmark times for linear_regression_rows_nd on my laptop:. Before this PR: [37.80013062, 37.84073734200001, 38.025162351999995]; After this PR: [31.85279850500001, 33.12659071399999, 31.33206254000001]. So about 15% faster, but still not fast enough. Regular linear regression is 22 seconds on my laptop.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10075
https://github.com/hail-is/hail/pull/10075:12,Usability,simpl,simplifies,12,"This change simplifies the logic to create the various globals when computing linear regression, cuts the size of the IR in half, and makes the code faster in the process. Benchmark times for linear_regression_rows_nd on my laptop:. Before this PR: [37.80013062, 37.84073734200001, 38.025162351999995]; After this PR: [31.85279850500001, 33.12659071399999, 31.33206254000001]. So about 15% faster, but still not fast enough. Regular linear regression is 22 seconds on my laptop.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10075
https://github.com/hail-is/hail/pull/10077:114,Availability,error,error,114,"The left and right sources may provide more fields than are necessary. This is OK, but; previously this caused an error because `filterSet` expects the argument to be a subset; of the `self` argument.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10077
https://github.com/hail-is/hail/pull/10082:65,Testability,test,test,65,Its definition is literally first so I do not think we need this test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10082
https://github.com/hail-is/hail/pull/10085:360,Security,hash,hash,360,"Based on conversation in Zulip: https://hail.zulipchat.com/#narrow/stream/123000-general/topic/Server.20hail.20version.20through.20API/near/226462327. Add version endpoint to ~~auth~~ query API. As suggested, I've added the the `make python-version-info` to generate the `hail_version`, but this requires the git history within the docker, as the short commit hash is added to the end. I've just cherry-picked the [merge commit](https://github.com/populationgenomics/hail/commit/700a0cf9d6e05827feca6bdd9c455e2b261e72db) from our populationgenomics fork.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10085
https://github.com/hail-is/hail/issues/10087:3508,Deployability,patch,patch,3508,"lass.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1334); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1405). The Hail version is: 0.2.61; The spark version is: 2.4.0.cloudera2. Checking the stacktrace and debugging it looks like flush() is being called on a closed stream. On a non-encryption zone HDFS write this seems to be silently ignored, but it causes an exception when writing to an encryption zone HDFS. Looking at the Hail code, there is a test for trying to close a stream that is already closed, so I created a patch to do the same check on a flush call:; --- current/hail/hail/src/main/scala/is/hail/io/fs/HadoopFS.scala 2021-02-12 11:17:14.000000000 -0500; +++ patched/hail/hail/src/main/scala/is/hail/io/fs/HadoopFS.scala 2021-02-16 10:16:46.156874381 -0500; @@ -32,7 +32,11 @@. override def write(bytes: Array[Byte], off: Int, len: Int): Unit = os.write(bytes, off, len). - override def flush(): Unit = os.flush(); + override def flush(): Unit = {; + if (!closed) {; + os.flush(); + }; + }. override def close(): Unit = {; if (!closed) {. This fixed the issue for us. I am hoping that you can evaluate this patch and include it in future versions of Hail. Please let me know if you need more information,. Thanks; Steve Keller",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10087
https://github.com/hail-is/hail/issues/10087:3660,Deployability,patch,patched,3660,"lass.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1334); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1405). The Hail version is: 0.2.61; The spark version is: 2.4.0.cloudera2. Checking the stacktrace and debugging it looks like flush() is being called on a closed stream. On a non-encryption zone HDFS write this seems to be silently ignored, but it causes an exception when writing to an encryption zone HDFS. Looking at the Hail code, there is a test for trying to close a stream that is already closed, so I created a patch to do the same check on a flush call:; --- current/hail/hail/src/main/scala/is/hail/io/fs/HadoopFS.scala 2021-02-12 11:17:14.000000000 -0500; +++ patched/hail/hail/src/main/scala/is/hail/io/fs/HadoopFS.scala 2021-02-16 10:16:46.156874381 -0500; @@ -32,7 +32,11 @@. override def write(bytes: Array[Byte], off: Int, len: Int): Unit = os.write(bytes, off, len). - override def flush(): Unit = os.flush(); + override def flush(): Unit = {; + if (!closed) {; + os.flush(); + }; + }. override def close(): Unit = {; if (!closed) {. This fixed the issue for us. I am hoping that you can evaluate this patch and include it in future versions of Hail. Please let me know if you need more information,. Thanks; Steve Keller",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10087
https://github.com/hail-is/hail/issues/10087:4108,Deployability,patch,patch,4108,"lass.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1334); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1405). The Hail version is: 0.2.61; The spark version is: 2.4.0.cloudera2. Checking the stacktrace and debugging it looks like flush() is being called on a closed stream. On a non-encryption zone HDFS write this seems to be silently ignored, but it causes an exception when writing to an encryption zone HDFS. Looking at the Hail code, there is a test for trying to close a stream that is already closed, so I created a patch to do the same check on a flush call:; --- current/hail/hail/src/main/scala/is/hail/io/fs/HadoopFS.scala 2021-02-12 11:17:14.000000000 -0500; +++ patched/hail/hail/src/main/scala/is/hail/io/fs/HadoopFS.scala 2021-02-16 10:16:46.156874381 -0500; @@ -32,7 +32,11 @@. override def write(bytes: Array[Byte], off: Int, len: Int): Unit = os.write(bytes, off, len). - override def flush(): Unit = os.flush(); + override def flush(): Unit = {; + if (!closed) {; + os.flush(); + }; + }. override def close(): Unit = {; if (!closed) {. This fixed the issue for us. I am hoping that you can evaluate this patch and include it in future versions of Hail. Please let me know if you need more information,. Thanks; Steve Keller",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10087
https://github.com/hail-is/hail/issues/10087:2830,Energy Efficiency,schedul,scheduler,2830,"lection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1334); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1334); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1405). The Hail version is: 0.2.61; The spark version is: 2.4.0.cloudera2. Checking the stacktrace and debugging it looks like flush() is being called on a closed stream. On a non-encryption zone HDFS write this seems to be silently ignored, but it causes an exception when writing to an encryption zone HDFS. Looking at the Hail code, there is a test for trying to close a stream that is already closed, so I created a patch to do the same check on a flush call:; --- current/hail/hail/src/main/scala/is/hail/io/fs/HadoopFS.scala 2021-02-12 11:17:14.000000000 -0500; +++ patched/hail/hail/src/main/scala/is/hail/io/fs/HadoopFS.scala 2021-02-16 10:16:46.156874381 -0500; @@ -32,7 +32,11 @@. override def write(bytes: Array[Byte], off: Int, len: In",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10087
https://github.com/hail-is/hail/issues/10087:2901,Energy Efficiency,schedul,scheduler,2901,"la.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48); at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310); at scala.collection.AbstractIterator.to(Iterator.scala:1334); at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1334); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1405). The Hail version is: 0.2.61; The spark version is: 2.4.0.cloudera2. Checking the stacktrace and debugging it looks like flush() is being called on a closed stream. On a non-encryption zone HDFS write this seems to be silently ignored, but it causes an exception when writing to an encryption zone HDFS. Looking at the Hail code, there is a test for trying to close a stream that is already closed, so I created a patch to do the same check on a flush call:; --- current/hail/hail/src/main/scala/is/hail/io/fs/HadoopFS.scala 2021-02-12 11:17:14.000000000 -0500; +++ patched/hail/hail/src/main/scala/is/hail/io/fs/HadoopFS.scala 2021-02-16 10:16:46.156874381 -0500; @@ -32,7 +32,11 @@. override def write(bytes: Array[Byte], off: Int, len: Int): Unit = os.write(bytes, off, len). - override def flush(): Unit = os",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10087
https://github.com/hail-is/hail/issues/10087:62,Security,encrypt,encryption,62,"Hi,. I have an issue where hail fails when writing to an HDFS encryption zone. HDFS writes to a non-encrypted HDFS work OK. Here is the stacktrace:; java.io.IOException: Stream closed; at org.apache.hadoop.crypto.CryptoOutputStream.checkStream(CryptoOutputStream.java:270); at org.apache.hadoop.crypto.CryptoOutputStream.flush(CryptoOutputStream.java:257); at java.io.FilterOutputStream.flush(FilterOutputStream.java:140); at java.io.DataOutputStream.flush(DataOutputStream.java:123); at is.hail.io.fs.HadoopFS$$anon$1.flush(HadoopFS.scala:35); at java.io.DataOutputStream.flush(DataOutputStream.java:123); at java.io.FilterOutputStream.close(FilterOutputStream.java:158); at is.hail.utils.package$.using(package.scala:620); at is.hail.io.RichContextRDDRegionValue$.writeSplitRegion(RichContextRDDRegionValue.scala:106); at is.hail.rvd.RVD$$anonfun$29.apply(RVD.scala:938); at is.hail.rvd.RVD$$anonfun$29.apply(RVD.scala:936); at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18.apply(ContextRDD.scala:259); at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18.apply(ContextRDD.scala:259); at is.hail.utils.richUtils.RichContextRDD$$anonfun$cleanupRegions$1$$anonfun$2.apply(RichContextRDD.scala:62); at is.hail.utils.richUtils.RichContextRDD$$anonfun$cleanupRegions$1$$anonfun$2.apply(RichContextRDD.scala:62); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at is.hail.utils.richUtils.RichContextRDD$$anonfun$cleanupRegions$1$$anon$1.hasNext(RichContextRDD.scala:71); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); at scala.collection.Iterator$class.foreach(Iterator.scala:891); at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mut",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10087
https://github.com/hail-is/hail/issues/10087:100,Security,encrypt,encrypted,100,"Hi,. I have an issue where hail fails when writing to an HDFS encryption zone. HDFS writes to a non-encrypted HDFS work OK. Here is the stacktrace:; java.io.IOException: Stream closed; at org.apache.hadoop.crypto.CryptoOutputStream.checkStream(CryptoOutputStream.java:270); at org.apache.hadoop.crypto.CryptoOutputStream.flush(CryptoOutputStream.java:257); at java.io.FilterOutputStream.flush(FilterOutputStream.java:140); at java.io.DataOutputStream.flush(DataOutputStream.java:123); at is.hail.io.fs.HadoopFS$$anon$1.flush(HadoopFS.scala:35); at java.io.DataOutputStream.flush(DataOutputStream.java:123); at java.io.FilterOutputStream.close(FilterOutputStream.java:158); at is.hail.utils.package$.using(package.scala:620); at is.hail.io.RichContextRDDRegionValue$.writeSplitRegion(RichContextRDDRegionValue.scala:106); at is.hail.rvd.RVD$$anonfun$29.apply(RVD.scala:938); at is.hail.rvd.RVD$$anonfun$29.apply(RVD.scala:936); at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18.apply(ContextRDD.scala:259); at is.hail.sparkextras.ContextRDD$$anonfun$cmapPartitionsWithIndex$1$$anonfun$apply$18.apply(ContextRDD.scala:259); at is.hail.utils.richUtils.RichContextRDD$$anonfun$cleanupRegions$1$$anonfun$2.apply(RichContextRDD.scala:62); at is.hail.utils.richUtils.RichContextRDD$$anonfun$cleanupRegions$1$$anonfun$2.apply(RichContextRDD.scala:62); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at is.hail.utils.richUtils.RichContextRDD$$anonfun$cleanupRegions$1$$anon$1.hasNext(RichContextRDD.scala:71); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:439); at scala.collection.Iterator$class.foreach(Iterator.scala:891); at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59); at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104); at scala.collection.mut",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10087
https://github.com/hail-is/hail/issues/10087:3268,Security,encrypt,encryption,3268,"lass.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1334); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1405). The Hail version is: 0.2.61; The spark version is: 2.4.0.cloudera2. Checking the stacktrace and debugging it looks like flush() is being called on a closed stream. On a non-encryption zone HDFS write this seems to be silently ignored, but it causes an exception when writing to an encryption zone HDFS. Looking at the Hail code, there is a test for trying to close a stream that is already closed, so I created a patch to do the same check on a flush call:; --- current/hail/hail/src/main/scala/is/hail/io/fs/HadoopFS.scala 2021-02-12 11:17:14.000000000 -0500; +++ patched/hail/hail/src/main/scala/is/hail/io/fs/HadoopFS.scala 2021-02-16 10:16:46.156874381 -0500; @@ -32,7 +32,11 @@. override def write(bytes: Array[Byte], off: Int, len: Int): Unit = os.write(bytes, off, len). - override def flush(): Unit = os.flush(); + override def flush(): Unit = {; + if (!closed) {; + os.flush(); + }; + }. override def close(): Unit = {; if (!closed) {. This fixed the issue for us. I am hoping that you can evaluate this patch and include it in future versions of Hail. Please let me know if you need more information,. Thanks; Steve Keller",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10087
https://github.com/hail-is/hail/issues/10087:3376,Security,encrypt,encryption,3376,"lass.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1334); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1405). The Hail version is: 0.2.61; The spark version is: 2.4.0.cloudera2. Checking the stacktrace and debugging it looks like flush() is being called on a closed stream. On a non-encryption zone HDFS write this seems to be silently ignored, but it causes an exception when writing to an encryption zone HDFS. Looking at the Hail code, there is a test for trying to close a stream that is already closed, so I created a patch to do the same check on a flush call:; --- current/hail/hail/src/main/scala/is/hail/io/fs/HadoopFS.scala 2021-02-12 11:17:14.000000000 -0500; +++ patched/hail/hail/src/main/scala/is/hail/io/fs/HadoopFS.scala 2021-02-16 10:16:46.156874381 -0500; @@ -32,7 +32,11 @@. override def write(bytes: Array[Byte], off: Int, len: Int): Unit = os.write(bytes, off, len). - override def flush(): Unit = os.flush(); + override def flush(): Unit = {; + if (!closed) {; + os.flush(); + }; + }. override def close(): Unit = {; if (!closed) {. This fixed the issue for us. I am hoping that you can evaluate this patch and include it in future versions of Hail. Please let me know if you need more information,. Thanks; Steve Keller",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10087
https://github.com/hail-is/hail/issues/10087:3435,Testability,test,test,3435,"lass.toBuffer(TraversableOnce.scala:302); at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1334); at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289); at scala.collection.AbstractIterator.toArray(Iterator.scala:1334); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945); at org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:945); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2101); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:121); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1405). The Hail version is: 0.2.61; The spark version is: 2.4.0.cloudera2. Checking the stacktrace and debugging it looks like flush() is being called on a closed stream. On a non-encryption zone HDFS write this seems to be silently ignored, but it causes an exception when writing to an encryption zone HDFS. Looking at the Hail code, there is a test for trying to close a stream that is already closed, so I created a patch to do the same check on a flush call:; --- current/hail/hail/src/main/scala/is/hail/io/fs/HadoopFS.scala 2021-02-12 11:17:14.000000000 -0500; +++ patched/hail/hail/src/main/scala/is/hail/io/fs/HadoopFS.scala 2021-02-16 10:16:46.156874381 -0500; @@ -32,7 +32,11 @@. override def write(bytes: Array[Byte], off: Int, len: Int): Unit = os.write(bytes, off, len). - override def flush(): Unit = os.flush(); + override def flush(): Unit = {; + if (!closed) {; + os.flush(); + }; + }. override def close(): Unit = {; if (!closed) {. This fixed the issue for us. I am hoping that you can evaluate this patch and include it in future versions of Hail. Please let me know if you need more information,. Thanks; Steve Keller",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10087
https://github.com/hail-is/hail/pull/10090:1556,Availability,down,down,1556,"This is a newer version of #9598. We decided to give users min(5Gi/core, 5 Gi) in `/` with mounting external storage at `/io` if they need more storage. All storage requests can be 0, 0 < storage < 10 will be rounded up to 10 Gi, or 10+Gi rounded up to the nearest integer. I added a loop to remove orphaned disks in gce.py. I changed how the resources appear in the spec. Now there's `req_cpu`, `req_storage`, `req_memory` which stores what the user specified. Then we also have `cores_mcpu`, `memory_bytes`, and `storage_gib` which are the actual resources allocated. I think this will be simpler and more understandable. Resources are computed in the front end now and the worker just uses the values from the front end (no more doing conversions on both the worker and front end). I kept backwards compatibility on the worker for now which can get deleted once there are no more jobs with batch format version < 6. I bumped the instance version to 16 so we know which workers have the new storage functionality. . I tested this by submitting 4 jobs on my 1 core test instance with 150Gi requests. I then looked at the worker logs to make sure the disks were created correctly and the value of the semaphore was correct. I also tested 0 Gi and 5 Gi by hand to make sure the resource fulfilled was 0Gi and 10Gi respectively. Lastly, I checked the billing to make sure we charged for the fraction of the SSD used as well as the cost of adding an extra persistent SSD for that job. I also looked at the disks in the GCE console to make sure they wear torn down correctly. Although there isn't a migration, we should make sure there are no non-ci jobs running so that we don't over allocate the storage available. Also, once this is merged, we should send an email to all users to let them know the cores must be a power of 2 now and about the storage now being mounted at '/io`. I put the WIP tag on so I can do this when I'm ready to.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10090
https://github.com/hail-is/hail/pull/10090:1702,Availability,avail,available,1702,"This is a newer version of #9598. We decided to give users min(5Gi/core, 5 Gi) in `/` with mounting external storage at `/io` if they need more storage. All storage requests can be 0, 0 < storage < 10 will be rounded up to 10 Gi, or 10+Gi rounded up to the nearest integer. I added a loop to remove orphaned disks in gce.py. I changed how the resources appear in the spec. Now there's `req_cpu`, `req_storage`, `req_memory` which stores what the user specified. Then we also have `cores_mcpu`, `memory_bytes`, and `storage_gib` which are the actual resources allocated. I think this will be simpler and more understandable. Resources are computed in the front end now and the worker just uses the values from the front end (no more doing conversions on both the worker and front end). I kept backwards compatibility on the worker for now which can get deleted once there are no more jobs with batch format version < 6. I bumped the instance version to 16 so we know which workers have the new storage functionality. . I tested this by submitting 4 jobs on my 1 core test instance with 150Gi requests. I then looked at the worker logs to make sure the disks were created correctly and the value of the semaphore was correct. I also tested 0 Gi and 5 Gi by hand to make sure the resource fulfilled was 0Gi and 10Gi respectively. Lastly, I checked the billing to make sure we charged for the fraction of the SSD used as well as the cost of adding an extra persistent SSD for that job. I also looked at the disks in the GCE console to make sure they wear torn down correctly. Although there isn't a migration, we should make sure there are no non-ci jobs running so that we don't over allocate the storage available. Also, once this is merged, we should send an email to all users to let them know the cores must be a power of 2 now and about the storage now being mounted at '/io`. I put the WIP tag on so I can do this when I'm ready to.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10090
https://github.com/hail-is/hail/pull/10090:559,Energy Efficiency,allocate,allocated,559,"This is a newer version of #9598. We decided to give users min(5Gi/core, 5 Gi) in `/` with mounting external storage at `/io` if they need more storage. All storage requests can be 0, 0 < storage < 10 will be rounded up to 10 Gi, or 10+Gi rounded up to the nearest integer. I added a loop to remove orphaned disks in gce.py. I changed how the resources appear in the spec. Now there's `req_cpu`, `req_storage`, `req_memory` which stores what the user specified. Then we also have `cores_mcpu`, `memory_bytes`, and `storage_gib` which are the actual resources allocated. I think this will be simpler and more understandable. Resources are computed in the front end now and the worker just uses the values from the front end (no more doing conversions on both the worker and front end). I kept backwards compatibility on the worker for now which can get deleted once there are no more jobs with batch format version < 6. I bumped the instance version to 16 so we know which workers have the new storage functionality. . I tested this by submitting 4 jobs on my 1 core test instance with 150Gi requests. I then looked at the worker logs to make sure the disks were created correctly and the value of the semaphore was correct. I also tested 0 Gi and 5 Gi by hand to make sure the resource fulfilled was 0Gi and 10Gi respectively. Lastly, I checked the billing to make sure we charged for the fraction of the SSD used as well as the cost of adding an extra persistent SSD for that job. I also looked at the disks in the GCE console to make sure they wear torn down correctly. Although there isn't a migration, we should make sure there are no non-ci jobs running so that we don't over allocate the storage available. Also, once this is merged, we should send an email to all users to let them know the cores must be a power of 2 now and about the storage now being mounted at '/io`. I put the WIP tag on so I can do this when I'm ready to.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10090
https://github.com/hail-is/hail/pull/10090:1373,Energy Efficiency,charge,charged,1373,"This is a newer version of #9598. We decided to give users min(5Gi/core, 5 Gi) in `/` with mounting external storage at `/io` if they need more storage. All storage requests can be 0, 0 < storage < 10 will be rounded up to 10 Gi, or 10+Gi rounded up to the nearest integer. I added a loop to remove orphaned disks in gce.py. I changed how the resources appear in the spec. Now there's `req_cpu`, `req_storage`, `req_memory` which stores what the user specified. Then we also have `cores_mcpu`, `memory_bytes`, and `storage_gib` which are the actual resources allocated. I think this will be simpler and more understandable. Resources are computed in the front end now and the worker just uses the values from the front end (no more doing conversions on both the worker and front end). I kept backwards compatibility on the worker for now which can get deleted once there are no more jobs with batch format version < 6. I bumped the instance version to 16 so we know which workers have the new storage functionality. . I tested this by submitting 4 jobs on my 1 core test instance with 150Gi requests. I then looked at the worker logs to make sure the disks were created correctly and the value of the semaphore was correct. I also tested 0 Gi and 5 Gi by hand to make sure the resource fulfilled was 0Gi and 10Gi respectively. Lastly, I checked the billing to make sure we charged for the fraction of the SSD used as well as the cost of adding an extra persistent SSD for that job. I also looked at the disks in the GCE console to make sure they wear torn down correctly. Although there isn't a migration, we should make sure there are no non-ci jobs running so that we don't over allocate the storage available. Also, once this is merged, we should send an email to all users to let them know the cores must be a power of 2 now and about the storage now being mounted at '/io`. I put the WIP tag on so I can do this when I'm ready to.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10090
https://github.com/hail-is/hail/pull/10090:1681,Energy Efficiency,allocate,allocate,1681,"This is a newer version of #9598. We decided to give users min(5Gi/core, 5 Gi) in `/` with mounting external storage at `/io` if they need more storage. All storage requests can be 0, 0 < storage < 10 will be rounded up to 10 Gi, or 10+Gi rounded up to the nearest integer. I added a loop to remove orphaned disks in gce.py. I changed how the resources appear in the spec. Now there's `req_cpu`, `req_storage`, `req_memory` which stores what the user specified. Then we also have `cores_mcpu`, `memory_bytes`, and `storage_gib` which are the actual resources allocated. I think this will be simpler and more understandable. Resources are computed in the front end now and the worker just uses the values from the front end (no more doing conversions on both the worker and front end). I kept backwards compatibility on the worker for now which can get deleted once there are no more jobs with batch format version < 6. I bumped the instance version to 16 so we know which workers have the new storage functionality. . I tested this by submitting 4 jobs on my 1 core test instance with 150Gi requests. I then looked at the worker logs to make sure the disks were created correctly and the value of the semaphore was correct. I also tested 0 Gi and 5 Gi by hand to make sure the resource fulfilled was 0Gi and 10Gi respectively. Lastly, I checked the billing to make sure we charged for the fraction of the SSD used as well as the cost of adding an extra persistent SSD for that job. I also looked at the disks in the GCE console to make sure they wear torn down correctly. Although there isn't a migration, we should make sure there are no non-ci jobs running so that we don't over allocate the storage available. Also, once this is merged, we should send an email to all users to let them know the cores must be a power of 2 now and about the storage now being mounted at '/io`. I put the WIP tag on so I can do this when I'm ready to.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10090
https://github.com/hail-is/hail/pull/10090:1814,Energy Efficiency,power,power,1814,"This is a newer version of #9598. We decided to give users min(5Gi/core, 5 Gi) in `/` with mounting external storage at `/io` if they need more storage. All storage requests can be 0, 0 < storage < 10 will be rounded up to 10 Gi, or 10+Gi rounded up to the nearest integer. I added a loop to remove orphaned disks in gce.py. I changed how the resources appear in the spec. Now there's `req_cpu`, `req_storage`, `req_memory` which stores what the user specified. Then we also have `cores_mcpu`, `memory_bytes`, and `storage_gib` which are the actual resources allocated. I think this will be simpler and more understandable. Resources are computed in the front end now and the worker just uses the values from the front end (no more doing conversions on both the worker and front end). I kept backwards compatibility on the worker for now which can get deleted once there are no more jobs with batch format version < 6. I bumped the instance version to 16 so we know which workers have the new storage functionality. . I tested this by submitting 4 jobs on my 1 core test instance with 150Gi requests. I then looked at the worker logs to make sure the disks were created correctly and the value of the semaphore was correct. I also tested 0 Gi and 5 Gi by hand to make sure the resource fulfilled was 0Gi and 10Gi respectively. Lastly, I checked the billing to make sure we charged for the fraction of the SSD used as well as the cost of adding an extra persistent SSD for that job. I also looked at the disks in the GCE console to make sure they wear torn down correctly. Although there isn't a migration, we should make sure there are no non-ci jobs running so that we don't over allocate the storage available. Also, once this is merged, we should send an email to all users to let them know the cores must be a power of 2 now and about the storage now being mounted at '/io`. I put the WIP tag on so I can do this when I'm ready to.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10090
https://github.com/hail-is/hail/pull/10090:1020,Testability,test,tested,1020,"This is a newer version of #9598. We decided to give users min(5Gi/core, 5 Gi) in `/` with mounting external storage at `/io` if they need more storage. All storage requests can be 0, 0 < storage < 10 will be rounded up to 10 Gi, or 10+Gi rounded up to the nearest integer. I added a loop to remove orphaned disks in gce.py. I changed how the resources appear in the spec. Now there's `req_cpu`, `req_storage`, `req_memory` which stores what the user specified. Then we also have `cores_mcpu`, `memory_bytes`, and `storage_gib` which are the actual resources allocated. I think this will be simpler and more understandable. Resources are computed in the front end now and the worker just uses the values from the front end (no more doing conversions on both the worker and front end). I kept backwards compatibility on the worker for now which can get deleted once there are no more jobs with batch format version < 6. I bumped the instance version to 16 so we know which workers have the new storage functionality. . I tested this by submitting 4 jobs on my 1 core test instance with 150Gi requests. I then looked at the worker logs to make sure the disks were created correctly and the value of the semaphore was correct. I also tested 0 Gi and 5 Gi by hand to make sure the resource fulfilled was 0Gi and 10Gi respectively. Lastly, I checked the billing to make sure we charged for the fraction of the SSD used as well as the cost of adding an extra persistent SSD for that job. I also looked at the disks in the GCE console to make sure they wear torn down correctly. Although there isn't a migration, we should make sure there are no non-ci jobs running so that we don't over allocate the storage available. Also, once this is merged, we should send an email to all users to let them know the cores must be a power of 2 now and about the storage now being mounted at '/io`. I put the WIP tag on so I can do this when I'm ready to.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10090
https://github.com/hail-is/hail/pull/10090:1066,Testability,test,test,1066,"This is a newer version of #9598. We decided to give users min(5Gi/core, 5 Gi) in `/` with mounting external storage at `/io` if they need more storage. All storage requests can be 0, 0 < storage < 10 will be rounded up to 10 Gi, or 10+Gi rounded up to the nearest integer. I added a loop to remove orphaned disks in gce.py. I changed how the resources appear in the spec. Now there's `req_cpu`, `req_storage`, `req_memory` which stores what the user specified. Then we also have `cores_mcpu`, `memory_bytes`, and `storage_gib` which are the actual resources allocated. I think this will be simpler and more understandable. Resources are computed in the front end now and the worker just uses the values from the front end (no more doing conversions on both the worker and front end). I kept backwards compatibility on the worker for now which can get deleted once there are no more jobs with batch format version < 6. I bumped the instance version to 16 so we know which workers have the new storage functionality. . I tested this by submitting 4 jobs on my 1 core test instance with 150Gi requests. I then looked at the worker logs to make sure the disks were created correctly and the value of the semaphore was correct. I also tested 0 Gi and 5 Gi by hand to make sure the resource fulfilled was 0Gi and 10Gi respectively. Lastly, I checked the billing to make sure we charged for the fraction of the SSD used as well as the cost of adding an extra persistent SSD for that job. I also looked at the disks in the GCE console to make sure they wear torn down correctly. Although there isn't a migration, we should make sure there are no non-ci jobs running so that we don't over allocate the storage available. Also, once this is merged, we should send an email to all users to let them know the cores must be a power of 2 now and about the storage now being mounted at '/io`. I put the WIP tag on so I can do this when I'm ready to.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10090
https://github.com/hail-is/hail/pull/10090:1129,Testability,log,logs,1129,"This is a newer version of #9598. We decided to give users min(5Gi/core, 5 Gi) in `/` with mounting external storage at `/io` if they need more storage. All storage requests can be 0, 0 < storage < 10 will be rounded up to 10 Gi, or 10+Gi rounded up to the nearest integer. I added a loop to remove orphaned disks in gce.py. I changed how the resources appear in the spec. Now there's `req_cpu`, `req_storage`, `req_memory` which stores what the user specified. Then we also have `cores_mcpu`, `memory_bytes`, and `storage_gib` which are the actual resources allocated. I think this will be simpler and more understandable. Resources are computed in the front end now and the worker just uses the values from the front end (no more doing conversions on both the worker and front end). I kept backwards compatibility on the worker for now which can get deleted once there are no more jobs with batch format version < 6. I bumped the instance version to 16 so we know which workers have the new storage functionality. . I tested this by submitting 4 jobs on my 1 core test instance with 150Gi requests. I then looked at the worker logs to make sure the disks were created correctly and the value of the semaphore was correct. I also tested 0 Gi and 5 Gi by hand to make sure the resource fulfilled was 0Gi and 10Gi respectively. Lastly, I checked the billing to make sure we charged for the fraction of the SSD used as well as the cost of adding an extra persistent SSD for that job. I also looked at the disks in the GCE console to make sure they wear torn down correctly. Although there isn't a migration, we should make sure there are no non-ci jobs running so that we don't over allocate the storage available. Also, once this is merged, we should send an email to all users to let them know the cores must be a power of 2 now and about the storage now being mounted at '/io`. I put the WIP tag on so I can do this when I'm ready to.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10090
https://github.com/hail-is/hail/pull/10090:1231,Testability,test,tested,1231,"This is a newer version of #9598. We decided to give users min(5Gi/core, 5 Gi) in `/` with mounting external storage at `/io` if they need more storage. All storage requests can be 0, 0 < storage < 10 will be rounded up to 10 Gi, or 10+Gi rounded up to the nearest integer. I added a loop to remove orphaned disks in gce.py. I changed how the resources appear in the spec. Now there's `req_cpu`, `req_storage`, `req_memory` which stores what the user specified. Then we also have `cores_mcpu`, `memory_bytes`, and `storage_gib` which are the actual resources allocated. I think this will be simpler and more understandable. Resources are computed in the front end now and the worker just uses the values from the front end (no more doing conversions on both the worker and front end). I kept backwards compatibility on the worker for now which can get deleted once there are no more jobs with batch format version < 6. I bumped the instance version to 16 so we know which workers have the new storage functionality. . I tested this by submitting 4 jobs on my 1 core test instance with 150Gi requests. I then looked at the worker logs to make sure the disks were created correctly and the value of the semaphore was correct. I also tested 0 Gi and 5 Gi by hand to make sure the resource fulfilled was 0Gi and 10Gi respectively. Lastly, I checked the billing to make sure we charged for the fraction of the SSD used as well as the cost of adding an extra persistent SSD for that job. I also looked at the disks in the GCE console to make sure they wear torn down correctly. Although there isn't a migration, we should make sure there are no non-ci jobs running so that we don't over allocate the storage available. Also, once this is merged, we should send an email to all users to let them know the cores must be a power of 2 now and about the storage now being mounted at '/io`. I put the WIP tag on so I can do this when I'm ready to.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10090
https://github.com/hail-is/hail/pull/10090:591,Usability,simpl,simpler,591,"This is a newer version of #9598. We decided to give users min(5Gi/core, 5 Gi) in `/` with mounting external storage at `/io` if they need more storage. All storage requests can be 0, 0 < storage < 10 will be rounded up to 10 Gi, or 10+Gi rounded up to the nearest integer. I added a loop to remove orphaned disks in gce.py. I changed how the resources appear in the spec. Now there's `req_cpu`, `req_storage`, `req_memory` which stores what the user specified. Then we also have `cores_mcpu`, `memory_bytes`, and `storage_gib` which are the actual resources allocated. I think this will be simpler and more understandable. Resources are computed in the front end now and the worker just uses the values from the front end (no more doing conversions on both the worker and front end). I kept backwards compatibility on the worker for now which can get deleted once there are no more jobs with batch format version < 6. I bumped the instance version to 16 so we know which workers have the new storage functionality. . I tested this by submitting 4 jobs on my 1 core test instance with 150Gi requests. I then looked at the worker logs to make sure the disks were created correctly and the value of the semaphore was correct. I also tested 0 Gi and 5 Gi by hand to make sure the resource fulfilled was 0Gi and 10Gi respectively. Lastly, I checked the billing to make sure we charged for the fraction of the SSD used as well as the cost of adding an extra persistent SSD for that job. I also looked at the disks in the GCE console to make sure they wear torn down correctly. Although there isn't a migration, we should make sure there are no non-ci jobs running so that we don't over allocate the storage available. Also, once this is merged, we should send an email to all users to let them know the cores must be a power of 2 now and about the storage now being mounted at '/io`. I put the WIP tag on so I can do this when I'm ready to.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10090
https://github.com/hail-is/hail/pull/10095:4,Availability,error,errorId,4,"Add errorId tracking to MakeNDArray, allowing user to get a good python error highlighting where an error is thrown from.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10095
https://github.com/hail-is/hail/pull/10095:72,Availability,error,error,72,"Add errorId tracking to MakeNDArray, allowing user to get a good python error highlighting where an error is thrown from.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10095
https://github.com/hail-is/hail/pull/10095:100,Availability,error,error,100,"Add errorId tracking to MakeNDArray, allowing user to get a good python error highlighting where an error is thrown from.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10095
https://github.com/hail-is/hail/pull/10099:62,Performance,cache,cache,62,I was asked to agree to some license after clearing my gradle cache. I do not think anyone needs this.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10099
https://github.com/hail-is/hail/pull/10099:43,Usability,clear,clearing,43,I was asked to agree to some license after clearing my gradle cache. I do not think anyone needs this.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10099
https://github.com/hail-is/hail/pull/10100:858,Availability,error,error,858,"One more time, with feeling! (was: #10072). - [x] (@tpoterba) a1f3b2a5c9 add fails_service_backend; - [ ] (@tpoterba, @cseed) dc0bee7ce1 [hail] introduce and use mktemp and mktempd; - [ ] (@tpoterba) 4b663be367 [hail] make is.hail.expr.ir.functions threadsafe; - [ ] (@tpoterba) d3c1f0987c [hail] fix use of row requiredness in lowerDistributedSort; - [ ] (@catoverdrive) aab6ba98be [query-service] handle void-typed IRs in query-service; - [ ] (@catoverdrive) a1619cff36 [query-service] make user cache thread-safe; - [ ] (@tpoterba) c315fcb0b1 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) 912c21f709 [shuffler] log ShuffleCodecSpec anytime it is created; - [x] (@daniel-goldstein) c2495837e7 [scala-lsm] bugfix: least key may equal greatest key; - [x] (@daniel-goldstein) 5fb3db703e [services] discovered new transient error; - [x] (@daniel-goldstein) 9cd0999938 [shuffler] more assertions in ShuffleClient; - [x] (@daniel-goldstein) a71a3c9b8c [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [x] (@daniel-goldstein) 41b06aeaa8 [query-service] move hail.jar earlier in Dockerfile; - [x] (@daniel-goldstein) 8df4029698 [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 0354e1f557 [query-service] simplify socket handling; - [x] (@jigold) 6690a4decc [batch] teach JVMJob where to find the hail configuration files; - [x] (@daniel-goldstein) ae2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x]",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:2324,Availability,error,error,2324,"e2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x] (@daniel-goldstein) 7f1b1363e9 [query-service] use two containers sharing an empty volume; - [x] (@daniel-goldstein) 2a8f23404a [query-service] in the service, log everything to stdout; - [x] (trivial) d8104a1dc4 [query-service] do not catch CancelledError; - [x] (trivial) efcb345185 [query-service] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdri",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:4133,Availability,error,errors,4133,"ice] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdrive) c985d3e3de [query-service] remove old test code; - [ ] (@catoverdrive) 0a5dc8c651 [query-service] all operations are idempotent; - [ ] (@cseed) 6d02d173fa [make] fix config.mk; - [x] (@daniel-goldstein) d21df54e63 [devbin] teach devbin/functions.py about multiple containers; - [x] (@jigold) 38878f7874 [batch] remove batch_worker_image false dependency on service_base_image; - [x] (@daniel-goldstein) f03defab3d [java-services] avoid NPEs in isTransientError; - [x] (@jigold) e535bdc00d [dependencies] upgrade gcsfs to 0.7.2 to fix GoogleFS rmtree issue; - [x] (@cseed) 743b5ba62f [query-service] enable auto-scaling for PR and dev deploy; - [ ] (@cseed) 6a52d45f6f [query-service] retry EndOfStream errors from java; - [ ] (@jigold) 5853a0bec4 [batch] remove restrictions on PR and dev batch pools; - [ ] (@cseed) 035b19642a [query-service] resolve last two issues",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:1378,Deployability,configurat,configuration,1378,"service] make user cache thread-safe; - [ ] (@tpoterba) c315fcb0b1 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) 912c21f709 [shuffler] log ShuffleCodecSpec anytime it is created; - [x] (@daniel-goldstein) c2495837e7 [scala-lsm] bugfix: least key may equal greatest key; - [x] (@daniel-goldstein) 5fb3db703e [services] discovered new transient error; - [x] (@daniel-goldstein) 9cd0999938 [shuffler] more assertions in ShuffleClient; - [x] (@daniel-goldstein) a71a3c9b8c [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [x] (@daniel-goldstein) 41b06aeaa8 [query-service] move hail.jar earlier in Dockerfile; - [x] (@daniel-goldstein) 8df4029698 [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 0354e1f557 [query-service] simplify socket handling; - [x] (@jigold) 6690a4decc [batch] teach JVMJob where to find the hail configuration files; - [x] (@daniel-goldstein) ae2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x] (@daniel-goldstein) 7f1b1363e9 [query-service] use two containers sharing an empty volume; - [x] (@daniel-goldstein) 2a8f23404a [query-service] in the service, log everything to stdout; - [x] (trivial) d8104a1dc4 [query-service] do not catch CancelledError; - [x] (trivial) efcb345185 [query-service] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:3935,Deployability,upgrade,upgrade,3935,"ice] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdrive) c985d3e3de [query-service] remove old test code; - [ ] (@catoverdrive) 0a5dc8c651 [query-service] all operations are idempotent; - [ ] (@cseed) 6d02d173fa [make] fix config.mk; - [x] (@daniel-goldstein) d21df54e63 [devbin] teach devbin/functions.py about multiple containers; - [x] (@jigold) 38878f7874 [batch] remove batch_worker_image false dependency on service_base_image; - [x] (@daniel-goldstein) f03defab3d [java-services] avoid NPEs in isTransientError; - [x] (@jigold) e535bdc00d [dependencies] upgrade gcsfs to 0.7.2 to fix GoogleFS rmtree issue; - [x] (@cseed) 743b5ba62f [query-service] enable auto-scaling for PR and dev deploy; - [ ] (@cseed) 6a52d45f6f [query-service] retry EndOfStream errors from java; - [ ] (@jigold) 5853a0bec4 [batch] remove restrictions on PR and dev batch pools; - [ ] (@cseed) 035b19642a [query-service] resolve last two issues",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:4065,Deployability,deploy,deploy,4065,"ice] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdrive) c985d3e3de [query-service] remove old test code; - [ ] (@catoverdrive) 0a5dc8c651 [query-service] all operations are idempotent; - [ ] (@cseed) 6d02d173fa [make] fix config.mk; - [x] (@daniel-goldstein) d21df54e63 [devbin] teach devbin/functions.py about multiple containers; - [x] (@jigold) 38878f7874 [batch] remove batch_worker_image false dependency on service_base_image; - [x] (@daniel-goldstein) f03defab3d [java-services] avoid NPEs in isTransientError; - [x] (@jigold) e535bdc00d [dependencies] upgrade gcsfs to 0.7.2 to fix GoogleFS rmtree issue; - [x] (@cseed) 743b5ba62f [query-service] enable auto-scaling for PR and dev deploy; - [ ] (@cseed) 6a52d45f6f [query-service] retry EndOfStream errors from java; - [ ] (@jigold) 5853a0bec4 [batch] remove restrictions on PR and dev batch pools; - [ ] (@cseed) 035b19642a [query-service] resolve last two issues",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:3286,Energy Efficiency,reduce,reduce,3286,"in the service, log everything to stdout; - [x] (trivial) d8104a1dc4 [query-service] do not catch CancelledError; - [x] (trivial) efcb345185 [query-service] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdrive) c985d3e3de [query-service] remove old test code; - [ ] (@catoverdrive) 0a5dc8c651 [query-service] all operations are idempotent; - [ ] (@cseed) 6d02d173fa [make] fix config.mk; - [x] (@daniel-goldstein) d21df54e63 [devbin] teach devbin/functions.py about multiple containers; - [x] (@jigold) 38878f7874 [batch] remove batch_worker_image false dependency on service_base_image; - [x] (@daniel-goldstein) f03defab3d [java-services] avoid NPEs in isTransientError; - [x] (@jigold) e535bdc00d [dependencies] upgrade gcsfs to 0.7.2 to fix GoogleFS rmtree issue; - [x] (@cseed) 743b5ba62f [query-service] enable auto-scaling for PR and dev deploy; - [ ] (@cseed) 6a52d45f6f [query-service] retry EndOfStream errors from j",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:2330,Integrability,message,message,2330,"e2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x] (@daniel-goldstein) 7f1b1363e9 [query-service] use two containers sharing an empty volume; - [x] (@daniel-goldstein) 2a8f23404a [query-service] in the service, log everything to stdout; - [x] (trivial) d8104a1dc4 [query-service] do not catch CancelledError; - [x] (trivial) efcb345185 [query-service] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdri",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:3774,Integrability,depend,dependency,3774,"ice] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdrive) c985d3e3de [query-service] remove old test code; - [ ] (@catoverdrive) 0a5dc8c651 [query-service] all operations are idempotent; - [ ] (@cseed) 6d02d173fa [make] fix config.mk; - [x] (@daniel-goldstein) d21df54e63 [devbin] teach devbin/functions.py about multiple containers; - [x] (@jigold) 38878f7874 [batch] remove batch_worker_image false dependency on service_base_image; - [x] (@daniel-goldstein) f03defab3d [java-services] avoid NPEs in isTransientError; - [x] (@jigold) e535bdc00d [dependencies] upgrade gcsfs to 0.7.2 to fix GoogleFS rmtree issue; - [x] (@cseed) 743b5ba62f [query-service] enable auto-scaling for PR and dev deploy; - [ ] (@cseed) 6a52d45f6f [query-service] retry EndOfStream errors from java; - [ ] (@jigold) 5853a0bec4 [batch] remove restrictions on PR and dev batch pools; - [ ] (@cseed) 035b19642a [query-service] resolve last two issues",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:3921,Integrability,depend,dependencies,3921,"ice] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdrive) c985d3e3de [query-service] remove old test code; - [ ] (@catoverdrive) 0a5dc8c651 [query-service] all operations are idempotent; - [ ] (@cseed) 6d02d173fa [make] fix config.mk; - [x] (@daniel-goldstein) d21df54e63 [devbin] teach devbin/functions.py about multiple containers; - [x] (@jigold) 38878f7874 [batch] remove batch_worker_image false dependency on service_base_image; - [x] (@daniel-goldstein) f03defab3d [java-services] avoid NPEs in isTransientError; - [x] (@jigold) e535bdc00d [dependencies] upgrade gcsfs to 0.7.2 to fix GoogleFS rmtree issue; - [x] (@cseed) 743b5ba62f [query-service] enable auto-scaling for PR and dev deploy; - [ ] (@cseed) 6a52d45f6f [query-service] retry EndOfStream errors from java; - [ ] (@jigold) 5853a0bec4 [batch] remove restrictions on PR and dev batch pools; - [ ] (@cseed) 035b19642a [query-service] resolve last two issues",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:1378,Modifiability,config,configuration,1378,"service] make user cache thread-safe; - [ ] (@tpoterba) c315fcb0b1 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) 912c21f709 [shuffler] log ShuffleCodecSpec anytime it is created; - [x] (@daniel-goldstein) c2495837e7 [scala-lsm] bugfix: least key may equal greatest key; - [x] (@daniel-goldstein) 5fb3db703e [services] discovered new transient error; - [x] (@daniel-goldstein) 9cd0999938 [shuffler] more assertions in ShuffleClient; - [x] (@daniel-goldstein) a71a3c9b8c [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [x] (@daniel-goldstein) 41b06aeaa8 [query-service] move hail.jar earlier in Dockerfile; - [x] (@daniel-goldstein) 8df4029698 [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 0354e1f557 [query-service] simplify socket handling; - [x] (@jigold) 6690a4decc [batch] teach JVMJob where to find the hail configuration files; - [x] (@daniel-goldstein) ae2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x] (@daniel-goldstein) 7f1b1363e9 [query-service] use two containers sharing an empty volume; - [x] (@daniel-goldstein) 2a8f23404a [query-service] in the service, log everything to stdout; - [x] (trivial) d8104a1dc4 [query-service] do not catch CancelledError; - [x] (trivial) efcb345185 [query-service] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:3597,Modifiability,config,config,3597,"ice] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdrive) c985d3e3de [query-service] remove old test code; - [ ] (@catoverdrive) 0a5dc8c651 [query-service] all operations are idempotent; - [ ] (@cseed) 6d02d173fa [make] fix config.mk; - [x] (@daniel-goldstein) d21df54e63 [devbin] teach devbin/functions.py about multiple containers; - [x] (@jigold) 38878f7874 [batch] remove batch_worker_image false dependency on service_base_image; - [x] (@daniel-goldstein) f03defab3d [java-services] avoid NPEs in isTransientError; - [x] (@jigold) e535bdc00d [dependencies] upgrade gcsfs to 0.7.2 to fix GoogleFS rmtree issue; - [x] (@cseed) 743b5ba62f [query-service] enable auto-scaling for PR and dev deploy; - [ ] (@cseed) 6a52d45f6f [query-service] retry EndOfStream errors from java; - [ ] (@jigold) 5853a0bec4 [batch] remove restrictions on PR and dev batch pools; - [ ] (@cseed) 035b19642a [query-service] resolve last two issues",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:498,Performance,cache,cache,498,"One more time, with feeling! (was: #10072). - [x] (@tpoterba) a1f3b2a5c9 add fails_service_backend; - [ ] (@tpoterba, @cseed) dc0bee7ce1 [hail] introduce and use mktemp and mktempd; - [ ] (@tpoterba) 4b663be367 [hail] make is.hail.expr.ir.functions threadsafe; - [ ] (@tpoterba) d3c1f0987c [hail] fix use of row requiredness in lowerDistributedSort; - [ ] (@catoverdrive) aab6ba98be [query-service] handle void-typed IRs in query-service; - [ ] (@catoverdrive) a1619cff36 [query-service] make user cache thread-safe; - [ ] (@tpoterba) c315fcb0b1 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) 912c21f709 [shuffler] log ShuffleCodecSpec anytime it is created; - [x] (@daniel-goldstein) c2495837e7 [scala-lsm] bugfix: least key may equal greatest key; - [x] (@daniel-goldstein) 5fb3db703e [services] discovered new transient error; - [x] (@daniel-goldstein) 9cd0999938 [shuffler] more assertions in ShuffleClient; - [x] (@daniel-goldstein) a71a3c9b8c [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [x] (@daniel-goldstein) 41b06aeaa8 [query-service] move hail.jar earlier in Dockerfile; - [x] (@daniel-goldstein) 8df4029698 [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 0354e1f557 [query-service] simplify socket handling; - [x] (@jigold) 6690a4decc [batch] teach JVMJob where to find the hail configuration files; - [x] (@daniel-goldstein) ae2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x]",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:3045,Performance,race condition,race conditions,3045,"in the service, log everything to stdout; - [x] (trivial) d8104a1dc4 [query-service] do not catch CancelledError; - [x] (trivial) efcb345185 [query-service] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdrive) c985d3e3de [query-service] remove old test code; - [ ] (@catoverdrive) 0a5dc8c651 [query-service] all operations are idempotent; - [ ] (@cseed) 6d02d173fa [make] fix config.mk; - [x] (@daniel-goldstein) d21df54e63 [devbin] teach devbin/functions.py about multiple containers; - [x] (@jigold) 38878f7874 [batch] remove batch_worker_image false dependency on service_base_image; - [x] (@daniel-goldstein) f03defab3d [java-services] avoid NPEs in isTransientError; - [x] (@jigold) e535bdc00d [dependencies] upgrade gcsfs to 0.7.2 to fix GoogleFS rmtree issue; - [x] (@cseed) 743b5ba62f [query-service] enable auto-scaling for PR and dev deploy; - [ ] (@cseed) 6a52d45f6f [query-service] retry EndOfStream errors from j",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:511,Safety,safe,safe,511,"One more time, with feeling! (was: #10072). - [x] (@tpoterba) a1f3b2a5c9 add fails_service_backend; - [ ] (@tpoterba, @cseed) dc0bee7ce1 [hail] introduce and use mktemp and mktempd; - [ ] (@tpoterba) 4b663be367 [hail] make is.hail.expr.ir.functions threadsafe; - [ ] (@tpoterba) d3c1f0987c [hail] fix use of row requiredness in lowerDistributedSort; - [ ] (@catoverdrive) aab6ba98be [query-service] handle void-typed IRs in query-service; - [ ] (@catoverdrive) a1619cff36 [query-service] make user cache thread-safe; - [ ] (@tpoterba) c315fcb0b1 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) 912c21f709 [shuffler] log ShuffleCodecSpec anytime it is created; - [x] (@daniel-goldstein) c2495837e7 [scala-lsm] bugfix: least key may equal greatest key; - [x] (@daniel-goldstein) 5fb3db703e [services] discovered new transient error; - [x] (@daniel-goldstein) 9cd0999938 [shuffler] more assertions in ShuffleClient; - [x] (@daniel-goldstein) a71a3c9b8c [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [x] (@daniel-goldstein) 41b06aeaa8 [query-service] move hail.jar earlier in Dockerfile; - [x] (@daniel-goldstein) 8df4029698 [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 0354e1f557 [query-service] simplify socket handling; - [x] (@jigold) 6690a4decc [batch] teach JVMJob where to find the hail configuration files; - [x] (@daniel-goldstein) ae2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x]",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:2785,Safety,avoid,avoid,2785,"e2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x] (@daniel-goldstein) 7f1b1363e9 [query-service] use two containers sharing an empty volume; - [x] (@daniel-goldstein) 2a8f23404a [query-service] in the service, log everything to stdout; - [x] (trivial) d8104a1dc4 [query-service] do not catch CancelledError; - [x] (trivial) efcb345185 [query-service] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdri",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:3140,Safety,safe,safe,3140,"in the service, log everything to stdout; - [x] (trivial) d8104a1dc4 [query-service] do not catch CancelledError; - [x] (trivial) efcb345185 [query-service] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdrive) c985d3e3de [query-service] remove old test code; - [ ] (@catoverdrive) 0a5dc8c651 [query-service] all operations are idempotent; - [ ] (@cseed) 6d02d173fa [make] fix config.mk; - [x] (@daniel-goldstein) d21df54e63 [devbin] teach devbin/functions.py about multiple containers; - [x] (@jigold) 38878f7874 [batch] remove batch_worker_image false dependency on service_base_image; - [x] (@daniel-goldstein) f03defab3d [java-services] avoid NPEs in isTransientError; - [x] (@jigold) e535bdc00d [dependencies] upgrade gcsfs to 0.7.2 to fix GoogleFS rmtree issue; - [x] (@cseed) 743b5ba62f [query-service] enable auto-scaling for PR and dev deploy; - [ ] (@cseed) 6a52d45f6f [query-service] retry EndOfStream errors from j",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:3861,Safety,avoid,avoid,3861,"ice] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdrive) c985d3e3de [query-service] remove old test code; - [ ] (@catoverdrive) 0a5dc8c651 [query-service] all operations are idempotent; - [ ] (@cseed) 6d02d173fa [make] fix config.mk; - [x] (@daniel-goldstein) d21df54e63 [devbin] teach devbin/functions.py about multiple containers; - [x] (@jigold) 38878f7874 [batch] remove batch_worker_image false dependency on service_base_image; - [x] (@daniel-goldstein) f03defab3d [java-services] avoid NPEs in isTransientError; - [x] (@jigold) e535bdc00d [dependencies] upgrade gcsfs to 0.7.2 to fix GoogleFS rmtree issue; - [x] (@cseed) 743b5ba62f [query-service] enable auto-scaling for PR and dev deploy; - [ ] (@cseed) 6a52d45f6f [query-service] retry EndOfStream errors from java; - [ ] (@jigold) 5853a0bec4 [batch] remove restrictions on PR and dev batch pools; - [ ] (@cseed) 035b19642a [query-service] resolve last two issues",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:650,Testability,log,log,650,"One more time, with feeling! (was: #10072). - [x] (@tpoterba) a1f3b2a5c9 add fails_service_backend; - [ ] (@tpoterba, @cseed) dc0bee7ce1 [hail] introduce and use mktemp and mktempd; - [ ] (@tpoterba) 4b663be367 [hail] make is.hail.expr.ir.functions threadsafe; - [ ] (@tpoterba) d3c1f0987c [hail] fix use of row requiredness in lowerDistributedSort; - [ ] (@catoverdrive) aab6ba98be [query-service] handle void-typed IRs in query-service; - [ ] (@catoverdrive) a1619cff36 [query-service] make user cache thread-safe; - [ ] (@tpoterba) c315fcb0b1 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) 912c21f709 [shuffler] log ShuffleCodecSpec anytime it is created; - [x] (@daniel-goldstein) c2495837e7 [scala-lsm] bugfix: least key may equal greatest key; - [x] (@daniel-goldstein) 5fb3db703e [services] discovered new transient error; - [x] (@daniel-goldstein) 9cd0999938 [shuffler] more assertions in ShuffleClient; - [x] (@daniel-goldstein) a71a3c9b8c [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [x] (@daniel-goldstein) 41b06aeaa8 [query-service] move hail.jar earlier in Dockerfile; - [x] (@daniel-goldstein) 8df4029698 [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 0354e1f557 [query-service] simplify socket handling; - [x] (@jigold) 6690a4decc [batch] teach JVMJob where to find the hail configuration files; - [x] (@daniel-goldstein) ae2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x]",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:918,Testability,assert,assertions,918,"One more time, with feeling! (was: #10072). - [x] (@tpoterba) a1f3b2a5c9 add fails_service_backend; - [ ] (@tpoterba, @cseed) dc0bee7ce1 [hail] introduce and use mktemp and mktempd; - [ ] (@tpoterba) 4b663be367 [hail] make is.hail.expr.ir.functions threadsafe; - [ ] (@tpoterba) d3c1f0987c [hail] fix use of row requiredness in lowerDistributedSort; - [ ] (@catoverdrive) aab6ba98be [query-service] handle void-typed IRs in query-service; - [ ] (@catoverdrive) a1619cff36 [query-service] make user cache thread-safe; - [ ] (@tpoterba) c315fcb0b1 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) 912c21f709 [shuffler] log ShuffleCodecSpec anytime it is created; - [x] (@daniel-goldstein) c2495837e7 [scala-lsm] bugfix: least key may equal greatest key; - [x] (@daniel-goldstein) 5fb3db703e [services] discovered new transient error; - [x] (@daniel-goldstein) 9cd0999938 [shuffler] more assertions in ShuffleClient; - [x] (@daniel-goldstein) a71a3c9b8c [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [x] (@daniel-goldstein) 41b06aeaa8 [query-service] move hail.jar earlier in Dockerfile; - [x] (@daniel-goldstein) 8df4029698 [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 0354e1f557 [query-service] simplify socket handling; - [x] (@jigold) 6690a4decc [batch] teach JVMJob where to find the hail configuration files; - [x] (@daniel-goldstein) ae2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x]",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:1485,Testability,log,logging,1485,"service] make user cache thread-safe; - [ ] (@tpoterba) c315fcb0b1 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) 912c21f709 [shuffler] log ShuffleCodecSpec anytime it is created; - [x] (@daniel-goldstein) c2495837e7 [scala-lsm] bugfix: least key may equal greatest key; - [x] (@daniel-goldstein) 5fb3db703e [services] discovered new transient error; - [x] (@daniel-goldstein) 9cd0999938 [shuffler] more assertions in ShuffleClient; - [x] (@daniel-goldstein) a71a3c9b8c [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [x] (@daniel-goldstein) 41b06aeaa8 [query-service] move hail.jar earlier in Dockerfile; - [x] (@daniel-goldstein) 8df4029698 [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 0354e1f557 [query-service] simplify socket handling; - [x] (@jigold) 6690a4decc [batch] teach JVMJob where to find the hail configuration files; - [x] (@daniel-goldstein) ae2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x] (@daniel-goldstein) 7f1b1363e9 [query-service] use two containers sharing an empty volume; - [x] (@daniel-goldstein) 2a8f23404a [query-service] in the service, log everything to stdout; - [x] (trivial) d8104a1dc4 [query-service] do not catch CancelledError; - [x] (trivial) efcb345185 [query-service] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:1767,Testability,test,tests,1767,"service] make user cache thread-safe; - [ ] (@tpoterba) c315fcb0b1 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) 912c21f709 [shuffler] log ShuffleCodecSpec anytime it is created; - [x] (@daniel-goldstein) c2495837e7 [scala-lsm] bugfix: least key may equal greatest key; - [x] (@daniel-goldstein) 5fb3db703e [services] discovered new transient error; - [x] (@daniel-goldstein) 9cd0999938 [shuffler] more assertions in ShuffleClient; - [x] (@daniel-goldstein) a71a3c9b8c [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [x] (@daniel-goldstein) 41b06aeaa8 [query-service] move hail.jar earlier in Dockerfile; - [x] (@daniel-goldstein) 8df4029698 [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 0354e1f557 [query-service] simplify socket handling; - [x] (@jigold) 6690a4decc [batch] teach JVMJob where to find the hail configuration files; - [x] (@daniel-goldstein) ae2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x] (@daniel-goldstein) 7f1b1363e9 [query-service] use two containers sharing an empty volume; - [x] (@daniel-goldstein) 2a8f23404a [query-service] in the service, log everything to stdout; - [x] (trivial) d8104a1dc4 [query-service] do not catch CancelledError; - [x] (trivial) efcb345185 [query-service] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:2162,Testability,log,log,2162,"e2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x] (@daniel-goldstein) 7f1b1363e9 [query-service] use two containers sharing an empty volume; - [x] (@daniel-goldstein) 2a8f23404a [query-service] in the service, log everything to stdout; - [x] (trivial) d8104a1dc4 [query-service] do not catch CancelledError; - [x] (trivial) efcb345185 [query-service] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdri",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:2507,Testability,Log,Logging,2507,"e2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x] (@daniel-goldstein) 7f1b1363e9 [query-service] use two containers sharing an empty volume; - [x] (@daniel-goldstein) 2a8f23404a [query-service] in the service, log everything to stdout; - [x] (trivial) d8104a1dc4 [query-service] do not catch CancelledError; - [x] (trivial) efcb345185 [query-service] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdri",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:2697,Testability,test,testing,2697,"e2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x] (@daniel-goldstein) 7f1b1363e9 [query-service] use two containers sharing an empty volume; - [x] (@daniel-goldstein) 2a8f23404a [query-service] in the service, log everything to stdout; - [x] (trivial) d8104a1dc4 [query-service] do not catch CancelledError; - [x] (trivial) efcb345185 [query-service] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdri",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:2889,Testability,log,log,2889,"e2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x] (@daniel-goldstein) 7f1b1363e9 [query-service] use two containers sharing an empty volume; - [x] (@daniel-goldstein) 2a8f23404a [query-service] in the service, log everything to stdout; - [x] (trivial) d8104a1dc4 [query-service] do not catch CancelledError; - [x] (trivial) efcb345185 [query-service] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdri",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:2968,Testability,log,logging,2968,"in the service, log everything to stdout; - [x] (trivial) d8104a1dc4 [query-service] do not catch CancelledError; - [x] (trivial) efcb345185 [query-service] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdrive) c985d3e3de [query-service] remove old test code; - [ ] (@catoverdrive) 0a5dc8c651 [query-service] all operations are idempotent; - [ ] (@cseed) 6d02d173fa [make] fix config.mk; - [x] (@daniel-goldstein) d21df54e63 [devbin] teach devbin/functions.py about multiple containers; - [x] (@jigold) 38878f7874 [batch] remove batch_worker_image false dependency on service_base_image; - [x] (@daniel-goldstein) f03defab3d [java-services] avoid NPEs in isTransientError; - [x] (@jigold) e535bdc00d [dependencies] upgrade gcsfs to 0.7.2 to fix GoogleFS rmtree issue; - [x] (@cseed) 743b5ba62f [query-service] enable auto-scaling for PR and dev deploy; - [ ] (@cseed) 6a52d45f6f [query-service] retry EndOfStream errors from j",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:3469,Testability,test,test,3469,"ice] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f70dd25 [query-service] JSON Logging; - [ ] (@catoverdrive) f5c3ffcbd1 [query-service] pervasively retry all idempotent operations; - [ ] (@tpoterba) 507db4b468 [hail] fix using; - [x] (@jigold) c32a253bb9 [query] when testing, ensure our thread has an event loop; - [ ] (@tpoterba) 110469c2da [query][lir] avoid dumping massive classes onto stderr; - [ ] (@tpoterba) e4aa1c15fe [query] do not print misleading log in RegionPool.finalizer; - [x] (trivial) 33eab9a80e [query-service] better logging information; - [ ] (@catoverdrive) e358e8feeb [query-service] remove race conditions in user management; - [ ] (@tpoterba) b60cb2bae5 [lir] make LIR genName thread-safe; - [ ] (@catoverdrive) 2d82e5faf5 [query-service] send a token for job identifiability; - [x] (@daniel-goldstein) fd78caedcb [query-service] reduce image size by ~2GB; - [ ] (@catoverdrive) 00d1840421 [query-service] retry CLOSE, CLOSED (i.e. connection dropped); - [ ] (@catoverdrive) c985d3e3de [query-service] remove old test code; - [ ] (@catoverdrive) 0a5dc8c651 [query-service] all operations are idempotent; - [ ] (@cseed) 6d02d173fa [make] fix config.mk; - [x] (@daniel-goldstein) d21df54e63 [devbin] teach devbin/functions.py about multiple containers; - [x] (@jigold) 38878f7874 [batch] remove batch_worker_image false dependency on service_base_image; - [x] (@daniel-goldstein) f03defab3d [java-services] avoid NPEs in isTransientError; - [x] (@jigold) e535bdc00d [dependencies] upgrade gcsfs to 0.7.2 to fix GoogleFS rmtree issue; - [x] (@cseed) 743b5ba62f [query-service] enable auto-scaling for PR and dev deploy; - [ ] (@cseed) 6a52d45f6f [query-service] retry EndOfStream errors from java; - [ ] (@jigold) 5853a0bec4 [batch] remove restrictions on PR and dev batch pools; - [ ] (@cseed) 035b19642a [query-service] resolve last two issues",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10100:1281,Usability,simpl,simplify,1281,"service] make user cache thread-safe; - [ ] (@tpoterba) c315fcb0b1 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) 912c21f709 [shuffler] log ShuffleCodecSpec anytime it is created; - [x] (@daniel-goldstein) c2495837e7 [scala-lsm] bugfix: least key may equal greatest key; - [x] (@daniel-goldstein) 5fb3db703e [services] discovered new transient error; - [x] (@daniel-goldstein) 9cd0999938 [shuffler] more assertions in ShuffleClient; - [x] (@daniel-goldstein) a71a3c9b8c [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [x] (@daniel-goldstein) 41b06aeaa8 [query-service] move hail.jar earlier in Dockerfile; - [x] (@daniel-goldstein) 8df4029698 [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 0354e1f557 [query-service] simplify socket handling; - [x] (@jigold) 6690a4decc [batch] teach JVMJob where to find the hail configuration files; - [x] (@daniel-goldstein) ae2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x] (@daniel-goldstein) 7f1b1363e9 [query-service] use two containers sharing an empty volume; - [x] (@daniel-goldstein) 2a8f23404a [query-service] in the service, log everything to stdout; - [x] (trivial) d8104a1dc4 [query-service] do not catch CancelledError; - [x] (trivial) efcb345185 [query-service] slightly more useful error message when socket dies; - [ ] (@tpoterba) f79c4023cf [shuffler] if we have an ExecuteContext, use it; - [x] (@daniel-goldstein,fyi: @tpoterba) 259f",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10100
https://github.com/hail-is/hail/pull/10105:188,Security,hash,hashable,188,"CHANGELOG: Evaluating hail expressions in python will now return `frozendict`, an immutable dictionary type. Sets will return python's `frozenset`. This is necessary because hail supports hashable dicts, but python does not. Same with sets.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10105
https://github.com/hail-is/hail/pull/10106:2785,Availability,error,error,2785," deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": ""https GET /michaelfranklin/query/api/v1alpha/wait done in 50.029999999998836s: 200"", ""remote_address"": ""10.28.127.3"", ""request_start_time"": ""[24/Feb/2021:23:22:35 +0000]"", ""request_duration"": 50.029999999998836, ""response_status"": 200, ""x_real_ip"": ""124.170.20.28"", ""hail_log"": 1}; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,005"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:255"", ""message"": ""Tasks have all completed."", ""hail_log"": 1}; ```. Test duration endpoint; ```python; @routes.get('/api/v1alpha/wait'); async def wait_seconds(request):; """"""; Wait query.duration seconds before returning the request.; """"""; duration = request.query.get('duration'); try:; duration = int(duration); except Exception as e:; return web.json_response({; 'error': f'Invalid parameter duration ""{duration}"": {e}',; }, status=422). await asyncio.sleep(int(duration)); e = os.getenv(""TEST_VALUE"", ""None""); return web.json_response({""d"": f""You waited '{duration}' seconds!!"", ""env"": e}); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:58,Deployability,deploy,deployment,58,"- Add `terminationGracePeriodSeconds` to query kubernetes deployment; - Implement `app.on_shutdown` signal handler to wait for all asyncio tasks to complete before returning.; - Upgrade `aiohttp == 0.7.3` to address tasks being cancelled before the on_shutdown method is called: https://github.com/aio-libs/aiohttp/issues/3593. ## Testing. - Adding a ""wait `n` seconds"" method that slept for n seconds, and returned the value of an environment variable. This environment variable meant I could track which version of the deployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": """,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:178,Deployability,Upgrade,Upgrade,178,"- Add `terminationGracePeriodSeconds` to query kubernetes deployment; - Implement `app.on_shutdown` signal handler to wait for all asyncio tasks to complete before returning.; - Upgrade `aiohttp == 0.7.3` to address tasks being cancelled before the on_shutdown method is called: https://github.com/aio-libs/aiohttp/issues/3593. ## Testing. - Adding a ""wait `n` seconds"" method that slept for n seconds, and returned the value of an environment variable. This environment variable meant I could track which version of the deployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": """,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:521,Deployability,deploy,deployment,521,"- Add `terminationGracePeriodSeconds` to query kubernetes deployment; - Implement `app.on_shutdown` signal handler to wait for all asyncio tasks to complete before returning.; - Upgrade `aiohttp == 0.7.3` to address tasks being cancelled before the on_shutdown method is called: https://github.com/aio-libs/aiohttp/issues/3593. ## Testing. - Adding a ""wait `n` seconds"" method that slept for n seconds, and returned the value of an environment variable. This environment variable meant I could track which version of the deployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": """,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:570,Deployability,deploy,deploy,570,"- Add `terminationGracePeriodSeconds` to query kubernetes deployment; - Implement `app.on_shutdown` signal handler to wait for all asyncio tasks to complete before returning.; - Upgrade `aiohttp == 0.7.3` to address tasks being cancelled before the on_shutdown method is called: https://github.com/aio-libs/aiohttp/issues/3593. ## Testing. - Adding a ""wait `n` seconds"" method that slept for n seconds, and returned the value of an environment variable. This environment variable meant I could track which version of the deployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": """,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:593,Deployability,deploy,deploy,593,"- Add `terminationGracePeriodSeconds` to query kubernetes deployment; - Implement `app.on_shutdown` signal handler to wait for all asyncio tasks to complete before returning.; - Upgrade `aiohttp == 0.7.3` to address tasks being cancelled before the on_shutdown method is called: https://github.com/aio-libs/aiohttp/issues/3593. ## Testing. - Adding a ""wait `n` seconds"" method that slept for n seconds, and returned the value of an environment variable. This environment variable meant I could track which version of the deployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": """,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:623,Deployability,deploy,deploy,623,"- Add `terminationGracePeriodSeconds` to query kubernetes deployment; - Implement `app.on_shutdown` signal handler to wait for all asyncio tasks to complete before returning.; - Upgrade `aiohttp == 0.7.3` to address tasks being cancelled before the on_shutdown method is called: https://github.com/aio-libs/aiohttp/issues/3593. ## Testing. - Adding a ""wait `n` seconds"" method that slept for n seconds, and returned the value of an environment variable. This environment variable meant I could track which version of the deployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": """,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:714,Deployability,deploy,deploy,714,"- Add `terminationGracePeriodSeconds` to query kubernetes deployment; - Implement `app.on_shutdown` signal handler to wait for all asyncio tasks to complete before returning.; - Upgrade `aiohttp == 0.7.3` to address tasks being cancelled before the on_shutdown method is called: https://github.com/aio-libs/aiohttp/issues/3593. ## Testing. - Adding a ""wait `n` seconds"" method that slept for n seconds, and returned the value of an environment variable. This environment variable meant I could track which version of the deployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": """,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:895,Deployability,deploy,deploy,895,"- Add `terminationGracePeriodSeconds` to query kubernetes deployment; - Implement `app.on_shutdown` signal handler to wait for all asyncio tasks to complete before returning.; - Upgrade `aiohttp == 0.7.3` to address tasks being cancelled before the on_shutdown method is called: https://github.com/aio-libs/aiohttp/issues/3593. ## Testing. - Adding a ""wait `n` seconds"" method that slept for n seconds, and returned the value of an environment variable. This environment variable meant I could track which version of the deployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": """,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:953,Deployability,deploy,deploy,953,"- Add `terminationGracePeriodSeconds` to query kubernetes deployment; - Implement `app.on_shutdown` signal handler to wait for all asyncio tasks to complete before returning.; - Upgrade `aiohttp == 0.7.3` to address tasks being cancelled before the on_shutdown method is called: https://github.com/aio-libs/aiohttp/issues/3593. ## Testing. - Adding a ""wait `n` seconds"" method that slept for n seconds, and returned the value of an environment variable. This environment variable meant I could track which version of the deployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": """,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:988,Deployability,rollout,rollout,988,"ment; - Implement `app.on_shutdown` signal handler to wait for all asyncio tasks to complete before returning.; - Upgrade `aiohttp == 0.7.3` to address tasks being cancelled before the on_shutdown method is called: https://github.com/aio-libs/aiohttp/issues/3593. ## Testing. - Adding a ""wait `n` seconds"" method that slept for n seconds, and returned the value of an environment variable. This environment variable meant I could track which version of the deployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": ""https GET /michaelfranklin/query/api/v1alpha/wait done in 50.02",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:1017,Deployability,deploy,deployment,1017,"ment; - Implement `app.on_shutdown` signal handler to wait for all asyncio tasks to complete before returning.; - Upgrade `aiohttp == 0.7.3` to address tasks being cancelled before the on_shutdown method is called: https://github.com/aio-libs/aiohttp/issues/3593. ## Testing. - Adding a ""wait `n` seconds"" method that slept for n seconds, and returned the value of an environment variable. This environment variable meant I could track which version of the deployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": ""https GET /michaelfranklin/query/api/v1alpha/wait done in 50.02",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:1467,Deployability,deploy,deploy,1467,"/3593. ## Testing. - Adding a ""wait `n` seconds"" method that slept for n seconds, and returned the value of an environment variable. This environment variable meant I could track which version of the deployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": ""https GET /michaelfranklin/query/api/v1alpha/wait done in 50.029999999998836s: 200"", ""remote_address"": ""10.28.127.3"", ""request_start_time"": ""[24/Feb/2021:23:22:35 +0000]"", ""request_duration"": 50.029999999998836, ""response_status"": 200, ""x_real_ip"": ""124.170.20.28"", ""hail_log"": 1}; {""severity"": ""INFO"", ""levelname"": ""INF",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:1487,Energy Efficiency,schedul,scheduled,1487,"track which version of the deployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": ""https GET /michaelfranklin/query/api/v1alpha/wait done in 50.029999999998836s: 200"", ""remote_address"": ""10.28.127.3"", ""request_start_time"": ""[24/Feb/2021:23:22:35 +0000]"", ""request_duration"": 50.029999999998836, ""response_status"": 200, ""x_real_ip"": ""124.170.20.28"", ""hail_log"": 1}; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,005"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:255"", ""message"": ""Tasks have all completed."", ""hail_log"": 1}; ```. Test dur",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:1682,Integrability,message,message,1682,".hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": ""https GET /michaelfranklin/query/api/v1alpha/wait done in 50.029999999998836s: 200"", ""remote_address"": ""10.28.127.3"", ""request_start_time"": ""[24/Feb/2021:23:22:35 +0000]"", ""request_duration"": 50.029999999998836, ""response_status"": 200, ""x_real_ip"": ""124.170.20.28"", ""hail_log"": 1}; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,005"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:255"", ""message"": ""Tasks have all completed."", ""hail_log"": 1}; ```. Test duration endpoint; ```python; @routes.get('/api/v1alpha/wait'); async def wait_seconds(request):; """"""; Wait query.duration seconds before returning the request.; """"""; duration = request.query.get('duration'); try:; duration = int(duration); except Exception as e:; return web.json_response({; 'error': f'In",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:1990,Integrability,message,message,1990,"eout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": ""https GET /michaelfranklin/query/api/v1alpha/wait done in 50.029999999998836s: 200"", ""remote_address"": ""10.28.127.3"", ""request_start_time"": ""[24/Feb/2021:23:22:35 +0000]"", ""request_duration"": 50.029999999998836, ""response_status"": 200, ""x_real_ip"": ""124.170.20.28"", ""hail_log"": 1}; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,005"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:255"", ""message"": ""Tasks have all completed."", ""hail_log"": 1}; ```. Test duration endpoint; ```python; @routes.get('/api/v1alpha/wait'); async def wait_seconds(request):; """"""; Wait query.duration seconds before returning the request.; """"""; duration = request.query.get('duration'); try:; duration = int(duration); except Exception as e:; return web.json_response({; 'error': f'Invalid parameter duration ""{duration}"": {e}',; }, status=422). await asyncio.sleep(int(duration)); e = os.getenv(""TEST_VALUE"", ""None""); return web.json_response({""d"": f""You waited '{duration}' seconds!!"", ""env"": e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:2426,Integrability,message,message,2426," deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": ""https GET /michaelfranklin/query/api/v1alpha/wait done in 50.029999999998836s: 200"", ""remote_address"": ""10.28.127.3"", ""request_start_time"": ""[24/Feb/2021:23:22:35 +0000]"", ""request_duration"": 50.029999999998836, ""response_status"": 200, ""x_real_ip"": ""124.170.20.28"", ""hail_log"": 1}; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,005"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:255"", ""message"": ""Tasks have all completed."", ""hail_log"": 1}; ```. Test duration endpoint; ```python; @routes.get('/api/v1alpha/wait'); async def wait_seconds(request):; """"""; Wait query.duration seconds before returning the request.; """"""; duration = request.query.get('duration'); try:; duration = int(duration); except Exception as e:; return web.json_response({; 'error': f'Invalid parameter duration ""{duration}"": {e}',; }, status=422). await asyncio.sleep(int(duration)); e = os.getenv(""TEST_VALUE"", ""None""); return web.json_response({""d"": f""You waited '{duration}' seconds!!"", ""env"": e}); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:2522,Integrability,rout,routes,2522," deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": ""https GET /michaelfranklin/query/api/v1alpha/wait done in 50.029999999998836s: 200"", ""remote_address"": ""10.28.127.3"", ""request_start_time"": ""[24/Feb/2021:23:22:35 +0000]"", ""request_duration"": 50.029999999998836, ""response_status"": 200, ""x_real_ip"": ""124.170.20.28"", ""hail_log"": 1}; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,005"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:255"", ""message"": ""Tasks have all completed."", ""hail_log"": 1}; ```. Test duration endpoint; ```python; @routes.get('/api/v1alpha/wait'); async def wait_seconds(request):; """"""; Wait query.duration seconds before returning the request.; """"""; duration = request.query.get('duration'); try:; duration = int(duration); except Exception as e:; return web.json_response({; 'error': f'Invalid parameter duration ""{duration}"": {e}',; }, status=422). await asyncio.sleep(int(duration)); e = os.getenv(""TEST_VALUE"", ""None""); return web.json_response({""d"": f""You waited '{duration}' seconds!!"", ""env"": e}); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:444,Modifiability,variab,variable,444,"- Add `terminationGracePeriodSeconds` to query kubernetes deployment; - Implement `app.on_shutdown` signal handler to wait for all asyncio tasks to complete before returning.; - Upgrade `aiohttp == 0.7.3` to address tasks being cancelled before the on_shutdown method is called: https://github.com/aio-libs/aiohttp/issues/3593. ## Testing. - Adding a ""wait `n` seconds"" method that slept for n seconds, and returned the value of an environment variable. This environment variable meant I could track which version of the deployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": """,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:471,Modifiability,variab,variable,471,"- Add `terminationGracePeriodSeconds` to query kubernetes deployment; - Implement `app.on_shutdown` signal handler to wait for all asyncio tasks to complete before returning.; - Upgrade `aiohttp == 0.7.3` to address tasks being cancelled before the on_shutdown method is called: https://github.com/aio-libs/aiohttp/issues/3593. ## Testing. - Adding a ""wait `n` seconds"" method that slept for n seconds, and returned the value of an environment variable. This environment variable meant I could track which version of the deployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": """,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:667,Modifiability,variab,variable,667,"- Add `terminationGracePeriodSeconds` to query kubernetes deployment; - Implement `app.on_shutdown` signal handler to wait for all asyncio tasks to complete before returning.; - Upgrade `aiohttp == 0.7.3` to address tasks being cancelled before the on_shutdown method is called: https://github.com/aio-libs/aiohttp/issues/3593. ## Testing. - Adding a ""wait `n` seconds"" method that slept for n seconds, and returned the value of an environment variable. This environment variable meant I could track which version of the deployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": """,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:1005,Safety,timeout,timeout,1005,"ment; - Implement `app.on_shutdown` signal handler to wait for all asyncio tasks to complete before returning.; - Upgrade `aiohttp == 0.7.3` to address tasks being cancelled before the on_shutdown method is called: https://github.com/aio-libs/aiohttp/issues/3593. ## Testing. - Adding a ""wait `n` seconds"" method that slept for n seconds, and returned the value of an environment variable. This environment variable meant I could track which version of the deployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": ""https GET /michaelfranklin/query/api/v1alpha/wait done in 50.02",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:331,Testability,Test,Testing,331,"- Add `terminationGracePeriodSeconds` to query kubernetes deployment; - Implement `app.on_shutdown` signal handler to wait for all asyncio tasks to complete before returning.; - Upgrade `aiohttp == 0.7.3` to address tasks being cancelled before the on_shutdown method is called: https://github.com/aio-libs/aiohttp/issues/3593. ## Testing. - Adding a ""wait `n` seconds"" method that slept for n seconds, and returned the value of an environment variable. This environment variable meant I could track which version of the deployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": """,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:1222,Testability,log,logs,1222,"/3593. ## Testing. - Adding a ""wait `n` seconds"" method that slept for n seconds, and returned the value of an environment variable. This environment variable meant I could track which version of the deployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": ""https GET /michaelfranklin/query/api/v1alpha/wait done in 50.029999999998836s: 200"", ""remote_address"": ""10.28.127.3"", ""request_start_time"": ""[24/Feb/2021:23:22:35 +0000]"", ""request_duration"": 50.029999999998836, ""response_status"": 200, ""x_real_ip"": ""124.170.20.28"", ""hail_log"": 1}; {""severity"": ""INFO"", ""levelname"": ""INF",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:1527,Testability,log,logs,1527,"ployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": ""https GET /michaelfranklin/query/api/v1alpha/wait done in 50.029999999998836s: 200"", ""remote_address"": ""10.28.127.3"", ""request_start_time"": ""[24/Feb/2021:23:22:35 +0000]"", ""request_duration"": 50.029999999998836, ""response_status"": 200, ""x_real_ip"": ""124.170.20.28"", ""hail_log"": 1}; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,005"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:255"", ""message"": ""Tasks have all completed."", ""hail_log"": 1}; ```. Test duration endpoint; ```python; @ro",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:1980,Testability,log,log,1980,"eout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": ""https GET /michaelfranklin/query/api/v1alpha/wait done in 50.029999999998836s: 200"", ""remote_address"": ""10.28.127.3"", ""request_start_time"": ""[24/Feb/2021:23:22:35 +0000]"", ""request_duration"": 50.029999999998836, ""response_status"": 200, ""x_real_ip"": ""124.170.20.28"", ""hail_log"": 1}; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,005"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:255"", ""message"": ""Tasks have all completed."", ""hail_log"": 1}; ```. Test duration endpoint; ```python; @routes.get('/api/v1alpha/wait'); async def wait_seconds(request):; """"""; Wait query.duration seconds before returning the request.; """"""; duration = request.query.get('duration'); try:; duration = int(duration); except Exception as e:; return web.json_response({; 'error': f'Invalid parameter duration ""{duration}"": {e}',; }, status=422). await asyncio.sleep(int(duration)); e = os.getenv(""TEST_VALUE"", ""None""); return web.json_response({""d"": f""You waited '{duration}' seconds!!"", ""env"": e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10106:2486,Testability,Test,Test,2486," deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": ""https GET /michaelfranklin/query/api/v1alpha/wait done in 50.029999999998836s: 200"", ""remote_address"": ""10.28.127.3"", ""request_start_time"": ""[24/Feb/2021:23:22:35 +0000]"", ""request_duration"": 50.029999999998836, ""response_status"": 200, ""x_real_ip"": ""124.170.20.28"", ""hail_log"": 1}; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,005"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:255"", ""message"": ""Tasks have all completed."", ""hail_log"": 1}; ```. Test duration endpoint; ```python; @routes.get('/api/v1alpha/wait'); async def wait_seconds(request):; """"""; Wait query.duration seconds before returning the request.; """"""; duration = request.query.get('duration'); try:; duration = int(duration); except Exception as e:; return web.json_response({; 'error': f'Invalid parameter duration ""{duration}"": {e}',; }, status=422). await asyncio.sleep(int(duration)); e = os.getenv(""TEST_VALUE"", ""None""); return web.json_response({""d"": f""You waited '{duration}' seconds!!"", ""env"": e}); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10106
https://github.com/hail-is/hail/pull/10107:109,Deployability,deploy,deployment,109,"Support [Artifact Registry](https://cloud.google.com/artifact-registry) to store images. It's useful for our deployment in Australia, as GCR does not support our continent. With AR, we would save on network egress. The PR adds a `DOCKER_PREFIX` variable, which is passed along in the code together with `GCP_PROJECT` and others. To switch to AR, one would need to modify `DOCKER_PREFIX` in `config.mk`:. ```; REGION := us-central1; DOCKER_PREFIX := gcr.io/$(PROJECT); ```. ```; REGION := australia-southeast1; DOCKER_PREFIX := $(REGION)-docker.pkg.dev/$(PROJECT)/hail; ```. Also, when making an initial deployment with Terraform, there is an extra variable `use_artifact_registry = false` that controls whether to use AR or GCR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10107
https://github.com/hail-is/hail/pull/10107:603,Deployability,deploy,deployment,603,"Support [Artifact Registry](https://cloud.google.com/artifact-registry) to store images. It's useful for our deployment in Australia, as GCR does not support our continent. With AR, we would save on network egress. The PR adds a `DOCKER_PREFIX` variable, which is passed along in the code together with `GCP_PROJECT` and others. To switch to AR, one would need to modify `DOCKER_PREFIX` in `config.mk`:. ```; REGION := us-central1; DOCKER_PREFIX := gcr.io/$(PROJECT); ```. ```; REGION := australia-southeast1; DOCKER_PREFIX := $(REGION)-docker.pkg.dev/$(PROJECT)/hail; ```. Also, when making an initial deployment with Terraform, there is an extra variable `use_artifact_registry = false` that controls whether to use AR or GCR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10107
https://github.com/hail-is/hail/pull/10107:245,Modifiability,variab,variable,245,"Support [Artifact Registry](https://cloud.google.com/artifact-registry) to store images. It's useful for our deployment in Australia, as GCR does not support our continent. With AR, we would save on network egress. The PR adds a `DOCKER_PREFIX` variable, which is passed along in the code together with `GCP_PROJECT` and others. To switch to AR, one would need to modify `DOCKER_PREFIX` in `config.mk`:. ```; REGION := us-central1; DOCKER_PREFIX := gcr.io/$(PROJECT); ```. ```; REGION := australia-southeast1; DOCKER_PREFIX := $(REGION)-docker.pkg.dev/$(PROJECT)/hail; ```. Also, when making an initial deployment with Terraform, there is an extra variable `use_artifact_registry = false` that controls whether to use AR or GCR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10107
https://github.com/hail-is/hail/pull/10107:391,Modifiability,config,config,391,"Support [Artifact Registry](https://cloud.google.com/artifact-registry) to store images. It's useful for our deployment in Australia, as GCR does not support our continent. With AR, we would save on network egress. The PR adds a `DOCKER_PREFIX` variable, which is passed along in the code together with `GCP_PROJECT` and others. To switch to AR, one would need to modify `DOCKER_PREFIX` in `config.mk`:. ```; REGION := us-central1; DOCKER_PREFIX := gcr.io/$(PROJECT); ```. ```; REGION := australia-southeast1; DOCKER_PREFIX := $(REGION)-docker.pkg.dev/$(PROJECT)/hail; ```. Also, when making an initial deployment with Terraform, there is an extra variable `use_artifact_registry = false` that controls whether to use AR or GCR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10107
https://github.com/hail-is/hail/pull/10107:648,Modifiability,variab,variable,648,"Support [Artifact Registry](https://cloud.google.com/artifact-registry) to store images. It's useful for our deployment in Australia, as GCR does not support our continent. With AR, we would save on network egress. The PR adds a `DOCKER_PREFIX` variable, which is passed along in the code together with `GCP_PROJECT` and others. To switch to AR, one would need to modify `DOCKER_PREFIX` in `config.mk`:. ```; REGION := us-central1; DOCKER_PREFIX := gcr.io/$(PROJECT); ```. ```; REGION := australia-southeast1; DOCKER_PREFIX := $(REGION)-docker.pkg.dev/$(PROJECT)/hail; ```. Also, when making an initial deployment with Terraform, there is an extra variable `use_artifact_registry = false` that controls whether to use AR or GCR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10107
https://github.com/hail-is/hail/pull/10114:39,Testability,test,tests,39,My query service PR will replace these tests with a complete test suite anyway. No one relies on; query being correct. Let us stop interrupting PRs with flaky tests.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10114
https://github.com/hail-is/hail/pull/10114:61,Testability,test,test,61,My query service PR will replace these tests with a complete test suite anyway. No one relies on; query being correct. Let us stop interrupting PRs with flaky tests.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10114
https://github.com/hail-is/hail/pull/10114:159,Testability,test,tests,159,My query service PR will replace these tests with a complete test suite anyway. No one relies on; query being correct. Let us stop interrupting PRs with flaky tests.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10114
https://github.com/hail-is/hail/pull/10115:4507,Availability,down,down,4507,"#5228](https://github.com/aio-libs/aiohttp/issues/5228) &lt;https://github.com/aio-libs/aiohttp/issues/5228&gt;</code>_</li>; </ul>; <h2>Misc</h2>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/blob/master/CHANGES.rst"">aiohttp's changelog</a>.</em></p>; <blockquote>; <h1>3.7.4 (2021-02-25)</h1>; <h2>Bugfixes</h2>; <ul>; <li>; <p><strong>(SECURITY BUG)</strong> Started preventing open redirects in the; <code>aiohttp.web.normalize_path_middleware</code> middleware. For; more details, see; <a href=""https://github.com/aio-libs/aiohttp/security/advisories/GHSA-v6wp-4m6f-gcjg"">https://github.com/aio-libs/aiohttp/security/advisories/GHSA-v6wp-4m6f-gcjg</a>.</p>; <p>Thanks to <code>Beast Glatisant &lt;https://github.com/g147&gt;</code>__ for; finding the first instance of this issue and <code>Jelmer Vernoo &lt;https://jelmer.uk/&gt;</code>__ for reporting and tracking it down; in aiohttp.; <code>[#5497](https://github.com/aio-libs/aiohttp/issues/5497) &lt;https://github.com/aio-libs/aiohttp/issues/5497&gt;</code>_</p>; </li>; <li>; <p>Fix interpretation difference of the pure-Python and the Cython-based; HTTP parsers construct a <code>yarl.URL</code> object for HTTP request-target.</p>; <p>Before this fix, the Python parser would turn the URI's absolute-path; for <code>//some-path</code> into <code>/</code> while the Cython code preserved it as; <code>//some-path</code>. Now, both do the latter.; <code>[#5498](https://github.com/aio-libs/aiohttp/issues/5498) &lt;https://github.com/aio-libs/aiohttp/issues/5498&gt;</code>_</p>; </li>; </ul>; <hr />; <h1>3.7.3 (2020-11-18)</h1>; <h2>Features</h2>; <ul>; <li>Use Brotli instead of brotlipy; <code>[#3803](https://github.com/aio-libs/aiohttp/issues/3803) &lt;https://github.com/aio-libs/aiohttp/issues/3803&gt;</code>_</li>; <li>Made exceptions pickleable. Also changed the repr of some exceptions",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:95,Deployability,Release,Release,95,"Bumps [aiohttp](https://github.com/aio-libs/aiohttp) from 3.6.0 to 3.7.4.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/releases"">aiohttp's releases</a>.</em></p>; <blockquote>; <h2>aiohttp 3.7.3 release</h2>; <h2>Features</h2>; <ul>; <li>Use Brotli instead of brotlipy; <code>[#3803](https://github.com/aio-libs/aiohttp/issues/3803) &lt;https://github.com/aio-libs/aiohttp/issues/3803&gt;</code>_</li>; <li>Made exceptions pickleable. Also changed the repr of some exceptions.; <code>[#4077](https://github.com/aio-libs/aiohttp/issues/4077) &lt;https://github.com/aio-libs/aiohttp/issues/4077&gt;</code>_</li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>Raise a ClientResponseError instead of an AssertionError for a blank; HTTP Reason Phrase.; <code>[#3532](https://github.com/aio-libs/aiohttp/issues/3532) &lt;https://github.com/aio-libs/aiohttp/issues/3532&gt;</code>_</li>; <li>Fix <code>web_middlewares.normalize_path_middleware</code> behavior for patch without slash.; <code>[#3669](https://github.com/aio-libs/aiohttp/issues/3669) &lt;https://github.com/aio-libs/aiohttp/issues/3669&gt;</code>_</li>; <li>Fix overshadowing of overlapped sub-applications prefixes.; <code>[#3701](https://github.com/aio-libs/aiohttp/issues/3701) &lt;https://github.com/aio-libs/aiohttp/issues/3701&gt;</code>_</li>; <li>Make <code>BaseConnector.close()</code> a coroutine and wait until the client closes all connections. Drop deprecated &quot;with Connector():&quot; syntax.; <code>[#3736](https://github.com/aio-libs/aiohttp/issues/3736) &lt;https://github.com/aio-libs/aiohttp/issues/3736&gt;</code>_</li>; <li>Reset the <code>sock_read</code> timeout each time data is received for a <code>aiohttp.client</code> response.; <code>[#3808](https://github.com/aio-libs/aiohttp/issues/3808) &lt;https://github.com/aio-libs/aiohttp/issues/3808&gt;</code>_</li>; <li>Fixed type annotation for add_view method of UrlDispatcher to accept any subclass of Vie",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:185,Deployability,release,releases,185,"Bumps [aiohttp](https://github.com/aio-libs/aiohttp) from 3.6.0 to 3.7.4.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/releases"">aiohttp's releases</a>.</em></p>; <blockquote>; <h2>aiohttp 3.7.3 release</h2>; <h2>Features</h2>; <ul>; <li>Use Brotli instead of brotlipy; <code>[#3803](https://github.com/aio-libs/aiohttp/issues/3803) &lt;https://github.com/aio-libs/aiohttp/issues/3803&gt;</code>_</li>; <li>Made exceptions pickleable. Also changed the repr of some exceptions.; <code>[#4077](https://github.com/aio-libs/aiohttp/issues/4077) &lt;https://github.com/aio-libs/aiohttp/issues/4077&gt;</code>_</li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>Raise a ClientResponseError instead of an AssertionError for a blank; HTTP Reason Phrase.; <code>[#3532](https://github.com/aio-libs/aiohttp/issues/3532) &lt;https://github.com/aio-libs/aiohttp/issues/3532&gt;</code>_</li>; <li>Fix <code>web_middlewares.normalize_path_middleware</code> behavior for patch without slash.; <code>[#3669](https://github.com/aio-libs/aiohttp/issues/3669) &lt;https://github.com/aio-libs/aiohttp/issues/3669&gt;</code>_</li>; <li>Fix overshadowing of overlapped sub-applications prefixes.; <code>[#3701](https://github.com/aio-libs/aiohttp/issues/3701) &lt;https://github.com/aio-libs/aiohttp/issues/3701&gt;</code>_</li>; <li>Make <code>BaseConnector.close()</code> a coroutine and wait until the client closes all connections. Drop deprecated &quot;with Connector():&quot; syntax.; <code>[#3736](https://github.com/aio-libs/aiohttp/issues/3736) &lt;https://github.com/aio-libs/aiohttp/issues/3736&gt;</code>_</li>; <li>Reset the <code>sock_read</code> timeout each time data is received for a <code>aiohttp.client</code> response.; <code>[#3808](https://github.com/aio-libs/aiohttp/issues/3808) &lt;https://github.com/aio-libs/aiohttp/issues/3808&gt;</code>_</li>; <li>Fixed type annotation for add_view method of UrlDispatcher to accept any subclass of Vie",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:205,Deployability,release,releases,205,"Bumps [aiohttp](https://github.com/aio-libs/aiohttp) from 3.6.0 to 3.7.4.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/releases"">aiohttp's releases</a>.</em></p>; <blockquote>; <h2>aiohttp 3.7.3 release</h2>; <h2>Features</h2>; <ul>; <li>Use Brotli instead of brotlipy; <code>[#3803](https://github.com/aio-libs/aiohttp/issues/3803) &lt;https://github.com/aio-libs/aiohttp/issues/3803&gt;</code>_</li>; <li>Made exceptions pickleable. Also changed the repr of some exceptions.; <code>[#4077](https://github.com/aio-libs/aiohttp/issues/4077) &lt;https://github.com/aio-libs/aiohttp/issues/4077&gt;</code>_</li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>Raise a ClientResponseError instead of an AssertionError for a blank; HTTP Reason Phrase.; <code>[#3532](https://github.com/aio-libs/aiohttp/issues/3532) &lt;https://github.com/aio-libs/aiohttp/issues/3532&gt;</code>_</li>; <li>Fix <code>web_middlewares.normalize_path_middleware</code> behavior for patch without slash.; <code>[#3669](https://github.com/aio-libs/aiohttp/issues/3669) &lt;https://github.com/aio-libs/aiohttp/issues/3669&gt;</code>_</li>; <li>Fix overshadowing of overlapped sub-applications prefixes.; <code>[#3701](https://github.com/aio-libs/aiohttp/issues/3701) &lt;https://github.com/aio-libs/aiohttp/issues/3701&gt;</code>_</li>; <li>Make <code>BaseConnector.close()</code> a coroutine and wait until the client closes all connections. Drop deprecated &quot;with Connector():&quot; syntax.; <code>[#3736](https://github.com/aio-libs/aiohttp/issues/3736) &lt;https://github.com/aio-libs/aiohttp/issues/3736&gt;</code>_</li>; <li>Reset the <code>sock_read</code> timeout each time data is received for a <code>aiohttp.client</code> response.; <code>[#3808](https://github.com/aio-libs/aiohttp/issues/3808) &lt;https://github.com/aio-libs/aiohttp/issues/3808&gt;</code>_</li>; <li>Fixed type annotation for add_view method of UrlDispatcher to accept any subclass of Vie",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:261,Deployability,release,release,261,"Bumps [aiohttp](https://github.com/aio-libs/aiohttp) from 3.6.0 to 3.7.4.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/releases"">aiohttp's releases</a>.</em></p>; <blockquote>; <h2>aiohttp 3.7.3 release</h2>; <h2>Features</h2>; <ul>; <li>Use Brotli instead of brotlipy; <code>[#3803](https://github.com/aio-libs/aiohttp/issues/3803) &lt;https://github.com/aio-libs/aiohttp/issues/3803&gt;</code>_</li>; <li>Made exceptions pickleable. Also changed the repr of some exceptions.; <code>[#4077](https://github.com/aio-libs/aiohttp/issues/4077) &lt;https://github.com/aio-libs/aiohttp/issues/4077&gt;</code>_</li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>Raise a ClientResponseError instead of an AssertionError for a blank; HTTP Reason Phrase.; <code>[#3532](https://github.com/aio-libs/aiohttp/issues/3532) &lt;https://github.com/aio-libs/aiohttp/issues/3532&gt;</code>_</li>; <li>Fix <code>web_middlewares.normalize_path_middleware</code> behavior for patch without slash.; <code>[#3669](https://github.com/aio-libs/aiohttp/issues/3669) &lt;https://github.com/aio-libs/aiohttp/issues/3669&gt;</code>_</li>; <li>Fix overshadowing of overlapped sub-applications prefixes.; <code>[#3701](https://github.com/aio-libs/aiohttp/issues/3701) &lt;https://github.com/aio-libs/aiohttp/issues/3701&gt;</code>_</li>; <li>Make <code>BaseConnector.close()</code> a coroutine and wait until the client closes all connections. Drop deprecated &quot;with Connector():&quot; syntax.; <code>[#3736](https://github.com/aio-libs/aiohttp/issues/3736) &lt;https://github.com/aio-libs/aiohttp/issues/3736&gt;</code>_</li>; <li>Reset the <code>sock_read</code> timeout each time data is received for a <code>aiohttp.client</code> response.; <code>[#3808](https://github.com/aio-libs/aiohttp/issues/3808) &lt;https://github.com/aio-libs/aiohttp/issues/3808&gt;</code>_</li>; <li>Fixed type annotation for add_view method of UrlDispatcher to accept any subclass of Vie",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:1013,Deployability,patch,patch,1013,"Bumps [aiohttp](https://github.com/aio-libs/aiohttp) from 3.6.0 to 3.7.4.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/releases"">aiohttp's releases</a>.</em></p>; <blockquote>; <h2>aiohttp 3.7.3 release</h2>; <h2>Features</h2>; <ul>; <li>Use Brotli instead of brotlipy; <code>[#3803](https://github.com/aio-libs/aiohttp/issues/3803) &lt;https://github.com/aio-libs/aiohttp/issues/3803&gt;</code>_</li>; <li>Made exceptions pickleable. Also changed the repr of some exceptions.; <code>[#4077](https://github.com/aio-libs/aiohttp/issues/4077) &lt;https://github.com/aio-libs/aiohttp/issues/4077&gt;</code>_</li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>Raise a ClientResponseError instead of an AssertionError for a blank; HTTP Reason Phrase.; <code>[#3532](https://github.com/aio-libs/aiohttp/issues/3532) &lt;https://github.com/aio-libs/aiohttp/issues/3532&gt;</code>_</li>; <li>Fix <code>web_middlewares.normalize_path_middleware</code> behavior for patch without slash.; <code>[#3669](https://github.com/aio-libs/aiohttp/issues/3669) &lt;https://github.com/aio-libs/aiohttp/issues/3669&gt;</code>_</li>; <li>Fix overshadowing of overlapped sub-applications prefixes.; <code>[#3701](https://github.com/aio-libs/aiohttp/issues/3701) &lt;https://github.com/aio-libs/aiohttp/issues/3701&gt;</code>_</li>; <li>Make <code>BaseConnector.close()</code> a coroutine and wait until the client closes all connections. Drop deprecated &quot;with Connector():&quot; syntax.; <code>[#3736](https://github.com/aio-libs/aiohttp/issues/3736) &lt;https://github.com/aio-libs/aiohttp/issues/3736&gt;</code>_</li>; <li>Reset the <code>sock_read</code> timeout each time data is received for a <code>aiohttp.client</code> response.; <code>[#3808](https://github.com/aio-libs/aiohttp/issues/3808) &lt;https://github.com/aio-libs/aiohttp/issues/3808&gt;</code>_</li>; <li>Fixed type annotation for add_view method of UrlDispatcher to accept any subclass of Vi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:5964,Deployability,patch,patch,5964," while the Cython code preserved it as; <code>//some-path</code>. Now, both do the latter.; <code>[#5498](https://github.com/aio-libs/aiohttp/issues/5498) &lt;https://github.com/aio-libs/aiohttp/issues/5498&gt;</code>_</p>; </li>; </ul>; <hr />; <h1>3.7.3 (2020-11-18)</h1>; <h2>Features</h2>; <ul>; <li>Use Brotli instead of brotlipy; <code>[#3803](https://github.com/aio-libs/aiohttp/issues/3803) &lt;https://github.com/aio-libs/aiohttp/issues/3803&gt;</code>_</li>; <li>Made exceptions pickleable. Also changed the repr of some exceptions.; <code>[#4077](https://github.com/aio-libs/aiohttp/issues/4077) &lt;https://github.com/aio-libs/aiohttp/issues/4077&gt;</code>_</li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>Raise a ClientResponseError instead of an AssertionError for a blank; HTTP Reason Phrase.; <code>[#3532](https://github.com/aio-libs/aiohttp/issues/3532) &lt;https://github.com/aio-libs/aiohttp/issues/3532&gt;</code>_</li>; <li>Fix <code>web_middlewares.normalize_path_middleware</code> behavior for patch without slash.; <code>[#3669](https://github.com/aio-libs/aiohttp/issues/3669) &lt;https://github.com/aio-libs/aiohttp/issues/3669&gt;</code>_</li>; <li>Fix overshadowing of overlapped sub-applications prefixes.; <code>[#3701](https://github.com/aio-libs/aiohttp/issues/3701) &lt;https://github.com/aio-libs/aiohttp/issues/3701&gt;</code>_</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/0a26acc1de9e1b0244456b7881ec16ba8bb64fc3""><code>0a26acc</code></a> Bump aiohttp to v3.7.4 for a security release</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/021c416c18392a111225bc7326063dc4a99a5138""><code>021c416</code></a> Merge branch 'ghsa-v6wp-4m6f-gcjg' into master</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/4ed7c25b537f71c6245bb74d6b20e5867db243ab""><code>4ed7c25</code></a> Bump chardet from 3.0.4 to 4.0.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:6607,Deployability,release,release,6607,">_</li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>Raise a ClientResponseError instead of an AssertionError for a blank; HTTP Reason Phrase.; <code>[#3532](https://github.com/aio-libs/aiohttp/issues/3532) &lt;https://github.com/aio-libs/aiohttp/issues/3532&gt;</code>_</li>; <li>Fix <code>web_middlewares.normalize_path_middleware</code> behavior for patch without slash.; <code>[#3669](https://github.com/aio-libs/aiohttp/issues/3669) &lt;https://github.com/aio-libs/aiohttp/issues/3669&gt;</code>_</li>; <li>Fix overshadowing of overlapped sub-applications prefixes.; <code>[#3701](https://github.com/aio-libs/aiohttp/issues/3701) &lt;https://github.com/aio-libs/aiohttp/issues/3701&gt;</code>_</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/0a26acc1de9e1b0244456b7881ec16ba8bb64fc3""><code>0a26acc</code></a> Bump aiohttp to v3.7.4 for a security release</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/021c416c18392a111225bc7326063dc4a99a5138""><code>021c416</code></a> Merge branch 'ghsa-v6wp-4m6f-gcjg' into master</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/4ed7c25b537f71c6245bb74d6b20e5867db243ab""><code>4ed7c25</code></a> Bump chardet from 3.0.4 to 4.0.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5333"">#5333</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/b61f0fdffc887df24244ba7bdfe8567c580240ff""><code>b61f0fd</code></a> Fix how pure-Python HTTP parser interprets <code>//</code></li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5c1efbc32c46820250bd25440bb7ea96cb05abe9""><code>5c1efbc</code></a> Bump pre-commit from 2.9.2 to 2.9.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5322"">#5322</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/007507580137efcc0a20391a0792f39b337d9c1a""><code>0075075</code></a> Bump ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:9239,Deployability,update,updates,9239,"ttp/issues/5290"">#5290</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/6724d0e7a944fd7e3a710dc292d785fa8fe424fd""><code>6724d0e</code></a> Bump pre-commit from 2.8.2 to 2.9.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5273"">#5273</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/c688451ce31b914c71b11d2ac6c326b0c87e6d1f""><code>c688451</code></a> Removed duplicate timeout parameter in ClientSession reference docs. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5262"">#5262</a>) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:10391,Deployability,upgrade,upgrade,10391,"ly by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language; - `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language; - `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language. You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:10567,Deployability,upgrade,upgrade,10567,"ly by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language; - `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language; - `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language. You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:10737,Deployability,upgrade,upgrade,10737,"ly by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language; - `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language; - `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language. You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:6987,Integrability,depend,dependabot,6987,"[#3669](https://github.com/aio-libs/aiohttp/issues/3669) &lt;https://github.com/aio-libs/aiohttp/issues/3669&gt;</code>_</li>; <li>Fix overshadowing of overlapped sub-applications prefixes.; <code>[#3701](https://github.com/aio-libs/aiohttp/issues/3701) &lt;https://github.com/aio-libs/aiohttp/issues/3701&gt;</code>_</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/0a26acc1de9e1b0244456b7881ec16ba8bb64fc3""><code>0a26acc</code></a> Bump aiohttp to v3.7.4 for a security release</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/021c416c18392a111225bc7326063dc4a99a5138""><code>021c416</code></a> Merge branch 'ghsa-v6wp-4m6f-gcjg' into master</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/4ed7c25b537f71c6245bb74d6b20e5867db243ab""><code>4ed7c25</code></a> Bump chardet from 3.0.4 to 4.0.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5333"">#5333</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/b61f0fdffc887df24244ba7bdfe8567c580240ff""><code>b61f0fd</code></a> Fix how pure-Python HTTP parser interprets <code>//</code></li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5c1efbc32c46820250bd25440bb7ea96cb05abe9""><code>5c1efbc</code></a> Bump pre-commit from 2.9.2 to 2.9.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5322"">#5322</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/007507580137efcc0a20391a0792f39b337d9c1a""><code>0075075</code></a> Bump pygments from 2.7.2 to 2.7.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5318"">#5318</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5085173d947e6cc01b6daf1aa48fe7698834c569""><code>5085173</code></a> Bump multidict from 5.0.2 to 5.1.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5308"">#5308</a>)<",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:7430,Integrability,depend,dependabot,7430,"ry>; <ul>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/0a26acc1de9e1b0244456b7881ec16ba8bb64fc3""><code>0a26acc</code></a> Bump aiohttp to v3.7.4 for a security release</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/021c416c18392a111225bc7326063dc4a99a5138""><code>021c416</code></a> Merge branch 'ghsa-v6wp-4m6f-gcjg' into master</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/4ed7c25b537f71c6245bb74d6b20e5867db243ab""><code>4ed7c25</code></a> Bump chardet from 3.0.4 to 4.0.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5333"">#5333</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/b61f0fdffc887df24244ba7bdfe8567c580240ff""><code>b61f0fd</code></a> Fix how pure-Python HTTP parser interprets <code>//</code></li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5c1efbc32c46820250bd25440bb7ea96cb05abe9""><code>5c1efbc</code></a> Bump pre-commit from 2.9.2 to 2.9.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5322"">#5322</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/007507580137efcc0a20391a0792f39b337d9c1a""><code>0075075</code></a> Bump pygments from 2.7.2 to 2.7.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5318"">#5318</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5085173d947e6cc01b6daf1aa48fe7698834c569""><code>5085173</code></a> Bump multidict from 5.0.2 to 5.1.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5308"">#5308</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5d1a75e68d278c641c90021409f4eb5de1810e5e""><code>5d1a75e</code></a> Bump pre-commit from 2.9.0 to 2.9.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5290"">#5290</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/6724d0e7a944fd7e3a710dc292d785fa8fe424fd""><code>6724d0e</code></a> Bump pre-commit from 2.8.2 to 2.9.0 (<a href=""https://githu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:7683,Integrability,depend,dependabot,7683,"92a111225bc7326063dc4a99a5138""><code>021c416</code></a> Merge branch 'ghsa-v6wp-4m6f-gcjg' into master</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/4ed7c25b537f71c6245bb74d6b20e5867db243ab""><code>4ed7c25</code></a> Bump chardet from 3.0.4 to 4.0.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5333"">#5333</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/b61f0fdffc887df24244ba7bdfe8567c580240ff""><code>b61f0fd</code></a> Fix how pure-Python HTTP parser interprets <code>//</code></li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5c1efbc32c46820250bd25440bb7ea96cb05abe9""><code>5c1efbc</code></a> Bump pre-commit from 2.9.2 to 2.9.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5322"">#5322</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/007507580137efcc0a20391a0792f39b337d9c1a""><code>0075075</code></a> Bump pygments from 2.7.2 to 2.7.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5318"">#5318</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5085173d947e6cc01b6daf1aa48fe7698834c569""><code>5085173</code></a> Bump multidict from 5.0.2 to 5.1.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5308"">#5308</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5d1a75e68d278c641c90021409f4eb5de1810e5e""><code>5d1a75e</code></a> Bump pre-commit from 2.9.0 to 2.9.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5290"">#5290</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/6724d0e7a944fd7e3a710dc292d785fa8fe424fd""><code>6724d0e</code></a> Bump pre-commit from 2.8.2 to 2.9.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5273"">#5273</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/c688451ce31b914c71b11d2ac6c326b0c87e6d1f""><code>c688451</code></a> Removed duplicate timeout parameter in ClientSession refe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:7937,Integrability,depend,dependabot,7937,"4 to 4.0.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5333"">#5333</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/b61f0fdffc887df24244ba7bdfe8567c580240ff""><code>b61f0fd</code></a> Fix how pure-Python HTTP parser interprets <code>//</code></li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5c1efbc32c46820250bd25440bb7ea96cb05abe9""><code>5c1efbc</code></a> Bump pre-commit from 2.9.2 to 2.9.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5322"">#5322</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/007507580137efcc0a20391a0792f39b337d9c1a""><code>0075075</code></a> Bump pygments from 2.7.2 to 2.7.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5318"">#5318</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5085173d947e6cc01b6daf1aa48fe7698834c569""><code>5085173</code></a> Bump multidict from 5.0.2 to 5.1.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5308"">#5308</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5d1a75e68d278c641c90021409f4eb5de1810e5e""><code>5d1a75e</code></a> Bump pre-commit from 2.9.0 to 2.9.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5290"">#5290</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/6724d0e7a944fd7e3a710dc292d785fa8fe424fd""><code>6724d0e</code></a> Bump pre-commit from 2.8.2 to 2.9.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5273"">#5273</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/c688451ce31b914c71b11d2ac6c326b0c87e6d1f""><code>c688451</code></a> Removed duplicate timeout parameter in ClientSession reference docs. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5262"">#5262</a>) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </detai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:8192,Integrability,depend,dependabot,8192,"parser interprets <code>//</code></li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5c1efbc32c46820250bd25440bb7ea96cb05abe9""><code>5c1efbc</code></a> Bump pre-commit from 2.9.2 to 2.9.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5322"">#5322</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/007507580137efcc0a20391a0792f39b337d9c1a""><code>0075075</code></a> Bump pygments from 2.7.2 to 2.7.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5318"">#5318</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5085173d947e6cc01b6daf1aa48fe7698834c569""><code>5085173</code></a> Bump multidict from 5.0.2 to 5.1.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5308"">#5308</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5d1a75e68d278c641c90021409f4eb5de1810e5e""><code>5d1a75e</code></a> Bump pre-commit from 2.9.0 to 2.9.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5290"">#5290</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/6724d0e7a944fd7e3a710dc292d785fa8fe424fd""><code>6724d0e</code></a> Bump pre-commit from 2.8.2 to 2.9.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5273"">#5273</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/c688451ce31b914c71b11d2ac6c326b0c87e6d1f""><code>c688451</code></a> Removed duplicate timeout parameter in ClientSession reference docs. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5262"">#5262</a>) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-v",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:8447,Integrability,depend,dependabot,8447,"s/aiohttp/issues/5322"">#5322</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/007507580137efcc0a20391a0792f39b337d9c1a""><code>0075075</code></a> Bump pygments from 2.7.2 to 2.7.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5318"">#5318</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5085173d947e6cc01b6daf1aa48fe7698834c569""><code>5085173</code></a> Bump multidict from 5.0.2 to 5.1.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5308"">#5308</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5d1a75e68d278c641c90021409f4eb5de1810e5e""><code>5d1a75e</code></a> Bump pre-commit from 2.9.0 to 2.9.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5290"">#5290</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/6724d0e7a944fd7e3a710dc292d785fa8fe424fd""><code>6724d0e</code></a> Bump pre-commit from 2.8.2 to 2.9.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5273"">#5273</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/c688451ce31b914c71b11d2ac6c326b0c87e6d1f""><code>c688451</code></a> Removed duplicate timeout parameter in ClientSession reference docs. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5262"">#5262</a>) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:8735,Integrability,depend,dependabot,8735,"li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5085173d947e6cc01b6daf1aa48fe7698834c569""><code>5085173</code></a> Bump multidict from 5.0.2 to 5.1.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5308"">#5308</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5d1a75e68d278c641c90021409f4eb5de1810e5e""><code>5d1a75e</code></a> Bump pre-commit from 2.9.0 to 2.9.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5290"">#5290</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/6724d0e7a944fd7e3a710dc292d785fa8fe424fd""><code>6724d0e</code></a> Bump pre-commit from 2.8.2 to 2.9.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5273"">#5273</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/c688451ce31b914c71b11d2ac6c326b0c87e6d1f""><code>c688451</code></a> Removed duplicate timeout parameter in ClientSession reference docs. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5262"">#5262</a>) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:8959,Integrability,Depend,Dependabot,8959,"8</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5d1a75e68d278c641c90021409f4eb5de1810e5e""><code>5d1a75e</code></a> Bump pre-commit from 2.9.0 to 2.9.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5290"">#5290</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/6724d0e7a944fd7e3a710dc292d785fa8fe424fd""><code>6724d0e</code></a> Bump pre-commit from 2.8.2 to 2.9.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5273"">#5273</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/c688451ce31b914c71b11d2ac6c326b0c87e6d1f""><code>c688451</code></a> Removed duplicate timeout parameter in ClientSession reference docs. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5262"">#5262</a>) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` wi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:8999,Integrability,depend,dependabot-badges,8999,"8</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5d1a75e68d278c641c90021409f4eb5de1810e5e""><code>5d1a75e</code></a> Bump pre-commit from 2.9.0 to 2.9.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5290"">#5290</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/6724d0e7a944fd7e3a710dc292d785fa8fe424fd""><code>6724d0e</code></a> Bump pre-commit from 2.8.2 to 2.9.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5273"">#5273</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/c688451ce31b914c71b11d2ac6c326b0c87e6d1f""><code>c688451</code></a> Removed duplicate timeout parameter in ClientSession reference docs. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5262"">#5262</a>) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` wi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:9058,Integrability,depend,dependency-name,9058,"0021409f4eb5de1810e5e""><code>5d1a75e</code></a> Bump pre-commit from 2.9.0 to 2.9.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5290"">#5290</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/6724d0e7a944fd7e3a710dc292d785fa8fe424fd""><code>6724d0e</code></a> Bump pre-commit from 2.8.2 to 2.9.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5273"">#5273</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/c688451ce31b914c71b11d2ac6c326b0c87e6d1f""><code>c688451</code></a> Removed duplicate timeout parameter in ClientSession reference docs. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5262"">#5262</a>) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` wil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:9219,Integrability,depend,dependabot-security-updates,9219,"ttp/issues/5290"">#5290</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/6724d0e7a944fd7e3a710dc292d785fa8fe424fd""><code>6724d0e</code></a> Bump pre-commit from 2.8.2 to 2.9.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5273"">#5273</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/c688451ce31b914c71b11d2ac6c326b0c87e6d1f""><code>c688451</code></a> Removed duplicate timeout parameter in ClientSession reference docs. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5262"">#5262</a>) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:9276,Integrability,Depend,Dependabot,9276,"44fd7e3a710dc292d785fa8fe424fd""><code>6724d0e</code></a> Bump pre-commit from 2.8.2 to 2.9.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5273"">#5273</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/c688451ce31b914c71b11d2ac6c326b0c87e6d1f""><code>c688451</code></a> Removed duplicate timeout parameter in ClientSession reference docs. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5262"">#5262</a>) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:9422,Integrability,depend,dependabot,9422," to 2.9.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5273"">#5273</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/c688451ce31b914c71b11d2ac6c326b0c87e6d1f""><code>c688451</code></a> Removed duplicate timeout parameter in ClientSession reference docs. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5262"">#5262</a>) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:9451,Integrability,depend,dependabot-automerge-start,9451,"/issues/5273"">#5273</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/c688451ce31b914c71b11d2ac6c326b0c87e6d1f""><code>c688451</code></a> Removed duplicate timeout parameter in ClientSession reference docs. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5262"">#5262</a>) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:9489,Integrability,depend,dependabot-automerge-end,9489,"/issues/5273"">#5273</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/c688451ce31b914c71b11d2ac6c326b0c87e6d1f""><code>c688451</code></a> Removed duplicate timeout parameter in ClientSession reference docs. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5262"">#5262</a>) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:9541,Integrability,Depend,Dependabot,9541,"tp/commit/c688451ce31b914c71b11d2ac6c326b0c87e6d1f""><code>c688451</code></a> Removed duplicate timeout parameter in ClientSession reference docs. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5262"">#5262</a>) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:9608,Integrability,Depend,Dependabot,9608,"e/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:9658,Integrability,depend,dependabot,9658,"e/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:9702,Integrability,depend,dependabot,9702,"e/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:9799,Integrability,depend,dependabot,9799,"e/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:9868,Integrability,depend,dependabot,9868,"e/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:9959,Integrability,depend,dependabot,9959,"e/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:10052,Integrability,depend,dependabot,10052,"e/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:10112,Integrability,depend,dependabot,10112,"e/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:10158,Integrability,Depend,Dependabot,10158,"e/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:10244,Integrability,depend,dependabot,10244,"ly by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language; - `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language; - `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language. You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:10310,Integrability,Depend,Dependabot,10310,"ly by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language; - `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language; - `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language. You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:10420,Integrability,depend,dependabot,10420,"ly by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language; - `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language; - `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language. You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:10486,Integrability,Depend,Dependabot,10486,"ly by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language; - `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language; - `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language. You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:10596,Integrability,depend,dependabot,10596,"ly by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language; - `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language; - `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language. You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:10619,Integrability,depend,dependency,10619,"ly by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language; - `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language; - `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language. You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:10659,Integrability,Depend,Dependabot,10659,"ly by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language; - `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language; - `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language. You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:10697,Integrability,depend,dependency,10697,"ly by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language; - `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language; - `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language. You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:10766,Integrability,depend,dependabot,10766,"ly by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language; - `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language; - `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language. You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:10885,Integrability,depend,dependabot,10885,"ly by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language; - `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language; - `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language. You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:11010,Integrability,depend,dependabot,11010,"ly by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language; - `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language; - `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language. You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:11135,Integrability,depend,dependabot,11135,"ly by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language; - `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language; - `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language. You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:1696,Safety,timeout,timeout,1696,ul>; <h2>Bugfixes</h2>; <ul>; <li>Raise a ClientResponseError instead of an AssertionError for a blank; HTTP Reason Phrase.; <code>[#3532](https://github.com/aio-libs/aiohttp/issues/3532) &lt;https://github.com/aio-libs/aiohttp/issues/3532&gt;</code>_</li>; <li>Fix <code>web_middlewares.normalize_path_middleware</code> behavior for patch without slash.; <code>[#3669](https://github.com/aio-libs/aiohttp/issues/3669) &lt;https://github.com/aio-libs/aiohttp/issues/3669&gt;</code>_</li>; <li>Fix overshadowing of overlapped sub-applications prefixes.; <code>[#3701](https://github.com/aio-libs/aiohttp/issues/3701) &lt;https://github.com/aio-libs/aiohttp/issues/3701&gt;</code>_</li>; <li>Make <code>BaseConnector.close()</code> a coroutine and wait until the client closes all connections. Drop deprecated &quot;with Connector():&quot; syntax.; <code>[#3736](https://github.com/aio-libs/aiohttp/issues/3736) &lt;https://github.com/aio-libs/aiohttp/issues/3736&gt;</code>_</li>; <li>Reset the <code>sock_read</code> timeout each time data is received for a <code>aiohttp.client</code> response.; <code>[#3808](https://github.com/aio-libs/aiohttp/issues/3808) &lt;https://github.com/aio-libs/aiohttp/issues/3808&gt;</code>_</li>; <li>Fixed type annotation for add_view method of UrlDispatcher to accept any subclass of View; <code>[#3880](https://github.com/aio-libs/aiohttp/issues/3880) &lt;https://github.com/aio-libs/aiohttp/issues/3880&gt;</code>_</li>; <li>Fixed querying the address families from DNS that the current host supports.; <code>[#5156](https://github.com/aio-libs/aiohttp/issues/5156) &lt;https://github.com/aio-libs/aiohttp/issues/5156&gt;</code>_</li>; <li>Change return type of MultipartReader.<strong>aiter</strong>() and BodyPartReader.<strong>aiter</strong>() to AsyncIterator.; <code>[#5163](https://github.com/aio-libs/aiohttp/issues/5163) &lt;https://github.com/aio-libs/aiohttp/issues/5163&gt;</code>_</li>; <li>Provide x86 Windows wheels.; <code>[#5230](https://github.com,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:8650,Safety,timeout,timeout,8650,"p pygments from 2.7.2 to 2.7.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5318"">#5318</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5085173d947e6cc01b6daf1aa48fe7698834c569""><code>5085173</code></a> Bump multidict from 5.0.2 to 5.1.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5308"">#5308</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5d1a75e68d278c641c90021409f4eb5de1810e5e""><code>5d1a75e</code></a> Bump pre-commit from 2.9.0 to 2.9.2 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5290"">#5290</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/6724d0e7a944fd7e3a710dc292d785fa8fe424fd""><code>6724d0e</code></a> Bump pre-commit from 2.8.2 to 2.9.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5273"">#5273</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/c688451ce31b914c71b11d2ac6c326b0c87e6d1f""><code>c688451</code></a> Removed duplicate timeout parameter in ClientSession reference docs. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5262"">#5262</a>) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:3970,Security,SECUR,SECURITY,3970,"m/aio-libs/aiohttp/issues/3958&gt;</code>_</li>; <li>Removed deprecation warning in tracing example docs; <code>[#3964](https://github.com/aio-libs/aiohttp/issues/3964) &lt;https://github.com/aio-libs/aiohttp/issues/3964&gt;</code>_</li>; <li>Fixed wrong &quot;Usage&quot; docstring of <code>aiohttp.client.request</code>.; <code>[#4603](https://github.com/aio-libs/aiohttp/issues/4603) &lt;https://github.com/aio-libs/aiohttp/issues/4603&gt;</code>_</li>; <li>Add aiohttp-pydantic to third party libraries; <code>[#5228](https://github.com/aio-libs/aiohttp/issues/5228) &lt;https://github.com/aio-libs/aiohttp/issues/5228&gt;</code>_</li>; </ul>; <h2>Misc</h2>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/blob/master/CHANGES.rst"">aiohttp's changelog</a>.</em></p>; <blockquote>; <h1>3.7.4 (2021-02-25)</h1>; <h2>Bugfixes</h2>; <ul>; <li>; <p><strong>(SECURITY BUG)</strong> Started preventing open redirects in the; <code>aiohttp.web.normalize_path_middleware</code> middleware. For; more details, see; <a href=""https://github.com/aio-libs/aiohttp/security/advisories/GHSA-v6wp-4m6f-gcjg"">https://github.com/aio-libs/aiohttp/security/advisories/GHSA-v6wp-4m6f-gcjg</a>.</p>; <p>Thanks to <code>Beast Glatisant &lt;https://github.com/g147&gt;</code>__ for; finding the first instance of this issue and <code>Jelmer Vernoo &lt;https://jelmer.uk/&gt;</code>__ for reporting and tracking it down; in aiohttp.; <code>[#5497](https://github.com/aio-libs/aiohttp/issues/5497) &lt;https://github.com/aio-libs/aiohttp/issues/5497&gt;</code>_</p>; </li>; <li>; <p>Fix interpretation difference of the pure-Python and the Cython-based; HTTP parsers construct a <code>yarl.URL</code> object for HTTP request-target.</p>; <p>Before this fix, the Python parser would turn the URI's absolute-path; for <code>//some-path</code> into <code>/</code> while the Cython code pres",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:4167,Security,secur,security,4167,"p/issues/3964&gt;</code>_</li>; <li>Fixed wrong &quot;Usage&quot; docstring of <code>aiohttp.client.request</code>.; <code>[#4603](https://github.com/aio-libs/aiohttp/issues/4603) &lt;https://github.com/aio-libs/aiohttp/issues/4603&gt;</code>_</li>; <li>Add aiohttp-pydantic to third party libraries; <code>[#5228](https://github.com/aio-libs/aiohttp/issues/5228) &lt;https://github.com/aio-libs/aiohttp/issues/5228&gt;</code>_</li>; </ul>; <h2>Misc</h2>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/blob/master/CHANGES.rst"">aiohttp's changelog</a>.</em></p>; <blockquote>; <h1>3.7.4 (2021-02-25)</h1>; <h2>Bugfixes</h2>; <ul>; <li>; <p><strong>(SECURITY BUG)</strong> Started preventing open redirects in the; <code>aiohttp.web.normalize_path_middleware</code> middleware. For; more details, see; <a href=""https://github.com/aio-libs/aiohttp/security/advisories/GHSA-v6wp-4m6f-gcjg"">https://github.com/aio-libs/aiohttp/security/advisories/GHSA-v6wp-4m6f-gcjg</a>.</p>; <p>Thanks to <code>Beast Glatisant &lt;https://github.com/g147&gt;</code>__ for; finding the first instance of this issue and <code>Jelmer Vernoo &lt;https://jelmer.uk/&gt;</code>__ for reporting and tracking it down; in aiohttp.; <code>[#5497](https://github.com/aio-libs/aiohttp/issues/5497) &lt;https://github.com/aio-libs/aiohttp/issues/5497&gt;</code>_</p>; </li>; <li>; <p>Fix interpretation difference of the pure-Python and the Cython-based; HTTP parsers construct a <code>yarl.URL</code> object for HTTP request-target.</p>; <p>Before this fix, the Python parser would turn the URI's absolute-path; for <code>//some-path</code> into <code>/</code> while the Cython code preserved it as; <code>//some-path</code>. Now, both do the latter.; <code>[#5498](https://github.com/aio-libs/aiohttp/issues/5498) &lt;https://github.com/aio-libs/aiohttp/issues/5498&gt;</code>_</p>; </li>; </u",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:4244,Security,secur,security,4244,"ring of <code>aiohttp.client.request</code>.; <code>[#4603](https://github.com/aio-libs/aiohttp/issues/4603) &lt;https://github.com/aio-libs/aiohttp/issues/4603&gt;</code>_</li>; <li>Add aiohttp-pydantic to third party libraries; <code>[#5228](https://github.com/aio-libs/aiohttp/issues/5228) &lt;https://github.com/aio-libs/aiohttp/issues/5228&gt;</code>_</li>; </ul>; <h2>Misc</h2>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/blob/master/CHANGES.rst"">aiohttp's changelog</a>.</em></p>; <blockquote>; <h1>3.7.4 (2021-02-25)</h1>; <h2>Bugfixes</h2>; <ul>; <li>; <p><strong>(SECURITY BUG)</strong> Started preventing open redirects in the; <code>aiohttp.web.normalize_path_middleware</code> middleware. For; more details, see; <a href=""https://github.com/aio-libs/aiohttp/security/advisories/GHSA-v6wp-4m6f-gcjg"">https://github.com/aio-libs/aiohttp/security/advisories/GHSA-v6wp-4m6f-gcjg</a>.</p>; <p>Thanks to <code>Beast Glatisant &lt;https://github.com/g147&gt;</code>__ for; finding the first instance of this issue and <code>Jelmer Vernoo &lt;https://jelmer.uk/&gt;</code>__ for reporting and tracking it down; in aiohttp.; <code>[#5497](https://github.com/aio-libs/aiohttp/issues/5497) &lt;https://github.com/aio-libs/aiohttp/issues/5497&gt;</code>_</p>; </li>; <li>; <p>Fix interpretation difference of the pure-Python and the Cython-based; HTTP parsers construct a <code>yarl.URL</code> object for HTTP request-target.</p>; <p>Before this fix, the Python parser would turn the URI's absolute-path; for <code>//some-path</code> into <code>/</code> while the Cython code preserved it as; <code>//some-path</code>. Now, both do the latter.; <code>[#5498](https://github.com/aio-libs/aiohttp/issues/5498) &lt;https://github.com/aio-libs/aiohttp/issues/5498&gt;</code>_</p>; </li>; </ul>; <hr />; <h1>3.7.3 (2020-11-18)</h1>; <h2>Features</h2>; <ul>; <li>U",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:6598,Security,secur,security,6598,">_</li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>Raise a ClientResponseError instead of an AssertionError for a blank; HTTP Reason Phrase.; <code>[#3532](https://github.com/aio-libs/aiohttp/issues/3532) &lt;https://github.com/aio-libs/aiohttp/issues/3532&gt;</code>_</li>; <li>Fix <code>web_middlewares.normalize_path_middleware</code> behavior for patch without slash.; <code>[#3669](https://github.com/aio-libs/aiohttp/issues/3669) &lt;https://github.com/aio-libs/aiohttp/issues/3669&gt;</code>_</li>; <li>Fix overshadowing of overlapped sub-applications prefixes.; <code>[#3701](https://github.com/aio-libs/aiohttp/issues/3701) &lt;https://github.com/aio-libs/aiohttp/issues/3701&gt;</code>_</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/0a26acc1de9e1b0244456b7881ec16ba8bb64fc3""><code>0a26acc</code></a> Bump aiohttp to v3.7.4 for a security release</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/021c416c18392a111225bc7326063dc4a99a5138""><code>021c416</code></a> Merge branch 'ghsa-v6wp-4m6f-gcjg' into master</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/4ed7c25b537f71c6245bb74d6b20e5867db243ab""><code>4ed7c25</code></a> Bump chardet from 3.0.4 to 4.0.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5333"">#5333</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/b61f0fdffc887df24244ba7bdfe8567c580240ff""><code>b61f0fd</code></a> Fix how pure-Python HTTP parser interprets <code>//</code></li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/5c1efbc32c46820250bd25440bb7ea96cb05abe9""><code>5c1efbc</code></a> Bump pre-commit from 2.9.2 to 2.9.3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5322"">#5322</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/007507580137efcc0a20391a0792f39b337d9c1a""><code>0075075</code></a> Bump ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:9188,Security,secur,security-vulnerabilities,9188,"ttp/issues/5290"">#5290</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/6724d0e7a944fd7e3a710dc292d785fa8fe424fd""><code>6724d0e</code></a> Bump pre-commit from 2.8.2 to 2.9.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5273"">#5273</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/c688451ce31b914c71b11d2ac6c326b0c87e6d1f""><code>c688451</code></a> Removed duplicate timeout parameter in ClientSession reference docs. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5262"">#5262</a>) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:9230,Security,secur,security-updates,9230,"ttp/issues/5290"">#5290</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/6724d0e7a944fd7e3a710dc292d785fa8fe424fd""><code>6724d0e</code></a> Bump pre-commit from 2.8.2 to 2.9.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5273"">#5273</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/c688451ce31b914c71b11d2ac6c326b0c87e6d1f""><code>c688451</code></a> Removed duplicate timeout parameter in ClientSession reference docs. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/5262"">#5262</a>) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.6.0...v3.7.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.6.0&new-version=3.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:11281,Security,secur,security,11281,"ly by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language; - `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language; - `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language. You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:11322,Security,Secur,Security,11322,"ly by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language; - `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language; - `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language. You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:755,Testability,Assert,AssertionError,755,"Bumps [aiohttp](https://github.com/aio-libs/aiohttp) from 3.6.0 to 3.7.4.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/releases"">aiohttp's releases</a>.</em></p>; <blockquote>; <h2>aiohttp 3.7.3 release</h2>; <h2>Features</h2>; <ul>; <li>Use Brotli instead of brotlipy; <code>[#3803](https://github.com/aio-libs/aiohttp/issues/3803) &lt;https://github.com/aio-libs/aiohttp/issues/3803&gt;</code>_</li>; <li>Made exceptions pickleable. Also changed the repr of some exceptions.; <code>[#4077](https://github.com/aio-libs/aiohttp/issues/4077) &lt;https://github.com/aio-libs/aiohttp/issues/4077&gt;</code>_</li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>Raise a ClientResponseError instead of an AssertionError for a blank; HTTP Reason Phrase.; <code>[#3532](https://github.com/aio-libs/aiohttp/issues/3532) &lt;https://github.com/aio-libs/aiohttp/issues/3532&gt;</code>_</li>; <li>Fix <code>web_middlewares.normalize_path_middleware</code> behavior for patch without slash.; <code>[#3669](https://github.com/aio-libs/aiohttp/issues/3669) &lt;https://github.com/aio-libs/aiohttp/issues/3669&gt;</code>_</li>; <li>Fix overshadowing of overlapped sub-applications prefixes.; <code>[#3701](https://github.com/aio-libs/aiohttp/issues/3701) &lt;https://github.com/aio-libs/aiohttp/issues/3701&gt;</code>_</li>; <li>Make <code>BaseConnector.close()</code> a coroutine and wait until the client closes all connections. Drop deprecated &quot;with Connector():&quot; syntax.; <code>[#3736](https://github.com/aio-libs/aiohttp/issues/3736) &lt;https://github.com/aio-libs/aiohttp/issues/3736&gt;</code>_</li>; <li>Reset the <code>sock_read</code> timeout each time data is received for a <code>aiohttp.client</code> response.; <code>[#3808](https://github.com/aio-libs/aiohttp/issues/3808) &lt;https://github.com/aio-libs/aiohttp/issues/3808&gt;</code>_</li>; <li>Fixed type annotation for add_view method of UrlDispatcher to accept any subclass of Vie",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10115:5706,Testability,Assert,AssertionError,5706,"<li>; <p>Fix interpretation difference of the pure-Python and the Cython-based; HTTP parsers construct a <code>yarl.URL</code> object for HTTP request-target.</p>; <p>Before this fix, the Python parser would turn the URI's absolute-path; for <code>//some-path</code> into <code>/</code> while the Cython code preserved it as; <code>//some-path</code>. Now, both do the latter.; <code>[#5498](https://github.com/aio-libs/aiohttp/issues/5498) &lt;https://github.com/aio-libs/aiohttp/issues/5498&gt;</code>_</p>; </li>; </ul>; <hr />; <h1>3.7.3 (2020-11-18)</h1>; <h2>Features</h2>; <ul>; <li>Use Brotli instead of brotlipy; <code>[#3803](https://github.com/aio-libs/aiohttp/issues/3803) &lt;https://github.com/aio-libs/aiohttp/issues/3803&gt;</code>_</li>; <li>Made exceptions pickleable. Also changed the repr of some exceptions.; <code>[#4077](https://github.com/aio-libs/aiohttp/issues/4077) &lt;https://github.com/aio-libs/aiohttp/issues/4077&gt;</code>_</li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>Raise a ClientResponseError instead of an AssertionError for a blank; HTTP Reason Phrase.; <code>[#3532](https://github.com/aio-libs/aiohttp/issues/3532) &lt;https://github.com/aio-libs/aiohttp/issues/3532&gt;</code>_</li>; <li>Fix <code>web_middlewares.normalize_path_middleware</code> behavior for patch without slash.; <code>[#3669](https://github.com/aio-libs/aiohttp/issues/3669) &lt;https://github.com/aio-libs/aiohttp/issues/3669&gt;</code>_</li>; <li>Fix overshadowing of overlapped sub-applications prefixes.; <code>[#3701](https://github.com/aio-libs/aiohttp/issues/3701) &lt;https://github.com/aio-libs/aiohttp/issues/3701&gt;</code>_</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/0a26acc1de9e1b0244456b7881ec16ba8bb64fc3""><code>0a26acc</code></a> Bump aiohttp to v3.7.4 for a security release</li>; <li><a href=""https://github.com/aio-libs/aio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10115
https://github.com/hail-is/hail/pull/10117:282,Availability,avail,available,282,"Our GKE nodes come with 2 CPU and 7.5 GB each, but not all of that is allocatable to our pods. In reality, somewhere between 5.7-5.9GB ([GCP Docs](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-architecture) say 5.7, GKE console says 5.9) of memory and 1.9CPU are available for us to use. Some of our Big services request 1 CPU and 3.75GB, but then we can never fit two big pods on one node. This is an attempt to standardize our requests so their easier to reason about while hopefully getting better packing. . | resource | Big | Medium | Small |; | --- | --- | --- | --- |; | CPU | 600m | 100m | 20m |; | Memory | 2G | 200M | 20M |. The intentions here are:; - always be able to comfortably get 2 Big pods on a node; - medium pods shouldn't have to force new nodes to spin up just because there's a Big pod there already; - small pods take up minimal resources; - there's ample room for small pods (which are mostly on HPA) to scale up considering most nodes shouldn't be at their medium pod capacity. The ratios don't match exactly, because I didn't want to assign CPU lower than 20m to prevent HPA thrashing we saw with auth and see a bit now with router. Setting it to 20m should hopefully convince k8s that idle small apps don't need to be scaled up under normal fluctuation. ## Big; - query; - batch-driver; - shuffler; - memory. ## Medium; - grafana; - ukbb-browser; - ukbb-static; - blog; - ci; - internal-gateway. ## Small; - amundsen; - router; - gateway; - site; - batch; - address; - atgu; - router-resolver; - ci/test statefulset & deployment; - auth-driver; - echo; - benchmark; - image-fetcher. ### Fun surprises I found along the way; - CI test statefulsets and deployment are getting .5GB and .5 CPU each; - We run a lot of image fetchers because a daemon set gets added per PR namespace. EDIT: It seems that discrepancy between GCP docs and GKE console is the console counts kube-system pods in ""Allocatable Memory"", and it really does take 2GB to run the Kuberne",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10117
https://github.com/hail-is/hail/pull/10117:1594,Availability,echo,echo,1594," come with 2 CPU and 7.5 GB each, but not all of that is allocatable to our pods. In reality, somewhere between 5.7-5.9GB ([GCP Docs](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-architecture) say 5.7, GKE console says 5.9) of memory and 1.9CPU are available for us to use. Some of our Big services request 1 CPU and 3.75GB, but then we can never fit two big pods on one node. This is an attempt to standardize our requests so their easier to reason about while hopefully getting better packing. . | resource | Big | Medium | Small |; | --- | --- | --- | --- |; | CPU | 600m | 100m | 20m |; | Memory | 2G | 200M | 20M |. The intentions here are:; - always be able to comfortably get 2 Big pods on a node; - medium pods shouldn't have to force new nodes to spin up just because there's a Big pod there already; - small pods take up minimal resources; - there's ample room for small pods (which are mostly on HPA) to scale up considering most nodes shouldn't be at their medium pod capacity. The ratios don't match exactly, because I didn't want to assign CPU lower than 20m to prevent HPA thrashing we saw with auth and see a bit now with router. Setting it to 20m should hopefully convince k8s that idle small apps don't need to be scaled up under normal fluctuation. ## Big; - query; - batch-driver; - shuffler; - memory. ## Medium; - grafana; - ukbb-browser; - ukbb-static; - blog; - ci; - internal-gateway. ## Small; - amundsen; - router; - gateway; - site; - batch; - address; - atgu; - router-resolver; - ci/test statefulset & deployment; - auth-driver; - echo; - benchmark; - image-fetcher. ### Fun surprises I found along the way; - CI test statefulsets and deployment are getting .5GB and .5 CPU each; - We run a lot of image fetchers because a daemon set gets added per PR namespace. EDIT: It seems that discrepancy between GCP docs and GKE console is the console counts kube-system pods in ""Allocatable Memory"", and it really does take 2GB to run the Kubernetes Engine ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10117
https://github.com/hail-is/hail/pull/10117:1565,Deployability,deploy,deployment,1565," come with 2 CPU and 7.5 GB each, but not all of that is allocatable to our pods. In reality, somewhere between 5.7-5.9GB ([GCP Docs](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-architecture) say 5.7, GKE console says 5.9) of memory and 1.9CPU are available for us to use. Some of our Big services request 1 CPU and 3.75GB, but then we can never fit two big pods on one node. This is an attempt to standardize our requests so their easier to reason about while hopefully getting better packing. . | resource | Big | Medium | Small |; | --- | --- | --- | --- |; | CPU | 600m | 100m | 20m |; | Memory | 2G | 200M | 20M |. The intentions here are:; - always be able to comfortably get 2 Big pods on a node; - medium pods shouldn't have to force new nodes to spin up just because there's a Big pod there already; - small pods take up minimal resources; - there's ample room for small pods (which are mostly on HPA) to scale up considering most nodes shouldn't be at their medium pod capacity. The ratios don't match exactly, because I didn't want to assign CPU lower than 20m to prevent HPA thrashing we saw with auth and see a bit now with router. Setting it to 20m should hopefully convince k8s that idle small apps don't need to be scaled up under normal fluctuation. ## Big; - query; - batch-driver; - shuffler; - memory. ## Medium; - grafana; - ukbb-browser; - ukbb-static; - blog; - ci; - internal-gateway. ## Small; - amundsen; - router; - gateway; - site; - batch; - address; - atgu; - router-resolver; - ci/test statefulset & deployment; - auth-driver; - echo; - benchmark; - image-fetcher. ### Fun surprises I found along the way; - CI test statefulsets and deployment are getting .5GB and .5 CPU each; - We run a lot of image fetchers because a daemon set gets added per PR namespace. EDIT: It seems that discrepancy between GCP docs and GKE console is the console counts kube-system pods in ""Allocatable Memory"", and it really does take 2GB to run the Kubernetes Engine ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10117
https://github.com/hail-is/hail/pull/10117:1698,Deployability,deploy,deployment,1698," come with 2 CPU and 7.5 GB each, but not all of that is allocatable to our pods. In reality, somewhere between 5.7-5.9GB ([GCP Docs](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-architecture) say 5.7, GKE console says 5.9) of memory and 1.9CPU are available for us to use. Some of our Big services request 1 CPU and 3.75GB, but then we can never fit two big pods on one node. This is an attempt to standardize our requests so their easier to reason about while hopefully getting better packing. . | resource | Big | Medium | Small |; | --- | --- | --- | --- |; | CPU | 600m | 100m | 20m |; | Memory | 2G | 200M | 20M |. The intentions here are:; - always be able to comfortably get 2 Big pods on a node; - medium pods shouldn't have to force new nodes to spin up just because there's a Big pod there already; - small pods take up minimal resources; - there's ample room for small pods (which are mostly on HPA) to scale up considering most nodes shouldn't be at their medium pod capacity. The ratios don't match exactly, because I didn't want to assign CPU lower than 20m to prevent HPA thrashing we saw with auth and see a bit now with router. Setting it to 20m should hopefully convince k8s that idle small apps don't need to be scaled up under normal fluctuation. ## Big; - query; - batch-driver; - shuffler; - memory. ## Medium; - grafana; - ukbb-browser; - ukbb-static; - blog; - ci; - internal-gateway. ## Small; - amundsen; - router; - gateway; - site; - batch; - address; - atgu; - router-resolver; - ci/test statefulset & deployment; - auth-driver; - echo; - benchmark; - image-fetcher. ### Fun surprises I found along the way; - CI test statefulsets and deployment are getting .5GB and .5 CPU each; - We run a lot of image fetchers because a daemon set gets added per PR namespace. EDIT: It seems that discrepancy between GCP docs and GKE console is the console counts kube-system pods in ""Allocatable Memory"", and it really does take 2GB to run the Kubernetes Engine ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10117
https://github.com/hail-is/hail/pull/10117:1171,Integrability,rout,router,1171," come with 2 CPU and 7.5 GB each, but not all of that is allocatable to our pods. In reality, somewhere between 5.7-5.9GB ([GCP Docs](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-architecture) say 5.7, GKE console says 5.9) of memory and 1.9CPU are available for us to use. Some of our Big services request 1 CPU and 3.75GB, but then we can never fit two big pods on one node. This is an attempt to standardize our requests so their easier to reason about while hopefully getting better packing. . | resource | Big | Medium | Small |; | --- | --- | --- | --- |; | CPU | 600m | 100m | 20m |; | Memory | 2G | 200M | 20M |. The intentions here are:; - always be able to comfortably get 2 Big pods on a node; - medium pods shouldn't have to force new nodes to spin up just because there's a Big pod there already; - small pods take up minimal resources; - there's ample room for small pods (which are mostly on HPA) to scale up considering most nodes shouldn't be at their medium pod capacity. The ratios don't match exactly, because I didn't want to assign CPU lower than 20m to prevent HPA thrashing we saw with auth and see a bit now with router. Setting it to 20m should hopefully convince k8s that idle small apps don't need to be scaled up under normal fluctuation. ## Big; - query; - batch-driver; - shuffler; - memory. ## Medium; - grafana; - ukbb-browser; - ukbb-static; - blog; - ci; - internal-gateway. ## Small; - amundsen; - router; - gateway; - site; - batch; - address; - atgu; - router-resolver; - ci/test statefulset & deployment; - auth-driver; - echo; - benchmark; - image-fetcher. ### Fun surprises I found along the way; - CI test statefulsets and deployment are getting .5GB and .5 CPU each; - We run a lot of image fetchers because a daemon set gets added per PR namespace. EDIT: It seems that discrepancy between GCP docs and GKE console is the console counts kube-system pods in ""Allocatable Memory"", and it really does take 2GB to run the Kubernetes Engine ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10117
https://github.com/hail-is/hail/pull/10117:1467,Integrability,rout,router,1467," come with 2 CPU and 7.5 GB each, but not all of that is allocatable to our pods. In reality, somewhere between 5.7-5.9GB ([GCP Docs](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-architecture) say 5.7, GKE console says 5.9) of memory and 1.9CPU are available for us to use. Some of our Big services request 1 CPU and 3.75GB, but then we can never fit two big pods on one node. This is an attempt to standardize our requests so their easier to reason about while hopefully getting better packing. . | resource | Big | Medium | Small |; | --- | --- | --- | --- |; | CPU | 600m | 100m | 20m |; | Memory | 2G | 200M | 20M |. The intentions here are:; - always be able to comfortably get 2 Big pods on a node; - medium pods shouldn't have to force new nodes to spin up just because there's a Big pod there already; - small pods take up minimal resources; - there's ample room for small pods (which are mostly on HPA) to scale up considering most nodes shouldn't be at their medium pod capacity. The ratios don't match exactly, because I didn't want to assign CPU lower than 20m to prevent HPA thrashing we saw with auth and see a bit now with router. Setting it to 20m should hopefully convince k8s that idle small apps don't need to be scaled up under normal fluctuation. ## Big; - query; - batch-driver; - shuffler; - memory. ## Medium; - grafana; - ukbb-browser; - ukbb-static; - blog; - ci; - internal-gateway. ## Small; - amundsen; - router; - gateway; - site; - batch; - address; - atgu; - router-resolver; - ci/test statefulset & deployment; - auth-driver; - echo; - benchmark; - image-fetcher. ### Fun surprises I found along the way; - CI test statefulsets and deployment are getting .5GB and .5 CPU each; - We run a lot of image fetchers because a daemon set gets added per PR namespace. EDIT: It seems that discrepancy between GCP docs and GKE console is the console counts kube-system pods in ""Allocatable Memory"", and it really does take 2GB to run the Kubernetes Engine ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10117
https://github.com/hail-is/hail/pull/10117:1524,Integrability,rout,router-resolver,1524," come with 2 CPU and 7.5 GB each, but not all of that is allocatable to our pods. In reality, somewhere between 5.7-5.9GB ([GCP Docs](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-architecture) say 5.7, GKE console says 5.9) of memory and 1.9CPU are available for us to use. Some of our Big services request 1 CPU and 3.75GB, but then we can never fit two big pods on one node. This is an attempt to standardize our requests so their easier to reason about while hopefully getting better packing. . | resource | Big | Medium | Small |; | --- | --- | --- | --- |; | CPU | 600m | 100m | 20m |; | Memory | 2G | 200M | 20M |. The intentions here are:; - always be able to comfortably get 2 Big pods on a node; - medium pods shouldn't have to force new nodes to spin up just because there's a Big pod there already; - small pods take up minimal resources; - there's ample room for small pods (which are mostly on HPA) to scale up considering most nodes shouldn't be at their medium pod capacity. The ratios don't match exactly, because I didn't want to assign CPU lower than 20m to prevent HPA thrashing we saw with auth and see a bit now with router. Setting it to 20m should hopefully convince k8s that idle small apps don't need to be scaled up under normal fluctuation. ## Big; - query; - batch-driver; - shuffler; - memory. ## Medium; - grafana; - ukbb-browser; - ukbb-static; - blog; - ci; - internal-gateway. ## Small; - amundsen; - router; - gateway; - site; - batch; - address; - atgu; - router-resolver; - ci/test statefulset & deployment; - auth-driver; - echo; - benchmark; - image-fetcher. ### Fun surprises I found along the way; - CI test statefulsets and deployment are getting .5GB and .5 CPU each; - We run a lot of image fetchers because a daemon set gets added per PR namespace. EDIT: It seems that discrepancy between GCP docs and GKE console is the console counts kube-system pods in ""Allocatable Memory"", and it really does take 2GB to run the Kubernetes Engine ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10117
https://github.com/hail-is/hail/pull/10117:1546,Testability,test,test,1546," come with 2 CPU and 7.5 GB each, but not all of that is allocatable to our pods. In reality, somewhere between 5.7-5.9GB ([GCP Docs](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-architecture) say 5.7, GKE console says 5.9) of memory and 1.9CPU are available for us to use. Some of our Big services request 1 CPU and 3.75GB, but then we can never fit two big pods on one node. This is an attempt to standardize our requests so their easier to reason about while hopefully getting better packing. . | resource | Big | Medium | Small |; | --- | --- | --- | --- |; | CPU | 600m | 100m | 20m |; | Memory | 2G | 200M | 20M |. The intentions here are:; - always be able to comfortably get 2 Big pods on a node; - medium pods shouldn't have to force new nodes to spin up just because there's a Big pod there already; - small pods take up minimal resources; - there's ample room for small pods (which are mostly on HPA) to scale up considering most nodes shouldn't be at their medium pod capacity. The ratios don't match exactly, because I didn't want to assign CPU lower than 20m to prevent HPA thrashing we saw with auth and see a bit now with router. Setting it to 20m should hopefully convince k8s that idle small apps don't need to be scaled up under normal fluctuation. ## Big; - query; - batch-driver; - shuffler; - memory. ## Medium; - grafana; - ukbb-browser; - ukbb-static; - blog; - ci; - internal-gateway. ## Small; - amundsen; - router; - gateway; - site; - batch; - address; - atgu; - router-resolver; - ci/test statefulset & deployment; - auth-driver; - echo; - benchmark; - image-fetcher. ### Fun surprises I found along the way; - CI test statefulsets and deployment are getting .5GB and .5 CPU each; - We run a lot of image fetchers because a daemon set gets added per PR namespace. EDIT: It seems that discrepancy between GCP docs and GKE console is the console counts kube-system pods in ""Allocatable Memory"", and it really does take 2GB to run the Kubernetes Engine ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10117
https://github.com/hail-is/hail/pull/10117:1602,Testability,benchmark,benchmark,1602," come with 2 CPU and 7.5 GB each, but not all of that is allocatable to our pods. In reality, somewhere between 5.7-5.9GB ([GCP Docs](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-architecture) say 5.7, GKE console says 5.9) of memory and 1.9CPU are available for us to use. Some of our Big services request 1 CPU and 3.75GB, but then we can never fit two big pods on one node. This is an attempt to standardize our requests so their easier to reason about while hopefully getting better packing. . | resource | Big | Medium | Small |; | --- | --- | --- | --- |; | CPU | 600m | 100m | 20m |; | Memory | 2G | 200M | 20M |. The intentions here are:; - always be able to comfortably get 2 Big pods on a node; - medium pods shouldn't have to force new nodes to spin up just because there's a Big pod there already; - small pods take up minimal resources; - there's ample room for small pods (which are mostly on HPA) to scale up considering most nodes shouldn't be at their medium pod capacity. The ratios don't match exactly, because I didn't want to assign CPU lower than 20m to prevent HPA thrashing we saw with auth and see a bit now with router. Setting it to 20m should hopefully convince k8s that idle small apps don't need to be scaled up under normal fluctuation. ## Big; - query; - batch-driver; - shuffler; - memory. ## Medium; - grafana; - ukbb-browser; - ukbb-static; - blog; - ci; - internal-gateway. ## Small; - amundsen; - router; - gateway; - site; - batch; - address; - atgu; - router-resolver; - ci/test statefulset & deployment; - auth-driver; - echo; - benchmark; - image-fetcher. ### Fun surprises I found along the way; - CI test statefulsets and deployment are getting .5GB and .5 CPU each; - We run a lot of image fetchers because a daemon set gets added per PR namespace. EDIT: It seems that discrepancy between GCP docs and GKE console is the console counts kube-system pods in ""Allocatable Memory"", and it really does take 2GB to run the Kubernetes Engine ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10117
https://github.com/hail-is/hail/pull/10117:1676,Testability,test,test,1676," come with 2 CPU and 7.5 GB each, but not all of that is allocatable to our pods. In reality, somewhere between 5.7-5.9GB ([GCP Docs](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-architecture) say 5.7, GKE console says 5.9) of memory and 1.9CPU are available for us to use. Some of our Big services request 1 CPU and 3.75GB, but then we can never fit two big pods on one node. This is an attempt to standardize our requests so their easier to reason about while hopefully getting better packing. . | resource | Big | Medium | Small |; | --- | --- | --- | --- |; | CPU | 600m | 100m | 20m |; | Memory | 2G | 200M | 20M |. The intentions here are:; - always be able to comfortably get 2 Big pods on a node; - medium pods shouldn't have to force new nodes to spin up just because there's a Big pod there already; - small pods take up minimal resources; - there's ample room for small pods (which are mostly on HPA) to scale up considering most nodes shouldn't be at their medium pod capacity. The ratios don't match exactly, because I didn't want to assign CPU lower than 20m to prevent HPA thrashing we saw with auth and see a bit now with router. Setting it to 20m should hopefully convince k8s that idle small apps don't need to be scaled up under normal fluctuation. ## Big; - query; - batch-driver; - shuffler; - memory. ## Medium; - grafana; - ukbb-browser; - ukbb-static; - blog; - ci; - internal-gateway. ## Small; - amundsen; - router; - gateway; - site; - batch; - address; - atgu; - router-resolver; - ci/test statefulset & deployment; - auth-driver; - echo; - benchmark; - image-fetcher. ### Fun surprises I found along the way; - CI test statefulsets and deployment are getting .5GB and .5 CPU each; - We run a lot of image fetchers because a daemon set gets added per PR namespace. EDIT: It seems that discrepancy between GCP docs and GKE console is the console counts kube-system pods in ""Allocatable Memory"", and it really does take 2GB to run the Kubernetes Engine ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10117
https://github.com/hail-is/hail/pull/10120:139,Deployability,install,install-deps,139,Bump aiohttp version and fix some discrepancies between requirements files. Cleaned out my virtual env and made sure I could `make -C hail install-deps` and `pip install -r docker/requirements.txt`,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10120
https://github.com/hail-is/hail/pull/10120:162,Deployability,install,install,162,Bump aiohttp version and fix some discrepancies between requirements files. Cleaned out my virtual env and made sure I could `make -C hail install-deps` and `pip install -r docker/requirements.txt`,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10120
https://github.com/hail-is/hail/pull/10121:100,Deployability,deploy,deploy,100,"The divs for the two columns now span the whole screen, so there is room to breathe between the dev deploy and PR tables. Fixed a spacing bug in the PR tables by aligning them to the start of the flexbox column and standardized on header / searchbox / table per card. This should take up more of the screen, but is not explicitly ""centered"", basically the tables start at 0% and 50%. Unfortunately it's a painful process to fiddle with the test repo to get anything good to look at on a development CI. I'll start thinking automatically writing out test data to better test UI changes, but for now I just want to see this in main.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10121
https://github.com/hail-is/hail/pull/10121:440,Testability,test,test,440,"The divs for the two columns now span the whole screen, so there is room to breathe between the dev deploy and PR tables. Fixed a spacing bug in the PR tables by aligning them to the start of the flexbox column and standardized on header / searchbox / table per card. This should take up more of the screen, but is not explicitly ""centered"", basically the tables start at 0% and 50%. Unfortunately it's a painful process to fiddle with the test repo to get anything good to look at on a development CI. I'll start thinking automatically writing out test data to better test UI changes, but for now I just want to see this in main.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10121
https://github.com/hail-is/hail/pull/10121:549,Testability,test,test,549,"The divs for the two columns now span the whole screen, so there is room to breathe between the dev deploy and PR tables. Fixed a spacing bug in the PR tables by aligning them to the start of the flexbox column and standardized on header / searchbox / table per card. This should take up more of the screen, but is not explicitly ""centered"", basically the tables start at 0% and 50%. Unfortunately it's a painful process to fiddle with the test repo to get anything good to look at on a development CI. I'll start thinking automatically writing out test data to better test UI changes, but for now I just want to see this in main.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10121
https://github.com/hail-is/hail/pull/10121:569,Testability,test,test,569,"The divs for the two columns now span the whole screen, so there is room to breathe between the dev deploy and PR tables. Fixed a spacing bug in the PR tables by aligning them to the start of the flexbox column and standardized on header / searchbox / table per card. This should take up more of the screen, but is not explicitly ""centered"", basically the tables start at 0% and 50%. Unfortunately it's a painful process to fiddle with the test repo to get anything good to look at on a development CI. I'll start thinking automatically writing out test data to better test UI changes, but for now I just want to see this in main.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10121
https://github.com/hail-is/hail/pull/10127:833,Availability,error,error,833,"This is needed to properly implement copy/rename when you don't know if the source is a file or directory. We now only stat dest if treat_dest_as == INFER_DEST. Suppose we do `cp src dest`. There are three cases:. - Treat dest as a directory, and copy `src` to `dest/src`; - Treat dest like the target, and copy `src` to `dest` (whether src is a file or directory).; - Infer the type of dest and act accordingly. If `dest` is a directory, we're in the first case. If dest doesn't exist, or is a file, we're in the second case. I added two tests cases: test_copy_rename_dir_dest_is_target and test_overwrite_rename_dir, which test copying a directory with DEST_IS_TARGET (when the dest exists or not). I already had tests for when we were copying a file. I regenerated the copy test specs because of renames and some minor changes to error checking behavior. I spot checked the differences, and they don't seem worse (e.g. `cp file destfile/` now generates an error instead of ignoring the trailing slash.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10127
https://github.com/hail-is/hail/pull/10127:959,Availability,error,error,959,"This is needed to properly implement copy/rename when you don't know if the source is a file or directory. We now only stat dest if treat_dest_as == INFER_DEST. Suppose we do `cp src dest`. There are three cases:. - Treat dest as a directory, and copy `src` to `dest/src`; - Treat dest like the target, and copy `src` to `dest` (whether src is a file or directory).; - Infer the type of dest and act accordingly. If `dest` is a directory, we're in the first case. If dest doesn't exist, or is a file, we're in the second case. I added two tests cases: test_copy_rename_dir_dest_is_target and test_overwrite_rename_dir, which test copying a directory with DEST_IS_TARGET (when the dest exists or not). I already had tests for when we were copying a file. I regenerated the copy test specs because of renames and some minor changes to error checking behavior. I spot checked the differences, and they don't seem worse (e.g. `cp file destfile/` now generates an error instead of ignoring the trailing slash.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10127
https://github.com/hail-is/hail/pull/10127:539,Testability,test,tests,539,"This is needed to properly implement copy/rename when you don't know if the source is a file or directory. We now only stat dest if treat_dest_as == INFER_DEST. Suppose we do `cp src dest`. There are three cases:. - Treat dest as a directory, and copy `src` to `dest/src`; - Treat dest like the target, and copy `src` to `dest` (whether src is a file or directory).; - Infer the type of dest and act accordingly. If `dest` is a directory, we're in the first case. If dest doesn't exist, or is a file, we're in the second case. I added two tests cases: test_copy_rename_dir_dest_is_target and test_overwrite_rename_dir, which test copying a directory with DEST_IS_TARGET (when the dest exists or not). I already had tests for when we were copying a file. I regenerated the copy test specs because of renames and some minor changes to error checking behavior. I spot checked the differences, and they don't seem worse (e.g. `cp file destfile/` now generates an error instead of ignoring the trailing slash.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10127
https://github.com/hail-is/hail/pull/10127:625,Testability,test,test,625,"This is needed to properly implement copy/rename when you don't know if the source is a file or directory. We now only stat dest if treat_dest_as == INFER_DEST. Suppose we do `cp src dest`. There are three cases:. - Treat dest as a directory, and copy `src` to `dest/src`; - Treat dest like the target, and copy `src` to `dest` (whether src is a file or directory).; - Infer the type of dest and act accordingly. If `dest` is a directory, we're in the first case. If dest doesn't exist, or is a file, we're in the second case. I added two tests cases: test_copy_rename_dir_dest_is_target and test_overwrite_rename_dir, which test copying a directory with DEST_IS_TARGET (when the dest exists or not). I already had tests for when we were copying a file. I regenerated the copy test specs because of renames and some minor changes to error checking behavior. I spot checked the differences, and they don't seem worse (e.g. `cp file destfile/` now generates an error instead of ignoring the trailing slash.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10127
https://github.com/hail-is/hail/pull/10127:715,Testability,test,tests,715,"This is needed to properly implement copy/rename when you don't know if the source is a file or directory. We now only stat dest if treat_dest_as == INFER_DEST. Suppose we do `cp src dest`. There are three cases:. - Treat dest as a directory, and copy `src` to `dest/src`; - Treat dest like the target, and copy `src` to `dest` (whether src is a file or directory).; - Infer the type of dest and act accordingly. If `dest` is a directory, we're in the first case. If dest doesn't exist, or is a file, we're in the second case. I added two tests cases: test_copy_rename_dir_dest_is_target and test_overwrite_rename_dir, which test copying a directory with DEST_IS_TARGET (when the dest exists or not). I already had tests for when we were copying a file. I regenerated the copy test specs because of renames and some minor changes to error checking behavior. I spot checked the differences, and they don't seem worse (e.g. `cp file destfile/` now generates an error instead of ignoring the trailing slash.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10127
https://github.com/hail-is/hail/pull/10127:777,Testability,test,test,777,"This is needed to properly implement copy/rename when you don't know if the source is a file or directory. We now only stat dest if treat_dest_as == INFER_DEST. Suppose we do `cp src dest`. There are three cases:. - Treat dest as a directory, and copy `src` to `dest/src`; - Treat dest like the target, and copy `src` to `dest` (whether src is a file or directory).; - Infer the type of dest and act accordingly. If `dest` is a directory, we're in the first case. If dest doesn't exist, or is a file, we're in the second case. I added two tests cases: test_copy_rename_dir_dest_is_target and test_overwrite_rename_dir, which test copying a directory with DEST_IS_TARGET (when the dest exists or not). I already had tests for when we were copying a file. I regenerated the copy test specs because of renames and some minor changes to error checking behavior. I spot checked the differences, and they don't seem worse (e.g. `cp file destfile/` now generates an error instead of ignoring the trailing slash.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10127
https://github.com/hail-is/hail/pull/10128:241,Availability,avail,available,241,"This PR introduces `SArray` and `SArrayValue`, lets us compile with arrays. I added implementations for `MakeArray` and `ArrayRef`. . To help myself out, I also registered the region allocation function on the `CompileModule` so it's always available to call. I added a `printf` function as well that takes a C++ string and a vector of `llvm::Value` to allow arbitrary debugging prints.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10128
https://github.com/hail-is/hail/pull/10132:84,Availability,redundant,redundant,84,"The previous formula, `(1/n) (sumsq - (2 * mean * sum) + (n * mean^2))` was weirdly redundant, since `mean * sum == n * mean^2`. This was added by #6728, which ported stats from Scala, but the weird formula did not come from the Scala implementation. I have no clue where this came from. The only reason for doing something like this might be for improved numerical stability, but that doesn't seem to be the case here. In fact, this current method of computing the variance (pre or post this pr) is known to be unstable when the mean is much larger than the stdev (as is easy to see: you're subtracting two nearly equal positive numbers). The Scala implementation used the spark `StatCounter`, which uses the more stable [Welford's algorithm](https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford's_online_algorithm). We should probably fix any variance or stdev computation to use a stable method, which I think requires a dedicated stats aggregator that maintains count, mean, and variance in a smart way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10132
https://github.com/hail-is/hail/pull/10132:84,Safety,redund,redundant,84,"The previous formula, `(1/n) (sumsq - (2 * mean * sum) + (n * mean^2))` was weirdly redundant, since `mean * sum == n * mean^2`. This was added by #6728, which ported stats from Scala, but the weird formula did not come from the Scala implementation. I have no clue where this came from. The only reason for doing something like this might be for improved numerical stability, but that doesn't seem to be the case here. In fact, this current method of computing the variance (pre or post this pr) is known to be unstable when the mean is much larger than the stdev (as is easy to see: you're subtracting two nearly equal positive numbers). The Scala implementation used the spark `StatCounter`, which uses the more stable [Welford's algorithm](https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford's_online_algorithm). We should probably fix any variance or stdev computation to use a stable method, which I think requires a dedicated stats aggregator that maintains count, mean, and variance in a smart way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10132
https://github.com/hail-is/hail/pull/10133:9,Testability,test,test,9,"PRing to test, hopefully will fix Akhil's bug. . Akhil's stack trace top:. ```; Java stack trace:; java.lang.RuntimeException: invoke __m684btree_insert: arg 2: type mismatch:; got +PBoolean; expected PBoolean; 	at is.hail.expr.ir.EmitCodeBuilder$$anonfun$1.apply(EmitCodeBuilder.scala:132); 	at is.hail.expr.ir.EmitCodeBuilder$$anonfun$1.apply(EmitCodeBuilder.scala:114); 	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241); 	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241); 	at scala.collection.immutable.Range.foreach(Range.scala:160); 	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241); 	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104); 	at is.hail.expr.ir.EmitCodeBuilder._invoke(EmitCodeBuilder.scala:114); 	at is.hail.expr.ir.EmitCodeBuilder.invokeCode(EmitCodeBuilder.scala:164); 	at is.hail.expr.ir.agg.AppendOnlyBTree.is$hail$expr$ir$agg$AppendOnlyBTree$$insert(AppendOnlyBTree.scala:231); 	at is.hail.expr.ir.agg.AppendOnlyBTree$$anonfun$getF$1$$anonfun$is$hail$expr$ir$agg$AppendOnlyBTree$$anonfun$$insertOrGetAt$1$1.apply$mcV$sp(AppendOnlyBTree.scala:245); 	at is.hail.asm4s.CodeBuilderLike$class.ifx(CodeBuilder.scala:83); 	at is.hail.expr.ir.EmitCodeBuilder.ifx(EmitCodeBuilder.scala:37); 	at is.hail.expr.ir.agg.AppendOnlyBTree$$anonfun$getF$1.is$hail$expr$ir$agg$AppendOnlyBTree$$anonfun$$insertOrGetAt$1(AppendOnlyBTree.scala:244); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10133
https://github.com/hail-is/hail/pull/10136:87,Availability,alive,alive,87,I think there is some unresolved issue with asyncgen shutdown that is keeping; workers alive. This is not an issue in worker because worker calls sys.exit; which forcibly stops execution. cc: @daniel-goldstein @jigold.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10136
https://github.com/hail-is/hail/pull/10137:97,Deployability,update,update,97,"When a bunch of longer running jobs got deleted at once, we instantly deleted the app. We should update the last_updated time when a delete operation comes in.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10137
https://github.com/hail-is/hail/pull/10139:373,Integrability,rout,router-resolver,373,"Right now the Grafana is exposed as a k8s service speaking http with only the grafana auth. This puts an nginx sidecar in front of Grafana to bring TLS all the way through the the Grafana pod and perform dev authentication. This required adding an api endpoint to auth that can verify a connection based on the session and not an Authorization header. Other services like `router-resolver` have gotten away with not having this since they construct the Authorization header in python before hitting the `userinfo` endpoint, but this seems like a straightforward addition that will make it easier for internal authentication such as this case. This does another deviant thing which is using a `runImage` step to template the nginx config instead of templating inside the container at container start time (like router and site currently do). It is a little janky, because there are essentially two jinja passes, one in CI to render the shell script for the job, and then the jinja line in the job itself to render the nginx config. But this looks to be the most straightforward way I could figure out without adding another `build.py` Step type and even in that case it would have to be some sort of no-op job.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10139
https://github.com/hail-is/hail/pull/10139:810,Integrability,rout,router,810,"Right now the Grafana is exposed as a k8s service speaking http with only the grafana auth. This puts an nginx sidecar in front of Grafana to bring TLS all the way through the the Grafana pod and perform dev authentication. This required adding an api endpoint to auth that can verify a connection based on the session and not an Authorization header. Other services like `router-resolver` have gotten away with not having this since they construct the Authorization header in python before hitting the `userinfo` endpoint, but this seems like a straightforward addition that will make it easier for internal authentication such as this case. This does another deviant thing which is using a `runImage` step to template the nginx config instead of templating inside the container at container start time (like router and site currently do). It is a little janky, because there are essentially two jinja passes, one in CI to render the shell script for the job, and then the jinja line in the job itself to render the nginx config. But this looks to be the most straightforward way I could figure out without adding another `build.py` Step type and even in that case it would have to be some sort of no-op job.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10139
https://github.com/hail-is/hail/pull/10139:730,Modifiability,config,config,730,"Right now the Grafana is exposed as a k8s service speaking http with only the grafana auth. This puts an nginx sidecar in front of Grafana to bring TLS all the way through the the Grafana pod and perform dev authentication. This required adding an api endpoint to auth that can verify a connection based on the session and not an Authorization header. Other services like `router-resolver` have gotten away with not having this since they construct the Authorization header in python before hitting the `userinfo` endpoint, but this seems like a straightforward addition that will make it easier for internal authentication such as this case. This does another deviant thing which is using a `runImage` step to template the nginx config instead of templating inside the container at container start time (like router and site currently do). It is a little janky, because there are essentially two jinja passes, one in CI to render the shell script for the job, and then the jinja line in the job itself to render the nginx config. But this looks to be the most straightforward way I could figure out without adding another `build.py` Step type and even in that case it would have to be some sort of no-op job.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10139
https://github.com/hail-is/hail/pull/10139:1023,Modifiability,config,config,1023,"Right now the Grafana is exposed as a k8s service speaking http with only the grafana auth. This puts an nginx sidecar in front of Grafana to bring TLS all the way through the the Grafana pod and perform dev authentication. This required adding an api endpoint to auth that can verify a connection based on the session and not an Authorization header. Other services like `router-resolver` have gotten away with not having this since they construct the Authorization header in python before hitting the `userinfo` endpoint, but this seems like a straightforward addition that will make it easier for internal authentication such as this case. This does another deviant thing which is using a `runImage` step to template the nginx config instead of templating inside the container at container start time (like router and site currently do). It is a little janky, because there are essentially two jinja passes, one in CI to render the shell script for the job, and then the jinja line in the job itself to render the nginx config. But this looks to be the most straightforward way I could figure out without adding another `build.py` Step type and even in that case it would have to be some sort of no-op job.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10139
https://github.com/hail-is/hail/pull/10139:196,Performance,perform,perform,196,"Right now the Grafana is exposed as a k8s service speaking http with only the grafana auth. This puts an nginx sidecar in front of Grafana to bring TLS all the way through the the Grafana pod and perform dev authentication. This required adding an api endpoint to auth that can verify a connection based on the session and not an Authorization header. Other services like `router-resolver` have gotten away with not having this since they construct the Authorization header in python before hitting the `userinfo` endpoint, but this seems like a straightforward addition that will make it easier for internal authentication such as this case. This does another deviant thing which is using a `runImage` step to template the nginx config instead of templating inside the container at container start time (like router and site currently do). It is a little janky, because there are essentially two jinja passes, one in CI to render the shell script for the job, and then the jinja line in the job itself to render the nginx config. But this looks to be the most straightforward way I could figure out without adding another `build.py` Step type and even in that case it would have to be some sort of no-op job.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10139
https://github.com/hail-is/hail/pull/10139:25,Security,expose,exposed,25,"Right now the Grafana is exposed as a k8s service speaking http with only the grafana auth. This puts an nginx sidecar in front of Grafana to bring TLS all the way through the the Grafana pod and perform dev authentication. This required adding an api endpoint to auth that can verify a connection based on the session and not an Authorization header. Other services like `router-resolver` have gotten away with not having this since they construct the Authorization header in python before hitting the `userinfo` endpoint, but this seems like a straightforward addition that will make it easier for internal authentication such as this case. This does another deviant thing which is using a `runImage` step to template the nginx config instead of templating inside the container at container start time (like router and site currently do). It is a little janky, because there are essentially two jinja passes, one in CI to render the shell script for the job, and then the jinja line in the job itself to render the nginx config. But this looks to be the most straightforward way I could figure out without adding another `build.py` Step type and even in that case it would have to be some sort of no-op job.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10139
https://github.com/hail-is/hail/pull/10139:208,Security,authenticat,authentication,208,"Right now the Grafana is exposed as a k8s service speaking http with only the grafana auth. This puts an nginx sidecar in front of Grafana to bring TLS all the way through the the Grafana pod and perform dev authentication. This required adding an api endpoint to auth that can verify a connection based on the session and not an Authorization header. Other services like `router-resolver` have gotten away with not having this since they construct the Authorization header in python before hitting the `userinfo` endpoint, but this seems like a straightforward addition that will make it easier for internal authentication such as this case. This does another deviant thing which is using a `runImage` step to template the nginx config instead of templating inside the container at container start time (like router and site currently do). It is a little janky, because there are essentially two jinja passes, one in CI to render the shell script for the job, and then the jinja line in the job itself to render the nginx config. But this looks to be the most straightforward way I could figure out without adding another `build.py` Step type and even in that case it would have to be some sort of no-op job.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10139
https://github.com/hail-is/hail/pull/10139:330,Security,Authoriz,Authorization,330,"Right now the Grafana is exposed as a k8s service speaking http with only the grafana auth. This puts an nginx sidecar in front of Grafana to bring TLS all the way through the the Grafana pod and perform dev authentication. This required adding an api endpoint to auth that can verify a connection based on the session and not an Authorization header. Other services like `router-resolver` have gotten away with not having this since they construct the Authorization header in python before hitting the `userinfo` endpoint, but this seems like a straightforward addition that will make it easier for internal authentication such as this case. This does another deviant thing which is using a `runImage` step to template the nginx config instead of templating inside the container at container start time (like router and site currently do). It is a little janky, because there are essentially two jinja passes, one in CI to render the shell script for the job, and then the jinja line in the job itself to render the nginx config. But this looks to be the most straightforward way I could figure out without adding another `build.py` Step type and even in that case it would have to be some sort of no-op job.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10139
https://github.com/hail-is/hail/pull/10139:453,Security,Authoriz,Authorization,453,"Right now the Grafana is exposed as a k8s service speaking http with only the grafana auth. This puts an nginx sidecar in front of Grafana to bring TLS all the way through the the Grafana pod and perform dev authentication. This required adding an api endpoint to auth that can verify a connection based on the session and not an Authorization header. Other services like `router-resolver` have gotten away with not having this since they construct the Authorization header in python before hitting the `userinfo` endpoint, but this seems like a straightforward addition that will make it easier for internal authentication such as this case. This does another deviant thing which is using a `runImage` step to template the nginx config instead of templating inside the container at container start time (like router and site currently do). It is a little janky, because there are essentially two jinja passes, one in CI to render the shell script for the job, and then the jinja line in the job itself to render the nginx config. But this looks to be the most straightforward way I could figure out without adding another `build.py` Step type and even in that case it would have to be some sort of no-op job.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10139
https://github.com/hail-is/hail/pull/10139:609,Security,authenticat,authentication,609,"Right now the Grafana is exposed as a k8s service speaking http with only the grafana auth. This puts an nginx sidecar in front of Grafana to bring TLS all the way through the the Grafana pod and perform dev authentication. This required adding an api endpoint to auth that can verify a connection based on the session and not an Authorization header. Other services like `router-resolver` have gotten away with not having this since they construct the Authorization header in python before hitting the `userinfo` endpoint, but this seems like a straightforward addition that will make it easier for internal authentication such as this case. This does another deviant thing which is using a `runImage` step to template the nginx config instead of templating inside the container at container start time (like router and site currently do). It is a little janky, because there are essentially two jinja passes, one in CI to render the shell script for the job, and then the jinja line in the job itself to render the nginx config. But this looks to be the most straightforward way I could figure out without adding another `build.py` Step type and even in that case it would have to be some sort of no-op job.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10139
https://github.com/hail-is/hail/pull/10141:27,Performance,Concurren,Concurrently,27,Reverts hail-is/hail#9738. Concurrently creating certs doesn't work when OpenSSL assigns consecutive serial numbers.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10141
https://github.com/hail-is/hail/pull/10142:1164,Security,authoriz,authorize,1164,"This kind of does a lot of small things:. - Adds a table at the top of the page that is all the PRs that require the user's attention, meaning: a personally authored PR where the build has failed or there are changes requested, or a PR for review that the user has not yet reviewed. - Under PRs that require a review, a user now sees those where they are listed under `Assignees` *as well as* under `Reviewers`. We have been using assignees to assign reviews, but outside collaborators are unable to do so or dismiss reviews. This is because we don't really align with GitHub's semantics for these labels. Per GitHub, Assignees are organization members responsible for the supervision of a PR, whether the author or the final merge sign-off. Meanwhile, reviewers are what they suggest. If an outside contributor submits a PR, they can request a review from organization members in the `Reviewers` box, and then re-request review once they are ready for the PR to be looked at again. We should probably just abandon assignees given how we currently use them, but I just wanted to first get all of the information onto CI so nothing falls through the cracks. - Adds authorize SHA input. - Fixes some small cosmetic bugs like a repeated ""running"" statement in batch tables and enables '/' focus on the jobs table in a batch.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10142
https://github.com/hail-is/hail/pull/10153:80,Testability,test,tests,80,The event loop is supposed to be initialized in the main thread. Sometimes; our tests get placed in the non-main thread (always a thread named Dummy-1).; Hopefully the session-scoped fixture is run in the main thread.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10153
https://github.com/hail-is/hail/pull/10159:45,Availability,error,error,45,Only one coro waits on receive now. We still error if a message is sent before; we make our first response.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10159
https://github.com/hail-is/hail/pull/10159:56,Integrability,message,message,56,Only one coro waits on receive now. We still error if a message is sent before; we make our first response.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10159
https://github.com/hail-is/hail/pull/10160:9,Testability,test,test,9,"We don't test the logs, but I did test this manually, it works as; expected.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10160
https://github.com/hail-is/hail/pull/10160:18,Testability,log,logs,18,"We don't test the logs, but I did test this manually, it works as; expected.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10160
https://github.com/hail-is/hail/pull/10160:34,Testability,test,test,34,"We don't test the logs, but I did test this manually, it works as; expected.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10160
https://github.com/hail-is/hail/pull/10161:62,Deployability,pipeline,pipelines,62,"This is useful for falling back to Dataproc clusters in Batch pipelines, until Query is feature-complete.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10161
https://github.com/hail-is/hail/pull/10162:57,Security,access,access,57,"The grafana image runs with user 472, so that user needs access to the `grafana-storage` persistent volume. Setting the `fsGroup` to 472 mounts the volume under that group.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10162
https://github.com/hail-is/hail/pull/10165:744,Availability,avail,available,744,"This adds a prometheus statefulset to track metrics like API request latency and uptime. It scrapes pods on a 15s interval and collects prometheus metrics from any container in a pod with `grafanak8sapp` label that exposes an https endpoint `/metrics`.; The batch front end was already exposing prometheus metrics, but I changed it up slightly. For any http endpoint there should be a single metric, `http_request_latency`. Prometheus adds app and namespace metrics so seeing latencies for batch in particular is just a filter applied to this single metric. You can track latency of an endpoint by adding the `@monitor_endpoint` decorator defined in `metrics.py`, which tracks latency as well as number of requests and status code per request, available in the `http_request_count` metric. I also added monitoring to all CI endpoints. This also includes an `up` metric for tracking uptime at the same 15s granularity. I'm not convinced prometheus will suit our finer-grained needs surrounding batch, but it should do well enough in the meantime for our more traditional SLIs and allows to focus on one problem at a time.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10165
https://github.com/hail-is/hail/pull/10165:803,Energy Efficiency,monitor,monitoring,803,"This adds a prometheus statefulset to track metrics like API request latency and uptime. It scrapes pods on a 15s interval and collects prometheus metrics from any container in a pod with `grafanak8sapp` label that exposes an https endpoint `/metrics`.; The batch front end was already exposing prometheus metrics, but I changed it up slightly. For any http endpoint there should be a single metric, `http_request_latency`. Prometheus adds app and namespace metrics so seeing latencies for batch in particular is just a filter applied to this single metric. You can track latency of an endpoint by adding the `@monitor_endpoint` decorator defined in `metrics.py`, which tracks latency as well as number of requests and status code per request, available in the `http_request_count` metric. I also added monitoring to all CI endpoints. This also includes an `up` metric for tracking uptime at the same 15s granularity. I'm not convinced prometheus will suit our finer-grained needs surrounding batch, but it should do well enough in the meantime for our more traditional SLIs and allows to focus on one problem at a time.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10165
https://github.com/hail-is/hail/pull/10165:69,Performance,latency,latency,69,"This adds a prometheus statefulset to track metrics like API request latency and uptime. It scrapes pods on a 15s interval and collects prometheus metrics from any container in a pod with `grafanak8sapp` label that exposes an https endpoint `/metrics`.; The batch front end was already exposing prometheus metrics, but I changed it up slightly. For any http endpoint there should be a single metric, `http_request_latency`. Prometheus adds app and namespace metrics so seeing latencies for batch in particular is just a filter applied to this single metric. You can track latency of an endpoint by adding the `@monitor_endpoint` decorator defined in `metrics.py`, which tracks latency as well as number of requests and status code per request, available in the `http_request_count` metric. I also added monitoring to all CI endpoints. This also includes an `up` metric for tracking uptime at the same 15s granularity. I'm not convinced prometheus will suit our finer-grained needs surrounding batch, but it should do well enough in the meantime for our more traditional SLIs and allows to focus on one problem at a time.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10165
https://github.com/hail-is/hail/pull/10165:572,Performance,latency,latency,572,"This adds a prometheus statefulset to track metrics like API request latency and uptime. It scrapes pods on a 15s interval and collects prometheus metrics from any container in a pod with `grafanak8sapp` label that exposes an https endpoint `/metrics`.; The batch front end was already exposing prometheus metrics, but I changed it up slightly. For any http endpoint there should be a single metric, `http_request_latency`. Prometheus adds app and namespace metrics so seeing latencies for batch in particular is just a filter applied to this single metric. You can track latency of an endpoint by adding the `@monitor_endpoint` decorator defined in `metrics.py`, which tracks latency as well as number of requests and status code per request, available in the `http_request_count` metric. I also added monitoring to all CI endpoints. This also includes an `up` metric for tracking uptime at the same 15s granularity. I'm not convinced prometheus will suit our finer-grained needs surrounding batch, but it should do well enough in the meantime for our more traditional SLIs and allows to focus on one problem at a time.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10165
https://github.com/hail-is/hail/pull/10165:677,Performance,latency,latency,677,"This adds a prometheus statefulset to track metrics like API request latency and uptime. It scrapes pods on a 15s interval and collects prometheus metrics from any container in a pod with `grafanak8sapp` label that exposes an https endpoint `/metrics`.; The batch front end was already exposing prometheus metrics, but I changed it up slightly. For any http endpoint there should be a single metric, `http_request_latency`. Prometheus adds app and namespace metrics so seeing latencies for batch in particular is just a filter applied to this single metric. You can track latency of an endpoint by adding the `@monitor_endpoint` decorator defined in `metrics.py`, which tracks latency as well as number of requests and status code per request, available in the `http_request_count` metric. I also added monitoring to all CI endpoints. This also includes an `up` metric for tracking uptime at the same 15s granularity. I'm not convinced prometheus will suit our finer-grained needs surrounding batch, but it should do well enough in the meantime for our more traditional SLIs and allows to focus on one problem at a time.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10165
https://github.com/hail-is/hail/pull/10165:215,Security,expose,exposes,215,"This adds a prometheus statefulset to track metrics like API request latency and uptime. It scrapes pods on a 15s interval and collects prometheus metrics from any container in a pod with `grafanak8sapp` label that exposes an https endpoint `/metrics`.; The batch front end was already exposing prometheus metrics, but I changed it up slightly. For any http endpoint there should be a single metric, `http_request_latency`. Prometheus adds app and namespace metrics so seeing latencies for batch in particular is just a filter applied to this single metric. You can track latency of an endpoint by adding the `@monitor_endpoint` decorator defined in `metrics.py`, which tracks latency as well as number of requests and status code per request, available in the `http_request_count` metric. I also added monitoring to all CI endpoints. This also includes an `up` metric for tracking uptime at the same 15s granularity. I'm not convinced prometheus will suit our finer-grained needs surrounding batch, but it should do well enough in the meantime for our more traditional SLIs and allows to focus on one problem at a time.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10165
https://github.com/hail-is/hail/pull/10172:80,Availability,error,errors,80,"added `curlylint` to lint jinja templates in `check` targets and fixed existing errors that it found. Also standardized on two-space indentation and a more consistent style of indenting jinja templates: everything inside an html div is indented two spaces, no exceptions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10172
https://github.com/hail-is/hail/pull/10174:27,Availability,error,error,27,"CHANGELOG: Fixed incorrect error message when incorrect type specifid with hl.loop. I added a test that gave a bad error message, then rearranged code in `hl.loop` to improve the error message. Prior to this change, the error a user would get here is that they wrote a loop that isn't tail recursive, because hail would insert an implicit cast when trying to unify types, and the casting would wrap the recursive loop call. Now, we check to make sure the loop's return type is correct before analyzing whether it's tail recursive, which I believe removes the possibility of getting a tail recursion error when you should be getting a type error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10174
https://github.com/hail-is/hail/pull/10174:115,Availability,error,error,115,"CHANGELOG: Fixed incorrect error message when incorrect type specifid with hl.loop. I added a test that gave a bad error message, then rearranged code in `hl.loop` to improve the error message. Prior to this change, the error a user would get here is that they wrote a loop that isn't tail recursive, because hail would insert an implicit cast when trying to unify types, and the casting would wrap the recursive loop call. Now, we check to make sure the loop's return type is correct before analyzing whether it's tail recursive, which I believe removes the possibility of getting a tail recursion error when you should be getting a type error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10174
https://github.com/hail-is/hail/pull/10174:179,Availability,error,error,179,"CHANGELOG: Fixed incorrect error message when incorrect type specifid with hl.loop. I added a test that gave a bad error message, then rearranged code in `hl.loop` to improve the error message. Prior to this change, the error a user would get here is that they wrote a loop that isn't tail recursive, because hail would insert an implicit cast when trying to unify types, and the casting would wrap the recursive loop call. Now, we check to make sure the loop's return type is correct before analyzing whether it's tail recursive, which I believe removes the possibility of getting a tail recursion error when you should be getting a type error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10174
https://github.com/hail-is/hail/pull/10174:220,Availability,error,error,220,"CHANGELOG: Fixed incorrect error message when incorrect type specifid with hl.loop. I added a test that gave a bad error message, then rearranged code in `hl.loop` to improve the error message. Prior to this change, the error a user would get here is that they wrote a loop that isn't tail recursive, because hail would insert an implicit cast when trying to unify types, and the casting would wrap the recursive loop call. Now, we check to make sure the loop's return type is correct before analyzing whether it's tail recursive, which I believe removes the possibility of getting a tail recursion error when you should be getting a type error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10174
https://github.com/hail-is/hail/pull/10174:599,Availability,error,error,599,"CHANGELOG: Fixed incorrect error message when incorrect type specifid with hl.loop. I added a test that gave a bad error message, then rearranged code in `hl.loop` to improve the error message. Prior to this change, the error a user would get here is that they wrote a loop that isn't tail recursive, because hail would insert an implicit cast when trying to unify types, and the casting would wrap the recursive loop call. Now, we check to make sure the loop's return type is correct before analyzing whether it's tail recursive, which I believe removes the possibility of getting a tail recursion error when you should be getting a type error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10174
https://github.com/hail-is/hail/pull/10174:639,Availability,error,error,639,"CHANGELOG: Fixed incorrect error message when incorrect type specifid with hl.loop. I added a test that gave a bad error message, then rearranged code in `hl.loop` to improve the error message. Prior to this change, the error a user would get here is that they wrote a loop that isn't tail recursive, because hail would insert an implicit cast when trying to unify types, and the casting would wrap the recursive loop call. Now, we check to make sure the loop's return type is correct before analyzing whether it's tail recursive, which I believe removes the possibility of getting a tail recursion error when you should be getting a type error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10174
https://github.com/hail-is/hail/pull/10174:33,Integrability,message,message,33,"CHANGELOG: Fixed incorrect error message when incorrect type specifid with hl.loop. I added a test that gave a bad error message, then rearranged code in `hl.loop` to improve the error message. Prior to this change, the error a user would get here is that they wrote a loop that isn't tail recursive, because hail would insert an implicit cast when trying to unify types, and the casting would wrap the recursive loop call. Now, we check to make sure the loop's return type is correct before analyzing whether it's tail recursive, which I believe removes the possibility of getting a tail recursion error when you should be getting a type error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10174
https://github.com/hail-is/hail/pull/10174:121,Integrability,message,message,121,"CHANGELOG: Fixed incorrect error message when incorrect type specifid with hl.loop. I added a test that gave a bad error message, then rearranged code in `hl.loop` to improve the error message. Prior to this change, the error a user would get here is that they wrote a loop that isn't tail recursive, because hail would insert an implicit cast when trying to unify types, and the casting would wrap the recursive loop call. Now, we check to make sure the loop's return type is correct before analyzing whether it's tail recursive, which I believe removes the possibility of getting a tail recursion error when you should be getting a type error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10174
https://github.com/hail-is/hail/pull/10174:185,Integrability,message,message,185,"CHANGELOG: Fixed incorrect error message when incorrect type specifid with hl.loop. I added a test that gave a bad error message, then rearranged code in `hl.loop` to improve the error message. Prior to this change, the error a user would get here is that they wrote a loop that isn't tail recursive, because hail would insert an implicit cast when trying to unify types, and the casting would wrap the recursive loop call. Now, we check to make sure the loop's return type is correct before analyzing whether it's tail recursive, which I believe removes the possibility of getting a tail recursion error when you should be getting a type error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10174
https://github.com/hail-is/hail/pull/10174:394,Integrability,wrap,wrap,394,"CHANGELOG: Fixed incorrect error message when incorrect type specifid with hl.loop. I added a test that gave a bad error message, then rearranged code in `hl.loop` to improve the error message. Prior to this change, the error a user would get here is that they wrote a loop that isn't tail recursive, because hail would insert an implicit cast when trying to unify types, and the casting would wrap the recursive loop call. Now, we check to make sure the loop's return type is correct before analyzing whether it's tail recursive, which I believe removes the possibility of getting a tail recursion error when you should be getting a type error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10174
https://github.com/hail-is/hail/pull/10174:94,Testability,test,test,94,"CHANGELOG: Fixed incorrect error message when incorrect type specifid with hl.loop. I added a test that gave a bad error message, then rearranged code in `hl.loop` to improve the error message. Prior to this change, the error a user would get here is that they wrote a loop that isn't tail recursive, because hail would insert an implicit cast when trying to unify types, and the casting would wrap the recursive loop call. Now, we check to make sure the loop's return type is correct before analyzing whether it's tail recursive, which I believe removes the possibility of getting a tail recursion error when you should be getting a type error.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10174
https://github.com/hail-is/hail/pull/10178:21,Availability,failure,failures,21,Due to most of these failures being due to service tests. Feel free to revert when you see fit,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10178
https://github.com/hail-is/hail/pull/10178:51,Testability,test,tests,51,Due to most of these failures being due to service tests. Feel free to revert when you see fit,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10178
https://github.com/hail-is/hail/pull/10179:27,Availability,down,down,27,One more step of stripping down router. ukbb lives in its own namespace and we never run dev versions of it so it's pretty much a drop-in.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10179
https://github.com/hail-is/hail/pull/10179:32,Integrability,rout,router,32,One more step of stripping down router. ukbb lives in its own namespace and we never run dev versions of it so it's pretty much a drop-in.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10179
https://github.com/hail-is/hail/pull/10181:54,Modifiability,config,configs,54,grafana and prometheus jobs for rendering their nginx configs were producing same name outputs so one would overwrite the other.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10181
https://github.com/hail-is/hail/pull/10182:232,Usability,clear,clear,232,"EDIT from John for future readers: The issue here is that in general we only expect consumers to free memory after they're done processing a row. So when doing any sort of filtering operation, we want to make our own region that we clear after each row is filtered out, otherwise the garbage rows will continue to accumulate until we finally find a row to keep. `filterWithContext` demonstrates the correct way to do this, and so switching to use that method fixes the problem.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10182
https://github.com/hail-is/hail/pull/10186:5,Availability,avail,available,5,"Make available [pan-ukb datasets](https://pan.ukbb.broadinstitute.org/docs/hail-format) via datasets API. Includes:; - Summary statistics MatrixTable, meta-analysis MatrixTable (both on GCS and S3); - LD score Table, variant index table, and LD BlockMatrix for each population (AFR, AMR, CSA, EAS, EUR, MID) (S3 only)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10186
https://github.com/hail-is/hail/pull/10188:82,Deployability,update,update,82,"Dev certificates expire in 30 days, and rerunning `kubectl create secret` doesn't update the secret if it already exists. So adding a `kubectl delete secret` line to make sure the new secret will be added. Though I'm not familiar with the `test` scope and not sure if it will break something for it?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10188
https://github.com/hail-is/hail/pull/10188:4,Security,certificate,certificates,4,"Dev certificates expire in 30 days, and rerunning `kubectl create secret` doesn't update the secret if it already exists. So adding a `kubectl delete secret` line to make sure the new secret will be added. Though I'm not familiar with the `test` scope and not sure if it will break something for it?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10188
https://github.com/hail-is/hail/pull/10188:240,Testability,test,test,240,"Dev certificates expire in 30 days, and rerunning `kubectl create secret` doesn't update the secret if it already exists. So adding a `kubectl delete secret` line to make sure the new secret will be added. Though I'm not familiar with the `test` scope and not sure if it will break something for it?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10188
https://github.com/hail-is/hail/pull/10189:166,Modifiability,variab,variables,166,"The idea is to allow the execution on both `SparkBackend` and `ServiceBackend` without code changes, simply switching to the Query service by setting the environment variables `HAIL_QUERY_BACKEND`, `HAIL_BILLING_PROJECT`, and `HAIL_BUCKET`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10189
https://github.com/hail-is/hail/pull/10189:101,Usability,simpl,simply,101,"The idea is to allow the execution on both `SparkBackend` and `ServiceBackend` without code changes, simply switching to the Query service by setting the environment variables `HAIL_QUERY_BACKEND`, `HAIL_BILLING_PROJECT`, and `HAIL_BUCKET`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10189
https://github.com/hail-is/hail/pull/10192:205,Modifiability,config,config,205,This is one piece of a multi-part saga to use tls for any and all communication between pods. This basically just required adding the `create_certs` step to the ci test `build.yaml` so we can create a ssl config for `hello`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10192
https://github.com/hail-is/hail/pull/10192:164,Testability,test,test,164,This is one piece of a multi-part saga to use tls for any and all communication between pods. This basically just required adding the `create_certs` step to the ci test `build.yaml` so we can create a ssl config for `hello`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10192
https://github.com/hail-is/hail/pull/10194:10,Deployability,update,update,10,Forgot to update this usage of the `pr_table` macro when fixing search bars.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10194
https://github.com/hail-is/hail/pull/10196:156,Integrability,rout,route,156,"We track valid docs paths in `docs_pages` relative to the docs directory, so e.g. `0.2/objects.inv` is a valid path, making `/docs/0.2/objects.inv` a valid route, but `0.2/objects.inv` is not a valid path on the host. To actually find and serve the file we have to use `f'{DOCS_PATH}/0.2/objects.inv`. We initialize jinja to know to look at the `docs` directory for templates but `web.FileResponse` takes a path to the specified file (all I could get from the documentation). Verified I receive `objects.inv` and get a 200 in my namespace.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/pull/10196
https://github.com/hail-is/hail/issues/10197:51,Deployability,install,installed,51,"On Ubuntu 20.10, with Python 3.8.6 and hail 0.2.64 installed from pip, I get: I get `TypeError: an integer is required (got type bytes)` immediately upon importing hail. A full transcript is below. (pyve is an alias to create a python virtual env and activate it). ---. ```; snafu$ pyve; + python3.8 -m venv venv/3.8; + source venv/3.8/bin/activate; + pip install -U setuptools pip; Collecting setuptools; Using cached setuptools-54.1.2-py3-none-any.whl (785 kB); Collecting pip; Using cached pip-21.0.1-py3-none-any.whl (1.5 MB); Installing collected packages: setuptools, pip; Attempting uninstall: setuptools; Found existing installation: setuptools 44.0.0; Uninstalling setuptools-44.0.0:; Successfully uninstalled setuptools-44.0.0; Attempting uninstall: pip; Found existing installation: pip 20.1.1; Uninstalling pip-20.1.1:; Successfully uninstalled pip-20.1.1; Successfully installed pip-21.0.1 setuptools-54.1.2; (3.8)  ~/sandbox/hail [master|8?2]; snafu$ pip install hail ipython; Collecting hail; Using cached hail-0.2.64-py3-none-any.whl (97.5 MB); Collecting ipython; Using cached ipython-7.21.0-py3-none-any.whl (784 kB); Collecting pandas<1.1.5,>=1.1.0; Using cached pandas-1.1.4-cp38-cp38-manylinux1_x86_64.whl (9.3 MB); Collecting python-json-logger==0.1.11; Using cached python_json_logger-0.1.11-py2.py3-none-any.whl; Collecting gcsfs==0.7.2; Using cached gcsfs-0.7.2-py2.py3-none-any.whl (22 kB); Collecting requests==2.22.0; Using cached requests-2.22.0-py2.py3-none-any.whl (57 kB); Collecting tabulate==0.8.3; Using cached tabulate-0.8.3-py3-none-any.whl; Collecting nest-asyncio; Using cached nest_asyncio-1.5.1-py3-none-any.whl (5.0 kB); Collecting parsimonious<0.9; Using cached parsimonious-0.8.1-py3-none-any.whl; Collecting pyspark<2.4.2,>=2.4; Using cached pyspark-2.4.1-py2.py3-none-any.whl; Collecting tqdm==4.42.1; Using cached tqdm-4.42.1-py2.py3-none-any.whl (59 kB); Collecting bokeh<2.0,>1.3; Using cached bokeh-1.4.0-py3-none-any.whl; Collecting Deprecated<1.3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10197
https://github.com/hail-is/hail/issues/10197:357,Deployability,install,install,357,"On Ubuntu 20.10, with Python 3.8.6 and hail 0.2.64 installed from pip, I get: I get `TypeError: an integer is required (got type bytes)` immediately upon importing hail. A full transcript is below. (pyve is an alias to create a python virtual env and activate it). ---. ```; snafu$ pyve; + python3.8 -m venv venv/3.8; + source venv/3.8/bin/activate; + pip install -U setuptools pip; Collecting setuptools; Using cached setuptools-54.1.2-py3-none-any.whl (785 kB); Collecting pip; Using cached pip-21.0.1-py3-none-any.whl (1.5 MB); Installing collected packages: setuptools, pip; Attempting uninstall: setuptools; Found existing installation: setuptools 44.0.0; Uninstalling setuptools-44.0.0:; Successfully uninstalled setuptools-44.0.0; Attempting uninstall: pip; Found existing installation: pip 20.1.1; Uninstalling pip-20.1.1:; Successfully uninstalled pip-20.1.1; Successfully installed pip-21.0.1 setuptools-54.1.2; (3.8)  ~/sandbox/hail [master|8?2]; snafu$ pip install hail ipython; Collecting hail; Using cached hail-0.2.64-py3-none-any.whl (97.5 MB); Collecting ipython; Using cached ipython-7.21.0-py3-none-any.whl (784 kB); Collecting pandas<1.1.5,>=1.1.0; Using cached pandas-1.1.4-cp38-cp38-manylinux1_x86_64.whl (9.3 MB); Collecting python-json-logger==0.1.11; Using cached python_json_logger-0.1.11-py2.py3-none-any.whl; Collecting gcsfs==0.7.2; Using cached gcsfs-0.7.2-py2.py3-none-any.whl (22 kB); Collecting requests==2.22.0; Using cached requests-2.22.0-py2.py3-none-any.whl (57 kB); Collecting tabulate==0.8.3; Using cached tabulate-0.8.3-py3-none-any.whl; Collecting nest-asyncio; Using cached nest_asyncio-1.5.1-py3-none-any.whl (5.0 kB); Collecting parsimonious<0.9; Using cached parsimonious-0.8.1-py3-none-any.whl; Collecting pyspark<2.4.2,>=2.4; Using cached pyspark-2.4.1-py2.py3-none-any.whl; Collecting tqdm==4.42.1; Using cached tqdm-4.42.1-py2.py3-none-any.whl (59 kB); Collecting bokeh<2.0,>1.3; Using cached bokeh-1.4.0-py3-none-any.whl; Collecting Deprecated<1.3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10197
https://github.com/hail-is/hail/issues/10197:532,Deployability,Install,Installing,532,"On Ubuntu 20.10, with Python 3.8.6 and hail 0.2.64 installed from pip, I get: I get `TypeError: an integer is required (got type bytes)` immediately upon importing hail. A full transcript is below. (pyve is an alias to create a python virtual env and activate it). ---. ```; snafu$ pyve; + python3.8 -m venv venv/3.8; + source venv/3.8/bin/activate; + pip install -U setuptools pip; Collecting setuptools; Using cached setuptools-54.1.2-py3-none-any.whl (785 kB); Collecting pip; Using cached pip-21.0.1-py3-none-any.whl (1.5 MB); Installing collected packages: setuptools, pip; Attempting uninstall: setuptools; Found existing installation: setuptools 44.0.0; Uninstalling setuptools-44.0.0:; Successfully uninstalled setuptools-44.0.0; Attempting uninstall: pip; Found existing installation: pip 20.1.1; Uninstalling pip-20.1.1:; Successfully uninstalled pip-20.1.1; Successfully installed pip-21.0.1 setuptools-54.1.2; (3.8)  ~/sandbox/hail [master|8?2]; snafu$ pip install hail ipython; Collecting hail; Using cached hail-0.2.64-py3-none-any.whl (97.5 MB); Collecting ipython; Using cached ipython-7.21.0-py3-none-any.whl (784 kB); Collecting pandas<1.1.5,>=1.1.0; Using cached pandas-1.1.4-cp38-cp38-manylinux1_x86_64.whl (9.3 MB); Collecting python-json-logger==0.1.11; Using cached python_json_logger-0.1.11-py2.py3-none-any.whl; Collecting gcsfs==0.7.2; Using cached gcsfs-0.7.2-py2.py3-none-any.whl (22 kB); Collecting requests==2.22.0; Using cached requests-2.22.0-py2.py3-none-any.whl (57 kB); Collecting tabulate==0.8.3; Using cached tabulate-0.8.3-py3-none-any.whl; Collecting nest-asyncio; Using cached nest_asyncio-1.5.1-py3-none-any.whl (5.0 kB); Collecting parsimonious<0.9; Using cached parsimonious-0.8.1-py3-none-any.whl; Collecting pyspark<2.4.2,>=2.4; Using cached pyspark-2.4.1-py2.py3-none-any.whl; Collecting tqdm==4.42.1; Using cached tqdm-4.42.1-py2.py3-none-any.whl (59 kB); Collecting bokeh<2.0,>1.3; Using cached bokeh-1.4.0-py3-none-any.whl; Collecting Deprecated<1.3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10197
https://github.com/hail-is/hail/issues/10197:629,Deployability,install,installation,629,"On Ubuntu 20.10, with Python 3.8.6 and hail 0.2.64 installed from pip, I get: I get `TypeError: an integer is required (got type bytes)` immediately upon importing hail. A full transcript is below. (pyve is an alias to create a python virtual env and activate it). ---. ```; snafu$ pyve; + python3.8 -m venv venv/3.8; + source venv/3.8/bin/activate; + pip install -U setuptools pip; Collecting setuptools; Using cached setuptools-54.1.2-py3-none-any.whl (785 kB); Collecting pip; Using cached pip-21.0.1-py3-none-any.whl (1.5 MB); Installing collected packages: setuptools, pip; Attempting uninstall: setuptools; Found existing installation: setuptools 44.0.0; Uninstalling setuptools-44.0.0:; Successfully uninstalled setuptools-44.0.0; Attempting uninstall: pip; Found existing installation: pip 20.1.1; Uninstalling pip-20.1.1:; Successfully uninstalled pip-20.1.1; Successfully installed pip-21.0.1 setuptools-54.1.2; (3.8)  ~/sandbox/hail [master|8?2]; snafu$ pip install hail ipython; Collecting hail; Using cached hail-0.2.64-py3-none-any.whl (97.5 MB); Collecting ipython; Using cached ipython-7.21.0-py3-none-any.whl (784 kB); Collecting pandas<1.1.5,>=1.1.0; Using cached pandas-1.1.4-cp38-cp38-manylinux1_x86_64.whl (9.3 MB); Collecting python-json-logger==0.1.11; Using cached python_json_logger-0.1.11-py2.py3-none-any.whl; Collecting gcsfs==0.7.2; Using cached gcsfs-0.7.2-py2.py3-none-any.whl (22 kB); Collecting requests==2.22.0; Using cached requests-2.22.0-py2.py3-none-any.whl (57 kB); Collecting tabulate==0.8.3; Using cached tabulate-0.8.3-py3-none-any.whl; Collecting nest-asyncio; Using cached nest_asyncio-1.5.1-py3-none-any.whl (5.0 kB); Collecting parsimonious<0.9; Using cached parsimonious-0.8.1-py3-none-any.whl; Collecting pyspark<2.4.2,>=2.4; Using cached pyspark-2.4.1-py2.py3-none-any.whl; Collecting tqdm==4.42.1; Using cached tqdm-4.42.1-py2.py3-none-any.whl (59 kB); Collecting bokeh<2.0,>1.3; Using cached bokeh-1.4.0-py3-none-any.whl; Collecting Deprecated<1.3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10197
https://github.com/hail-is/hail/issues/10197:781,Deployability,install,installation,781,"On Ubuntu 20.10, with Python 3.8.6 and hail 0.2.64 installed from pip, I get: I get `TypeError: an integer is required (got type bytes)` immediately upon importing hail. A full transcript is below. (pyve is an alias to create a python virtual env and activate it). ---. ```; snafu$ pyve; + python3.8 -m venv venv/3.8; + source venv/3.8/bin/activate; + pip install -U setuptools pip; Collecting setuptools; Using cached setuptools-54.1.2-py3-none-any.whl (785 kB); Collecting pip; Using cached pip-21.0.1-py3-none-any.whl (1.5 MB); Installing collected packages: setuptools, pip; Attempting uninstall: setuptools; Found existing installation: setuptools 44.0.0; Uninstalling setuptools-44.0.0:; Successfully uninstalled setuptools-44.0.0; Attempting uninstall: pip; Found existing installation: pip 20.1.1; Uninstalling pip-20.1.1:; Successfully uninstalled pip-20.1.1; Successfully installed pip-21.0.1 setuptools-54.1.2; (3.8)  ~/sandbox/hail [master|8?2]; snafu$ pip install hail ipython; Collecting hail; Using cached hail-0.2.64-py3-none-any.whl (97.5 MB); Collecting ipython; Using cached ipython-7.21.0-py3-none-any.whl (784 kB); Collecting pandas<1.1.5,>=1.1.0; Using cached pandas-1.1.4-cp38-cp38-manylinux1_x86_64.whl (9.3 MB); Collecting python-json-logger==0.1.11; Using cached python_json_logger-0.1.11-py2.py3-none-any.whl; Collecting gcsfs==0.7.2; Using cached gcsfs-0.7.2-py2.py3-none-any.whl (22 kB); Collecting requests==2.22.0; Using cached requests-2.22.0-py2.py3-none-any.whl (57 kB); Collecting tabulate==0.8.3; Using cached tabulate-0.8.3-py3-none-any.whl; Collecting nest-asyncio; Using cached nest_asyncio-1.5.1-py3-none-any.whl (5.0 kB); Collecting parsimonious<0.9; Using cached parsimonious-0.8.1-py3-none-any.whl; Collecting pyspark<2.4.2,>=2.4; Using cached pyspark-2.4.1-py2.py3-none-any.whl; Collecting tqdm==4.42.1; Using cached tqdm-4.42.1-py2.py3-none-any.whl (59 kB); Collecting bokeh<2.0,>1.3; Using cached bokeh-1.4.0-py3-none-any.whl; Collecting Deprecated<1.3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10197
https://github.com/hail-is/hail/issues/10197:883,Deployability,install,installed,883,"On Ubuntu 20.10, with Python 3.8.6 and hail 0.2.64 installed from pip, I get: I get `TypeError: an integer is required (got type bytes)` immediately upon importing hail. A full transcript is below. (pyve is an alias to create a python virtual env and activate it). ---. ```; snafu$ pyve; + python3.8 -m venv venv/3.8; + source venv/3.8/bin/activate; + pip install -U setuptools pip; Collecting setuptools; Using cached setuptools-54.1.2-py3-none-any.whl (785 kB); Collecting pip; Using cached pip-21.0.1-py3-none-any.whl (1.5 MB); Installing collected packages: setuptools, pip; Attempting uninstall: setuptools; Found existing installation: setuptools 44.0.0; Uninstalling setuptools-44.0.0:; Successfully uninstalled setuptools-44.0.0; Attempting uninstall: pip; Found existing installation: pip 20.1.1; Uninstalling pip-20.1.1:; Successfully uninstalled pip-20.1.1; Successfully installed pip-21.0.1 setuptools-54.1.2; (3.8)  ~/sandbox/hail [master|8?2]; snafu$ pip install hail ipython; Collecting hail; Using cached hail-0.2.64-py3-none-any.whl (97.5 MB); Collecting ipython; Using cached ipython-7.21.0-py3-none-any.whl (784 kB); Collecting pandas<1.1.5,>=1.1.0; Using cached pandas-1.1.4-cp38-cp38-manylinux1_x86_64.whl (9.3 MB); Collecting python-json-logger==0.1.11; Using cached python_json_logger-0.1.11-py2.py3-none-any.whl; Collecting gcsfs==0.7.2; Using cached gcsfs-0.7.2-py2.py3-none-any.whl (22 kB); Collecting requests==2.22.0; Using cached requests-2.22.0-py2.py3-none-any.whl (57 kB); Collecting tabulate==0.8.3; Using cached tabulate-0.8.3-py3-none-any.whl; Collecting nest-asyncio; Using cached nest_asyncio-1.5.1-py3-none-any.whl (5.0 kB); Collecting parsimonious<0.9; Using cached parsimonious-0.8.1-py3-none-any.whl; Collecting pyspark<2.4.2,>=2.4; Using cached pyspark-2.4.1-py2.py3-none-any.whl; Collecting tqdm==4.42.1; Using cached tqdm-4.42.1-py2.py3-none-any.whl (59 kB); Collecting bokeh<2.0,>1.3; Using cached bokeh-1.4.0-py3-none-any.whl; Collecting Deprecated<1.3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10197
https://github.com/hail-is/hail/issues/10197:972,Deployability,install,install,972,"On Ubuntu 20.10, with Python 3.8.6 and hail 0.2.64 installed from pip, I get: I get `TypeError: an integer is required (got type bytes)` immediately upon importing hail. A full transcript is below. (pyve is an alias to create a python virtual env and activate it). ---. ```; snafu$ pyve; + python3.8 -m venv venv/3.8; + source venv/3.8/bin/activate; + pip install -U setuptools pip; Collecting setuptools; Using cached setuptools-54.1.2-py3-none-any.whl (785 kB); Collecting pip; Using cached pip-21.0.1-py3-none-any.whl (1.5 MB); Installing collected packages: setuptools, pip; Attempting uninstall: setuptools; Found existing installation: setuptools 44.0.0; Uninstalling setuptools-44.0.0:; Successfully uninstalled setuptools-44.0.0; Attempting uninstall: pip; Found existing installation: pip 20.1.1; Uninstalling pip-20.1.1:; Successfully uninstalled pip-20.1.1; Successfully installed pip-21.0.1 setuptools-54.1.2; (3.8)  ~/sandbox/hail [master|8?2]; snafu$ pip install hail ipython; Collecting hail; Using cached hail-0.2.64-py3-none-any.whl (97.5 MB); Collecting ipython; Using cached ipython-7.21.0-py3-none-any.whl (784 kB); Collecting pandas<1.1.5,>=1.1.0; Using cached pandas-1.1.4-cp38-cp38-manylinux1_x86_64.whl (9.3 MB); Collecting python-json-logger==0.1.11; Using cached python_json_logger-0.1.11-py2.py3-none-any.whl; Collecting gcsfs==0.7.2; Using cached gcsfs-0.7.2-py2.py3-none-any.whl (22 kB); Collecting requests==2.22.0; Using cached requests-2.22.0-py2.py3-none-any.whl (57 kB); Collecting tabulate==0.8.3; Using cached tabulate-0.8.3-py3-none-any.whl; Collecting nest-asyncio; Using cached nest_asyncio-1.5.1-py3-none-any.whl (5.0 kB); Collecting parsimonious<0.9; Using cached parsimonious-0.8.1-py3-none-any.whl; Collecting pyspark<2.4.2,>=2.4; Using cached pyspark-2.4.1-py2.py3-none-any.whl; Collecting tqdm==4.42.1; Using cached tqdm-4.42.1-py2.py3-none-any.whl (59 kB); Collecting bokeh<2.0,>1.3; Using cached bokeh-1.4.0-py3-none-any.whl; Collecting Deprecated<1.3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10197
https://github.com/hail-is/hail/issues/10197:7441,Deployability,Install,Installing,7441,"hed Pygments-2.8.1-py3-none-any.whl (983 kB); Collecting backcall; Using cached backcall-0.2.0-py2.py3-none-any.whl (11 kB); Collecting parso<0.9.0,>=0.8.0; Using cached parso-0.8.1-py2.py3-none-any.whl (93 kB); Collecting ptyprocess>=0.5; Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB); Collecting wcwidth; Using cached wcwidth-0.2.5-py2.py3-none-any.whl (30 kB); Collecting ipython-genutils; Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB); Collecting requests-oauthlib>=0.7.0; Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB); Collecting oauthlib>=3.0.0; Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB); Installing collected packages: six, pyasn1, urllib3, rsa, pyparsing, pyasn1-modules, protobuf, idna, chardet, certifi, cachetools, requests, pytz, packaging, oauthlib, multidict, googleapis-common-protos, google-auth, yarl, typing-extensions, requests-oauthlib, MarkupSafe, google-api-core, attrs, async-timeout, wrapt, wcwidth, tornado, PyYAML, python-dateutil, py4j, ptyprocess, pillow, parso, numpy, Jinja2, ipython-genutils, google-resumable-media, google-cloud-core, google-auth-oauthlib, fsspec, decorator, aiohttp, traitlets, tqdm, tabulate, scipy, python-json-logger, pyspark, PyJWT, pygments, prompt-toolkit, pickleshare, pexpect, parsimonious, pandas, nest-asyncio, jedi, hurry.filesize, humanize, google-cloud-storage, gcsfs, dill, Deprecated, bokeh, backcall, asyncinit, aiohttp-session, ipython, hail; Successfully installed Deprecated-1.2.12 Jinja2-2.11.3 MarkupSafe-1.1.1 PyJWT-2.0.1 PyYAML-5.4.1 aiohttp-3.7.4 aiohttp-session-2.7.0 async-timeout-3.0.1 asyncinit-0.2.4 attrs-20.3.0 backcall-0.2.0 bokeh-1.4.0 cachetools-4.2.1 certifi-2020.12.5 chardet-3.0.4 decorator-4.4.2 dill-0.3.3 fsspec-0.8.7 gcsfs-0.7.2 google-api-core-1.26.1 google-auth-1.27.1 google-auth-oauthlib-0.4.3 google-cloud-core-1.6.0 google-cloud-storage-1.25.0 google-resumable-media-0.5.1 googleapis-common-protos-1.53.0 hail-0.2.64 humanize-1.0.0 hur",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10197
https://github.com/hail-is/hail/issues/10197:8269,Deployability,install,installed,8269,"ils-0.2.0-py2.py3-none-any.whl (26 kB); Collecting requests-oauthlib>=0.7.0; Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB); Collecting oauthlib>=3.0.0; Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB); Installing collected packages: six, pyasn1, urllib3, rsa, pyparsing, pyasn1-modules, protobuf, idna, chardet, certifi, cachetools, requests, pytz, packaging, oauthlib, multidict, googleapis-common-protos, google-auth, yarl, typing-extensions, requests-oauthlib, MarkupSafe, google-api-core, attrs, async-timeout, wrapt, wcwidth, tornado, PyYAML, python-dateutil, py4j, ptyprocess, pillow, parso, numpy, Jinja2, ipython-genutils, google-resumable-media, google-cloud-core, google-auth-oauthlib, fsspec, decorator, aiohttp, traitlets, tqdm, tabulate, scipy, python-json-logger, pyspark, PyJWT, pygments, prompt-toolkit, pickleshare, pexpect, parsimonious, pandas, nest-asyncio, jedi, hurry.filesize, humanize, google-cloud-storage, gcsfs, dill, Deprecated, bokeh, backcall, asyncinit, aiohttp-session, ipython, hail; Successfully installed Deprecated-1.2.12 Jinja2-2.11.3 MarkupSafe-1.1.1 PyJWT-2.0.1 PyYAML-5.4.1 aiohttp-3.7.4 aiohttp-session-2.7.0 async-timeout-3.0.1 asyncinit-0.2.4 attrs-20.3.0 backcall-0.2.0 bokeh-1.4.0 cachetools-4.2.1 certifi-2020.12.5 chardet-3.0.4 decorator-4.4.2 dill-0.3.3 fsspec-0.8.7 gcsfs-0.7.2 google-api-core-1.26.1 google-auth-1.27.1 google-auth-oauthlib-0.4.3 google-cloud-core-1.6.0 google-cloud-storage-1.25.0 google-resumable-media-0.5.1 googleapis-common-protos-1.53.0 hail-0.2.64 humanize-1.0.0 hurry.filesize-0.9 idna-2.8 ipython-7.21.0 ipython-genutils-0.2.0 jedi-0.18.0 multidict-5.1.0 nest-asyncio-1.5.1 numpy-1.20.1 oauthlib-3.1.0 packaging-20.9 pandas-1.1.4 parsimonious-0.8.1 parso-0.8.1 pexpect-4.8.0 pickleshare-0.7.5 pillow-8.1.2 prompt-toolkit-3.0.17 protobuf-3.15.6 ptyprocess-0.7.0 py4j-0.10.7 pyasn1-0.4.8 pyasn1-modules-0.2.8 pygments-2.8.1 pyparsing-2.4.7 pyspark-2.4.1 python-dateutil-2.8.1 python-json-logger-0.1.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10197
https://github.com/hail-is/hail/issues/10197:5191,Integrability,wrap,wrapt,5191,"ls in ./venv/3.8/lib/python3.8/site-packages (from hurry.filesize==0.9->hail) (54.1.2); Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1; Using cached urllib3-1.25.11-py2.py3-none-any.whl (127 kB); Collecting idna<2.9,>=2.5; Using cached idna-2.8-py2.py3-none-any.whl (58 kB); Collecting certifi>=2017.4.17; Using cached certifi-2020.12.5-py2.py3-none-any.whl (147 kB); Collecting tornado>=4.3; Using cached tornado-6.1-cp38-cp38-manylinux2010_x86_64.whl (427 kB); Collecting six>=1.5.2; Using cached six-1.15.0-py2.py3-none-any.whl (10 kB); Collecting packaging>=16.8; Using cached packaging-20.9-py2.py3-none-any.whl (40 kB); Collecting pillow>=4.0; Using cached Pillow-8.1.2-cp38-cp38-manylinux1_x86_64.whl (2.2 MB); Collecting python-dateutil>=2.1; Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB); Collecting PyYAML>=3.10; Using cached PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB); Collecting Jinja2>=2.7; Using cached Jinja2-2.11.3-py2.py3-none-any.whl (125 kB); Collecting wrapt<2,>=1.10; Using cached wrapt-1.12.1-cp38-cp38-linux_x86_64.whl; Collecting pyasn1-modules>=0.2.1; Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB); Collecting rsa<5,>=3.1.4; Using cached rsa-4.7.2-py3-none-any.whl (34 kB); Collecting cachetools<5.0,>=2.0.0; Using cached cachetools-4.2.1-py3-none-any.whl (12 kB); Collecting google-api-core<2.0.0dev,>=1.21.0; Using cached google_api_core-1.26.1-py2.py3-none-any.whl (92 kB); Collecting pytz; Using cached pytz-2021.1-py2.py3-none-any.whl (510 kB); Collecting googleapis-common-protos<2.0dev,>=1.6.0; Using cached googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB); Collecting protobuf>=3.12.0; Using cached protobuf-3.15.6-cp38-cp38-manylinux1_x86_64.whl (1.0 MB); Collecting MarkupSafe>=0.23; Using cached MarkupSafe-1.1.1-cp38-cp38-manylinux2010_x86_64.whl (32 kB); Collecting pyparsing>=2.0.2; Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB); Collecting pyasn1<0.5.0,>=0.4.6; Using cached pyasn1-0.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10197
https://github.com/hail-is/hail/issues/10197:5220,Integrability,wrap,wrapt-,5220,"site-packages (from hurry.filesize==0.9->hail) (54.1.2); Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1; Using cached urllib3-1.25.11-py2.py3-none-any.whl (127 kB); Collecting idna<2.9,>=2.5; Using cached idna-2.8-py2.py3-none-any.whl (58 kB); Collecting certifi>=2017.4.17; Using cached certifi-2020.12.5-py2.py3-none-any.whl (147 kB); Collecting tornado>=4.3; Using cached tornado-6.1-cp38-cp38-manylinux2010_x86_64.whl (427 kB); Collecting six>=1.5.2; Using cached six-1.15.0-py2.py3-none-any.whl (10 kB); Collecting packaging>=16.8; Using cached packaging-20.9-py2.py3-none-any.whl (40 kB); Collecting pillow>=4.0; Using cached Pillow-8.1.2-cp38-cp38-manylinux1_x86_64.whl (2.2 MB); Collecting python-dateutil>=2.1; Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB); Collecting PyYAML>=3.10; Using cached PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB); Collecting Jinja2>=2.7; Using cached Jinja2-2.11.3-py2.py3-none-any.whl (125 kB); Collecting wrapt<2,>=1.10; Using cached wrapt-1.12.1-cp38-cp38-linux_x86_64.whl; Collecting pyasn1-modules>=0.2.1; Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB); Collecting rsa<5,>=3.1.4; Using cached rsa-4.7.2-py3-none-any.whl (34 kB); Collecting cachetools<5.0,>=2.0.0; Using cached cachetools-4.2.1-py3-none-any.whl (12 kB); Collecting google-api-core<2.0.0dev,>=1.21.0; Using cached google_api_core-1.26.1-py2.py3-none-any.whl (92 kB); Collecting pytz; Using cached pytz-2021.1-py2.py3-none-any.whl (510 kB); Collecting googleapis-common-protos<2.0dev,>=1.6.0; Using cached googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB); Collecting protobuf>=3.12.0; Using cached protobuf-3.15.6-cp38-cp38-manylinux1_x86_64.whl (1.0 MB); Collecting MarkupSafe>=0.23; Using cached MarkupSafe-1.1.1-cp38-cp38-manylinux2010_x86_64.whl (32 kB); Collecting pyparsing>=2.0.2; Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB); Collecting pyasn1<0.5.0,>=0.4.6; Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10197
https://github.com/hail-is/hail/issues/10197:7754,Integrability,wrap,wrapt,7754,"hed Pygments-2.8.1-py3-none-any.whl (983 kB); Collecting backcall; Using cached backcall-0.2.0-py2.py3-none-any.whl (11 kB); Collecting parso<0.9.0,>=0.8.0; Using cached parso-0.8.1-py2.py3-none-any.whl (93 kB); Collecting ptyprocess>=0.5; Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB); Collecting wcwidth; Using cached wcwidth-0.2.5-py2.py3-none-any.whl (30 kB); Collecting ipython-genutils; Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB); Collecting requests-oauthlib>=0.7.0; Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB); Collecting oauthlib>=3.0.0; Using cached oauthlib-3.1.0-py2.py3-none-any.whl (147 kB); Installing collected packages: six, pyasn1, urllib3, rsa, pyparsing, pyasn1-modules, protobuf, idna, chardet, certifi, cachetools, requests, pytz, packaging, oauthlib, multidict, googleapis-common-protos, google-auth, yarl, typing-extensions, requests-oauthlib, MarkupSafe, google-api-core, attrs, async-timeout, wrapt, wcwidth, tornado, PyYAML, python-dateutil, py4j, ptyprocess, pillow, parso, numpy, Jinja2, ipython-genutils, google-resumable-media, google-cloud-core, google-auth-oauthlib, fsspec, decorator, aiohttp, traitlets, tqdm, tabulate, scipy, python-json-logger, pyspark, PyJWT, pygments, prompt-toolkit, pickleshare, pexpect, parsimonious, pandas, nest-asyncio, jedi, hurry.filesize, humanize, google-cloud-storage, gcsfs, dill, Deprecated, bokeh, backcall, asyncinit, aiohttp-session, ipython, hail; Successfully installed Deprecated-1.2.12 Jinja2-2.11.3 MarkupSafe-1.1.1 PyJWT-2.0.1 PyYAML-5.4.1 aiohttp-3.7.4 aiohttp-session-2.7.0 async-timeout-3.0.1 asyncinit-0.2.4 attrs-20.3.0 backcall-0.2.0 bokeh-1.4.0 cachetools-4.2.1 certifi-2020.12.5 chardet-3.0.4 decorator-4.4.2 dill-0.3.3 fsspec-0.8.7 gcsfs-0.7.2 google-api-core-1.26.1 google-auth-1.27.1 google-auth-oauthlib-0.4.3 google-cloud-core-1.6.0 google-cloud-storage-1.25.0 google-resumable-media-0.5.1 googleapis-common-protos-1.53.0 hail-0.2.64 humanize-1.0.0 hur",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10197
https://github.com/hail-is/hail/issues/10197:9410,Integrability,wrap,wrapt-,9410,"cinit-0.2.4 attrs-20.3.0 backcall-0.2.0 bokeh-1.4.0 cachetools-4.2.1 certifi-2020.12.5 chardet-3.0.4 decorator-4.4.2 dill-0.3.3 fsspec-0.8.7 gcsfs-0.7.2 google-api-core-1.26.1 google-auth-1.27.1 google-auth-oauthlib-0.4.3 google-cloud-core-1.6.0 google-cloud-storage-1.25.0 google-resumable-media-0.5.1 googleapis-common-protos-1.53.0 hail-0.2.64 humanize-1.0.0 hurry.filesize-0.9 idna-2.8 ipython-7.21.0 ipython-genutils-0.2.0 jedi-0.18.0 multidict-5.1.0 nest-asyncio-1.5.1 numpy-1.20.1 oauthlib-3.1.0 packaging-20.9 pandas-1.1.4 parsimonious-0.8.1 parso-0.8.1 pexpect-4.8.0 pickleshare-0.7.5 pillow-8.1.2 prompt-toolkit-3.0.17 protobuf-3.15.6 ptyprocess-0.7.0 py4j-0.10.7 pyasn1-0.4.8 pyasn1-modules-0.2.8 pygments-2.8.1 pyparsing-2.4.7 pyspark-2.4.1 python-dateutil-2.8.1 python-json-logger-0.1.11 pytz-2021.1 requests-2.22.0 requests-oauthlib-1.3.0 rsa-4.7.2 scipy-1.6.1 six-1.15.0 tabulate-0.8.3 tornado-6.1 tqdm-4.42.1 traitlets-5.0.5 typing-extensions-3.7.4.3 urllib3-1.25.11 wcwidth-0.2.5 wrapt-1.12.1 yarl-1.6.3; (3.8)  ~/sandbox/hail [master|8?2]; snafu$ ipython ; Python 3.8.6 (default, Jan 27 2021, 15:42:20) ; Type 'copyright', 'credits' or 'license' for more information; IPython 7.21.0 -- An enhanced Interactive Python. Type '?' for help. In [1]: import hail; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-1-e24d842d2b9a> in <module>; ----> 1 import hail. ~/sandbox/hail/venv/3.8/lib/python3.8/site-packages/hail/__init__.py in <module>; 32 # F401 '.expr.*' imported but unused; 33 # E402 module level import not at top of file; ---> 34 from .table import Table, GroupedTable, asc, desc # noqa: E402; 35 from .matrixtable import MatrixTable, GroupedMatrixTable # noqa: E402; 36 from .expr import * # noqa: F401,F403,E402. ~/sandbox/hail/venv/3.8/lib/python3.8/site-packages/hail/table.py in <module>; 2 import itertools; 3 import pandas; ----> 4 import pyspark; 5 from typing import Optional",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10197
https://github.com/hail-is/hail/issues/10197:10796,Integrability,protocol,protocol,10796,"a> in <module>; ----> 1 import hail. ~/sandbox/hail/venv/3.8/lib/python3.8/site-packages/hail/__init__.py in <module>; 32 # F401 '.expr.*' imported but unused; 33 # E402 module level import not at top of file; ---> 34 from .table import Table, GroupedTable, asc, desc # noqa: E402; 35 from .matrixtable import MatrixTable, GroupedMatrixTable # noqa: E402; 36 from .expr import * # noqa: F401,F403,E402. ~/sandbox/hail/venv/3.8/lib/python3.8/site-packages/hail/table.py in <module>; 2 import itertools; 3 import pandas; ----> 4 import pyspark; 5 from typing import Optional, Dict, Callable; 6 . ~/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/__init__.py in <module>; 49 ; 50 from pyspark.conf import SparkConf; ---> 51 from pyspark.context import SparkContext; 52 from pyspark.rdd import RDD, RDDBarrier; 53 from pyspark.files import SparkFiles. ~/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/context.py in <module>; 29 from py4j.protocol import Py4JError; 30 ; ---> 31 from pyspark import accumulators; 32 from pyspark.accumulators import Accumulator; 33 from pyspark.broadcast import Broadcast, BroadcastPickleRegistry. ~/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/accumulators.py in <module>; 95 import socketserver as SocketServer; 96 import threading; ---> 97 from pyspark.serializers import read_int, PickleSerializer; 98 ; 99 . ~/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/serializers.py in <module>; 69 xrange = range; 70 ; ---> 71 from pyspark import cloudpickle; 72 from pyspark.util import _exception_message; 73 . ~/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/cloudpickle.py in <module>; 143 ; 144 ; --> 145 _cell_set_template_code = _make_cell_set_template_code(); 146 ; 147 . ~/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/cloudpickle.py in _make_cell_set_template_code(); 124 ); 125 else:; --> 126 return types.CodeType(; 127 co.co_argcount,; 128 co.co_kwonlyargcount,. TypeError: an integer is required",MatchSource.ISSUE,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/issues/10197
